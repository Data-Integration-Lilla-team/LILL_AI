{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data\n",
    "data=pd.read_csv(\"output\\index_csv_parsed.csv\")\n",
    "text_parsed=data[\"parsed_text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2count(data):\n",
    "    out=dict()\n",
    "    for line in data:\n",
    "        if type(line)!=type(\"ue\"):\n",
    "            line=str(line)\n",
    "        else:\n",
    "            words=line.strip()\n",
    "            words=words.split(\" \")\n",
    "            for w in words:\n",
    "                if w not in out:\n",
    "                    out[w]=0\n",
    "                out[w]+=1\n",
    "    out = dict(sorted(out.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "word2count=get_word2count(text_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oggetti', 1156),\n",
       " ('essere', 929),\n",
       " ('due', 880),\n",
       " ('programmazione', 859),\n",
       " ('orientata', 839),\n",
       " ('classe', 791),\n",
       " ('base', 788),\n",
       " ('matrice', 783),\n",
       " ('ogni', 767),\n",
       " ('numero', 765),\n",
       " ('pu', 762),\n",
       " ('esempio', 750),\n",
       " ('public', 733),\n",
       " ('layer', 701),\n",
       " ('funzione', 684),\n",
       " ('geometria', 656),\n",
       " ('copyright', 617),\n",
       " ('sistema', 617),\n",
       " ('dati', 598),\n",
       " ('valore', 588),\n",
       " ('caso', 583),\n",
       " ('esercizio', 535),\n",
       " ('campo', 535),\n",
       " ('combinatoria', 532),\n",
       " ('test', 520),\n",
       " ('punto', 514),\n",
       " ('set', 501),\n",
       " ('solo', 486),\n",
       " ('tipo', 483),\n",
       " ('training', 478),\n",
       " ('metodo', 462),\n",
       " ('corso', 452),\n",
       " ('classi', 451),\n",
       " ('parametri', 447),\n",
       " ('vettore', 444),\n",
       " ('spazio', 440),\n",
       " ('input', 434),\n",
       " ('new', 420),\n",
       " ('learning', 415),\n",
       " ('viene', 411),\n",
       " ('calcolatori', 411),\n",
       " ('output', 405),\n",
       " ('valori', 400),\n",
       " ('elettronici', 399),\n",
       " ('torlone', 395),\n",
       " ('rispetto', 392),\n",
       " ('vettori', 392),\n",
       " ('tempo', 387),\n",
       " ('data', 387),\n",
       " ('modello', 382),\n",
       " ('int', 378),\n",
       " ('pattern', 375),\n",
       " ('riccardo', 370),\n",
       " ('dataset', 367),\n",
       " ('possono', 363),\n",
       " ('corrente', 357),\n",
       " ('feature', 352),\n",
       " ('return', 347),\n",
       " ('modo', 341),\n",
       " ('class', 341),\n",
       " ('forza', 339),\n",
       " ('elementi', 332),\n",
       " ('memoria', 324),\n",
       " ('nome', 319),\n",
       " ('stato', 318),\n",
       " ('array', 318),\n",
       " ('lineare', 313),\n",
       " ('bit', 313),\n",
       " ('dimensione', 310),\n",
       " ('dato', 298),\n",
       " ('rete', 295),\n",
       " ('possiamo', 293),\n",
       " ('stanza', 290),\n",
       " ('metodi', 287),\n",
       " ('void', 286),\n",
       " ('probabilit', 283),\n",
       " ('molto', 278),\n",
       " ('possibile', 278),\n",
       " ('quindi', 276),\n",
       " ('tale', 273),\n",
       " ('universit', 270),\n",
       " ('deve', 270),\n",
       " ('vettoriale', 270),\n",
       " ('somma', 265),\n",
       " ('prima', 264),\n",
       " ('string', 260),\n",
       " ('complessit', 259),\n",
       " ('codice', 258),\n",
       " ('peso', 256),\n",
       " ('quando', 255),\n",
       " ('nodo', 254),\n",
       " ('sempre', 252),\n",
       " ('riferimento', 252),\n",
       " ('stesso', 251),\n",
       " ('matrici', 251),\n",
       " ('operazioni', 250),\n",
       " ('generale', 248),\n",
       " ('carica', 248),\n",
       " ('unit', 247),\n",
       " ('tre', 246)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2count.items())[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 55),\n",
       " ('a', 30),\n",
       " ('e', 24),\n",
       " ('n', 21),\n",
       " ('t', 19),\n",
       " ('r', 19),\n",
       " ('w', 14),\n",
       " ('x', 13),\n",
       " ('s', 10),\n",
       " ('v', 10),\n",
       " ('d', 8),\n",
       " ('b', 7),\n",
       " ('j', 7),\n",
       " ('q', 7),\n",
       " ('l', 6),\n",
       " ('m', 5),\n",
       " ('p', 4),\n",
       " ('u', 4),\n",
       " ('f', 3),\n",
       " ('o', 3),\n",
       " ('i', 3),\n",
       " ('y', 2),\n",
       " ('z', 1),\n",
       " ('g', 1),\n",
       " ('k', 1),\n",
       " ('h', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analisi delle parole\n",
    "single_letter_words=[]\n",
    "for k in word2count.keys():\n",
    "    if len(k)==1:\n",
    "        entry=(k,word2count[k])\n",
    "        single_letter_words.append(entry)\n",
    "\n",
    "\n",
    "single_letter_words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'\\\\\\\\\\', \\'}\\', \\'_\\', \\'^\\', \\'$\\', \\'+\\', \\'.\\', \\'â€¢\\', \\'/\\', \\'=\\', \\'|\\', \\'#\\', \\'[\\', \\'>\\', \\':\\', \\'<\\', \\'(\\', \\'!\\', \\',\\', \\';\\', \\']\\', \\'\"\\', \\')\\', \\'?\\', \\'&\\', \\'-\\', \\'`\\', \"\\'\", \\'@\\', \\'*\\', \\'{\\', \\'%\\', \\'~\\'}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "words=set(string.punctuation)\n",
    "words.add(\"â€¢\")\n",
    "str(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def get_symbols(words):\n",
    "    \n",
    "    symbols = re.findall(r'[^a-zA-Z\\s]', words)\n",
    "    return symbols\n",
    "#other symbols in text\n",
    "\n",
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "symbols = set(json.loads(json_data))\n",
    "for k in word2count.keys():\n",
    "    word=k\n",
    "    symbols_in_words=get_symbols(word)\n",
    "    symbols.update(symbols_in_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "symbols=list(symbols)\n",
    "\n",
    "json_data=json.dumps(symbols)\n",
    "\n",
    "with open(\"symbols.json\",\"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'âŽ¡', 'ã®', '\\uf8fb', 'ðœŒ', 'Î‡', 'â‰ª', 'ð°', 'ã‚', 'ð‘£', 'ÑŽ', 'Ä', 'ð•', 'â‡¡', 'Ã ', 'Â»', 'Ð½', 'ãŸ', 'â™¥', 'Ò§', '\\uf022', 'Â§', 'âˆ©', '\\x02', '\\uf079', '\\uf0b4', '\\uf0cc', 'ð‘‚', 'â‰ƒ', 'Ï‘', 'Î®', 'âŽ¤', 'ã‚', 'â€”', 'â‡£', 'ð‘‰', 'ð”', 'âœ”', 'ãƒ', 'â‡¥', 'âˆˆ', '\\uf0cd', 'á¿¯', 'Â´', 'ðœ™', 'Ï†', '\\uf8f7', '\\uf0a2', 'ð‘™', '\\uf03e', '\\uf072', '\\uf8fa', '\\uf8fc', 'ð’™', 'à´¥', '\\uf024', 'Ã­', 'ã¯', 'âŠ™', 'Ï–', 'Ñ‚', 'â€²', 'â€œ', 'âˆ‚', 'Ãº', 'âŒ§', 'â‰ ', '\\uf0a3', 'Â¼', 'â”€', 'æƒ…', 'Ï‡', '\\uf0c7', 'â—¦', 'ç¾Ž', 'ð‘´', 'Ð·', 'ð‘¤', 'ð›¤', 'Ï‚', 'ðœ“', 'âŠ¥', 'ã‚©', 'â€™', 'ð’Š', 'â„', 'Â®', 'â„°', 'Âµ', 'Ã¯', 'ðœˆ', 'â€¢', 'Ñ€', 'ðœ•', 'ðšº', 'ð—', 'Ã¨', 'é–“', 'âŽ', 'Â¬', '\\uf8ff', 'âˆ§', 'ð¼', 'ð›º', 'å††', 'Î¾', 'Â·', '\\uf0b2', 'â‡’', 'ð‘', 'Û¦', 'â‹…', 'Âª', '\\uf8f1', 'ðœ‡', 'ð‘Ÿ', 'è¶³', '\\uf0b7', 'ð‘‡', 'â‹¯', 'ð‘', 'âˆ«', '\\uf0fc', 'ð›½', '\\uf8f8', 'æ—¥', 'ð‘¡', 'â„“', 'ðš', 'Â°', 'Îµ', '\\uf07b', 'ð·', 'â‰”', 'ð‘„', 'âˆƒ', 'âž¢', 'âŽ£', 'âŒ©', 'Ïµ', 'â‰«', '\\uf8eb', 'ð¿', '\\x9f', 'âœ¸', 'âŠ†', '\\uf8ec', '\\uf064', 'æ³¢', 'ä¸', 'ð€', 'âˆ¼', 'ð‘€', 'ðœ—', 'Ñ†', 'ð›´', 'ð‘˜', '\\uf8ef', '\\uf0d9', '\\u0dcd', 'ãƒ•', '\\uf078', '\\x98', 'Ã§', 'Ï•', 'âŸº', 'åœ¨', 'Ð³', 'è¾¾', 'Ð±', 'ç¤¾', 'ð›', 'å±…', '\\uf8f6', 'Ð¿', 'Ð»', 'ð‘š', 'â‰¥', '\\x0f', 'Â¯', 'Û§', 'á‰', 'ðœŽ', '\\uf04c', 'âŽ¢', 'Å·', 'å ±', 'âŒ¦', 'ð›', 'âŽ ', 'ð‘', 'ðš¥', '\\uf0ce', '\\uf061', 'ð‘', 'ð¶', 'Ð²', 'Ð°', 'ð©', 'ðšª', 'ï¬', 'ð‘“', 'âˆŠ', '\\x03', 'ð›‚', 'ðœ†', 'ð›¥', 'âž¡', 'Ã²', 'â€˜', '\\x10', 'âƒ—', 'âŸ¨', 'ð›¿', 'âˆ™', 'ð›¼', 'âŠ‚', 'ð‘”', 'â‹®', 'ð“”', 'àµ—', 'âˆ¥', 'ð‘’', 'âˆž', 'âŽŸ', '\\uf077', 'Ï‰', '\\x0e', 'Ðº', 'Ð´', 'â—', '\\uf0c8', 'Ç»', 'âŸ©', 'ð›¾', 'ðœ', '\\uf0da', 'â„•', 'â‰…', 'â†’', 'â„Ž', '\\x1b', 'ð½', 'Ë™', 'ð´', 'âŽ¯', 'âŠ—', '\\uf0d8', 'Âº', 'ï¬€', 'Ã¦', 'Ä±', 'ä¸œ', 'âŽ¦', 'ð', 'æ™‚', 'ð‘†', '×', 'ï¬‚', 'éƒ¨', 'å—', 'Ï„', 'æ‹‰', 'ð¹', 'âŽž', '\\uf8f3', '\\uf03c', 'Ã¶', 'Ïƒ', 'Ñ', 'Ã¼', 'â„œ', 'ð‹', '\\uf0e0', '\\x83', 'âˆ…', 'ðŽ', 'ãƒ³', 'à¶±', '\\uf0b9', 'ð‘—', 'â†', '\\uf8f0', 'âœ', '\\uf065', 'Î±', '\\uf053', 'âŽœ', 'â†“', 'Ã¬', 'â‰ˆ', 'Â£', 'Â±', '\\x01', 'ãƒ¥', '\\uf0b3', 'Ñƒ', '\\uf062', 'â„‚', 'ð‘…', '\\uf0c6', '\\uf8fd', 'âŽ¥', 'Â¦', '\\x12', 'ãƒ¼', 'ð²', 'ã€‚', 'Ã¾', 'Ã©', '\\uf8f4', 'ð’', 'ç´„', 'âˆ­', '\\uf075', 'Ã®', '\\uf8ed', 'èŽŽ', 'â‡¢', 'ï¬„', 'âˆ‡', 'â–ª', 'Î¹', 'ð‘¦', 'ð±', 'ð‘§', '\\uf06a', 'âˆš', '\\uf0f1', '\\uffff', 'Î¿', 'Ñ„', 'âˆ‰', '\\uf8fe', 'Ã—', 'ä½', 'Î´', 'ð•”', 'ð‘¥', 'ð‘·', 'Ñ…', 'Ð¹', 'çš„', 'ðœ‹', 'âˆ‘', '\\uf07a', 'Ë†', 'ð‘‘', 'ð‘Ž', 'ð‘¢', 'Î·', '\\uf0a5', 'Ñ‹', 'â‚¬', '\\uf0de', 'ç½—', '\\uf0e8', 'âˆ˜', 'âˆ€', 'ð†', 'Ñ', 'âˆ®', 'Â«', 'âŸ¶', '\\uf8f2', 'âˆ¬', 'å›½', 'çŽ°', 'â€¦', 'Î³', 'Î»', 'â‡¤', 'Ã¡', 'âˆª', 'Ã¸', 'ä½›', 'â†µ', 'â„', 'â€', 'å¨ƒ', 'ð‘œ', 'æœˆ', 'âˆ—', 'ð‘–', 'âŠ˜', 'Ñ‰', 'ð‘ž', 'Ð¾', 'ðœƒ', 'âŒ˜', 'Ð¼', '\\uf0ba', 'â€“', 'â‰¤', 'ãƒ»', 'é‡Œ', 'Ã¹', 'Ñ‡', '\\uf0d6', 'âŽ›', 'Åµ', 'Ðµ', 'Ï', 'Â©', 'â„’', 'Î¼', 'Î¸', '\\uf0cf', 'ð’“', '\\x13', 'â‰¡', 'Ï€', '\\uf06c', 'â‡”', 'ð‘›', 'ð®', 'ð¾', 'Ð¸', 'âˆ’', '\\uf067', 'âŸ¹', 'â¨‚', 'Ì‚', '\\uf076', 'É¸', 'ðœ”', 'Î²', 'ðµ', 'Ãª', 'ðœ‘', 'âœ“', 'ð‘ƒ', 'ð‘ ', 'â– ', 'à´¤', '\\uf0db', 'âˆ', 'ð¸', 'ä¸‡', '\\uf0ae', 'ð‘ª', 'â¨'}\n"
     ]
    }
   ],
   "source": [
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "set_list = json.loads(json_data)\n",
    "\n",
    "# Convert the list to a set\n",
    "my_set = set(set_list)\n",
    "\n",
    "# Now you can use the set as needed\n",
    "print(my_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sto studiare il lingua italiano'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemming\n",
    "import spacy\n",
    "\n",
    "# Load the Italian language model\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "# Text to be lemmatized\n",
    "text = \"Sto studiando la lingua italiana\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatize each token in the text\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Print the lemmas\n",
    "text=\" \".join(lemmas)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ranked retrieval Thus far, our queries have all been Boolean.\\nDocuments either match or donâ€™t.\\nGood for expert users with precise understanding of their needs and the collection.\\nAlso good for applications: Applications can easily consume 1000s of results.\\nNot good for the majority of users.\\nMost users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\\nMost users donâ€™t want to wade through 1000s of results.\\nThis is particularly true of web search.\\nC. D. Manning,\\xa0P. Raghavan\\xa0and\\xa0H. SchÃ¼tze,\\xa0 Introduction to Information Retrieval '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input='''Ranked retrievalThus far, our queries have all been Boolean.\n",
    "Documents either match or donâ€™t.\n",
    "Good for expert users with precise understanding of their needs and the collection.\n",
    "Also good for applications: Applications can easily consume 1000s of results.\n",
    "Not good for the majority of users.\n",
    "Most users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\n",
    "Most users donâ€™t want to wade through 1000s of results.\n",
    "This is particularly true of web search.\n",
    "C. D. Manning,Â P. RaghavanÂ andÂ H. SchÃ¼tze,Â  Introduction to Information Retrieval '''\n",
    "text_with_space = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", input)\n",
    "\n",
    "text_with_space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
