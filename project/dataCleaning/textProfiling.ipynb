{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data\n",
    "data=pd.read_csv(\"output\\index_csv_parsed.csv\")\n",
    "text_parsed=data[\"parsed_text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2count(data):\n",
    "    out=dict()\n",
    "    for line in data:\n",
    "        if type(line)!=type(\"ue\"):\n",
    "            line=str(line)\n",
    "        else:\n",
    "            words=line.strip()\n",
    "            words=words.split(\" \")\n",
    "            for w in words:\n",
    "                if w not in out:\n",
    "                    out[w]=0\n",
    "                out[w]+=1\n",
    "    out = dict(sorted(out.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "word2count=get_word2count(text_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer', 701),\n",
       " ('the', 583),\n",
       " ('ogni', 517),\n",
       " ('campo', 515),\n",
       " ('training', 476),\n",
       " ('due', 445),\n",
       " ('funzione', 437),\n",
       " ('numero', 431),\n",
       " ('learning', 415),\n",
       " ('set', 412),\n",
       " ('input', 410),\n",
       " ('esempio', 390),\n",
       " ('essere', 378),\n",
       " ('output', 378),\n",
       " ('valore', 371),\n",
       " ('pu', 370),\n",
       " ('dati', 369),\n",
       " ('pattern', 369),\n",
       " ('dataset', 367),\n",
       " ('modello', 354),\n",
       " ('feature', 351),\n",
       " ('parametri', 344),\n",
       " ('forza', 330),\n",
       " ('caso', 325),\n",
       " ('valori', 313),\n",
       " ('corrente', 304),\n",
       " ('and', 298),\n",
       " ('data', 281),\n",
       " ('rete', 277),\n",
       " ('probabilit', 273),\n",
       " ('for', 260),\n",
       " ('modo', 258),\n",
       " ('sistema', 255),\n",
       " ('punto', 255),\n",
       " ('carica', 246),\n",
       " ('universit', 246),\n",
       " ('rispetto', 235),\n",
       " ('superficie', 235),\n",
       " ('spazio', 234),\n",
       " ('vettore', 231),\n",
       " ('net', 229),\n",
       " ('classi', 225),\n",
       " ('self', 223),\n",
       " ('esercizio', 220),\n",
       " ('features', 219),\n",
       " ('classe', 214),\n",
       " ('possiamo', 211),\n",
       " ('velocit', 206),\n",
       " ('flusso', 203),\n",
       " ('pesi', 201),\n",
       " ('test', 200),\n",
       " ('classificazione', 198),\n",
       " ('generale', 196),\n",
       " ('regression', 195),\n",
       " ('error', 190),\n",
       " ('punti', 188),\n",
       " ('maltoni', 188),\n",
       " ('bologna', 188),\n",
       " ('model', 187),\n",
       " ('keras', 185),\n",
       " ('densit', 184),\n",
       " ('prof', 184),\n",
       " ('davide', 184),\n",
       " ('distanza', 181),\n",
       " ('machine', 177),\n",
       " ('fisica', 176),\n",
       " ('magnetico', 176),\n",
       " ('import', 175),\n",
       " ('tempo', 174),\n",
       " ('solo', 172),\n",
       " ('molto', 172),\n",
       " ('precedente', 172),\n",
       " ('istanze', 171),\n",
       " ('from', 164),\n",
       " ('kernel', 161),\n",
       " ('circuito', 160),\n",
       " ('lineare', 159),\n",
       " ('tre', 156),\n",
       " ('bayes', 155),\n",
       " ('possono', 154),\n",
       " ('elettrico', 154),\n",
       " ('esempi', 153),\n",
       " ('dimensione', 153),\n",
       " ('deep', 152),\n",
       " ('loss', 150),\n",
       " ('decision', 150),\n",
       " ('problema', 149),\n",
       " ('tale', 149),\n",
       " ('matrice', 146),\n",
       " ('seguente', 145),\n",
       " ('somma', 145),\n",
       " ('step', 143),\n",
       " ('galli', 143),\n",
       " ('moto', 142),\n",
       " ('state', 138),\n",
       " ('learn', 138),\n",
       " ('cariche', 138),\n",
       " ('sempre', 137),\n",
       " ('scikit', 137),\n",
       " ('forze', 137)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2count.items())[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('º', 36),\n",
       " ('𝐱', 22),\n",
       " ('c', 18),\n",
       " ('ª', 18),\n",
       " ('⋅', 18),\n",
       " ('𝚺', 12),\n",
       " ('𝑗', 5),\n",
       " ('t', 4),\n",
       " ('e', 4),\n",
       " ('𝑘', 4),\n",
       " ('ξ', 4),\n",
       " ('°', 3),\n",
       " ('n', 2),\n",
       " ('q', 2),\n",
       " ('a', 2),\n",
       " ('w', 2),\n",
       " ('l', 2),\n",
       " ('𝑠', 2),\n",
       " ('𝐶', 2),\n",
       " ('𝐒', 2),\n",
       " ('d', 1),\n",
       " ('s', 1),\n",
       " ('𝑄', 1),\n",
       " ('𝑟', 1),\n",
       " ('p', 1),\n",
       " ('r', 1),\n",
       " ('↵', 1),\n",
       " ('k', 1),\n",
       " ('𝑚', 1),\n",
       " ('𝜆', 1),\n",
       " ('𝐲', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analisi delle parole\n",
    "single_letter_words=[]\n",
    "for k in word2count.keys():\n",
    "    if len(k)==1:\n",
    "        entry=(k,word2count[k])\n",
    "        single_letter_words.append(entry)\n",
    "\n",
    "\n",
    "single_letter_words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'?\\', \\'}\\', \\'%\\', \\',\\', \\'#\\', \\'^\\', \\'>\\', \\'<\\', \\']\\', \\')\\', \\'@\\', \\'\\\\\\\\\\', \\'[\\', \"\\'\", \\'&\\', \\'$\\', \\'*\\', \\'/\\', \\'|\\', \\':\\', \\'!\\', \\'\"\\', \\'{\\', \\'~\\', \\'+\\', \\'`\\', \\'.\\', \\'=\\', \\'_\\', \\';\\', \\'-\\', \\'•\\', \\'(\\'}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "words=set(string.punctuation)\n",
    "words.add(\"•\")\n",
    "str(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def get_symbols(words):\n",
    "    \n",
    "    symbols = re.findall(r'[^a-zA-Z\\s]', words)\n",
    "    return symbols\n",
    "#other symbols in text\n",
    "\n",
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "symbols = set(json.loads(json_data))\n",
    "for k in word2count.keys():\n",
    "    word=k\n",
    "    symbols_in_words=get_symbols(word)\n",
    "    symbols.update(symbols_in_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "symbols=list(symbols)\n",
    "\n",
    "json_data=json.dumps(symbols)\n",
    "\n",
    "with open(\"symbols.json\",\"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ω', '\\uf024', '–', 'チ', '⋮', '美', '⊥', '\\uf0a3', '\\uf077', '\\uf0cf', 'ҧ', '𝑥', '⨝', '\\u0dcd', '娃', '報', '\\uf0cc', '£', '©', '\\uf0ce', '\\uf0c8', 'ー', 'α', '\\uf0de', '𝛽', '情', '\\uf0da', '住', '∪', '南', '\\uf0cd', '’', '∈', '\\uf0ba', '\\uf0b2', '\\uf03e', '≈', '\\x83', '′', '\\uf079', 'ú', '—', '⇒', '\\uf0a5', 'の', 'め', 'σ', '\\uf0e8', '≤', '达', '罗', '\\uf0b4', '波', '𝑏', '✓', '莎', '\\uf03c', '的', '𝑖', '間', 'β', '。', '\\uf06a', 'フ', 'ォ', 'γ', '·', 'א', '◦', '×', '»', '→', 'π', '社', '足', '\\uf0db', '\\uf053', '¬', 'í', '𝑧', '・', '万', '居', '円', 'à', '∩', '\\uf0a2', 'ュ', '𝜑', '里', 'ù', '\\uf07b', '−', '𝑦', '∞', '←', '¼', 'ï', '\\uf076', '𝑎', 'ℕ', '现', '•', '\\uf04c', '\\uf0d9', 'é', '拉', '日', '𝛼', 'ê', '«', 'τ', '≥', '≠', '\\uf075', '⋯', 'φ', '∉', '”', 'ρ', 'ン', '\\uf0c7', '…', 'ü', '𝑛', 'è', 'ത', '国', '佛', '\\uf0c6', 'ൗ', '\\uf0ae', '𝜋', 'ۦ', '\\uf067', 'ò', '\\uf078', '部', 'あ', '\\uf062', '不', '\\uf0e0', '𝜃', '∗', '∅', 'ۧ', '“', '\\uf0b3', '\\uf064', '\\uf0d6', '𝕔', '\\uf07a', '‘', '东', '\\uf022', '\\uf0b9', '\\uf065', 'た', '約', 'は', '𝑢', '\\uf061', '𝜓', '月', '在', 'ì', '時', '\\uf0f1', '⇔'}\n"
     ]
    }
   ],
   "source": [
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "set_list = json.loads(json_data)\n",
    "\n",
    "# Convert the list to a set\n",
    "my_set = set(set_list)\n",
    "\n",
    "# Now you can use the set as needed\n",
    "print(my_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sto studiare il lingua italiano'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemming\n",
    "import spacy\n",
    "\n",
    "# Load the Italian language model\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "# Text to be lemmatized\n",
    "text = \"Sto studiando la lingua italiana\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatize each token in the text\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Print the lemmas\n",
    "text=\" \".join(lemmas)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ranked retrieval Thus far, our queries have all been Boolean.\\nDocuments either match or don’t.\\nGood for expert users with precise understanding of their needs and the collection.\\nAlso good for applications: Applications can easily consume 1000s of results.\\nNot good for the majority of users.\\nMost users are incapable of writing Boolean queries (or they are, but they think it’s too much work).\\nMost users don’t want to wade through 1000s of results.\\nThis is particularly true of web search.\\nC. D. Manning,\\xa0P. Raghavan\\xa0and\\xa0H. Schütze,\\xa0 Introduction to Information Retrieval '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input='''Ranked retrievalThus far, our queries have all been Boolean.\n",
    "Documents either match or don’t.\n",
    "Good for expert users with precise understanding of their needs and the collection.\n",
    "Also good for applications: Applications can easily consume 1000s of results.\n",
    "Not good for the majority of users.\n",
    "Most users are incapable of writing Boolean queries (or they are, but they think it’s too much work).\n",
    "Most users don’t want to wade through 1000s of results.\n",
    "This is particularly true of web search.\n",
    "C. D. Manning, P. Raghavan and H. Schütze,  Introduction to Information Retrieval '''\n",
    "text_with_space = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", input)\n",
    "\n",
    "text_with_space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
