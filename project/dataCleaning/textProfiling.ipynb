{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data\n",
    "data=pd.read_csv(\"..\\index_csv_parsed.csv\")\n",
    "text_parsed=data[\"parsed_text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2count(data):\n",
    "    out=dict()\n",
    "    for line in data:\n",
    "        if type(line)!=type(\"ue\"):\n",
    "            line=str(line)\n",
    "        else:\n",
    "            words=line.strip()\n",
    "            words=words.split(\" \")\n",
    "            for w in words:\n",
    "                if w not in out:\n",
    "                    out[w]=0\n",
    "                out[w]+=1\n",
    "    out = dict(sorted(out.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "word2count=get_word2count(text_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 986),\n",
       " ('and', 662),\n",
       " ('dati', 348),\n",
       " ('information', 344),\n",
       " ('retrieval', 321),\n",
       " ('introduction', 307),\n",
       " ('manning', 302),\n",
       " ('raghavan', 302),\n",
       " ('schtze', 302),\n",
       " ('basi', 257),\n",
       " ('for', 255),\n",
       " ('query', 238),\n",
       " ('linguaggio', 177),\n",
       " ('document', 176),\n",
       " ('grammatiche', 174),\n",
       " ('qubit', 170),\n",
       " ('data', 165),\n",
       " ('are', 153),\n",
       " ('with', 134),\n",
       " ('', 131),\n",
       " ('not', 130),\n",
       " ('that', 128),\n",
       " ('term', 128),\n",
       " ('tipo', 126),\n",
       " ('terms', 118),\n",
       " ('documents', 112),\n",
       " ('esempio', 109),\n",
       " ('index', 108),\n",
       " ('quantum', 100),\n",
       " ('queries', 98),\n",
       " ('linguaggi', 96),\n",
       " ('this', 96),\n",
       " ('can', 95),\n",
       " ('relazione', 94),\n",
       " ('web', 82),\n",
       " ('search', 76),\n",
       " ('each', 76),\n",
       " ('base', 75),\n",
       " ('but', 75),\n",
       " ('atzeni', 72),\n",
       " ('insieme', 70),\n",
       " ('two', 69),\n",
       " ('have', 68),\n",
       " ('words', 68),\n",
       " ('more', 68),\n",
       " ('insiemi', 66),\n",
       " ('example', 66),\n",
       " ('postings', 62),\n",
       " ('from', 60),\n",
       " ('espressioni', 57),\n",
       " ('idf', 57),\n",
       " ('funzione', 56),\n",
       " ('set', 56),\n",
       " ('dictionary', 56),\n",
       " ('need', 53),\n",
       " ('regolari', 52),\n",
       " ('value', 51),\n",
       " ('xn', 51),\n",
       " ('use', 51),\n",
       " ('stato', 50),\n",
       " ('esercizio', 50),\n",
       " ('computing', 49),\n",
       " ('than', 49),\n",
       " ('numeri', 48),\n",
       " ('text', 47),\n",
       " ('size', 47),\n",
       " ('essere', 46),\n",
       " ('one', 46),\n",
       " ('ogni', 45),\n",
       " ('impiegati', 45),\n",
       " ('new', 45),\n",
       " ('its', 45),\n",
       " ('list', 44),\n",
       " ('processing', 44),\n",
       " ('lucene', 44),\n",
       " ('algoritmi', 43),\n",
       " ('generato', 43),\n",
       " ('ranking', 43),\n",
       " ('boolean', 43),\n",
       " ('valori', 42),\n",
       " ('produzioni', 42),\n",
       " ('grammatica', 42),\n",
       " ('distance', 42),\n",
       " ('due', 41),\n",
       " ('word', 41),\n",
       " ('numero', 40),\n",
       " ('totale', 40),\n",
       " ('battista', 40),\n",
       " ('discovery', 40),\n",
       " ('frequency', 40),\n",
       " ('chapter', 40),\n",
       " ('every', 40),\n",
       " ('tree', 40),\n",
       " ('copyright', 40),\n",
       " ('cardinalit', 39),\n",
       " ('x', 39),\n",
       " ('chomsky', 39),\n",
       " ('relevant', 39),\n",
       " ('how', 39),\n",
       " ('instradamento', 39)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2count.items())[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', 39),\n",
       " ('e', 27),\n",
       " ('v', 24),\n",
       " ('z', 21),\n",
       " ('a', 18),\n",
       " ('l', 15),\n",
       " ('s', 8),\n",
       " ('c', 8),\n",
       " ('m', 6),\n",
       " ('i', 6),\n",
       " ('b', 6),\n",
       " ('p', 6),\n",
       " ('r', 6),\n",
       " ('y', 6),\n",
       " ('n', 5),\n",
       " ('d', 3),\n",
       " ('f', 3),\n",
       " ('g', 3),\n",
       " ('h', 3),\n",
       " ('o', 3),\n",
       " ('q', 3),\n",
       " ('t', 3),\n",
       " ('u', 3)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analisi delle parole\n",
    "single_letter_words=[]\n",
    "for k in word2count.keys():\n",
    "    if len(k)==1:\n",
    "        entry=(k,word2count[k])\n",
    "        single_letter_words.append(entry)\n",
    "\n",
    "\n",
    "single_letter_words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'*\\', \\'!\\', \"\\'\", \\'#\\', \\'?\\', \\'>\\', \\':\\', \\'~\\', \\',\\', \\'+\\', \\'$\\', \\')\\', \\'_\\', \\'<\\', \\'â€¢\\', \\'@\\', \\'{\\', \\'[\\', \\'&\\', \\'-\\', \\']\\', \\'.\\', \\'/\\', \\'%\\', \\'=\\', \\'\\\\\\\\\\', \\'\"\\', \\'}\\', \\'`\\', \\'|\\', \\'(\\', \\'^\\', \\';\\'}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "words=set(string.punctuation)\n",
    "words.add(\"â€¢\")\n",
    "str(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_symbols(words):\n",
    "    \n",
    "    symbols = re.findall(r'[^a-zA-Z\\s]', words)\n",
    "    return symbols\n",
    "#other symbols in text\n",
    "symbols=set()\n",
    "for k in word2count.keys():\n",
    "    word=k\n",
    "    symbols_in_words=get_symbols(word)\n",
    "    symbols.update(symbols_in_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u03c9' in position 2: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     file\u001b[39m.\u001b[39mwrite(json_data)\n\u001b[0;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msymbols.txt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m---> 11\u001b[0m     file\u001b[39m.\u001b[39;49mwrite(\u001b[39mstr\u001b[39;49m(symbols))\n",
      "File \u001b[1;32mC:\\Python39\\lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_encode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,encoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u03c9' in position 2: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "symbols=list(symbols)\n",
    "\n",
    "json_data=json.dumps(symbols)\n",
    "\n",
    "with open(\"symbols.json\",\"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ï‰', '\\uf024', 'â€“', 'ãƒ', 'â‹®', 'ç¾', 'âŠ¥', '\\uf0a3', '\\uf077', '\\uf0cf', 'Ò§', 'ğ‘¥', 'â¨', '\\u0dcd', 'å¨ƒ', 'å ±', '\\uf0cc', 'Â£', 'Â©', '\\uf0ce', '\\uf0c8', 'ãƒ¼', 'Î±', '\\uf0de', 'ğ›½', 'æƒ…', '\\uf0da', 'ä½', 'âˆª', 'å—', '\\uf0cd', 'â€™', 'âˆˆ', '\\uf0ba', '\\uf0b2', '\\uf03e', 'â‰ˆ', '\\x83', 'â€²', '\\uf079', 'Ãº', 'â€”', 'â‡’', '\\uf0a5', 'ã®', 'ã‚', 'Ïƒ', '\\uf0e8', 'â‰¤', 'è¾¾', 'ç½—', '\\uf0b4', 'æ³¢', 'ğ‘', 'âœ“', 'è', '\\uf03c', 'çš„', 'ğ‘–', 'é–“', 'Î²', 'ã€‚', '\\uf06a', 'ãƒ•', 'ã‚©', 'Î³', 'Â·', '×', 'â—¦', 'Ã—', 'Â»', 'â†’', 'Ï€', 'ç¤¾', 'è¶³', '\\uf0db', '\\uf053', 'Â¬', 'Ã­', 'ğ‘§', 'ãƒ»', 'ä¸‡', 'å±…', 'å††', 'Ã ', 'âˆ©', '\\uf0a2', 'ãƒ¥', 'ğœ‘', 'é‡Œ', 'Ã¹', '\\uf07b', 'âˆ’', 'ğ‘¦', 'âˆ', 'â†', 'Â¼', 'Ã¯', '\\uf076', 'ğ‘', 'â„•', 'ç°', 'â€¢', '\\uf04c', '\\uf0d9', 'Ã©', 'æ‹‰', 'æ—¥', 'ğ›¼', 'Ãª', 'Â«', 'Ï„', 'â‰¥', 'â‰ ', '\\uf075', 'â‹¯', 'Ï†', 'âˆ‰', 'â€', 'Ï', 'ãƒ³', '\\uf0c7', 'â€¦', 'Ã¼', 'ğ‘›', 'Ã¨', 'à´¤', 'å›½', 'ä½›', '\\uf0c6', 'àµ—', '\\uf0ae', 'ğœ‹', 'Û¦', '\\uf067', 'Ã²', '\\uf078', 'éƒ¨', 'ã‚', '\\uf062', 'ä¸', '\\uf0e0', 'ğœƒ', 'âˆ—', 'âˆ…', 'Û§', 'â€œ', '\\uf0b3', '\\uf064', '\\uf0d6', 'ğ•”', '\\uf07a', 'â€˜', 'ä¸œ', '\\uf022', '\\uf0b9', '\\uf065', 'ãŸ', 'ç´„', 'ã¯', 'ğ‘¢', '\\uf061', 'ğœ“', 'æœˆ', 'åœ¨', 'Ã¬', 'æ™‚', '\\uf0f1', 'â‡”'}\n"
     ]
    }
   ],
   "source": [
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "set_list = json.loads(json_data)\n",
    "\n",
    "# Convert the list to a set\n",
    "my_set = set(set_list)\n",
    "\n",
    "# Now you can use the set as needed\n",
    "print(my_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sto studiare il lingua italiano'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemming\n",
    "import spacy\n",
    "\n",
    "# Load the Italian language model\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "# Text to be lemmatized\n",
    "text = \"Sto studiando la lingua italiana\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatize each token in the text\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Print the lemmas\n",
    "text=\" \".join(lemmas)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ranked retrieval Thus far, our queries have all been Boolean.\\nDocuments either match or donâ€™t.\\nGood for expert users with precise understanding of their needs and the collection.\\nAlso good for applications: Applications can easily consume 1000s of results.\\nNot good for the majority of users.\\nMost users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\\nMost users donâ€™t want to wade through 1000s of results.\\nThis is particularly true of web search.\\nC. D. Manning,\\xa0P. Raghavan\\xa0and\\xa0H. SchÃ¼tze,\\xa0 Introduction to Information Retrieval '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input='''Ranked retrievalThus far, our queries have all been Boolean.\n",
    "Documents either match or donâ€™t.\n",
    "Good for expert users with precise understanding of their needs and the collection.\n",
    "Also good for applications: Applications can easily consume 1000s of results.\n",
    "Not good for the majority of users.\n",
    "Most users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\n",
    "Most users donâ€™t want to wade through 1000s of results.\n",
    "This is particularly true of web search.\n",
    "C. D. Manning,Â P. RaghavanÂ andÂ H. SchÃ¼tze,Â  Introduction to Information Retrieval '''\n",
    "text_with_space = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", input)\n",
    "\n",
    "text_with_space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
