{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data\n",
    "data=pd.read_csv(\"output\\index_csv_parsed.csv\")\n",
    "text_parsed=data[\"parsed_text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2count(data):\n",
    "    out=dict()\n",
    "    for line in data:\n",
    "        if type(line)!=type(\"ue\"):\n",
    "            line=str(line)\n",
    "        else:\n",
    "            words=line.strip()\n",
    "            words=words.split(\" \")\n",
    "            for w in words:\n",
    "                if w not in out:\n",
    "                    out[w]=0\n",
    "                out[w]+=1\n",
    "    out = dict(sorted(out.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "word2count=get_word2count(text_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer', 701),\n",
       " ('the', 583),\n",
       " ('ogni', 517),\n",
       " ('campo', 515),\n",
       " ('training', 476),\n",
       " ('due', 445),\n",
       " ('funzione', 437),\n",
       " ('numero', 431),\n",
       " ('learning', 415),\n",
       " ('set', 412),\n",
       " ('input', 410),\n",
       " ('esempio', 390),\n",
       " ('essere', 378),\n",
       " ('output', 378),\n",
       " ('valore', 371),\n",
       " ('pu', 370),\n",
       " ('dati', 369),\n",
       " ('pattern', 369),\n",
       " ('dataset', 367),\n",
       " ('modello', 354),\n",
       " ('feature', 351),\n",
       " ('parametri', 344),\n",
       " ('forza', 330),\n",
       " ('caso', 325),\n",
       " ('valori', 313),\n",
       " ('corrente', 304),\n",
       " ('and', 298),\n",
       " ('data', 281),\n",
       " ('rete', 277),\n",
       " ('probabilit', 273),\n",
       " ('for', 260),\n",
       " ('modo', 258),\n",
       " ('sistema', 255),\n",
       " ('punto', 255),\n",
       " ('carica', 246),\n",
       " ('universit', 246),\n",
       " ('rispetto', 235),\n",
       " ('superficie', 235),\n",
       " ('spazio', 234),\n",
       " ('vettore', 231),\n",
       " ('net', 229),\n",
       " ('classi', 225),\n",
       " ('self', 223),\n",
       " ('esercizio', 220),\n",
       " ('features', 219),\n",
       " ('classe', 214),\n",
       " ('possiamo', 211),\n",
       " ('velocit', 206),\n",
       " ('flusso', 203),\n",
       " ('pesi', 201),\n",
       " ('test', 200),\n",
       " ('classificazione', 198),\n",
       " ('generale', 196),\n",
       " ('regression', 195),\n",
       " ('error', 190),\n",
       " ('punti', 188),\n",
       " ('maltoni', 188),\n",
       " ('bologna', 188),\n",
       " ('model', 187),\n",
       " ('keras', 185),\n",
       " ('densit', 184),\n",
       " ('prof', 184),\n",
       " ('davide', 184),\n",
       " ('distanza', 181),\n",
       " ('machine', 177),\n",
       " ('fisica', 176),\n",
       " ('magnetico', 176),\n",
       " ('import', 175),\n",
       " ('tempo', 174),\n",
       " ('solo', 172),\n",
       " ('molto', 172),\n",
       " ('precedente', 172),\n",
       " ('istanze', 171),\n",
       " ('from', 164),\n",
       " ('kernel', 161),\n",
       " ('circuito', 160),\n",
       " ('lineare', 159),\n",
       " ('tre', 156),\n",
       " ('bayes', 155),\n",
       " ('possono', 154),\n",
       " ('elettrico', 154),\n",
       " ('esempi', 153),\n",
       " ('dimensione', 153),\n",
       " ('deep', 152),\n",
       " ('loss', 150),\n",
       " ('decision', 150),\n",
       " ('problema', 149),\n",
       " ('tale', 149),\n",
       " ('matrice', 146),\n",
       " ('seguente', 145),\n",
       " ('somma', 145),\n",
       " ('step', 143),\n",
       " ('galli', 143),\n",
       " ('moto', 142),\n",
       " ('state', 138),\n",
       " ('learn', 138),\n",
       " ('cariche', 138),\n",
       " ('sempre', 137),\n",
       " ('scikit', 137),\n",
       " ('forze', 137)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2count.items())[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Âº', 36),\n",
       " ('ð±', 22),\n",
       " ('c', 18),\n",
       " ('Âª', 18),\n",
       " ('â‹…', 18),\n",
       " ('ðšº', 12),\n",
       " ('ð‘—', 5),\n",
       " ('t', 4),\n",
       " ('e', 4),\n",
       " ('ð‘˜', 4),\n",
       " ('Î¾', 4),\n",
       " ('Â°', 3),\n",
       " ('n', 2),\n",
       " ('q', 2),\n",
       " ('a', 2),\n",
       " ('w', 2),\n",
       " ('l', 2),\n",
       " ('ð‘ ', 2),\n",
       " ('ð¶', 2),\n",
       " ('ð’', 2),\n",
       " ('d', 1),\n",
       " ('s', 1),\n",
       " ('ð‘„', 1),\n",
       " ('ð‘Ÿ', 1),\n",
       " ('p', 1),\n",
       " ('r', 1),\n",
       " ('â†µ', 1),\n",
       " ('k', 1),\n",
       " ('ð‘š', 1),\n",
       " ('ðœ†', 1),\n",
       " ('ð²', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analisi delle parole\n",
    "single_letter_words=[]\n",
    "for k in word2count.keys():\n",
    "    if len(k)==1:\n",
    "        entry=(k,word2count[k])\n",
    "        single_letter_words.append(entry)\n",
    "\n",
    "\n",
    "single_letter_words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'?\\', \\'}\\', \\'%\\', \\',\\', \\'#\\', \\'^\\', \\'>\\', \\'<\\', \\']\\', \\')\\', \\'@\\', \\'\\\\\\\\\\', \\'[\\', \"\\'\", \\'&\\', \\'$\\', \\'*\\', \\'/\\', \\'|\\', \\':\\', \\'!\\', \\'\"\\', \\'{\\', \\'~\\', \\'+\\', \\'`\\', \\'.\\', \\'=\\', \\'_\\', \\';\\', \\'-\\', \\'â€¢\\', \\'(\\'}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "words=set(string.punctuation)\n",
    "words.add(\"â€¢\")\n",
    "str(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def get_symbols(words):\n",
    "    \n",
    "    symbols = re.findall(r'[^a-zA-Z\\s]', words)\n",
    "    return symbols\n",
    "#other symbols in text\n",
    "\n",
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "symbols = set(json.loads(json_data))\n",
    "for k in word2count.keys():\n",
    "    word=k\n",
    "    symbols_in_words=get_symbols(word)\n",
    "    symbols.update(symbols_in_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "symbols=list(symbols)\n",
    "\n",
    "json_data=json.dumps(symbols)\n",
    "\n",
    "with open(\"symbols.json\",\"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ï‰', '\\uf024', 'â€“', 'ãƒ', 'â‹®', 'ç¾Ž', 'âŠ¥', '\\uf0a3', '\\uf077', '\\uf0cf', 'Ò§', 'ð‘¥', 'â¨', '\\u0dcd', 'å¨ƒ', 'å ±', '\\uf0cc', 'Â£', 'Â©', '\\uf0ce', '\\uf0c8', 'ãƒ¼', 'Î±', '\\uf0de', 'ð›½', 'æƒ…', '\\uf0da', 'ä½', 'âˆª', 'å—', '\\uf0cd', 'â€™', 'âˆˆ', '\\uf0ba', '\\uf0b2', '\\uf03e', 'â‰ˆ', '\\x83', 'â€²', '\\uf079', 'Ãº', 'â€”', 'â‡’', '\\uf0a5', 'ã®', 'ã‚', 'Ïƒ', '\\uf0e8', 'â‰¤', 'è¾¾', 'ç½—', '\\uf0b4', 'æ³¢', 'ð‘', 'âœ“', 'èŽŽ', '\\uf03c', 'çš„', 'ð‘–', 'é–“', 'Î²', 'ã€‚', '\\uf06a', 'ãƒ•', 'ã‚©', 'Î³', 'Â·', '×', 'â—¦', 'Ã—', 'Â»', 'â†’', 'Ï€', 'ç¤¾', 'è¶³', '\\uf0db', '\\uf053', 'Â¬', 'Ã­', 'ð‘§', 'ãƒ»', 'ä¸‡', 'å±…', 'å††', 'Ã ', 'âˆ©', '\\uf0a2', 'ãƒ¥', 'ðœ‘', 'é‡Œ', 'Ã¹', '\\uf07b', 'âˆ’', 'ð‘¦', 'âˆž', 'â†', 'Â¼', 'Ã¯', '\\uf076', 'ð‘Ž', 'â„•', 'çŽ°', 'â€¢', '\\uf04c', '\\uf0d9', 'Ã©', 'æ‹‰', 'æ—¥', 'ð›¼', 'Ãª', 'Â«', 'Ï„', 'â‰¥', 'â‰ ', '\\uf075', 'â‹¯', 'Ï†', 'âˆ‰', 'â€', 'Ï', 'ãƒ³', '\\uf0c7', 'â€¦', 'Ã¼', 'ð‘›', 'Ã¨', 'à´¤', 'å›½', 'ä½›', '\\uf0c6', 'àµ—', '\\uf0ae', 'ðœ‹', 'Û¦', '\\uf067', 'Ã²', '\\uf078', 'éƒ¨', 'ã‚', '\\uf062', 'ä¸', '\\uf0e0', 'ðœƒ', 'âˆ—', 'âˆ…', 'Û§', 'â€œ', '\\uf0b3', '\\uf064', '\\uf0d6', 'ð•”', '\\uf07a', 'â€˜', 'ä¸œ', '\\uf022', '\\uf0b9', '\\uf065', 'ãŸ', 'ç´„', 'ã¯', 'ð‘¢', '\\uf061', 'ðœ“', 'æœˆ', 'åœ¨', 'Ã¬', 'æ™‚', '\\uf0f1', 'â‡”'}\n"
     ]
    }
   ],
   "source": [
    "with open('symbols.json', 'r') as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert the JSON data back to a list\n",
    "set_list = json.loads(json_data)\n",
    "\n",
    "# Convert the list to a set\n",
    "my_set = set(set_list)\n",
    "\n",
    "# Now you can use the set as needed\n",
    "print(my_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sto studiare il lingua italiano'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemming\n",
    "import spacy\n",
    "\n",
    "# Load the Italian language model\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "# Text to be lemmatized\n",
    "text = \"Sto studiando la lingua italiana\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatize each token in the text\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Print the lemmas\n",
    "text=\" \".join(lemmas)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ranked retrieval Thus far, our queries have all been Boolean.\\nDocuments either match or donâ€™t.\\nGood for expert users with precise understanding of their needs and the collection.\\nAlso good for applications: Applications can easily consume 1000s of results.\\nNot good for the majority of users.\\nMost users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\\nMost users donâ€™t want to wade through 1000s of results.\\nThis is particularly true of web search.\\nC. D. Manning,\\xa0P. Raghavan\\xa0and\\xa0H. SchÃ¼tze,\\xa0 Introduction to Information Retrieval '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input='''Ranked retrievalThus far, our queries have all been Boolean.\n",
    "Documents either match or donâ€™t.\n",
    "Good for expert users with precise understanding of their needs and the collection.\n",
    "Also good for applications: Applications can easily consume 1000s of results.\n",
    "Not good for the majority of users.\n",
    "Most users are incapable of writing Boolean queries (or they are, but they think itâ€™s too much work).\n",
    "Most users donâ€™t want to wade through 1000s of results.\n",
    "This is particularly true of web search.\n",
    "C. D. Manning,Â P. RaghavanÂ andÂ H. SchÃ¼tze,Â  Introduction to Information Retrieval '''\n",
    "text_with_space = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", input)\n",
    "\n",
    "text_with_space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
