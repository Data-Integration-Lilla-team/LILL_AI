path,page,text,parsed_text
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#0,0,Calcolatori  Elettronici T  Complementi ed Esercizi  di Reti Logiche  ,calcolatori elettronici complementi esercizi reti logiche
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#1,1,Stefano Mattoccia  Ricevimento : su appuntamento via email    Telefono  : 051 2093860  Email   : stefano.mattoccia@unibo.it  Web   : www.vision.deis.unibo.it/smatt ,stefano mattoccia ricevimento appuntamento via email telefono email web
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#10,10,"OE=0 0 1 U=? Quale valore logico assume U ? 
Che cosa è necessario garantire nella rete seguente ?  Quando il segnale U assume un valore logico significativo ? 1 U=? OE1 OE2 I1 I2 ",valore logico assume cosa necessario garantire rete seguente quando segnale assume valore logico significativo
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#11,11,"Esercizio 1  Registro a 1 bit con uscita tri-state Utilizzando latch SR progettare una rete che, quando WE=1,memorizza sulluscita OUT il segnale di ingresso IN. Lultimo valore trasferito in uscita deve essere mantenuto per tutto il tempo in cui il segnale WE=0. La rete deve essere inoltre dotata di un segnale OE che, se a livello logico 0, pone il segnale di OUT nello stato di alta impedenza. WE IN OUT OE ? WE IN OE OUT ",esercizio registro bit uscita tri state utilizzando latch progettare rete che quando ememorizza sulluscita segnale ingresso lultimo valore trasferito uscita deve essere mantenuto tempo segnale rete deve essere inoltre dotata segnale che livello logico pone segnale stato alta impedenza
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#12,12,"S Q Q* R WE IN OE OUT Soluzione 
La rete tratteggiata (8X) è un latch CD dotato di uscita tri-state ed esiste in forma integrata (‘373). Q 
NOTA - Perché le due reti seguenti NON sono equivalenti ? a b c b a c ",soluzione rete tratteggiata latch dotato uscita tri state esiste forma integrata due reti seguenti equivalenti
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#13,13,"RSA notevoli: Flip-Flop D FFD D CK Q Q* D CK Q Q* FFD: RSA che assume il valore logico presente sull’ingresso D durante i fronti di salita (positive edge triggered) dell’ingresso CK 
Il FFD è tipicamente utilizzato come cella elementare di memoria  nelle reti sequenziali sincrone. In tal caso, il segnale CK, è un segnale di tipo periodico (clock). CK D Q ",notevoli flip flop assume valore logico presente sullingresso durante fronti salita positive edge triggered dellingresso tipicamente utilizzato cella elementare memoria reti sequenziali sincrone tal caso segnale segnale tipo periodico clock
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#14,14,"FFD D CK Q Q* D CK Q Q* A_SET* A_RES* 
A_RES* A_SET* 
CK D Q* Q I FFD sono dotati di due ulteriori ingressi “asincroni” che consentono di settare (A_SET) o resettare (A_RES) Q indipendentemente da CK e D. A_SET* 
A_RES* Tipica realizzazione di  un FFD della famiglia  TTL (‘374) mediante 3  latch SR.  Q=0 se A_RES=1 Q=1 se A_SET=1  A_SET e A_RES sono  prioritari rispetto  a CK e D NOTA: i segnali asincroni di set e reset denominati nella slide (rispettivamente) A_SET e A_RES  sono spesso denominati (rispettivamente) PR e CL oppure S e R. Inoltre, se non indicati nello  schema logico si suppone che tali comandi siano non asseriti (A_SET=0 e A_RES=0). ",dotati due ulteriori ingressi asincroni consentono settare resettare tipica realizzazione famiglia mediante latch prioritari rispetto segnali asincroni set reset denominati slide spesso denominati oppure inoltre indicati schema logico suppone tali comandi asseriti
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#15,15,"Vincoli di corretto impiego per i FFD   Tempi di Setup (τSU), Hold (τH) e Risposta (τR) FFD D CK Q Q* D CK Q Q* CK D Q τH τSU τR Il corretto funzionamento è garantito solo se τSU≥ τSUmin e τH ≥ τHmin. In caso contrario, metastabilità.   Cosa implicano i parametri τSUmin e τRmin indicati nei datasheet ? ",vincoli corretto impiego tempi setup hold risposta corretto funzionamento garantito solo su sumin hmin caso contrario metastabilit cosa implicano parametri sumin rmin indicati datasheet
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#16,16,"Il FFD come elemento fondamentale delle RSS 
D CK Q Se all’ingresso CK viene inviato un segnale periodico (clock):   il FFD ritarda (D = Delay) il segnale di uscita Q, rispetto al  segnale di ingresso D, di un tempo pari al periodo di clock T  Qn+1 = Dn FFD D CK Q Q* D CK Q Q* 
T T T T ",elemento fondamentale allingresso viene inviato segnale periodico clock ritarda delay segnale uscita rispetto segnale ingresso tempo pari periodo clock
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#17,17,"Vincoli di campionamento e metastabilità Il mancato rispetto dei vincoli sul campionamento dei segnali porta  a metastabilità.  CK D Q τSU τH ???????????? 
0 1 metastabile 
stabile stabile ? ? 1? 0? τ = ??? ",vincoli campionamento metastabilit mancato rispetto vincoli campionamento segnali porta metastabilit metastabile stabile stabile
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#18,18,"Sincronizzazione di segnali (non sincroni) FFD D CK Q I metastabile FFD D CK Q Stabile (?) I_sync I_M Normalmente i segnali provenienti dall’esterno (ma non solo) non sono sincroni con il clock della RSS. Questo è un problema molto comune.   Come gestire potenziali situazioni di metastabilità che potrebbero  compromettere il corretto funzionamento della RSS?  
CK •  La soluzione mostrata garantisce che l’uscita I_sync assume il valore   di I nel momento in cui tale segnale è stato campionato?   •  Sono sufficienti due livelli di FF?  •  Quali sono gli effetti collaterali di questa soluzione? ",segnali non sincroni metastabile stabile isync normalmente segnali provenienti dallesterno solo sincroni clock problema molto comune gestire potenziali situazioni metastabilit potrebbero compromettere corretto funzionamento soluzione mostrata garantisce luscita isync assume valore momento tale segnale stato campionato sufficienti due livelli quali effetti collaterali soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#19,19,Reti Sequenziali Sincrone (RSS) ? k (k) FFD k k FFD sull’anello di retroazione  Tutti con lo stesso clock di periodo T S S* S S* CK S U S* It t+T t+2·T t-T Nel caso specifico: Moore o Mealy ? Lo stato cambia anche se non cambia l’ingresso ? L’uscita cambia anche se non cambia l’ingresso ? CK ,reti sequenziali sincrone sullanello retroazione stesso clock periodo tt caso specifico moore mealy stato cambia cambia lingresso luscita cambia cambia lingresso
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#2,2,"Introduzione Reti Logiche: sintesi mediante approccio “formale” 
Calcolatori Elettronici: sintesi mediante approccio “diretto” Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL 
Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL ",introduzione reti logiche sintesi mediante approccio formale calcolatori elettronici sintesi mediante approccio diretto grafo stati tabella flusso tabella transizioni sintesi karnaugh etc specifiche problema grafo stati tabella flusso tabella transizioni sintesi karnaugh etc specifiche problema
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#20,20,"Alcune considerazioni sulle RSS •  Lo stato della rete cambia solo in corrispondenza dei fronti di   salita del clock che si susseguono con periodo T  •  La rete risponde ogni T ⇒ se si desidera massimizzare la velocità   di risposta della rete è necessario adottare il modello di Mealy   •  La rete è svincolata dai ritardi della rete G! Quindi, nessun   problema di corse critiche (purché T > τSUmin + τRmin !)  •  All’interno di uno stesso progetto sono tipicamente presenti più    RSS e non necessariamente per tutte le RSS il clock è lo stesso   e/o coincide con il clock del processore  •  Le RSS sono (più) facili da progettare delle RSA ",alcune considerazioni stato rete cambia solo corrispondenza fronti salita clock susseguono periodo rete risponde ogni desidera massimizzare velocit risposta rete necessario adottare modello mealy rete svincolata ritardi rete quindi nessun problema corse critiche purch sumin rmin allinterno stesso progetto tipicamente presenti necessariamente tutte clock stesso coincide clock processore pi facili progettare
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#21,21,"Clock gating e glitch sul clock Nelle reti sincrone è necessario evitare variazioni spurie (glitch) del segnale di clock che possono provocare commutazioni indesiderate dei FFD.   Ad esempio, per via dei reciproci ritardi tra i t segnali D[t-1..0] e/o le alee introdotte dalla rete combinatoria di decodifica, a causa del “clock gating“, può verificarsi quanto segue FFD D CK Q Q* D CK Q Q* CK P CK_G 
CK_G Glitch sul clock → commutazione spuria del FFD ! NO !! Rete di  Decodifica D[t-1..0] P t ",clock gating glitch clock reti sincrone necessario evitare variazioni spurie glitch segnale clock possono provocare commutazioni indesiderate esempio via reciproci ritardi segnali alee introdotte rete combinatoria decodifica causa clock gating pu verificarsi segue glitch clock commutazione spuria rete decodifica
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#22,22,"Il clock gating, oltre a generare potenziali glitch introduce  “clock-skew”. Ad esempio, consideriamo le due RSS seguenti Clock gating e clock-skew 
CK CK_G τAND FFD D CK Q Q* I1 CK B B* CK_G 1 FFD D CK Q Q* I2 CK A A* τAND 
τAND I clock delle due reti sono sfasati di un tempo pari al ritardo introdotto dall’AND. Tale fenomeno (“clock-skew”) è potenzialmente dannoso. Perchè ? 
Il “clock-skew” non è causato solo dal clock gating ma anche (ad esempio) da percorsi elettrici di lunghezza diversa. ",clock gating oltre generare potenziali glitch introduce clock skew esempio consideriamo due seguenti clock gating clock skew clock due reti sfasati tempo pari ritardo introdotto dalla tale fenomeno clock skew potenzialmente dannoso perch clock skew causato solo clock gating esempio percorsi elettrici lunghezza diversa
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#23,23,"Esercizio 2  Progettare un registro a 8 bit con uscita tri-state utilizzando FFD positive edge triggered.  La rete, ad ogni fronte di salita del clock, memorizza il byte IN[7..0] in ingresso se WE=1 mentre mantiene il valore precedentemente memorizzato in caso contrario (WE=0). L’uscita OUT[7..0] della rete deve essere posta nello stato di alta impedenza quando il segnale OE=0. Inoltre, la rete deve essere dotata di un ingresso asincrono di RESET (A_RESET) che, se 1, pone al livello logico 0 l’uscita OUT[7..0] indipendentemente dal valore dei segnali WE, IN e CK. Quali condizioni devono essere soddisfatte perché sia garantito il corretto funzionamento della rete ? ? WE A_RESET IN[7..0] CK OUT[7..0] OE WE IN[7..0] OE OUT[7..0] ",esercizio progettare registro bit uscita tri state utilizzando positive edge triggered rete ogni fronte salita clock memorizza byte ingresso mentre mantiene valore precedentemente memorizzato caso contrario luscita rete deve essere posta stato alta impedenza quando segnale inoltre rete deve essere dotata ingresso asincrono che pone livello logico luscita valore segnali quali condizioni devono essere soddisfatte garantito corretto funzionamento rete
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#24,24,"WE OE FFD D Q Q* R IN OUT 0 1 Q A_RESET Soluzione Caso singolo bit 
NOTA  - Per garantire il corretto funzionamento della rete è   necessario rispettare tempi di setup e hold  - Il FFD esiste (8X) in forma integrata (74XX374) ed è dotato   di comando di OE CK ",soluzione caso singolo bit garantire corretto funzionamento rete necessario rispettare tempi setup hold esiste forma integrata dotato comando
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#25,25,"NOTA  - La soluzione seguente NON è corretta in quanto:       a) variazioni spurie (glitch), dovute a instabilità del        segnale WE, possono causare commutazioni indesiderate         del flip-flop       b) il gate ritarda il segnale di clock del FFD e potrebbe        causare potenziali sfasamenti (“clock-skew”) tra i clock        dei vari componenti della rete sincrona complessiva WE OE FFD D Q Q* R IN OUT Q A_RESET CK ",soluzione seguente corretta quanto variazioni spurie glitch dovute instabilit segnale possono causare commutazioni indesiderate flip flop gate ritarda segnale clock potrebbe causare potenziali sfasamenti clock skew clock vari componenti rete sincrona complessiva
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#26,26,"FFD D Q Q* R IN7 WE OE OUT7 0 1 
FFD D Q Q* R IN1 OUT1 0 1 
FFD D Q Q* R IN0 OUT0 0 1 Q7 
Q1 Q0 A_RESET Estensione a 8 bit CK ",estensione bit
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#27,27,"Estensione a 8 bit (meglio) 
WE OE FFD D Q Q* R IN[7..0] OUT[7..0] 0 1 Q[7..0] A_RESET CK 8 8 8 8 8 ",estensione bit meglio
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#28,28,"Esercizio 3  Progettare una rete che periodicamente dopo tre periodi di clock setta al livello logico 1 la propria uscita per un periodo clock. 
A_RESET CK OUT 
CK OUT (0) (1) (2) (0) (1) (2) (3) (3) ? OUT ",esercizio progettare rete periodicamente dopo tre periodi clock setta livello logico propria uscita periodo clock
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#29,29,"COUNTER X4 Una possibile soluzione si basa sullutilizzo di un contatore modulo 4.  Soluzione 3.1  
CK u1 u0 OUT A_RESET Progettare un contatore modulo 4…. A_RES Perchè ? u1 u0 ",possibile soluzione basa sullutilizzo contatore modulo soluzione progettare contatore modulo perch
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#3,3,"Modello della Macchina a Stati Finiti (FSM) - Mealy F G k n I? r U S S* U=F(S,I) S*=G(S,I) ",modello macchina stati finiti mealy ufsi sgsi
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#30,30,FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 ,contatore modulo
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#31,31,"Contatore modulo 4 con comando di ENABLE (EN) 
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 EN 0 1 EN ",contatore modulo comando
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#32,32,"0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 UP/DOWN (U/D*)  
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 U/D* ",contatore modulo
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#33,33,Contatore modulo 4 con LOAD (L) FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 1 0 L 1 0 L i0 i1 ,contatore modulo
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#34,34,"Esercizi E3-1) Progettare un contatore modulo 4 dotato dei segnali       U/D*, EN e L nei seguenti 2 casi:   a) segnale L prioritario rispetto a EN    b) segnale EN prioritario rispetto a L       In entrambi i casi si supponga che U/D* sia il     segnale meno prioritario tra i tre.  E3-2) Progettare un contatore modulo 8  E3-3) Progettare un contatore modulo 5 utilizzando un       contatore modulo 8 ",esercizi progettare contatore modulo dotato segnali seguenti casi segnale prioritario rispetto segnale prioritario rispetto entrambi casi supponga segnale meno prioritario tre progettare contatore modulo progettare contatore modulo utilizzando contatore modulo
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#35,35,Osservando le forme donda mostrate sotto si può ottenere una soluzione alternativa alla precedente (3.1) Soluzione 3.2  CK u1 u0 OUT (0) (1) (2) (0) (1) (2) (3) (3) ,osservando forme donda mostrate sotto pu ottenere soluzione alternativa precedente soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#36,36,FFD D Q Q* R* CK A_RESET* FFD D Q Q* R* OUT NOTA - Questa soluzione non può essere ottenuta con il metodo   della sintesi formale studiato a Reti Logiche ,soluzione pu essere ottenuta metodo sintesi formale studiato reti logiche
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#37,37,"ττττNOTA - Non è il caso della rete della pagina precedente, ma la   presenza di alee può creare problemi alle reti che seguono   se queste utilizzano come ingresso di clock un segnale che    presenta oscillazioni spurie (glitches).    Si consideri ad esempio il caso seguente: 
FFD D Q Q* c b a 1 1 IN OUT S u u S τττ
Alea statica: provoca un campionamento indesiderato del FFD ", caso rete pagina precedente presenza alee pu creare problemi reti seguono utilizzano ingresso clock segnale presenta oscillazioni spurie glitches consideri esempio caso seguente alea statica provoca campionamento indesiderato
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#38,38,NOTA -  Le alee possono essere eliminate introducendo ulteriori   gates (vedi reti logiche)   -  In alcuni casi le alee possono essere filtrate dagli   stessi gates (ad esempio nel caso di ‘lentezza’ dei   dispositivi rispetto ai tempi del glitch); questa   possibilità deve essere verificata attentamente   analizzando i datasheets dei componenti utilizzati a b c a b c Un impulso troppo breve potrebbe essere filtrato dallAND ,alee possono essere eliminate introducendo ulteriori gates vedi reti logiche alcuni casi alee possono essere filtrate gates esempio caso lentezza dispositivi rispetto tempi glitch possibilit deve essere verificata attentamente analizzando datasheets componenti utilizzati impulso troppo breve potrebbe essere filtrato dalla
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#39,39,"Soluzione canonica ottenuta mediante sintesi formale. Soluzione 3.3  
A,0 B,0 C,0 D,1 Grafo degli stati  
Tabella di flusso  sn sn+1 sn,u u A B 0 B C 0 C D 0 D A 1 Tabella delle  transizioni  y1n y0n u 0 0 0  1 0 0 1 1  0 0 1 0 1  1 0 1 1 0  0 1 y1n+1 y0n+1 Sintesi minima (mappe di Karnaugh,…) u = y1n·y0n y0n+1 = y0n* y1n+1 = y1n XOR y0n ",soluzione canonica ottenuta mediante sintesi formale soluzione grafo stati tabella flusso snu tabella transizioni sintesi minima mappe karnaugh ynyn
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#4,4,"F G k n I? r U S S* U=F(S) S*=G(S,I) Modello della Macchina a Stati Finiti (FSM) - Moore ",ufs sgsi modello macchina stati finiti moore
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#40,40,"FFD D Q Q* FFD D Q Q* XOR y0 y1 R* R* CK u NOTA  - Se si desidera aggiungere un segnale di ENABLE alla rete   precedente mediante il metodo della sintesi formale ?   - E necessario ripetere tutti i passi precedenti (grafo,   diagramma stati, …) ",desidera aggiungere segnale rete precedente mediante metodo sintesi formale necessario ripetere passi precedenti grafo diagramma stati
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#41,41,Esercizio 4  Progettare un registro a scorrimento (shift-register) a 3 bit. ? IN A_RESET CK OUT1 OUT2 OUT0 IN A_RESET O1 O2 O0 ,esercizio progettare registro scorrimento shift register bit
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#42,42,"CK IN A_RESET OUT1 Soluzione 
OUT2 OUT0 ",soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#43,43,"FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* IN OUT2 OUT1 OUT0 
CK Esercizi E4-1) Progettare uno shift-register dotato di comandi         di enable EN e LOAD (parallelo e prioritario         rispetto allenable).  E4-2) Utilizzando due shift-register a 4 bit e un        contatore modulo 8: progettare un convertitore         serie parallelo a 8 bit dotato di un segnale (ACK)    che comunica lavventura ricezione degli 8 bit.  ",esercizi progettare shift register dotato comandi enable parallelo prioritario rispetto allenable utilizzando due shift register bit contatore modulo progettare convertitore serie parallelo bit dotato segnale comunica lavventura ricezione bit
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#44,44,Esercizio 5  Progettare una rete sincrona dotata di un ingresso  IN e di un’uscita OUT. L’uscita OUT deve asserirsi esattamente per un periodo di clock se viene rilevata una transizione da 0 a 1 del segnale di ingresso (monoimpulsore). Si noti che il segnale di ingresso potrebbe anche essere non sincrono (purché rispetti tempi di setup  e hold) ? IN CK OUT CK IN OUT IN OUT ,esercizio progettare rete sincrona dotata ingresso unuscita luscita deve asserirsi esattamente periodo clock viene rilevata transizione segnale ingresso noti segnale ingresso potrebbe essere sincrono purch rispetti tempi setup hold
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#45,45,"FFD D Q Q* FFD D Q Q* IN OUT CK Soluzione 
CK IN OUT ",soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#46,46,"FFD D Q Q* IN OUT CK Perchè questa soluzione è sbagliata (1) ? 
CK IN OUT ",perch soluzione sbagliata
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#47,47,"Perchè questa soluzione è sbagliata (2) ? 
FFD D Q Q* IN OUT CK CK IN OUT ",perch soluzione sbagliata
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#48,48,"Perchè questa soluzione è sbagliata (3) ? 
FFD D Q Q* IN OUT CK CK IN OUT ",perch soluzione sbagliata
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#49,49,"Esercizio 6  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati sull’ingresso IN[7..0] mentre il segnale EN era a livello logico 1 sono stati FFh (primo carattere della sequenza), 27h e 30h. Nel caso sia rilevata la sequenza FF-27-30, nel periodo di clock successivo a quello dell’ultimo carattere ricevuto (30h), deve essere asserita l’uscita OUT e rimanere tale fino a che non viene asserito il segnale (asincrono) di reset A_RESET. In seguito ad un reset deve riprendere immediatamente il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere. ? EN A_RESET IN[7..0] CK OUT EN A_RESET IN[7..0] OUT ",esercizio progettare rete controlla ultimi tre caratteri presentati sullingresso mentre segnale livello logico stati primo carattere sequenza caso rilevata sequenza periodo clock successivo dellultimo carattere ricevuto deve essere asserita luscita rimanere tale fino viene asserito segnale asincrono reset seguito reset deve riprendere immediatamente controllo sequenza ingresso stato ricevuto alcun carattere
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#5,5,"Reti Sequenziali Asincrone (RSA) ? k τk Retroazione diretta (τ: ritardo intrinseco della RC G) S U S* IS S* S S* 
t t+τ(1) (2) (3) ",reti sequenziali asincrone retroazione diretta ritardo intrinseco
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#50,50,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) ",
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#51,51,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK DEC_30 DEC_27 DEC_FF OE* OE* 0 0 Soluzione 6.1 ",segnale condiziona lultimo carattere sequenza soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#52,52,"Soluzione 6.2 
CK A_RESET* LOAD ENABLE 0 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Una soluzione alternativa utilizzando un contatore dotato di  comando di LOAD 
Cè un problema… ",soluzione ffe nd oe nd oe nd ffe nd oe nd oe nd soluzione alternativa utilizzando contatore dotato comando c problema
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#53,53,"CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  .. nella soluzione della pagina precedente cosa accade se i  caratteri ricevuti (con EN=1) sono FF-FF-27-30 ? 
DEC_FF ",ffe nd oe nd oe nd ffe nd oe nd oe nd soluzione pagina precedente cosa accade caratteri ricevuti con
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#54,54,"Esercizi E5-1) Riprogettare la rete dellesercizio 6 in modo che     OUT assuma il valore logico 1 in seguito alla     ricezione anche non consecutiva (con EN=1) dei     caratteri FFh, 27h e 30h.          Ad esempio, OUT=1 se i caratteri ricevuti (mentre     EN=1) sono stati: FF-7A-80-9F-27-B2-30-…  ",esercizi riprogettare rete dellesercizio modo assuma valore logico seguito ricezione consecutiva con caratteri esempio caratteri ricevuti mentre stati
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#55,55,"Esercizio 7  Modificare lesercizio precedente in modo che, in seguito al rilevamento della sequenza, luscita OUT assuma il valore logico 1 per un solo periodo di clock. Appena ricevuta una sequenza completa il controllo dei caratteri in ingresso deve riprendere immediatamente. ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] ",esercizio modificare lesercizio precedente modo che seguito rilevamento sequenza luscita assuma valore logico solo periodo clock appena ricevuta sequenza completa controllo caratteri ingresso deve riprendere immediatamente
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#56,56,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) Soluzione 7.1 ",soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#57,57,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* A_RESET* 
A_RESET* CK CK 
CK ",
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#58,58,"Soluzione 7.2 
CK A_RESET LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30* + OUT ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Rispetto allesercizio 6.2 è sufficiente modificare il comando di LOAD facendo in modo che LOAD=1 quando OUT=1 ?  
EN·DEC_FF 
Cosa accade se (con EN=1) la sequenza è 45-FF-27-30-FF-27-30-… ? ",soluzione ffe nd oe nd oe nd ffe nd oe nd oe nd rispetto allesercizio sufficiente modificare comando modo quando nd cosa accade con sequenza
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#59,59,"Esercizi E6-1) Riprogettare la rete dellesercizio 6 in modo che    OUT=1 in seguito alla ricezione anche non consecutiva    (con EN=1) dei caratteri FFh, 27h e 30h.         Ad esempio, OUT=1 se i caratteri ricevuti mentre EN=1    sono stati: FF-7A-80-9F-27-B2-30-…   E6-2) Cosa accade alle soluzioni 6.1 e 6.2 se (mentre EN=1)       la sequenza è: 45-FF-27-30-FF-27-30-… ?  ",esercizi riprogettare rete dellesercizio modo seguito ricezione consecutiva con caratteri esempio caratteri ricevuti mentre stati cosa accade soluzioni mentre sequenza
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#6,6,"•  Le reti asincrone rispondono molto rapidamente (appena possibile)   alle variazioni degli ingressi •  Non è necessario un segnale di sincronismo (clock) •  Ridotta dissipazione di potenza Aspetti positivi delle RSA (vs RSS) Aspetti negativi delle RSA (vs RSS) •  Vincoli per il corretto impiego   - l’ingresso può variare solo quando la rete ha raggiunto     una condizione di stabilità   - i segnali di ingresso possono variare uno alla volta •  Esposte a potenziali malfunzionamenti (corse critiche)  •  Difficili da progettare In pratica, sono utilizzate per realizzare latch e flip-flop.  A noi interessano (maggiormente) le reti sincrone (RSS) ! ",reti asincrone rispondono molto rapidamente appena possibile variazioni ingressi necessario segnale sincronismo clock ridotta dissipazione potenza aspetti positivi aspetti negativi vincoli corretto impiego lingresso pu variare solo quando rete raggiunto condizione stabilit segnali ingresso possono variare volta esposte potenziali corse critiche difficili progettare pratica utilizzate realizzare latch flip flop interessano maggiormente reti sincrone
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#60,60,"Esercizio 8  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati in ingresso IN[7..0] mentre il segnale EN=1 sono stati FFh (primo carattere della sequenza), 27h  e 30h. Nel caso sia rilevata tale sequenza, due periodi di clock successivi a quello dell’ultimo carattere della sequenza ricevuto deve essere asserita l’uscita OUT e rimanere tale fino a che il segnale di reset (asincrono) A_RESET non assume il valore logico 1. In seguito ad un reset (asincrono) la rete deve riprendere immediatamente  il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere.  ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] ",esercizio progettare rete controlla ultimi tre caratteri presentati ingresso mentre segnale stati primo carattere sequenza caso rilevata tale sequenza due periodi clock successivi dellultimo carattere sequenza ricevuto deve essere asserita luscita rimanere tale fino segnale reset asincrono assume valore logico seguito reset asincrono rete deve riprendere immediatamente controllo sequenza ingresso stato ricevuto alcun carattere
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#61,61,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 18h 16h 80h 
OUT (1) (2) (3) ",
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#62,62,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK FFD D Q Q* R* A_RESET* CK Soluzione 8.1 ",segnale condiziona lultimo carattere sequenza soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#63,63,CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = (ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*)·OUT_1*  ENABLE = (ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30)·OUT_1*  DEC_FF Soluzione 8.2 FFD D Q Q* R* A_RESET* CK OUT_1 ,ffe nd oe nd oe nd eco ffe nd oe nd oe nd eco soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#64,64,"Esercizio 9  Progettare una rete dotata di tre ingressi E, A/I*, A_RES e unuscita OUT. Il segnale di ingresso A/I* influisce sulla rete solo se contemporaneamente E=1. Luscita della rete deve andare al livello logico 1 per un periodo di clock se viene rilevato per cinque volte, anche non consecutive, il valore 1 del segnale A/I* in presenza del segnale E=1. Ogni volta che il segnale A/I* assume il valore 0 (con E=1) deve essere ridotto di uno il numero di eventi rilevati fino a quel momento. Successivamente a un reset (segnale asincrono) o nel caso nessun evento sia stato ancora rilevato (o che il numero di incrementi sia stato compensato da un numero equivalente di decrementi la rete deve rimanere nello stato 000 anche se A/I*=0 ed E=1. Dopo avere rilevato cinque eventi la rete deve riprendere l’analisi degli ingressi. ? E A/I* A_RESET CLOCK OUT OUT E A/I* A_RES ",esercizio progettare rete dotata tre ingressi unuscita segnale ingresso influisce rete solo luscita rete deve andare livello logico periodo clock viene rilevato cinque volte consecutive valore segnale presenza segnale ogni volta segnale assume valore con deve essere ridotto numero eventi rilevati fino quel momento successivamente reset segnale asincrono caso nessun evento stato ancora rilevato numero incrementi stato compensato numero equivalente decrementi rete deve rimanere stato dopo avere rilevato cinque eventi rete deve riprendere lanalisi ingressi
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#65,65,"COUNTER X 8 EN U/D# LOAD I2 I1 I0 O2 O1 O0 E A/I* OUT OUT CLOCK 0 0 A/I* 
O2 O1 O0 A/I* RESET A_RESET Soluzione 9.1 E L’OR blocca il conteggio (EN=0), anche con E=1, se il contatore si trova nello stato 000 e il comando DOWN è asserito (A/I*=0). Perché ? 
O1 è strettamente necessario ?  (No, perché ?) ",soluzione lo blocca conteggio contatore trova stato comando asserito strettamente necessario
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#66,66,"A,0 B,0 C,0 D,0 E,0 F,1 E A/I* 0 – 1 0 0 – 0 – 0 – 0 – 1 1 1 1 1 1 1 1 1 1 1 1 0 – 1 0 1 0 1 0 1 0 1 0 Soluzione mediante sintesi formale: grafo -> tabella di  flusso -> tabella delle transizioni,... NON SI USA !!!! Soluzione 9.2 ",soluzione mediante sintesi formale grafo tabella flusso tabella transizioni soluzione
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#67,67,Esercizio 10  Utilizzando un microprocessore dotato di un bus indirizzi a 16 bit e di un bus dati a 8 bit: mappare nello parte bassa dello spazio di indirizzamento 12k di RAM e nella parte alta 16k di EPROM. ,esercizio utilizzando microprocessore dotato bus indirizzi bit bus dati bit mappare parte bassa spazio indirizzamento parte alta
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#68,68,"Soluzione RAM (12K) 
EPROM (16K) 0000h  2FFFh 
C000h FFFFh A15..A12 A11..A8 A7..A4 A3..A0 0000 0000 0000 0000 (0000h)  
1111 1111 1111 1111 (FFFFh) 0010 1111 1111 1111  (2FFFh) 
1100 0000 0000 0000 (C000h) RAM_1 (8k) RAM_2 (2k) RAM_3 (2k) 
EPROM (16k) 0001 1111 1111 1111 (1FFFh)  0010 0000 0000 0000  (2000h) 0010 0111 1111 1111  (27FFh) 0010 1000 0000 0000  (2800h) CS_RAM_1=A15*·A13* CS_RAM_2=A15*·A13· A11* CS_RAM_3=A15*·A13· A11 CS_EPROM=A15 Segnali di decodifica: ",soluzione ffh maa maa maa segnali decodifica
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#69,69,"- Il segnale CS_EPROM si attiva per ogni indirizzo maggiore   o uguale di 8000h (seconda metà dello spazio di   indirizzamento) 0000h  
C000h FFFFh 8000h Indirizzi di memoria con A15=1 CS_EPROM=A15 NOTA  - La codifica semplificata implica lattivazione dei   segnali di selezioni anche per indirizzi diversi da   quelli in cui sono realmente presenti i dispositivi    di memoria.  
EPROM (16K) EPROM (16K) ",segnale attiva ogni indirizzo maggiore uguale seconda met spazio indirizzamento indirizzi memoria codifica semplificata implica lattivazione segnali selezioni indirizzi diversi realmente presenti dispositivi memoria
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#7,7,"RSA notevoli: Latch SR SR S R Q Q* S R Q Q* S R 0 0 0 1 1 0 1 1 Q Q* Q Q* 0 1 1 0 
Q = S’ ↑ (q ↑ R’) S’ R’ Q Q*  Q = R ↓ (S ↓ q) S R Q Q*  
I comandi di set e reset devono avere una durata minima (vedi datasheet) per consentire il raggiungimento della condizione di stabilità ",notevoli latch comandi set reset devono avere durata minima vedi datasheet consentire raggiungimento condizione stabilit
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#70,70,"- Il segnale CS_RAM_1 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=0:  0000h  
FFFFh 8000h CS_RAM_1=A15*·A13* RAM_1 (8k) A15..A12  A11..A8    A7..A4   A3....A0 0000  0000  0000  0000 (0000h)  0001  1111  1111  1111 (1FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0100  0000  0000  0000 (4000h)  0101  1111  1111  1111 (5FFFh)  Quindi, CS_RAM_1=1 per entrambi i  seguenti intervalli di memoria: 1FFFh  4000h RAM_1 (8k) 5FFFh ",segnale attiva ogni indirizzo compreso maa quindi entrambi seguenti intervalli memoria
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#71,71,"- Il segnale CS_RAM_2 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=0 :  0000h  
FFFFh 8000h CS_RAM_2=A15*·A13·A11* A15..A12  A11..A8    A7..A4   A3....A0 0010  0000  0000  0000 (2000h)  0010  0111  1111  1111 (27FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  0000  0000  0000 (3000h)  0011  0111  1111  1111 (37FFh)  Quindi, CS_RAM_2=1 per i seguenti quattro intervalli di memoria: 2000h  4000h 6000h A15..A12  A11..A8    A7..A4   A3....A0 0110  0000  0000  0000 (6000h)  0110  0111  1111  1111 (67FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  0000  0000  0000 (7000h)  0111  0111  1111  1111 (77FFh)  RAM_2 (2k) RAM_2 (2k) 3000h  RAM_2 (2k) RAM_2 (2k) 7000h ",segnale attiva ogni indirizzo compreso ffh ffh quindi seguenti quattro intervalli memoria ffh ffh
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#72,72,"- Il segnale CS_RAM_3 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=1 :  0000h  
FFFFh CS_RAM_3=A15*·A13·A11 A15..A12  A11..A8    A7..A4   A3....A0 0010  1000  0000  0000 (2800h)  0010  1111  1111  1111 (2FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  1000  0000  0000 (3800h)  0011  1111  1111  1111 (3FFFh)  Quindi, CS_RAM_3=1 per i seguenti quattro intervalli di memoria: 2800h  6800h A15..A12  A11..A8    A7..A4   A3....A0 0110  1000  0000  0000 (6800h)  0110  1111  1111  1111 (6FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  1000  0000  0000 (7800h)  0111  1111  1111  1111 (7FFFh)  RAM_3 (2k) RAM_3 (2k) 3800h  RAM_3 (2k) RAM_3 (2k) 7800h ",segnale attiva ogni indirizzo compreso quindi seguenti quattro intervalli memoria
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#73,73,"0000h  
FFFFh 2800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 2000h  3800h  RAM_2 (2k) RAM_3 (2k) 3000h  4000h  6800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 6000h  7800h  RAM_2 (2k) RAM_3 (2k) 7000h  EPROM (16K) EPROM (16K) 8000h  C000h Effetto di replica nella mappatura in memoria dovuto alla  decodifica semplificata. Nella figura seguente sono indicati  solo gli indirizzi iniziali. ",effetto replica mappatura memoria dovuto decodifica semplificata figura seguente indicati solo indirizzi iniziali
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#74,74,"Esercizio 11  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:  - mappare nello parte bassa dello spazio di indirizzamento    32k di RAM e nella parte alta 32k di EPROM   Nel sistema sono presenti anche due dispositivi di I/O denominati D1 (dotato di due registri interni) e D2 (dotato di quattro registri interni):  - mappare in memoria anche i due dispositivi di I/O D1 e    D2 agli indirizzi 2000h e 1000h  Osservando che esiste una sovrapposizione tra gli indirizzi di una memoria e dei due dispositivi di IO, si scrivano i CS, in forma semplificata, di tutti i dispositivi presenti nel sistema riducendo al minimo gli indirizzi “sottratti” dai dispositivi di IO alla memoria. ",esercizio utilizzando microprocessore dotato bus indirizzi bit bus dati bit mappare parte bassa spazio indirizzamento parte alta sistema presenti due dispositivi denominati dotato due registri interni dotato quattro registri interni mappare memoria due dispositivi indirizzi osservando esiste sovrapposizione indirizzi memoria due dispositivi scrivano forma semplificata dispositivi presenti sistema riducendo minimo indirizzi sottratti dispositivi memoria
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#75,75,"Soluzione  RAM: 1 chip da 32KB RAM  (00000h->07FFFh) CS_RAM = BA19*·CS_D1*·CS_D2*   EPROM: 1 chip da 32KB EPROM (F8000h – FFFFFh) CS_EPROM = BA19   D1: Mappato in memoria allindirizzo 02000h, occupa 2 locazioni (A0)     nello spazio di indirizzamento. CS_D1 = BA19*·BA14*·BA13·BA12*·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·          BA5*·BA4*·BA3*·BA2*·BA1*   D2: Mappato in memoria allindirizzo 01000h, occupa 4 locazioni (A1A0) nello spazio di indirizzamento.  CS_D2 = BA19*·BA14*·BA13*·BA12·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·       BA5*·BA4*·BA3*·BA2*  ",soluzione chip ac dc chip ffh mappato memoria allindirizzo occupa locazioni spazio indirizzamento ab ab ab ab ab ab ab ab ab ab ab ab ab mappato memoria allindirizzo occupa locazioni spazio indirizzamento ab ab ab ab ab ab ab ab ab ab ab ab
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#76,76,"Esercizio 12  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:    - mappare 32k di RAM nella parte bassa dello spazio di    indirizzamento, 32k di RAM a partire dallindirizzo     1C000h e 64k EPROM nella parte alta dello spazio di    indirizzamento ",esercizio utilizzando microprocessore dotato bus indirizzi bit bus dati bit mappare parte bassa spazio indirizzamento partire dallindirizzo parte alta spazio indirizzamento
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#77,77,"RAM_1 (32k) RAM_2 (32k) 
EPROM (64k) 00000h 10000h 20000h 30000h 
F0000h 1C000h    0001 1100 0000 0000 0000  23FFFh    0010 0011 1111 1111 1111     
FFFFFh Soluzione 00000h    0000 0000 0000 0000 0000  07FFFh    0000 0111 1111 1111 1111     
F0000h    1111 0000 0000 0000 0000  FFFFFh    1011 1111 1111 1111 1111     CS_RAM_1=A19*·A17*·A16* CS_RAM_2=A19*·(A17 + A16) CS_EPROM=A19 CS_RAM_2=A19*·CS_RAM_1* oppure ",ffh soluzione ffh maa mac oppure
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#8,8,RSA notevoli: Latch CD CD C D Q Q* C D Q Q* C D 0 0 0 1 1 0 1 1 Q Q* Q Q* Q Q* 0 1 1 0 SR S R Q Q* C D Q Q* C D Q τSU τH τSU ≥ τSUmin τH≥ τHmin Vincoli: Tempo di risposta: τR > τH Latch CD: il problema/vantaggio delle “uscite trasparenti” ,notevoli latch sumin hmin vincoli tempo risposta latch uscite trasparenti
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#9,9,"Driver 3-state 
OE I U OE=0 I U OE=1 I U I OE U Quale è il valore della tensione  ? OE I 1 0 1 1 0 0 0 1 U 0 1 Z Z ? ",driver state valore tensione
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#0,0,"01 IntroduzioneCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",introduzione calcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#1,1,"DocentiStefanoMattocciaRicevimento:pressostudio,vicinoaula5.7,suappuntamentoconcordatoviaemailEmail:stefano.mattoccia@unibo.itHomepage:http://vision.disi.unibo.it/~smattMatteoPoggi(tutor,AA2020/21)Ricevimento:pressoLaboratoriodiComputerVision,suappuntamentoconcordatoviaemailEmail:m.poggi@unibo.itHomepage:https://mattpoggi.github.io/",docenti stefano mattoccia matteo poggitutora laboratoriodi computer
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#10,10,"Struttura di una prova d’esame 
Esercizio 1: progetto di un sistema a microprocessore.Per superare l’esame, è necessario proporre una soluzione ragionevole. L’esercizio 1 determina il superamento/non superamentodella prova.Esercizi 2 e 3: domande di teoria che richiedono qualcheragionamento. Volutamente non è fornita la soluzione.",struttura prova desame esercizio progetto sistema superare lesame necessario proporre soluzione ragionevole lesercizio determina superamentonon provaesercizi domande teoria richiedono volutamente fornita soluzione
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#11,11,"Elaborazione delle informazioni
InputOutputUnessereviventeelaboracontinuamentedelleinformazionieforniscedellerisposteoagisceinundeterminatomodoinbasealleinformazioniiningresso.
Unsistemadiqualsiasinaturaperl’elaborazionedelleinformazioniisolatodall’esternoservirebbeabenpoco(meglio,nulla).Inputeoutputdebbonoesserecodificatiinmodoappropriato
",elaborazione informazioni input output
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#12,12,"Elaborazione delle informazioniOvviamente,inquestocorso,siamointeressatiasistemidinaturaelettronicaperelaborareleinformazioni.Inparticolare,perleragionievidenziateaRetiLogicheT,siamointeressatiasistemidigitali->RetiLogiche
InputOutput
RL01101101011101",elaborazione informazioni reti logiche reti logiche input output
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#13,13,Elaborazione delle informazioniUnprimoproblema:leretilogicheelaboranoinformazioniditipodigitaleMoltiinputeoutputdiparticolareinteressenonsonodinaturadigitalemaanalogica(quellapreferitadagliesseriumani)•Prossimitàaunsemaforoounostacolo•Monitor•Movimentodelmouse•Voce/Audio•Pressionetasti•Touchscreen•etc,elaborazione informazioni
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#14,14,"InputOutput
RLA/D
D/A
Pertanto,è(spesso)necessarioconvertiresegnalidinaturaanalogicainsegnalidigitalieviceversaElaborazione delle informazioni
‘01001101’ ‘110111’ Inunsistemadielaborazione,iningressoeinuscitatroviamosolosegnalidigitali(binari)",input output lad elaborazione informazioni
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#15,15,Elaborazione delle informazioniAltroproblema:laretelogicacheelaboraleinformazionièspessomoltoefficienti/veloce/etcmaallostessotempopocoflessibileperquantoriguardaillinguaggioutilizzabileperfornireleinformazioni(digitali)ininputeinterpretareleinformazioni(digitali)elaborateinoutput.Sesidesiderainteragireconunsistemadielaborazionedigitaleenecessarioadeguarsiallinguaggiochelaretelogicautilizza.Questolinguaggioècodificatodall’evoluzionetemporaledialcunisegnali(ilminimoindispensabile)emessioricevibilidallaretelogica.L’evoluzionetemporalediquestisegnalisidefinisceciclodibus(buscycle).,elaborazione informazioni
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#16,16,"RLElaborazione delle informazioni
ttttttttQuindi,l’unicomodoperinteragireconunsistemadigitaleperl’elaborazionedelleinformazioniconsistenell’adottarequestaconvenzione(ie,iciclidibus,descrittiindettagliosuidatasheetcheilproduttoredelsistemarendesempredisponibili).
ciclo di busciclo di bus",lelaborazione informazioni tttttttt ciclo busciclo bus
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#17,17,"Quale rete logica utilizzare?Sonodisponibilidiversearchitetturedielaborazione(i,e,retilogiche).Qualescegliere?Dipendedalcontestoapplicativoedalleprestazioni,consumi,ingombri,peso,etc:-sistemageneralpurpose-sistemaembedded-sistemapervideogiochi-etcUnatipologiadiarchitettura,basatasulmodellodiVonNeumann,èmoltopiùflessibiledellealtreepuòessereutilizzata,anchesenonsempreconrisultatiottimali,inognicontesto.Questomodelloèl’oggettodiquestocorsoeutilizzacomeelementodibaseunaCPU(microprocessore).",rete logica sistemaembedded etc von
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#18,18,"Esempi di architetture di elaborazione
19
•CPU(CentralProcessingUnit)•CPUMulticore•CPUEmbedded•SOC(SystemonaChip)•GPU(GraphicProcessingUnit)•FPGA(FieldProgrammableGateArray)•Sistemiibridi(e.g.FPGA+CPU)•...",esempi architetture elaborazione pucentral processing unitc multicorec embeddeds ocsystemona chipg pugraphic processing unitf afield programmable gate pu
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#19,19,■Architetturadeltuttogeneralecheportaarealizzazionipocodipendentidalfunzionamentodesiderato■Ilfunzionamentodesideratoèespressointerminidi✸sequenzadiistruzioni(programma)✸memorizzatesuunsupportodimemoria■Percambiarefunzionamentoèsufficientecambiareilprogramma:questodifattomodificalaretelogicadicontrolloperogniistruzioneeseguita■L’architetturaèadattaatrattareproblemimoltopiùcomplessidiquellivistinelcorsodiretilogichemaconefficienza(tipicamente)inferiore■L'importanzaeladiffusionedeicalcolatoridipendefortementedallaflessibilitàdiquestomodelloIl modello di riferimento: Von Neumann,modello riferimento von neumann
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#2,2,"Obiettivi del corsoApprendere,•i principi di funzionamento•le architetture•la progettazione hardware e softwaredei sistemi per l’elaborazione delle informazioni basati microprocessore(o CPU –Central Processing Unit)
",obiettivi corso apprenderei principi architetturela progettazione hardware softwaredei sistemi lelaborazione informazioni basati central processing unit
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#20,20,"Rete combinatoriaUscite OjIngressi Xi  Variabilidi statoYk(n+1)Variabili di statoYk(n)Rete Sequenziale(Sincrona)RegistriSistema di elaborazione: rete sequenzialeIl sistema di elaborazione può essere schematizzato in modoastratto come una Rete Sequenziale (Sincrona), RSS",rete combinatoria uscite ingressi variabilidi stato stato yknrete sistema elaborazione rete sequenziale sistema elaborazione pu essere schematizzato modoastratto rete sequenziale sincrona
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#21,21,"Come cambiareil funzionamento della RL?
RegistriUscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RetecombinatoriaSegnali dicontrolloProgramma(software)RispettoaRetiLogiche,lanovitàèilsoftware(programma)checonsentedivariareilfunzionamentodellareteinbasealleesigenzedesiderate(ie,ilcodicescrittodalprogrammatore).",cambiareil funzionamento registri uscite ingressi variabilidi stato stato segnali dicontrollo reti
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#22,22,"In realtà le cose sono più complesse
Uscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RCSegnali dicontrolloProgramma(software)Unità dicontrollo(RSS)Istruzioni (dalla memoria)
LunitàdicontrollononsologovernalaretecombinatoriamaanchetuttelealtreretilogichepresentinelsistemaEsempio:abilitagliingressieleuscitequandonecessario,etcRegistri
",realt cose complesse uscite ingressi variabilidi stato stato yknr csegnali dicontrollo dicontrollor ssistruzioni dalla memoria registri
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#23,23,"•Ilprogrammarisiedeinmemoriaedècostituitodaistruzionicodificateinformabinaria(linguaggiomacchina)•Inmemoriarisiedonoancheglioperandidelleistruzioni,cioèidatielaboratiedaelaborare(formabinaria)•LeistruzionivengonoeseguiteinsequenzadallaCPU•LaCPUèunamacchinasequenzialesincrona(conunclock)Modello di esecuzione del programma
Uscite
istruzioniIngressiCPUIstr. #1Istr. #2. . .Istr. #NCk",ula esecuzione programma uscite istruzioni ingressi uistr istr istr
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#24,24,"Alivellodimassimaastrazione,ilfunzionamentodell’interosistemapuòesseredescrittomedianteduesolistati:–StatoincuilaCPUleggeinmemorialaprossimaistruzionedaeseguire(INSTRUCTIONFETCHoIF)–StatoincuilaCPUeseguelistruzionelettainIF(EXECUTEoEX)ISTRUCTIONFETCH(IF)EXECUTE(EX)
CPUIstr. #1Istr. #2. . .Istr. #N",ife teo exi chi tee istr istr istr
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#25,25,"RL CPU e istruzioni•Leretilogichevistearetilogicheelaboravanoeproducevanosegnalibinari•SelaCPUèunaRL,comesonocodificateleistruzioni?•Ovviamenteinbinario...•Esempioistruzione#1->00010100000101111101010000010011istruzione#2->10110101100100011001010000011001......istruzione#N->01010110100101010101010110011110•OgniistruzioneindicaallaCPUqualeoperazionedevesvolgere/eseguire•Nonsembraessereunmodomoltocomodo(pergliesseriumani)",uuna
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#26,26,"Esempi di istruzioni•QualiistruzionipossonoessereeseguitedaunaCPU?•Somme•Moltiplicazioni•Divisioni•Confronto•Letturedallamemoriaodaaltridispositivi*•Scrittureinmemoriaoversoaltridispositivi*•...EsistonosostanzialmenteduetipologiediCPU:•RISC(ReducedInstructionSetComputer)Pocheesempliciistruzioni,retilogichesempliciemoltoveloci(frequenzadiclockelevata).eg,ARM•CISC(ComplexInstructionSetComputer)Molteistruzioni,alcunemoltocomplesse,retilogichecomplicate.eg,InteleAMD",esempi ur creduced instruction set rmc ccomplex instruction set
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#27,27,"RISC vs CISC•TipicamenteaunasolaistruzioneCISCcorrispondonopiùistruzioniRISC•Tuttavia,ognisingolaistruzioneRISCèeseguitaspessopiùrapidamentediunaistruzioneCISC•Spesso,ilcodiceRISC,anchesepiùdenso,èpiùveloce•LeRLRISCsonotipicamentepiùsemplicidiquelleCISC•Seleretisonopiùsemplicilospazio(silicio)puòessereutilizzatoperaltrefinalità(registri,cache,etc)•IprocessoriRISCsonomoltodiffusi(smartphone,tablete)•AncheiprocessoriCISCsonomoltodiffusi(PC)perviadelsoftwareesistente*•LeCPUCISCmodernesonoinrealtàinternamentedeiRISC",
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#28,28,"•IndipendentementedaltipodiCPU,leistruzioniinformabinarianonsonofacilmenteinterpretabilieperquestononutilizzateinquestaformaquandosiscriveilcodice•Illinguaggiochesiutilizzaèl’assembler:ADDR1,R2,R3;poneinR1lasommatraregistriR2eR3Questaistruzionepotrebbeesserecodificatacon:00010100000101111101010000010011Iltraduttoreassembler->codicemacchinainbinarioèunaLookUpTable(LUT),ovverounatabellaL’assemblersembraessereunpassoavantinotevolema...Perchénonavetemaiutilizzatoillinguaggioassemblernonostantescrivetecodicedalprimoanno?Istruzioni in forma più comprensibile",rrrponein look tablel forma comprensibile
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#29,29,"Compilatore e istruzioni binarie•Ilmotivoècheavetescrittocodiceadaltolivello(C)eutilizzatouncompilatore(e.g.,GCC)•Ilcompilatore,converteilcodicescrittoinlinguaggioadaltolivelloinistruzionimacchinabinarie#include<stdio.h>intmain(intargc,char**argv){inta=5;intb=6;intc;c=a+b;printf(“Lasommatra%de%dè%d\n”,a,b,c);}GCC0001010000010111110101000001001110110101100100011001010000011001. . .01010110100101010101010110011110",compilatore istruzioni
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#3,3,Orario lezioniOrario ufficiale:https://corsi.unibo.it/laurea/IngegneriaInformatica/orario-lezioni?anno=2&curricula=Lunedì inizio ore 9.00-11onlineGiovedì inizio ore 14.00-17.00Aula 6.1,orario lezioni orario inizio ore online gioved inizio ore aula
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#30,30,"Come si accede alla memoria (e non solo)?•SappiamocheilcodicenelmodellodiVonNeumannrisiedeinmemoria•Comesilegge(escrivedallamemoria)?•Comesileggonoescrivonoidati?
CPU
?•L’unico modo è attraverso dei segnali predefiniti (con un ben definito andamento temporale, ciclo di bus)  ",accede memoria von lunico modo attraverso segnali predefiniti con ben definito andamento temporale ciclo bus
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#31,31,"IndirizziBA[K..0]DatiBD[R..0] READControlloWRITEREADYINT
CPU
K+1R+1
",indirizzi bakdati bdr dcontrollo
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#32,32,"Come avviene la comunicazione?CPU
K+1MemoriaPeriferica#i
R+1•Tutto viaggia sui bus di sistema•Tutto è regolato da cicli di bus",avviene comunicazionec memoria perifericai rtutto viaggia bus sistematutto regolato cicli bus
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#33,33,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura,readyesempio ciclo lettura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#34,34,CKADDRESSMEMRDMEMWRDATADATA_OUTReady?Esempio di ciclo di scrittura,treadyesempio ciclo scrittura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#35,35,"Range di indirizzi•Sesonodisponibili32bit(BA[31..0])èpossibileavereaccessoa2^32elementi(memorie,periferiche)•32segnalidiindirizzo,4GB•Aogniindirizzoèassociatoundispositivo(memorie,periferiche)•E’necessariodecodificarel’indirizzoemessodallaCPUperdeterminareconqualedispositivolaCPUintendecomunicare•Quantibytepossonoesseretrasferitiduranteunciclodibus?Dipendedall’ampiezzadelbusdati",range
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#36,36,"Relazione tra hardware e software•ConsideriamounaistruzioneperleggeredallamemoriaunbyteaundeterminatoindirizzoxxxLBdestinazione,indirizzo;letturadiunbytePerprimacosaèeseguitoilfetchdell’istruzioneall’indirizzoxxx.come?Conunciclodibus,naturalmenteComefacciamoaconoscerel’indirizzoxxx?LaCPUhaaccessoalprogramcounterPCUnavoltalettaedecodificata,l’istruzioneèeseguita.Durantel’esecuzioneèeseguitounciclodibusdiletturaDuranteilciclodibusèemessol’indirizzo",relazione hardware
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#4,4,"Materiale didatticoDisponibile in formato PDF sul sito del corso:http://vision.disi.unibo.it/~smatt/Site/Courses.htmlNel sito sono presenti anche numerose prove d’esameI lucidi non sono un libro, seguire con attenzione le lezioni è fondamentale per superare rapidamente e con buoni risultati l’esame...",materiale didattico disponibile formato sito sito presenti numerose prove desame lucidi libro seguire attenzione lezioni fondamentale superare rapidamente buoni risultati lesame
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#5,5,"Materiale didattico per approfondimentiSeguendo il corso con attenzione e utilizzando i lucidiforniti NON è necessario utilizzare altro materialeper la preparazione dell’esame.Tuttavia, per chi desiderasse approfondire:–Hennessy & Patterson, ""Computer architecture: a quantitative  approach, Morgan Kaufmann, Anche in versione italiana. La seconda edizione (inglese, a dx) descrive approfonditamente il processore DLX-G. Bucci, Architettura e organizzazione dei calcolatori elettronici. Fondamenti, McGraw-Hill-J. Yiu, The definitive guide to the ARM Cortex M0, Newnes-Patterson &  Waterman, RISC-V, Strawberry Canyon
",materiale didattico approfondimenti seguendo corso attenzione utilizzando lucidiforniti necessario utilizzare altro materialeper preparazione desiderasse patterson computer architecture quantitative approach morgan kaufmann versione italiana seconda edizione inglese descrive processore bucci architettura organizzazione calcolatori elettronici fondamenti graw hill yiu the definitive guide cortex newnes patterson waterman strawberry canyon
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#6,6,RequisitiPer superare in modo proficuo il corso di Calcolatori Elettronici T è fondamentale avere compreso bene:1) Fondamenti di Informatica T2) Reti Logiche TPer Reti Logiche T è cruciale la progettazione diretta.Si sconsiglia vivamente di seguire questo corso senza avere solide basi in 1) e soprattutto di Reti Logiche T,requisiti superare modo proficuo corso calcolatori elettronici fondamentale avere compreso bene fondamenti informatica reti logiche reti logiche cruciale progettazione direttasi sconsiglia vivamente seguire corso senza avere solide basi soprattutto reti logiche
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#7,7,"Avvisi e altre comunicazioni Eventuali comunicazione di carattere generale sarannoinserite nella pagina web del corso, nella sezione “Avvisi” di Calcolatori Elettronici T o chat Teams
",avvisi altre comunicazioni eventuali comunicazione carattere generale sarannoinserite pagina web corso sezione avvisi calcolatori elettronici chat teams
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#8,8,"Modalità di svolgimento dell’esame •L’esame consiste in una prova SCRITTA di 2.5 ore•Nessuna prova orale• Non è possibile portare libri, appunti, computer, telefoni, smartphone, tablet, smartwatch, etc• E’ indispensabile (pena l’esclusione dall’esame) presentarsi con documento di identitàe badge•Esami gravemente insufficienti saranno verbalizzati",modalit svolgimento dellesame lesame consiste prova orenessuna prova orale possibile portare libri appunti computer telefoni smartphone tablet smartwatch etc indispensabile pena lesclusione dallesame presentarsi documento identite badgeesami gravemente insufficienti verbalizzati
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#9,9,"Prossimi appelli d’esame 
•La date degli esami sono consultabili su Almaesami•L’iscrizioneagli appelli via Almaesamiè obbligatoria e si chiude (circa) una settimana prima• Non è ammessa alcuna deroghe all’iscrizione•Sono previsti 6 appelli all’anno: -3 Dicembre/Febbraio -2 Giugno/Luglio -1 SettembreNessun appello straordinarioSe possibile (aule, etc) il primo appello subito dopo il termine delle lezioni",prossimi appelli desame la date esami consultabili appelli via almaesami obbligatoria chiude circa settimana prima ammessa alcuna deroghe previsti appelli allanno giugnoluglio settembre nessun appello straordinario possibile aule etc primo appello subito dopo termine lezioni
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#0,0,"02 Mappinge decodificaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",mappinge decodifica calcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#1,1,"Spazio di indirizzamento•Una CPU emette un certo numero di indirizzi e altri segnalisui bus di sistema per comunicare con altri moduli  •Il numero di diversi indirizzi emessi dalla CPU costituiscelo spazio di indirizzamento•Una CPU che emette un indirizzo a 20 bit ha uno spazio diindirizzamento di 1 MB (2^20)•Una CPU che emette un indirizzo a 32 bit ha uno spazio diindirizzamento di 4 GB (2^32)•Le prime CPU avevano spazi di indirizzamento molto ridottodi alcuni KB (e.g., 64 KB o meno)•Oggi è consuetudine avere almeno 32 bit di indirizzo",spazio emette certo numero indirizzi altri segnalisui bus sistema comunicare altri moduli il numero diversi indirizzi emessi costituiscelo spazio emette indirizzo bit spazio una emette indirizzo bit spazio le prime spazi indirizzamento molto ridottodi alcuni menooggi consuetudine avere almeno bit indirizzo
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#10,10,"11Memorie RAM (SRAM)
•Memorie volatili, leggibili e scrivibili•Capacità a multipli di 4:8K, 32K, 128K, 512K, etc•DRAM: 1 transistore per  bit, maggiore capacità, più lenteAiCE*OE*I/OiTceTaccToe(Out)ReadCycleAiCE*WE*I/OiTawTwp(In)TdsWriteCycleNCA16A14A12A7A6A5A4A3A2A1A0I/O0I/O1I/O2GNDVCCA15NCWE*A13A8A9A11OE*A10CE*I/O7I/O6I/O5I/O4I/O31234567891011121314151632313029282726252423222120191817128K ´8RAM",memorie memorie volatili leggibili multipli etcd transistore bit maggiore capacit lente ceo eioi tce tacc toeoutread cycle cew eioi taw twpintds write cycle wea oea ceio
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#11,11,"12
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#12,12,"13
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#13,13,"14
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#14,14,"15
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#15,15,"16
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#16,16,17Integrati Notevoli: 2441A11A21A31A42A12A22A32A41Y11Y21Y31Y42Y12Y22Y32Y4EN1*EN2*74XX244ENx*xAixYiDriver 3-state ad 8-bit(strutturato in 2 gruppi di 4 bit) ,integrati notevoli ene enxx aix driver state bitstrutturato gruppi bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#17,17,"18
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#18,18,"19
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#19,19,"20
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#2,2,"Un indirizzo per distribuire merci
WR(consegna)RD(preleva)
",indirizzo distribuire merci rconsegnar dpreleva
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#20,20,21EN*BiDIRAiA1A2A3A4A5A6A7A8B1B2B3B4B5B6B7B8EN*DIR74XX245IntegratiNotevoli: 245Driver bidirezionale (transceiver) ad 8-bit.,enbi rai end integrati notevoli driver bidirezionale transceiver bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#21,21,"22
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#22,22,"23
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#23,23,"24
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#24,24,"25Integrati Notevoli: 373D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7COE*74XX373
CDiQiOE*OiZCQiDCDiOE*OiLatch CD 
Latch a 8-bit con uscite 3-state",integrati notevoli d oeoi oeoi latch latch bit uscite state
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#25,25,"26Integrati Notevoli: 374D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7CKOE*74XX374
CKDiQiOE*OiZQiDCKDiOE*OiFlip-Flop D
Registro edge-triggeredcon uscite 3-state",integrati notevoli d kdi oeoi zqi kdi oeoi flip flop registro edge triggeredcon uscite state
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#26,26,,
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#27,27,"28
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#28,28,"29
",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#29,29,"30Registro Edge-Triggered con WE*WE*D0OE*O0Flip-Flop DMUX10CKDQ0O1Flip-Flop DDQ1MUX10ON-1Flip-Flop DDQNMUX10D1
DN-1D[0..N-1]WE*OE*O[0..N-1]",registro edge triggered oeo flip flop flip flop flip flop eon
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#3,3,"CPU
Decoder(RC)I livelloCS_ACS_BCS_CCS_DCS_ECS_FCS_GCS_HABCD
EFGHUn indirizzo per distribuire dati (CPU)
Il decoder di II livello è all’interno di ciascundispositivo (memoria, etc) 
BA[K-1..0]BD[R-1..0]",decoderr livello hun indirizzo distribuire dati decoder livello allinterno memoria etc
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#30,30,"Register File (1 read-port, 1 write-port)DEC01M-1EN*m  Read_AddressDEC01M-1EN*m  Write_AddressRD*WR*N  Write_DataRead_DataN CKD[0..N-1]WE*OE*O[0..N-1]R0D[0..N-1]WE*OE*O[0..N-1]R1
D[0..N-1]WE*OE*O[0..N-1]RM-1N.B. :M=2m",register file read port write portd enm read address enm write address rdw write data read data kdn eon eon eon
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#31,31,Mappingdi dispositivi da 8 bit in sistemicon bus dati da 8 bit•Consideriamodispositiviconportadatia8bit•Imponiamo(temporaneamente)lulteriorecondizionecheilparallelismodelbusdatisiaa8bit•Inquesteipotesilassegnamentoaundispositivodiunafinestradiindirizziinunospaziodiindirizzamentoavverràingeneralenelrispettodelledueseguentiulterioricondizionirestrittive:–ladimensionedellafinestradiindirizziassociataaundispositivoèunapotenzadidue–lafinestraècompostadaindirizzicontigui,mappingdi dispositivi bit sistemicon bus dati
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#32,32,"33Dimensione della finestra occupata da un dispositivo -esempi•Undispositivoaccessibileattraversoilbusoccupaingeneralen=2^Kposizioninellospaziodiindirizzamento•nrappresentailnumerodioggettia8bitindirizzabiliallinternodeldispositivo(es.numerodicelledimemorianelleRAMedEPROM)•K(numerodibitdiindirizzointernialdispositivo)èfortementevariabilealvariaredeldispositivo:–Ingeneraleneidispositividiinput/output(i.e.,leinterfacce)Kèpiccolo(e.g.,2)–ingeneraleneidispositividimemoriaKègrande(e.g.,perunaRAMda128KBsihaK=17)",dimensione finestra occupata dispositivo med mda kbsiha
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#33,33,"Caratteristiche ai morsetti di un dispositivo indirizzabile su una finestra di n = 2^K byteQualunquedispositivoda8bitconall’internon=2^kelementiindirizzabiliseparatamentehaalsuointernoundecoder(IIlivello)diKvariabiliconingressodienablecheselezionaisingolioggettiindirizzabili–Read(RD),dettoancheOutputEnable(OE)èilcomandodilettura.QuandoRDeCSsonoattivi,ildispositivoesponeilsuBD[7..0]ilcontenutodellacellaindirizzata–Write(WR),èilcomandodiscrittura.QuandoCSasseritosulfrontedidiscesediWRècampionatoildaatopresentesuBD[7..0]DISPCSA[K-1..0].RDWRD[R..0]?KBA[K-1..0]CS_DISP8BD[7..0]RDWR",caratteristiche morsetti dispositivo indirizzabile finestra byte ilivellodi ddettoanche output enableo rde bdd sak rdrk bak bdr
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#34,34,"350K32K8K8K8K8KSpazio di memoria8KDispositivo di memoria fisico che realizza una zona della memoria logica00001FFF0121314Ind. delBloccoIndirizzo interno al blocco
CS = A14 AND A13*(Dispositivo da 8K di memoria)Esempio con 15 bit di indirizzo del sistema 
In questo caso ",kspazio memoria kdispositivo memoria fisico realizza zona memoria logica ind blocco indirizzo interno blocco memoriaesempio bit indirizzo sistema caso
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#35,35,"Mapping allineato di dispositivi da 8 bit in sistemi con bus dati da 8 bitSiconsideriundispositivoDdin=2^Kbyteindirizzabili•SidicecheDèmappatoallindirizzoAsegliindirizzideibytediDsonocompresitraAeA+(n-1),cioèseAèlindirizzopiùbassotratuttigliindirizziassociatiaD•SidicecheDèallineatoseAèunmultiplodin(numerodibytesinternialdispositivo),cioèse:(indirizzopiùbassodiD)MODn=0(condizionediallineamento)•SeDèallineatoalloraikbitmenosignificatividiAsonougualiazeroEsempi:•Undispositivodaduebyteèallineatoseèmappatoaunindirizzopari•Unadispositivoda8byteèallineatoseèmappatoaunindirizzoilcuivalorecodificatoinbinarioterminacon3zeri•Undispositivoda16byteèallineatoseilsuoindirizzoinizialeincodiceesadecimalehalaciframenosignificativaugualeazero•Undispositivoda64KBèallineatoseilsuoindirizzoincodiceesadecimalehalequattrocifremenosignificativeugualiazero",mapping allineato dispositivi bit sistemi bus dati bit ciose dsidiceche dallineatose
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#36,36,"Come individuare univocamente una finestra allineata di 2^K byte in uno spazio di indirizzamento•Supponiamo di mappare un dispositivo D di 2^k bytes(k=4) a un indirizzo A allineato di uno spazio di indirizzamento di 1 MB (bus di indirizzi di 20 bit): •Allora possiamo porre A = α ## (0)k(ex F8570) ove αè una configurazione binaria di 20 -K bit e gli indirizzi associati a D saranno compresi traAmin= A = α ## (0)k e Amax= Amin+ 2k -1 = α## (1)k    (Amin= F8570–Amax=  F857F)•Dunque, possiamo indicare lindirizzo  Aidelli-esimo byte di D come linsieme di due campi concatenati: Ai = α ## i(Ai = F8573)αindividua tra le 2^(20-K) finestre allineate di 2^K byte presenti nello spazio di indirizzamento, quella su cui è mappato (a = F857)iindividua loffset nel chip del byte indirizzato (i = 3)(NB ## è l’operatore simbolico concatenazione)",individuare univocamente finestra allineata byte spazio mappare dispositivo bytesk indirizzo allineato spazio indirizzamento bus indirizzi bit allora possiamo porre kex ove configurazione binaria bit indirizzi associati compresi amin amax amin amin famax fdunque possiamo indicare lindirizzo aidelli esimo byte linsieme due campi concatenati iai finestre allineate byte presenti spazio indirizzamento mappato fiindividua loffset chip byte indirizzato loperatore simbolico concatenazione
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#37,37,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 1IndirizzamentodiunbytediunaRAMallindirizzo40010Hinunospaziodiindirizzamentodi1MBnellipotesididisporrediunchipda128KBmappatoallindirizzo40000H:Lindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi128KBincuièmappatalaRAM,ilsecondoidentificaloffsetall’internodellaRAM
A0A19A17A16Identificatore dellafinestra di 128Kin cui si trova la RAMOffset del byte indirizzato allinterno del dispositivo di 128KB 0      1       00  0000  0000  0001  0000iα",campi suddivide lindirizzo dispositivi mappati spazio indirizzamento esempio identificatore dellafinestra kin trova offset byte indirizzato allinterno dispositivo
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#38,38,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 2Indirizzamentodiunbyteall’indirizzo1026HinundispositivodiI/Odi16bytemappatoall’indirizzo1020Hdiunospaziodiindirizzamentodi64KBLindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi16Bincuièmappatoildispositivo,ilsecondoidentificaloffsetneldispositivo
A0A15A4A3Identificatore dellafinestra di 16Bin cui si trova DOffset del byte indirizzato allinterno del dispositivo Ddi 16 Bindirizzato 0 0 0 1       0 0 0 0         0 0 1 00       1        1        0iα",campi suddivide lindirizzo dispositivi mappati spazio indirizzamento esempio identificatore dellafinestra bin trova offset byte indirizzato allinterno dispositivo ddi bindirizzato
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#39,39,"Decodifica degli indirizzi in caso di mappingallineato•Consideriamounospaziodiindirizzamentodi1MBincuisiamappatoundispositivodi2^Kbyte•PerindividuareunacelladiindirizzoAi=α##ipossiamodecodificaretuttii20bitchecompongonoAi•Questadecodificaèeffettuataricorrendoallastrutturadeidecoderadalbero,conalberodiduelivelli:–IlIlivelloèusatoperdecodificareα(cheidentificalaposizioneincuiilchipèmappato);perdecodificareαdobbiamodecodificare20-Kvariabili–ilIIlivellovieneutilizzatoperdecodificarei(cheidentificailbyteallinternodelchip,serveundecoderdikvariabili)•IldecoderdiIIlivellositrovaallinternodelchipmentreladecodificadiαèacaricodelprogettistadelsistemachepuòutilizzareundecoderdi20-kvariabiliconcuisidecodificaα•Ladecodificaècompletasesiutilizzanotuttii20-Kbitperdecodificareα,semplificatasesiutilizzasolounsottoinsieme(minimo)dei20-Kbit",decodifica indirizzi caso kvariabiliil kbit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#4,4,"Condizione di visibilità di un dispositivo da parte del software•Condizionenecessariaaffinchéundispositivofisico(memoria,interfaccia,oaltraentità)siaaccessibilealsoftwareè:–ildispositivodeveesseremappatoinunospaziodiindirizzamento•Mappareinunospaziodiindirizzamentosignifica:–associarealdispositivounafinestradiindirizzidiquellospaziodiindirizzamento•Siaccedeaidispositivimappatiinunospaziodiindirizzamentoconciclidibus",condizione visibilit dispositivo parte
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#40,40,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèdifattoattivato(mappato)induedifferentizonedellamemorialogica00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13*Segliindirizziusatidaunprogrammasonoquellichevannoda16Ka24K(overoda4000Ha5FFFH)equellida24Ka32K(da6000Ha7FFF)nonsonousatialloraèpossibileladecodificaincompletaoparzialeinquantolazona24K-32Knonvienemaiindirizzata.EspressioneCSpiùsemplice,kspazio memoria ind blocco indirizzo interno blocco koveroda fhequellida kda cspisemplice
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#41,41,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèattivato(mappato)induedifferentizonedellamemorialogicanonconsecutive00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13Decodifica parziale 2/2,kspazio memoria ind blocco indirizzo interno blocco decodifica parziale
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#42,42,EsercizioSiconsideriunsistemaconbusindirizzia16bitebusdatia8bit.Scrivereleespressionididecodificacompletaesemplificata(quelladausareall’esame)neiseguenticasi:1)Dispositivodimemoriada16KBmappatoa8000h2)Dispositivodimemoriada8KBmappatoa0000h3)EntrambiidispositiviprecedentiSec’èunsolodispositivo(casi1e2)ilCSèmoltoparticolare….,esercizio
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#43,43,44,
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#44,44,"Mapping, read, write e set/reset di un FFD
•Il FFD èun elementaredispositivodi memoria•Con unaCPU, come possiamo:•scriverenelFFD•leggerenelFFD •settareo resettarein modoasincronoilFFD FFDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]?
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassi",mapping read write setreset il un memoriacon dleggerenel settareo resettarein modoasincronoil bdb consideriamo caso bus dati bit bit indirizzo indirizzi alti indirizzi bassi
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#45,45,"NellepagineseguentiassumiamocheicomandidelFFDsianomappatineiseguentiindirizzi:CS_READ_FFD ->  80003hCS_WRITE_FFD ->  80002hCS_A_RES_FFD ->  80001hCS_A_SET_FFD ->  80000hAssumiamoinoltrediutilizzareilsegnaleBD0delbusdatiperleggereescrivereilsingolobitdidato.Ovviamentesarebbepossibileutilizzarealtriindirizzinonappartenentiallememorieeanchealtrisegnalidelbusdati(anchediversiperlettureescritture).Seiltestodell’esamenonspecificaqualiindirizziusarelasceltaèlasciataallostudente.Spesso,lasceltadegliindirizzisemplifica/complicaisegnalididecodifica.",
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#46,46,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura,readyesempio ciclo lettura
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#47,47,"CKADDRESS
DATADATA_OUTReady?Esempio di ciclo di scrittura
MEMRDMEMWR",treadyesempio ciclo scrittura
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#48,48,"FFDDQA_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD0BD0MEMWR*CS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_FFD = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_FFD = BA19·BA18*·BA1·BA0*       (ist. scrittura)CS_A_RES_FFD = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_FFD = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).01",ab ab ab ab ab ab ab am ist letturac ab ab ab ist scritturac ab ab ab am wrist scritturac ab ab ab am wrist scrittura avedremo istruzioni lettura scrittura risploadbyte storebytes
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#49,49,"FFD(x8)D[7..0]Q[7..0]A_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD[7..0]BD[7..0]MEMWR*Estensione a 8 bit
01
StessiCSdellapaginaprecedente,cambiasoloilnumerodibitdidatotrasferiti.8888",wrestensione bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#5,5,"Esempio: una CPU con K=3 bit di indirizzo
CPU3•Lospaziodiindirizzamentosarebbedisolo8elementi•Supponiamodiavereduedispositividimemoria,da4byte:AeB76543210111110101100011010001000Decoder(RC)I livelloCS_ACS_BBA[2..0]",esempio bit indirizzo decoderr livello
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#50,50,"Mapping, read, write e set/reset di un latch
•Anche il latch CD è un elementare dispositivo di memoria•Con una CPU, come possiamo:•scriverenel latch•leggerenel latch •settare o resettare in modo asincrono il latch CDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassiC?",mapping read write setreset latch anche latch elementare dispositivo memoriacon latch settare resettare modo asincrono latch bdb consideriamo caso bus dati bit bit indirizzo indirizzi alti indirizzi bassi
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#51,51,"CDA_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD0BD0CS_WRITE_LATCHCS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_LATCH = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_LATCH = BA19·BA18*·BA1·BA0*·MEMWR(ist. scrittura)CS_A_RES_LATCH = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_LATCH = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).CDQMappiamo i quattro comandi del latch agli stessi indirizzi usati per il FFD.",ab ab ab ab ab ab ab am ist letturac ab ab ab am wrist scritturac ab ab ab am wrist scritturac ab ab ab am wrist scrittura avedremo istruzioni lettura scrittura risploadbyte storebytes mappiamo quattro comandi latch indirizzi usati
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#52,52,"Estensione a 8 bit
Stessi CS della pagina precedente, cambia solo il numero di bit di dato trasferiti.CD(x8)A_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD[7..0]CS_WRITE_LATCHCBD[7..0]888D[7..0]Q[7..0]",estensione bit pagina precedente cambia solo numero bit dato trasferitic dxa
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#53,53,"Incrementare il parallelismo dei dati
•Abbiamoconsideratofinoaorasistemiconunparallelismo(busdati)a8bit•Ognitrasferimentorichiedeunciclodibus•Nelementi(byte)->Nciclidibus•Sappiamochelememorie(enonsolo)sonolente(vsCPU)
1",incrementare parallelismo dati
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#54,54,"i)
ii)
iii)
111",iii
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#55,55,"•Possiamo fare meglio?•Si, aumentando il parallelismo dei dati•Riducendo la dimensione di ciascuna memoria•Trasferendo più dati nello stesso ciclo di bus 
¼¼¼¼i)i)i)i)IS",possiamo fare megliosi aumentando parallelismo datiriducendo dimensione ciascuna dati stesso ciclo bus iiiii
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#56,56,"•CosaNON fare?•Trasferireglielementisequenzialmentein memoriepiùpiccole•Elementicontiguivannosumemoriediverse 
¼¼¼¼NOilparallelismodi ciascunamemoriaèsempre8 bit!
i)ii)iii)iv)i)ii)iii)iv)",cosa bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#57,57,"Memoria con processori a parallelismo > 8Il caso dei 16 bitIndirizzo fisicomemorie = Indirizzo logico/ 2Sul piedino  A0della memoria -> BA1busA1della memoria ->BA2 bus……………………………..
MemorialogicaMemoriafisicaBUS ALTOBUS BASSO876543210876543210abcdefghi
acegibdfhlWord(3) -> Byteh(1) e Byteb(2) -> 2 lettureLogicoFisicoFisicoLe memorie  fisiche vanno sempre in coppiaPer ogni bancoci deve essere un ByteEnableBE0 per banco 7-0 e BE1 per banco 15-8078bit 15Indirizzo interno ai chip
Memorie sempre in coppia Ad esempio 2 x8K = 16 K (Lettura bytes 3 e 4 che però stanno a indirizzi fisici interni delle memorie differenti)(d ,e)(d )(e )",memoria processori parallelismo caso bit indirizzo fisicomemorie indirizzo logico piedino adella memoria abus adella memoria memorialogica memoriafisica acegibdfhl word byteh byteb letture logico fisico fisico memorie fisiche vanno sempre coppia ogni bancoci deve essere byte enable banco banco bit indirizzo interno chip memorie sempre coppia esempio lettura bytes per indirizzi fisici interni memorie differentid
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#58,58,"Memorie con bus a 16 bitBE1      BE01           1       Word1           0       Byte alto (ind. dispari)0           1       Byte basso (ind. pari)0           0       Non possibile  Lo scambio byte alto esterno, byte basso del registro  e viceversa avviene allinternodel microprocessore
BA0del processorenon viene generato (di fatto seleziona il banco -al suo posto BE0 e BE1)BA1del processore connesso ai piedini A0delle memorieBA2del processore connesso ai piedini A1delle memorie etc. etc.7      015     8Memorie fisicheMicroprocessoreRiMUX",memorie bus bit word byte alto ind dispari byte basso ind pari possibile scambio byte alto esterno byte basso registro viceversa avviene allinternodel microprocessore adel processorenon viene generato fatto seleziona banco posto adel processore connesso piedini adelle memorie badel processore connesso piedini adelle memorie etc etc memorie fisiche microprocessore
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#59,59,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  740000h5FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19*BA18BA17*BE1CSEPROM0= BA19*BA18BA17* BE0Individua la zona di memoria da realizzareLe memorie vanno sempre in coppia (16 bit)La decodifica si fa come se si avesse una memoria a 8 bit. Si usano dispositivi di taglia metà selezionati con BE0 e BE1Memoria con processori a parallelismo > 8Il caso dei 16 bit",memorialogica memoriafisica ffh kbit ffhh ffh indirizzi interni bee ab ab ab ab ab individua zona memoria realizzare memorie vanno sempre coppia bitla decodifica memoria bit usano dispositivi taglia met selezionati memoria processori parallelismo caso bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#6,6,"•Comefacciamoadattivareunadelleduememorieinbaseall’indirizzoBA[2..0]emessodallaCPU?•Ovvero,comeèfattalaretedidecodifica(Ilivello)chegeneraiduesegnaliCS_AeCS_B?•CS_A=BA2CS_B=BA2*•Questisegnalisarannoinviatiaallememorie(decodificadiIlivello)•Poi,saràindividuatol’elementoall’internodellememoriaselezionata(decodificadiIIlivello)76543210111110101100011010001000BA2=1BA2=0II livello",bc livello
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#60,60,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  780000h9FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19BA18*BA17*BE1CSEPROM0= BA19BA18*BA17*BE0Individua la zona di memoria da realizzareMemoria con processori a parallelismo > 8Il caso dei 16 bit",memorialogica memoriafisica ffh kbit ffhh ffh indirizzi interni bee ab ab ab ab ab ab individua zona memoria realizzare memoria processori parallelismo caso bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#61,61,"BUS BASSO4000540004400034000240001400005FFFF5FFFE5FFFD5FFFC5FFFBMemoria Logica
128K0   Eprom Pin0    Bus Pin77EPROM0BE0 -64KFFFFFFFEFFFDFFFC0003000200010000BUS ALTO07EPROM1BE1 -64KFFFFFFFEFFFDFFFC0003000200010000Eprom PinBus Pin       15              8Indirizzi interni della EPROMIndirizzi interni della EPROM
Indirizzi della memoria logicaMemoria con processori a parallelismo > 8Il caso dei 16 bit",memoria logica eprom pin bus pin eprom pin bus pin indirizzi interni indirizzi interni indirizzi memoria logica memoria processori parallelismo caso bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#62,62,"Memoria con processori a parallelismo 32 bitMemorialogicaMemoriafisica
BUS 3BE3876543210abcdefghi
aeibfl07815cgdh162324bit 3187654210BUS 2BE2BUS 1BE1BUS 0BE0Indirizzo fisico = Indirizzo logico/4",memoria processori parallelismo bit memorialogica memoriafisica indirizzo fisico indirizzo logico
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#63,63,"64Bus enable con parallelismo 32 bitBE3      BE2     BE1     BE01            1            1           1       Word 32 bit0            0            1           1       Half word bassa 1            1            0           0      Half word alta  0            0            0           1       Byte 0-7  N.B. BA0 e BA1  del processorenon vengono generati (di fatto selezionano uno  dei banchi -al loro posto BE0, BE1, BE2, BE3)BA2del processore connesso ai piedini A0delle memorieBA3del processore connesso ai piedini A1delle memorie etc. etc.etc.0            0            1           0       Byte 15-8  Lo scambio fra i bytes (half word) dei banchi di memoria e i byte (half word)  dei registri  e viceversa avviene allinternodel microprocessore",bus enable parallelismo bit word bit half word bassa half word alta byte processorenon vengono generati fatto selezionano banchi posto adel processore connesso piedini adelle memorie badel processore connesso piedini adelle memorie etc etcetc byte scambio fra bytes half word banchi memoria byte half word registri viceversa avviene allinternodel microprocessore
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#64,64,"65Memoria logicaMemoria fisica
BUS 32MB2MB2MBFFFFFFFFh
00000000h512K243140000000h401FFFFFh00000h7FFFFhIndirizzi interni alle EPROM
4 Memorie x 512K= 2MBEPROM3BE3*
CSEPROM3= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE3CSEPROM2 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE2CSEPROM1 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE1CSEPROM0= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE0Individua la zona di  memoria da realizzare512K1623EPROM2BE2*512K815EPROM1BE1*512K07EPROM0BE0*BUS 2BUS 1BUS0Selezionail BUS
CS espressi in forma veraMemoria allineata11 bitdi indirizzosono fissiMemorie con parallelismo 32 bit",memoria logica memoria fisica ffh fhh ffh indirizzi interni memorie ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab individua zona memoria realizzare beb selezionail espressi forma vera memoria allineata bitdi indirizzosono fissi memorie parallelismo bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#65,65,"Memoria logicaMemoria fisicaBUS 3  -D24-312MB2MB2MBFFFFFFFFh
00000000h512K40000000h401FFFFFh00000h7FFFFhEPROM3DLX512K512KEPROM2EPROM100000h7FFFFh00000h7FFFFh512KEPROM000000h7FFFFhBUS 2  -D23-16BUS1  -D15-8BUS 0  -D7-0BE0BE1BE2BE3
Emessi dal processoreal posto di BA1e BA0Memorie con parallelismo 32 bit",memoria logica memoria fisica ffh fhh ffh ffhh ffh omh ffh emessi processoreal posto memorie parallelismo bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#66,66,"Memoria logica(come vista dal programmatore)512K
40000000h401FFFFFh
00000h7FFFFhEPROM3Memoria fisica(come realizzatafisicamente)
dh00001h2MB
512K00000h7FFFFhEPROM2
cg00001h512K00000h7FFFFhEPROM1
bf00001h512K00000h7FFFFhEPROM0
ae00001habcde40000001h40000002h40000003h40000004hIndirizzi fisicidei singolidispositivi
------x
I dati di indirizzi logiciconsecutivisi trovano su dispositivi diversiLa cella x di indirizzo logico abcdefghsi troverà allindirizzo fisicoabcdefgh/4 del dispositivo EPROMi ove iè il resto della divisioneabcdefghMemorie con parallelismo 32 bit",memoria logicacome vista ffh memoria fisicacome dhh ffh cgh ffh bfh ffh indirizzi fisicidei dati indirizzi trovano dispositivi diversi cella indirizzo logico abcdefghsi trover allindirizzo dispositivo omi ove resto memorie parallelismo bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#67,67,"Esempio:sivuolerealizzarenelDLX(bus32bit)unamemoriaRAMda256Kpostaallindirizzo84000000(allineata).Campodiindirizzamento84000000-8403FFFF.Dispositivi:8RAMda32K(leRAMda64KstaticheNONesistono!!!!)Difattoquindivisonoduebanchida128Kluno:ilprimorealizzalamemoriada84000000a8401FFFFelaltroda84020000a8403FFFF.Ichipdimemoriada32Kutilizzanoallorointerno(fisicamente)comeindirizzidiselezionedellecelleipinA14-A0chesonoperòcollegatirispettivamenteagliindirizziemessidalDLXBA16-BA2(ricordiamoinfatticheBA1eBA0delDLXNONsonoemessiealloropostovengonoemessiBE3,BE2,BE1eBE0).SinotiilruolodellindirizzoDLXBA17chedivideiduebanchiPrimobanco(decodificanonsemplificata)CSRAM00=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE0CSRAM01=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE1CSRAM02=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE2CSRAM03=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE3Secondobanco(decodificanonsemplificata)CSRAM10=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE0CSRAM11=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE1CSRAM12=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE2CSRAM13=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE3Ovviamentenelcasodidecodificasemplificata(memorialogicaincompletamenterealizzatafisicamente)lefunzionididecodificavengonoridottedicomplessità.OvequestiduebanchifosserogliunicidarealizzareiCSdipenderebberosolodaBA17edaBEiMemorie con parallelismo 32 bit",mda mda kle mda kstatiche bae badel beb amb ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab amb ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab baeda bei memorie parallelismo bit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#7,7,"Come è fatto un generico dispositivo?•Unqualsiasidispositivo(memoria,periferica,etc),comunicaconlaCPUmedianteunainterfacciastandardasxDISPCSA[K-1..0].RDWRD[R-1..0]?KBA[K-1..0]CS_DISPRBD[R-1..0]RDWRCPU•Lacomunicazioneconl’esternoavvienesecondomodalitàchesonospecifichedeldispositivoequindinonstandard•BA[K-1..0]utilizzati(internamente)perdecodificadiIIlivello",fatto generico rdr bak iilivello
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#8,8,"9Memorie EPROM•Memorie non volatili a sola lettura•Capacità a multipli di 2:32K, 64K, 128K, 256K, etcVPPA16A15A12A7A6A5A4A3A2A1A0D0D1D2GNDVCCPGM*NCA14A13A8A9A11OE*A10CE*D7D6D5D4D3EPROM1234567891011121314151632313029282726252423222120191817128K ´8AiCE*OE*DiTceTaccToeCE*OE*DiCella M/bit i",memorie ommemorie volatili sola multipli etc oea ced ceo edi tce tacc toe ceo edi cella mbit
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#9,9,CQiDCella di indirizzo jA0  A1    An-1WR RDD0   DiDN-1La cella di una RAMDECODERIIj2n´N,dcella indirizzo ja cella ijnn
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#0,0,"03 Linguaggio macchinaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",linguaggio macchina calcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#1,1,"Instruction Set Architecture•L’insieme delle istruzioni e dei registri di una CPU costituiscono l’InstructionSet Architecture(ISA)•Mediante l’ISA è possibile accedere alle risorseinterne (e.g., registri) ed esterne (e.g., memoria)•Tipicamente le istruzioni in linguaggio macchina sono generate da un compilatore•Più raramente, come in questo corso, scritte daiprogrammatori•Purtroppo, (quasi) ogni CPU possiede un proprio ISA •A proposito di ISA, esistono due linee di pensiero:•RISC: insieme ridotto di istruzioni semplici -> moltiregistri interni (DLX, ARM, RISC-V, etc)•CISC: insieme ampio di istruzioni complesse -> pochiregistri (Intel X86)",instruction set istruzioni registri costituiscono linstruction set architecturei samediante li possibile accedere risorseinterne registri esterne istruzioni linguaggio macchina generate compilatorepi raramente corso scritte quasi ogni possiede proprio proposito esistono due linee pensieror insieme ridotto istruzioni semplici moltiregistri interni etcc insieme ampio istruzioni complesse pochiregistri intel
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#10,10,Consentediesprimereefficacementeconfigurazionibinarie:•Traslazionelogicaasinistradinbit:<<n(inserendo“0”adestra)•Traslazionelogicaadestradinbit:>>n(inserendo“0”asinistra)•Concatenazionediduecampi:##•Ripetizionenvoltedix:(x)n•Ennesimobitdiunaconf.binariax:xn(ilpediceselezionaunbit)•Selezionediuncampoinunastringadibitx:xn..m(unrangeinpediceselezionailcampo)•Datalaconfigurazionebinariadi8bitC=011011002:–C<<2:101100002–C3..0##1111:1100|11112–(C3..0)2:110011002–(C6)4##C>>4:1111|000001102Notazioneper la costruzionedi configurazionibinarie,notazioneper costruzionedi
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#11,11,"•Trasferimentodiundato:←Ilnumerodibittrasferitièdatodalladimensionedelcampodestinazione;lalunghezzadelcampovaspecificatasecondolanotazioneseguentetuttelevoltechenonèaltrimentievidente•Trasferimentodiundatodinbit:←nQuestanotazionesiusapertrasferireuncampodinbit,tuttelevoltecheilnumerodibitdatrasferirenonèevidentesenzalarelativaindicazioneesplicita•Contenutodicelledimemoriaadiacentiapartiredall’indirizzox:M[x]Esempio:R1←32M[x]indicailtrasferimentodallamemoriaversoilregistroR1dei4byte:M[x],M[x+1],M[x+2],M[x+3]Altranotazione",
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#12,12,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
IlsegnalediRESETèasserito,all’avvio,daunareteesterna.AncheisegnalidiREADY,INTsonogeneratidaretiesternemautilizzatiduranteilnormalefunzionamento.Segnali del processore DLX30
32",bdm bab bdr ilsegnaledi processore
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#13,13,"•Unicospaziodiindirizzamentodi4G•32registrida32bitGP(R0,…,R31,conR0=0)•Istruzionidilunghezzacostante,32bitallineate•Campidelleistruzionididimensioni/posizionifisse•3formatidiistruzione:I,R,J•Noncisonoistruzionipergestirelostack•Peristruzionicheprevedonounindirizzodiritorno(JAL/JALR),essoèsalvatoinR31•NonesisteunregistrodiFLAGsettatodalleistruzioniALU.Lecondizionisonosettateesplicitamenteneiregistri(istruzioniSET)•E’presenteun’unicamodalitàdiindirizzamentoinmemoria(indiretto,medianteregistro+offset)•Leoperazioniaritmetico/logichesonoeseguitesolotraregistri(nontraregistriememoria)•Esistonoalcuneistruzioni(MOVS2IeMOVI2S)perspostaredatitraregistriGPeregistrispecialieviceversaCaratteristiche dell’ISA DLX (integer)",gprrcon alj caratteristiche delli integer
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#14,14,"Registri del DLX (integer)R0=0R1R2R3R28R29R30R3132PCIARMARMDR32Registri GP*accessibilidirettamentedal codiceRegistri nonaccessibilidirettamentedal codice*
",registri integerr registri codice registri codice
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#15,15,DLX (integer): tipi di datoNelDLX(integer)sonodisponibilitretipididato:BYTE(8bit)HALF-WORD(16bit)WORD(32bit)•Idatididimensioneinferiorea32bit(quindia8o16bit)lettidallamemoriadebbonoessereestesia32bitduranteilcaricamentoneiregistri(semprea32bit)•Questaoperazionepuòessereeseguitamantenendoomenoilsegnodeldatolettodallamemoria07015031,integer tipi dato ebith dbitw
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#16,16,"Estensione del segnoInmolticasiènecessarioèestenderelarappresentazionediundatocodificatoconnbit,inundatoconunarappresentazioneambit(conm>n).Peresempio,volendotrasferireunbyte(n=8)dallamemoriainunregistroa32bit(m=32)ènecessarioconoscerelamodalitàconlaqualeèrappresentatoildatoletto.Esempio:10110101(n=8)Assumendoildatosenzasegno(unsigned),l‘estensionea32bitavvieneaggiungeno24zeri:00000000000000000000000010110101oppure(0)24##10110101Assumendoildatoconsegno(signed),l’estesioneavvienereplicando24volteilbitdisegno11111111111111111111111110110101oppure(1)24##10110101",estensione segno
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#17,17,"Il set di istruzioni (integer) del DLX•Le principali istruzioni aritmetiche e logiche•Istruzioni logiche anche con op. immediato: AND, ANDI, OR, ORI, XOR, XORI•Istruzioni aritmetiche: ADD, ADDI, SUB, SUBI•Istruzioni di shift(a destra anche aritmetico): SLL1, SRL, SRA2•Istruzioni di SET CONDITION: Sx, con x= {EQ, NE, LT, GT, LE, GE} •Le principali istruzioni di trasferimento dati•Loadbyte signede unsigned(LB, LBU), loadhalfwordsignede unsigned(LH, LHU), loadword (LW)•Storebyte, storehalfword, storeword: SB, SH, SW•Copia un dato da un registro GP a un registro speciale e viceversa MOVS2Ie MOVI2S•Le principali istruzioni di trasferimento del controllo•Istruzioni di salto condizionato (PC+4 relative): BNEZ, BEQZ•Istruzioni di salto incondizionato J: assoluto (con reg.) e PC-relative•Istruzioni di chiamata a procedura Jumpand Link (JAL). L’indirizzo di ritorno viene automaticamente salvato in R31. JAL con registro e immediato  (PC-relative)•Istruzione di ritorno dalla procedura di servizio delle interruzioni: RFE1)Shiftlogicoasinistraeshiftaritmeticoasinistracoincidono(entrano0neibitmenosignificativi).PerquestaragioneNONesisteSLA.Fareattenzioneconshiftasinistra,nonpreservailsegnoepuògenerareoverflow2)Trascinandoadestradiunaposizioneunregistroeinserendoasinistrasempreilbitdelsegnosimantieneilsegnodeldatomentrelosidividesuccessivamenteper2",set istruzioni integer lxle principali istruzioni aritmetiche logiche immediato iistruzioni aritmetiche iistruzioni shifta destra aritmetico raistruzioni le principali istruzioni trasferimento datiloadbyte signede unsignedl unsignedl loadword wstorebyte storehalfword storeword wcopia dato registro registro speciale viceversa sle principali istruzioni trasferimento salto condizionato relative zistruzioni salto incondizionato assoluto con reg chiamata procedura jumpand link lindirizzo ritorno viene automaticamente salvato registro immediato ritorno procedura servizio interruzioni nesiste
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#18,18,"Elencoistruzionidel DLX (integer)Data TransferLWRa,Imm16bit(Rb)LB Ra,Imm16bit(Rb)LBU Ra,Imm16bit(Rb)LH  Ra,Imm16bit(Rb)LHURa,Imm16bit(Rb)SW  Ra,Imm16bit(Rb)SH  Ra,Imm16bit(Rb)SB  Ra,Imm16bit(Rb)MOVS2IRa,Rs*MOVI2SRs*,RaSpecial registerRs* (IAR)Aritmetiche/logicheADD Ra,Rb,RcADDIRa,Rb,Imm16bitADDURa,Rb,RcADDUI Ra,Rb,Imm16bitSUB Ra,Rb,RcSUBIRa,Rb,Imm16bitSUBURa,Rb,RcSUBUIRa,Rb,Imm16bitSLL Ra,Rb,RcSLLI Ra,Rb,Imm16bitSRL Ra,Rb,RcSRLI Ra,Rb,Imm16bitSRA Ra,Rb,RcSRAI Ra,Rb,Imm16bitOR Ra,Rb,RcORIRa,Rb,Imm16bitXORRa,Rb,RcXORIRa,Rb,Imm16bitANDRa,Rb,RcANDIRa,Rb,Imm16bitLHI Ra,Imm16bitControlloSxRa,Rb,RcSxIRa,Rb,Imm16bitBEQZRa,Imm16bitBNEZ Ra,Imm16bitJImm26bitJRRaJALImm26bitJALRRaxpuò essere: LT,GT,LE,GE,EQ,NE
Ra{R0+,R1,..,R30,R31}Rb{R0,R1,..,R30,R31}Rc{R0,R1,..,R30,R31}+RanonpuòessereR0comeregistrodestinazionediistruzioniload,MOV2SI,aritmetico/logiche,LHIeSET∈∈∈
Per le istruzioni aritmetiche: l’immediato a 16 bit è esteso senza segno se di tipo U (unsigned) altrimenti con segno.  Per istruzioni logiche, sempre estensione senza segno.  ",integerdata transfer irarsm srsra special register rarbrc rarbimmbit rarbrc rarbimmbit rarbrc rarbimmbit rarbrc irarbimmbit rarbrc rarbimmbit rarbrc rarbimmbit rarbrc rarbimmbit rarbrc irarbimmbit rrarbrc rarbimmbit drarbrc rarbimmbit raimmbit controllo rarbrc irarbimmbit raimmbit raimmbit jimmbit limmbit raxpu essere hie t istruzioni aritmetiche limmediato bit esteso senza segno tipo unsigned altrimenti segno istruzioni logiche sempre estensione senza segno
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#19,19,"DLX: formato delle istruzioni
•Istruzionidiload,store,branch,JeJALconregistro,serconditionSxIeALUconoperandoimmediato.L’immediatoèa16bit•NelleoperazioniloadeALURS2/RdèRd.NellestoreRS2/RdèRS2.InentrambiicasiRS1perindirizzosorgente(loadostore)oregistrosorgente(operazioniALUconconoperandoimmediato)IOpCodeRS2/RdRS1Immediato di 16 bit
JOpCodeImmediato/offset di 26 bit (PC relative)•Salti incondizionato con e senza ritorno (Je JAL) con immediatoROpCodeRS2RS1RdOpCodeext. (11 bit)•IstruzioniALUdeltipoRd¬Rs1opRs2oppuresetconditionSxtraregistri6 bit5 bit5 bit5 bit11 bit031•In alcuneistruzionidi tipoI (LOAD e ALU), RS2 rappresentailregistrodestinazioneRd•Alcuneistruzioni(e.g., J e JAL con registro) potrebberoesserecodificatecon piùdi un formatotraquellidisponibili",formato istruzioni srd rdnellestore rsrd code rsrd immediato bit code bit relativesalti incondizionato senza ritorno immediato rop code codeext bitistruzioni udeltipo rdrsop sxtraregistri bit bit bit bit bitin tipo registro pidi
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#2,2,"Requisitidi un linguaggiomacchina/ISAOltreallapossibilitàdipoterrisolvereunqualsiasiproblema*,unrequisitofondamentalediunlinguaggiomacchina/ISAèquellodiminimizzareiltempodiesecuzionedelcodice*•SeCPImedioèilnumeromediodiclockperl’esecuzionediunaistruzione,l’obiettivoèquellodiminimizzareCPUTime=Nistruzioni*CPImedio*TCK•Lostessoproblema,puòesserequindirisoltoconCPUTimediversiinbasea:•Nistruzioni(RISC,richiedonoingenerepiùistruzioni)•CPImedio(RISC,tipicamenteistruzionipiùveloci)•TCK(Retilogichesemplicipotenzialmentepiùveloci)",requisitidi pimediot pimedior
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#20,20,"Modalitàdi accessoallamemoria•OgniISAdisponediistruzioniperaccedereallamemoriainletturaescrittura•Normalmenteèpossibilestabilireladimensionedeldatochepuòesseretrasferito(BYTE,HALF-WORD,WORD,etc)•Idueprincipalimetodidiaccessoallamemoria(indirizzamento)sono:–Diretto(indirizzocablatonell’istruzione)–Indiretto(indirizzomodificabilearun-time)",modalitdi time
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#21,21,"Indirizzamentodiretto•Conquestamodalitàl’istruzionecontienealsuointernounvalore(cablato)chespecifical’indirizzodiaccessoallamemoriaLBR7,0800h-“LeggiunBYTE(8bit)all’indirizzo0800hememorizzalanelregistroR7”A0870800Ipotetica codifica dell’istruzione con 32 bit",leggiun ra ipotetica codifica dellistruzione bit
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#22,22,"Indirizzamentoindiretto•Conquestamodalitàl’indirizzodiaccessoallamemoriaèottenutosommandounvalorecostantepresentenell’istruzioneconilcontenutodiunregistro•Indirizzo=costante+registro•Ilregistroècablatonell’istruzionemailsuocontenutopuòcambiareatempodiesecuzioneLBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hememorizzalanelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit",leggiun ra ipotetica codifica dellistruzione bit
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#23,23,"Indirizzamentodirettovsindiretto1/2•Ladifferenzatraleduemodalitàdiindirizzamentoènotevole•Perrenderveneconto,poteteconsiderareuncasopiuttostocomune:“sommareglielementidiunarrayAdi8elementimemorizzatoapartiredall’indirizzo0800h”
00800h10801h20802h30803h40804h50805h60806h70807h
A[0]",
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#24,24,"Indirizzamentodirettovsindiretto2/2Diretto(non usato):XOR  R8,R8,R8; R8=0LBU R7,0800hADD R8,R8,R7 ; R8=R8+R7LBU R7,0801hADD R8,R8,R7 ; R8=R8+R7LBU R7,0802hADD R8,R8,R7 ; R8=R8+R7LBU R7,0803hADD R8,R8,R7 ; R8=R8+R7LBU R7,0804hADD R8,R8,R7 ; R8=R8+R7LBU R7,0805hADD R8,R8,R7 ; R8=R8+R7LBU R7,0806hADD R8,R8,R7 ; R8=R8+R7LBU R7,0807hADD R8,R8,R7 ; R8=R8+R7Indiretto:XOR  R8,R8,R8; R8=0ADDI R9,R8,8; R9=8LOOP: SUBI R9,R9,1; R9=R9-1LBU R7,0800h(R9); legge BYTE ; a 0800+R9ADD R8,R8,R7; R8=R8+R7BNEZ R9,LOOP; se R9!=0; salta a LOOP•Il registro R9 è utilizzato in ogniiterazione per cambiare l’indirizzobase (0800h)•Pensate se l’array fosse di 1000000elementi...",direttonon usatox rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr rrr indirettox rrr rhr legge rrr rrr salta pil registro utilizzato ogniiterazione cambiare lindirizzobase hpensate larray
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#25,25,"DLX: modalitàdi accessoallamemoria•IlDLXprevedeun’unicamodalitàdiindirizzamento:indiretto•L’indirizzo(a32bit)èsempreottenutosommandounregistroa32bitconunvaloreimmediatoa16bitestesoa32bitconsegno.•Esempio:LWR7,Imm16_bit(R8)•CaricainR7,lawordall’indirizzo(a32bit)ottenutosommandoR8ilvaloredell’immediatoestesoa32bitconsegno:R7ç32M[R8+Imm16_bit[15]16##Imm16_bit[15..0]]•Nell’eserciziodellepagineprecedentiabbiamosottointeso,persemplicità,chel’indirizzofossea16bit.Inrealtà,nelDLXl’indirizzoèsemprea32bit(lospaziodiindirizzamentoè4G)",modalitdi
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#26,26,"Come sonomemorizzatiidatiin memoriain un sistemacon parallelismo> 8? •Consideriamounsistemaconbusdatia16bit•Comepossiamomemorizzareilvalorea16bit0468hapartiredall’indirizzo(chesupponiamoa20bit)00010h?•Esistonodueconvenzioni:04680468046800010h00011h00010h00011h880000Fh00012h0000Fh00012h16HL
Little Endian(e.g., Intel)Big Endian(e.g., Motorola)",memoriain sistemacon parallelismo fhh fhh little endianeg intelbig endianeg motorola
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#27,27,"Istruzioni Aritmetico Logiche (ALU)•Istruzioni a 3 operandi:–2 operandi “sorgente”–1 operando “destinazione”. •“destinazione”: sempre un registro (a 32 bit)•“sorgente”: registro, registro •“sorgente”: operando immediato(16 bit)Esempi: ADD R1,R2,R3; R1 çR2 + R3 formato RADDIR1,R2,3; R1 çR2 + 3 formato I; il valore (3) dell’immediato a 16 bit ; è esteso a 32 bit ",istruzioni aritmetico logiche luistruzioni operandi operandi sorgente operando destinazione sempre registro registro registro sorgente operando immediato bitesempi rrr formato formato valore dellimmediato bit esteso bit
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#28,28,"Istruzioni di Set ConditionQuesteistruzioniconfrontanoidueoperandisorgenteemettonoa“1”oppurea“0”l’operandodestinazioneinfunzionedelrisultatodelconfronto•“SET EQUAL” (SEQ, =) : settase uguale•“SET NOT EQUAL” (SNE, !=): settase diverso•“SET LESSER THAN” (SLT, <) : settase <•. . . Gli operandi possono anche essere unsigned:•“SET LESSER THAN UNSIGNED” (SLTU, <)Esempi SLT R1,R2,R3; R1 ç1 se R2<R3 altrimenti R1 ç0; formato RSLTIR1,R2,3; R1 ç1 se R2<3 altrimenti R1 ç0; formato I",istruzioni set condition al settase uguales al settase diversos settase operandi possono essere unsigneds esempi rrr altrimenti formato altrimenti formato
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#29,29,"Istruzioni per il trasferimento dati •Sonoistruzionicheaccedonoallamemoria(loadestore):LB,LBU,SB,LH,LHU,SH,LW,SW•L’indirizzodell’operandoinmemoriaèlasommadelcontenutodiunregistroa32bitconun“offset”di16bit(Imm16bit)estesoconsegnoa32bit•L’istruzioneècodificatasecondoilformatoIEsempi:LWR1,40(R3);R1←32M[40+R3]LBR1,40(R3);R1←32(M[40+R3]7)24##M[40+R3]LBUR1,40(R3);R1←32(0)24##M[40+R3]",istruzioni trasferimento dati bus hus iesempil mrl
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#3,3,"Istruzionie risorseinterne a unaCPULeistruzionieseguibilidaunaCPU,codificateinbinario,sonoingeneremoltopiùsemplicidelleistruzionicheutilizzateneilinguaggiadaltolivello.Tipicheoperazionisono:-somme,sottrazioni,divisioni,moltiplicazioni,etc-lettureescrittureinmemoriaeperiferiche-confrontotraoperandi(“A>B?”)-salticondizionati(“saltase”)eincondizionati(“salta”)-...E’possibile,medianteleistruzioni,accederearisorseinternedellaCPUcomeregistriarchitetturalietalvoltaaregistridistato(e.g.,AeramaggiorediB?)LerisorsechesonoaccessibilialleistruzioniinlinguaggiomacchinasonodefinitedaiprogettistidallaCPUTuttavia,nontuttiiregistriinternisonoaccessibilialprogrammatore(senzachequestorappresentiunproblema)",istruzionie risorseinterne
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#30,30,"Istruzioni per il trasferimento del controllo:salti incondizionati (con e senza ritorno)•“JUMP”: salto incondizionato•“JUMP AND LINK: salto incondizionato con ritornoEsempiJoffset; PC = PC + 4 + (offset[25])6## offset, tipo JJR R3; PC = R3, tipo RJAL offset; R31 = PC+4; PC = PC + 4 + (offset[25])6## offset, tipo JJALR R5; R31 = PC + 4, PC = R5JR R31; PC = R31; istruzione per tornare da una procedura ",istruzioni trasferimento controllosalti incondizionati con senza ritornoj salto salto incondizionato ritorno esempi joffset offset offset tipo tipo offset offset offset tipo istruzione tornare procedura
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#31,31,"BCONDRd,Imm16E’ possiibleverificare solo due condizioni (COND):•BEQZ“BEQUAL ZERO”: salta se registro è 0•BNEQZ“BRANCH NOT EQUAL ZERO”: salta se registro è ≠ 0EsempiBEQZR4,Imm16; se R4==0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4BNEZR4,Imm16; se R4!=0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4Conunaistruzioneditiposetseguitadaun’istruzionedibranchsirealizzalafunzionedicompareandbranch(confrontoesaltocondizionatodalrisultatodelconfronto)senzabisognodiflagdedicatiIstruzioni per il trasferimento del controllo: salti condizionati (Branch)",rdimm solo due condizioni db zb salta registro qzb salta registro esempi rimm imm imm altrimenti rimm imm imm altrimenti istruzioni trasferimento controllo salti condizionati branch
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#32,32,"Come generare valori a 32 bitNelDLXèpresenteunaistruzione,LHI(“LoadHighImmediate”)checonsentedicrearerapidamentevaloria32bit(NONèunaistruzionediaccessoallamemoria!).LHI Rd,Imm16; Rd= Imm16 ## 0000h  InserisceinRdilvaloredell’immediatonei16bitpiùsignificativie0neirimanentibitTipicamente,LHIèutilizzatapergenerareindirizzia32bitpartendodaimmediatia16bit.QualipotrebberoesseredellealternativeallaLHI?Esempio LHI R1,8420; R1 = 8420 ## 0000h = 84200000h",generare valori bit hiload high rdimm imm inseriscein tipicamentel iesempio
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#33,33,"Esempio di codice assemblerDLX 1QualevaloreassumonoiregistriR3edR4alterminedell’esecuzionedelcodiceseguente?LHIR1,0xE000ADDUIR2,R0,0x0081SB0x0000(R1),R2LBUR3,0x0000(R1)LBR4,0x0000(R1)R3=?,R4=?",esempio codice assembler red irrx sbxrr urxrl
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#34,34,"EsercizioScrivereilcodiceDLXchesommaduewordmemorizzateapartiredallametàdellospaziodiindirizzamento(80000000h).LHIR4,8000h;R4=8000##0000hLWR5,0(R4);R5<-M[R4+0]LWR6,4(R4);R6<-M[R4+4]ADDR7,R5,R6;R7=R5+R6",esercizio rrr mrl wrrr mra
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#35,35,"EsercizioProgettareunsistemabasatosulprocessoreDLXcon512MBdiEPROMnellapartebassadellospaziodiindirizzamento,1GBdiRAMapartiredall’indirizzo0x40000000e512MBdiRAMnellapartefinaledellospaziodiindirizzamento.Nelsistema,medianteopportuneistruzionisoftware,ènecessariopoter:-impostareallivellologico0o1unsegnaledenominatoSTARTUP,mappatoa0xC0000000einizialmentealvalore1-invertirelostatodiunLED,inizialmentespentoemappatoall’indirizzo0x90000000,prevedendoanchelapossibilitàdipoterneleggerelostato(ie,determinareseilLEDèaccesoospento)EPROM512 MBRAM 1 GBRAM512 MB
0xC00000000x90000000
0x1FFFFFFF
0x40000000
0x7FFFFFFFSTARTUPLED
0xE0000000",esercizio xcon mbdi gbdi mbdi pmappatoax
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#36,36,"Struttura di una soluzioneRispostaaeventualidomandespecificheindicateneltestoIndicazionedeidispositiviedellememorieutilizzaticonrelativiindirizzidimappingreali(inizioefineinesadecimale)Scritturadeichip-selectdiciascundispositivocondecodificasemplificataProgettodieventualiretilogichenecessarieperrisolvereilproblema
ScritturadelcodiceinassemblerDLX,necessarioarisolvereilproblemaIndicazionedicomesonoconnessituttiidispostivi(inclusetuttelememorie)presentinellasouzioneaibusdisistemadelDLXCognomeNomeMatricolaDataTipoesame(CalcolatoriToLA)",struttura soluzione xcognome nome matricola data
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#37,37,Soluzione -chip selectCS_EPROM_512_3=CS_EPROM_512_2=CS_EPROM_512_1=CS_EPROM_512_0=CS_RAM_1_GB_L_3=CS_RAM_1_GB_L_2=CS_RAM_1_GB_L_1=CS_RAM_1_GB_L_0=CS_RAM_1_GB_H_3=CS_RAM_1_GB_H_2=CS_RAM_1_GB_H_1=CS_RAM_1_GB_H_0=CS_READ_LED=(0x90000000)CS_SWITCH_LED=(0x90000004)CS_READ_STARTUP=(0xC0000000)CS_WRITE_STARTUP=(0xC0000004)CS_RAM_512_3=CS_RAM_512_2=CS_RAM_512_1=CS_RAM_512_0=,soluzione chip select dxc dxc
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#38,38,Soluzione –rete segnale STARTUPAll’avviodelsistemaSTARTUP=1,soluzione rete segnale
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#39,39,Soluzione –rete segnale LEDAll’avviodelsistemaLED=0,soluzione rete segnale
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#4,4,"Registridi unaCPU•OgniCPUpossiedeuncertonumerodiregistriaccessibilialprogrammatore•Ilnumeroeladimensionedeiregistridipendonodall’ISA(equestohaimpattosullaretelogicarisultante)•Ovviamente,averemoltiregistrigeneralpurpose(GP)èvantaggioso(menoaccessiallalentamemoria)•Avereistruzionichepossonousaretutti,oquasi,iregistriGPsenzavincolièvantaggioso•LostessoISApuòessererealizzatoconretilogichecompletamentedifferenti(e.g.,InteleAMD)•Questeretihannoingenereprestazionidiverse(diversoCPUTimesebbeneabbianostessoNistruzioni)•NonsarebbestatomeglioavereunsoloISA?",registridi uogni
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#40,40,"Soluzione –connessione memorie
_3_2_1_0BA[  ..  ]MEMWRMEMRDCS_CS_CS_CS_
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[  ..  ]RD WR CSRD WR CSRD WR CSRD WR CS",soluzione connessione memorie
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#41,41,"Soluzione –codice assemblerDLX 1/2 LetturasegnaleSTARTUP
ImpostazionesegnaleSTARTUPalvalorelogico0",soluzione codice assembler letturasegnale
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#42,42,"Soluzione –codice assemblerDLX 2/2 LetturasegnaleLED
InversionevaloredelsegnaleLED",soluzione codice assembler letturasegnale
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#43,43,"Simulatore DLXNell’ambitodialcunetestidilaureaèstatosviluppatounsimulatorediistruzioniDLXperscopididatticidisponibileaquestoindirizzo:http://dlx-simulator.disi.unibo.it/dlxAncorainfasedisperimentazionemapotrebbeessereunavalidaalternativaalsoftwareindicatonellepagineseguenti.Perchifosseinteressato,sebbenesiaancorainformamoltopreliminare,èpossibilesimulareancheistruzioniRISC-VSonograditesegnalazionidibachiesuggerimentipermigliorareisimulatoriinprossimetesiTesidilaureasvolteinquestocontesto:FedericoPomponii,“SviluppodiunsimulatoreDLXperscopididattici”,AA2019/20FabrizioMaccagnani,“ProgettodiunsimulatorediDLXperscopididattici”,AA2018/19AlessandroFoglia,“ProgettodiunsimulatorediRISC-Vperscopididattici”,AA2018/19",simulatore fabrizio alessandro
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#44,44,"AlcunenotesulsimulatoreDLXattuale-Negliimmediatinecessarioilprefisso0X(eg,0x8000)-Nellestoreladestinazioneasinistra(eg,SW0x800(R0),R18)-Altro?Esempio:sommaelementidiunarrayinit:XORR8,R8,R8;R8=0ADDIR9,R8,0x0008;R9=8LOOP:SUBIR9,R9,0x0001;R9=R9-1LBUR7,0x0800(R9);leggeunBYTEa00000800+R9ADDUR8,R8,R7;R8=R8+R7BNEZR9,LOOP;seR9!=0saltaaLOOP
",xattuale xegx wxrr rrrr ops tear pse rsaltaa
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#45,45,,
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#46,46,"Esempio di codice assemblerDLX 2E’correttoilcodiceseguente?LHIR1,0x0000ADDIR2,R0,0x0081SH0x7FF1(R1),R2LHUR3,0x7FF1(R1)LHR4,0x7FF1(R1)",esempio codice assembler rrx shx ffrr urx ffrl hrx ffr
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#47,47,"Esempio di codice assemblerDLX 3ScrivereilcodiceassemblerDLXperinserireinmemoria,apartiredall’indirizzoE0000800hl’arraydiwordindicatoinfigura.
01234567
0xE00008000xE00008040xE00008080xE000080C0xE00008100xE00008140xE00008180xE000081C0xE0000820
32",esempio codice assembler
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#48,48,"ADDR2,R0,R0;R2usatocomeindicedelcicloLHIR3,0xE000;R3=E0000000Loop:SWR2,0800(R3);scriveindiceinmemoriaADDIR2,R2,1;incrementaindicedelciclodi1ADDIR3,R3,4;incrementaindiceoffestdi4SNEIR4,R2,8;confrontaindiceR2con8BNEZR4,Loop;saltaseR4nonèzeroi)QualevaloreènecessariosostituireaLoopinBNEZ?i)Sipuòfaremeglio(ie,usaremenoistruzioni)?",irx loops rcon rloopsaltase loopin
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#49,49,"76543210
0x000008000x000008040x000008080x0000080C0x000008100x000008140x000008180x0000081C0x00000820
32Esempio di codice assemblerDLX 4Scrivereilcodiceassemblerperilcalcolodellasommadeiprimi8elementidiunvettorediWORDmemorizzatoapartiredall’indirizzo00000800h.Ilrisultatodell’elaborazionedeveesserememorizzatoall’indirizzoE0000200h.Σ
",esempio codice assembler eh
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#5,5,"IA: Intel X86 (CISC)
IA: ARM (RISC)
ATMEL (RISC 8 bit)ArduinoUnoDesktopSmartphonee Tablet",intel bitarduino desktop smartphonee tablet
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#50,50,"ADDR1,R0,R0;azzeraR1,accumulatoreADDIR2,R0,20h;R2=3210Loop:SUBIR2,R2,4h;R2=R2-410LWR3,0800(R2);leggewordinmemoriaADDR1,R1,R3;aggiornaaccumulatoreR1BNEZR2,Loop;saltaseR2nonèzeroLHIR7,0xE000;R7=E0000000SWR1,0200h(R7);memorizzaaccumulatoreinE0000200h",rrrazzera raccumulatore loops irrhrr rloopsaltase rnonzero irx
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#51,51,Esercizio,esercizio
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#6,6,"RISC-V (1/2)•IlprogettoRISC-Vmiraproprioaquesto:creareunISAunicoeopensource•Ovviamentel’obiettivononèquellodiuniformareleretilogichecheimplementanol’ISA•L’ISAbasedelprogettoRISC-VèmoltosimileaquelladelDLXchestudieremoeprogetteremoinquestocorso•Esistonospecificheperestenderel’ISAbasealfinedicontemplareparticolarifunzionalità(floating-point,SingleInstructionMutipleData(SIMD),32/64/128bit,etc)
https://riscv.org/
RISC-V: The Free and Open RISC Instruction Set Architecture",sali pointsingle instruction mutiple datas free open instruction set architecture
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#7,7,"RISC-V (2/2)
https://www.slideshare.net/KrsteAsanovic/riscv-20160507patterson
",asanovicriscv
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#8,8,"Codificabinariadelleistruzioni•LeistruzioniperessereeseguitedallaretelogicaCPUdebbonoesserecodificateinbinariosecondounformatonotoedocumentatodalproduttore(datasheet)•Lacodificabinariadeveconteneretutteleinformazioninecessarieall’UnitàdiControlloperpotereseguirel’istruzione•EsistonoCPUconcodificadelleistruzionialunghezza:-costante(e.g.,32bitcasoRISCDLXemoltialtri)-variabiledaistruzioneaistruzione(IntelX86)Esempio:LBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hetrasferiscinelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit. I bit non utilizzati per codificare R3, R7e 0800rappresentano il codice operativo (op code) ",xemoltialtri xesempiol brr leggiun ra ipotetica codifica dellistruzione bit bit utilizzati codificare codice operativo code
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#9,9,"Linguaggioassembler•Lacodificadelleistruzioniinlinguaggiomacchinaèpocointuitivapergliesseriumani•Nellinguaggio*assemblersicodificanoleinformazioniinunmodo(unpo’)piùintuitivoMacchina->Assembler014FA27Dh->ADDR1,R2,R3;R1=R2+R3Escludendolacaratteristicaappenaevidenziata,unaltrosignificativovantaggioèquellodipoterdefiniredellelabelutili(spesso)neisaltiLOOP:SUBR1,R1,R3......BNEZ(R1),LOOP;saltaaLOOPseR1!=0",macchina assembler ops rrrb zrl psaltaa opse
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#0,0,"04 InterruzioniCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",interruzioni calcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#1,1,"•Inunsistemaamicroprocessoreèdifondamentaleimportanzapotergestireeventichesiverificanoall’esterno(manonsolo)dellaCPU•Peresempio,determinareseèstatopremutountastosullatastiera,seilmouseèstatospostato,etc•Unastrategia,pocoefficiente,perraggiungerequestoscopoconsistenelcontrollareperiodicamentesetalieventisisonoverificati(polling)•Questopuòesserefattointerrogandodicontinuolaperifericachesidesideragestire•Ovviamente,conquestastrategia,laCPUspendemolticiclimacchinaperlaverifica(oleverifiche)•Unastrategiamoltopiùefficiente,basatasuunastrategia“push”,consistenell’usodiinterruptGestioneeventicon unaCPU: polling",polling
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#10,10,"Interruzionimultiple e priorità
•Inunsistemanelqualeèpresentepiùdiunasorgentediinterruzioneèfondamentalepoterassociareunlivellodiprioritàaciascunainterruzione•Sarebbeauspicabilepoterinterromperel’interrupthandlerinesecuzionesegiungeunarichiestadiinterruzionepiùprioritaria(annidamento)•Esempio:
PROBLEMA_SISTEMA_FRENIPROBLEMA_SISTEMA_AUDIOINT?
",priorit
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#11,11,"•AssumeremocheilDLXsiasensibileallivellodelsegnalediinterruptINTenonalsuofronte•L’indirizzodiritorno(PC+4)èsalvatoinIAR•Inseguitoall’arrivodiuninterrupt,l’istruzioneincorsoècompletataedèeseguitoilcodiceall’indirizzo00000000h•Ilritornodall’interrupthandler(PCçIAR)avvienemediantel’istruzioneRFE(ReturnFromException)•Ingenere,manonnelDLXbase,gliinterruptpossonoessereabilitatiodisabilitatimedianteistruzioni•Nell’ISADLX,ègestitounsoloindirizzodiritorno.Pertanto,ilDLXdisabilitaleinterruzionimentreeseguel’handlereleriabilitaautomaticamenteritornandodall’handler(RFE).Incasocontrario,nelDLX,servirebbeunostacksoftwareInterrupt nelDLX",csalvatoin ereturn interrupt
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#12,12,"•Conannidamento(nesting)delleinterruzionisiintendelapossibilitàdipoteravviareuninterrupthandlerdurantel’esecuzionediunaltrohandler•QuestacaratteristicaèstandardnellamaggiorpartedelleCPUincommerciomanonèprevistadalDLXbase•Perpoterannidaregliinterruptsarebbenecessariounostacksoftware(utilizzandol’istruzioneMOVS2I)eaverelapossibilitàdiri-abilitaregliinterruptnell’handlermedianteopportuneistruzioni(ENI)nonprevistadall’ISAbase•Incasomultiplesorgentidiinterruzione,nasceilproblemadicomeassociareunascaladiprioritàalleinterruzioni•Atalfineesistonovariepolitiche:prioritàfissa,variabile,etc.Ovviamentelaprioritàècrucialenonsoloquandoèpossibileannidaregliinterrupt",
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#13,13,"•Lerichiestediinterruptpossonoverificarsiinqualsiasimomento•E’perònecessariomantenerelaconsistenzadeidatiinmodocheilcodiceinesecuzionenonsiamodificatodall’arrivoomenodiinterruptediconseguenzadall’esecuzioneomenodegliinterrupthandler•Perquestaragioneènecessariofareinmodochel’interrupthandler(i.e.,ildriverdeldispositivo)noninterferiscaconilcodicedelprogramma(main)inesecuzione•Comefare?Salvandoeripristinandoiregistrimodificatidall’interrupthandlerall’internodellostessocodice(handler)•Nellapaginaseguenteèmostratol’effettodiunpessimointerrupthandlerchenonpreservairegistriInterrupt handler e consistenzadeidati",interrupt handler
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#14,14,"1
+
2
=
33
a)b)c)
d)e)
1+2=33??Chi ha scrittoildriver/handler del nuovodispositivo, avràsalvatoe ripristinatolo statodeiregistri?Temodi no…",abc chi avrsalvatoe ripristinatolo no
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#15,15,"Nelcasodiunasingolasorgentediinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;codicedirispostaallarichiesta;diinterruzione;istruzionidiripristinodeiregistri;modificatiinprecedenzaXXXXXXXXhRFE;ritornodall’interrupt(PCçIAR)Interrupt handlercon singolainterruzione",xxh rinterrupt handlercon
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#16,16,"Nelcasodimultiplesorgentidiinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;Identificazionedell’interruptpiù;prioritariotraquelliasseriti;ripristinaregistriesaltaalcodice;dell’interruptpiùprioritario;salvaregistrimodificatiinseguito;codicehandler_1XXXXXXXXh;ripristinaregistrieritorno(RFE);salvaregistrimodificatiinseguito;codicehandler_2YYYYYYYYh;ripristinaregistrieritorno(RFE)Interrupt handlercon multiple interruzione
RFERFEPreambolo",feinterrupt handlercon multiple interruzione epreambolo
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#17,17,"•Conlastrategiamostratanellapaginaprecedenteèilsoftware,interrogandoognisingolaperiferica,adoverdeterminarequalèl’interruptpiùprioritario•Atalfinesaràanchenecessariaunaopportunainfrastrutturahardware(itri-stateserviranno?)•Tuttavia,èpossibilevelocizzareesemplificareleretilogichedisupportoaquestocompitomediantel’utilizzodiundispositivoadhoc(PIC)•IlPICsioccupadigestiremultiplesorgentidiinterruzioneediforniredirettamenteallaCPU(surichiesta)qualèilcodice/indirizzodell’interruptpiùprioritariotraquelliasseritiinquelmomento•Tipicamente,inunPICèpossibiledisabilitarelesingolesorgentidiinterruzioneestabilireillivellodiprioritàdiciascunainaccordoavariepolitiche(prioritàfissa,variabile,etc)Programmable Interrupt Controller (PIC)",icil interrupt controller
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#18,18,PICCSA[K-1..0]RDWRD[7..0]KBA[?..?]CS_PIC8BD[7..0]RDWRINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTINTINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0•LastrutturadiunipoteticoPICpotrebbeesserequellamostratainseguito•LevariesorgentidiinterruzioneINT[7..0]sonoinviatealPICchesioccupadiinviarelarichiestasull’unicopinINTdelDLX•Piùavantineprogetteremounomoltosempliceconfunzionalitàdibase(abilita/disabilitaINT_i),rdk bac bdr tdel
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#19,19,"INTPICCSA[K-1..0]RDWRD[7..0]INT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTCPU•IlPICinviailsegnalediINTefornisceallaCPU,surichiesta,ilcodicedell’interruptconprioritàpiùelevatatraquelliasseritiinquelmomento•PerchénelPICèpresenteancheilsegnaleWR?Perché dei timer?Come può essere realizzato un timer?
Cosa comunicano alla CPU le reti?",sak rdi puil teforniscealla wrperch timercome pu essere realizzato timer cosa comunicano reti
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#2,2,"main(){bool tasto_premuto=false;while(1){if (tasto_premuto==true)gestisci_evento();. . .}}void gestisci_evento(){. . .return;}Premuto?Premuto?Premuto?Premuto?
LaCPUspendemoltotemponelcontrollare(polling)sel’eventosièverificato.Questastrategiarallental’esecuzionedelmainPocoefficiente….",mainbool void
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#20,20,"(i)(ii)INT
ΔxΔyΔwheelpressed_Lpressed_R•Inrealtàleinformazionisonoconvogliatesuuncanaleseriale(USB,PS/2)perridurreilnumerodiconnessioni/fili•Tuttavia,possiamopensareperlenostrefinalitàchel’interfacciamouse/CPUespongaisegnalidiunaportadiI/Ostandard(CS,RD,WR,D[7..0],indirizzi)
Inrealtàgliinterruptsonoemessiperiodicamente(e.g.,100Hz)esolosenecessario(uneventonelmouse)
",iiii lpressed sbp iostandardc
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#21,21,,
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#22,22,"•InunaCPU(manonnelDLX)puòesserepresenteunulterioresegnale(ininput)denominatoNMI(NotMaskableInterrupt)•Atalesegnalesonocollegateunnumerolimitatodisorgentidiinterruzioniparticolarmentecritiche•Peresempio,l’outputdiunaretecherilevaesegnalaunaimminenteperditadialimentazioneelettrica•UnarichiestadiinterruptinviatasulpinNMInonpuòessereignorata(eventualiistruzionichedisabilitanogliinterruptnonagisconoperquestosegnale)einterrompel’esecuzionedialtrihandler•L’handlerassociatoalpinNMIèaprioritàmassimaedeveessereseguitonelminortempopossibileInterrupt non mascherabili(segnaleNMI)",inuna umanonnel inot maskable interrupt
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#23,23,"•IlsegnaleNMIvausatoconcautelaesolopersegnalazionicriticheallaCPU•NelcasodelDLXutilizzeremosoloINT•Sefossedisponibile,perlagestionedelsegnaleNMIsarebbenecessarioinserireleistruzioninellaprimapartedel“preambolo”all’indirizzo00000000h,primadigestiregliinterruptchesonoinviatiattraversoINT",ilsegnale unelcasodel
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#24,24,"ProgettareunsistemabasatosulprocessoreDLX,conun1GBdiEPROMaindirizzibassie512MBdiRAMaindirizzialti.Intalesistema,utilizzandounpulsante,deveesserepossibileaccendere/spegnereunledmedianteinterrupt.All’avvioilleddeveessereacceso.Sifaccial’ipotesicheR29eR30possanoessereusatisenzalanecessitàdiessereripristinati.Esercizio",xconun gbdi mbdi
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#25,25,"Alcune considerazioni sul reset asincrono
FFDDQQ*A_SETA_RESRESETClockRESET_SYNCTuttavia,presentadeiproblemi:•E’semprenecessariounsegnalediclock•QuandoRESETvaa1,RESET_SYNCsiasserisce(ie,diventaattivo)alprimofrontediclockL’applicazionediunsegnaleasincronodireset,puòportareaproblemidimetastabilitànelmomentoincuitalesegnalevienepostoalvalore0(ie,quandosiescedalreset,assumendochetalesegnalesiaattivoalto).Leproblematichesonoanalogheaquelleevidenziateduranteilcampionamentodiunsegnalechenonrispettaitempidisetupehold.Unapossibilesoluzioneèlaseguente:",alcune considerazioni reset asincrono clock tvaar
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#26,26,"FFDDQQ*A_SETA_RES0ClockRESET_SYNCRESETUnasoluzionecheeliminaidueproblemiprecedenti,echegarantisceun’uscitasincronadalreset,èlaseguente:
ClockRESETRESET_SYNCAttivazionenonsincronadelresetUscitasincronadalreset",clock clock
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#3,3,"•UninterruptèuneventocheinterrompelaCPUduranteilregolareflussodiesecuzionedelcodice•L’interruptsegnalachesièverificatouneventochemeritaimmediata*attenzionedapartedellaCPU•SelaCPUèabilitata*ariceveretalesegnalazione,esegueautomaticamenteunaporzionedicodicedenominatainterrupthandleralfinedigestirel’evento•Glieventipossonoessererelativiafattoriesterni(e.g.,premutountasto)ointerni(e.g.,èstataeseguitaunadivisioneperzero,overflow,etc)•Quandodipendonodafattoriinternisiparladieccezioni(exceptions)•Inoltre,èpossibileinvocarel’handlermedianteopportuneistruzioni(e.g.,perinvocaresystemcall)Gestioneeventicon CPU: interrupt",usela interrupt
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#4,4,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
Inogniprocessore,èpresentealmenounsegnaledenominatoINTpergestireleinterruzioni.Inmolticasi,manonnelDLX,èpresenteancheunulterioresegnaledenominatoNMIpergestireinterruzionichenonpossonoessereignorate.Gestione interruzioni nel DLX30
32NMI(NA nelDLX)NMI",bdm bab bdr interruzioni
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#5,5,"•Nelcasodiinterruptgeneratodall’esternolasituazioneèquesta:
•Lapressionedeltastoinnesca*l’esecuzionedelcodicedell’interrupthandler(2)(1)(2); Interrupt hander. . . . . . . . . .. . . . .RFEINT
LaCPUnormalmentesvolgeoperazioniutiliedèavvisatasoloquandosiverifical’evento(inquestocaso,lapressionedeltasto)",interrupt hander
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#6,6,"•Nelcasodiinterruptgeneratodall’esternolasituazione,dalpuntodivistasoftware,èquesta:main(){Istruzione1;Istruzione2;Istruzione3;Istruzione4;Istruzione5;Istruzione6;Istruzione7;Istruzione8;}
(i); Interrupt handler ADD R1,R0,R0. . . . . . . . . .RFE(ii)(iii)•L’interruptpuòverificarsiinqualsiasimomento(i.e.,durantel’esecuzionediqualsiasiistruzione)enonèsincronizzatoconilclock•Assumeremosempreche,l’esecuzionedell’istruzionedurantelaqualesiverifical’interruptsiasempreportataatermineprimadieseguirel’handler
L’is tr uzio n e4èportataatermineprimadieseguirel’interrupthandler",interrupt handler rrr lis uzio
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#7,7,"•EsistonoCPUsensibiliallivellodelsegnalediinterrupt,altrealfrontedisalitaealtreaentrambelecose•NelcasodelDLXassumeremochelaCPUsiasensibileallivellodelsegnale(1sel’interruptèattivoe0incasocontrario)•Nelcasodeidispositivichegeneranointerrupt,assumeremocheessorimangaa1fintantochélacausachelohageneratononsiastatagestitadallaCPU•Pertanto,seunaperifericahauninterruptalivelloasserito,rimanetalefintantochél’interruptnonègestitodallaCPU(nonnecessariamentesubito*)•Inalcunicasi,nell’handlerpuòesserenecessarioeseguiredelleoperazionisoftwareperpoterportareallivellologico0ilsegnalediinterruptprovenientedall’esternodopoavergestitol’eventoSegnaledi interrupt: fronteo livello",esistono segnaledi interrupt fronteo livello
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#8,8,"FFDDQ1A_RESINT_FRONTEINT_LIVELLOCS_RESET_INT
•Comefareseildispositivochegeneral’interruptassumechelaCPUsiasensibileaifrontimentrelaCPUèsensibilesoloallivellodelsegnale?•E’necessarioeseguireunatrasformazionedafrontealivellodelsegnaleINT_FRONTE•Inuncasocomequesto,illivellologicodelsegnaleINT_LIVELLOdeveessereportatoazerodaunopportunocomandosoftware(CPU)cheasserisceilsegnaleCS_RESET_INTTrasformazioneda frontea livello",frontea livello
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#9,9,"•C’èperòunproblema:escludendoNMI(discussodopo)ilDLXhaunsolosegnalediinterruptdenominatoINT.Comefacciamoagestire,cometipicamenteaccade,multiplesorgentidiinterrupt?•Siconvogliano(e.g.,medianteunORoaltrefunzioniinbaseallespecificheesigenze)tuttigliinterruptversol’unicosegnaleINTpresentenelDLX•Rimaneunaltroproblema:comedeterminarequale/qualiinterruptsonoasseritiinundeterminatoistante?•Atalpropositoè(tipicamente)necessariopoterdeterminarelostatodellerichiestediinterruptmedianteopportuneistruzionisoftware•Vedremocheesistonoanchedellereti,denominatePIC,chepossonoagevolarequestocompitoallaCPUGestionedi interruzionimultiple",tpresentenel ugestionedi
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#0,0,"05 Periferiche di I/O con handshakeCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",periferiche handshake calcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#1,1,"Porte di Input/Output (I/O)•InprecedenzaabbiamovistocomeprogettaredellesempliciperiferichediI/O,perscambiaredatitraCPUemondoesternomedianteunbuffer•Tuttavia,nonvieranessunagaranziasulcorrettoesitodeitrasferimenti•Infatti,cosaaccadese,mentrelaCPUscrivenellaportainoutput,undispositivoesternoleggedallamedesimaporta?Inoltre,cosaaccadeselaCPUleggeundatocheinrealtànonèmaistatoscrittodaundispositivoesterno?Comepuòsaperlo?Perquesto,itrasferimentisonointrinsecamenteespostiaerrori•Inpiù,lagestionedeltrasferimentieratotalmenteacaricodellaCPU(chepotrebbefarealtro)•LeportediI/Ononeranoingradodigenerareinterruptcontutteleproblematichechenederivano",porte inputoutput
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#10,10,"WROBFINT_OACKHandshake (OUTPUT): formed’onda
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUTOUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK",handshake formedonda rdeve essere diretto processore porta sdo
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#11,11,"Unesempiodiunitàesternainoutputpotrebbeessererappresentatadaunastampantecheimprimesullacartaunacarattereallavolta.LaCPU,fornisce*idatiallastampanteattraversolaperifericadioutputquandoilsegnaleINT_Oèasserito(questoimplicacheOBFsia0)LastampanteleggeildatosoloquandoilsegnaleOBFèasserito(i.e.,quandolaportainoutputcomunicaallastampantecheunnuovodatoèstatoscrittodallaCPUnelbufferedèquindidisponibile)
OUTPUTINT_OACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK
Lastampantedevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake",sdo
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#12,12,"ProgettareunaretelogicabasatasuFFDingradodigestirelecomunicazioniconduedispositiviesterni–unoininputmappatoaCS+0eunoinoutputmappatoaCS+1–utilizzandoilprotocollodihandshakeEsercizio
ParallelI/OBD[7..0]RDINT_ICSA0WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFA_RESETRDINT_ICSBA2WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFRESET
BD[7..0]",esercizio parallel bdr ins ins
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#13,13,"ProgettodellinterfacciaL’interfacciaparallelaèdotatadidueporte,ciascunaingradoditraferiredatia8bit:•PortainINPUTmappataall’indirizzoCS+0•PortainOUTPUTmappataall’indirizzoCS+1Alfinedirisolvereilproblema,risultautilepensarelaportadiI/Ocomecompostadadueporteindipendenti:unaportaininputeunaportainoutputInoltre,nellasoluzionesidesideraevitareclockgatingIlpuntodipartenzasonoleformed’ondadelprotocollodihandhsake,mostratenellepagineprecedenti",csportain
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#14,14,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB",dhandshake ddeve essere diretto processore porta inr sdi
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#15,15,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUT01230INPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB",dhandshake ddeve essere diretto processore porta inr sdi
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#16,16,"STBIBFINT_IRDU0U1U2U300 0 010 0 011 0 011 1 011 1 101 1 100 1 100 0 100 0 010 0 011 0 011 1 011 1 1Handshake (INPUT): soluzionesenzaclock gating
013715141280137151otrasferimento2otrasferimento3otrasferimentoOsservando le forme donda, è possibile individuare unasoluzione senza clock gating
Due trasferimenti, un ciclo completo ",handshake gating osservando forme donda possibile individuare unasoluzione senza clock gating due trasferimenti ciclo completo
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#17,17,"IlsegnaleDEC(x)identificalaconfigurazionebinariaU3U2U1U0equivalenteaxinbase10.Pertanto,isegnaliIBFeINT_Irisultano:IBF=(DEC(1)+DEC(3)+DEC(7))+(DEC(14)+DEC(12)+DEC(8))INT_I=DEC(3)+DEC(12)Oppure,IBF=U0XORU3INT_I=U1XORU2CSèilchip-selectdellaperifericaininputFFDDQ0A_RESQ0*RESETSTBU0FFDDQ1A_RESQ1*RESETSTB*U1
FFDDQ3A_RESQ3*RESETRD*U3Q3*Q310CS·A0*FFDDQ2A_RESQ2*RESETRDU2Q2*Q210CS·A0*",ilsegnale irisultanoi bfd ecd ecd ecd ecd ecd eci ecd ecoppurei bfu csilchip sqr sqr sqr rdu csaf sqr csa
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#18,18,"373D[7..0]Q[7..0]OECCS·RD·A0*D_IN[7..0]BD[7..0]STBHandshake (INPUT): buffer di ingressocon 373 Ipotizzando di mappare la porta in INPUTall’indirizzoCS + 0e di voler utilizzare dei latch 373 come buffer.
Ovviamentesarebbepossibileunasoluzionedeltuttoequivalentecon374comemostratonellapaginasuccessiva",dqo csr dad inb handshake buffer ingressocon ipotizzando mappare porta utallindirizzo voler utilizzare latch buffer
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#19,19,374D[7..0]Q[7..0]OECS·RD·A0*D_IN[7..0]BD[7..0]STB*Handshake (INPUT): buffer di ingressocon 374 IpotizzandodimapparelaportainINPUTall’indirizzoCS+0edivolerutilizzaredeiFFD374comebuffer,dqo sr dad inb tbhandshake buffer ingressocon tallindirizzo dcomebuffer
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#2,2,"FFD(x8)D[7..0]Q[7..0]CS·RDDI[7..0]BD[7..0]WRITE*Unasempliceperifericaperleggeredatidall’esterno,senzautilizzareinterrupt,èlaseguente:CPU
EsternoTuttavia,conquestasoluzione,sorgonodeglievidentiproblemi:•ComepuòsaperelaCPUcheèdisponibileunnuovodatoscrittodall’esternonellaporta?•Comesipuòsaperedall’esternochelaCPUhalettoildatoscrittoinprecedenzanellaporta?
",sr esterno
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#20,20,Esercizio: progettodellaportain outputProgettarelaperifericapergestireitrasferimentiinOutputmediantehandshakeapartiredalleformedondamostratenelleslidesuccessive.OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK,esercizio output sdo
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#21,21,"WROBFINT_OACKHandshake (OUTPUT)
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUT01230OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK",handshake rdeve essere diretto processore porta sdo
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#22,22,"Registridi statoe programmazioneSarebbeutileaggiungereallaperifericachegestisceinputeoutputconprotocollodihandshakeiseguentiregistri:•Registrodistato(letturasegnalidistatopergestioneapolling)indirizzoA1A0=10•Registrodiprogrammazione(enable/disablesingolainterfaccia,etc)indirizzoA1A0=11Ovviamente,serveunulteriorebit(A1)perindirizzaregliulterioridueregistriEsercizioComesipotrebbemodificareilprogettodellaportadiI/Oconhandshakeperaggiungerequestenuovefunzionalità?",registridi statoe programmazione esercizio
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#23,23,"ProgettareunsistemabasatosulmicroprocessoreDLX,con1GBdiEPROMagliindirizzibassie2GBdiRAMagliindirizzialti.Nelsistemaèpresenteunaportaininput,giàprogettataedenominataINPUT_PORT,eunpulsantedenominatoP.Ilbyte(unsigned)lettodaINPUT_PORTdeveesserememorizzatoall’indirizzoFFFF0020hmentreilregistroR20deveessereincrementatodiuno,viasoftware,aognipressionediPeinizializzatoa0all’avviodelsistema.Inoltre,siassumache:1)IlpulsantePabbiaprioritàmaggiorediINPUT_PORT2)IlpulsantePnonpossaesserepremutoprimachesiaterminatalagestionediPdapartedell’interrupthandler.Atalfinesegnalare,conunLED,quandoilpulsantenondeveesserepremuto3)IregistridaR25aR30possonoessereutilizzatisenzalanecessitàdiessereripristinati4)IlregistroR20siamodificabilesolodall’handlerchegestisceilpulsanteEsercizio",xcon gbdi gbdi rtilpulsante esercizio
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#3,3,"Unesempiocheevidenziaquestiproblemiriguardaloscambiodibeni/datitraunproduttoreeunconsumatore
Seilproduttoreproduceuncaffècheèprelevatoprimadell’arrivodiunaltrotuttopotrebbeapparentementefunzionarecorrettamente(setupehold?)Tuttavia,comepuòsapereilproduttorecheilcaffèèstatoprelevato?Comepuòsapereilconsumatorecheèdisponibileunnuovocaffèpreparatodalproduttore?Perquesteragioni,sorgonoaltriproblemi...PC
",
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#4,4,"Unprimoproblemasiverificaseilconsumatoresmettediprelevarecaffèperchénonèpronto(e.g.,ilconsumatoreèaltelefono).Comepuòsaperloilproduttore?
PC
bla,bla,bla",blablabla
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#5,5,"Ilproblemadualesiverificaseilproduttoresmettediprepararecaffèperchéimpegnatoafarealtro(e.g.,parlarealtelefono).Comepuòsaperloilconsumatore?
bla,bla,bla
•IdueproblemievidenziatipossonoessererisoltiinmodomoltosemplicericorrendoaqualcheformadisincronizzazionetraledueentitàPeC•Perquestoscopol’handshakeèunapprocciosemplice,efficienteeampiamenteutilizzatoPC
",blablabla
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#6,6,"Segnali del protocollo handshake: INPUT
1.SeIBF=0,quandopossibile*UEpuòscrivereildatonelbufferdingressodellaporta2.UE,portandoSTBa1,scriveildatonellaportachecontemporaneamenteasserisceIBF(InputBufferFull)3.QuandoUEportaSTBazero(scritturaterminata),linterfacciaattivaINT_I(InterruptRequest)4.Quandopossibile*,laCPUandràaleggereildatoscrittonellaportadaUE.Altermine,IBFandràazero(mentreINT_Ivaa0,dall’iniziodellalettura)INPUTUnitàEsterna(UE)InputRDINT_IBD[7..0]D_IN[7..0]STBIBFCSRDINTRBD[7..0]CSD[7..0]STBIBF",segnali protocollo handshake eportando finput buffer fullquando ueporta iinterrupt uealterminei unit esternau einput ins sds
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#7,7,"STBIBFINT_IRDHandshake (INPUT): formed’ondaINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTCSRDINTRBD[7..0]CSD[7..0]IBFSTB",dhandshake formedonda inr ddeve essere diretto processore porta bdc sdi
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#8,8,"Unesempiodiunitàesternaininputpotrebbeessererappresentatadaunsensore(e.g.,ditemperatura)IlsensoreinviaidatiallaCPUattraversolaperifericadiinputquandounanuovamisuraèdisponibileeIBF=0.Alterminediogniscritturanellaportadapartedelsensoreditemperatura,ilsegnaleINT_IsiasserisceINPUTINT_ISTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB
Ilsensoredevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake",isiasserisce inr sdi
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#9,9,"Segnali del protocollo handshake: OUTPUTOUTPUTUnità Esterna(UE)Output1.IlsegnaleINT_OasseritocomunicaallaCPUchelaportapuòaccettareunnuovodato2.InrispostoallarichiestadiinterruptlaCPUscrive,quandopossibile*,ildatosulbufferdellaporta1.LinterfacciasegnalaaUEcheèdisponibileunnuovodatoattivandoOBF(OutputBufferFull)2.Quandopossibile*,UEleggeildatoscrittodallaCPUasserendoACK(acknowledge)WRINT_OBD[7..0]D_OUT[7..0]ACKOBFCSWRINTRBD[7..0]CSD[7..0]ACKOBF",segnali protocollo handshake tunit esternau foutput buffer uasserendo kacknowledgew sda
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#0,0,"06 ProgrammableInterrupt Controller (PIC)Calcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia",programmable interrupt controller iccalcolatori elettronici ingegneria informatica stefano mattoccia
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#1,1,"•Abbiamogiàvistocheèpossibile,opzionalmente,utilizzareundispositivoad-hocperlagestionedimultiplesorgentiinterruzionidenominatoPIC•IlPICvelocizzaefacilitalafasedianalisiegestionedegliinterrupt•TipicamenteunPICconsentedi:•Abilitaredisabilitaresingoleinterruzioni•Fornireinformazionisulleinterruzioniasserite•Gestirelaprioritàdelleinterruzioni•Perleragionievidenziate,unPICèprogrammabilemediantel’utilizzodiopportuniregistriinterni•Sebbenesiasemprepossibileunagestioneinteramentesoftwaredelleinterruzioni,l’utilizzodiunPICpuòessereunavalidaalternativa•Perquesteragioni,progettiamounPICmoltosempliceGestionedelleinterruzionicon PIC",cil cmoltosemplice
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#10,10,"EN_INT_0INT_0Diconseguenza,inogniistante,gliinterruptabilitatirisultanodalleuscitediquestarete:EN_INT_1INT_1EN_INT_2INT_2EN_INT_3INT_3RAW_ENABLED_INT_0RAW_ENABLED_INT_1RAW_ENABLED_INT_2RAW_ENABLED_INT_3Si ricorda che, come mostrato nello schema ai morsetti del PIC, risulta:INT_0= INT_OUT_PORT_0INT_1= INT_OUT_PORT_1INT_2= INT_IN_PORT_0INT_3= INT_IN_PORT_1Al pin di interrupt del DLX è pertanto inviato il segnale:INT_DLX= RAW_ENABLED_INT_0+RAW_ENABLED_INT_1+RAW_ENABLED_INT_2+RAW_ENABLED_INT_3",ricorda che mostrato schema morsetti risultai pin interrupt pertanto inviato segnalei
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#11,11,"Perevitareproblemidimetastabiitàèpossibilecampionarelostatodegliinterrupt,primadiprocedereallalorolettura,peresempioconquattroFFDchecampionanogliinterruptsulfrontedisalitadiMEMRD.RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_0SYNC_ENABLED_INT_0RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_1SYNC_ENABLED_INT_1RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_2SYNC_ENABLED_INT_2RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_3SYNC_ENABLED_INT_3",
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#12,12,"Alfinedileggerelostatodegliinterruptasseriti,traquellichesonostatiabilitati,siutilizzanodeibuffertri-statepilotatidalsegnaleCS_PIC_READ_INTscomesegue:CS_PIC_READ_INTsSYNC_ENABLED_INT_0CS_PIC_READ_INTsSYNC_ENABLED_INT_1CS_PIC_READ_INTsSYNC_ENABLED_INT_2CS_PIC_READ_INTsSYNC_ENABLED_INT_3CS_PIC_READ_INTs‘0000’ENABLED_INT[0]ENABLED_INT[1]ENABLED_INT[2]ENABLED_INT[3]ENABLED_INT[7..4]IsegnaliENABLED_INT[7..0]sonoconnessialbusdatiBD[7..0]44",tscomeseguec tse tisegnali
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#13,13,"Lareteseguente,consentedileggereaCS_PIC_READ_CODEilcodicea16bit(perragionimostratedopo)dell’interruptpiùprioritario(BD[15..0])
CS_PIC_READ_CODESYNC_ENABLED_INT_0·SYNC_ENABLED_INT_1*· SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3* CS_PIC_READ_CODESYNC_ENABLED_INT_1·SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_2·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_3CS_PIC_READ_CODE‘00000000’
CS_PIC_READ_CODE‘0000’INT_CODE[7..0]INT_CODE[8]INT_CODE[9]INT_CODE[10]INT_CODE[11]INT_CODE[15..12]NOTA: come richiesto dal testo del problema, si assegna il seguente ordine crescente di priorità:0) INT_0 (Minima) 1) INT_12) INT_23) INT_3 (Massima)4488",ts ts ts ts ts de dei dei dei dei dei dei den richiesto testo problema assegna seguente ordine crescente priorit minima massima
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#14,14,"Icodicidipriorità,a16bitpervelocizzarel’handler,associatiallequattrointerruzionielettiall’indirizzoCS_PIC_READ_CODE,risultano:0800hseèasseritoSYNC_ENABLED_INT_3(massimapriorità)0400hseèasseritoSYNC_ENABLED_INT_2enonSYNC_ENABLED_INT_30200h se è asseritoSYNC_ENABLED_INT_1e non SYNC_ENABLED_INT_2oSYNC_ENABLED_INT_30100h se è asserito SYNC_ENABLED_INT_0e nessun altro segnaleIl codice per abilitare le interruzioni dalle 4 porte risulta:LHI R25,8000h; R25 = 80000000hADDI R26,R0,000Fh; R26 = 0 + 0000000FSBR26,(R25)04h; scrive il byte 0Fh contenuto in R26; all’indirizzo CS_PIC_SET_INTs(80000004h)Il codice per leggere quali sono le interruzioni asserite:LHI R25,8000h; R25 = 80000000hLBUR26,(R25)08h; legge in R26 gli interrupt asseriti, tra quelli; abilitati, all’indirizzo CS_PIC_READ_INTs; (80000008h)",tenon asserito asserito nessun altro segnale codice abilitare interruzioni porte risultal brrh scrive byte contenuto allindirizzo tshil codice leggere quali interruzioni asseritel urrh legge interrupt asseriti quelli abilitati allindirizzo
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#15,15,"Il codice dell’interrupt handlerè il seguente:00000000: LHI R25,8000h; prepara indirizzo 80000000h00000004: LHU R26,(R25)0Ch; lettura del codice di priorità a 16 bit; all’indirizzo CS_PIC_READ_CODE00000008: LHIR27,FFFF; prepara in R27 l’indirizzo per : operazioni comuni successive al salto 0000000C: JRR26; salta all’indirizzo presente in R26; checorrisponde al codice di interrupt ; più prioritario letto mediante LHU00000100: LBU R28,(R27)10h; legge in memoria un byte a FFFF0010h00000104: SB R28,(R25)2h; scrive quanto letto in OUTPUT_PORT_000000108: RFE; (80000002h) e ritorna dall’interrupt00000200: LBU R28,(R27)20h; legge in memoria un byte a FFFF0020h00000204: SB R28,(R25)3h; scrive quanto letto in OUTPUT_PORT_100000208: RFE; (80000003h) e ritorna dall’interrupt00000400: LBU R28,(R25)0; legge da INPUT_PORT_0(80000000h)00000404: SB R28,(R27)40h; scrive byte in memoria a FFFF0040h  00000408: RFE; ritorna dall’interrupt00000800: LBU R28,(R25)1; legge da INPUT_PORT_1(80000001h)00000804: SB R28,(R27)80h; scrive byte in memoria a FFFF0080h  00000808: RFE; ritorna dall’interrupt",codice dellinterrupt handler prepara indirizzo lettura codice priorit bit allindirizzo prepara lindirizzo operazioni comuni successive salto salta allindirizzo presente checorrisponde codice interrupt prioritario letto mediante rrh legge memoria byte rrh scrive letto ritorna rrh legge memoria byte rrh scrive letto ritorna legge rrh scrive byte memoria ritorna legge rrh scrive byte memoria ritorna dallinterrupt
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#16,16,"RAM_3RAM_2RAM_1RAM_0BA[28..2]Interfacciamento RAMMEMWRMEMRDCS_RAM_0CS_RAM_1CS_RAM_2CS_RAM_3
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[26..0]RD WR CSRD WR CSRD WR CSRD WR CS",
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#17,17,"Interfacciamento EPROM
BD[7..0]BD[15..8]BD[23..16]BD[31..24]EPROM_3EPROM_2EPROM_1EPROM_0BA[29..2]MEMRDCS_EPROM_0CS_EPROM_1CS_EPROM_2CS_EPROM_3
A[27..0]RD  CSRD  CSRD  CSRD  CS",bam
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#2,2,"InunsistemabasatosulDLX,con1GBdiEPROMmappatanegliindirizzibassie512MBdiRAMmappatanegliindirizzialti,sonopresentiegiàprogettate2portea8bitinINPUT(IN_1eIN_0)e2portea8bitinOUTPUT(OUT_1eOUT_0)basatesulprotocollodihandshake.ProgettareunsemplicePICalfinediassegnareleseguentiprioritàstaticheallequattrointerruzioni:IN_1(massimapriorità),IN_0,OUT_1eOUT_0(minimapriorità).IlPICdovràinoltreconsentiredi:a)disabilitare/abilitareselettivamente,medianteparoledicontrollo,ciascunainterruzionegeneratadalle4perifericheb)fornireleinterruzioniasserite(traquelleabilitate)c)fornireuncodicecheindicaqualèl’interruzionepiùprioritaria(traquelleabilitate)inundeterminatoistanteUtilizzandolaretelogicaprogettatagestirelequattrointerruzioniinmodochedurantel’esecuzionedell’interrupthandlersiaeseguito,nelmodopiùrapidopossibile,soloiltrasferimentoattivopiùprioritarioinquelmomento.Eventualialtrerichiesteditrasferimentoattivesarannogestitedurantesuccessiveesecuzionidell’interrupthandler.IdatilettidalleporteinINPUTdovrannoesserescrittiaFFFF0080(IN_1)eFFFF0040(IN_0)mentreidatidascriverenelleporteinOUTPUTdovrannoesserelettidaFFFF0020(OUT_1)eFFFF0010(OUT_0).All’avviodelsistemailPICdovràautomaticamentedisabilitaretuttelerichiestediinterruzioneprovenientidallequattroporte.-ScrivereilcodicecheabilitatutteleinterruzioninelPICeilcodicecheconsentedileggerelostatodegliinterrupt-Scrivereilcodiceottimizzatodell’interrupthandler(iregistridaR25aR29possonoessereutilizzatisenzalanecessitàdidoverliripristinare).Progettodi un semplicePIC",xcon gbdi mbdi uto ute ute ffi ffi ffo ute ffo semplice
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#3,3,"PICProgrammableInterruptControllerA_RESETINT_0 (-)INT_1INT_2INT_3 (+)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_INTs_CODED[3..0]INT_TO_DLXENABLED_INT[7..0]INT_CODE[15..0]4816BD[7..0]BD[15..0]BD[3..0]INT(to DLX)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_CODEINT_OUT_PORT_0INT_OUT_PORT_1INT_IN_PORT_0INT_IN_PORT_1RESETIlPIC(ProgrammableInterruptController),ingradodigestire4interruzioni,puòessereschematizzatonelmodoseguente:
RDWRMEMRDMEMWR",programmable interrupt controller bdb ntto lxc til cprogrammable interrupt
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#4,4,"NelPIC,lamassimaprioritàèassegnataaINT_3,quellaminimaaINT_0.Leprioritàsonostatiche,comeprevistodaltesto.IsegnalidiingressodelPICINT_3,INT_2,INT_1eINT_0sonoconnessiai4interruptdelleperifericheinmododasoddisfareivincolisullaprioritàprevistidaltestodelproblema.ScrivendoaCS_PIC_SET_INTs,idatipresentisuipinD[3..0]consentonodiabilitare/disabilitareisingoliinterrupt.Gliinterruptasseritidalleperiferiche,traquelliabilitati,possonoessereletti,aCS_PIC_READ_INTs,attraversoisegnaliENABLED_INT[7..0].Essendoprevistisolo4interrupt,4degli8bitsonocablatia0(i4bitpiùsignificativi).Ilcodicechecorrispondeall’interruptpiùprioritario,traquelliabilitati,potràessereletto,aCS_PIC_READ_CODE,attraversoisegnaliINT_CODE[15..0].Diquestiultimi16segnali,12sarannosemprecablatia0perragionichiariteinseguito.",nti nti nte
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#5,5,"Dispositivi e segnali presenti nel sistemaMemorie:RAM_512_MBmappata da E0000000h:FFFFFFFFh, 4 banchi da 128 MBEPROM_1_GB mappata da 00000000h:3FFFFFFFh, 4 banchi da 256 MBPorte di input, output e altri chip-selecte/o segnali:CS_INPUT_PORT_0mappato a 80000000hCS_INPUT_PORT_1mappato a 80000001hCS_OUTPUT_PORT_0mappato a 80000002hCS_OUTPUT_PORT_1mappato a 80000003hCS_PIC_SET_INTsmappato a 80000004hCS_PIC_READ_INTsmappato a 80000008hCS_PIC_READ_CODEmappato a 8000000Ch",dispositivi segnali presenti sistema memorier mbmappata ehf banchi mappata banchi bporte input output altri chip selecteo segnalic rtmappato rtmappato rtmappato rtmappato tsmappato tsmappato demappato
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#6,6,"Segnali di decodifica di memorie, periferiche e segnali:CS_RAM_0 = BA31·BA30·BE0CS_RAM_1= BA31·BA30·BE1CS_RAM_2= BA31·BA30·BE2CS_RAM_3= BA31·BA30·BE3CS_INPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE0·IBF_0mappato a 80000000hCS_INPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE1·IBF_1mappato a 80000001h CS_OUTPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE2·OBF_0*mappato a 80000002h CS_OUTPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE3·OBF_1*mappato a80000003hCS_PIC_SET_INTs= BA31·BA30*·BA3*·BA2mappato a 80000004hCS_PIC_READ_INTs= BA31·BA30*·BA3·BA2*·MEMRDmappato a 80000008hCS_PIC_READ_CODE= BA31·BA30*·BA3·BA2·MEMRDmappato a 8000000ChCS_EPROM_0 = BA31*·BE0 CS_EPROM_1= BA31*·BE1CS_EPROM_2 = BA31*·BE2CS_EPROM_3 = BA31*·BE3",segnali decodifica memorie periferiche segnalic ab ab ab ab ab ab ab ab ab ab ab ab ei bfmappato ab ab ab ab ei bfmappato ab ab ab ab eo bfmappato ab ab ab ab eo bfmappato ab ab ab amappato ab ab ab am rdmappato ab ab ab am rdmappato ab ab ab ab
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#7,7,"INPUTPORT_0D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_0MEMRDUNITA’ESTERNA#0INT_IN_PORT_0BD[7..0]IBF_0Nelsistemasonopresentidueporteininput,collegateaibusdatiBD[7..0](INPUT_PORT_0)eBD[15..8](INPUT_PORT_1)
INPUTPORT_1D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_1MEMRDUNITA’ESTERNA#1INT_IN_PORT_1BD[15..8]IBF_1STB_1STB_0A_RESETRESET
A_RESETRESET",ins tae bdi bdi rte bdi ins tae bdi
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#8,8,"OUTPUTPORT_0D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFA_RESETCS_OUTPUT_PORT_0MEMWRRESETUNITA’ESTERNA#2INT_OUT_PORT_0     BD[23..16]NelsistemasonopresentianchedueporteinoutputcollegateaibusdatiBD[23..16](OUTPUT_PORT_0)eBD[31..24](OUTPUT_PORT_1)
OUTPUTPORT_1D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFCS_OUTPUT_PORT_1MEMWRUNITA’ESTERNA#3INT_OUT_PORT_1     BD[31..24]ACK_1OBF_1ACK_0OBF_0
A_RESETRESET",ae bdo rte bdo tae
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#9,9,"RESETFFDDQA_RES10MEMWR*D0EN_INT_0AlfinediabilitareedisabilitareselettivamentegliinterruptsipossonoutilizzarequattroFFD.IquattrobitD[3..0]sonoconnessiaisegnaliBD[3..0]delbusdatieutilizzatipercondizionareognisingolainterruzionemedianteisegnaliEN_INT_0,EN_INT_1,EN_INT_2eEN_INT_3generatidalleretiseguenti:CS_PIC_SET_INTsEN_INT_0RESETFFDDQA_RES10MEMWR*D1EN_INT_1CS_PIC_SET_INTsEN_INT_1RESETFFDDQA_RES10MEMWR*D2EN_INT_2CS_PIC_SET_INTsEN_INT_2RESETFFDDQA_RES10MEMWR*D3EN_INT_3CS_PIC_SET_INTsEN_INT_3",diquattrobit
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#0,0,"DLX: implementazione sequenziale  Calcolatori Elettronici T Ingegneria Informatica 
",implementazione sequenziale calcolatori elettronici ingegneria informatica
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#1,1,"Datapath e Unità di Controllo  • La struttura di una CPU, come tutte le reti logiche sincrone che  elaborano dati, può essere strutturata in due blocchi: Unità di Controllo e Datapath  • La CPU, per funzionare, ha bisogno della memoria esterna su cui risiedono il programma e i dati 
reset interrupt ready 
CPU istruzioni Dati (in)  indirizzi 
Dati (out) U.d.C. Data Path clock memoria Rete logica CPU ",datapath unit controllo struttura tutte reti logiche sincrone elaborano dati pu essere strutturata due blocchi unit controllo datapath funzionare bisogno memoria esterna risiedono programma dati reset interrupt ready istruzioni dati indirizzi dati out udc data path clock memoria rete logica
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#10,10,"Estrazione “automatica” dei registri durante la fase di decode di una istruzione (qualsiasi)  I Codice  operativo  RS2/Rd RS1 Operando immediato di 16 bit J Codice  operativo  Offset di 26 bit (PC relative) R Codice  operativo  RS2 RS1 Rd Estensione al Cod. op (11 bit) 0 31 < A B 
Questi 5 + 5 bit  sono utilizzati per estrarre, preventivamente e ancora prima di conoscere che tipo  di istruzione che è stata letta dalla memoria, dal Register File due registri in A e B. Nel caso di  istruzione J non ci sono registri coinvolti e quindi saranno estratti bit corrispondenti all’offset. Nel  caso di istruzione I, in B potrebbe finire il valore del registro destinazione (e.g. in una LD o  operazione ALU (tipo I)). Infine: i 5 + 5 bit rappresentano gli indici (o presunti tali) ma non il valore dei due registri che è  contenuto nel Register File. ",estrazione automatica registri durante fase decode istruzione qualsiasi codice operativo srd operando immediato bit codice operativo offset bit relative codice operativo estensione cod bit bit utilizzati estrarre preventivamente ancora prima conoscere tipo istruzione stata letta memoria register file due registri caso istruzione registri coinvolti quindi estratti bit corrispondenti alloffset caso istruzione potrebbe finire valore registro destinazione operazione tipo infine bit rappresentano indici presunti tali valore due registri contenuto register file
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#11,11,"Gli stati della fase di fetch  • In questa fase si deve verificare se è presente un interrupt (evento esterno asincrono che la CPU deve “servire” con apposito software); • se l’interrupt è presente e può essere servito (IEN = true) si esegue implicitamente l’istruzione di chiamata a procedura all’indirizzo 0, e si salva l’indirizzo di ritorno nell’apposito registro IAR; • se l’interrupt non è presente o le interruzioni non sono abilitate, si va a leggere in memoria la prossima istruzione da eseguire (il cui indirizzo è in PC) MAR ← PC Dall’ultimo stato  dell’istruzione precedente  IAR:  Interrupt  Address  Register  IAR ← PC PC ← 0 IEN ← 0 IEN:  Interrupt  Enable  Flag  (int and IEN) = 1 (int and IEN) = 0 IR ← M(MAR) Alla fase di decodifica Ready = 1 Ready = 0 ",stati fase fetch fase deve verificare presente interrupt evento esterno asincrono deve servire apposito software linterrupt presente pu essere servito true esegue implicitamente listruzione chiamata procedura allindirizzo salva lindirizzo ritorno nellapposito registro linterrupt presente interruzioni abilitate leggere memoria prossima istruzione eseguire indirizzo dallultimo stato dellistruzione precedente interrupt address register interrupt enable flag int int fase decodifica ready ready
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#12,12,Si modifica il  DATAPATH in  maniera da poter  indirizzare  la memoria dal PC.  Meno stati ma maggiore complessità  Data transfer ALU Set Jump Branch Ready ? INSTRUCTION FETCH INSTRUCTION  DECODE* Tutte le istruzioni impiegano un clock in meno per essere eseguite !  Ma potenzialmente aggiore lentezza  -> minore freq. clock Il diagramma  degli  stati del  controller  PC <- PC +4  A <- RS1 B <- RS2  IR <- M [PC] ,modifica maniera poter indirizzare memoria meno stati maggiore complessit data transfer set jump branch ready tutte istruzioni impiegano clock meno essere eseguite potenzialmente aggiore lentezza minore freq clock diagramma stati controller
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#13,13,"Ready ? IR <- M [PC] 
 MAR <- A + (IR15)16 ## IR15..0 LOAD MDR <- M[MAR]  LB Ready ? C <- (MDR7)24 ## MDR7..0 RD <- C   PC <- PC +4  A <- RS1  B <- RS2  Controllo per  l’istruzione LB  (LOAD BYTE) ALU ALU Parte comune 
RS2 è da intendersi come registro di destinazione (A) = (RS1) Estensione segno ",ready ready controllo listruzione parte comune intendersi registro destinazione estensione segno
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#14,14,"Estensione del segno   (IR15)16 ## IR15..0 0    15      31 IR 
31 30…………17  16 BUS S1 o S0 Da UdC 
15-0 ",estensione segno 
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#15,15,"MDR <- M[MAR]
MDR <- B.C <- MDRRD <- C M[MAR] <-MDRINIT STORE 
LB LBU LH LHU LW Controllo per  le istruzioni di  DATA  TRANSFER  LB  LBU LH LHU LW STORE  Byte -> SB Half Word –> SH Word -> SW  C <-(MDR7)24 ## MDR7..0C <- (0)24 ## MDR7..0C <- (MDR15)16 ## MDR15..0 C <-(0)16 ## MDR15..0MAR <- A + (IR15)16 ## IR15..0 LOAD 
Mancano nell’esempio  SH e SB (sempre unsigned)  che corrispondono a attivazione degli specifici WE delle memorie e “traslatori” dei bytes del registro MDR.  Come si realizzerebbero ?  NB: in lettura la parte meno  significativa del dato viene letta  sempre allineata al registro MDR per permettere il filling SW Il contenuto di A come unsigned Ready ? 
Ready ? ",controllo istruzioni byte half word word mancano nellesempio sempre unsigned corrispondono attivazione specifici memorie traslatori bytes registro realizzerebbero lettura parte meno significativa dato viene letta sempre allineata registro permettere filling contenuto unsigned ready ready
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#16,16,"17  17  Trasferimenti BYTE, HW  •  I trasferimenti di bytes sono SEMPRE considerati allineati •  I trasferimenti di HW debbono avvenire a indirizzi multipli di 2 •  I trasferimenti di Word debbono sempre avvenire a indirizzi multipli di 4 •  In caso di disallineamento: fault •  Nel caso di store di dati di dimensione inferiore alla word NON si ha estensione del segno •  La lettura/scrittura di bytes e HW (a causa del reciproco disallineamento fra i registri e la memoria) implica che fra i registri e la memoria siano interposti dei mux/demux (realizzati con tristate) Registro MDR 
Memoria Come sono attivati i WE delle memorie ? Progettare la rete  ",trasferimenti trasferimenti bytes considerati allineati trasferimenti debbono avvenire indirizzi multipli trasferimenti word debbono sempre avvenire indirizzi multipli caso fault caso store dati dimensione inferiore word estensione segno bytes causa reciproco disallineamento fra registri memoria implica fra registri memoria interposti muxdemux realizzati tristate registro memoria attivati memorie progettare rete
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#17,17,"Trasferimenti BYTE, HW  MDR 
Memoria 31 0 Mux Demux I MUX 23-16 e 31-24 hanno come ingresso anche il bit 7 del byte 7-0 della memoria (LB) e il bit 15 del byte 15-8 della memoria (LH)  Ad esempio in una LB il MUX 7-0 si collega direttamente alla memoria mentre i MUX 15-8, 23-16 e 31-24 si collegano al bit 7 del MUX 7-0 proveniente dalla memoria.  In una SH a indirizzo multiplo di 2 e non di 4  il DEMUX 7-0  dal MDR si collega alla memoria 23-16 e il DEMUX 15-8 alla memoria 31-24. Gli altri due bytes della memoria rimangono invariati Mux Demux “0” Bit più signif. byte precedenti Solo in lettura Trasferimento  “unsigned” 24 23 16 ",trasferimenti memoria mux demux ingresso bit byte memoria bit byte memoria esempio collega direttamente memoria mentre collegano bit proveniente memoria indirizzo multiplo collega memoria memoria altri due bytes memoria rimangono invariati mux demux bit signif byte precedenti solo lettura trasferimento unsigned
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#18,18,"C <- A + TempC <- A xor TempC <- A - Temp C <- A and TempC <- A or TempINIT RD <- CRegistro (formato R) Immediato (formato I) 
ADD AND SUB XOR OR   Temp <- BTemp <- (IR15)16 ## IR15..0Esempi di istruzioni  ALU  Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP  Lo stesso schema si può usare per gli shift etc.  Il contenuto dei registri come signed se op aritmetica ",temp xor temp temp temp temp registro formato immediato formato temp temp esempi istruzioni duplicando percorsi potrebbe risparmiare passaggio stesso schema pu usare shift etc contenuto registri signed aritmetica
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#19,19," RD <- C A = Temp
C <- 1SEQ SLT SGE SNE SGT SLE YES NO  Il risultato del test è un input per il controller ! Registro (formato R) Immediato (formato I) Controllo per  le istruzioni  di SET  (confronto) ex. SLT R1,R2,R3  
INIT Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP   Temp<- BTemp <- (IR15)16 ## IR15..0 A < Temp A >= Temp A <= Temp A > Temp A! = TempC <- 0I micropassi sono eseguiti  in ALU ma il risultato  NON è memorizzato in un registro: i flag sono utilizzati dalla ALU per impostare (almeno) il bit 0 del registro C  Il contenuto dei registri come signed ",temp risultato test input controller registro formato immediato formato controllo istruzioni confronto rrr duplicando percorsi potrebbe risparmiare passaggio temp temp temp temp temp temp temp micropassi eseguiti risultato memorizzato registro flag utilizzati impostare almeno bit registro contenuto registri signed
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#2,2,"•  Datapath: contiene tutte le unità di elaborazione ed  i registri necessari per l’esecuzione delle istruzioni  della CPU. Ogni istruzione appartenente all’ISA è  eseguita mediante una successione di operazioni  elementari, dette micro-operazioni •  Micro-operazione: operazione eseguita all’interno  del DATAPATH in un ciclo di clock ( e s e m p i :  trasferimento di un dato da un registro ad un altro  registro, elaborazione ALU) •  Unità di Controllo: è una RSS che in ogni ciclo di  clock invia un ben preciso insieme di segnali di  controllo al DATAPATH al fine di specificare  l’esecuzione di una determinata micro-operazione  Datapath e Unità di Controllo  ",datapath contiene tutte unit elaborazione registri necessari lesecuzione istruzioni ogni istruzione appartenente alli eseguita mediante successione operazioni elementari dette micro operazioni micro operazione operazione eseguita allinterno ciclo clock trasferimento dato registro altro registro elaborazione unit controllo ogni ciclo clock invia ben preciso insieme segnali controllo fine specificare lesecuzione determinata micro operazione datapath unit controllo
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#20,20,"INIT  C <- PCJALR JAL JMP JR JALR 
JALR JR JAL 
JMP JAL JALR  JAL Controllo per  le istruzioni  di JUMP  (IR15)16 ## IR15..0  C <- PC
PC <-  PC + (IR25)6 ## IR25..0 PC <- A R31 <- CPer il salvataggio in R31 
Istruzione  formato I  Istruzione  formato J  ",controllo istruzioni salvataggio istruzione formato istruzione formato
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#21,21,"INIT A = 0 BRANCH 
YES YES NO NO BEQZ BNEZ Controllo per  le istruzioni  di BRANCH  A! = 0 PC <-  PC + (IR15)16 ## IR15..0 Ex. BNEQZ R5, 100 Il controllo se 0 (o !=0) è fatto sull’intero registro A (a 32 bit) e non solo sul bit meno significativo ",controllo istruzioni controllo fatto sullintero registro bit solo bit meno significativo
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#22,22,"Numero di clock necessari per eseguire le istruzioni  Istruzione Cicli Wait Totale Load 6 2 8 Store 5 2 7 ALU 5 1 6 Set 6 1 7 Jump 3 1 4 Jump and link 5 1 6 Branch (taken) 4 1 5 Branch (not taken) 3 1 4 CPICPIN numero totale di istruzioni iin=i = 1 ∑(*)Esempio su DLX  LOAD: 21%, STORE: 12%, ALU: 37%, SET: 6%, JUMP: 2% BRANCH (taken): 12%, BRANCH (not-taken): 11%    CPI = 6.3 ",numero clock necessari eseguire istruzioni istruzione cicli wait totale load store set jump jump link branch taken branch not taken numero totale istruzioni iini esempio taken not taken
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#23,23,"Controllo cablato (“hardwired”) Segnali di  controllo 
INSTRUCTION REGISTER (IR) 40 Opcode +  OpCode Extension   6 Datapath Stato presente Rete combinatoria che  genera uscite e stato futuro Int e ready 2 6+11 3 Stato futuro 228 righe Rs1, Rs2, Rd - Indici di Rs1, Rs2 e Rd provengono da IR - IR25..0 sono portati ai bus S1 ed S2 del data path attraverso due buffer tristate IR25..0 U.d.C. 
32 bit dalla  memoria - U.d.C. genera anche i segnali di comando per la memoria (MEMRD e  MEMWR) Flag ",controllo cablato hardwired segnali controllo opcode code extension datapath stato presente rete combinatoria genera uscite stato futuro int ready stato futuro righe indici provengono portati bus data path attraverso due buffer tristate udc bit memoria udc genera segnali comando memoria flag
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#24,24,"I passi dell’esecuzione delle istruzioni  Nel DLX l’esecuzione di tutte le istruzioni può essere scomposta in 5 passi, ciascuno eseguito in uno o più cicli di clock.   Tali passi sono detti:  1) FETCH:   l’istruzione viene prelevata dalla memoria e posta in IR.  2) DECODE: l’istruzione in IR viene decodificata e vengono prelevati gli   operandi sorgente dal Register File.   3) EXECUTE: elaborazione aritmetica o logica mediante la ALU.   4) MEMORY: accesso alla memoria e, nel caso di BRANCH aggiornamento   del PC (“branch completion”).   5) WRITE-BACK:   scrittura sul Register File. ",passi dellesecuzione istruzioni lesecuzione tutte istruzioni pu essere scomposta passi ciascuno eseguito cicli clock tali passi detti listruzione viene prelevata memoria posta listruzione viene decodificata vengono prelevati operandi sorgente register file elaborazione aritmetica logica mediante accesso memoria caso aggiornamento branch completion scrittura register file
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#25,25,"Le micro-operazioni eseguite  in ciascun passo  1) FETCH MAR   ß PC ;   ß  M[MAR]; 2) DECODE A  ß RS1, B  ß RS2,  PC  ß PC+4 IR   ",micro operazioni eseguite ciascun passo
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#26,26,"Le micro-operazioni eseguite  in ciascun passo  MEMORIA: MDR   ß   B;        ALU:   BRANCH: 3) EXECUTE MAR      A + (IR15)16 ## IR15..0 ; ß C  <- A op B (oppure A op (IR15)16 ## IR15..0) ; Temp       PC + (IR15)16 ## IR15..0) ; (utilizza ALU, S1, S2, dest: qui non si sa       ancora se si deve saltare) ß (utilizzano ALU, S1, S2, dest)  C <-  sign( A op B (oppure A op (IR15)16 ## IR15..0));  se SCn (NB: serve nelle Store  ove RD=RS2 operazione non significativa nelle LOAD)  J e JAL  Temp       PC + (IR25)6 ## IR25..0) ;  ß JR e JALR Temp       A;  ß ",micro operazioni eseguite ciascun passo oppure temp utilizza dest qui ancora deve saltare utilizzano dest sign oppure serve store ove operazione significativa temp temp
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#27,27,"Le micro-operazioni eseguite  in ciascun passo  4) MEMORY MDR   ß M[MAR];  (LOAD) ß  MDR;    (STORE)  BRANCH: M[MAR]  If (Cond)      PC       Temp; ß Memoria: 
[A] è il registro che condiziona il salto (Cond) ; JAL e JALR: C       PC; ß ",micro operazioni eseguite ciascun passo cond temp memoria registro condiziona salto cond
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#28,28,"5) WRITE-BACK RD  ß C ; C ß MDR; (se è una LOAD – due micropassi)) Le micro-operazioni eseguite  in ciascun passo  
PC       Temp; ß  istruzioni J, JR, JAL, JALR  istruzioni diverse da J, JR, JAL, JALR RD  ß C ; ",due micropassi micro operazioni eseguite ciascun passo temp istruzioni istruzioni diverse
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#3,3,"Register file C A B Struttura del DLX (esecuzione sequenziale)  
TEMP IAR PC S1 S2 dest alu 
CPU Memoria dati in scrittura dati/istruzioni in lettura Indirizzi Instruction register C O N T R O L U N I T 
fetch MDR MAR execute Parallelismo dell’architettura: 32 bit (bus, alu e registri hanno parallelismo 32) I segnali di controllo non sono riportati !  ",register file struttura esecuzione sequenziale dest alu memoria dati scrittura datiistruzioni lettura indirizzi instruction register fetch execute parallelismo bit bus alu registri parallelismo segnali controllo riportati
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#4,4,"I registri del DLX (tutti a 32 bit)  • Register f i l e: 32 General Purpose Registers R 0 … . R 3 1  con  R0=0 • IAR: Interrupt Address Register –  D e p o s i t o  dell’indirizzo di ritorno in caso di interruzione • PC: Program Counter • MAR: Memory Address Register –  C o n t i e n e  l’indirizzo  del dato da scrivere o leggere in memoria • IR: Instruction Register –  C o n t i e n e  l’istruzione  attualmente in esecuzione • TEMP: Temporary Register –  R e g i s t r o  d i  d e p o s i t o  temporaneo di risultati  • MDR: Memory Data Register –  R e g i s t r o  d i  t r a n s i t o  temporaneo dei dati da e per la memoria • A e B: Registri di uscita dal Register File A parte il Register File questi registri NON sono accessibili  al programmatore. In alcuni casi istruzioni speciali per  accedere ad alcuni (e.g., IAR) ",registri tutti bit register general purpose registers interrupt address register dellindirizzo ritorno caso interruzione program counter memory address register lindirizzo dato scrivere leggere memoria instruction register listruzione attualmente esecuzione temporary register temporaneo risultati memory data register temporaneo dati memoria registri uscita register file parte register file registri accessibili programmatore alcuni casi istruzioni speciali accedere alcuni
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#5,5,"Funzioni della ALU       Dest (uscite) – 4 bit di comando  S1 + S2 S1 – S2 S1 and S2 S1 or S2 S1 exor S2 Shift S1 a sinistra di S2 posizioni Shift S1 a destra di S2 posizioni Shfit S1 aritmetico a destra di S2 posizioni S1 S2 0 1   Flag di uscita  Zero Segno negativo Carry 
• La ALU è una rete PURAMENTE combinatoria • Non esiste nel DLX un registro di flag ",funzioni dest uscite bit comando exor shift sinistra posizioni shift destra posizioni shfit aritmetico destra posizioni flag uscita zero segno negativo carry rete combinatoria esiste registro flag
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#6,6,"Trasferimento dati sul datapath • I bus S1 ed S2 sono multiplexati (tri-state) con parallelismo 32 bit. • I registri campionano sul fronte positivo del clock, hanno due porte di uscita O1 e O2 per i due bus (o i registri A e B) e dispongono di tre ingressi di controllo:  – un ingresso di Write Enable (WE*)  ed  uno di Output Enable per ogni porta di uscita, una per ogni bus S1 e S2 (OE1* e OE2*). • Al fine di valutare la massima frequenza a cui è possibile far funzionare il datapath è importante conoscere le seguenti temporizzazioni: – TC (max) : ritardo max tra il fronte positivo del clock e l’istante in cui i  segnali di controllo generati dall’unità di controllo sono validi; – TOE (max): ritardo max tra l’arrivo del segnale OE e l’istante in cui i dati del registro sono disponibili sul bus; – TALU (max): ritardo massimo introdotto dalla ALU; – TSU (min)  : tempo di set-up minimo dei registri (requisito minimo per il corretto campionamento da parte dei registri).  • La massima frequenza di funzionamento del data path si calcola come segue:      fCK(max) = 1/TCK TCK  > TC (max) + TOE (max) + TALU (max) + TSU (min) ",trasferimento dati datapath bus multiplexati tri state parallelismo bit registri campionano fronte positivo clock due porte uscita due bus registri dispongono tre ingressi controllo ingresso write enable output enable ogni porta uscita ogni bus fine valutare massima frequenza possibile far funzionare datapath importante conoscere seguenti max ritardo max fronte positivo clock listante segnali controllo generati dallunit controllo validi max ritardo max larrivo segnale listante dati registro disponibili bus max ritardo massimo introdotto min tempo set minimo registri requisito minimo corretto campionamento parte registri massima frequenza funzionamento data path calcola segue ckmax max max max min
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#7,7,"Esempio : esecuzione della microistruzione  Rin ← Rout  S2 
alu WE*  OE1* OE2* WE* OE1* OE2* S1 Rout Rin dest clock O2 O1 O2 O1 I I i1 i2 u = i2 WERin* OE2Rout* I segnali in blu (segnali di controllo) provengono dall’Unità di Controllo 
I segnali di controllo in grassetto sono attivi nel ciclo di clock in cui il micro-step Rin ← Rout viene eseguito  (e.g. TEMP) (e.g. MAR) Clock sempre collegato:  write enable !  ",esempio esecuzione microistruzione rin rout alu rout rin dest clock erin rout segnali blu segnali controllo provengono dallunit controllo segnali controllo grassetto attivi ciclo clock micro step rin rout viene eseguito clock sempre collegato write enable
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#8,8,"Il progetto dell’Unità di Controllo  • Una volta definito il Set di Istruzioni e progettato il DATAPATH, il passo successivo del progetto di una CPU è il progetto dell’Unità di Controllo  (CONTROLLER). • Il CONTROLLER è una RSS: il suo funzionamento può essere specificato tramite un diagramma degli stati.  •  Il CONTROLLER (come tutte le RSS) permane in un determinato stato per un ciclo di clock e transita (può transitare) da uno stato all’altro in corrispondenza degli istanti di sincronismo (fronti del clock).  •  Ad ogni stato corrisponde quindi un ciclo di clock.  Le micro-operazioni che devono essere eseguite in quel ciclo di clock sono specificate (in linguaggio RTL) nel diagramma degli stati che descrive il funzionamento del CONTROLLER all’interno degli stati. •  A partire dalla descrizione RTL si sintetizzano poi i segnali di controllo che  devono essere inviati al DATAPATH per eseguire le operazioni elementari  associate ad ogni stato.   ",progetto dellunit controllo volta definito set istruzioni progettato passo successivo progetto progetto dellunit controllo funzionamento pu essere specificato tramite diagramma stati come tutte permane determinato stato ciclo clock transita pu transitare stato allaltro corrispondenza istanti sincronismo fronti clock ogni stato corrisponde quindi ciclo clock micro operazioni devono essere eseguite quel ciclo clock specificate linguaggio diagramma stati descrive funzionamento allinterno stati partire descrizione sintetizzano poi segnali controllo devono essere inviati eseguire operazioni elementari associate ogni stato
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#9,9,"Il diagramma  degli  stati del  controller  Data transfer ALU Set Jump Branch Ready ?  IR <- M [MAR] INSTRUCTION  FETCH INSTRUCTION  DECODE* MAR <- PC  
 PC<- PC+4 A <- RS1 B <- RS2 Oltre a decodificare l’istruzione si prelevano  gli operandi sorgente dal RF (anche se non utilizzati !) e si incrementa il PC.  Qui non si sa ancora quale sia l’istruzione ma il trasferimento ai registri è fatto  comunque !! N.B. I primi tre stadi sono comuni a tutte  le istruzioni  ",diagramma stati controller data transfer set jump branch ready oltre decodificare listruzione prelevano operandi sorgente anche utilizzati incrementa qui ancora listruzione trasferimento registri fatto comunque primi tre stadi comuni tutte istruzioni
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#0,0,"ISA DLX: implementazione pipelinedCalcolatori Elettronici TIngegneria Informatica
",implementazione pipelined calcolatori elettronici ingegneria informatica
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#1,1,"Principio del PipeliningIl pipeliningè oggi la principale tecnica di base impiegata per rendere veloceuna CPU . Lidea alla base del pipeliningè generale, e trova applicazione in molteplici settori dellindustria (linee di produzione, oleodotti …)Un sistema, S, deve eseguire Nvolte unattività A: A1 , A2 , A3…ANSR1 , R2 , R3…RNLatency: tempo che intercorre fra linizio ed il completamentodellattività A(TA).Throughput: frequenza con cui vengono  completate le attività.",principio pipelining pipelining oggi principale tecnica base impiegata rendere veloceuna lidea base pipelining generale trova applicazione molteplici settori dellindustria linee produzione oleodotti un sistema deve eseguire nvolte unattivit aa rr nlatency tempo intercorre fra linizio athroughput frequenza vengono completate attivit
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#10,10,"Requisiti per l’implementazione in pipeline•Ogni stadio deve essere attivo in ogni ciclo di clock. •Enecessario incrementare il PC in IF (invece che in ID).•Enecessario introdurre un ADDER (PC <--PC+4 –PC <-PC+1) nello stadio IF.•Sono necessari due MDR (che chiameremo LMDR e SMDR) per gestire il caso di una LOAD seguita immediatamente da una STORE (WB-MEM sovrapposti –sovrapposizione di due dati in attesa di essere scritti, uno in memoria e l’altro nel RF). •In ogni ciclo di clock devono poter essere eseguiti 2 accessi alla memoria (IF, MEM): InstructionMemory (IM) e Data Memory (DM) ->  Architettura ‘Harvard’•Il clock della CPU è determinato dallo stadio più lento: IM, DM devono essere delle memorie cache(on-chip) •I Pipeline Registerstrasportano sia dati sia informazioni di controllo (l’unità di controllo è ‘distribuita’  fra gli stadi della pipeline)",requisiti pipelineogni stadio deve essere attivo ogni ciclo clock enecessario incrementare invece introdurre stadio fsono necessari due che chiameremo gestire caso seguita immediatamente sovrapposti due dati attesa essere scritti memoria laltro in ogni ciclo clock devono poter essere eseguiti accessi memoria instruction memory data memory architettura harvardil clock determinato stadio lento devono essere memorie cacheon chip pipeline dati informazioni controllo lunit controllo distribuita fra stadi pipeline
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#11,11,"GerarchiadellamemoriaL0 (registri CPU)L1L2L3Memoria (DDR)
DiscoCosto/ByteTempo di accessoH
LL
HCPU ",registri pul memoria disco costobyte tempo accesso
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#12,12,"13MemoriecacheCPUCacheMemoria (DDR)Una(opiùlivelli)memoriavelocemadiridottedimensioni,iecache,ingradodisfruttareilprincipiodilocalitàfannoapparirela(lenta)memoriaDDRmoltopiùveloce",memoriecache ucache memoria rmoltopiveloce
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#13,13,"14
Area di silicio occupata da cache L1,L2,L3 in un Intel Core i5Fonte: https://thecodeartist.blogspot.com/2011/12/why-readmostly-does-not-work-as-it.html",area silicio occupata cache lll intel core fonte readmostly work ithtml
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#14,14,"IFIDEXMEMWBDatapath in Pipeline del DLX
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBEstensionedel segnoNumero reg. dest.nel caso di LOADe ALU instr.JL (il PC in   R31)JLRPer il calcolo del nuovo PC nei salti
Per le operazioni con immediatiRDDRS1RS2
Numero del registro di destinazioneDatiPCIn realtà è un contatore programmabile  visto che i due bit meno significativi sono a 0se saltoContiene anche i circuiti di swapPer SCn(anche <0 e >0)[agisce sulluscita]
=0?per BranchDurante JMP e BRANCH taken in IF/ID entra PC… Pazienza, sarà eliminata l’istruzione mediante NOP",datapath pipeline bestensionedel segno numero reg destnel caso instrj calcolo nuovo salti operazioni immediati numero registro destinazione dati realt contatore programmabile visto due bit meno significativi salto contiene circuiti swap cnanche agisce sulluscita per branch durante taken entra pazienza eliminata listruzione mediante
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#15,15,"Stadiodi Fetch con contatore1/2
Counter 30 bitENU[29..0]ClockSTALL*LDJUMPPC[31..2]I[29..0]JUMP_ADDRESS[31..2]
Sempre con riferimento allo stesso schema del DLX. Il segnale JUMPcodifica se il DLX deve saltare alla destinazione specificata daJUMP_ADDRESS[31.2]. Entrambi i segnali sono inviati dallo stadio MEM.Il segnale STALL, è generato dalla Unità di Controllo quando lostadio di IF deve essere bloccato. PC (to memory)ConriferimentoalprimoschemadelDLXpipelinedstudiatoduranteilcorso(maconsiderazionianaloghesiapplicanoallealtreversionidelDLX),lareteseguenteconsentedisostituireloschemabasatosuregistroemultiplexerconuncontatorea30bit(iduebitmenosignificatividell’indirizzosonosuperfluiperchéilDLXesegueilfetchsempreaindirizziallineati).PC +1 (to IF/ID)Come?",stadiodi fetch contatore counter bit uclock sempre riferimento stesso schema segnale pcodifica deve saltare destinazione specificata entrambi segnali inviati stadio emil segnale generato unit controllo quando lostadio deve essere bloccato dcome
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#16,16,"REGISTER30 bitStadio di Fetch con contatore 2/2Un’osservazione: come possiamo generare PC + 1 per lo stadio IF/ID(quando viene eseguito il fetch a PC è necessario fare entrare nellapipeline (stadio IF/ID) PC +1 ?
CKD[29..0]OUT[29..0]+1PC +1 (to IF/ID)
PC  (to memory)Stato presenteStato futuro
PC[31..2]",bit stadio fetch contatore possiamo generare stadio dquando viene eseguito fetch necessario fare entrare nellapipeline stadio kdo memorystato presente stato futuro
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#17,17,"Sezione IDIRRFSERDDRS1RS2IF/IDID/EX
IR25-21IR20-16
Numero registro destinaz.(dallo stadio WB) Dati (dallo stadio WB)(31-16) Immed./Branch(31-26)  JumpIR15IR25LBSWIR31-26 (Codop)IR15-0    (Offset/Immediato/Branch/Load -Reg. dest.)IR25-16   (J; JL))
PC31-0    (JAL)PCAB26 (J e JL)
61632323232
32Info che viaggiacon listruzioneIR10-00 (ExtCO)DEC
Estensione segno",sezione ifi numero registro destinazdallo stadio dati dallo stadio jump codopi reg desti alp info viaggiacon listruzione ext cod estensione segno
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#18,18,"Datapath in Pipeline del DLX ADD4MUX
DMALUMUXMUXIMRFSEPCDEC
MUXIF/IDID/EXEX/MEMMEM/WBIR1ABIR2PC2CONDX
X: ALUOUPUT/DMAR/BTASMDRYLMDR
Y: ALUOUPUT1IFIDEX MEMWBPC1PC3PC4IndirizzoDatiIR3IR4n.  registro di destinazionePer SCn(anche <0 e >0)[agisce sulluscita]
=0?=0?per BranchJLJLR(il PC in R31)",datapath pipeline ifi indirizzo dati irn registro destinazione cnanche agisce sulluscita per branch ril
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#19,19,"Esecuzione in pipeline di istruzione ALU
X : ALUOUTPUT(in EX/MEM),  Y : ALUOUTPUT1NB in questa come nelle altre istruzioni RD (RS2) è trasferita fino allo stadio WBIFIDEXMEMY <-X (parcheggioin attesa di WB)WBRD <-YIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;X <-A op BoppureX <-A op (IR215)16##IR215..0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]N.B. al passare degli stadi IRperde i bit che non servono più in tutte le istruzioni. Da uno stadio al successivo vengono mantenuti i bit che servono qualunque sia listruzione",esecuzione pipeline istruzione lu utin utn altre istruzioni trasferita fino stadio parcheggioin attesa ide decodifica istruzionex boppure cla decodifica attraversa stadii rnb passare stadi rperde bit servono tutte istruzioni stadio successivo vengono mantenuti bit servono qualunque listruzione
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#2,2,"Motore: 2000 ccTipo:BenzinaColore:Rosso
",motore tipobenzina colorerosso
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#20,20,Esecuzione in pipeline di istruzione MEMIFIDEXMEMLMDR <-M[MAR]  (LOAD)oppureM[MAR] <-SMDR  (STORE)WBRD <-LMDR   (LOAD)  [ext. Segno]IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;MAR <-A op (IR215)16##IR215..0SMDR <-B[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2[IR4  <.-IR3],esecuzione pipeline istruzione emi doppure rew ext segnoi ide decodifica istruzionem cla decodifica attraversa stadii
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#21,21,"Esecuzione in pipeline di istruzione BRANCH 
X : BTA (BRANCH TARGET ADDRESS)IFIDEXMEMif (Cond) PC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-PC2 op (IR15)16##IR15..0Cond <-A op 0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3Il test avviene sul valore del registro",esecuzione pipeline istruzione ssi emif cond wbn opi ide decodifica istruzionex cond cla decodifica attraversa stadii test avviene valore registro
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#22,22,"Esecuzione in pipeline di unistruzione JRIDMEMWBIFIDEXMEMPC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-A [PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]
Come sarebbe la sequenza degli stati per una J ?",esecuzione pipeline unistruzione ri wbn opi ide decodifica istruzionex cla decodifica attraversa stadii sequenza stati
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#23,23,"Esecuzione in pipeline di istruzione JL  o JLRIDIFIDEXMEMPC <-X ; PC4<-PC3WBR31 <-PC4IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;PC3 <-PC2X <-A (Se JLR)     X <-PC2 + (IR25)6##IR25..0(Se JL)
NB: La scrittura in R31 NON può essere anticipata perché potrebbe sovrapporsi ad altra scrittura di registro Decod. in tutti gli stadi[IR4 <-IR3][IR3  <.-IR2]
Evidenziati perché in questo caso utilizzati",esecuzione pipeline istruzione lri ide decodifica istruzionep rse scrittura pu essere anticipata potrebbe sovrapporsi altra scrittura registro decod stadii evidenziati caso utilizzati
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#24,24,"25Qual sarebbe la sequenza nel caso di SCN  (ex SLT R1,R2,R3) ?IDIFIDEXMEMWBIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;???",qual sequenza caso rrr ide decodifica istruzione
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#25,25,"Alee nelle Pipeline•AleeStrutturali-Unarisorsaècondivisafraduestadidellapipeline:leistruzionichesitrovanocorrentementeintalistadinonpossonoessereeseguitesimultaneamente.•AleediDato–Sonodovuteadipendenzefraleistruzioni.Adesempiounaistruzionecheleggeunregistroscrittodaunistruzioneprecedente(RAW).•AleediControllo–Leistruzionicheseguonounbranchdipendonodalrisultatodelbranch(taken/nottaken).SiverificaunasituazionediAlea(Hazard)quandoinundeterminatociclodiclockunistruzionepresenteinunostadiodellapipelinenonpuòessereeseguitainquelclock.
Listruzionechenonpuòessereeseguitavienebloccata(stallodellapipeline),insiemeatuttequellechelaseguono,mentreleistruzionichelaprecedonoavanzanonormalmente(cosìdarimuoverelacausadellalea).",alee pipelinealee strutturali awaleedi
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#26,26,"Clk 6Clk 7Clk 8Alee e Stalli
IDIFIDEXMEMWBIi-3Ii-2Ii-1IiIDEXMEMIDEXIDIFIFIFIFIi+1Clk 1Clk 2Clk 3Clk 4Clk 5WBClk 9Clk 10Clk 11Clk 12WBWBT5=  8 * CLK = (5 + 3) * CLKT5= 5 * (1 + 3/5 ) * CLKCPI  idealeStalli per istruzioneTN= N *  1  * CLKTN= N *  (1 + S) * CLKCPI  effettivoSSSSSIFSMEMWBStallo: blocco del clock dello stadio e di tutti quelli precedentie propagazione progressiva agli stadi successiviEffetto–adesempio-diunaaleadidato:selistruzioneIinecessitadiundatoprodottodallaistruzioneIi-1deveaspettarefinoalWBdellaIi-1",clk clk clk alee stalli fii clk clk clk clk clk clk clk clk clk ideale stalli istruzione effettivo bstallo blocco clock stadio precedentie propagazione progressiva stadi successivi wbdella
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#27,27,"IFIDEXMEMWBStalli nel salto (1/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoal campionamento della  verifica della condizione di salto sono inserite 3 NOP al posto dei codici operativi provenienti dalla memoria",stalli salto dati pcse salto forzate salto primo fronte positivo clock successivoal campionamento verifica condizione salto inserite posto codici operativi provenienti memoria
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#28,28,"IFIDEXMEMWBStalli nel salto (2/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoalla verifica della condizione di salto sono inserite 2 NOP al posto dei codici operativi provenienti dalla memoriaNB In questo caso la condizione di salto e il nuovo PC sono presentatial MUX nello stesso periodo di produzione  della condizione",stalli salto dati pcse salto forzate salto primo fronte positivo clock successivoalla verifica condizione salto inserite posto codici operativi provenienti memoria caso condizione salto nuovo presentatial stesso periodo produzione condizione
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#29,29,"IFIDEXMEMWBStalli nel salto (3/3)ADD4
DATAMEMALUMUXMUX=0?INSTRMEMRFSEDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOP per salto
Al primo fronte positivo del clock successivoalla produzione della verifica della condizione di salto e inserita una NOP al posto del codice operativo proveniente dalla stadio IF/IDNB In questo caso la condizione di salto e il nuovo PC agisconosul MUX nello stesso periodo di produzione  della condizione
PCMUX",stalli salto dati pcse salto salto primo fronte positivo clock successivoalla produzione verifica condizione salto inserita posto codice operativo proveniente stadio caso condizione salto nuovo agisconosul stesso periodo produzione condizione
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#3,3,"Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
t",motore tipobenzina colorerosso motore tipobenzina colorerosso motore tipobenzina colorerosso motore tipobenzina colorerosso motore tipobenzina colorerosso
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#30,30,"ForwardingADD  R3, R1, R4Clk 6Clk 7Clk 8MEMWBIFIDEXMEMWBIDEXMEMIDEXIDIFIFIFIFClk 1Clk 2Clk 3Clk 4Clk 5WBEXMEMIDEXClk 9MEMWBWBIDIDIDIl forwardingconsente di eliminare quasi tutte le alee di tipo RAW dellapipeline del DLX senza stallarela pipeline. (NB: nel DLX si alteranoi registri  soloin WB)SUB  R7, R3, R5 aleaOR  R1, R3, R5 aleaLW  R6, 100 (R3) aleaAND R9, R5, R3  no aleaAnche qui il dato non è ancora in RF per essere estratto in ID !",forwarding clk clk clk fclk clk clk clk clk xclk dil eliminare quasi tutte alee tipo dellapipeline senza stallarela pipeline alteranoi registri soloin alea alea alea alea qui dato ancora essere estratto
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#31,31,"Implementazione del ForwardingFU
EX/MEMMUXMEM/WBALUMUXID/EXMUXMUXRS1/RS2CODOPRD2/CodOpRD1 (registro di destinazione/CodOpConfronto fraRS1, RS2 e RD1, RD2 e i cod. Op.RFMUX
Spesso realizzato allinterno del RFOppure SPLIT-CYCLE(v. dopo)scrittura prima di lettura
Permette di anticipareil registro su ID/EXControllo MUX: codice operativo IF/ID e confronto RD con RS1 e RS2 IF/IDFU –> Forwarding Unit",implementazione forwarding emw dcod registro confronto fra cod opr spesso realizzato allinterno foppure lev doposcrittura prima lettura permette anticipareil registro xcontrollo codice operativo confronto forwarding unit
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#32,32,"33Split-cycleT
In questo semiperiodo si scriveil registroIn questo semiperiodo si leggeil registro",split cycle semiperiodo scriveil registro semiperiodo leggeil registro
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#33,33,"34Alea di dato dovuta alle istruzioni di LOAD
N.B.ildatorichiestodallaADDèpresentesoloallafinediMEM.Laleanonpuòessereeliminataconilforwarding(amenodinonaprireunaulteriorediingressoaimuxdellaALUdallamemoria–ritardi!)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7LW    R1,32(R6)MEMWBIFIDEXMEMIFIDEXIFIDIFIDEX
LW     R1,32(R6)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7IFIDEXMEMWBIFIDSEXMEMIFSIDEXSIFIDEnecessario stallare lapipelineDi fatto non viene generato il clock. Il blocco di un  clock si propaga lungo  la pipeline uno stadio alla volta. Dalla fine di questo stadio in poi normale forwarding",alea dato dovuta istruzioni rrr rrr rrr rrm rra rrr rrr rrr denecessario stallare lapipeline fatto viene generato clock blocco clock propaga lungo pipeline stadio volta fine stadio poi normale forwarding
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#34,34,"Delayed loadIn diverse CPU RISC lalea associata alla LOAD non è gestita in HW stallando la pipeline ma è gestita via SW dal compilatore (delayed load): Istruzione LOADdelay slotIstruzione SuccessivaIl compilatore cercadi riempire il delay-slotcon unistruzione utile(caso peggiore: NOP).LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)",delayed load diverse lalea associata gestita stallando pipeline gestita via compilatore delayed load istruzione ddelay slot istruzione successiva compilatore cercadi riempire delay slotcon unistruzione utilecaso peggiore opl rrl rrr rrl rrr
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#35,35,"36Alee di Controllo
BEQZ R4, 200PCBEQZ R4, 200PC+4SUB  R7, R3, R5PC+8OR   R1, R3, R5PC+12LW   R6, 100 (R8)PC+4+200AND R9, R5, R3(BTA)Next InstructionAddressR4 = 0 :    Branch Target Address(taken)R4 ¹0 :   PC+4(not taken)Clk 6Clk 7Clk 8IFIDEXMEMWBIDIDClk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFWBIDIDIDIFEXWBIDMEMFetch connuovo PCNuovo valore PC calcolato (Aluout)SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Nuovo valore in PC (un clock dopo)  
IDIFEXWBIDMEM",alee controllo tanext instruction address branch target cnot takenclk clk clk dclk clk clk clk clk mfetch connuovo cnuovo valore calcolato aluouts rnuovo valore clock dopo
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#36,36,"ADD4
IMRFSEPCDECInstruction FetchInstruction DecodeExecuteMemoryWriteBack
IF/IDID/EXALUMUXEX/MEMMUXMUXDatapath in Pipeline del DLX  (caso 1/3) -(Branch o JMP)BEQZ R4, 200
MUXDMMEM/WBNel momento in cui il nuovo PC agisce sulla IM treistruzioni hanno eseguito i primi trestadi (fino a EXincluso)=0?=0?",instruction fetch instruction decode execute memory write back datapath pipeline caso branch mpb bnel momento nuovo agisce treistruzioni eseguito primi trestadi fino xincluso
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#37,37,"Gestione delle Alee di ControlloBEQZ R4,200Clk 6Clk 7Clk 8IFIDEXMEMWBClk 1Clk 2Clk 3Clk 4Clk 5SSIFSFetch at new PC•Always Stall (blocco di tre clock che si propaga)
Hyp.:  Freq.Branch = 25 %CPI = (1 + S) = ( 1 + 3 * 0.25) = 1.75•Predict Not TakenIFIDEXMEMWBIDIDIDBEQZ R4, 200SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Clk 6Clk 7Clk 8Clk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFIFWBEXWBIDIDIDMEMBranch CompletionFlush:diventanoNOPNOP           NOP           NOP           IF–maquilistruzioneprecedentenonancoradecodificataSIFIFIDSSituazione realeIF ripetuto PC <-PC -4Qui il nuovo valoreè campionato dal PC
Nessun danno: nessuna istruzione ha effettuato WB !",gestione alee controllo clk clk clk bclk clk clk clk clk sfetch new calways stall blocco tre clock propaga hyp freqbranch predict taken rclk clk clk clk clk clk clk clk mbranch completion flushdiventano situazione reale ripetuto qui nuovo valore campionato nessun danno nessuna istruzione effettuato
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#38,38,"Delayed branchSimilmentealcasodellaLOAD,indiverseCPUditipoRISClaleaassociataalleistruzionidiBRANCHègestitaviaSWdalcompilatore(delayedbranch):Istruzione BRANCHdelay slotIstruzione SuccessivaIl compilatore cercadi riempire i delay-slotcon istruzioni utili(caso peggiore: NOP).delay slotdelay slot",delayed branch adindiverse uditipo chgestitavia hdelay slot istruzione successiva compilatore cercadi riempire delay slotcon istruzioni utilicaso peggiore opdelay slotdelay slot
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#39,39,"Delayed branch/jumpAdd  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21Sne   R1, R8, R9; condizione di branchBr     R1, +100Sne   R1, R8, R9; condizione di branchBr     R1, +100Add  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21CompilatoOriginale
Eseguite inentrambi i casiOvviamente in questo gruppo  non debbono esserci salti !!!!Al posto di una o più istruzioni posposteil compilatore mette delle NOP in caso non riesca a trovarne di adatte",delayed branchjump add sub sne condizione branch sne condizione branch add sub compilato originale eseguite inentrambi casi ovviamente gruppo debbono esserci salti posto istruzioni posposteil compilatore mette caso riesca trovarne adatte
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#4,4,"•Latenza: 5 fasi(clock)•Throughput: a regime, dopo5 fasi(clock), un’automobileper fase(clock)",latenza regime dopo fasiclock faseclock
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#40,40,Gestione delle Alee di Controllo con BTBDynamic Prediction: Branch Target Buffer -> nessuno stallo (quasi)T/NTTAGSPredicted PCPC=HIT:  Fetch a PC  predettoMISS: Fetch a  PC + 4Predizione Corretta :    0 stalli Predizione Errata :       da 1 a 3 stalli  (fetch corretto in  ID o EX   v. precedentemente)N.B.  Qui il branch è individuato durante il periodo del clock IF che carica IR1 in IF/ID,gestione alee controllo dynamic prediction branch target buffer nessuno stallo quasitn spredicted fetch predetto fetch predizione corretta stalli predizione errata stalli fetch corretto qui branch individuato durante periodo clock carica
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#41,41,"Buffer di predizione: caso più semplice un bit che  indica cosa è successo l'ultima volta.
In presenza di preponderanza di un caso quando si verifica il caso opposto si hannodueerrorisuccessivi.Loop1Loop2Quando esce da loop2 sbaglia (predetto takenma in realtà untaken) ma sbagli ancora quando predice untakenrientrando nuovamente in loop2 a causa di  loop1 ",buffer predizione caso semplice bit indica cosa successo lultima volta presenza preponderanza caso quando verifica caso opposto loop quando esce loop sbaglia predetto takenma realt untaken sbagli ancora quando predice nuovamente loop causa loop
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#42,42,"Normalmente duebits.TAKENTAKEN
UNTAKENUNTAKENTAKENUNTAKENTAKENUNTAKENTAKENTAKEN
UNTAKENUNTAKEN",normalmente duebitst
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#43,43,"Esempio, molto frequente, di loop annidato:for (i=0; i<5000; i++)for (j=0; j<1000; j++}{x[i,j] = i*j + i + j;...... }",esempio molto frequente loop annidatofor ifor jxij
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#5,5,"Principio del Pipelining1) Sistema Sequenziale A2A3tANA1TALatency(tempo di esecuzione di una istruzione)= TAThroughput=1TA2) Sistema in Pipeline
SAP1P2P3P4tS1S2S3S4Si: pipeline stage",principio pipelining sistema sequenziale latencytempo esecuzione istruzione athroughput sistema pipeline pipeline stage
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#6,6,"Principio del PipeliningP1TPP2P1A2P2P3P1A3tA1
SS1S2S3S4P4P3P2P1A4P4P3P4P2P3P4AnLatency(2)= 4 *TP = TAThroughput(2)@1TP4TA==4 * Throughput(1)TP : pipeline cycle ",principio pipelining latency throughputt pipeline cycle
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#7,7,"Pipeliningin una CPU (DLX)Attività:    A1 , A2 , A3…ANIstruzioni:    I1 , I2 , I3…INIEXIDtMEMWBIF
CPI=1 (idealmente !)IF/IDID/EXEX/MEMMEM/WBCPU (datapath)IFIDEXMEMWBPipeline CycleClock CycleRitardo dello stadio piùlentoRegistri(Pipeline)Registers)ReticombinatorieN.B. architettura TOTALMENTEdiversa !!!!!",pipeliningin lxattivit aa nistruzioni ii idt idealmente datapathi pipeline cycle clock cycle ritardo stadio pilento architettura ediversa
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#8,8,"Pipeline del DLXInstr iInstr i+1Instr i+2Instr i+3Instr i+4IFIDEXMEMWB
Tclk=  Td  +  TP+  TsuClock CycleCPI (ideale)  = 1
Overhead introdotto dai Pipeline Registers:Ritardo registroa monteSet-up registro a valleRitardo stadio combinatorio più lentoIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBt",pipeline instr instr instr instr instr tclk tsu clock cycle ideale overhead introdotto pipeline registroa monte set registro valle ritardo stadio combinatorio lento wbt
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#9,9,DDRCTp,ctp
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#0,0,"Machine Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning: Introduzione
1",machine learning universit roma tre dipartimento ingegneria anno accademico deep learning introduzione
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#1,1,"Sommario
Informazioni sul corso  
Programma, testi consigliati, precondizioni  
Software tools  
Cos'è il deep learning  
Representation learning  
Autoencoders  
Factors of variation  
Approcci di IA ed evoluzione delle architetture  
Curse dimensionality  
Local constancy & smoothness regularization  
Libreria D2L",sommario informazioni corso programma testi consigliati precondizioni software tools cos deep learning representation learning autoencoders factors variation approcci evoluzione architetture curse dimensionality local constancy smoothness regularization libreria
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#10,10,"Google Colaboratory (o Colab)  
",google colaboratory colab
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#11,11,"Google Colaboratory (o Colab)  
GPUs includes Tesla 
 P100
  (used in Colab), Tesla 
 V100
  (equipped in 
Amazon EC2 P3 instance), and Tesla 
 T4
 (equipped in Amazon EC2 
G4 instance). 
 TPUs
  are tensor processing units developed by Google 
to accelerate operations on a Tensor
 ﬂ
ow Graph. Each TPU packs up 
to 180 tera
 ﬂ
ops of 
 ﬂ
oating-point performance and 64 GB of high-
bandwidth memory onto a single board.
",google colaboratory colab pus includes tesla used colab tesla equipped amazon instance tesla equipped amazon instance pus tensor processing units developed google accelerate operations tensor graph packs tera ops oating point performance high bandwidth memory onto single board
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#12,12,"Cos'è il Deep Learning
Il 
machine learning
  riguarda tecnologie capaci di acquisire conoscenza 
relativamente all'ambiente di interesse allo scopo di risolvere problemi in 
modo automatizzato, cioè senza l'intervento dell'utente.  
Per problemi complessi occorre rappresentare la conoscenza come 
concetti su vari livelli di astrazione, creando dipendenze tra gli stessi, in 
modo simile a come avviene nella mente umana.  
Da queste strutture deriva il termine 
 deep learning
 . 
Storicamente i computer sono stati impiegati per rappresentare conoscenza 
formale (es. regole per giocare a scacchi) su cui implementare meccanismi 
di 
reasoning
  (es. regole logiche) mentre è stato più dif
 ﬁ
cile rappresentare la 
conoscenza informale.  
Esempio: Cyc inference engine e ""Fred shaving in the morning""
13",cos deep learning machine learning riguarda tecnologie capaci acquisire conoscenza relativamente allambiente interesse scopo risolvere problemi modo automatizzato cio senza lintervento dellutente problemi complessi occorre rappresentare conoscenza concetti vari livelli astrazione creando dipendenze stessi modo simile avviene mente umana strutture deriva termine deep learning storicamente computer stati impiegati rappresentare conoscenza formale regole giocare scacchi implementare meccanismi reasoning regole logiche mentre stato dif cile rappresentare conoscenza informale esempio cyc inference engine fred shaving morning
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#13,13,"Representation learning (1)
Successivamente sono state introdotte tecniche di machine learning per 
acquisire la conoscenza (
 know-how
 ) estraendo 
 patterns
  dai dati in modo 
automatico, es. logistic regression e naive Bayes.  
Le prestazioni di tali approcci dipendono dalla scelta con cui i dati sono 
rappresentati. È importanti scegliere le informazioni più rilevanti (
 features
 ) 
per il task che si intende risolvere (approccio 
 hand-designed
 ). 
LXI + XCIX = ?  
Per alcuni task de
 ﬁ
nire una rappresentazione dei task è arduo.  
Es. identi
 ﬁ
care un auto potrebbe ridursi al task di riconoscere le ruote; 
come puoi farlo a partire da una rappresentazione a pixel?  
A differenza del hand-designed, il 
 representation learning
  introduce un 
sotto-task nel processo di ML che mira a riconoscere le feature più rilevanti 
in modo automatico. 
14",representation learning successivamente state introdotte tecniche machine learning acquisire conoscenza know estraendo patterns dati modo automatico logistic regression naive bayes prestazioni tali approcci dipendono scelta dati rappresentati importanti scegliere informazioni rilevanti features task intende risolvere approccio hand designed alcuni task nire task arduo identi care auto potrebbe ridursi task riconoscere ruote puoi farlo partire pixel differenza hand designed representation learning introduce sotto task processo mira riconoscere feature rilevanti modo automatico
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#14,14,"Representation learning (2)
Identi
 ﬁ
care le features in modo automatico garantisce vantaggi:  
L'approccio hand-designed è lungo e richiede risorse  
Si può facilmente adattare l'addestramento a nuovi tasks
15",representation learning identi care features modo automatico garantisce vantaggi lapproccio hand designed lungo richiede risorse pu facilmente adattare laddestramento nuovi tasks
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#15,15,"Autoencoders
Gli 
autoencoders
  sono composti da un 
 encoder
  e un 
 decoder
 . Il primo 
converte l'input in una rappresentazione compatta, cioè con 
dimensionalità ridotta,, il decoder mira a ricostruire l'input originale da tale 
rappresentazione.  
L'addestramento degli autoencoders crea uno 
 spazio 
 che mira a 
rappresentare solo le features salienti necessarie per identi
 ﬁ
care una certa 
istanza, tralasciando informazioni non utili.  
Nel corso vedremo diversi tipi di autoencoders. Le 
 Generative Adversarial 
Network (GAN)
  impiegano tali tecnologie.
16",autoencoders autoencoders composti encoder decoder primo converte linput compatta cio dimensionalit ridotta decoder mira ricostruire linput originale tale laddestramento autoencoders crea spazio mira rappresentare solo features salienti necessarie identi care certa istanza tralasciando informazioni utili corso vedremo diversi tipi autoencoders generative adversarial network impiegano tali tecnologie
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#16,16,"Factors of variation
Le features identi
 ﬁ
cate con un approccio hand-designed, oppure 
riconosciute in modo automatico durante il learning, devono saper 
distinguere i 
 fattori di variazione
 . 
Sono spesso considerati degli elementi astratti (non misurabili) che 
in
ﬂ
uenzano il modo in cui le istanze vengono viste dagli approcci di ML. 
Se identi
 ﬁ
cati ci permettono di capire meglio la grande variabilità di 
istanze in certi domini.  
Ad esempio, età, sesso, un certo accento possono in
 ﬂ
uenzare le parole 
pronunciate da una certa persona in un task di speech-recognition. 
Osservando un automobile, la posizione, il colore, l'angolo di incidenza 
dei raggi solari sono altri tipici fattori per l'analisi di una immagine.  
Se riusciamo a riconoscerli e ignorarli durante il processamento saremmo 
in grado di sempli
 ﬁ
care molti task di ML.
17",factors variation features identi cate approccio hand designed oppure riconosciute modo automatico durante learning devono saper distinguere fattori variazione spesso considerati elementi astratti non misurabili uenzano modo istanze vengono viste approcci identi cati permettono capire meglio grande variabilit istanze certi domini esempio et sesso certo accento possono uenzare parole pronunciate certa persona task speech recognition osservando automobile posizione colore langolo incidenza raggi solari altri tipici fattori lanalisi immagine riusciamo riconoscerli ignorarli durante processamento grado sempli care molti task
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#17,17,"Esercizio
Prova a identi
 ﬁ
care un ulteriore task adatto ad un approccio di ML, ed 
elenca qualche fattore di variazione. 
18",esercizio prova identi care ulteriore task adatto approccio elenca qualche fattore variazione
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#18,18,"Deep Learning
Il Deep learning segue un approccio di 
 representation learning
 , dove certe 
rappresentazioni sono espresse mediante altre più semplici, es., l'immagine 
di un uomo viene composta da angoli e contorni, che a sua volta sono 
rappresentati con piccoli segmenti.  
Un esempio di una architettura Deep, il 
 multilayer perception:
19
Immagine tratta da Zeiler and Fergus (2014).",deep learning deep learning segue approccio representation learning certe espresse mediante altre semplici limmagine uomo viene composta angoli contorni volta rappresentati piccoli segmenti esempio architettura deep multilayer perception immagine tratta zeiler fergus
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#19,19,"Schema sempli
 ﬁ
cato approcci di IA
I box scuri includono fasi esplicite di apprendimento.
20
",schema sempli cato approcci box scuri includono fasi esplicite apprendimento
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#2,2,"Il corso
L'obiettivo del 
 corso di Deep Learning (DL)
  di 6 CFU è fornire competenze 
avanzate e speci
 ﬁ
che nell'ambito delle architetture di reti neurali Deep.  
Il corso è strutturato in una parte teorica e 
 metodologica
  sui concetti 
fondamentali, e da una 
 attività di programmazione 
 in cui tali concetti sono 
applicati nella risoluzione di problemi mediante recenti framework di 
sviluppo (Keras & PyTorch).  
Al termine del corso lo studente sarà in grado di:  
addestrare e ottimizzare in maniera adeguata reti neurali Deep;  
saper distinguere tra diverse soluzioni, e saper selezionare e 
personalizzare le architetture di reti più ef
 ﬁ
caci da utilizzare in ambiti 
applicativi reali, supervised, unsupervised o seguendo un approccio 
basato su un apprendimento per rinforzo.  
Il corso prevede lo svolgimento di progetti.
3",corso lobiettivo corso deep learning fornire competenze avanzate speci nellambito architetture reti neurali deep corso strutturato parte teorica metodologica concetti fondamentali attivit programmazione tali concetti applicati risoluzione problemi mediante recenti framework sviluppo keras torch termine corso studente grado addestrare ottimizzare maniera adeguata reti neurali deep saper distinguere diverse soluzioni saper selezionare personalizzare architetture reti caci utilizzare ambiti applicativi reali supervised unsupervised seguendo approccio basato apprendimento rinforzo corso prevede svolgimento progetti
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#20,20,"Evoluzione delle architetture
Ogni 2,4 anni il numero di neuroni nascosti è all'incirca raddoppiato.
21
",evoluzione architetture ogni anni numero neuroni nascosti allincirca raddoppiato
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#21,21,"I.A. & Big Data: il contesto attuale
2222
",big data contesto attuale
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#22,22,"Curse of dimensionality
Nei corsi di I.A. e M.L. sono stati descritti numerosi algoritmi che si 
adattano facilmente i vari task. Ma solo pochi riescono ad affrontare 
problemi centrali come riconoscere il parlato od oggetti arbitrari.  
Tali task causano il cosiddetto 
 curse of dimensionality
 : il numero di 
potenziali con
 ﬁ
gurazioni di variabili di ingresso cresce in modo 
esponenziali col numero di variabili considerate.  
Ne segue: istanze di training << # potenziali con
 ﬁ
gurazioni 
23
Incrementando il numero di dimensioni (da 1d a 3d) il 
numero di regioni di interesse (box colorati) incrementa, 
e abbiamo necessità di un numero elevato di istanze per 
caratterizzarne ognuna.",curse dimensionality corsi stati descritti numerosi algoritmi adattano facilmente vari task solo pochi riescono affrontare problemi centrali riconoscere parlato oggetti arbitrari tali task causano cosiddetto curse dimensionality numero potenziali gurazioni variabili ingresso cresce modo esponenziali numero variabili considerate segue istanze training potenziali gurazioni incrementando numero dimensioni numero regioni interesse box colorati incrementa necessit numero elevato istanze caratterizzarne ognuna
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#23,23,"Local constancy & Smoothness regularization
Imponiamo che la distribuzione di probabilità a priori, che in
 ﬂ
uenza i 
parametri ma anche la funzione che stiamo cercando di stimare, sia 
smoothness prior
  o 
local constancy prior
 . 
Sotto questa assunzione, se l'output di una funzione è OK per una certa 
istanza 
 x
, allora l'output è buono anche per istanze vicine ad 
 x
: 
Esempio
 : algoritmo di 
 k
-nearest neighbors.  
Per dimensionalità elevate, una funzione smooth potrebbe cambiare (in 
modo smooth) in modo diverso a seconda della dimensione. Occorrono 
molte istanze di training per caratterizzarle.  
Il deep learning introduce dipendenze tra le regioni di interesse (cioè nelle 
distribuzioni dei dati) per ridurre il numero di istanze necessarie. 
24
",local constancy smoothness regularization imponiamo distribuzione probabilit priori uenza parametri funzione cercando stimare smoothness prior local constancy prior sotto assunzione loutput funzione certa istanza allora loutput buono istanze vicine esempio algoritmo nearest neighbors dimensionalit elevate funzione smooth potrebbe cambiare modo smooth modo diverso seconda dimensione occorrono molte istanze training deep learning introduce dipendenze regioni interesse cio distribuzioni dati ridurre numero istanze necessarie
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#24,24,"La libreria D2L
Durante il corso faremo uso di una libreria Python di supporto chiamata 
D2L.ai  
La libreria d2l mette a disposizione alcune funzionalità per rendere il 
codice più interpretabile e compatto.  
Vediamone alcuni esempi di impiego:  
01-d2l_3.2.ipynb  
02-d2l_regressione_3.3.ipynb
25",libreria durante corso uso libreria python supporto chiamata lai libreria mette disposizione alcune funzionalit rendere codice interpretabile compatto vediamone alcuni esempi impiego dlipynb
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#3,3,"Il programma
4
",programma
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#4,4,"Testi consigliati e altri riferimenti
• I. Goodfellow, Y. Bengio, and A. Courville, ""Deep Learning"", MIT Press, 
2016.  
• A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola, ""Dive into Deep Learning"", 
2020 (free online).  
• A. Geron, “Hands-on Machine Learning with Scikit-Learn, Keras, and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems”, 
O'Reilly Media, Inc, USA, 2019.  
• M. Nielsen, ""Neural Networks and Deep Learning"", 2019 (free online).  
Altri riferimenti a codice, tutorial, e altre fonti saranno dati durante il corso.
5",testi consigliati altri riferimenti goodfellow bengio courville deep learning press zhang lipton smola dive deep learning free online geron hands machine learning scikit learn keras tensor flow concepts tools techniques build intelligent systems oreilly media inc nielsen neural networks deep learning free online altri riferimenti codice tutorial altre fonti dati durante corso
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#5,5,"Precondizioni
Le seguenti lezioni del corso di Machine Learning sono requisiti per il 
corso di DL:  
Introduzione alla Regressione  
La Valutazione nella Regressione  
Over
 ﬁ
tting, Cross Validation  
Introduzione alle Reti Neurali Arti
 ﬁ
ciali (es. algoritmo di 
backpropagation)  
Sebbene alcuni dei concetti saranno ripresi per introdurre i formalismi 
necessari al resto del corso.
6",precondizioni seguenti lezioni corso machine learning requisiti corso introduzione regressione valutazione regressione tting cross validation introduzione reti neurali arti ciali algoritmo sebbene alcuni concetti ripresi introdurre formalismi necessari resto corso
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#6,6,"Software Tools
Docker  
https://www.docker.com/community-edition#/download  
Jupyter Notebook Scienti
 ﬁ
c Python Stack + Tensor
 ﬂ
ow + Tensorboard  
https://github.com/lspvic/jupyter_tensorboard  
docker pull lspvic/tensorboard-noteboo
 k
docker run -it --rm -p 8888:8888 lspvic/tensorboard-noteboo
 k
Docker Engine Utility for NVIDIA GPUs  
https://github.com/NVIDIA/nvidia-docker   
Anaconda + Tensor
 ﬂ
ow 
https://docs.anaconda.com/anaconda/user-guide/tasks/tensor
 ﬂ
ow/ 
",software tools docker jupyter notebook scienti python stack tensor tensorboard docker pull noteboo docker run noteboo docker engine utility pus anvidia docker anaconda tensor
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#7,7,"Jupiter
https://jupyter.readthedocs.io/en/latest/  
",jupiter
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#8,8,"Google Colaboratory (o Colab)  
Servizio di calcolo online basato su Nvidia Tesla T4 GPUs  
12 GB of RAM  
ﬁ
no a 12 ore di seguito  
Supporto multi-ambiente: TensorFlow, Keras, PyTorch, e OpenCV.  
Molti dataset disponibili nell'ambiente  
https://www.tensor
 ﬂ
ow.org/datasets/catalog/overview   
Interfaccia Jupyter ben nota.  
Default: Runtime Python 3 e nessun acceleratore hardware.  
Menu Runtime -> Change runtime type  
Possibilità di trasferire l’esecuzione in locale (per elaborazioni molto 
lunghe)  
https://research.google.com/colaboratory/local-runtimes.html  
",google colaboratory colab servizio calcolo online basato nvidia tesla pus ore seguito supporto multi ambiente tensor flow keras torch open molti dataset disponibili nellambiente interfaccia jupyter ben nota default runtime python nessun acceleratore hardware menu runtime change runtime type possibilit trasferire lesecuzione locale per elaborazioni molto lunghe runtimeshtml
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#9,9,"Google Colaboratory (o Colab)  
Acceleratore: GPU
",google colaboratory colab acceleratore
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Multilayer Perceptrons, One-hot encoding e Softmax
1",deep learning universit roma tre dipartimento ingegneria anno accademico multilayer perceptrons one hot encoding softmax
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#1,1,"Sommario
Monotonicità  
MLP e Hidden layers  
Non linearità  
Funzioni di attivazione  
Datasets  
MLP e Tensor
 ﬂ
ow 
Da regressione lineare a classi
 ﬁ
cazione  
Funziona softmax  
One-hot encoding e misure di distanza",sommario monotonicit hidden layers linearit funzioni attivazione datasets tensor regressione lineare classi cazione funziona softmax one hot encoding misure distanza
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#10,10,"Alcuni toy datasets 
Elenchiamo alcuni dataset che vengono spesso impiegati negli approcci di 
ML e DL:  
MNIST  
notMNIST  
fashion-MNIST  
Dataset più complessi saranno introdotti più avanti. 
11",alcuni toy datasets elenchiamo alcuni dataset vengono spesso impiegati approcci fashion dataset complessi introdotti avanti
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#11,11,"Dataset MNIST
Composto da cifre numeriche, usato per addestrare sistemi OCR.  
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others.""  
Contiene 60K immagini di addestramento e 10K di training.  
1998: un linear classi
 ﬁ
er ha ottenuto 7.6% di errore rate.  
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%.  
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono 
centrate in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare 
una cifra.  
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12",dataset composto cifre numeriche usato addestrare sistemi work work all well work may still fail others contiene immagini addestramento training linear classi ottenuto errore rate mezzo architettura convolutional neural networks arrivati ogni immagine rappresentata scala grigi livelli cifre centrate box pixel valori rappresentare cifra recognizerdata implementazione online ott nethtml
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#12,12,"Dataset MNIST: train.csv e test.csv
Il 
ﬁ
le train.csv contiene una matrice con 785 colonne. La prima colonna è il 
label
 della cifra (es. 3) e le restanti colonne sono la rappresentazione 
sequenziale dell’immagine:  
Il 
ﬁ
le test.csv ha la stessa rappresentazione senza la prima colonna.  
Esempio di immagini:
13
",dataset traincsv testcsv traincsv contiene matrice colonne prima colonna label cifra restanti colonne sequenziale dellimmagine testcsv stessa senza prima colonna esempio immagini
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#13,13,"Dataset MNIST - svantaggi
Troppo semplice: algoritmi classici di ML raggiungono i 97% di precisione, 
architetture DL il 99.7%  
Si rischia di ideare nuove architetture adatte solo per questo dataset e 
dif
ﬁ
cilmente adattabili in altri contesti.  
Molto diverso dai task studiati attualmente nell’ambito del DL.
14",dataset svantaggi troppo semplice algoritmi classici raggiungono precisione architetture rischia ideare nuove architetture adatte solo dataset dif cilmente adattabili altri contesti molto diverso task studiati attualmente nellambito
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#14,14,"Dataset notMNIST
Simile a MNIST: contiene 10 labels (lettere da A a J), ma ogni lettera nel 
dataset ha un font molto diverso dalle altre, es.:  
http://yaroslavvb.blogspot.
 ﬁ
/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione  
notMNIST_small.tar.gz -> test 
15
",dataset simile contiene labels lettere ogni lettera dataset font molto diverso altre datasethtml download tlargetargz training validazione tsmalltargz test
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#15,15,"Dataset fashion-MNIST
Fornito da Zalando: 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc).  
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST:  
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
16
",dataset fashion fornito zalando classi riferimento generi vestiario sandali shirt borse etc contiene immagini addestramento training ogni immagine rappresentata scala grigi pixel mnist side side accuracy fashion httpfashion mnists websiteeu central
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#16,16,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes.  
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su WordNet. In 
media 1K immagini per concetto.  
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi.  
Open Image
 : 9 milioni di URLs di immagini annotate con bounding boxes e 
migliaia di classi.  
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 questions 
per immagini con 10 ground truth answers per question.  
The Street View House Numbers
 : 600K immagini di numeri civici.  
Risultati sperimentali ottenuti per varie architetture  
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
17",altri dataset popolari immagini colour images classes image net milioni immagini organizzate etichettate word net media immagini concetto task milioni immagini classi open image milioni rls immagini annotate bounding boxes migliaia classi visual open ended questions immagini media questions immagini ground truth answers question street view house numbers immagini numeri civici risultati sperimentali ottenuti varie architetture
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#17,17,"MLP e Tensor
 ﬂ
ow
Proviamo a costruire una MLP con Tensor
 ﬂ
ow (Keras).  
Coalb 04-mlp_5.2.1.ipynb
18",tensor proviamo costruire tensor keras coalb mlpipynb
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#18,18,"Da regressione lineare a classi
 ﬁ
cazione
Nei problemi di regressione rispondiamo a domande del tipo ""
 Quale 
quantità o valore?
 "". Ma molti problemi mirano a trovare una classe di 
appartenenza,  
es. è una email di spam? è più probabile che un utente si iscriva ad un 
abbonamento oppure no?  
Ci può interessare la classe più verosimile (
 hard assignements
 ), oppure la 
distribuzione di probabilità sulle classi possibili (
 soft assignements
 ), o siamo 
in presenza di più classi di appartenenza (
 multi-label classi
 ﬁ
cation
 ). 
In caso di più valori in output (es. un layer di output con più nodi), ogni 
valore può essere interpretato come 
 il grado di appartenenza dell'istanza in 
ingresso ad una certa classe
 . La loss misura il discostamento tra classe attesa 
e valori prodotti dal modello. 
19",regressione lineare classi cazione problemi regressione rispondiamo domande tipo quantit valore molti problemi mirano trovare classe appartenenza email spam probabile utente iscriva abbonamento oppure pu interessare classe verosimile hard assignements oppure distribuzione probabilit classi possibili soft assignements presenza classi appartenenza multi label classi cation caso valori output layer output nodi ogni valore pu essere interpretato grado appartenenza dellistanza ingresso certa classe loss misura discostamento classe attesa valori prodotti modello
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#19,19,"Classi
 ﬁ
cazione binaria
Si ha interesse ad associare una istanza in input ad un valore in y
 ∈
{0,1} 
Se usiamo un modello di regressione, estraiamo dall'istanza x features 
numeriche e le combinano linearmente. Il risultato dipende dalle somme 
dei valori di input e dei parametri del modello.  
Al risultato del modello applichiamo la funzione 
 logistic
 , che restituisce un 
valore in [0,1]. La funzione è facilmente differenziabile.  
Interpretiamo tale valore come la probabilità di appartenenza ad una delle 
due classi.  
Si ottiene una 
 logistic regression
 . 
Vogliamo generallizzare la logistic regression al caso K classi, con K>2
20!""=	argmax!*(!|-)",classi cazione binaria interesse associare istanza input valore usiamo modello regressione estraiamo dallistanza features numeriche combinano linearmente risultato dipende somme valori input parametri modello risultato modello applichiamo funzione logistic restituisce valore funzione facilmente interpretiamo tale valore probabilit appartenenza due classi ottiene logistic regression vogliamo generallizzare logistic regression caso classi argmax
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#2,2,"Motivazioni
Tale dispensa richiama in modo sommario molti concetti trattati nel corso di 
ML con particolare attenzione ai concetti che interessano maggiormente lo 
sviluppo di architetture DL (architetture MLP).  
Si rimanda al materiale del corso di ML per i dettagli
3",motivazioni tale dispensa richiama modo sommario molti concetti trattati corso particolare attenzione concetti interessano maggiormente sviluppo architetture architetture rimanda materiale corso dettagli
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#20,20,"Esempio  
Supponiamo di avere 3 classi e l’output della combinazione lineare sia:  
Sebbene la classe più probabile sia associata all’indice 1, i valori non sono 
direttamente interpretabili come distribuzioni di probabilità, infatti:  
I valori non sono in in [0,1]  
La somma non è pari 1
21y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥",esempio supponiamo avere classi loutput combinazione lineare sia sebbene classe probabile associata allindice valori direttamente interpretabili distribuzioni probabilit infatti valori somma pari
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#21,21,"La funzione Softmax
La funzione 
 softmax
  prende in input un vettore in 
 ℝ
T
 e dà in output un 
vettore 
 ℝ
T  
nell'intervallo (0,1] la cui somma è pari a 1. È de
 ﬁ
nita: 
L'output può essere interpretato come distribuzione di probabilità su K 
classi, a differenza di altri modelli (es. classi
 ﬁ
catore SVM).
22S(yi)=eyi
eyj
jK
∑",funzione softmax funzione softmax prende input vettore output vettore nellintervallo somma pari nita loutput pu essere interpretato distribuzione probabilit classi differenza altri modelli classi catore syieyi eyj
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#22,22,"Layer softmax nelle reti neurali
La funzione softmax è tipicamente applicata all’output di un layer fully-
connected, creando un nuovo layer chiamato 
 softmax
 . 
Il seguente esempio rappresenta un singolo layer, con funzione di attivazione 
softmax su T classi.  
Nota
 : la funzione softmax introduce non linearità.
23
y s(y)",layer softmax reti neurali funzione softmax tipicamente applicata alloutput layer fully connected creando nuovo layer chiamato softmax seguente esempio rappresenta singolo layer funzione attivazione softmax classi nota funzione softmax introduce linearit
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#23,23,"Softmax in Keras
In Keras è semplice implementare il modello precedente con il parametro 
activation
  di layer Dense:  
24
",softmax keras keras semplice implementare modello precedente parametro activation layer dense
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#24,24,"One-hot encoding
Nel ML le rappresentazioni dell’input e output sono sottoinsiemi dei 
domini 
 ℕ
 e 
ℝ
. Tali insieme introducono implicitamente ordinamenti.  
Es. se abbiamo 3 categorie (es. rosso=1, bianco=2 e nero=3) e gli 
assegniamo 3 numeri, introduciamo una relazione di ordinamento che 
non esiste nei dati.  
Durante l’addestramento tali relazioni possono essere considerate 
potenziali features, e di conseguenza apprese dall'algoritmo  
Es. Le due istanze Rosso-Nero possono considerarsi più distanti rispetto 
a Rosso-Bianco  
La rappresentazione 
 one-hot
  caratterizza ogni istanza con una 
con
ﬁ
gurazione univoca, costituita da una sequenza binaria di zero, tranne 
un solo elemento pari a 1.
25",one hot encoding dellinput output sottoinsiemi domini tali insieme introducono implicitamente ordinamenti categorie rosso bianco nero assegniamo numeri introduciamo relazione ordinamento esiste dati durante laddestramento tali relazioni possono essere considerate potenziali features conseguenza apprese dallalgoritmo due istanze rosso nero possono considerarsi distanti rispetto rosso bianco one hot caratterizza ogni istanza gurazione univoca costituita sequenza binaria zero tranne solo elemento pari
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#25,25,"One-hot encoding in Python
Colab 05_onehot.ipynb
26",one hot encoding python colab onehotipynb
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#26,26,"Loss e one-hot encoding
Se la 
 softmax
  genera una distribuzione di probabilità su K possibili, la 
codi
ﬁ
ca one-hot genera una distribuzione che ""concentra"" tutta la densità di 
probabilità sulle classi corrette, es.:  
[0, …, 0, 1, 0 …, 0].  
Per addestrare il modello occorre de
 ﬁ
nire una misura di loss che tenga conto 
della distanza tra le due distribuzioni.
27",loss one hot encoding softmax genera distribuzione probabilit possibili codi one hot genera distribuzione concentra tutta densit probabilit classi corrette addestrare modello occorre nire misura loss tenga conto distanza due distribuzioni
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#27,27,"Misura di Distanza: cross entropy
Per confrontare due generici vettori 
 p
 e 
q
 che rappresentano distribuzioni di 
probabilità si impiega la misura 
 cross entropy
 : 
Dove 
 x
 si estende su tutte i valori potenziali della variabile causale su cui 
sono de
 ﬁ
nite le probabilità, cioè le classi in output.  
Attenzione: la funzione H non è simmetrica:  
Se uno dei parametri (
 p
 o 
q
) è codi
 ﬁ
cato one-hot, in che posizione conviene 
averlo?
28H(p,q)≠H(q,p)H(p,q)=−p
x∑ (x)⋅log	q(x)",misura distanza cross entropy confrontare due generici vettori rappresentano distribuzioni probabilit impiega misura cross entropy estende tutte valori potenziali variabile causale nite probabilit cio classi output attenzione funzione simmetrica parametri codi cato one hot posizione conviene averlo xlog
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#28,28,"Misura di Distanza: cross entropy
Nella fase di addestramento un parametro della cross entropy è l’output 
della funzione softmax s(y), mentre il secondo è la codi
 ﬁ
ca one-hot che 
indica una o più classi di appartenenza.  
Supponiamo di usare la codi
 ﬁ
ca one-hot per il calcolo dei logaritmi:  
Anche il layer softmax può generare valori 0, ma è un problema raro e 
facilmente risolvibile (es. aggiungendo un 
 ε
).
29D(s(y),ˆy)=−s(y1)⋅log	1.0+s(y2)⋅log	0+s(y3)⋅log	0 ( ) ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥",misura distanza cross entropy fase addestramento parametro cross entropy loutput funzione softmax mentre secondo codi one hot indica classi appartenenza supponiamo usare codi one hot calcolo logaritmi layer softmax pu generare valori problema raro facilmente risolvibile aggiungendo sylog sylog
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#29,29,"Multinomial logistic classi
 ﬁ
cation
30x=2.0
0.7
1.5
...
8.0⎡
⎣⎢
⎢
⎢
⎢
⎢
⎢⎤
⎦⎥
⎥
⎥
⎥
⎥
⎥S(y)=0.659
0.242
0.099⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥D(ˆy,S(y))Input
Linear model Softmax Onehot rep.
Cross entropy distanceLabels",multinomial logistic classi cation sy y linear model softmax onehot rep cross entropy distance labels
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#3,3,"Monotonicità
Le architetture lineare impongono l'assunzione di 
 monotonicità
 : 
l'incremento di una feature generare un incremento/decremento nel valore 
in output del modello, a seconda del valore dei pesi (o parametri).  
Per certi task è verosimile, sebbene non sempre vero, ad esempio:  
Task: ""
 un individuo sarà regolare con le rate del mutuo?
 "". Se il salario 
passa da 0K a 50K la probabilità che ripaghi il mutuo sarà molto diversa; 
mentre se il salario passa da 1M a 1,05M la probabilità non cambierà 
molto.  
Task: ""
 predire se un individuo è malato in base alla temperatura
 "".  
T << 37 o T >> 37 indica una possibile patologia.  
Come pensi si può risolvere il problema impiegando un algoritmo di 
regressione lineare?
4",monotonicit architetture lineare impongono lassunzione monotonicit lincremento feature generare valore output modello seconda valore pesi parametri certi task verosimile sebbene sempre vero esempio task individuo regolare rate mutuo salario passa probabilit ripaghi mutuo molto diversa mentre salario passa probabilit cambier molto task predire individuo malato base temperatura indica possibile patologia pensi pu risolvere problema impiegando algoritmo regressione lineare
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#30,30,"Esercizio
Supponiamo di avere 3 istanze di addestramento che consistono in varie 
features (es. sex, age, etc) e vogliamo predire se un elettore voterà 
democratico o repubblicano con una rete neurale.  
Avendo due reti che producono in output i seguenti valori:  
Calcola l’errore impiegando: (1) cross entropy, (2) mean squared error, (3) 
accuratezza (binaria).
31
#1
#2",esercizio supponiamo avere istanze addestramento consistono varie features sex age etc vogliamo predire elettore voter democratico repubblicano rete neurale due reti producono output seguenti valori calcola lerrore impiegando cross entropy mean squared error accuratezza binaria
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#31,31,"Confronto tra misure di loss
Cross entropy  
#1: -(ln(0.4) + ln(0.4) + ln(0.1)) / 3 = 1.38  
#2: -(ln(0.7) + ln(0.7) + ln(0.3)) / 3 = 0.64 (smaller)  
Mean squared error  
#1: [(0.3 - 0)^2 + (0.3 - 0)^2 + (0.4 - 1)^2 + …] / 3  
(0.54 + 0.54 + 1.34) / 3 = 0.81  
#2: (0.14 + 0.14 + 0.74) / 3 = 0.34 (smaller)  
Accuratezza (binaria)  
Entrambi: classi
 ﬁ
cation error 1/3 = 0.33, accuracy 2/3 = 0.67  
Nota
 : le implementazione delle misure discusse sono in 
 sklearn.metrics  
32",confronto misure loss cross entropy smaller mean squared error smaller accuratezza binaria entrambi classi cation error accuracy nota implementazione misure discusse sklearnmetrics
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#32,32,"Confronto tra misure di loss
Cross entropy  
#1: 1.38  
#2: 0.64 (migliore)  
Mean squared error  
#1: 0.81  
#2: 0.34 (migliore)  
Accuratezza (binaria)  
Entrambi: 0.67  
Rispetto alla cross entropy, MSE da molta importanza agli output sbagliati, 
ma allo stesso tempo, se la rete si avvicina ai risultati corretti, i gradienti 
diventano assai bassi, rallentando notevolmente la convergenza.
33
#1
#2",confronto misure loss cross entropy migliore mean squared error migliore accuratezza binaria entrambi rispetto cross entropy molta importanza output sbagliati stesso tempo rete avvicina risultati corretti gradienti diventano assai bassi rallentando notevolmente convergenza
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#4,4,"Monotonicità
Per un task ""
 l'immagine contiene un cane
 ?"", come possiamo creare una 
relazione tra un certo pixel è una classe in output?  
L'assunzione di linearità ci impone un vincolo tra:  
luminosità del pixel <-> classe di appartenenza;  
ignorando però il contesto (altri pixel) e la complesse relazioni tra essi che 
portano a rappresentare visivamente un oggetto.  
Invece di de
 ﬁ
nire una rappresentazione adeguata, impieghiamo reti neurali 
multistrato
 , dove gli 
 hidden layer
  si occupano di riconoscere una 
rappresentazione adeguata dei dati in input, che viene impiegata da un 
predittore lineare per generare l'output. 
5",monotonicit task limmagine contiene cane possiamo creare relazione certo pixel classe output lassunzione linearit impone vincolo tra luminosit pixel classe appartenenza ignorando per contesto altri pixel complesse relazioni essi portano rappresentare visivamente oggetto invece nire adeguata impieghiamo reti neurali multistrato hidden layer occupano riconoscere adeguata dati input viene impiegata predittore lineare generare loutput
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#5,5,"Hidden layers e MLP
L'approccio più semplice per aggiungere strati nascosti è 
 impilarli
  (stack) uno 
dopo l'altro, ottenendo L layers.  
Interpretiamo gli L layer, tranne l'ultimo, come l'insieme di nodi impiegati 
per la rappresentazione, e l'ultimo come predittore lineare.  
Otteniamo una architettura 
 Multilayer perceptron (MLP)
  fully connected.
6
",hidden layers lapproccio semplice aggiungere strati nascosti impilarli stack dopo laltro ottenendo layers interpretiamo layer tranne lultimo linsieme nodi impiegati lultimo predittore lineare otteniamo architettura multilayer perceptron fully connected
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#6,6,"Da lineare a non lineare
Indichiamo con 
  un 
minibatch
  (una sottoinsieme del dataset di 
training) di 
 n
 istanze dove ogni istanza ha 
 d
 features.  
Per un hidden layer con 
 h
 unità, indichiamo con 
  il relativo 
output. Avendo layer fully connected, abbiamo come parametri:  
i pesi 
   e i  bias 
  . 
Il layer di output avrà parametri:   
    e    
L'output è ricavato nel seguente modo:  
 
 
Secondo te, combinando più funzioni af
 ﬁ
ni, siamo riusciti a introdurre non 
linearità nel modello?
X
∈
ℝ
n
×
d
H
∈
ℝ
n
×
h
W
(
1
)
∈
ℝ
d
×
h
b
(
1
)
∈
ℝ
1
×
h
W
(
2
)
∈
ℝ
h
×
q
b
(
2
)
∈
ℝ
1
×
q
H
=
X
W
(
1
)
+
b
(
1
)
O
=
H
W
(
2
)
+
b
(
2
)
7",lineare lineare indichiamo minibatch una sottoinsieme dataset training istanze ogni istanza features hidden layer unit indichiamo relativo output layer fully connected parametri pesi bias layer output parametri loutput ricavato seguente modo secondo combinando funzioni riusciti introdurre linearit modello
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#7,7,"Da lineare a non lineare
Combinando le equazioni viste in precedenza otteniamo un modello 
equivalente ad un singolo layer:  
 
La non linearità viene espressa mediante funzioni di attivazione 
  non 
lineari (es. ReLU) impiegate all'interno delle unità nascoste, a valle della 
trasformazione af
 ﬁ
ne. 
Facendo 
 stacking
  di più hidden layer con funzioni non lineari, es:  
 
 
si ottengono architetture 
 deep
 , che approssimano funzioni più complesse.
O
=
(
X
W
(
1
)
+
b
(
1
)
)
W
(
2
)
+
b
(
2
)
=
X
W
(
1
)
W
(
2
)
+
b
(
1
)
W
(
2
)
+
b
(
2
)
=
X
W
+
b
σ
H
(
1
)
=
σ
1
(
X
W
(
1
)
+
b
(
1
)
)
H
(
2
)
=
σ
2
(
H
(
1
)
W
(
2
)
+
b
(
2
)
)
8",lineare lineare combinando equazioni viste precedenza otteniamo modello equivalente singolo layer linearit viene espressa mediante funzioni attivazione lineari impiegate allinterno unit nascoste valle trasformazione stacking hidden layer funzioni lineari ottengono architetture deep approssimano funzioni complesse
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#8,8,"Universal approximators
Ci si può chiedere quanta capacità rappresentativa (i.e. quanto è 
 potente
 ) è 
espressa da una rete neurale.  
Alcuni risultati suggeriscono che 
 per
ﬁ
no con un solo hidden layer
  è possibile 
approssimare qualsiasi funzione con un numero adeguato di unità.  
Una rete neurale deep può essere pensata come un programma in C,  
cioè puoi risolvere qualsiasi problema software, ma i programmi possono 
raggiungere complessità molto elevate.  
Vedremo architetture di reti deep possono risolvere gli stessi task in modo 
molto più ef
 ﬁ
ciente. 
9",universal approximators pu chiedere capacit rappresentativa potente espressa rete neurale alcuni risultati suggeriscono solo hidden layer possibile approssimare qualsiasi funzione numero adeguato unit rete neurale deep pu essere pensata programma cio puoi risolvere qualsiasi problema software programmi possono raggiungere complessit molto elevate vedremo architetture reti deep possono risolvere task modo molto ciente
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#9,9,"Funzioni di attivazione
Ne esistono molte, ad esempio:  
Funzione Sigmoide  
Tangente iperbolica (tanh)  
Relu 
Leaky Relu  
Swish  
Relu parametrizzato  
ELU 
Softplus e Softsign  
Selu 
Gelu  
Durante il corso discuteremo pro e contro delle principali.  
Colab 03-funzioni_di_attivazione_5.1.2
10",funzioni attivazione esistono molte esempio funzione sigmoide tangente iperbolica tanh relu leaky relu swish relu parametrizzato softplus softsign selu gelu durante corso discuteremo pro principali colab
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Kayers e moduli in Keras
1",deep learning universit roma tre dipartimento ingegneria anno accademico kayers moduli keras
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#1,1,"Sommario
Moduli e Keras  
Sequential  
Moduli custom  
Gestione dei parametri: lettura, condivisione, inizializzazione  
Inizializzazione lazy  
Layer custom  
I/O 
GPU e Keras",sommario moduli keras sequential moduli custom gestione parametri lettura condivisione lazy layer custom keras
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#10,10,"Gestione dei parametri: accesso
Il loop di addestramento mira a trovare i parametri che minimizzano la funzione di 
loss. Le architetture più classiche hanno implementazioni che si occupano 
interamente della gestione dei parametri. In altri casi è necessario accedervi 
durante l'esecuzione (es. debugging, riuso dei parametri in parti diverse del 
modello).  
Vediamo come accedere ai parametri. Costruiamo un semplice modello:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
I layer nel modello sono memorizzati mediante liste. I parametri sono facilmente 
accedibili:  
net.layers[
 2
].weights       # secondo layer: 4 pesi e 1 bias  
[<tf.Variable 
 'dense_1/kernel:0'
  shape=(
 4
, 
1
) dtype=float32, numpy=  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32)>,  
 <tf.Variable 
 'dense_1/bias:0'
  shape=(
 1
,) dtype=float32, numpy=array([
 0.
], dtype=float32)>]  
11",gestione parametri accesso loop addestramento mira trovare parametri minimizzano funzione loss architetture classiche implementazioni occupano interamente gestione parametri altri casi necessario accedervi durante lesecuzione debugging riuso parametri parti diverse modello vediamo accedere parametri costruiamo semplice modello import tensorflow net netxshape layer modello memorizzati mediante liste parametri facilmente accedibili netlayers weights secondo layer pesi bias tfvariable shape dtypefloat numpy array tfvariable shape dtypefloat numpyarray
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#11,11,"Gestione dei parametri: lettura
In Keras i parametri sono salvati in particolari classi. Per ottenere il valore 
bisogna convertire le classi in tensori, ad esempio, per ottenere il bias dal 
secondo layer della rete:  
type
(net.layers[
 2
].weights[
 1
]), tf.convert_to_tensor(net.layers[
 2
].weights[
 1
]) 
(tensorflow.python.ops.resource_variable_ops.ResourceVariable,  
 <tf.Tensor: shape=(
 1
,), dtype=float32, numpy=array([
 0.
], dtype=float32)>)  
Mentre per ottenere tutti i parametri:  
net.get_weights()  
[array([[-
 0.20149094
 ,  
0.69364685
 , -
0.12403131
 ,  
0.81778544
 ], 
        [ 
 0.3347332
  ,  
0.43645364
 ,  
0.18376476
 , -
0.5020199
  ], 
        [-
 0.7681664
  , -
0.14477473
 , -
0.6313741
  ,  
0.8246415
  ], 
        [-
 0.8074637
  , -
0.20050609
 ,  
0.4308104
  ,  
0.69257575
 ]], 
       dtype=float32),  
 array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32),  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32),  
 array([
 0.
], dtype=float32)]  
12",gestione parametri lettura keras parametri salvati particolari classi ottenere valore bisogna convertire classi tensori esempio ottenere bias secondo layer rete type netlayers weights weights variable tftensor shape dtypefloat numpyarray mentre ottenere parametri array dtypefloat array dtypefloat array dtypefloat array dtypefloat
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#12,12,"Condivisione dei parametri
In alcune architetture è conveniente condividere i parametri in layer distinti, 
in modo che la modi
 ﬁ
ca dei parametri di un layer si ri
 ﬂ
etta sull'altro.  
shared = tf.keras.layers.Dense(
 4
, activation=tf.nn.relu)  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    shared,  
    shared,  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
In questo caso, i gradienti del secondo e terzo layer sono sommati.
13",condivisione parametri alcune architetture conveniente condividere parametri layer distinti modo modi parametri layer etta sullaltro shared net shared shared netx caso gradienti secondo terzo layer sommati
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#13,13,"Inizializzazione dei parametri
All'interno del modulo Python 
 keras.initializers
  sono contenute le 
implementazioni di vari tipi di inizializzazione dei parametri. Tali approcci 
dipendono solitamente dall'input e dell'output e i valori dei bias sono 
impostati a zero.  
Per default, l'inizializziazione dei parametri è basata su una distribuzione 
uniforme (
 glorot initializer
 ) nell'intervallo [-k,k], dove k = sqrt(6/(
 ﬁ
n_in + 
fan_out)).  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
Vedi: 
 https://keras.io/api/layers/initializers/  
14",parametri allinterno modulo python contenute implementazioni vari tipi parametri tali approcci dipendono solitamente dallinput delloutput valori bias impostati zero default parametri basata distribuzione uniforme glorot initializer nellintervallo sqrt nin fanout import tensorflow net netxshape vedi
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#14,14,"Inizializzazione dei parametri
Nell'esempio si impiega una inizializzazione basata su una distribuzione 
gaussiana con deviazione standard 0.01.  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.random_normal_initializer(mean=
 0
, stddev=
 0.01
), 
        bias_initializer=tf.zeros_initializer()),  
    tf.keras.layers.Dense(
 1
)]) 
net(X) 
net.weights[
 0
], net.weights[
 1
] 
(<tf.Variable 
 'dense_2/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
 array([[-
 0.00021173
 ,  
0.00316905
 , -
0.00598176
 ,  
0.00144992
 ], 
        [-
 0.00882782
 ,  
0.01484077
 , -
0.00652608
 , -
0.00581241
 ], 
        [ 
 0.00398763
 , -
0.01069997
 , -
0.01145216
 , -
0.00430671
 ], 
        [ 
 0.00342147
 , -
0.01215916
 ,  
0.01345742
 ,  
0.01632656
 ]], 
       dtype=float32)>,  
 <tf.Variable 
 'dense_2/bias:0'
  shape=(
 4
,) dtype=float32, numpy=array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32)>)  
Invece per una inizializzazione con valori costanti:  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.keras.initializers.Constant(
 1
), 
        bias_initializer=tf.zeros_initializer()),  
Nota
 : è possibile impiegare inizializzazioni distinte per ogni layer.
15",parametri nellesempio impiega basata distribuzione gaussiana deviazione standard net stddev netx netweights netweights tfvariable shape dtypefloat numpy array tfvariable shape dtypefloat numpyarray invece valori costanti nota possibile impiegare distinte ogni layer
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#15,15,"Inizializzazione dei parametri - custom
Per una inizializzazione custom dei parametri bisogna creare una classe a 
partire dalla classe Initializer, e de
 ﬁ
nire la funzione __call__() che restituisce 
il tensore in base alle dimensioni passate come parametro, es:  
class 
MyInit
(tf.keras.initializers.Initializer):  
    
 def 
__call__
 (
self
, shape, dtype=
 None
): 
        data=tf.random.uniform(shape, -
 10
, 
10
, dtype=dtype)  
        factor=(tf.abs(data) >= 
 5
) 
        factor=tf.cast(factor, tf.float32)  
        
 return
 data * factor  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, 
        activation=tf.nn.relu,  
        kernel_initializer=MyInit()),  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
print
(net.layers[
 1
].weights[
 0
]) 
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[-
 0.
       , -
 6.526873
  ,  
8.615063
  ,  
5.7617836
 ], 
       [ 
 0.
       ,  
 0.
       ,  
 6.0559807
 , -
0.
       ],  
       [-
 6.7486644
 ,  
8.665197
  ,  
0.
       , -
 7.035637
  ], 
       [-
 0.
       , -
 0.
       , -
 7.608464
  ,  
0.
       ]], dtype=float32)>  
16",parametri custom custom parametri bisogna creare classe partire classe initializer nire funzione call restituisce tensore base dimensioni passate parametro class init def call self shape dtype none dtypedtype tffloat return data factor net init netx print netlayers weights tfvariable shape dtypefloat numpy array dtypefloat
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#16,16,"Inizializzazione dei parametri - custom (2)
In alternativa si possono impostare i parametri direttamente:  
net.layers[
 1
].weights[
 0
][:].assign(net.layers[
 1
].weights[
 0
] + 
1
) 
net.layers[
 1
].weights[
 0
][
0
, 
0
].assign(
 42
) 
net.layers[
 1
].weights[
 0
] # stampa  
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[
 42.
       , -
 5.526873
  ,  
9.615063
  ,  
6.7617836
 ], 
       [ 
 1.
       ,  
 1.
       ,  
 7.0559807
 ,  
1.
       ],  
       [-
 5.7486644
 ,  
9.665197
  ,  
1.
       , -
 6.035637
  ], 
       [ 
 1.
       ,  
 1.
       , -
 6.608464
  ,  
1.
       ]], dtype=float32)>  
Nell'esempio aggiorno i pesi del primo layer (+1) e imposto uno speci
 ﬁ
co 
peso al valore 42.
17",parametri custom alternativa possono impostare parametri direttamente netlayers weights weights netlayers weights assign netlayers weights stampa tfvariable shape dtypefloat numpy array dtypefloat nellesempio aggiorno pesi primo layer imposto speci peso valore
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#17,17,"Inizializzazione lazy
Nel codice visto, il risultato di alcune istruzioni dipende da iperparametri 
quali la dimensione dei layer (es. inizializzazione dei parametri, inserire un 
layer senza indicarne il numero di nodi), sebbene tali iperparametri non 
sono esplicitamente indicati.  
Con la inizializzazione differita (o lazy) è possibile de
 ﬁ
nire una architettura 
in modo più possibile parametrico, in modo da speci
 ﬁ
care solo gli 
iperparametri essenziali e derivare gli altri in modo automatico.  
In questo esempio manca la dimensione del layer di input, perciò Keras non 
può de
 ﬁ
nire completamente gli iperparametri:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
[net.layers[i].get_weights() 
 for
 i 
in 
range
(
len
(net.layers))]  
[[], []]  
...
18",lazy codice visto risultato alcune istruzioni dipende iperparametri quali dimensione layer parametri inserire layer senza indicarne numero nodi sebbene tali iperparametri esplicitamente indicati differita lazy possibile nire architettura modo possibile parametrico modo speci care solo iperparametri essenziali derivare altri modo automatico esempio manca dimensione layer input perci keras pu nire completamente iperparametri import tensorflow net range len netlayers
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#18,18,"Inizializzazione lazy (2)
Se proviamo a de
 ﬁ
nire le dimensioni di un certo input, Keras può 
completare l'inizializzazione, ad esempio:  
X = tf.random.uniform((
 2
, 
20
)) 
net(X) 
[w.shape 
 for
 w 
in
 net.get_weights()]  
[(
20
, 
256
), (
256
,), (
256
, 
10
), (
10
,)]
19",lazy proviamo nire dimensioni certo input keras pu completare esempio netx wshape
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#19,19,"Layer custom
Possiamo de
 ﬁ
nire layer anche senza parametri da sottoporre ad 
addestramento. Nell'esempio implementiamo una sorta di normalizzazione 
sottraendo la media dai valori in input. Tale operazioni vanno inserite nella 
funzione call().  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
class 
CenteredLayer
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
call
(
self
, inputs):  
        
 return
 inputs - tf.reduce_mean(inputs)  
layer = CenteredLayer()  
layer(tf.constant([
 1.0
, 
2
, 
3
, 
4
, 
5
])) 
<tf.Tensor: shape=(
 5
,), dtype=float32, numpy=array([-
 2.
, -
1.
,  
0.
,  
1.
,  
2.
], dtype=float32)>  
Impieghiamo il layer custom nel nostro modello, e veri
 ﬁ
chiamo che con dait 
random otteniamo un valore medio in output quasi 0:  
net = tf.keras.Sequential([tf.keras.layers.Dense(
 128
), CenteredLayer()])  
Y = net(tf.random.uniform((
 4
, 
8
))) 
tf.reduce_mean(Y)  
<tf.Tensor: shape=(), dtype=float32, numpy=
 9.313226e-10
 >
20",layer custom possiamo nire layer senza parametri sottoporre addestramento nellesempio implementiamo sorta normalizzazione sottraendo media valori input tale operazioni vanno inserite funzione call import tensorflow import tensorflow class centered layer def init self super init def call self inputs return inputs layer centered layer tftensor shape dtypefloat numpyarray dtypefloat impieghiamo layer custom modello veri chiamo dait random otteniamo valore medio output quasi net centered layer tftensor shape dtypefloat numpy
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#2,2,"Deep networks e moduli
Abbiamo visto come una MLP sia composta da uno o più layer, ognuno 
composto da uno o più nodi che costituiscono l'unità elementare di 
elaborazione.  
Alcuni risultati ci suggeriscono che questo sia un modello suf
 ﬁ
cientemente 
generale per simulare un dominio molto vasto funzioni. Ma risultati 
sperimentali hanno dimostrato che modelli intermedi, più grandi del singolo 
neurone, ma più piccoli dell'intero modello computazionale siano più adatti 
per costruire architetture deep.  
Esempio
 : l'architettura 
 ResNet-152
  (Residual NN) sviluppata nell'ambito 
della computer vision è una delle prime architetture con 100ia di layers. 
La rete è costituita da schemi di nodi e connessioni (
 moduli
 ) che si 
ripetono. Particolari tecniche (
 skip connections
 ) sono impiegate per 
risolvere il vanishing problem.  
Un modulo può essere un layer, più layers, o l'intero modello; e generalizza 
un elemento computazionale che può essere ripetuto, o riutilizzato in diverse 
architetture.
3",deep networks moduli visto composta layer ognuno composto nodi costituiscono lunit elementare elaborazione alcuni risultati suggeriscono modello suf cientemente generale simulare dominio molto vasto funzioni risultati sperimentali dimostrato modelli intermedi grandi singolo neurone piccoli dellintero modello computazionale adatti costruire architetture deep esempio larchitettura res net residual sviluppata nellambito computer vision prime architetture layers rete costituita schemi nodi connessioni moduli ripetono particolari tecniche skip connections impiegate risolvere vanishing problem modulo pu essere layer layers lintero modello generalizza elemento computazionale pu essere ripetuto riutilizzato diverse architetture
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#20,20,"Layer custom con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
21",layer custom parametri nellesempio ricreiamo layer fully connected classe custom funzione init creiamo parametri dipendono dimensione dellinput mentre build niamo dipendono eventuale funzione build viene invocata automaticamente prima call funzione addweight automatizza creazione parametri sottoporre addestramento class dense def init self units super init secondo parametro indica dimensione dellinput self units units secondo parametro indica dimensione dellinput def build self xshape self weight self weight shapexshape self units self bias self addweight name bias shape self units def call self linear tfmatmulx self weight self bias return vedi
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#21,21,"Layer con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
22",layer parametri nellesempio ricreiamo layer fully connected classe custom funzione init creiamo parametri dipendono dimensione dellinput mentre build niamo dipendono eventuale funzione build viene invocata automaticamente prima call funzione addweight automatizza creazione parametri sottoporre addestramento class dense def init self units super init secondo parametro indica dimensione dellinput self units units secondo parametro indica dimensione dellinput def build self xshape self weight self weight shapexshape self units self bias self addweight name bias shape self units def call self linear tfmatmulx self weight self bias return vedi
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#22,22,"I/O su 
 ﬁ
le - tensori
Gli addestramenti di reti deep possono essere molto lunghe. È necessario 
salvare i risultati parziale e 
 ﬁ
nali su 
 ﬁ
le in modo da poterli recuperare 
facilmente.  
Ad esempio, per salvare e recuperare i tensori:  
import 
numpy 
as 
np 
import 
tensorflow  
as 
tf 
# salvataggio  
x = tf.range(
 4
) 
np.save(
 'x-file.npy'
 , x) 
# recupero  
x2 = np.load(
 'x-file.npy'
 , allow_pickle=
 True
) 
# salvataggio di più sensori  
y = tf.zeros(
 4
) 
np.save(
 'xy-files.npy'
 , [x, y])  
x2, y2 = np.load(
 'xy-files.npy'
 , allow_pickle=
 True
) 
# o salvare dizionari stringa-tensore  
mydict = {
 'x'
: x, 
'y'
: y} 
np.save(
 'mydict.npy'
 , mydict)  
mydict2 = np.load(
 'mydict.npy'
 , allow_pickle=
 True
) 
23",tensori addestramenti reti deep possono essere molto lunghe necessario salvare risultati parziale nali modo poterli recuperare facilmente esempio salvare recuperare tensori import numpy import tensorflow salvataggio tfrange npsave filenpy recupero npload filenpy allowpickle true salvataggio sensori tfzeros npsave filesnpy npload filesnpy allowpickle true salvare dizionari stringa tensore mydict npsave mydictnpy mydict mydict npload mydictnpy allowpickle true
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#23,23,"I/O su 
 ﬁ
le - modelli
Per i modelli, occorre distinguere architettura e parametri. Per la prima, ci si 
basa sul codice che si usa per crearla, perciò senza salvataggio su 
 ﬁ
le. 
Mentre per i parametri si sfruttano le funzionalità di Keras.  
Ad esempio, de
 ﬁ
niamo una architettura, salviamo i parametri e ricostruiamo 
la rete con il recupero dei parametri:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
 def 
call
(
self
, inputs):  
        x = 
 self
.flatten(inputs)  
        x = 
 self
.hidden(x)  
        
 return 
self
.out(x) 
net = MLP()  
X = tf.random.uniform((
 2
, 
20
)) 
Y = net(X)  
net.save_weights(
 'mlp.params'
 ) 
...  
clone = MLP()  
clone.load_weights(
 'mlp.params'
 )
24",modelli modelli occorre distinguere architettura parametri prima basa codice usa crearla perci senza salvataggio mentre parametri sfruttano funzionalit keras esempio niamo architettura salviamo parametri ricostruiamo rete recupero parametri class def init self super init self flatten self hidden self out def call self inputs self self hiddenx return self outx net netx mlpparams clone mlpparams
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#24,24,"GPU e Keras
Per default i tensori sono creati in memoria e le computazioni sono sulla 
CPU. Ma possiamo comunque controllare l'elaborazione:  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
cpu
():   
    
 return
 tf.device(
 '/CPU:0'
 ) 
def 
gpu
(i=
0
):   
    
 return
 tf.device(
 f'/GPU:
{
i
}
'
) 
cpu(), gpu(), gpu(
 1
) 
(<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa2b271c0
 >, 
 <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa257a100
 >, 
 [<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ad00
 >, 
  <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ab40
 >]) 
def 
num_gpus
 ():   
    
 return 
len
(tf.config.experimental.list_physical_devices(
 'GPU'
)) 
def 
try_gpu
(i=
0
):   
    
# restituisce gpu(i) se esiste, altrimenti cpu()  
    
 if
 num_gpus() >= i + 
 1
: 
        
 return
 gpu(i) 
    
 return
 cpu() 
def 
try_all_gpus
 ():   
    # 
Numero di GPU disponibili, o CPU se le GPU non ci sono  
    
 return
 [gpu(i) 
 for
 i 
in 
range
(num_gpus())]  
try_gpu(), try_gpu(
 10
), try_all_gpus()
25",keras default tensori creati memoria computazioni possiamo comunque controllare lelaborazione import tensorflow import tensorflow def cpu return tfdevice def gpu return tfdevice cpu gpu gpu eager device context xfafabc eager device context xfafaa eager device context xfafaad eager device context xfafaab def numgpus return len def trygpu restituisce gpui esiste altrimenti cpu numgpus return gpui return cpu def tryallgpus numero disponibili return gpui range numgpus trygpu trygpu tryallgpus
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#25,25,"GPU e Keras (2)
# su quale device è allocato il tensore  
# Nota: è fondamentale avere tutti i parametri di una operazione sullo stesso device  
x = tf.constant([
 1
, 
2
, 
3
]) 
x.device  
'/job:localhost/replica:0/task:0/device:GPU:0'  
# alloca un tensore su una GPU  
with
 try_gpu():  
    X = tf.ones((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
1.
]], dtype=float32)>  
# alloca un tensore sulla seconda GPU  
with
 try_gpu(
 1
): 
    Y = tf.random.uniform((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 0.44844735
 , 
0.7493162
  , 
0.5692874
  ], 
       [
 0.10097635
 , 
0.81023645
 , 
0.5274769
  ]], dtype=float32)>  
# per calcolare X + Y, dobbiamo averli sullo stesso device  
# spostiamo X sulla stessa GPU di Y  
with
 try_gpu(
 1
): 
    Z = X  
print
(X) 
print
(Z) 
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
# ora possiamo calcolarlo  
Y + Z
26",keras device allocato tensore nota fondamentale avere parametri operazione stesso device tfconstant xdevice alloca tensore trygpu tfones tftensor shape dtypefloat numpy array dtypefloat alloca tensore seconda trygpu tftensor shape dtypefloat numpy array dtypefloat calcolare dobbiamo averli stesso device spostiamo stessa trygpu print print tftensor shape dtypefloat tftensor shape dtypefloat ora possiamo calcolarlo
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#26,26,"GPU e Keras (3)
È possibile indicare a Keras di impiegare le GPU disponibili per 
l'elaborazione di un certo modello:  
strategy = tf.distribute.MirroredStrategy()  
with
 strategy.scope():  
    net = tf.keras.models.Sequential([  
        tf.keras.layers.Dense(
 1
)]) 
INFO:tensorflow:Using MirroredStrategy 
 with
 devices (
 '/job:localhost/replica:0/task:0/device:GPU:0'
 , 
'/
job:localhost/replica:0/task:0/device:GPU:1'
 ) 
net(X) 
<tf.Tensor: shape=(
 2
, 
1
), dtype=float32, numpy=  
array([[-
 1.1522729
 ], 
       [-
 1.1522729
 ]], dtype=float32)>  
# vediamo la conferma cheanche i parametri sono memorizzati nello stesso device  
net.layers[
 0
].weights[
 0
].device, net.layers[
 0
].weights[
 1
].device  
(
'/job:localhost/replica:0/task:0/device:GPU:0'
 , 
 
'/job:localhost/replica:0/task:0/device:GPU:0')
27",keras possibile indicare keras impiegare disponibili lelaborazione certo modello strategy strategy net mirrored strategy devices netx tftensor shape dtypefloat numpy array dtypefloat vediamo conferma cheanche parametri memorizzati stesso device netlayers weights device netlayers weights device
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#3,3,"Moduli in Keras
Un modulo è rappresentato da una classe Python che implementa la forward 
propagation, memorizza i parametri, e fornisca la backpropagation. 
Quest'ultimo aspetto può essere delegato alla tecnica autodiff, senza perciò 
de
ﬁ
nire manualmente i singoli gradienti.  
Ad esempio il seguente codice genera due layer: il primo con 256 nodi 
 fully 
connected
  (o 
denso
 ) ed uno di output con 10 nodi.  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
X = tf.random.uniform((
 2
, 
20
)) 
net(X).shape  
Il modello è costruito istanziando la classe 
 Sequential
  e passandogli i singoli 
layer come parametri. Sia 
 Sequential
  che 
 Dense
  sono istanze di 
 keras.Model
 .  
4",moduli keras modulo rappresentato classe python implementa forward propagation memorizza parametri fornisca questultimo aspetto pu essere delegato tecnica autodiff senza perci nire manualmente singoli gradienti esempio seguente codice genera due layer primo nodi fully connected denso output nodi import tensorflow net netxshape modello costruito istanziando classe sequential passandogli singoli layer parametri sequential dense istanze kerasmodel
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#4,4,"Sequential in Keras
Sequential crea una lista ordinata di layer.  
La procedura di forward propagation è de
 ﬁ
nita implicitamente: l'output di 
un layer corrisponde all'input del secondo.  
Nell'esempio si invoca net(X), che corrisponde alla funzione net.call(X), per 
ottenere l'output dal modello appena creato.
5",sequential keras sequential crea lista ordinata layer procedura forward propagation nita implicitamente loutput layer corrisponde allinput secondo nellesempio invoca netx corrisponde funzione netcallx ottenere loutput modello appena creato
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#5,5,"Moduli custom
Per creare nuovi moduli occorre tener presente come vengono impiegati 
durante l'esecuzione:  
1.
I dati di input vengono mandati in input alla forward propagation  
2.
La funzione di propagazione restituisce i valori in output  
3.
Si calcolano i gradienti dell'output rispetto agli input per mezzo del 
metodo di backpropagation. Uno step solitamente gestito in automatico  
4.
Memorizzare i parametri ottenuti necessari per la successiva forward 
propagation
6",moduli custom creare nuovi moduli occorre tener presente vengono impiegati durante lesecuzione dati input vengono mandati input forward propagation funzione propagazione restituisce valori output calcolano gradienti delloutput rispetto input mezzo metodo step solitamente gestito automatico memorizzare parametri ottenuti necessari successiva forward propagation
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#6,6,"Moduli custom
Ad esempio, la rete precedente (un layer da 256 nodi seguito da un layer di 
10 nodi) si codi
 ﬁ
ca nel seguente modo:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 # Sempre necessario richiamare il costruttore della superclass  
        
 super
().
__init__
 () 
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
# forward propagation  
    
 def 
call
(
self
, X): 
        
 return 
self
.out(
self
.hidden((X)))  
de
ﬁ
nendo il costruttore e la funzione che si occupa della forward 
propagation.  
Il metodo call permette di creare layer che richiedono particolari 
elaborazioni (es. controllare il 
 ﬂ
usso di esecuzione durante la forward 
propagation) che non corrispondono a quelle prede
 ﬁ
nite in Keras.
7",moduli custom esempio rete precedente layer nodi seguito layer nodi codi seguente modo class def init self sempre necessario richiamare costruttore superclass super init self hidden self out forward propagation def call self return self out self hiddenx nendo costruttore funzione occupa forward propagation metodo call permette creare layer richiedono particolari elaborazioni controllare usso esecuzione durante forward propagation corrispondono prede nite keras
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#7,7,"Moduli custom - esempio
Durante l'elaborazione possiamo aver bisogno di accedere a costanti, cioè valori 
che non sono associati a parametri da stimare durante l'apprendimento, perciò 
non soggetti a back propagation.  
Nell'esempio, istanziamo i parametri in modo casuale, e rimarranno costanti 
durante il training. Restituiamo la somma dei valori in output.  
L'esempio è di scarsa utilità ma dimostra le potenzialità dei moduli custom.  
class 
FixedHiddenMLP
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
       
self
.rand_weight = tf.constant(tf.random.uniform((
 20
, 
20
))) 
        
 self
.dense = tf.keras.layers.Dense(
 20
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        X = 
 self
.flatten(inputs)  
        
 # Usiamo i parametri costanti per generare l'output  
        X = tf.nn.relu(tf.matmul(X, 
 self
.rand_weight) + 
 1
)        
        X = 
 self
.dense(X)  
        
 # Control flow: simil l1 regularization  
        
 while
 tf.reduce_sum(tf.math.abs(X)) > 
 1
: 
            X /= 
 2 
        
 # reduce_sum() calcola la somma dei valori per una certa dimensione del tensore  
        
 # senza secondo parametro la somma è operata su tutte le dimensioni del tensore  
        
 return
 tf.reduce_sum(X)  
net = FixedHiddenMLP()  
net(X) 
<tf.Tensor: shape=(), dtype=float32, numpy=
 0.88945085
 >
8",moduli custom esempio durante lelaborazione possiamo aver bisogno accedere costanti cio valori associati parametri stimare durante perci soggetti back propagation nellesempio istanziamo parametri modo casuale rimarranno costanti durante training restituiamo somma valori output lesempio scarsa utilit dimostra potenzialit moduli custom class fixed hidden def init self super init self flatten self randweight self dense def call self inputs self usiamo parametri costanti generare loutput self randweight self densex control flow simil regularization reducesum calcola somma valori certa dimensione tensore senza secondo parametro somma operata tutte dimensioni tensore return net fixed hidden netx tftensor shape dtypefloat numpy
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#8,8,"Moduli custom - esempio
Nell'esempio de
 ﬁ
nisco un altro modello (NestMLP) e successivamente un 
nuovo modello che include il primo come layer:  
class 
NestMLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.net = tf.keras.Sequential()  
        
 self
.net.add(tf.keras.layers.Dense(
 64
, activation=tf.nn.relu))  
        
 self
.net.add(tf.keras.layers.Dense(
 32
, activation=tf.nn.relu))  
        
 self
.dense = tf.keras.layers.Dense(
 16
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        
 return 
self
.dense(
self
.net(inputs))  
chimera = tf.keras.Sequential()  
chimera.add(NestMLP())  
chimera.add(tf.keras.layers.Dense(
 20
)) 
chimera.add(FixedHiddenMLP())  
chimera(X)
9",moduli custom esempio nellesempio nisco altro modello nest successivamente nuovo modello include primo layer class nest def init self super init self net self self self dense def call self inputs return self dense self netinputs chimera hidden chimerax
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#9,9,"Esercizio
Implementare un modulo che prende l'output di due moduli (es. 
 net1
 e 
net2
) e restituisce un output concatenato durante la forward propagation.
10",esercizio implementare modulo prende loutput due moduli net net restituisce output concatenato durante forward propagation
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN) - parte 1
1",deep learning universit roma tre dipartimento ingegneria anno accademico convolutional neural networks parte
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#1,1,"Sommario
Introduzione  
Architettura Visual cortex  
MLP fully connected e limiti  
Invarianza (spaziale) e principio di località  
Convolutional layer e canali",sommario introduzione architettura visual cortex fully connected limiti invarianza spaziale principio localit convolutional layer canali
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#10,10,"MLP - fully connected
Le reti MLP sono comunque ef
 ﬁ
caci in molti contesti, ad esempio:  
In presenza di dati in formato 
 tebellare
 , dove non assumiamo a priori 
una struttura che mette in correlazione le features per ogni istanza, 
sebbene possano esserci potenziali correlazioni e dipendenze.  
Dati da cui si possono estrarre un numero di features non elevatissimo 
(<<1000), che perciò necessitano di un numero di parametri da stimare 
limitato.
11",fully connected reti comunque caci molti contesti esempio presenza dati formato tebellare assumiamo priori struttura mette correlazione features ogni istanza sebbene possano esserci potenziali correlazioni dipendenze dati possono estrarre numero features elevatissimo perci necessitano numero parametri stimare limitato
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#11,11,"Invarianza (spaziale) #1
12
Nella identi
 ﬁ
cazione delle targhe, per addestrare una MLP dobbiamo 
costruire un training set con molte istanze, in modo da :  
avere lo stesso oggetto che compare in varie posizioni, angolazioni e 
dimensioni.  
oggetto visualizzato parzialmente (es. sul bordo).  
casi di overlap tra oggetti etc.",invarianza spaziale identi cazione targhe addestrare dobbiamo costruire training set molte istanze modo avere stesso oggetto compare varie posizioni angolazioni dimensioni oggetto visualizzato parzialmente bordo casi overlap oggetti etc
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#12,12,"Invarianza (spaziale) #2
Nel task ""Where's Waldo?"" non siamo interessati alla posizione, ma solo 
alla presenza o meno di una certa istanza.  
Il modello dovrebbe tentare di analizzare piccole zone dell'immagine e 
confrontarle con il pattern ""Waldo"".
13
",invarianza spaziale task wheres waldo interessati posizione solo presenza meno certa istanza modello dovrebbe tentare analizzare piccole zone dellimmagine confrontarle pattern waldo
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#13,13,"Proprietà locali
14Per riconoscere certe caratteristiche speci ﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata . Non c'è bisogno di considerare l'intera immagine iniziale.  
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  ",propriet locali riconoscere certe caratteristiche speci che analizziamo informazioni locali ravvicinate cio distanza relativa limitata bisogno considerare lintera immagine iniziale output associato certa feature occhio naso associato solo certo numero pixel input
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#14,14,"MLP: Proprietà desiderate
15
Nei primi layer la rete dovrebbe comportarsi in modo simile 
indipendentemente dalla posizione di una certa regione di interesse 
(
translation invariance
  o 
translation equivariance
 ). 
Nei primi layer l'analisi deve essere limitata a piccole regioni 
dell'immagine in input, e non sull'intera immagine (
 principio di località
 ).  
Nei successivi layer, tali analisi considerano regioni più vaste, combinando 
l'output delle analisi precedenti, 
 ﬁ
no ad arrivare all'intera immagine.",propriet desiderate primi layer rete dovrebbe comportarsi modo simile posizione certa regione interesse translation invariance translation equivariance primi layer lanalisi deve essere limitata piccole regioni dellimmagine input sullintera immagine principio localit successivi layer tali analisi considerano regioni vaste combinando loutput analisi precedenti arrivare allintera immagine
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#15,15,"Esempio MLP e immagini
16
Supponiamo di avere una MLP con uno strato nascosto 
 H
. L'input 
 X
 è 2d, ed è 
rappresentato da un tensore, anch'esso 2d. Supponiamo per ora che 
 H
 abbia la 
stessa struttura di 
 X
. 
Indichiamo con [
 X
]
i,j
 e [
H
]
i,j
 il pixel nella posizione <i,j> e il corrispettivo nodo nel 
layer nascosto.  
Indichiamo con 
 W
 e 
U
 pesi e bias della rete. Poiché ogni nodo di 
 H
 riceve input 
da tutti i pixel in input, usiamo matrici-tensori di ordine 4.  
Dove [
 V
]
i,j,a,b
 := [
H
]
i,j,i+a,j+b 
 , 
perciò introduciamo un semplice cambio notazione. 
Gli indici 
 a
 e 
b
 sono offset rispetto a <i,j> e scorrono l'intera immagine in input, 
perciò possono assumere valori negativi.  
Numero di parametri: per immagini 1000x1000 abbiamo 10
12
 parametri, infatti 
ogni nodo in 
 H
 deve essere connesso con tutti i nodi del layer precedente.
",esempio immagini supponiamo avere strato nascosto linput rappresentato tensore anchesso supponiamo ora stessa struttura indichiamo pixel posizione corrispettivo nodo layer nascosto indichiamo pesi bias rete poich ogni nodo riceve input pixel input usiamo matrici tensori ordine ijab ijiajb perci introduciamo semplice cambio notazione indici offset rispetto scorrono lintera immagine input perci possono assumere valori negativi numero parametri immagini parametri infatti ogni nodo deve essere connesso nodi layer precedente
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#16,16,"Invarianza spaziale nella pratica
17
Tale proprietà impone che, se abbiamo uno 
 shift
 nell'input 
 X
, anche la 
rappresentazione 
 H
 deve subire lo stesso 
 shift
, in modo da mantenere lo 
stesso output. Ma questo è possibile solo se 
 U 
e 
V
 non dipendono da 
 <i,j>
, 
cioè [
 V
]
i,j,a,b
 := [
V
]
a,b  
e 
U
 è una costante.  
Rappresenta l'operatore di 
 convoluzione
 . Il pixel <i+a,j+b>, vicino alla 
location <i,j>, è pesato con il coef
 ﬁ
ciente [
 V
]
a,b
 per ottenere l'output [
 H
]
i,j
. 
[
V
]
a,b  
richiede meno coef
 ﬁ
cienti poiché è indipendente dalla location. I 
parametri passano da 10
12
 a 4·10
6
, con 
 a
 e 
b
 in (-1000,1000).
",invarianza spaziale pratica tale propriet impone che shift nellinput deve subire stesso shift modo mantenere stesso output possibile solo dipendono cio ijab costante rappresenta loperatore convoluzione pixel iajb vicino location pesato coef ciente ottenere loutput richiede meno coef cienti poich indipendente location parametri passano
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#17,17,"Principio di località nella pratica
18
Limitiamo l'analisi per determinare [
 H
]
i,j
 a una zona 
 Δ
×
Δ
, con 
Δ
<<1000 
(es. 
Δ
=10), perciò evitando di considerare l'intera immagine:  
I parametri si riducono ulteriormente da 4·10
6
 a 4·
Δ
2
, sebbene il layer 
nascosto mantenga la dimensione iniziale, e perciò la quantità di 
informazione originale.  
La regione 
 Δ
×
Δ
 che genera le attivazioni nel successivo strato è chiamata 
Local receptive 
 ﬁ
eld (LRF)
 .
",principio localit pratica limitiamo lanalisi determinare zona perci evitando considerare lintera immagine parametri riducono ulteriormente sebbene layer nascosto mantenga dimensione iniziale perci quantit informazione originale regione genera attivazioni successivo strato chiamata local receptive eld
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#18,18,"CNN - Convolutional layer e LRF
19
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input:  
immagine 25x25 pixe l
in bianco e neroOutput dopo il primo  
layer convolutivo .local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato  
da una certa posizione del 
LRF  che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione",convolutional layer nodo input successivo hidden layer esempio input immagine pixe bianco nero output dopo primo layer convolutivo local receptive eld ogni nodo attivato base allinput determinato certa posizione scorre lungo linputinput convolutional layer notiamo riduzione dimensione rispetto attivazioni elaborazione
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#19,19,"Convolutional neural networks
20
Il layer 
 H
 che abbiamo introdotto prende il nome di 
 convolutional layer,
  e 
le rete basate su tale layer 
 Convolutional neural networks
  (CNNs).  
V
 è comunemente chiamato 
 convolution kernel
  o 
ﬁ
ltro
. 
Per rappresentare features più complesse e ad alto livello, si impiegano più 
layer convolutivi alternati a non linearità.",convolutional neural networks layer introdotto prende nome convolutional layer rete basate tale layer convolutional neural networks nns comunemente chiamato convolution kernel ltro rappresentare features complesse alto livello impiegano layer convolutivi alternati linearit
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#2,2,"Introduzione
Alcune so
 ﬁ
sticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come:  
•
Riconoscere un giocattolo in una immagine  
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speci
 ﬁ
che.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture.  
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identi
 ﬁ
carlo.  
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
3",introduzione alcune sticate architetture riuscite ottenere performance superiori umane gioco scacchi deep blue solo intorno ottenute buone performance task apparentemente semplici come riconoscere giocattolo immagine speech recognition riconoscimento vocale task semplici levoluzione portato cervello costruire strutture funzioni speci che quando informazioni arrivano parti deputate ragionamento alto livello gi arricchite features alto livello elaborate strutture sebbene coscienti esiste giocattolo sappiamo spiegare processo seguito identi carlo architetture convolutional neural networks state sviluppate anni base studi zona corteccia deputata riconoscimento visivo ultime decadi diffuse grazie presenza
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#20,20,"Channels (canali)
21
Le immagini a colori hanno 3 canali RGB, perciò, ai due assi principali che 
identi
 ﬁ
cano le relazioni spaziali, ne aggiungiamo un terzo ottenendo 
tensori 3d [
 X
]
i,j,k
 con 
 ﬁ
ltri del tipo [
 V
]
a,b,c
 . 
Muovendoci in profondità, possiamo creare una terza dimensione per ogni 
strato hidden. In pratica si ha uno 
 stack
  di griglie, chiamato 
 feature maps
 , 
dove ogni griglia è creata con un 
 ﬁ
ltro distinto. Il numero di griglie 
corrisponde ai canali per quello strato.  
Generalizzando, supponendo di avere più canali in input (
 c
) e più canali 
nell'hidden layer (
 d
), si ha:  
Il successivo layer userà i 
 d
 canali dell'hidden layer che diverranno i 
 c 
canali di input.
",channels canali immagini colori canali perci due assi principali identi cano relazioni spaziali aggiungiamo terzo ottenendo tensori ijk ltri tipo abc muovendoci profondit possiamo creare terza dimensione ogni strato hidden pratica stack griglie chiamato feature maps ogni griglia creata ltro distinto numero griglie corrisponde canali strato generalizzando supponendo avere canali input canali nellhidden layer successivo layer user canali dellhidden layer diverranno canali input
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#21,21,"Esercizio
22
Impiega il dataset di cifre MNIST e crea una rete convolutiva per la 
classi
 ﬁ
cazione.  
Colab 
 07-lenet.ipynb 
",esercizio impiega dataset cifre crea rete convolutiva classi cazione colab lenetipynb
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#3,3,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive 
 ﬁ
eld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale.  
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
con
ﬁ
gurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"".  
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi.  
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
4",larchitettura visual cortex anni hubel wiesel dimostrato molti neuroni parte corteccia deputata riconoscimento immagini possiedono piccolo local receptive eld cio possono reagire stimoli situati regioni limitate campo visuale sebbene condividano alcuni neuroni attivano solo presenza linee orizzontali altri solo verticali alcuni neuroni estesi attivano presenza certe gurazioni caratteristiche basso livello pu desumere lattivazione neuroni alto livello basata sulloutput neuroni basso livello ritenuti vicini aumentando complessit ripetendo volte cascata passi riportati possiamo riconoscere patterns visuali molto complessi nota resto lezione suppone considerare immagini istanze input tecnologie introdotte possono essere usate altri input
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#4,4,"L'architettura della Visual cortex
5
Secondo te è una MLP?Ad ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds",larchitettura visual cortex secondo lpad ogni livello saliamo astrazione pattern individuati local receptive elds
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#5,5,"L'architettura della Visual cortex
6
È simile a una MLP ,  
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds",larchitettura visual cortex simile ogni nodo connesso solo piccolo insieme neuroni vicini ogni livello saliamo astrazione pattern individuati local receptive elds
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#6,6,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
7",fully connected usiamo riconoscere oggetti
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#7,7,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
8",fully connected usiamo riconoscere oggetti causa dell elevato numero parametri stimare supponiamo avere input piccola immagine pixel creiamo primo layer appena nodi perci ltra notevolmente informazioni passata successivi layer primo strato gi milioni parametri stimare
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#8,8,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare.  
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo 
task
, es. riconoscere linee orizzontali.  
•
I neuroni specializzati sono attivati se il pattern da identi
 ﬁ
care è 
localizzato in una certa zona.  
•
Ma vorremmo poter identi
 ﬁ
care lo stesso pattern indipendentemente da 
dove compare.
9",fully connected usiamo riconoscere oggetti causa dell elevato numero parametri stimare supponiamo avere input piccola immagine pixel creiamo primo layer appena nodi perci ltra notevolmente informazioni passata successivi layer primo strato gi milioni parametri stimare supponiamo certi nodi primo strato specializzino certo task riconoscere linee orizzontali neuroni specializzati attivati pattern identi care localizzato certa zona vorremmo poter identi care stesso pattern compare
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#9,9,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
3. Le reti 
 MLP 
non riescono a codi
 ﬁ
care esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identi
 ﬁ
cano 
features analizzando piccole aree dell'immagine.  
•
I neuroni ""ad alto livello"" combinano tali features per identi
 ﬁ
care features 
spazialmente più estese.
10",fully connected usiamo riconoscere oggetti reti riescono codi care esplicitamente spaziale features visual cortex neuroni strati vicini allinput identi cano features analizzando piccole aree dellimmagine neuroni alto livello combinano tali features identi care features spazialmente estese
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
2a parte
1",deep learning universit roma tre dipartimento ingegneria anno accademico convolutional neural networks parte
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#1,1,"Sommario
Convolutional Neural network  
•
Convolutional layer  
•
Local receptive 
 ﬁ
eld 
•
Stride e Padding  
•
Filters e Feature Maps  
•
Pooling Layer  
Architettura LeNet-5",sommario convolutional neural network convolutional layer local receptive eld stride padding filters feature maps pooling layer architettura net
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#10,10,"CNN - Stride
11•La distanza s tra due LRF  adiacenti è chiamata stride . 
•Finora abbiamo visto stride di 1 pixel, ma la LRF  può scorrere di più pixel . 
•Le CNN spesso impiegano kernels di dimensione 1,3,5 o 7. Questo rende più facile mantenere 
la dimensionalità con padding (vedi di seguito) che consistono nello stesso numero di righe in 
cima e in fondo, e colonne a sinistra e a destra dell'immagine. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3  
Stride = 2",stride la distanza due adiacenti chiamata stride finora visto stride pixel pu scorrere pixel le spesso impiegano kernels dimensione rende facile mantenere dimensionalit padding vedi seguito consistono stesso numero righe cima fondo colonne sinistra destra dellimmagine output layer precedente layer convoluzionale padding padding stride
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#11,11,"CNN: Padding
12•Supponendo stride > 1 , può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF ) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input.  
•Il padding  aggiunge dimensioni  ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding ). Si hanno i seguenti vantaggi :
•Permettere alla LRF  di scorrere per intero l'immagine in input senza ignorarne delle parti .
•Un LRF potrebbe ""imparare"" a riconosce una certa feature  quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo , senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding",padding supponendo stride pu accadere convolutional layer comunque ridotto causa dimensioni layer precedente poich pu scorrere lintera instanza input il padding aggiunge dimensioni dati input normalmente dati inseriti valori nulli padding seguenti vantaggi permettere scorrere intero limmagine input senza ignorarne parti un potrebbe imparare riconosce certa feature quando centrata nellimmagine feature posizionata molto vicino bordo senza padding potrebbe essere ignorata padding output layer precedente senza padding output layer precedente padding
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#12,12,"CNN: Riduzione dimensionalità e Stride
13Output layer precedente•La presenza di stride > 1  altera gli indici iniziali e ﬁnali che identi ﬁcato il LRF associato ad 
un certo nodo.  
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista .
•Stride > 1 riducono la dimensione  del layer convoluzionale a scapito della precisione .
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3  
Stride = 2",riduzione dimensionalit stride output layer precedentela presenza stride altera indici iniziali nali identi cato associato certo nodo lattivazione nodo posizione certo layer determinato output nodi layer precedente posizionati righe colonne per pari torna formulazione gi vista stride riducono dimensione layer convoluzionale scapito precisione layer convoluzionale padding padding stride verticale stride orizzontale stride
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#13,13,"CNN: Filters
14Filters•Supponiamo di poter rappresentare gra ﬁcamente i pesi associati a un certo nodo , usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters  o convolution kernels  
(o kernels )
•Ad esempio, una LRF  77 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input",filters poter rappresentare gra camente pesi associati certo nodo usati calcolo attivazione tali pesi prendono nome lters convolution kernels kernels ad esempio corrisponder ltro medesime dimensioni nellesempio due ltri vertical lter horizontal lter entrambi matrice tutta tranne colonna riga input
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#14,14,"Esempi di 
 ﬁ
ltri e attivazioni (1)
15Esempio di input  
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo .
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni",esempi ltri attivazioni esempio input immagine pixel output dopo primo layer convolutivo immagine input immagine input output output filtro filtro attivazioni attivazioni
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#15,15,"Esempi di 
 ﬁ
ltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro",esempi ltri attivazioni ltro ltro
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#16,16,"CNN: Feature Maps
17Filters•Le LRF  scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione . Tale approccio prende il nome di shared weights . 
•L'insieme delle attivazioni ottenute (output) con lo stesso ﬁltro viene chiamato feature map 
poiché rappresenta le features apprese nella dimensione spaziale. Esse possono essere 
visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map  dove le zone dell'input simili a una 
linea verticale  sono più evidenziate  (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate . Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input",feature maps filtersle scorrono immagine input supponiamo mantenere costante valori ltro usato calcolo tale approccio prende nome shared weights linsieme attivazioni ottenute output stesso ltro viene chiamato feature map poich rappresenta features apprese dimensione spaziale esse possono essere visualizzate immagine nellesempio nota vertical lter crea feature map zone dellinput simili linea verticale evidenziate cio attivazione mentre zone meno simili scure sfocate discorso duale ltro horizontal lterfeature maps input
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#17,17,"CNN: Stacking feature maps
In 
ogni layer
  possiamo avere 
 più 
ﬁ
ltri con le medesime dimensioni
 . Ogni 
ﬁ
ltro produrrà una diversa feature map. Ogni layer sarà così costituito da 
una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i 
 ﬁ
ltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di:  
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP.  
•
Durante la backpropagation, adattare ogni 
 ﬁ
ltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso 
 ﬁ
ltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
18",stacking feature maps ogni layer possiamo avere ltri medesime dimensioni ogni ltro produrr diversa feature map ogni layer cos costituito sequenza matrici attivazioni perci struttura durante forward propagation fondamentale ltri cio parametri pesi bias costituiscono layer convoluzionale rimangano costanti sebbene valore attivazioni ovvero feature map cambiano base posizione permette avere numero molto minore parametri stimare rispetto layer durante adattare ogni ltro particolare caratteristica saliente possibilit usare stesso ltro diverse zone dellimmagine garantisce translational simmetry cio possiamo riconoscere caratteristica diverse posizioni rete fully connected potrebbe riconoscere caratteristica posizione stimando certi parametri grado riutilizzarli altre posizioni
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#18,18,"Canali multipli in input
Abbiamo già visto l'operatore di convoluzione in presenza di più canali.  
Se in ingresso abbiamo più canali, es. RGB, 
 c
i
 > 1, allora il 
 ﬁ
ltro 
rappresentato dal tensore 
 k
h
 × 
k
w
 dovrà essere ripetuto per ogni canale. Se 
concateniamo i tensori abbiamo un tensore 
 c
i 
× k
h
 × 
k
w
. 
Il risultato sarà un tensore 2d poiché il risultato delle singole convoluzioni 
sarà sommato nella dimensione dei canali.  
Ad esempio, considerando 2 canali in input:
19
",canali multipli input gi visto loperatore convoluzione presenza canali ingresso canali allora ltro rappresentato tensore dovr essere ripetuto ogni canale concateniamo tensori tensore risultato tensore poich risultato singole convoluzioni sommato dimensione canali esempio considerando canali input
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#19,19,"Canali multipli in output
Nelle CNN tradizionalmente il numero di canali aumentano con il numero 
di layer processati, generalmente riducendo allo stesso tempo la risoluzione 
spaziale degli input.  
Idealmente ogni canale rappresenterà un different set di features, ma in 
realtà le features possono essere 
 sparse
  su più canali.  
Per avere un output multicanale, creiamo più tensori 
 c
i 
× k
h
 × 
k
w 
, ognuno 
per singolo canale in output. Se li concateniamo otteniamo un kernel  
c
o 
× c
i 
× k
h
 × 
k
w
 .
20",canali multipli output numero canali aumentano numero layer processati generalmente riducendo stesso tempo risoluzione spaziale input idealmente ogni canale rappresenter different set features realt features possono essere sparse canali avere output multicanale creiamo tensori ognuno singolo canale output concateniamo otteniamo kernel
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#2,2,"CNN - Struttura gerarchica
3Input layer:  
È un layer costituito da unità  
a cui viene associato il valore  
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerData una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota : Nelle tradizionali MLP , input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori , ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN  tale ridimensionamento è controproducente  poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell' input layer  le features  
corrispondono ai singoli pixel",struttura gerarchica input layer layer costituito unit viene associato valore singoli pixel dellimmagine reale convolutional layer secondo convolutional layer data instanza input nodi vicini convolutional layer layer attivati base features estratte certa zona dellinput astrazione features nota tradizionali input bidimensionali immagini bianco nero comunemente ridimensionati vettori ovvero matrici dimensioni tale poich perderebbe linformazione relativa vicinanza features input struttura gerarchica nell input layer features corrispondono singoli pixel
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#20,20,"CNN: Feature Maps e Canali
21...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB, cioè 3 
canali.Possiamo de ﬁnire un certo numero di 
ﬁltri (es. 12) per riconoscere diverse 
caratteristiche salienti dell'immagine 
iniziale. I ﬁltri analizzano 
contemporaneamente 3 canali RGB, 
perciò i ﬁltri saranno de ﬁniti con 
matrici a 3 dimensioni. Un ﬁltro 
applicato all'immagine in input 
produce un singolo convolutional layer.I successivi layer convoluzionali 
analizzato le attivazioni di più ﬁltri 
contemporaneamente. I ﬁltri di questo 
layer riconosceranno caratteristiche 
più astratte.depth = 3 depth = 12 depth = 7",feature maps canali input convolutional layer convolutional layer immagine colori matrici associate canali cio canalipossiamo nire certo numero ltri riconoscere diverse caratteristiche salienti dellimmagine iniziale ltri analizzano canali perci ltri niti matrici dimensioni ltro applicato allimmagine input produce singolo convolutional layeri successivi layer convoluzionali analizzato attivazioni ltri ltri layer riconosceranno caratteristiche astrattedepth depth depth
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#21,21,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori:  
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
2201234567891011121300 12345678910111213
senza padding ('VALID' ) con padding ('SAME' )ignorati
stride=5padding P=+3",tensor flow padding tensor flow fornisce parametro padding pu assumere due valori caso voglia ignorare padding aggiungere automaticamente righe colonne composte valori modo bilanciato garantire scorra lintera matrice input senza padding padding ignorati stridepadding
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#22,22,"Stride, padding e Keras
Le dimensioni del kernel e i restanti iperparametri sono de
 ﬁ
niti via 
costruttore del modello Conv2D:  
# numero di kernels pari a 1  
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=
 3
, padding=
 'same'
, strides=
 2
) 
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=(
 3
,
5
), padding=
 'valid'
, strides=(
 3
, 
4
)) ",stride padding keras dimensioni kernel restanti iperparametri niti via costruttore modello conv numero kernels pari convd kernelsize padding same strides convd kernelsize padding valid strides
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#23,23,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di 
 ﬁ
ltri per layer (o 
 depth
 ) 
Dimensione del LRF  
Stride e padding  
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una con
 ﬁ
gurazione 
verosimilmente già ottimizzata.
24",tuning rispetto molti iperparametri stimare numero ltri layer depth dimensione stride padding invece usare tecniche automatiche tuning ispira architetture gi studiate letteratura avere gurazione verosimilmente gi ottimizzata
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#24,24,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con 
ﬁ
ltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200  
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile.  
•
Con 
ﬂ
oat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
25",risorse memoria considerazioni backpropagation richiede memorizzare valor intermedi calcolati durante forward propagation esempio convolutional layer ltri feature maps dimensione stride padding input immagini numero parametri layer completamente connesso layer input richiederebbe parametri ognuna mappe contiene nodi ogni nodo ricava lattivazione valutando input corrispondono milioni moltiplicazioni virgola mobile oat bit layer output impiega circa ogni istanza istanze layer occuperebbe produzione attivazioni layer possono essere dimenticate appena calcoli layer successivo terminati richiedendo molta meno memoria cio massimo layer
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#25,25,"Pooling layer
Ripetendo i layer convolutivi, ad ogni layer il 
 receptive 
 ﬁ
eld
 sarà 
 sensibile  
ad una parte sempre maggiore in riferimento all'immagine iniziale. Perciò 
gli ultimi nodi della rete saranno attivati in base all'intera informazione 
presente nell'immagine iniziale.  
Spesso l'informazione spaziale esatta delle features riconosciute non è 
importante, soprattutto se ci interessa l'invarianza ad eventuali translazione 
dell'input.  
I pooling layer sono utili per:  
mitigare la sensitività
  dei layer convolutivi rispetto alle posizioni delle 
features  
ridurre la dimensionalità dell'input da elaborare
 .
26",pooling layer ripetendo layer convolutivi ogni layer receptive eld sensibile parte sempre maggiore riferimento allimmagine iniziale perci ultimi nodi rete attivati base allintera informazione presente nellimmagine iniziale spesso linformazione spaziale esatta features riconosciute importante soprattutto interessa linvarianza eventuali translazione dellinput pooling layer utili per mitigare sensitivit layer convolutivi rispetto posizioni features ridurre dimensionalit dellinput elaborare
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#26,26,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti:  
•
Meno complessità computazione  
•
Meno risorse di memoria  
•
Meno parametri (e ridurre l'over
 ﬁ
tting come effetto collaterale)  
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF.  
•
Occorre de
 ﬁ
nire dimensione, stride e padding  
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
27",pooling layer layer pooling scopo ridurre numero parametri operando campionamento sampling dati vantaggi seguenti meno complessit computazione meno risorse memoria meno parametri ridurre lover tting effetto collaterale convolutional layer ogni nodo connesso numero limitato nodi layer precedente posizionati certo occorre nire dimensione stride padding pooling layer parametri opera semplicemente aggregazione valori associati nodi esempio calcolando media valore massimo spesso calcolo fatto ogni canale input cio singolo strato volta rispetto allintera profondit layer precedente canale separatamente profondit numero layer uscita corrisponder ingresso
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#27,27,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁ
eld (
pooling size
 ), il 
pooling stride
 , e tipo di aggregazione.  
•
Spesso pooling size e stride corrispondono.  
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identi
 ﬁ
cata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche.  
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta.  
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel 
ﬁ
eld considerato.  
•
average pooling:
  considero il valor medio nel 
 ﬁ
eld.
28",pooling layer parametri inferire solo iperparametri cio dimensione eld pooling size pooling stride tipo aggregazione spesso pooling size stride corrispondono molti scenari fondamentale posizione esatta certa caratteristica fatto esista certa zona identi cata certa sequenza pattern features senza considerare esattamente rispettive distanze reciproche esempio face detection interesse riconoscere due occhi vicini interessa distanza esatta esistono due tipi principali aggregazione max pooling nodo assume lattivazione massima valori presenti eld considerato average pooling considero valor medio eld
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#28,28,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max.  
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
29
A causa del padding VALID  
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  fpo è il pooling size , spo il pooling stride ,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1",esempio pooling layer nellesempio pooling kernel stride pari padding aggregazione max layer output contiene meno valori layer precedente causa padding valore alcuni nodi ignorato input canale layer fpo pooling size spo pooling stride dimensione layer output nfpo spo
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#29,29,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri.  
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente:  
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×",convolutional layer dimensione output dimensione delloutput convolutional layer ricava partire dimensione dellinput valore iperparametri semplicit assumiamo input dimensione stride righe colonne aggiunte padding allora due dimensione layer output seguente dimensione output perci corrisponde
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#3,3,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la 
 ﬁ
nestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della 
 ﬁ
nestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF",esempio attivazione nodo lattivazione nodo layer convoluzionale ottiene analizzando loutput layer precedente mezzo esempio funzione dattivazione nodo valuta considerando bias matrice dimensione associati caso pari parametri determinare offset riferiti nestra scorre passo volta allora riferimento allorigine nestra ijlk
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#30,30,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classi
 ﬁ
cazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden:  
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID  
•Numero ﬁltri (o depth) = 96  
•L’output per ogni ﬁltro avrà dimensione di lato 
(227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 
=290.400 nodi.  
•L'attivazione di un nodo si ricava considerando 
11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri.  
•Per la proprietà degli shared weights, nella CNN il 
numero di parametri sarà 11x11x3x96 + 96 = 
34.944.  × ×
×
×
feature mapscomputazione",alex net prime architetture reti neurali combina nellambito classi cazione oggetti esempio calcolo parametri alex netoutput depth input depth ricordiamoci local receptive eld profondit pari dellinput esempi calcolo parametri primo layer hidden dim immagine input dim stride padding numero ltri depth loutput ogni ltro dimensione lato cio ltro considerando profondit nodi lattivazione nodo ricava considerando nodi layer precedente in parametri per propriet shared weights numero parametri xxx feature
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#31,31,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST.  
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identi
 ﬁ
cate dalle CNN 
per fare classi
 ﬁ
cazione per mezzo della MLP.  
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni.",architettura net net prime architetture stata ideata fare garantendo errore combina layers rete tradizionale valle scopo impiegare caratteristiche salienti identi cate fare classi cazione mezzo rete interamente fully connected richiesto molti parametri ottenere prestazioni
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#32,32,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/  ",demo net
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#33,33,"Architettura LeNet-5
convolutional layer#1 conv. laye r
feature maps:  
28x28, depth 6#3 conv. layer  
feature maps:  
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling laye r
feature maps:  
14x14, depth 6#4 pooling laye r
feature maps:  
5x5, depth 16
conv. layer#6 fully connected layer  
nodi 84#5 conv. layer  
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer  
nodi 10
La con ﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding.",architettura net convolutional layer conv laye feature maps depth conv layer feature maps depth avg poolingconv layeravg pooling pooling laye feature maps depth pooling laye feature maps depth conv layer fully connected layer nodi conv layer feature maps depth immagini gray scalel loutput dellultimo convolution layer convertito vettore adatto input fully connected layer ancora stata approfondita tempi net impiegata tradizionale tanh fully connected layer nodi gurazione iperparametri dimensione dellinput necessita impiegare padding
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#34,34,"LeNet-5: esempio di 
 ﬁ
ltri
Nel caso del dataset MNIST di caratteri numerici (immagini 28x28), 
otteniamo 
 ﬁ
ltri di questo tipo:  
",net esempio ltri caso dataset caratteri numerici immagini otteniamo ltri tipo
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#4,4,"CNN - LRF
5Output layer precedente•In un certo layer convoluzionale , un nodo con indice (i, j) prende in input  gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF  va dalla riga  i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e fw corrispondono all'altezza e larghezza del LRF . 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni .forward propagation
Esempio con LRF 3x3  
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding  
(discusso più avanti)
•Notazioni: rispetto alle slide precedenti 2Δ=fh=fw",output layer precedentein certo layer convoluzionale nodo indice prende input output nodi layer precedente posizionati allinterno la regione riga riga colonna colonna fh corrispondono allaltezza larghezza indici scorrono dim dim convolutional layer rappresentato griglia bidimensionale contiene risultato attivazioni forward propagation esempio stride pari padding padding dim dimy padding discusso avanti notazioni rispetto slide precedenti fhfw
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#5,5,"Cross-correlazione
Supponendo 
 K
 il kernel e 
 X
 l'input 2d, possiamo de
 ﬁ
nire la funzione 
 corr2d
 () che 
restituisce un output di dimensioni pari all'input, meno la dimensione del kernel 
 + 
1
: 
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
corr2d
(X, K):  
    h, w = K.shape  
    Y = tf.Variable(tf.zeros((X.shape[
 0
] - h + 
 1
, X.shape[
 1
] - w + 
 1
))) 
    
 for
 i 
in 
range
(Y.shape[
 0
]): 
        
 for
 j 
in 
range
(Y.shape[
 1
]):         
            # estraggo la parte di X che mi interessa  
            # calcolo una moltiplicazione element-wise tra le matrici  
            # ricavo infine la somma  
            Y[i, j].assign(tf.reduce_sum(  
                X[i: i + h, j: j + w] * K))  
    
 return
 Y 
X = tf.constant([[
 0.0
, 
1.0
, 
2.0
], [
3.0
, 
4.0
, 
5.0
], [
6.0
, 
7.0
, 
8.0
]]) 
K = tf.constant([[
 0.0
, 
1.0
], [
2.0
, 
3.0
]]) 
corr2d(X, K)  
<tf.Variable 
 'Variable:0'
  shape=(
 2
, 
2
) dtype=float32, numpy=  
array([[
 19.
, 
25.
], 
       [
 37.
, 
43.
]], dtype=float32)>  
Nota
 : l'operatore di 
 convoluzione
  è simile all'operatore 
 cross-correlazione
 , ma nel 
primo il kernel è ""
 capovolto"" 
 durante il calcolo. Nelle CNN si impiega usualmente 
la cross-correlazione. Non c'è differenza poiché i pesi ricavati durante 
l'addestramento sono i medesimi, ma con ordine invertito. Spesso nei testi e nel 
codice i due termini assumono lo stesso signi
 ﬁ
cato.
",cross correlazione supponendo kernel linput possiamo nire funzione corrd restituisce output dimensioni pari allinput meno dimensione kernel import tensorflow import tensorflow def corrd kshape xshape range yshape range yshape estraggo parte interessa calcolo moltiplicazione element wise matrici ricavo infine somma return tfconstant tfconstant corrdx tfvariable variable shape dtypefloat numpy array dtypefloat nota loperatore convoluzione simile alloperatore cross correlazione primo kernel capovolto durante calcolo impiega usualmente cross correlazione differenza poich pesi ricavati durante laddestramento medesimi ordine invertito spesso testi codice due termini assumono stesso signi cato
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#6,6,"Esempio di modello Conv2D
class 
Conv2D
(tf.keras.layers.Layer):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
build
(
self
, kernel_size):  
        initializer = tf.random_normal_initializer()  
        
 self
.weight = 
 self
.add_weight(name=
 'w'
, shape=kernel_size,  
                                      initializer=initializer)  
        
 self
.bias = 
 self
.add_weight(name=
 'b'
, shape=(
 1
, ), 
                                    initializer=initializer)  
    
 def 
call
(
self
, inputs):  
        
 return
 corr2d(inputs, 
 self
.weight) + 
 self
.bias",esempio modello conv class conv def init self super init def build self kernelsize initializer self weight self self bias self shape def call self inputs return corrdinputs self weight self bias
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#7,7,"Esempio: riconoscimento bordi
Supponiamo che vogliamo riconoscere il bordoe in una immagine 
monitorando il cambio del valore dei pixel.  
Costruiamo una immagine 6x8 nel seguente modo:  
X = tf.Variable(tf.ones((
 6
, 
8
))) 
X[:, 
2
:
6
].assign(tf.zeros(X[:, 
 2
:
6
].shape))  
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
8
) dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
]], dtype=float32)>  
Costruiamo un kernel 1x2  
K = tf.constant([[
 1.0
, -
1.0
]]) 
Con la crosscorrelazione, l'output è 0 quando due elementi adiacenti 
dell'input sono uguali, altrimenti un valore diverso da 0.  
Nota
 : la crosscorrelazione corrisponde ad una approssimazione 
discreta della derivata del primo ordine.
",esempio riconoscimento bordi supponiamo vogliamo riconoscere bordoe immagine monitorando cambio valore pixel costruiamo immagine seguente modo shape tfvariable variable shape dtypefloat numpy array dtypefloat costruiamo kernel tfconstant loutput quando due elementi adiacenti dellinput uguali altrimenti valore diverso nota corrisponde approssimazione discreta derivata primo ordine
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#8,8,"Esempio: riconoscimento bordi
Si nota il risultato +1 nei bordi da bianco a nero, -1 da nero a bianco:  
Y = corr2d(X, K)  
Y 
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
7
) dtype=float32, numpy=  
array([[ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
]], dtype=float32)>  
Trasponendo l'immagine, il kernel non individua più i bordi:  
corr2d(tf.transpose(X), K)  
<tf.Variable 
 'Variable:0'
  shape=(
 8
, 
5
) dtype=float32, numpy=  
array([[
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
]], dtype=float32)>",esempio riconoscimento bordi nota risultato bordi bianco nero nero bianco corrdx tfvariable variable shape dtypefloat numpy array dtypefloat trasponendo limmagine kernel individua bordi tfvariable variable shape dtypefloat numpy array dtypefloat
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#9,9,"Kernel: training
Al principio non abbiamo kernel precostituiti, dobbiamo ottenerli 
durante l'addestramento, soprattutto se abbiamo molti layer convolutivi 
in cascata. Il procedimento è simile al caso MLP, es:  
# Un layer convolutivo, 2d con 1 canale in output, un kernel 1x2  
# Per semplicità ignoriamo i bias ora  
conv2d = tf.keras.layers.Conv2D(
 1
, (
1
, 
2
), use_bias=
 False
) 
# L'input è nella forma (batch_size, height, width, channel),  
# dove batch size e canali sono entrambi 1  
X = tf.reshape(X, (
 1
, 
6
, 
8
, 
1
)) 
Y = tf.reshape(Y, (
 1
, 
6
, 
7
, 
1
)) 
lr = 
3e-2  
# Learning rate  
Y_hat = conv2d(X)  
for
 i 
in 
range
(
10
): 
    
 with
 tf.GradientTape(watch_accessed_variables=
 False
) 
as
 g: 
        
 # indichiamo noi le variabili su cui operare il gradiente  
        g.watch(conv2d.weights[
 0
]) 
        Y_hat = conv2d(X)  
        l = (
 abs
(Y_hat - Y)) ** 
 2 
        
 # aggiornamento kernel  
        update = tf.multiply(lr, g.gradient(l, conv2d.weights[
 0
])) 
        weights = conv2d.get_weights()  
        weights[
 0
] = conv2d.weights[
 0
] - update  
        conv2d.set_weights(weights)  
        
 if
 (i + 
1
) % 
2
 == 
0
: 
            
 print
(
f'epoch 
 {
i + 
1
}
, loss 
{
tf.reduce_sum(l)
 :
.3f
}
'
) 
epoch 
2
, loss 
17.533 
epoch 
4
, loss 
3.607 
epoch 
6
, loss 
0.878 
epoch 
8
, loss 
0.259 
epoch 
10
, loss 
0.089 
# monitoriamo i tensori ottenuti  
tf.reshape(conv2d.get_weights()[
 0
], (
1
, 
2
))",kernel training principio kernel precostituiti dobbiamo ottenerli durante soprattutto molti layer convolutivi cascata procedimento simile caso layer convolutivo canale output kernel semplicit ignoriamo bias ora convd usebias false linput forma batchsize height width channel batch size canali entrambi tfreshapex tfreshapey learning rate yhat convdx range tfgradient false indichiamo variabili operare gradiente yhat convdx abs yhat aggiornamento kernel update tfmultiplylr ggradientl convdweights weights weights convdweights update print fepoch loss epoch loss epoch loss epoch loss epoch loss epoch loss monitoriamo tensori ottenuti
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
3a parte
1",deep learning universit roma tre dipartimento ingegneria anno accademico convolutional neural networks parte
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#1,1,"Sommario
Calcolo del numero dei parametri  
LeNet-5 e calcolo dei parametri  
Architettura AlexNet  
1x1 convolution",sommario calcolo numero parametri net calcolo parametri architettura alex net convolution
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#10,10,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
11",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#11,11,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 .
12",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#12,12,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
13",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#13,13,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
14",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#14,14,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.
15",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer usare oat bit invece
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#15,15,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.  
5.
Distribuire la computazione
  su più elaboratori.
16",esercizio memoria suf ciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer usare oat bit invece distribuire computazione elaboratori
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#16,16,"Architettura CNN più recenti
Ne sono state proposte molte. Anche se sviluppate in un particolare task di 
computer vision, esse sono state impiegate in modo pro
 ﬁ
cuo in altri domini, es. 
tracking, segmentation, object detection, style transformation.  
La challenge ImageNet (dal 2010) è favorito lo sviluppo di molte architetture.  
Le CNN sono relativamente semplici, ma creare una architettura ef
 ﬁ
ciente 
richiede intuizione, una base algebrica, e molti tentativi.  
Speso nuove architetture sfruttano elementi di architetture precedenti.",architettura recenti state proposte molte sviluppate particolare task computer vision esse state impiegate modo pro cuo altri domini tracking segmentation object detection style transformation challenge image net dal favorito sviluppo molte architetture relativamente semplici creare architettura ciente richiede intuizione base algebrica molti tentativi speso nuove architetture sfruttano elementi architetture precedenti
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#17,17,"Architettura CNN più recenti #1
Sebbene LeNet sia ef
 ﬁ
ciente per il problema OCR, non si adatta facilmente a 
dataset più grandi ed eterogenei. Effettivamente dal 1995 (LeNet) al 2012 (AlexNet) 
sono state proposte tecniche ML alternative (es. kernels, ensemble, structured 
estimation) ef
 ﬁ
cienti in molti tasks.  
Perché abbiamo atteso così a lungo per avere una rete più versatile e capace di 
competere con le altre architetture ML?  
Nel anni '90 una scheda GPU come la NVIDIA GeForce 256 era capace di 480 
MFLOP, senza la disponibilità di framework software per sempli
 ﬁ
care la 
programmazione. Oggi la NVIDIA Ampere A100 raggiunge i 300 TFLOPS . Un 
dataset di cifre a bassa risoluzione (28x28) era considerato molto arduo da trattare.  
In pratica, era molto complesso testare architetture GPU-based anche su 
dataset semplici.  
I 
dati disponibili
  adatti all'addestramento sono aumentati sensibilmente, e questo 
ha garantito la sperimentazione di un numero maggiore di architetture.  
ImageNet è stato costruito mediante Google Image e per mezzo di Amazon 
Mechanical Turk per la classi
 ﬁ
cazione manuale.",architettura recenti sebbene net ciente problema adatta facilmente dataset grandi eterogenei effettivamente net alex net state proposte tecniche alternative kernels ensemble structured estimation cienti molti tasks atteso cos lungo avere rete versatile capace competere altre architetture anni scheda force capace senza disponibilit framework software sempli care programmazione oggi ampere raggiunge dataset cifre bassa risoluzione considerato molto arduo trattare pratica molto complesso testare architetture based dataset semplici dati disponibili adatti aumentati sensibilmente garantito sperimentazione numero maggiore architetture image net stato costruito mediante google image mezzo amazon mechanical turk classi cazione manuale
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#18,18,"LeNet vs AlexNet
AlexNet ha 8 layers: 5 convolutivi, 2 FC nascosti, 1 FC output.  
Usa la ReLU invece delle sigmoid o tanh.
",net alex net alex net layers convolutivi nascosti output usa invece sigmoid tanh
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#19,19,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%) sviluppata da Alex Krizhevsky e 
Ilya Sutskever.  
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.  
E' molto simile a 
 LeNet-5
  ma con più profondità.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer.  
Impiega ReLI, SGD e 
momentum.  
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 NVIDIA 
GTX 580s con 3Gb).",architettura alex net architettura vincitrice challenge object detection top error secondo ottenuto sviluppata alex krizhevsky ilya sutskever primo tentativo sfruttare piattaforme hardware enabled addestrare reti complesse molto simile net profondit dopo convolutional layers max pooling rete layer impiega momentum doppia pipeline dovuta allhardware impiegato laddestramento
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#2,2,"Calcolo del numero di parametri di una rete neurale
Il calcolo del numero di parametri è
  fondamentale per 
comprendere la complessità 
 della rete e apportare miglioramenti 
all'architettura (es. introducendo pooling layer per ridurre i 
parametri).  
Il calcolo dipende dal tipo di layer che stiamo considerando e dai 
valori ricevuti dal layer precedente.  
Consideriamo il calcolo del numero di parametri per le seguenti 
con
ﬁ
gurazioni:  
Un 
Convolutional layer 
 seguito da un 
 FC layer
   (
CONV
 FC
) 
Un
 Input layer 
 seguito da un 
 Convolutional layer
  (
I
FC
) 
Un 
FC layer 
 seguito da un 
 FC layer 
 (
FC
 FC
)
→
→
→",calcolo numero parametri rete neurale calcolo numero parametri fondamentale comprendere complessit rete apportare miglioramenti introducendo pooling layer ridurre parametri calcolo dipende tipo layer considerando valori ricevuti layer precedente consideriamo calcolo numero parametri seguenti gurazioni convolutional layer seguito layer input layer seguito convolutional layer layer seguito layer
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#20,20,"Architettura AlexNet (2)
Le immagini di ImageNet sono 8x più grandi rispetto a MNIST.  
I LRF del primo strato sono 11x11, 5x5 nel secondo e 3x3 nel terzo.  
Dopo il primo, il secondo e 5o strato convolutivo, c'è un 
 max-pooling layers
  con 
ﬁ
nestra 3x3 e uno stride pari a 2.  
AlexNet ha 10 volte i canali di LeNet.  
La rete FC multi-layer ha 1Gb di parametri. La doppia pipeline di elaborazione 
permetteva di suddividere l'occupazione.  
Il numero elevato di parametri rende AlexNet poco ef
 ﬁ
ciente rispetto ad 
architetture più recenti.  
La ReLU rende la computazione dei gradienti più rapida. Inoltre se 
l'inizializzazione dei parametri porta a valori di attivazione vicini ad 1 o 0 
(estremi dell'intervallo) la derivata è vicina allo 0, e questo rallenta 
l'aggiornamento dei pesi. Il gradiente della ReLU è sempre 1 per valori positivi.  ",architettura alex net immagini image net grandi rispetto primo strato secondo terzo dopo primo secondo strato convolutivo max pooling layers nestra stride pari alex net volte canali net rete multi layer parametri doppia pipeline elaborazione permetteva suddividere loccupazione numero elevato parametri rende alex net poco ciente rispetto architetture recenti rende computazione gradienti rapida inoltre parametri porta valori attivazione vicini estremi derivata vicina rallenta laggiornamento pesi gradiente sempre valori positivi
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#21,21,"Architettura AlexNet (3)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signi
 ﬁ
cativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
Il dropout nei layer FC prende il posto del weight decay della LeNet. Questo 
garantisce una sorta di regolarizzazione dei parametri  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
",architettura alex net impiega dropout strati data augumentation layer impiega local response normalization nodo riceve attivazione signi cativa inibiscono nodi stessa posizione altre feature maps dropout layer prende posto weight decay net garantisce sorta parametri lipotesi favorire competitivit specializzando ogni feature map caratteristiche distinte
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#22,22,"Esempio: Filtri di AlexNet
Esempi di 
 ﬁ
ltri dei primi layer di Alex Net dopo l'addestramento:
",esempio filtri alex net esempi ltri primi layer alex net dopo
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#23,23,"AlexNet e Keras
08-AlexNet.ipynb",alex net keras alex netipynb
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#24,24,"La 
1
1 convolution
  è un 
 ﬁ
ltro di dimensione 
 1
1
C
 e (ovviamente) si 
applica a input con profondità 
 C
. 
•
Può essere vista come una 
 rete neurale con un layer,
  che prende in input 
un vettore di 
 C
 elementi.  
•
Per 
C
 pari a 
 1 
non viene impiegato  
•
Un 
ﬁ
ltro 1
 1
1 corrisponde ad una moltiplicazione per uno scalare, operazione 
inutile in una rete neurale.  
A cosa può servire?
×
 ×
×
×
×
CNN: 1
 1 convolution
×
output layer precedente :
supponi una profondità C > 1feature map  
avrà la stessa 
dimensione dell'input 
ma profondità pari a 1
dimensione LRF : 
11C××",convolution ltro dimensione ovviamente applica input profondit pu essere vista rete neurale layer prende input vettore elementi pari viene impiegato ltro corrisponde moltiplicazione scalare operazione inutile rete neurale cosa pu servire convolution output layer precedente supponi profondit feature map stessa dimensione dellinput profondit pari dimensione c
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#25,25,"CNN: 1x1 convolution (2)
Effettua un 
 feature pooling
  cioè combina linearmente più features legate tra 
loro da un certa legame spaziale (es. i 3 valori dei canali RGB di un pixel).  
•
Utile quando si hanno feature maps con grande profondità e si vuole ridurre 
il numero di paremetri nei layer successivi.  
•
Mentre il 
 pooling
  tradizionale aggrega più feature vicine all'interno della 
stessa feature map.  
Se in input abbiamo una feature maps con profondità 
 C
, ogni mappa 
rappresenterà l'importanza di una diversa feature in una certa posizione. La  
1
1 convolution
  raccoglie le informazioni di 
 C
 features diverse valutate nella 
stessa posizione per determinare un singolo output.
×
1x1 conv
La profondità è passata da 32 a 1.  
Impiegano n ﬁltri 1x1 conv, 
otteniamo una profondità n della 
feature maps in output.",convolution effettua feature pooling cio combina linearmente features legate certa legame spaziale valori canali pixel utile quando feature maps grande profondit vuole ridurre numero paremetri layer successivi mentre pooling tradizionale aggrega feature vicine allinterno stessa feature map input feature maps profondit ogni mappa rappresenter limportanza diversa feature certa posizione convolution raccoglie informazioni features diverse valutate stessa posizione determinare singolo output conv profondit passata impiegano ltri conv otteniamo profondit feature maps output
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#26,26,"CNN: 1x1 convolution (3)
Oltre a ridurre il numero di parametri nei layer successivi in presenza di 
feature maps con grande profondità, la 
 1
1 convolution
  viene usata 
anche per creare nuove 
 proiezioni  
lineari
  a partire dalle feature map 
correnti.  
•
Le proiezioni creazioni 
 nuove features
  determinate dalla combinazioni 
di più feature maps nei layer precedenti. 
×
+verso i layer successivi...",convolution oltre ridurre numero parametri layer successivi presenza feature maps grande profondit convolution viene usata creare nuove proiezioni lineari partire feature map correnti proiezioni creazioni nuove features determinate combinazioni feature maps layer precedenti verso layer successivi
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#3,3,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  nel layer convoluzionale, che 
produrranno i valori delle attivazioni nelle feature maps.  
•
Il layer di input non ha pesi associati.  
Se indichiamo con:  
•
#
W
c
 e #
B
c 
il numero di pesi e bias del layer convoluzionale  
•
f
 la dimensione del LRF  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
C
 profondità delle istanze in input (es. 3 per immagine a colori RGB)  
allora si ha:  
#
W
c
 = f
2 
 C 
 N
c 
    e    #
 B
c
 = N
 c 
Lo stesso risultato si ottiene per con
 ﬁ
gurazioni 
 CONV
 CONV
 , considerando come 
profondità 
 C
 la profondità delle feature maps nel layer precedente.  
Si nota come il numero di parametri è indipendente dalla dimensione X,Y dell'input.
×
×
→
Calcolo del numero dei parametri: 
 I
FC
→",parametri consistono nellinsieme pesi bias layer convoluzionale produrranno valori attivazioni feature maps layer input pesi associati indichiamo con numero pesi bias layer convoluzionale dimensione numero ltri convolutional layer profondit istanze input immagine colori allora stesso risultato ottiene gurazioni considerando profondit profondit feature maps layer precedente nota numero parametri indipendente dimensione dellinput calcolo numero parametri
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#4,4,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso alle 
feature maps prodotte dal convolutional layer precedente.  
Se indichiamo con:  
•
#
W
cf
 e #
B
cf  
il numero di pesi e bias del layer FC  
•
O
 dimensione delle feature maps nel convolutional layer, supponendo larghezza e 
altezza coincidenti.  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
F
 numero dei nodi nel layer FC  
allora si ha:  
#
W
cf
 = O
2 
 N
c 
 F 
   e   
 #B
cf
 = F  
Spesso si opera una ""
 linearizzazione
 "" dell'output del convolutional layer. Se 
abbiamo 
 N
c 
ﬁ
ltri e una dimensione delle feature maps pari a OxO, introduciamo 
una rappresentazione 1-dimensionale con un vettore di 
 O
2
• N
 c
 elementi, passato in 
input al layer fully-connected.
×
×
Calcolo del numero dei parametri: 
 CONV
 FC
→",parametri consistono nellinsieme pesi bias layer connesso feature maps prodotte convolutional layer precedente indichiamo con numero pesi bias layer dimensione feature maps convolutional layer supponendo larghezza altezza coincidenti numero ltri convolutional layer numero nodi layer allora spesso opera linearizzazione delloutput convolutional layer ltri dimensione feature maps pari introduciamo dimensionale vettore elementi passato input layer fully connected calcolo numero parametri
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#5,5,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso al FC 
precedente.  
Se indichiamo con:  
•
#
W
ff
 e #
B
ff 
 il numero pesi e bias del layer FC  
•
F
 il numero di nodi nel layer FC  
•
F
-1
 il numero di nodi nel layer FC precedente  
allora si ha:  
#W
 ff
 = F
 -1 
 F
    e   
 #B
ff
 = F
 ×
Calcolo del numero dei parametri: 
 FC
 FC
→",parametri consistono nellinsieme pesi bias layer connesso precedente indichiamo con numero pesi bias layer numero nodi layer numero nodi layer precedente allora calcolo numero parametri
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#6,6,"LeNet-5: numero di parametri
Indichiamo con 
 f
, 
s
 e 
p
 rispettivamente la dimensione del 
 ﬁ
ltro, stride e 
pooling (dove 0 corrisponde al pooling VALID).
Non è un vero layer ,
ma una linearizzazione dei 
dati: rendiamo ﬂat la 
rappresentazion e
5x5x16 -> 40028x28x6  
feature maps di 6 ﬁltri 
di dimensione 28x28 l'uno
14x14x6  
un pooling layer con f e s pari 
a 2 dimezza le dimensioni ,
ma mantiene uguale la dept h
della feature maps.",net numero parametri indichiamo rispettivamente dimensione ltro stride pooling dove corrisponde pooling vero layer linearizzazione dati rendiamo at rappresentazion feature maps ltri dimensione luno pooling layer pari dimezza dimensioni mantiene uguale dept feature maps
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#7,7,"LeNet-5: numero di parametri (2)
Dopo la convoluzione 
abbiamo 6 ﬁltri 28x28. Dopo il pooling abbiamo  
6 ﬁltri 14x14
Invece di avere 240000 
parametri ne abbiamo 
151600 (vedi commento 
dopo).Stesso procedimento di S2 
ma ora abbiamo 16 ﬁltriPooling
Poolingncl-1 è la profondità  
del  layer precedente. 
supponiamo input depth = 1  
cioè scala di grigiil pooling layer non  
altera la profondità
ognuno dei 28x28 in output 
ha 5x5x6 connessioni col 
layer precedente, cioè 
l’immagine in input.Connections =  
28x28 x 5x5x1x6 = 117600
Connections =  
10x10x5x5x6x10 = 150000",net numero parametri dopo convoluzione ltri dopo pooling ltri invece avere parametri vedi commento dopostesso procedimento ora ltri pooling poolingncl profondit layer precedente supponiamo input depth cio scala grigiil pooling layer altera profondit ognuno output connessioni layer precedente cio limmagine xxx connections xxxxx
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#8,8,"LeNet-5: peculiarità
Nel #3 hidden layer, con lo scopo di ridurre potenziali simmetrie e il numero di 
connessioni, gli autori hanno deciso che
  solo 10 delle 16 features maps sono connesse 
con le 6 features maps del layer precedente
 .  
La tecnica 
 dropout
  introdotta solo successivamente ha automatizzato questo step, 
perciò non si riscontra in architetture più recenti.
Schema di interconnessione tra feature maps impiegato.
Connections =  
10x10x5x5x6x10 = 150000",net peculiarit hidden layer scopo ridurre potenziali simmetrie numero connessioni autori deciso solo features maps connesse features maps layer precedente tecnica dropout introdotta solo successivamente automatizzato step perci riscontra architetture recenti schema feature maps impiegato connections xxxxx
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#9,9,"LeNet-5: numero di parametri (3)
Rendiamo “ ﬂat” l’output 
precedente.  Abbiamo 400 
(5x5x16) nodi dal layer S4. 
Il primo strato fully 
connected layer ha 120 nodi. 
Ogni nodo del layer è 
connesso con i 400 nodi 
dello strato precedente.Fully connected layer con 
84 neuroni.softmax",net numero parametri rendiamo at loutput precedente nodi layer primo strato fully connected layer nodi ogni nodo layer connesso nodi strato connected layer neuronisoftmax
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
4a parte - Architetture
1",deep learning universit roma tre dipartimento ingegneria anno accademico convolutional neural networks parte architetture
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#1,1,"Sommario
Architetture avanzate CNN  
VGG  
NiN 
GoogleNet",sommario architetture avanzate google net
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#10,10,"Poiché le risorse di calcolo necessarie alla VGG sono molto 
maggiori di AlexNet, costruiamo una rete con un numero minore di 
canali, suf
 ﬁ
cienti per il dataset Fashion-MNIST.  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
with
 d2l.try_gpu():  
    model = VGG(arch=((
 1
, 
16
), (
1
, 
32
), (
2
, 
64
), (
2
, 
128
), (
2
, 
128
)), lr=
0.01
) 
    trainer.fit(model, data)  
C'è una similarità tra val_loss e train_loss, con un discostamento 
minimale che può rappresentare un piccolo over
 ﬁ
tting.
Training VGG Network e Keras
",poich risorse calcolo necessarie molto maggiori alex net costruiamo rete numero minore canali suf cienti dataset fashion trainer data dlfashion tbatchsize resize dltrygpu model ggarch data similarit valloss trainloss discostamento minimale pu rappresentare piccolo tting training network keras
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#11,11,"L'upsampling di Fashion-MNIST di un fattore 8 (da 28x28 a 
224x224) è molto inef
 ﬁ
ciente. Prova a modi
 ﬁ
care l'architettura per 
trattare immagini 28x28.
VGG - Esercizio",lupsampling fashion fattore molto inef ciente prova modi care larchitettura trattare immagini esercizio
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#12,12,"Rispetto a LeNet, AlexNet e VGG intervengono principalmente 
creando strutture (conv_layer + pooling) più ""profonde"" e più 
""ampie"".  
Ma i layer FC 
 ﬁ
nali richiedono ancora molti parametri.  
Una semplice VGG-11 richiede matrici 25088x4096, con una 
occupazione di 400Mb di RAM (FP32). Non adatti a sistemi 
embedded e mobile.  
L'architettura Network in network (NiN) blocks consiste in un 1x1 
conv layer che aggiunge non-linearità tra le attivazioni dei canali, e 
un 
global average pooling
  nell'ultimo layer.
Network in Network (NiN)",rispetto net alex net intervengono principalmente creando strutture convlayer pooling profonde ampie layer nali richiedono ancora molti parametri semplice richiede matrici occupazione adatti sistemi embedded mobile larchitettura network network blocks consiste conv layer aggiunge linearit attivazioni canali global average pooling nellultimo layer network network
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#13,13,"Rimpiazza i layer FC di una rete CNN tradizionale con un pooling.  
Prende in input un tensore 3d (height,width,channels) e ricava 
l'avg rispetto al dimensione channels.  
L'idea è generare una feature map per ogni categoria di interesse nel 
task nei layer 
 ﬂ
attening, inviando l'output direttamente alla softmax.  
Introduce una sorta di codi
 ﬁ
ca più diretta tra feature maps e 
categorie di interesse. Le feature maps possono essere interpretate 
come 
 mappe di con
 ﬁ
denze con le categorie
 . 
Non ci sono i parametri tradizionali, e si evitano fenomeni di 
over
ﬁ
tting.  
È più robusto a traslazioni spaziali poiché l'operazione considera 
tutte le informazioni spaziali disponibili.
Global average pooling
",rimpiazza layer rete tradizionale pooling prende input tensore ricava lavg rispetto dimensione channels lidea generare feature map ogni categoria interesse task layer attening inviando loutput direttamente softmax introduce sorta codi diretta feature maps categorie interesse feature maps possono essere interpretate mappe denze categorie parametri tradizionali evitano fenomeni tting robusto traslazioni spaziali poich loperazione considera tutte informazioni spaziali disponibili global average pooling
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#14,14,"Ricordiamo che l'input e output dei conv layers sono tensori 4d: 
istanze, channel, height e width.  
L'input e output di un layer FC sono tensori 2d (istanze, features).  
L'idea è applicare un FC layer a ogni posizione di pixel (per ogni 
height e width). La rete risultante 1x1 conv può essere interpretata 
come un layer FC indipendente per ogni pixel.  
Il blocco NiN è costituito da un conv layer seguito da convoluzioni 
1x1. 
In questo modo non c'è necessità di una grossa rete FC al termine 
dell'architettura.
Blocchi NiN",ricordiamo linput output conv layers tensori istanze channel height width linput output layer tensori istanze features lidea applicare layer ogni posizione pixel per ogni height width rete risultante conv pu essere interpretata layer indipendente ogni pixel blocco costituito conv layer seguito convoluzioni modo necessit grossa rete termine blocchi
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#15,15,"La rete NiN usa le stesse dimensioni dei 
 ﬁ
ltri di AlexNet: 11x11, 5x5 
e 3x3; e le stesse dimensioni dei canali di output.  
Le conv net sono seguite da pooling layer 3x3 con stride 2.  
NiN non include FC layer. Il numero dei canali di output dei blocchi 
NiN corrispondono al numero di classi del task, seguite da un 
global average pooling
 , ottenendo un vettore di logits.  
L'architettura riduce il numero di parametri a scapito del tempo di 
training, più lungo.
Architettura NiN",rete usa dimensioni ltri alex net dimensioni canali output conv net seguite pooling layer stride include layer numero canali output blocchi corrispondono numero classi task seguite global average pooling ottenendo vettore logits larchitettura riduce numero parametri scapito tempo training lungo architettura
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#16,16,"Architettura NiN
",architettura
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#17,17,"NiN in codice Keras:  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
def 
nin_block
 (out_channels, kernel_size, strides, padding):  
    
 return
 tf.keras.models.Sequential([  
    tf.keras.layers.Conv2D(out_channels, kernel_size, strides=strides,  
                           padding=padding),  
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
)])
Blocco NiN in Keras",codice keras import tensorflow pip install apost import tensorflow def ninblock outchannels kernelsize strides padding return doutchannels kernelsize relu doutchannels relu doutchannels relu blocco keras
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#18,18,"class 
NiN
(d2l.Classifier):  
    
 def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            nin_block(
 96
, kernel_size=
 11
, strides=
 4
, padding=
 'valid'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 256
, kernel_size=
 5
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 384
, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            tf.keras.layers.Dropout(
 0.5
), 
            nin_block(num_classes, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.GlobalAvgPool2D(),  
            tf.keras.layers.Flatten()])  
model = NiN()  
X = tf.random.normal((
 1
, 
224
, 
224
, 
1
)) 
for
 layer 
 in
 model.net.layers:  
    X = layer(X)  
    
print
(layer.
__class__
 .
__name__
 ,
'output shape:
 \t
'
, X.shape)  
Sequential output shape:     (
 1
, 
54
, 
54
, 
96
) 
MaxPooling2D output shape:   (
 1
, 
26
, 
26
, 
96
) 
Sequential output shape:     (
 1
, 
26
, 
26
, 
256
) 
MaxPooling2D output shape:   (
 1
, 
12
, 
12
, 
256
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
384
) 
MaxPooling2D output shape:   (
 1
, 
5
, 
5
, 
384
) 
Dropout output shape:        (
 1
, 
5
, 
5
, 
384
) 
Sequential output shape:     (
 1
, 
5
, 
5
, 
10
) 
GlobalAveragePooling2D output shape:         (
 1
, 
10
) 
Flatten output shape:        (
 1
, 
10
)
Architettura NiN in Keras",class def init self numclasses super init self self net ninblock kernelsize strides padding valid pool dpoolsize strides ninblock kernelsize strides padding same pool dpoolsize strides ninblock kernelsize strides padding same pool dpoolsize strides kernelsize strides padding same avg pool model layer layerx print layer class name output shape xshape sequential output shape max pooling output shape sequential output shape max pooling output shape sequential output shape max pooling output shape dropout output shape sequential output shape global average pooling output shape flatten output shape architettura keras
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#19,19,"model = NiN(lr=
 0.05
) 
trainer = d2l.Trainer(max_epochs=
 10
, num_gpus=
 1
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
model.apply_init([
 next
(
iter
(data.get_dataloader(
 True
)))[
0
]], d2l.init_cnn)  
trainer.fit(model, data)  
Training NiN in Keras
",model nlr trainer numgpus data dlfashion tbatchsize resize next iter true dlinitcnn data training keras
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#2,2,"Networks Using Blocks (VGG)
Sebbene 
 AlexNet
  abbia permesso di ottenere buone performance in 
diversi task, non fornisce dei 
 template
  per la realizzazione di nuove 
architetture.  
Il Visual Geometry Group Oxford University ha de
 ﬁ
nito 
l'architettura VGG che consiste in strutture ripetute de
 ﬁ
nite per 
mezzo di istruzioni di loop e subroutines.  
Il 
blocco
  fondamentale della CNN è una sequenza di (i) 
convolutional layer con padding (ii) nonlinearità come la ReLU, (iii) 
pooling layer per ridurre la risoluzione.  
Il problema di questo approccio è che la risoluzione spaziale si 
riduce abbastanza rapidamente. Introduce il limite rigido di 
 log
2
d 
layer convolutivi prima che tutte le dimensioni (
 d
) si esauriscano.  
Per esempio per 
 ImageNet
  non si possono avere più di 8 layer.",networks using blocks sebbene alex net permesso ottenere buone performance diversi task fornisce template realizzazione nuove architetture visual geometry group oxford university nito larchitettura consiste strutture ripetute nite mezzo istruzioni loop subroutines blocco fondamentale sequenza convolutional layer padding nonlinearit iii pooling layer ridurre risoluzione problema approccio risoluzione spaziale riduce abbastanza rapidamente introduce limite rigido log layer convolutivi prima tutte dimensioni esauriscano esempio image net possono avere layer
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#20,20,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁ
ltri negli strati iniziali.  
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
",alcune problematiche seguenti esempi riconosciamo cane posizione dimensione dellanimale molto diverse loro facile determinare giusta dimensione numero ltri strati iniziali nonostante tecnologie apprendimento introdotte architetture molto deep con molti strati pu sempre riproporsi vanishing gradient problem
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#21,21,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identi
 ﬁ
cate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei 
 ﬁ
ltri
. Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo.  
•
Si impiegano 
 ﬁ
ltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function.  
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 .",inception module google net inception module basa ipotesi combinare informazioni provenienti diverse pipeline processamento basate convolutional layer permetta estendere caratteristiche salienti identi cate convolution layer parallelo ognuno diversa dimensione ltri output convolution layers combinati singola struttura consister nellinput layer successivo impiegano ltri dimensioni pari stride padding activation function pratica processa stesso input considerando dimensioni linception module stato impiegato prima volta google net
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#22,22,"CNN: Inception module (GoogleNet)
GoogleNet ha vinto la challenge ImageNet 2015 con una struttura 
che combina le caratteristiche di NiN, blocchi ripetuti, e un mix di 
kernel convolutivi.  
Crea una distinzione tra:  
stem
 (data ingest), primi 2-3 conv layers per estrarre feature a 
basso livello  
body
  (data processing), serie di blocchi convolutivi  
head
  (prediction), per problemi di classi
 ﬁ
cation, segmentation, 
detection, o tracking.  
L'idea è combinare l'output di più conv layer con diverse 
dimensioni in un unico output ",inception module google net google net vinto challenge image net struttura combina caratteristiche blocchi ripetuti mix kernel convolutivi crea distinzione tra stem data ingest primi conv layers estrarre feature basso livello body data processing serie blocchi convolutivi head prediction problemi classi cation segmentation detection tracking lidea combinare loutput conv layer diverse dimensioni unico output
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#23,23,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempli
 ﬁ
care i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali.  
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5.  
•
Sperimentalmente si nota come gli inception module sono più 
ef
ﬁ
cienti se usati negli layer più a valle.
Inception module
",inception module linput dato convolution layers max pooling convolution comprimono profondit dellinput utili soprattutto sempli care dati input convoluzioni richiedono risorse computazionali combinazione possibilit rappresentare feature complesse rispetto singoli nota inception module cienti usati layer valle inception module
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#24,24,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri.  
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module",architettura goog net larchitettura vincitrice object detection challenge raggiungendo top error principale caratteristica profondit layer considerando pooling layers inception module cascata dopo ogni inception module opera average pooling ridurre numero parametri sebbene profonda possiede parametri alex net milioni circa altre tecniche impiegate batch normalization image distortions msprop inception module
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#25,25,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classi
 ﬁ
cazione 
 per mezzo di una softmax.  
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer.  
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati.  
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più ef
 ﬁ
ciente il training e migliorare l’accuracy.
auxiliary classi ﬁerauxiliary classi ﬁer",architettura goog net output due inception module intermedi inception module valutato preliminarmente task classi cazione mezzo softmax affrontare problema vanishing gradient problem dato generano gradienti addizionali hidden layer lontani dallultimo layer valore loss intermedia chiamato auxiliary loss durante training viene combinato linearmente scalato loss dellintera rete produzione test set vengono impiegati nota versioni google net introducono molti espedienti rendere ciente training migliorare laccuracy auxiliary classi erauxiliary classi er
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#26,26,"GoogLeNet: esempio di 
 ﬁ
ltri
",goog net esempio ltri
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#27,27,"Inception e Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
Inception
 (tf.keras.Model):  
    
# `c1`--`c4` sono il numero di canali in output per ogni ramo  
    
 def 
__init__
 (
self
, c1, c2, c3, c4):  
        
 super
().
__init__
 () 
        
 self
.b1_1 = tf.keras.layers.Conv2D(c1, 
 1
, activation=
 'relu'
) 
        
 self
.b2_1 = tf.keras.layers.Conv2D(c2[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b2_2 = tf.keras.layers.Conv2D(c2[
 1
], 
3
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b3_1 = tf.keras.layers.Conv2D(c3[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b3_2 = tf.keras.layers.Conv2D(c3[
 1
], 
5
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b4_1 = tf.keras.layers.MaxPool2D(
 3
, 
1
, padding=
 'same'
) 
        
 self
.b4_2 = tf.keras.layers.Conv2D(c4, 
 1
, activation=
 'relu'
) 
    
 def 
call
(
self
, x): 
        b1 = 
 self
.b1_1(x)  
        b2 = 
 self
.b2_2(
self
.b2_1(x))  
        b3 = 
 self
.b3_2(
self
.b3_1(x))  
        b4 = 
 self
.b4_2(
self
.b4_1(x))  
        
 return
 tf.keras.layers.Concatenate()([b1, b2, b3, b4])",inception keras import tensorflow pip install apost import tensorflow class inception numero canali output ogni ramo def init self super init self activation relu self activation relu self padding same activation relu self activation relu self padding same activation relu self pool padding same self activation relu def call self self self self self self self self return
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#28,28,"GoogleNet e Keras
Uno stack di 9 blocchi 
 inception, 
 organizzati in 3 gruppi 
intramezzati da max-pooling per ridurre le dimensioni, e un global 
average pooling per generare l'ultimo output prima del FC layer.
",google net keras stack blocchi inception organizzati gruppi intramezzati max pooling ridurre dimensioni global average pooling generare lultimo output prima layer
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#29,29,"GoogleNet e Keras
class 
GoogleNet
 (d2l.Classifier):  
    
 def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, 
7
, strides=
 2
, padding=
 'same'
, 
                                   activation=
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b2
(
self
): 
    
 return
 tf.keras.Sequential([  
        tf.keras.layers.Conv2D(
 64
, 
1
, activation=
 'relu'
), 
        tf.keras.layers.Conv2D(
 192
, 
3
, padding=
 'same'
, activation=
 'relu'
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b3
(
self
): 
    
 return
 tf.keras.models.Sequential([  
        Inception(
 64
, (
96
, 
128
), (
16
, 
32
), 
32
), 
        Inception(
 128
, (
128
, 
192
), (
32
, 
96
), 
64
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) ",google net keras class google net def self return strides padding same activation relu pool dpoolsize strides padding same net def self return activation relu padding same activation relu pool dpoolsize strides padding same net def self return inception inception pool dpoolsize strides padding same
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#3,3,"VGG Blocks
L'idea è di impiegare convoluzioni multiple e distinte tra periodici 
downsampling (eg. max-pooling) sotto forma di unico blocco 
funzionale.  
L'ipotesi che 
 diverse dimensioni di convoluzioni (deep e wide) 
possono meglio rappresentare le features signi
 ﬁ
cative
 .  
Per esempio 3x3 convolutions interessa gli stessi pixel della 5x5 
convolutions. Ma l'ultima usa un numero di parametri (
 25•c
2
) come 
tre 3x3 convolutions (
 3•9•c
2
), cioè uno 
 stacking
  di convoluzioni 
3x3. Dimostrano che tali con
 ﬁ
gurazioni (deep & narrow) ottengono 
prestazioni migliori.  
La dimensione della rete con stacking 3x3 può oltrepassare i 100 
layers, un approccio molto comune nelle moderne architetture.",blocks lidea impiegare convoluzioni multiple distinte periodici downsampling max pooling sotto forma unico blocco funzionale lipotesi diverse dimensioni convoluzioni deep wide possono meglio rappresentare features signi cative esempio convolutions interessa pixel convolutions lultima usa numero parametri tre convolutions c cio stacking convoluzioni dimostrano tali gurazioni deep narrow ottengono prestazioni migliori dimensione rete stacking pu oltrepassare layers approccio molto comune moderne architetture
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#30,30,"GoogleNet e Keras
@d2l
.add_to_class(GoogleNet)  
def 
b4
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 192
, (
96
, 
208
), (
16
, 
48
), 
64
), 
        Inception(
 160
, (
112
, 
224
), (
24
, 
64
), 
64
), 
        Inception(
 128
, (
128
, 
256
), (
24
, 
64
), 
64
), 
        Inception(
 112
, (
144
, 
288
), (
32
, 
64
), 
64
), 
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b5
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        Inception(
 384
, (
192
, 
384
), (
48
, 
128
), 
128
), 
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Flatten()])  
@d2l
.add_to_class(GoogleNet)  
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
    
super
(GoogleNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.Sequential([  
        
 self
.b1(), 
self
.b2(), 
self
.b3(), 
self
.b4(), 
self
.b5(), 
        tf.keras.layers.Dense(num_classes)])  ",google net keras net def self return inception inception inception inception inception pool dpoolsize strides padding same net def self return inception inception avg pool net def init self numclasses super google net self init self self net self self self self self
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#31,31,"GoogleNet e Keras
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = GoogleNet(lr=
 0.01
) 
    trainer.fit(model, data)  
",google net keras model google sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape dense output shape model google sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape dense output shape trainer data dlfashion tbatchsize resize dltrygpu model google netlr data
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#32,32,"GoogleNet - vantaggi
GoogleNet richiede meno potenza di calcolo rispetto alle 
architetture precedenti mantenendo una precisione più elevata.  
L'approccio è basato sulla approssimazione dell'architettura senza 
andare a scapito delle prestazioni.  
Introduce un 
 design by block
 , con iperparametri più ""ad alto livello"".",google net vantaggi google net richiede meno potenza calcolo rispetto architetture precedenti mantenendo precisione elevata lapproccio basato approssimazione senza andare scapito prestazioni introduce design block iperparametri alto livello
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#33,33,"Architetture AlexNet, VGG, NiN, GoogleNet
Esercizio
 : valuta la differenza di prestazioni e i tempi di 
addestramento su medesimi dataset (FashionMNIST) o subset di 
dataset più complessi (ImageNet).",architetture alex net google net esercizio valuta differenza prestazioni tempi addestramento medesimi dataset fashion subset dataset complessi image net
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#34,34,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza.  
35
",architetture principali architetture immagini complessit numero operazioni richieste laddestramento accuratezza
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#35,35,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Scarica alcune immagini di animali, ad esempio usando la funzion 
matplotlib.image.mpimg.imread(). Ridimensionali e fai crop 299x299 pixel, 
con 3 canali RGB.  
•
Scarica i modelli pre-addestrati di Inception v3  
•
https://github.com/tensor
 ﬂ
ow/models/tree/master/research/slim  
•
Crea il modello Inception v3 usando la funzione inception_v3() con 
is_training=False, num_classes=1001 nel seguente modo:  
from 
 tensor
 ﬂ
ow.contrib.slim.nets 
 import 
 inceptio
 n
import 
 tensor
 ﬂ
ow.contrib.slim 
 as 
sli
m
X 
= 
tf
.
placeholder
 (
tf
.
ﬂ
oat32
 , 
shape
 =[
None
 , 
299
, 
299
, 
3
]
)
with 
slim
.
arg_scope
 (
inception
 .
inception_v3_arg_scope
 ())
:
logits
 , 
end_points 
 = 
inception
 .
inception_v3
 (
X
, 
num_classes
 =
1001
 , 
is_training
 =
False
 )
predictions 
 = 
end_points
 [
""Predictions""
 ]
saver 
 = 
tf
.
train
.
Saver
 (
)
•
...
",esercizio inception classi cazione immagini problema classi cazione immagini usando inception scarica alcune immagini animali esempio usando funzion ridimensionali crop pixel canali scarica modelli pre addestrati inception crea modello inception usando funzione inceptionv seguente modo tensor import inceptio import tensor owcontribslim sli placeholder oat shape none slim argscope inception logits endpoints inception inceptionv numclasses istraining false predictions endpoints predictions saver train saver
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#36,36,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
... Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Crea una sessione e usa Saver per recuperare il modello pre-addestrato.  
•
Lancia il modello per addestrare le immagini che hai scaricato visualizzando 
le top-5 predictions e la relativa probabilità.  
•
I nomi delle categorie le trovi qui: 
 https://github.com/ageron/handson-ml/
blob/master/datasets/inception/imagenet_class_names.txt  
",esercizio inception classi cazione immagini problema classi cazione immagini usando inception crea sessione usa saver recuperare modello pre addestrato lancia modello addestrare immagini scaricato visualizzando top predictions relativa probabilit nomi categorie trovi qui
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#4,4,"VGG Blocks in Keras
Un funzione che prende come parametri il numero di layer 
convolutivi e il numero di channel di output  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2l
def 
vgg_block
 (num_convs, num_channels):  
    blk = tf.keras.models.Sequential()  
    
 for
 _ 
in 
range
(num_convs):  
        blk.add(  
            tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                   padding=
 'same'
, activation=
 'relu'
)) 
    blk.add(tf.keras.layers.MaxPool2D(pool_size=
 2
, strides=
 2
)) 
    
 return
 blk",blocks keras funzione prende parametri numero layer convolutivi numero channel output import tensorflow pip install apost import tensorflow def vggblock numconvs numchannels blk range numconvs blkadd dnumchannels kernelsize padding same activation relu pool dpoolsize strides return blk
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#5,5,"L'architettura VGG e AlexNet a confronto, con i blocchi funzionali 
che si ripetono:
VGG Network e AlexNet
",larchitettura alex net confronto blocchi funzionali ripetono network alex net
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#6,6,"L'aspetto distintivo sono i layer convolutivi,raggruppati in 
trasformazioni non lineari che medesima dimensione per gruppo.  
Si impiegano 
 ﬁ
ltri 
3x3
 con zero padding in modo da scorrere 
l'intera l'immagine.  
Successivamente c'è lo step di riduzione della risoluzione (2x2 
pooling)  
Al termine ci sono layer FC  
Nota: 100M di parametri nei FC in confronto dei 40M degli strati 
convolutivi
VGG Network",laspetto distintivo layer trasformazioni lineari medesima dimensione gruppo impiegano ltri zero padding modo scorrere lintera limmagine successivamente step riduzione risoluzione pooling termine layer nota parametri confronto strati convolutivi network
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#7,7,"VGG Network - Dettaglio parametri
",network dettaglio parametri
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#8,8,"La prima parte della rete VGG è una successione di blocchi VGG.  
La conv_arch consiste in una lista di tuple (una per blocco), ognuna 
che contiene 2 valori: il numero di conv layers e il numero di 
canali.  
class 
VGG
(d2l.Classifier):  
    
 def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential()  
        
 for
 (num_convs, num_channels) 
 in
 arch: 
            
 self
.net.add(vgg_block(num_convs, num_channels))  
        
 self
.net.add(  
            tf.keras.models.Sequential([  
            tf.keras.layers.Flatten(),  
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(num_classes)]))  
VGG Network e Keras",prima parte rete successione blocchi convarch consiste lista tuple una blocco ognuna contiene valori numero conv layers numero canali class def init self arch numclasses super init self self net numconvs numchannels arch self numchannels self netadd activation relu activation relu network keras
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#9,9,"La VGG originale chiamata 
 VGG-11
  ha 5 blocchi: i primi 2 con un 
conv layer ognuno, e gli 3 con 2 conv layer ognuno. Il 1o blocco ha 
64 canali, e i successivi raddoppiato i canali, 
 ﬁ
no a 512.  
VGG(arch=((
 1
, 
64
), (
1
, 
128
), (
2
, 
256
), (
2
, 
512
), (
2
, 
512
))).layer_summary(  
    (
1
, 
224
, 
224
, 
1
)) 
Sequential output shape:     (
 1
, 
112
, 
112
, 
64
) 
Sequential output shape:     (
 1
, 
56
, 
56
, 
128
) 
Sequential output shape:     (
 1
, 
28
, 
28
, 
256
) 
Sequential output shape:     (
 1
, 
14
, 
14
, 
512
) 
Sequential output shape:     (
 1
, 
7
, 
7
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
La dimensione 
 ﬁ
nale dopo la sequenza dei blocchi è 7x7, seguita 
dal 
ﬂ
attening e il successivo processamento FC.
VGG Network e Keras",originale chiamata blocchi primi conv layer ognuno conv layer ognuno blocco canali successivi raddoppiato canali ggarch sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape dimensione nale dopo sequenza blocchi seguita attening successivo processamento network keras
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
5a parte - Batch Normalization e ResNet
1",deep learning universit roma tre dipartimento ingegneria anno accademico convolutional neural networks parte batch normalization res net
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#1,1,"Sommario
Internal covariate shift  
Batch normalization  
Architettura Residual Network (ResNet)",sommario internal covariate shift batch normalization architettura residual network res net
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#10,10,"Batch Normalization layer
Poiché la BN dipende dalla dimensione del mini batch, e perciò dai dati di 
training, non possiamo ignorarla quando de
 ﬁ
niamo la nostra architettura.  
Per reti FC si può applicare la BN tra la trasformazione lineare e il calcolo 
della funzione di attivazione.  
Per conv layers l'approccio è simile, ma consideriamo la BN per ogni 
singolo canale, valutandola sui i dati sparsi spazialmente. Perciò ogni canale 
avrà una stima diversa di media e deviazione standard.  
Questo è in linea col principio di 
 invarianza spaziale
 , cioè nel calcolo 
possiamo ignorare l'informazione relativa alla posizione.
11",batch normalization layer poich dipende dimensione mini batch perci dati training possiamo ignorarla quando niamo architettura reti pu applicare trasformazione lineare calcolo funzione attivazione conv layers lapproccio simile consideriamo ogni singolo canale valutandola dati sparsi spazialmente perci ogni canale stima diversa media deviazione standard linea principio invarianza spaziale cio calcolo possiamo ignorare linformazione relativa posizione
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#11,11,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci:
12",batch normalization altri vantaggi dimostra empiricamente oltre ridurre vanishing gradients garantisce ulteriori bene
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#12,12,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).
13",batch normalization altri vantaggi dimostra empiricamente oltre ridurre vanishing gradients garantisce ulteriori bene permette impiegare funzioni attivazione saturano input molto grandi piccoli logistic tanh
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#13,13,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 .
14",batch normalization altri vantaggi dimostra empiricamente oltre ridurre vanishing gradients garantisce ulteriori bene permette impiegare funzioni attivazione saturano input molto grandi piccoli logistic tanh riduce dipendenza effetti certa scelta parametri iniziali
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#14,14,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 . 
•
Richiamo: Introduce una certa 
 regolarizzazione 
 dei parametri, sebbene non 
sostituisce le tecniche più ef
 ﬁ
caci (es. dropout)  
•
Richiamo: Permette l'uso di 
 learning rate più elevati
 , riducendo i tempi di 
apprendimento.  
•
Es. Per un tipico task di image classi
 ﬁ
cation, si ottengono incrementi x14.
15",batch normalization altri vantaggi dimostra empiricamente oltre ridurre vanishing gradients garantisce ulteriori bene permette impiegare funzioni attivazione saturano input molto grandi piccoli logistic tanh riduce dipendenza effetti certa scelta parametri iniziali richiamo introduce certa parametri sebbene sostituisce tecniche caci dropout richiamo permette luso learning rate elevati riducendo tempi apprendimento tipico task image classi cation ottengono incrementi
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#15,15,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?
16",batch normalization limitiamo normalizzare dati input ogni layer lasciare rete determinare parametri lottimalit input output
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#16,16,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?  
Se impieghiamo funzioni di attivazioni logistiche, 
 forziamo al rete a 
lavorare in regime di quasi-linearità
 , riducendo la capacità di costruire 
relazioni input-output non lineari.
17",batch normalization limitiamo normalizzare dati input ogni layer lasciare rete determinare parametri lottimalit input output impieghiamo funzioni attivazioni logistiche forziamo rete lavorare regime quasi linearit riducendo capacit costruire relazioni input output lineari
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#17,17,"Batch Normalization e LeNet - Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
BNLeNet
(d2l.Classifier):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(filters=
 6
, kernel_size=
 5
, 
                                   input_shape=(
 28
, 
28
, 
1
)), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Conv2D(filters=
 16
, kernel_size=
 5
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Flatten(), tf.keras.layers.Dense(
 120
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(
 84
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(num_classes)])  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
) 
with
 d2l.try_gpu():  
    model = BNLeNet(lr=
 0.5
) 
    trainer.fit(model, data)
18
",batch normalization net keras import tensorflow pip install apost import tensorflow class nle net def init self numclasses super init self self net dfilters kernelsize inputshape sigmoid pool dpoolsize strides dfilters kernelsize sigmoid pool dpoolsize strides sigmoid sigmoid trainer data dlfashion tbatchsize dltrygpu model nle netlr data
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#18,18,"Architettura Residual Network - Motivazioni
In generale, architetture di reti complesse (es. più profonde) possono stimare 
una classe più ampia di funzioni. Ma se aggiungiamo layer, nessuno ci 
garantisce che l'apprendimento ci permette di trovarle, anzi in taluni casi 
possiamo allontanarci dall'ottimo.  
Inoltre reti profonde potrebbero soffrire del vanishing gradient problem.  
Ma se aggiungiamo layer che mirano a stimare una funzione identità, i.e., 
f(x)=x, sicuramente manteniamo la stessa ef
 ﬁ
cacia della rete iniziale.  
L'ipotesi è che, i layer che aggiungiamo alla rete dovrebbero avere più 
probabilità nel rappresentare funzioni identità per garantire prestazioni ottimali.",architettura residual network motivazioni generale architetture reti complesse profonde possono stimare classe ampia funzioni aggiungiamo layer nessuno garantisce lapprendimento permette trovarle anzi taluni casi possiamo allontanarci dallottimo inoltre reti profonde potrebbero soffrire vanishing gradient problem aggiungiamo layer mirano stimare funzione identit fxx sicuramente manteniamo stessa cacia rete iniziale lipotesi che layer aggiungiamo rete dovrebbero avere probabilit rappresentare funzioni identit garantire prestazioni ottimali
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#19,19,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers.  
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice e veloce propagare segnali 
 su varie parti 
della rete.  
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
",architettura residual network res net res net stata presentata top consiste layers introducono skip connections propagano loutput certo layer nellinput layer posizionato valle lipotesi rendere semplice veloce propagare segnali varie parti rete fasi iniziali comportamento random obbliga parti rete comportarsi modo riproporre valori input rendendo veloce lapprendimento
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#2,2,"Motivazioni
L'addestramento delle architetture Deep mostra alcune problematiche 
aggiuntive oltre quelle già discusse per le MLP. Una signi
 ﬁ
cativa è il tempo 
necessario per addestrarle.  
Spesso si operano 
 standardizzazioni
  nei valori delle features in ingresso con 
forme di pre-processamento, es:  
imporre µ=0 (zero mean) o la unit-variance (cioè dividere per la stddev)  
zero mean
  sul valore delle features, considerando la singola istanza; spesso 
utile per dati con informazioni spaziali.  
Ci garantisce che durante l'addestramento i valori dei parametri rimangano in 
intervalli ottimali, sia considerando i layer per l'intera profondità della rete, sia 
tra i nodi di un singolo layer, sia tra i valori di ogni parametro per la durata 
dell'addestramento.",motivazioni laddestramento architetture deep mostra alcune problematiche aggiuntive oltre gi discusse signi cativa tempo necessario addestrarle spesso operano valori features ingresso forme pre processamento imporre zero mean unit variance cio dividere stddev zero mean valore features considerando singola istanza spesso utile dati informazioni spaziali garantisce durante laddestramento valori parametri rimangano intervalli ottimali considerando layer lintera profondit rete nodi singolo layer valori ogni parametro durata
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#20,20,"ResNet: Residual learning e residual block
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning o mapping
 . 
Dal punto di vista operativo, è suf
 ﬁ
ciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
",res net residual learning residual block addestrare rete neurale pu essere interpretato approssimare funzione aggiungi valore alloutput rete allora rete obbligata modellare funzione tale approccio chiamato residual learning mapping punto vista operativo suf ciente combinare loutput layer loutput layer posizionato monte prima valutare funzione attivazione
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#21,21,"Architettura ResNet
L'architettura ResNet impiega conv layer 3x3 (simili a VGG).  
Ogni blocco ResNet ha due 3x3 conv layer seguite dalla batch normalization e 
attivazione ReLU. Prima dell'ultima ReLU sommiamo l'input dalla skip 
connection.  
La 1x1 conv layer è necessaria per adattare i canali dell'input con quelli 
ottenuti a valle del blocco.
",architettura res net larchitettura res net impiega conv layer simili ogni blocco res net due conv layer seguite batch normalization attivazione prima dellultima sommiamo linput skip connection conv layer necessaria adattare canali dellinput ottenuti valle blocco
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#22,22,"Blocco ResNet e Keras
class 
Residual
 (tf.keras.Model):  
    
def 
__init__
 (
self
, num_channels, use_1x1conv=
 False
, strides=
 1
): 
        
 super
().
__init__
 () 
        
 self
.conv1 = tf.keras.layers.Conv2D(num_channels, padding=
 'same'
, 
                                            kernel_size=
 3
, strides=strides)  
        
 self
.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                            padding=
 'same'
) 
        
 self
.conv3 = 
 None 
# dipende se vogliamo usare o meno il 1x1 conv layer  
        
 if
 use_1x1conv:  
            
 self
.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 1
, 
                                                strides=strides)  
        
 self
.bn1 = tf.keras.layers.BatchNormalization()  
        
 self
.bn2 = tf.keras.layers.BatchNormalization()  
    
def 
call
(
self
, X): 
        Y = tf.keras.activations.relu(
 self
.bn1(
self
.conv1(X)))  
        Y = 
 self
.bn2(
self
.conv2(Y))  
        
 if 
self
.conv3 
is 
not 
None
: 
            X = 
 self
.conv3(X)  
        Y += X  
        
 return
 tf.keras.activations.relu(Y)  
blk = Residual(
 3
) 
X = tf.random.normal((
 4
, 
6
, 
6
, 
3
)) 
Y = blk(X)  
Y.shape 
TensorShape([
 4
, 
6
, 
6
, 
3
]) ",blocco res net keras class residual def init self numchannels usexconv false strides super init self conv dnumchannels padding same kernelsize self conv dnumchannels kernelsize padding same self conv none dipende vogliamo usare meno conv layer usexconv self conv dnumchannels kernelsize self normalization self normalization def call self self self convx self self convy self conv none self convx return blk residual blkx yshape tensor shape
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#23,23,"Architettura ResNet-18
I primi layer di ResNet sono simili a GoogleNet, ma in ResNet si usa la Batch 
normalization.  
Seguono vari moduli ripetuti ResNet. La ResNet-18 include 18 layer totali, ma 
si hanno modelli addestrati con molti più layer, es. ResNet-152.
",architettura res net primi layer res net simili google net res net usa batch normalization seguono vari moduli ripetuti res net res net include layer totali modelli addestrati molti layer res net
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#24,24,"Architettura ResNet e Keras
class 
ResNet
(d2l.Classifier):  
    
def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, kernel_size=
 7
, strides=
 2
, 
                                   padding=
 'same'
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(ResNet)  
def 
block
(
self
, num_residuals, num_channels, first_block=
 False
): 
    blk = tf.keras.models.Sequential()  
    
for
 i 
in 
range
(num_residuals):  
        
 if
 i == 
0 
and 
not
 first_block:  
            blk.add(Residual(num_channels, use_1x1conv=
 True
, strides=
 2
)) 
        
 else
: 
            blk.add(Residual(num_channels))  
    
return
 blk 
@d2l
.add_to_class(ResNet)  
def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
    
super
(ResNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.models.Sequential(
 self
.b1()) 
    
for
 i, b 
in 
enumerate
 (arch): 
        
 self
.net.add(
 self
.block(*b, first_block=(i==
 0
))) 
    
self
.net.add(tf.keras.models.Sequential([  
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Dense(units=num_classes)]))  ",architettura res net keras class res net def self return kernelsize strides padding same relu pool dpoolsize strides padding same net def block self numresiduals numchannels firstblock false blk range firstblock usexconv true strides else return blk net def init self arch numclasses super res net self init self self net self enumerate arch self netadd self blockb self avg pool
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#25,25,"Architettura ResNet e Keras
class 
ResNet18
 (ResNet):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 (((
2
, 
64
), (
2
, 
128
), (
2
, 
256
), (
2
, 
512
)), 
                       lr, num_classes)  
ResNet18().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
128
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
256
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = ResNet18(lr=
 0.01
) 
    trainer.fit(model, data)  
",architettura res net keras class res net res net def init self numclasses super init numclasses res sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape sequential output shape trainer data dlfashion tbatchsize resize dltrygpu model res netlr data
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#26,26,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?
27",esercizio quali innovazioni alex net rispetto net riguarda google net res net
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#27,27,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.
28",esercizio quali innovazioni alex net rispetto net riguarda google net res net alex net profonda ampia rispetto net crea stack convolutional layer sullaltro invece alternarli pooling layer
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#28,28,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.
29",esercizio quali innovazioni alex net rispetto net riguarda google net res net alex net profonda ampia rispetto net crea stack convolutional layer sullaltro invece alternarli pooling layer google net impiega inception modules permettono avere reti ancora profonde meno parametri rispetto precedenti
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#29,29,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.  
•
ResNet
  introduce le skip connections, che permettono un numero di layer 
oltre i 100. Anche la relativa semplicità la contraddistingue. 
30",esercizio quali innovazioni alex net rispetto net riguarda google net res net alex net profonda ampia rispetto net crea stack convolutional layer sullaltro invece alternarli pooling layer google net impiega inception modules permettono avere reti ancora profonde meno parametri rispetto precedenti res net introduce skip connections permettono numero layer oltre relativa semplicit
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#3,3,"Motivazioni
Inoltre un layer che produce valori di attivazione molto elevati rispetto agli altri 
(es. x100) richiede aggiustamenti (es. modi
 ﬁ
cando il learning rate in modo 
adattivo per produrre variazioni più ef
 ﬁ
caci durante il training).  
In
ﬁ
ne, per affrontare l'over
 ﬁ
tting è spesso utile introdurre 
 regolarizzazioni
  sul 
valore dei parametri (es. aggiungendo del rumore).",motivazioni inoltre layer produce valori attivazione molto elevati rispetto altri richiede aggiustamenti modi cando learning rate modo adattivo produrre variazioni caci durante training affrontare lover tting spesso utile introdurre valore parametri aggiungendo rumore
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#30,30,"Esercizio su CNN e MNIST
Prova costruire una tua architettura CNN (cioè con uno o più convolution 
layers, pooling layers, etc) per raggiungere la migliore accuratezza per i 
dataset MNIST.  
•
MNIST dataset: 
 http://yann.lecun.com/exdb/mnist/   
•
MNIST e Tensor
 ﬂ
ow: 
https://www.tensor
 ﬂ
ow.org/quantum/tutorials/mnist  
",esercizio prova costruire architettura cio convolution layers pooling layers etc raggiungere migliore accuratezza dataset dataset tensor
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#4,4,"Internal covariate shift
Con 
Internal covariate shift
  si indica la circostanza in cui 
 la distribuzione 
dei valori di attivazione nella rete cambia a causa della variazione dei 
parametri durante il training
 .  
•
Fenomeno fondamentale nelle architetture deep (con molti layers).  
•
E' chiaro che i parametri in
 ﬂ
uenzano le attivazioni, ma 
 la distribuzione 
dei valori 
 non dovrebbe alterarsi a causa dei parametri.  
•
Il vanishing/exploding gradient ricade in questa circostanza.  
•
ReLU, e le sue varianti, riducono il fenomeno ma non lo escludono.  
L'obiettivo è ridurre il 
 covariance shift
  all'interno della reti.
5",internal covariate shift internal covariate shift indica circostanza distribuzione valori attivazione rete cambia causa variazione parametri durante training fenomeno fondamentale architetture deep con molti layers chiaro parametri uenzano attivazioni distribuzione valori dovrebbe alterarsi causa parametri gradient ricade circostanza varianti riducono fenomeno escludono lobiettivo ridurre covariance shift allinterno reti
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#5,5,"Batch Normalization
La 
batch normalization
  (
BN
) è una tecnica per affrontare tale problema. 
Prima della funzione di attivazione di ogni layer:  
•
Normalizza gli input
 , centrandoli in 0 e dividendoli per la deviazione 
standard 
 σ
. 
•
Introduce 
 2 parametri
 , uno per determinare la 
 scalatura
  e uno per lo 
 shift
. 
Tali parametri saranno soggetti ad addestramento.  
Dopo la normalizzazione 
 la rete apprende il valore medio e la scala più 
giusta degli input per ogni layer
 . 
•
La normalizzazione è frequente nei dati in ingresso degli approcci basati su 
ML. La tecnica proposta estende tale tecnica ad ogni layer della rete.  
Per normalizzare bisogna prima conoscere valor medio e varianza dei dati. 
Si stimano entrambi 
 impiegando 
 mini-batch,  
cioè un piccolo sottoinsieme 
del training set. Da questo il termine 
 batch normalization
 .
6",batch normalization batch normalization tecnica affrontare tale problema prima funzione attivazione ogni layer normalizza input centrandoli dividendoli deviazione standard introduce parametri determinare scalatura shift tali parametri soggetti addestramento dopo normalizzazione rete apprende valore medio scala giusta input ogni layer normalizzazione frequente dati ingresso approcci basati tecnica proposta estende tale tecnica ogni layer rete normalizzare bisogna prima conoscere valor medio varianza dati stimano entrambi impiegando mini batch cio piccolo sottoinsieme training set termine batch normalization
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#6,6,"Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
7
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare",batch normalization consiste algoritmo applicato ogni singola istanza input considerando mini batch istanze media varianza parametri apprendere durante training scale offset costante aggiunta varianza evitare divisione ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift trasformazione lineare
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#7,7,"Batch Normalization - Considerazioni
La tecnica BN può essere impiegata sui singoli layer, soprattutto sugli 
hidden, oppure all'intera rete.  
La stima di media e deviazione standard sono ricavate sul mini batch 
corrente.  
Possiamo interpretare i parametri 
 scale
  e 
offset
  stimati durante 
l'apprendimento come un mezzo per ""recuperare"" i gradi di libertà persi a 
causa della normalizzazione e limitarsi a considerare mini-batch invece 
dell'intero dataset.  
Con mini-batch di dimensione adeguata (un iperparametro da de
 ﬁ
nire) si 
raggiungono buoni incrementi di prestazioni e una 
 stabilità
  nell'andamento. 
Ma richiede un tuning che dipende dai dati impiegati.  
La tecnica non permette al valore dei parametri di divergere. Inoltre permette 
di incrementare il 
 learning rate
 . 
8",batch normalization considerazioni tecnica pu essere impiegata singoli layer soprattutto hidden oppure allintera rete stima media deviazione standard ricavate mini batch corrente possiamo interpretare parametri scale offset stimati durante lapprendimento mezzo recuperare gradi libert persi causa normalizzazione limitarsi considerare mini batch invece dellintero dataset mini batch dimensione adeguata iperparametro nire raggiungono buoni incrementi prestazioni stabilit nellandamento richiede tuning dipende dati impiegati tecnica permette valore parametri divergere inoltre permette incrementare learning rate
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#8,8,"Batch Normalization - Considerazioni (2)
Può sembrare illogico introdurre approssimazioni nei valori di media e 
deviazione standard, ma nella pratica rappresentano una sorta di rumore 
introdotto arti
 ﬁ
cialmente che garantisce tempi più rapidi e minor effetto 
over
ﬁ
tting.  
Valori spesso ottimali della dimensione del mini batch sono 50-100 istanze, 
che garantiscono la giusta 
 quantità di rumore
  introdotto durante 
l'apprendimento.
9",batch normalization considerazioni pu sembrare illogico introdurre approssimazioni valori media deviazione standard pratica rappresentano sorta rumore introdotto arti cialmente garantisce tempi rapidi minor effetto tting valori spesso ottimali dimensione mini batch istanze garantiscono giusta quantit rumore introdotto durante
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#9,9,"Batch Normalization - Considerazioni (3)
In casi particolari 
 γ
 e 
β
 possono assumere valori tali da ""invertire"" il processo 
di normalizzazione degli input del processo di 
 batch normalization
 , se 
questo garantisce l'ottimalità durante il training.  
La BN può essere vista come una 
 trasformazione lineare
 , perciò facilmente 
differenziabile
  durante il calcolo dei gradienti.  
La normalizzazione basata su mini-batch è essenziale per garantire 
l'ef
ﬁ
cienza di tale tecnica, ma è inutile nel test e in produzione.  
In 
produzione
  vogliamo una rete che renda l'output dipendente 
unicamente e deterministicamente dall'input
 , perciò non in
 ﬂ
uenzata 
dallo speci
 ﬁ
co mini-batch.  
Per tale motivo la normalizzazione sarà calcolata sull'intera popolazione 
 {x} 
con valori di media e varianza costanti durante l'elaborazione:
10
",batch normalization considerazioni casi particolari possono assumere valori tali invertire processo normalizzazione input processo batch normalization garantisce lottimalit durante training pu essere vista trasformazione lineare perci facilmente differenziabile durante calcolo gradienti normalizzazione basata mini batch essenziale garantire lef cienza tale tecnica inutile test produzione produzione vogliamo rete renda loutput dipendente unicamente dallinput perci uenzata speci mini batch tale motivo normalizzazione calcolata sullintera popolazione valori media varianza costanti durante lelaborazione
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep
1",deep learning universit roma tre dipartimento ingegneria anno accademico laddestramento reti neurali deep
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#1,1,"Sommario
Motivazioni dell'apprendimento speci
 ﬁ
co per reti Deep  
Vanishing/Exploding gradients  
La funzione di attivazione softmax  
Inizializzazione dei parametri  
Funzione di attivazione ReLU e variazioni  
Batch normalization  
Gradient clipping  
Reusing Pretrained layers - Transfer learning  
Unsupervised Pretraining  
Pretraining su Auxiliary tasks",sommario motivazioni speci reti deep gradients funzione attivazione softmax parametri funzione attivazione variazioni batch normalization gradient clipping reusing pretrained layers transfer learning unsupervised pretraining pretraining auxiliary tasks
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#10,10,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
11",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#11,11,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
12",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#12,12,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
13",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#13,13,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
14",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#14,14,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
15",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#15,15,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
16",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#16,16,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
17",xavier schema dimostrazione impiegare distribuzione casuale gaussiana media sembra ragionevole porre vincolo varianza consideriamo singolo neurone certo layer input vettore vettore elementi matrice pesi vale anche supponendo indipendenti vale seguente uguaglianza media pari riduce supponendo indipendenti ogni generato stessa distribuzione imponiamo due varianza identiche allora otteniamo
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#17,17,"Altre inizializzazioni
Ricerche più recenti adattano la suddetta inizializzazione considerando 
diversi scenari di funzione attivazione
 , dove si distinguono per ogni layer il 
numero di connessioni in input (
 n
inputs
) e in output (
 n
outputs
 ). 
Riferimenti:  
•
He et al. 
 Delving Deep into Recti
 ﬁ
ers: Surpassing Human-Level Performance on ImageNet Classi
 ﬁ
cation
  2015
18
Hu initialization →",altre ricerche recenti adattano suddetta considerando diversi scenari funzione attivazione distinguono ogni layer numero connessioni input inputs output outputs riferimenti delving deep recti ers surpassing human level performance image net classi cation initialization
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#18,18,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?
19",pesi usiamo zero initialization valori iniziali uguali
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#19,19,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.
20",pesi usiamo zero initialization valori iniziali uguali valori pesi prossimi favoriscono vanishing gradients problem stesso modo valori troppo grandi saturano logistic function generando gradienti vicini
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo visto architetture di Reti neurali (
 NN
) con più strati (
 layer
 ), ognuno 
composto da molti nodi completamente connessi con i layer precedenti e 
successivi (
 fully connected
 ). 
L'addestramento (training) di tali architetture mostra le seguenti 
problematiche:  
•
Vanishing gradients
  o 
Exploding gradients
 : che rendono la ricerca dei 
parametri molto dif
 ﬁ
cile 
•
Lentezza
 : la stima di molti parametri richiede molto tempo  
•
Over
 ﬁ
tting
: la presenza di molti parametri aumenta la possibilità di 
over
ﬁ
tting (cioè mancanza di generalizzazione).  
Per tale motivo introduciamo
  tecniche di addestramento speci
 ﬁ
che
 per 
affrontarle, che permettono di de
 ﬁ
nire architetture NN più complesse e 
deep
 .
3",motivazioni visto architetture reti neurali strati layer ognuno composto molti nodi completamente connessi layer precedenti successivi fully connected laddestramento training tali architetture mostra seguenti problematiche vanishing gradients exploding gradients rendono ricerca parametri molto dif cile lentezza stima molti parametri richiede molto tempo tting presenza molti parametri aumenta possibilit tting cio mancanza tale motivo introduciamo tecniche addestramento speci affrontarle permettono nire architetture complesse deep
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#20,20,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.  
2.
Per 
valori prossimi allo 0 la logistic function si comporta in modo 
lineare
 .  
•
Tale comportamento ci preclude l'addestramento di funzioni complesse e non 
lineari, anche in presenza di più layer.
21",pesi usiamo zero initialization valori iniziali uguali valori pesi prossimi favoriscono vanishing gradients problem stesso modo valori troppo grandi saturano logistic function generando gradienti vicini valori prossimi logistic function comporta modo lineare tale comportamento preclude laddestramento funzioni complesse lineari presenza layer
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#21,21,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?
22",pesi scegliere singolo valore random diverso pesi
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#22,22,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?  
1.
Avere 
 una rete inizializzata con gli stessi valori implica avere stessi 
gradienti e stessi aggiornamenti per ogni nodo di un layer
 .  
•
Uno degli obiettivi della inizializzazione dei parametri è 
 rompere eventuali 
simmetrie
  nel comportamento della rete.  
•
La simmetria 
 non permette di specializzare diversi neuroni su diversi scopi
 .  
•
Un layer con tutti nodi con lo stesso peso è equivalente ad un layer con un 
singolo nodo.  
•
La 
backpropagation  
non è in grado di risolvere in modo adeguato questo tipo 
di simmetrie
 .
23",pesi scegliere singolo valore random diverso pesi avere rete inizializzata valori implica avere gradienti aggiornamenti ogni nodo layer obiettivi parametri rompere eventuali simmetrie comportamento rete simmetria permette specializzare diversi neuroni diversi scopi layer nodi stesso peso equivalente layer singolo nodo backpropagation grado risolvere modo adeguato tipo simmetrie
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#23,23,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?
24",pesi possiamo inizializzare valore bias
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#24,24,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?  
•
È possibile inizializzare i 
 bias
 a 0, oppure seguire il procedimento di 
inizializzazione usato per i pesi 
 w
.
25",pesi possiamo inizializzare valore bias possibile inizializzare bias oppure seguire procedimento usato pesi
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#25,25,"Inizializzazione dei pesi e softmax
La 
softmax
  è spesso usata nella classi
 ﬁ
cazione multi label.  
Tende a dare 
 molta più probabilità
  alle classi associate ai nodi che hanno in 
output 
 attivazione superiori agli altri,
  soprattutto se l'intervallo dei valori 
delle attivazioni è esteso.  
Si cerca di ridurre questo intervallo (ad esempio con vincoli sulla varianza) 
per alleviare questo comportamento ""
 opinionated
 "", soprattutto nelle prime 
fasi di training.  
•
L'inizializzazione dei pesi è fondamentale.  
•
Si garantisce una esplorazione più ampia dello spazio di ricerca.
26
",pesi softmax softmax spesso usata classi cazione multi label tende dare molta probabilit classi associate nodi output attivazione superiori altri soprattutto lintervallo valori attivazioni esteso cerca ridurre intervallo esempio vincoli varianza alleviare comportamento opinionated soprattutto prime fasi training pesi fondamentale garantisce esplorazione ampia spazio ricerca
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#26,26,"Nonsaturing activation functions
La 
logistic function
  è molto popolare, ed è in parte ispirata al 
comportamento di un neurone 
 ﬁ
sico.  
Ma nelle architetture 
 deep
  è più conosciuta la:  
Recti
 ﬁ
ed Linear Function  
ReLU :  
f(x)=max(0,x)  
Fino a pochi anni fa la più popolare nelle architetture deep.
27
",nonsaturing activation functions logistic function molto popolare parte ispirata comportamento neurone sico architetture deep conosciuta recti linear function fxmaxx fino pochi anni popolare architetture deep
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#27,27,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:
28",activation function principali vantaggi sono
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#28,28,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
 .
29",activation function principali vantaggi sono garantisce linearit
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#29,29,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 .
30",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#3,3,"Vanishing/Exploding gradients
L'
algoritmo di backpropagation
  usato per addestrare una NN segue questi passi:  
•
Per ogni coppia input-output si valuta l'errore tra output ottenuto dalla NN e 
output atteso mediante la 
 loss function 
 (o 
cost function
 ). 
•
Si calcola il 
 gradiente
 , cioè l'insieme delle derivate parziali dell'errore rispetto 
ai parametri (pesi), mediante la 
 chain rule
 . 
•
In base a tali valori si aggiornano i pesi in modo da ridurre l'errore, ad esempio 
mediante il 
 gradient descent.  
Impiegando i gradienti per addestrare la rete può capitare di ottenere valori 
molto piccoli (
 vanishing gradients
 ), soprattutto per i layer vicini all'input.  
•
Il gradiente nei primi strati si ottiene come 
 prodotto
  dei gradienti degli strati più 
lontani.  
•
Questo implica che nei primi layer i pesi non vengono pressoché alterati 
durante il training 
 e dif
ﬁ
cilmente si converge ad una soluzione
 .
4",gradients algoritmo backpropagation usato addestrare segue passi ogni coppia input output valuta lerrore output ottenuto output atteso mediante loss function cost function calcola gradiente cio linsieme derivate parziali dellerrore rispetto parametri pesi mediante chain rule base tali valori aggiornano pesi modo ridurre lerrore esempio mediante gradient descent impiegando gradienti addestrare rete pu capitare ottenere valori molto piccoli vanishing gradients soprattutto layer vicini allinput gradiente primi strati ottiene prodotto gradienti strati lontani implica primi layer pesi vengono pressoch alterati durante training dif cilmente converge soluzione
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#30,30,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.
31",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem riduce complessit computazione essendoci componente esponenziale differenziare
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#31,31,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 :
32",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem riduce complessit computazione essendoci componente esponenziale differenziare svantaggi
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#32,32,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
33",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem riduce complessit computazione essendoci componente esponenziale differenziare svantaggi prona allover tting perci usa insieme tecniche ridurre problema dropout
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#33,33,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
34",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem riduce complessit computazione essendoci componente esponenziale differenziare svantaggi prona allover tting perci usa insieme tecniche ridurre problema dropout durante lapprendimento linput combinato pesi genera valore negativo loutput pari pu capitare neuroni smettano generare valori diversi dying lus
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#34,34,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
•
L'intervallo dell'output è 
 [
0,
∞
]
35",activation function principali vantaggi sono garantisce linearit valori prossimi satura valori positivi elevati gradienti sempre signi cativi rispetto logistic tanh riduce vanishing problem riduce complessit computazione essendoci componente esponenziale differenziare svantaggi prona allover tting perci usa insieme tecniche ridurre problema dropout durante lapprendimento linput combinato pesi genera valore negativo loutput pari pu capitare neuroni smettano generare valori diversi dying lus lintervallo delloutput
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#35,35,"Leaky ReLU
Per risolvere il problema
  dying ReLUs
  si introduce la 
 Leaky ReLU 
 o 
LReLU:  
                               
dove 
 α
 è un 
 iperparametro
  (es. 
0.01
) che garantisce un valore diverso da 
 0 
per 
x < 0
 . 
f
(
x
)
=
m
a
x
(
α
⋅
x
,
x
)
36
",leaky risolvere problema dying lus introduce leaky iperparametro garantisce valore diverso
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#36,36,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU):  
α
 viene impostato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
37",altre parametric diviene parametro viene stimato durante training rispetto incrementa performance dataset immagini molto grandi randomized leaky viene impostato modo casuale durante training tenuto sso durante test pu ridurre fenomeni tting exponential linear unit gradiente contro dying media output layer vicina rispetto riduce vanishing problem singolarit cio sempre derivate sebbene richieda tempo calcolo gradiente compensa tasso convergenza veloce
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#37,37,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
38",altre parametric diviene parametro viene stimato durante training rispetto incrementa performance dataset immagini molto grandi randomized leaky viene alterato modo casuale durante training tenuto sso durante test pu ridurre fenomeni tting exponential linear unit gradiente contro dying media output layer vicina rispetto riduce vanishing problem singolarit cio sempre derivate sebbene richieda tempo calcolo gradiente compensa tasso convergenza veloce
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#38,38,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU)
 :     
•
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 Producendo valori <0, la media 
degli output di un layer è più vicina allo 0 rispetto a quella della ReLU, e si riduce il 
vanishing problem.  
•
Non ha singolarità nello 0
 , cioè è sempre derivabile.  
•
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un 
 tasso di 
convergenza più veloce 
 della ReLU.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
39
",altre parametric diviene parametro viene stimato durante training rispetto incrementa performance dataset immagini molto grandi randomized leaky viene alterato modo casuale durante training tenuto sso durante test pu ridurre fenomeni tting exponential linear unit gradiente contro dying producendo valori media output layer vicina rispetto riduce vanishing problem singolarit cio sempre derivabile sebbene richieda tempo calcolo gradiente compensa tasso convergenza veloce
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#39,39,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?
40",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#4,4,"Vanishing/Exploding gradients
In modo simile i 
 gradienti possono aumentare 
 e in alcuni layer il valore può 
eccedere gli intervalli rappresentabili nei framework di NN (
 exploding 
gradients
 ). 
•
Fenomeno che capita spesso nelle 
 Recurrent NN
  che studieremo più avanti  
Più in generale, 
 strati diversi della rete possono aggiornarsi con 
""velocità"" 
 (cioè valori di gradienti)
  molto diverse
 . 
Tali problemi sono ancora più evidenti 
 con funzioni di attivazione con 
valore medio <> 0
 , e 
inizializzazione dei pesi casuale 
 con distribuzione 
gaussiana
 . 
•
Ad esempio, nel caso della 
 logistic 
 (o
 sigmoid
 )
 function
 , per valori in input 
grandi in modulo, la funzioni 
 satura a 0 o 1
 , con 
 derivate
  tendenti allo 
 0
. 
Si ha perciò 
 vanishing gradients
 . 
5",gradients modo simile gradienti possono aumentare alcuni layer valore pu eccedere intervalli rappresentabili framework exploding gradients fenomeno capita spesso recurrent studieremo avanti generale strati diversi rete possono aggiornarsi velocit cio valori gradienti molto diverse tali problemi ancora evidenti funzioni attivazione valore medio pesi casuale distribuzione gaussiana esempio caso logistic sigmoid function valori input grandi modulo funzioni satura derivate tendenti perci vanishing gradients
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#40,40,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
41",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#41,41,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
42",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#42,42,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
43",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti semplicit motiva diffusione sebbene leaky comportino generalmente meglio
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#43,43,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
44",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti semplicit motiva diffusione sebbene leaky comportino generalmente meglio possibilit produrre esattamente torna utile certi task
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#44,44,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
45",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti semplicit motiva diffusione sebbene leaky comportino generalmente meglio possibilit produrre esattamente torna utile certi task tangente iperbolica tanh usata nelloutput layer produrre valori viene usata hidden layers
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#45,45,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
46",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti semplicit motiva diffusione sebbene leaky comportino generalmente meglio possibilit produrre esattamente torna utile certi task tangente iperbolica tanh usata nelloutput layer produrre valori viene usata hidden layers logistic usata nelloutput layer stimare probabilit classi cazione binaria raramente usata hidden layers
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#46,46,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
7.
La 
softmax
  è adatta per ottenere distribuzioni di probabilità su classi 
mutuamente esclusive.
47",funzioni attivazione quali casi impiegheresti leaky varianti tanh logistic softmax buona scelta iniziale reti veloci meglio leaky varianti semplicit motiva diffusione sebbene leaky comportino generalmente meglio possibilit produrre esattamente torna utile certi task tangente iperbolica tanh usata nelloutput layer produrre valori viene usata hidden layers logistic usata nelloutput layer stimare probabilit classi cazione binaria raramente usata hidden layers softmax adatta ottenere distribuzioni probabilit classi mutuamente esclusive
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#47,47,"Gradient clipping
Una tecnica molto facile per ridurre il fenomeno del 
 exploding gradients
  è 
introdurre 
 una soglia per limitare il valore dei gradienti
  durante il 
backpropagation, chiamata 
 gradient clipping
 . 
Chiaramente ponendo valori soglia rischiamo di ridurre l'informazione che 
tali parametri possono propagare.  
La rivedremo tra poco ma nel dominio della regolarizzazione dei parametri 
W
.
48",gradient clipping tecnica molto facile ridurre fenomeno exploding gradients introdurre soglia limitare valore gradienti durante chiamata gradient clipping chiaramente ponendo valori soglia rischiamo ridurre linformazione tali parametri possono propagare rivedremo poco dominio parametri
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#48,48,"Reusing pretrained layers
Addestrare un rete deep complessa 
 richiede molte risorse
 , a volte 
impossibili da avere, ad eccezione di pochi laboratori al mondo.  
Il 
transfer learning
  è l'approccio che ha l'obiettivo di
  ri-utilizzare parametri 
ottenuti da architetture già addestrate 
 su obiettivi simili.  
Ha il duplice vantaggio di ridurre:  
•
il 
tempo di addestramento,  
•
la 
dimensione del training set
  relativo all'obiettivo di interesse.  
Ad esempio, una rete è addestrata a riconoscere animali, piante, automobili, 
etc., mentre siamo interessati a distinguere il modello di certe auto.  
•
Conviene riutilizzare i parametri che permettono di rappresentare speci
 ﬁ
che 
features della classe auto (es. forme di fanali e paraurti) e sfruttarli per 
adattare la rete alle nuove classi.
49",reusing pretrained layers addestrare rete deep complessa richiede molte risorse volte impossibili avere eccezione pochi laboratori mondo transfer learning lapproccio lobiettivo utilizzare parametri ottenuti architetture gi addestrate obiettivi simili duplice vantaggio ridurre tempo addestramento dimensione training set relativo allobiettivo interesse esempio rete addestrata riconoscere animali piante automobili etc mentre interessati distinguere modello certe auto conviene riutilizzare parametri permettono rappresentare speci features classe auto forme fanali paraurti sfruttarli adattare rete nuove classi
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#49,49,"Esempio di complessità della architettura GPT-3
Generative Pre-trained Transformer 3
  (
GPT-3
 ) è un architettura deep creata 
da 
OpenAI
  per ottenere modelli (transformer) di linguaggio naturale.  
Apparsa nel 2020 come evoluzione delle versioni v2 e v1, è popolare 
per la capacità di redigere testo (es. news) simili a quelle scritte da 
persone umane. E' suf
 ﬁ
ciente dare poche parole per farla partire.  
Contiene 175 miliardi di parametri.  
Addestrata su quasi 500 miliardi di parole estratte da varie fonti 
(CommonCrawl, WebText2, Books, Wikipedia)  
Con una GPU cloud Tesla V100 richiederebbe $4.6M e 355 anni per 
l'addestramento.  
Esempi di applicazione: 
 https://beta.openai.com/examples/  
50",esempio complessit architettura generative pre trained transformer architettura deep creata open ottenere modelli transformer linguaggio naturale apparsa evoluzione versioni popolare capacit redigere testo news simili scritte persone umane suf ciente dare poche parole farla partire contiene miliardi parametri addestrata quasi miliardi parole estratte varie fonti common crawl web text books wikipedia cloud tesla richiederebbe anni esempi applicazione
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#5,5,"Logistic (sigmoid) function
6
Saturazione  
(risposta max)  
gradiente basso
Saturazione  
(risposta max )
gradiente basso Quasi-lineare 
derivata costante 
cioè indipendente dagli input
",logistic sigmoid function saturazione risposta max gradiente basso saturazione risposta max gradiente basso quasi lineare derivata costante cio indipendente input
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#50,50,"Reusing pretrained layers
Nelle architetture deep i 
 layer rappresentano features 
 rilevanti per la 
classi
 ﬁ
cazione 
 con diversi livelli di 
 astrazione
 . Ad esempio nel task della 
classi
 ﬁ
cazione delle immagini:  
•
I 
primi layer
  (vicini all'input) si specializzano su  
features di base
 , come 
line, angoli, variazioni cromatiche  
•
I 
layer più vicini all'output
  legano le feature precedenti per rappresentare 
oggetti complessi e relative 
 caratteristiche salienti
  (es. il muso e le orecchie 
di un animale).  
Il transfer learning 
 mira a riutilizzare i parametri (e il tipo di feature) più 
importanti.  
•
I pesi che si riusano si possono 
 congelare, 
 e focalizzare l'addestramento 
solo sui nuovi parametri che dipendono dal nuovo task.  
•
Si sempli
 ﬁ
ca l'addestramento poiché alcuni parametri non si alterano. 
51",reusing pretrained layers architetture deep layer rappresentano features rilevanti classi cazione diversi livelli astrazione esempio task classi cazione immagini primi layer vicini allinput specializzano features base line angoli variazioni cromatiche layer vicini alloutput legano feature precedenti rappresentare oggetti complessi relative caratteristiche salienti muso orecchie animale transfer learning mira riutilizzare parametri tipo feature importanti pesi riusano possono congelare focalizzare laddestramento solo nuovi parametri dipendono nuovo task sempli laddestramento poich alcuni parametri alterano
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#51,51,"Transfer learning - procedimento
Gli output layers della rete iniziale spesso si scartano perché tipicamente 
non riadattabili al nuovo task, cioè non rappresentano le feature signi
 ﬁ
cative 
per il nuovo task e ai nuovi output di interesse.  
Il 
procedimento
  generale del 
 transfer learning
  è il seguente:  
1.
Si tenta di 
 riutilizzare tutti i parametri della vecchia rete
  e si valutano le 
performance.  
2.
Si 
""scongelano"" gli ultimi 1 o 2 layer
  e si permette il loro addestramento, 
valutando miglioramenti.  
3.
In caso il training set sia limitato, 
 si scartano gli ultimi layer,
  e si 
congelano i restanti. Si valutano le performance.  
4.
Se si hanno suf
 ﬁ
cienti dati, i
  layer scartati si rimpiazzano con nuovi 
layer
 , eventualmente aumentano la profondità della rete rispetto a quella 
di partenza.
52",transfer learning procedimento output layers rete iniziale spesso scartano tipicamente riadattabili nuovo task cio rappresentano feature signi cative nuovo task nuovi output interesse procedimento generale transfer learning seguente tenta riutilizzare parametri vecchia rete valutano performance scongelano ultimi layer permette addestramento valutando miglioramenti caso training set limitato scartano ultimi layer congelano restanti valutano performance suf cienti dati layer scartati rimpiazzano nuovi layer eventualmente aumentano profondit rete rispetto partenza
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#52,52,"Reusing pretrained layers
Nota: 
 Il transfer learning è adatto quando le istanze in input hanno feature a basso livello  
(es. numero di pixel di una immagine) simili a quelle delle istanze in input alla nuova rete.
53
Parametri da addestrare,  
parzialmente riutilizzati
Parametri ﬁssi ottenuti  
dalla rete già addestrata.
Rete già addestrata  
per un certo task.Rete da addestrare  
per un task simile.CongelatiNon congelati
}}",reusing pretrained layers nota transfer learning adatto quando istanze input feature basso livello numero pixel immagine simili istanze input nuova rete parametri addestrare parzialmente riutilizzati parametri ssi ottenuti rete gi addestrata rete gi addestrata certo taskrete addestrare task congelati
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#53,53,"Transfer learning
Dove posso trovare parametri già addestrati?
54",transfer learning posso trovare parametri gi addestrati
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#54,54,"Transfer learning
Dove posso trovare parametri già addestrati?  
Sui repository dei framework di DL, o su blog specializzati, si trovano 
elenchi aggiornati di modelli per diversi task, es:  
•
https://github.com/tensor
 ﬂ
ow/models  
•
https://pytorch.org/docs/stable/torchvision/models.html   
I modelli fanno riferimento ad architetture DL conosciute in letteratura  
•
Es. AlexNet, VGG, ResNet, SqueezeNet, DenseNet, Inception v3, GoogLeNet, 
Shuf
ﬂ
eNet v2, MobileNet v2, ResNeXt, Wide ResNet, MNASNet
55",transfer learning posso trovare parametri gi addestrati repository framework blog specializzati trovano elenchi aggiornati modelli diversi task owmodels modelli riferimento architetture conosciute letteratura alex net res net squeeze net dense net inception goog net shuf net mobile net res wide res net snet
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#55,55,"Unsupervised Pretraining
Può capitare di lavorare su un task dove abbiamo 
 un training set di istanze 
labelled
  ridotto
 , e non esistono modelli pre-addestrati da impiegare.  
Nel 
unsupervised pretraining
  la rete viene addestrata 
 uno strato alla volta
 , 
partendo da quello più vicino agli input.  
•
Ogni layer è addestrato impiegando l'output del layer precedente, quindi in 
modo 
 unsupervised
 . 
•
Tutti i layer sono congelati, tranne quello sotto addestramento.  
•
Quando tutti i layer sono stati addestrati, la rete può essere addestrata con 
un approccio 
 ﬁ
ne-tuned 
 supervised
 .  
•
Tipicamente (1) si aggiunge un ultimo layer, (2) si congelano i pesi dei 
layer precedenti, e (3) si considera il training set disponibile.
56",unsupervised pretraining pu capitare lavorare task training set istanze labelled ridotto esistono modelli pre addestrati impiegare unsupervised pretraining rete viene addestrata strato volta partendo vicino input ogni layer addestrato impiegando loutput layer precedente quindi modo unsupervised layer congelati tranne sotto addestramento quando layer stati addestrati rete pu essere addestrata approccio tuned supervised tipicamente aggiunge ultimo layer congelano pesi layer precedenti considera training set disponibile
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#56,56,"Unsupervised Pretraining
La fase di unsupervised permette di creare 
 una approssimazione dei 
parametri (o inizializzazione) 
 utile per la fase di addestramento reale.  
Ipotesi sostengono che tale fase individua il sottoinsieme di 
 minimi
  più 
probabili nello spazio di ricerca.  
È un approccio piuttosto lungo da completare, ma è stato impiegato di 
frequente 
 ﬁ
no alla comparsa delle prime tecniche che hanno affrontato il 
vanishing gradients
  problem. 
57",unsupervised pretraining fase unsupervised permette creare approssimazione parametri utile fase addestramento reale ipotesi sostengono tale fase individua sottoinsieme minimi probabili spazio ricerca approccio piuttosto lungo completare stato impiegato frequente comparsa prime tecniche affrontato vanishing gradients problem
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#57,57,"Unsupervised Pretraining - considerazioni
Ricordiamoci che in una architettura deep è facile ricavare valori di errore 
sugli strati 
 ﬁ
nali, vicini all'output atteso. Ma a causa del vanishing problem, 
 i 
primi strati potrebbero non avere suf
 ﬁ
ciente informazione per il relativo 
addestramento
 . 
L'approccio iterativo del 
 unsupervised pretraining  
addestra 
 uno strato alla 
volta
 , mantenendo costanti gli altri parametri, perciò senza la possibilità che 
possano in
 ﬂ
uenzare il training in modo sub-ottimale.  
•
L'addestramento è suddiviso in più fasi, e in ogni fase abbiamo pochi 
parametri da determinare.  
•
L'
output atteso 
 di un layer sotto addestramento 
 corrisponde all'output dello 
strato precedente
  (approccio unsupervised)  
•
In ogni fase si tenta di identi
 ﬁ
care 
 minimi locali 
 utili per la fase 
 ﬁ
nale.  
Con 
pretraining
  si indica in generale 
 il procedimento di addestrare modelli 
sempli
 ﬁ
cati su dati sempli
 ﬁ
cati 
prima di arrivare al modello 
 ﬁ
nale su dati 
complessi.
58",unsupervised pretraining considerazioni ricordiamoci architettura deep facile ricavare valori errore strati nali vicini alloutput atteso causa vanishing problem primi strati potrebbero avere suf ciente informazione relativo addestramento lapproccio iterativo unsupervised pretraining addestra strato volta mantenendo costanti altri parametri perci senza possibilit possano uenzare training modo sub ottimale laddestramento suddiviso fasi ogni fase pochi parametri determinare output atteso layer sotto addestramento corrisponde alloutput strato precedente approccio unsupervised ogni fase tenta identi care minimi locali utili fase nale pretraining indica generale procedimento addestrare modelli sempli cati dati sempli cati prima arrivare modello nale dati complessi
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#58,58,"Unsupervised Pretraining
59
Layer addestratoLayer addestratoLayer addestratoRete addestrata",unsupervised pretraining layer addestrato layer addestrato layer addestrato rete addestrata
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#59,59,"Pretraining su auxiliary task
Un modo alternativo per addestrare una rete con scarsi dati di training e 
trovare un 
 auxiliary task
 , cioè un task simile che condivide un insieme di 
feature detectors
  salienti con il task di nostro interesse.  
Ipotesi
 : se riusciamo ad addestrare la rete sul task alternativo, potremmo 
riutilizzare i primi layer dato che si sono specializzati sulle features di 
comune interesse.  
Esempio: 
 face detection  
Tipicamente ci sono
  poche istanze 
 per ogni viso da riconoscere.  
Possiamo andare su Google e collezionare facilmente molti visi di 
celebrity. La rete imparerà a riconoscere le 
 feature salienti
  che potranno 
essere impiegate sul nostro training set.  
Un approccio alternativo è ""corrompere"" un sottoinsieme di istanze 
disponibili di una certa classe per associarle ad una classe negativa.
60",pretraining auxiliary task modo alternativo addestrare rete scarsi dati training trovare auxiliary task cio task simile condivide insieme feature detectors salienti task interesse ipotesi riusciamo addestrare rete task alternativo potremmo riutilizzare primi layer dato specializzati features comune interesse esempio face detection tipicamente poche istanze ogni viso riconoscere possiamo andare google collezionare facilmente molti visi celebrity rete imparer riconoscere feature salienti potranno essere impiegate training set approccio alternativo corrompere sottoinsieme istanze disponibili certa classe associarle classe negativa
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#6,6,"Vanishing/Exploding gradients
Una possibilità sarebbe 
 comprimere
  i valori delle attivazioni in un intervallo 
ristretto, ma intorno allo 0 la logistic mostra comportamenti prettamente 
lineari, che non permettono di rappresentare funzioni complesse.
7",gradients possibilit comprimere valori attivazioni intervallo ristretto intorno logistic mostra comportamenti prettamente lineari permettono rappresentare funzioni complesse
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#7,7,"Vanishing/Exploding gradients
8
",gradients
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#8,8,"Vanishing/Exploding gradients problem:  
Cosa succede durante l'addestramento?
Comportamenti tipici in presenza di vanishing gradients problem sono:  
•
Le performance migliorano 
 troppo lentamente
 , o 
non migliorano  
•
Prematura convergenza
  (ma non a valori ottimi)  
•
Analizzando i parametri appresi si notano 
 variazioni più signi
 ﬁ
cative negli 
ultimi strati
 , vicini all'output, 
 rispetto ai primi strati
 .
9",gradients problem cosa succede durante comportamenti tipici presenza vanishing gradients problem sono performance migliorano troppo lentamente migliorano prematura convergenza valori ottimi analizzando parametri appresi notano variazioni signi cative ultimi strati vicini alloutput rispetto primi strati
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#9,9,"Inizializzazione di Xavier e He 
L'obiettivo è garantire la propagazione delle attivazioni (forward) e dei 
gradienti (backward) in modo corretto, cioè senza 
 exploding
  e 
vanishing
 . 
Xavier e He
  propongono di mantenere uguali:  
•
i valori della varianza degli output di ogni layer con la varianza degli input 
del layer successivo
  (forward propagation).  
•
le varianze dei gradienti ottenuti prima e dopo un certo layer
  (backward 
propagation)  
Tali condizioni possono essere veri
 ﬁ
cate solo se ogni layer ha lo 
 stesso 
numero di connessioni in entrata e in uscita
 .  
Introducendo una approssimazione de
 ﬁ
niamo la 
 Xavier initialization
  così:
10I pesi della rete sono inizializzati per ogni layer in modo casuale  
con distribuzione gaussiana  con media 0  e varianza pari a n-1, 
dove n il numero di nodi del layer precedente.",xavier lobiettivo garantire propagazione attivazioni forward gradienti backward modo corretto cio senza exploding vanishing xavier propongono mantenere uguali valori varianza output ogni layer varianza input layer successivo forward propagation varianze gradienti ottenuti prima dopo certo layer backward propagation tali condizioni possono essere veri cate solo ogni layer stesso numero connessioni entrata uscita introducendo approssimazione niamo xavier initialization cos pesi rete inizializzati ogni layer modo casuale distribuzione gaussiana media varianza pari numero nodi layer precedente
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 2: Optimizers, learning rates adattivi
1",deep learning universit roma tre dipartimento ingegneria anno accademico laddestramento reti neurali deep parte optimizers learning rates adattivi
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#1,1,"Sommario
Faster Optimizer  
Momentum optimization  
Nesterov Accelerated Gradient  
AdaGrad Algorithm  
RMSProp algorithm  
Adam Optimization  
Learning rate schedule   
Adaptive learning rate algorithms",sommario faster optimizer momentum optimization nesterov accelerated gradient ada grad algorithm prop algorithm adam optimization learning rate schedule adaptive learning rate algorithms
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#10,10,"Richiami: Gradient descent
•
Alterazioni troppo piccole allungano i tempi di esplorazioni.  
•
Alterazioni troppo grandi (es. learning rate elevati) generare comportamenti 
che possono allontanarci dall'ottimo.
11
Ricerca lenta Ricerca imprecisa",richiami gradient descent alterazioni troppo piccole allungano tempi esplorazioni alterazioni troppo grandi learning rate elevati generare comportamenti possono allontanarci dallottimo ricerca lenta ricerca imprecisa
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#11,11,"Gradient descent vs Stochastic vs Minibatch
•
Gradient descent
 : iteriamo sull'intero training set, cioè su tutte le istanze, 
prima di aggiornare i pesi.  
•
Sebbene la stima dell'errore sia molto precisa, per training set grandi 
dobbiamo attendere molto prima di aggiornare i parametri. Gli output 
sono ricavati con i parametri ricavati nel ciclo precedente, senza poterli 
aggiornare durante l'epoca.  
•
Stochastic Gradient descent (SGD)
 : ad ogni istanza estratta dal training set 
(in modo random) aggiorniamo i parametri.  
•
La stima dei gradienti è approssimata su una singola istanza, perciò poco 
precisa. Ma aggiorniamo i parametri istantaneamente. Convergenza più 
rapida, ma meno probabilità di raggiungere l'ottimo.  
•
Minibatch SGD
 : dopo un minibatch di istanze aggiorniamo i pesi.  
•
Si suppone che il minibatch stimi meglio le variazioni dei parametri 
simulando la stima sull'training set. In altre parole, riduce la varianza sui 
valori stimati. Combina i vantaggi di entrambi.
12",gradient descent stochastic minibatch gradient descent iteriamo sullintero training set cio tutte istanze prima aggiornare pesi sebbene stima dellerrore molto precisa training set grandi dobbiamo attendere molto prima aggiornare parametri output ricavati parametri ricavati ciclo precedente senza poterli aggiornare durante lepoca stochastic gradient descent ogni istanza estratta training set modo random aggiorniamo parametri stima gradienti approssimata singola istanza perci poco precisa aggiorniamo parametri convergenza rapida meno probabilit raggiungere lottimo minibatch dopo minibatch istanze aggiorniamo pesi suppone minibatch stimi meglio variazioni parametri simulando stima sulltraining set altre parole riduce varianza valori stimati combina vantaggi entrambi
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#12,12,"Richiami: (Mini)Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
13
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare",richiami minibatch normalization consiste algoritmo applicato ogni singola istanza input considerando mini batch istanze media varianza parametri apprendere durante training scale offset costante aggiunta varianza evitare divisione ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift trasformazione lineare
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#13,13,"Gradient vs Stochastic Gradient descent
In condizioni ideali (es. convex function) un gradient descent tradizionale è 
l'approccio ottimale per raggiungere il minimo in poche iterazioni.  
L'approccio stocastico introduce rumore che può rallentare il 
raggiungimento del minimo (es. a dx dopo 50 iterazioni non si hanno ancora 
valori ottimali, a sx dopo 20 iterazioni possiamo fermarci).  
Ma generalmente nel DL non abbiamo 
 convex functions
 .
14
",gradient stochastic gradient descent condizioni ideali convex function gradient descent tradizionale lapproccio ottimale raggiungere minimo poche iterazioni lapproccio stocastico introduce rumore pu rallentare raggiungimento minimo dopo iterazioni ancora valori ottimali dopo iterazioni possiamo fermarci generalmente convex functions
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#14,14,"Gradient descent e learning rate
•
Per rendere la ricerca 
 più ef
 ﬁ
ciente 
 potremmo pensare di 
 variare il learning 
rate 
  durante l'esplorazione:  
•
Aumentandolo ulteriormente al principio
 , per rendere la ricerca più rapida,  
e riducendolo alla 
 ﬁ
ne
, soprattutto nel caso del SGD e minibatch SGD, per 
ridurre gli effetti che il rumore possa avere sulla ricerca dell'ottimo.  
•
Nell'esempio, aumentiamo la velocità durante la discesa della curva, e la 
riduciamo quando la curva riduce la pendenza.
η
15
Costo
Θ",gradient descent learning rate rendere ricerca ciente potremmo pensare variare learning rate durante lesplorazione aumentandolo ulteriormente principio rendere ricerca rapida riducendolo soprattutto caso minibatch ridurre effetti rumore possa avere ricerca dellottimo nellesempio aumentiamo velocit durante discesa curva riduciamo quando curva riduce pendenza costo
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#15,15,"Momentum optimization
La 
momentum optimization 
 introduce il concetto di 
 accelerazione
  e 
velocità  
durante l'esplorazione.  
Introduco il 
 vettore momentum  
m
, usato per aggiornare i pesi 
 . Il suo compito è 
interpretare il gradiente 
  come una 
 accelerazione,
  che altera la 
 velocità 
corrente
  rappresentata da 
 . 
 
 
 è chiamato 
 parametro momentum
 , o semplicemente 
 momentum
 , e ha lo scopo 
di evitare che la velocità cresca eccessivamente.  
•
=0 resistenza massima (corrisponde al gradient descent), 
 =1 nessuna resistenza.  
Si veri
 ﬁ
ca facilmente che, se il il valore del gradiente rimane costante, la variazione 
massima dei pesi è 
 . 
•
Per 
 =0.9 e 
 =1
, si ottiene 10 volte il valore del gradiente.
Θ
η
∇
Θ
J
(
Θ
)
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
m
β
β
 β
η
1
1
−
β
β
 η
16",momentum optimization momentum optimization introduce concetto accelerazione velocit durante lesplorazione introduco vettore momentum usato aggiornare pesi compito interpretare gradiente accelerazione altera velocit corrente rappresentata chiamato parametro momentum semplicemente momentum scopo evitare velocit cresca eccessivamente resistenza massima corrisponde gradient descent nessuna resistenza veri facilmente che valore gradiente rimane costante variazione massima pesi ottiene volte valore gradiente
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#16,16,"Momentum optimization (2)
Analogia con una biglia su una super
 ﬁ
cie. La direzione non corrisponde più 
a quella determinata dal gradiente calcolato attualmente, ma in base alle 
media pesata di tutti i gradienti precedenti.  
L'approccio rientra nella classi dei 
 accelerated gradient methods
 . 
Ha molteplici 
 vantaggi
 : 
•
Rende più stabile la ricerca quando qualche gradiente risulta scarsamente 
accurato (es. scelta sbagliata della istanza/minibatch), mediando su una serie 
di valori.  
•
Si 
accelera l'esplorazione
  quando stiamo esplorando spazi dei parametri 
ampi, e dove le super
 ﬁ
ci de
 ﬁ
nite dalla funzione di costo variano lentamente.  
•
L'accelerazione permette più facilmente di 
 evitare (o uscire) minimi locali 
rispetto al gradient descent tradizionale
 . 
Il momentum 
  è un 
 iperparametro da stimare
  caso per caso, ma valori 
intorno allo 
 0.9
 sono molto comuni.
β
17",momentum optimization analogia biglia super cie direzione corrisponde determinata gradiente calcolato attualmente base media pesata gradienti precedenti lapproccio rientra classi accelerated gradient methods molteplici vantaggi rende stabile ricerca quando qualche gradiente risulta scarsamente accurato scelta sbagliata mediando serie valori accelera lesplorazione quando esplorando spazi parametri ampi super nite funzione costo variano lentamente laccelerazione permette facilmente evitare uscire minimi locali rispetto gradient descent tradizionale momentum iperparametro stimare caso caso valori intorno molto comuni
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#17,17,"Momentum optimization
18apprendimento lento
apprendimento veloce
Discesa del gradiente  
con Momentum optimizationDiscesa del gradiente  
tradizionale",momentum optimization apprendimento lento apprendimento veloce discesa gradiente momentum optimization discesa gradiente tradizionale
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#18,18,"Momentum optimization: esempio
10-momentum.ipynb
19",momentum optimization esempio momentumipynb
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#19,19,"Nesterov Accelerated Gradient
Il 
Nesterov Accelerated Gradient
  (
NAG
 ) è una variazione del momentum 
optimization dove il 
 gradiente
  viene valutato non nella posizione corrente 
ma nella direzione del momentum  
 : 
 
 
In genere il vettore momentum indica la direzione verso l'ottimo, perciò 
sembra più logico misurare il gradiente verso quella direzione.  
Queste piccole variazioni si sommano e il NAG si dimostra essere 
 più 
rapido rispetto al momentum optimization
 .
Θ
+
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
+
β
⋅
m
)
Θ
←
Θ
−
m
20",nesterov accelerated gradient nesterov accelerated gradient variazione momentum optimization gradiente viene valutato posizione corrente direzione momentum genere vettore momentum indica direzione verso lottimo perci sembra logico misurare gradiente verso direzione piccole variazioni sommano dimostra essere rapido rispetto momentum optimization
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#2,2,"Gli optimizer
Un 
optimizer
  è un algoritmo usato per alterare i parametri della rete, ed 
eventualmente alcuni iperparametri quali il learning rate, in modo da 
minimizzare la misura di loss.  
Per tale motivo la funzione di loss è anche chiamata 
 objective function
 . 
Nelle architetture deep si impiegano spesso 
 optimizer
  alternativi alla discesa 
del gradiente.  
Concettualmente, l'apprendimento delle architetture DL è ricavare un 
modello adatto al task in base ai dati disponibili, mentre l'optimizer si 
focalizza sulla objective function.  
L'ottimizzazione si focalizza sulla loss è sui dati disponibili, perciò ul 
training error
 . 
Altrettanto fondamentale nel DL è minimizzare l'
 over
ﬁ
tting
, cioè 
massimizzare le capacità di 
 generalizzazione
 . Per questo durante 
l'ottimizzazione dobbiamo includere ulteriori analisi. 
3",optimizer optimizer algoritmo usato alterare parametri rete eventualmente alcuni iperparametri quali learning rate modo minimizzare misura loss tale motivo funzione loss chiamata objective function architetture deep impiegano spesso optimizer alternativi discesa gradiente lapprendimento architetture ricavare modello adatto task base dati disponibili mentre loptimizer focalizza objective function focalizza loss dati disponibili perci training error altrettanto fondamentale minimizzare tting cio massimizzare capacit durante dobbiamo includere ulteriori analisi
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#20,20,"Nesterov Accelerated Gradient
Nello scenario classico di una discesa verso l'ottimo il NAG 
 riduce eventuali 
oscillazioni 
 causate dall'accelerazione puntuale del momentum 
optimization.
21
βm",nesterov accelerated gradient scenario classico discesa verso lottimo riduce eventuali oscillazioni causate puntuale momentum optimization
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#21,21,"AdaGrad Algorithm: Motivazioni
In presenza di 
 dati sparsi
 , i parametri 
  associati alle
  features poco 
frequenti riceveranno update signi
 ﬁ
cativi molto raramente
 .  
•
Se decrementiamo il learning rate durante l'esplorazione, nel caso tali 
features non compaiono al principio del training, 
 è probabile che i relativi 
pesi non verranno aggiornati adeguatamente prima di raggiungere la 
condizione di ottimo.  
Facciamo l'ipotesi  
che il 
 learning rate  
 è legato 
 al numero di volte  
s(i,t)
 che 
abbiamo 
 ""notato"" una certa features 
 i
 durante il training 
 ﬁ
no al tempo 
 t
. 
•
Features frequenti vedranno il learning rate associato ai relativi parametri 
diminuire più velocemente:  
 
Ma se contiamo solo le occorrenze 
 non teniamo in considerazione il valore 
del gradiente
 , a volte molto grande, a volte irrilevante.
Θ
η
η
=
η
0
s
(
i
,
t
)
+
ϵ
22",ada grad algorithm motivazioni presenza dati sparsi parametri associati features poco frequenti riceveranno update signi cativi molto raramente decrementiamo learning rate durante lesplorazione caso tali features compaiono principio training probabile relativi pesi verranno aggiornati adeguatamente prima raggiungere condizione ottimo lipotesi learning rate legato numero volte sit notato certa features durante training tempo features frequenti vedranno learning rate associato relativi parametri diminuire velocemente contiamo solo occorrenze teniamo considerazione valore gradiente volte molto grande volte irrilevante
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#22,22,"AdaGrad Algorithm
Il 
AdaGrad algorithm
  rende il 
 learning rate adattivo
 , dove 
 ogni parametro 
ha un proprio rate
 . 
Per tale motivo si considera un 
 vettore  
s
 che 
 memorizza gli update per ogni 
parametro
  calcolato nel seguente modo:  
 
 
si assume 
 s
0
 = 0. 
La prima espressione accumula nel vettore 
 s
 i quadrati dei gradienti rispetto 
ai parametri  
ﬁ
no all'istante attuale.  
•
Se 
la funzione di costo è ripida
  rispetto ad una direzione 
 i
, la sequenza dei 
gradienti assumeranno un valore elevato
  in modulo, e la componente  
aumenterà ad ogni iterazione.
s
←
s
+
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
Θ
s
i
23...cont",ada grad algorithm ada grad algorithm rende learning rate adattivo ogni parametro proprio rate tale motivo considera vettore memorizza update ogni parametro calcolato seguente modo assume prima espressione accumula vettore quadrati gradienti rispetto parametri allistante attuale funzione costo ripida rispetto direzione sequenza gradienti assumeranno valore elevato modulo componente aumenter ogni iterazione cont
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#23,23,"AdaGrad Algorithm (
 cont.
 )
La seconda è simile alla discesa del gradiente, ma 
 il vettore dei gradienti è 
scalato del fattore  
 , dove 
  è il solito parametro di smoothing per 
evitare divisioni per 0.  
•
Le coordinate che mostreranno spesso gradienti elevati saranno 
maggiormente 
 ridimensionate
 , al contrario, gradienti signi
 ﬁ
cativi sporadici 
o in valore ridotto corrisponderanno a learning rate più importanti.  
I principali vantaggi di 
 AdaGrad
  sono i seguenti:  
•
Adatto a training data sparsi e addestramenti molto lunghi.  
•
Il
 tuning del learning rate super
 ﬂ
uo
. Si imposta a un valore comune,  
es. 
=0.01, evitandolo di considerare come iperparametro da ottimizzare.  
•
La 
complessità computazione è paragonabile alla discesa del gradiente 
tradizionale.
s
+
ϵ
 ϵ
η
24",ada grad algorithm cont seconda simile discesa gradiente vettore gradienti scalato fattore solito parametro smoothing evitare divisioni coordinate mostreranno spesso gradienti elevati maggiormente ridimensionate contrario gradienti signi cativi sporadici valore ridotto learning rate importanti principali vantaggi ada grad seguenti adatto training data sparsi addestramenti molto lunghi tuning learning rate super imposta valore comune evitandolo considerare iperparametro ottimizzare complessit computazione paragonabile discesa gradiente tradizionale
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#24,24,"AdaGrad Algorithm
25
parametro soggetto a gradienti 
elevati e legati a features frequenti
parametro soggetto a gradienti  
ridotti e legati a features sparse",ada grad algorithm parametro soggetto gradienti elevati legati features frequenti parametro soggetto gradienti ridotti legati features sparse
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#25,25,"RMSProp algorithm
AdaGrad può rallentare la discesa del gradiente interrompendo 
anticipatamente il training.  
L'
algoritmo RMSProp
  è una variazione di AdaGrad dove 
 il vettore 
accumulatore 
 s
 considera maggiormente gli ultimi gradienti calcolati
 .  
•
Si introduce un 
 fattore di decay  
. 
 
 
•
Sebbene 
  sia un iperparametro, valori intorno allo 0.9 mostrano un buon 
comportamento.  
RMSProp
  si dimostra
  spesso migliore di AdaGrad
  e di altre ottimizzazioni 
(es. Momentum optimization e NAG).
β
s
←
β
s
+
(
1
−
β
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
β
26",prop algorithm ada grad pu rallentare discesa gradiente interrompendo anticipatamente training algoritmo prop variazione ada grad vettore accumulatore considera maggiormente ultimi gradienti calcolati introduce fattore decay sebbene iperparametro valori intorno mostrano buon comportamento prop dimostra spesso migliore ada grad altre ottimizzazioni momentum optimization
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#26,26,"Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
β
1
27Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ",adam optimization adam adaptive moment estimation combinazione momentum optimization prop indica literazione corrente rispetto momentum prima espressione introduce decay gradienti espressione utili incrementare valore allinizio training valori iniziali pari momentum prop prop mm ss j j
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#27,27,"Adam Optimization
Riguardo il 
 tuning
  dell'Adam Optimization:  
•
Valori tipici per 
  e 
 sono 0.9 e 0.999, rispettivamente.  
•
Come per gli altri 
 algoritmi di adaptive learning rate
 , il valore iniziale di  
può essere impostato ad un valore tipico di 0.001 senza ulteriore tuning.
β
1
β
2
η
28",adam optimization riguardo tuning delladam optimization valori tipici altri algoritmi adaptive learning rate valore iniziale pu essere impostato valore tipico senza ulteriore tuning
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#28,28,"Tecniche di ottimizzazione e complessità
Gli approcci 
 ﬁ
nora trattati si basano su 
 derivate parziali del primo ordine  
(Jacobians). Il numero di output per ogni dimensione in input è 
 n
,
 con 
 n 
numero di parametri.  
Esistono molti approcci del 
 secondo ordine (
 Hessians), ma richiedono 
 n
2 
Hessians per output.  
•
Recenti architetture Deep contengono oltre 10
8
 parametri.  
•
Limiti sulla memoria di calcolo non permettono di usare tali approcci.
29",tecniche ottimizzazione complessit approcci nora trattati basano derivate parziali primo ordine jacobians numero output ogni dimensione input numero parametri esistono molti approcci secondo ordine hessians richiedono hessians output recenti architetture deep contengono oltre parametri limiti memoria calcolo permettono usare tali approcci
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#29,29,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?
30",momentum cosa succede usiamo momentum optimizer iperparametro quasi
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#3,3,"Gli optimizer (2)
Nel DL le funzioni di 
 loss
 sono complesse e non hanno una 
 soluzione 
analitica
 , cioè non possono essere formalizzati in modo da poter ricavare la 
soluzione ottima con le risorse (tempo e hardware) disponibili in una serie di 
step. Per questo si impiegano 
 soluzioni numeriche
  che seguono un 
procedimento di trail & error su un insieme di soluzioni candidate.  
Es.
 i coef
 ﬁ
cienti di una regressione lineare possono essere ricavati 
analiticamente via algebra lineare (es. 
 matrix factorization
 ), oppure 
numericamente (es. 
 gradient descent
 ) quando i dati non sono 
interamente memorizzabili.
4",optimizer funzioni loss complesse soluzione analitica cio possono essere formalizzati modo poter ricavare soluzione ottima risorse tempo hardware disponibili serie step impiegano soluzioni numeriche seguono procedimento trail error insieme soluzioni candidate coef cienti regressione lineare possono essere ricavati analiticamente via algebra lineare matrix factorization oppure numericamente gradient descent quando dati interamente memorizzabili
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#30,30,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepasserà il momentum. 
31",momentum cosa succede usiamo momentum optimizer iperparametro quasi ricerca molto veloce verso lottimo causa momentum ricerca oltrepasser momentum
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#31,31,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.
32",momentum cosa succede usiamo momentum optimizer iperparametro quasi ricerca molto veloce verso lottimo causa momentum ricerca oltrepassera momentum rallenter torner indietro accelerer oltrepasser nuovo
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#32,32,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.  
3.
Potrà oscillare molte volte prima di arrivare al minimo.
33",momentum cosa succede usiamo momentum optimizer iperparametro quasi ricerca molto veloce verso lottimo causa momentum ricerca oltrepassera momentum rallenter torner indietro accelerer oltrepasser nuovo potr oscillare molte volte prima arrivare minimo
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#33,33,"Keras e optimizer
Si può de
 ﬁ
nire facilmente via compile()  
from
 tensorflow 
 import
 keras
from
 tensorflow.keras 
 import
 layers
model = keras.Sequential()
model.add(layers.Dense(
 64
, kernel_initializer=
 'uniform'
 , input_shape=(
 10
,)))
model.add(layers.Activation(
 'softmax'
 ))
opt = keras.optimizers.Adam(learning_rate=
 0.01
)
model.
compile
(loss=
'categorical_crossentropy'
 , optimizer=opt
 )
# oppur
e
model.compile(loss='categorical_crossentropy', 
 optimizer='adam'
 )
Oppure all'interno del training loop:  
optimizer = tf.keras.optimizers.Adam()
# Iterate over the batches of a dataset.
for
 x, y 
in
 dataset:
   
with
 tf.GradientTape() 
 as
 tape:
        
 # Forward pass.
        logits = model(x)
        
 # Loss value for this batch.
        loss_value = loss_fn(y, logits)
    
# Get gradients of loss wrt the weights.
    gradients = tape.gradient(loss_value, model.trainable_weights)
    
# Update the weights of the model.
    
optimizer.apply_gradients
 (
zip
(gradients, model.trainable_weights))
34
Optimizer disponibili:  
•
SGD,  
•
RMSprop,  
•
Adam,  
•
Adadelta,  
•
Adagrad,  
•
Adamax,  
•
Nadam,  
•
Ftrl",keras optimizer pu nire facilmente via compile tensorflow import keras import layers model uniform inputshape softmax opt model compile loss optimizeropt oppur oppure allinterno training loop optimizer iterate batches dataset dataset tfgradient tape tape forward pass logits modelx loss value batch lossvalue lossfny logits get gradients loss wrt weights gradients update weights model zip gradients optimizer disponibili msprop adam adadelta adagrad adamax nadam ftrl
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#34,34,"Richiami: Learning rate
Impostare un 
 learning rate troppo alto
  può far 
 divergere
  l'apprendimento 
dall'ottimo.  
Valori 
 troppo bassi 
 provocano 
 tempi di addestramento lunghi
 .  
Valori 
 elevati
  rendono il processo più rapido avvicinandosi all'ottimo ma 
senza convergere realmente
 .  
•
Tecniche quali
  AdaGrad, RMSProp
  e 
Adam
  affrontano questo problema ma 
richiedono comunque tempo, perciò 
 risorse di calcolo
 . 
Avviando il training più volte 
 su un training set ridotto e con diversi learning 
rate ci permette di 
 stimare
  quello più adatto.
35
EpocheLoss",richiami learning rate impostare learning rate troppo alto pu far divergere lapprendimento dallottimo valori troppo bassi provocano tempi addestramento lunghi valori elevati rendono processo rapido avvicinandosi allottimo senza convergere realmente tecniche quali ada grad prop adam affrontano problema richiedono comunque tempo perci risorse calcolo avviando training volte training set ridotto diversi learning rate permette stimare adatto epoche loss
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#35,35,"Richiami: Learning rate
36
Minimo cost function
learning rate elevato
learning rate basso
learning rate ideale",richiami learning rate minimo cost function learning rate elevato learning rate basso learning rate ideale
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#36,36,"Learning rate schedule
Le strategie di 
 learning schedules
  mirano ad 
 adattare il valore del learning rate  
durane il training.  
I più popolari algoritmi di 
 adaptive learning rate
  sono:  
•
Predetermined piecewise constant learning rate
 : 
•
Ogni 
 n
 epoche decrementa il rate di un valore predeterminato.  
•
Performance scheduling
 : 
•
Misura le perfomance (es. validation error) ogni 
 n
 steps e riduce il rate di un 
fattore prede
 ﬁ
nito quando le performance non migliorano.  
•
Exponential scheduling
 : 
•
Il rate si riduce di 
  dopo 
 r
 steps:  
•
Power scheduling
 : 
•
Simile al precedente ma il rate decresce più lentamente: 
1
10
η
(
t
)
=
η
0
⋅
10
−
t
r
η
(
t
)
=
η
0
(
1
+
t
r
)
−
c
37",learning rate schedule strategie learning schedules mirano adattare valore learning rate durane training popolari algoritmi adaptive learning rate sono predetermined piecewise constant learning rate ogni epoche decrementa rate valore predeterminato performance scheduling misura perfomance validation error ogni steps riduce rate fattore prede nito quando performance migliorano exponential scheduling rate riduce dopo steps power scheduling simile precedente rate decresce lentamente
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#37,37,"Learning rate schedule: considerazioni
Nel dominio dello 
 speech recognition
  e impiegando il Momentum 
optimization, il 
 performance scheduling
  e 
exponential scheduling  
dimostrano 
 migliori performance
 . 
•
L'
exponential scheduling 
 è da preferire perché 
 più facile nel tuning
 . 
Se si impiegano i seguenti optimizer 
 AdaGrad, RMSProp
  e 
Adam 
 non è 
necessario implementare il learning rate schedule.
38",learning rate schedule considerazioni dominio speech recognition impiegando momentum optimization performance scheduling exponential scheduling dimostrano migliori performance exponential scheduling preferire facile tuning impiegano seguenti optimizer ada grad prop adam necessario implementare learning rate schedule
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#38,38,"Keras e learning rate
Nell'esempio si de
 ﬁ
nisce un learning rate adattivo basato su exponential 
decay:  
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=
 1e-2
,
    decay_steps=
 10000
,
    decay_rate=
 0.9
)
optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)
39",keras learning rate nellesempio nisce learning rate adattivo basato exponential decay lrschedule decay decaysteps decayrate optimizer
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#4,4,"Local vs Global minimum
Un approccio numerico tradizionale che porta lo stato vicino ad un minimo 
locale restituirà una soluzione sub-ottima. Introducendo un certo grado di 
rumore abbiamo possibilità di continuare la ricerca altrove  
Nel 
minibatch stoachastic gradient descent
 , si introducono variazioni 
dovute ai gradienti calcolati sui minibatch e non sull'intero batch. 
5
",local global minimum approccio numerico tradizionale porta stato vicino minimo locale restituir soluzione sub ottima introducendo certo grado rumore possibilit continuare ricerca altrove minibatch stoachastic gradient descent introducono variazioni dovute gradienti calcolati minibatch sullintero batch
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#5,5,"Saddle points
I punti di sella generano vanishing gradients, e creano problemi se non 
siamo in minimi locali o globali.  
Nell'esempio 
 f(x)=x
3
6
",saddle points punti sella generano vanishing gradients creano problemi minimi locali globali nellesempio fxx
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#6,6,"Saddle points (2)
Nell'esempio sotto abbiamo 
 f(x,y)=x
2
-y
2 
con punto di sella in (0,0), massimo 
per y e minimo per x. Se assumiamo l'input di f un vettore k-dimensionale e 
l'output scalare, abbiamo  
Derivate parziali  
La 
matrice di Hessian
  (H) consiste nelle derivate parziali del secondo 
ordine. Essa rappresenta proprietà geometriche della super
 ﬁ
cie, 
soprattutto quando i gradienti sono pari a 0.
7
∇f(x)=[∂f(x)
∂x1,∂f(x)
∂x2,⋯,∂f(x)
∂xk]
Hf=∂2f
∂x1∂x1∂2f
∂x1∂x2⋯∂2f
∂x1∂xk
∂2f
∂x2∂x1∂2f
∂2x2⋯∂2f
∂x2∂xk
⋯
∂2f
∂x1∂xk∂2f
∂x2∂xk⋯∂2f
∂2xk",saddle points nellesempio sotto fxyx punto sella massimo minimo assumiamo linput vettore dimensionale loutput scalare derivate parziali matrice hessian consiste derivate parziali secondo ordine essa rappresenta propriet geometriche super cie soprattutto quando gradienti pari fxfx xfx xfx xk hff xxf xxf xxk xxf xf xxk xxkf xxkf xk
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#7,7,"Punti critici
In particolare gli autovalori e il determinante di H ci danno indicazioni sui punti 
critici e sulla funzione di costo.  
Una 
 convex function
  (cioè con un unico minimo) ha sempre autovalori non negativi.  
Ma il calcolo di H è oneroso di risorse (spazio e calcolo). Inoltre i task su cui si 
applicano architetture di DL non sono tipicamente associati a convex functions.
8
",punti critici particolare autovalori determinante danno indicazioni punti critici funzione costo convex function cio unico minimo sempre autovalori negativi calcolo oneroso risorse spazio calcolo inoltre task applicano architetture tipicamente associati convex functions
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#8,8,"Formalismo
Nei lucidi seguenti useremo il formalismo:  
•
:   i pesi attuali 
 w
 e 
b
 della RN (in passato 
 W
) 
•
 :  
funzione di costo
  (in passato 
 E 
o 
f
) 
•
 : 
gradiente
  della funzione di costo  
•
:   
 learning rate 
 o step size (in passato 
 ) 
•
, 
:  
moltiplicazione
  e 
divisione element-wise
 , 
   cioè posizione 
  posizione  
Θ
J
(
Θ
)
∇
Θ
J
(
Θ
)
η
 α
⊗
⊘
×
9",formalismo lucidi seguenti useremo formalismo pesi attuali passato funzione costo passato gradiente funzione costo learning rate step size passato moltiplicazione divisione element wise cio posizione posizione
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#9,9,"Richiami: Gradient descent
Il processo di ottimizzazione 
 Gradient descent
  opera una 
 sequenza di step 
regolari
  per ogni punto verso la direzione di massima discesa che 
corrisponde a quella determinata dall'opposto del suo gradiente in quel 
punto.  
 
In questo modo si ha che:  
•
L'
aggiornamento dipende solo dal gradiente calcolato localmente
 , e non 
da quelli precedenti.  
•
Se il 
 gradiente locale è piccolo
 , l'aggiornamento sarà 
 poco signi
 ﬁ
cativo
 .
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
10",richiami gradient descent processo ottimizzazione gradient descent opera sequenza step regolari ogni punto verso direzione massima discesa corrisponde determinata dallopposto gradiente quel punto modo che aggiornamento dipende solo gradiente calcolato localmente precedenti gradiente locale piccolo laggiornamento poco signi cativo
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 3: Over
 ﬁ
tting 
1",deep learning universit roma tre dipartimento ingegneria anno accademico laddestramento reti neurali deep parte tting
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#1,1,"Sommario
Affrontare l'Over
 ﬁ
tting 
Richiami  
Early stopping  
1 e 
 2 regularization  
Dropout  
Max-Norm regularization  
Data Augumentation  
Esercizi
ℓ
 ℓ",sommario affrontare lover tting richiami early stopping regularization dropout max norm regularization data augumentation esercizi
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#10,10,"Early stopping - ipotesi
Alcuni studi mostrano che le reti DL hanno la capacità di fare 
 ﬁ
tting di label 
arbitrarie, per
 ﬁ
no generate casualmente, ma solo dopo un numero elevato 
di iterazioni. In presenza di label ben de
 ﬁ
nite nel training set, la rete tende a 
rappresentarle per prime, e poi interpolare i dati associati a label ""rumore"".  
Ci garantisce la capacità di generalizzazione: è suf
 ﬁ
ciente riuscire ad 
addestrare il modello sui dati con label ben de
 ﬁ
nite, ed evitare di 
continuare su dati mal addestrati.
11",early stopping ipotesi alcuni studi mostrano reti capacit fare tting label arbitrarie generate casualmente solo dopo numero elevato iterazioni presenza label ben nite training set rete tende rappresentarle prime poi interpolare dati associati label rumore garantisce capacit suf ciente riuscire addestrare modello dati label ben nite evitare continuare dati mal addestrati
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#11,11,"Early stopping
Invece di introdurre vincoli sui parametri (l1 e l2 regularization), il vincolo 
può essere sul numero di epoche del training.   
Nella tecnica di regolarizzazione 
 early stopping
  interrompiamo il training 
quando le prestazioni della rete non migliorano, ad esempio:  
•
Alla 
ﬁ
ne di ogni epoca possiamo valutare le prestazioni sul 
 validation set
 .  
•
Teniamo traccia dell'ultima volta in cui il modello ha migliorato le 
prestazioni.  
•
Se dopo un certo numero di epoche non ci sono stati miglioramenti 
signi
ﬁ
cativi (> 
 ε
), spesso chiamata 
 patience criteria
 , interrompiamo e 
scegliamo lo snapshot del modello che in passato si è dimostrato migliore.  
Il vantaggio è aumentare il potere di generalizzazione evitando di 
considerare label noisy. Inoltre riduce il tempo di training.  
È spesso utile combinarlo ad altre tecniche di regolarizzazione.
12",early stopping invece introdurre vincoli parametri vincolo pu essere numero epoche training tecnica early stopping interrompiamo training quando prestazioni rete migliorano esempio ogni epoca possiamo valutare prestazioni validation set teniamo traccia dellultima volta modello migliorato prestazioni dopo certo numero epoche stati miglioramenti signi cativi spesso chiamata patience criteria interrompiamo scegliamo snapshot modello passato dimostrato migliore vantaggio aumentare potere evitando considerare label noisy inoltre riduce tempo training spesso utile combinarlo altre tecniche
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#12,12,"1
 e 
 2
 regularization
 ℓ
ℓ
1
 e 
 2 
regularization
  introducono limiti sul valore dei parametri e possono 
prevenire l'over
 ﬁ
tting.  
•
Corrispondono rispettivamente alle tecniche di 
 Lasso
  e 
Ridge 
 nella 
regressione e 
 1
 e 
 2
-penalty nella classi
 ﬁ
cazione.  
•
In pratica, oltre alla corrispondenza tra output attesi e output prodotti dalla 
rete, aggiungiamo un ulteriore vincolo da soddisfare durante il training.  
Modelli complessi tendono a rappresentare anche 
 ﬂ
uttuazioni causate dal 
rumore.  
Le due regolarizzazioni spingono i parametri del modello ad assumere valori 
vicini allo 0 e, come effetto collaterale, a ridurre gli effetti dei layer nascosti 
della rete, perciò rendendo il modello meno complesso.
ℓ
ℓ
ℓ
ℓ
13",regularization regularization introducono limiti valore parametri possono prevenire lover tting corrispondono rispettivamente tecniche lasso ridge regressione penalty classi cazione pratica oltre corrispondenza output attesi output prodotti rete aggiungiamo ulteriore vincolo soddisfare durante training modelli complessi tendono rappresentare uttuazioni causate rumore due spingono parametri modello assumere valori vicini effetto collaterale ridurre effetti layer nascosti rete perci rendendo modello meno complesso
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#13,13,"1
 regularization
ℓ
Nella 
 1
  si 
aggiunge la magnitudo sui pesi 
 (valore assoluto) come 
coef
ﬁ
ciente di penalità
  (o 
termine di regolarizzazione
 ) alla funzione di loss.  
1
 riduce signi
 ﬁ
cativamente il valore dei pesi associati alle feature meno 
importanti, operando una sorta di 
 feature selection
 , che
  riduce complessità 
e signi
 ﬁ
catività di alcune feature
 .  
Alfa è l'iperparametro 
 regularization rate
 . Valori 
 troppo elevati 
 comportano 
modelli semplici e potenziali 
 under
 ﬁ
tting, valori molto bassi 
 annullano la 
regolarizzazione.
ℓ
ℓ
14
",regularization aggiunge magnitudo pesi valore assoluto coef ciente penalit termine funzione loss riduce signi cativamente valore pesi associati feature meno importanti operando sorta feature selection riduce complessit signi cativit alcune feature alfa liperparametro regularization rate valori troppo elevati comportano modelli semplici potenziali tting valori molto bassi annullano
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#14,14,"2
 regularization
ℓ
Nella 
 2
  si 
aggiunge la magnitudo al quadrato sui pesi 
 (o norma Ecluidea)  
come coef
 ﬁ
ciente di penalità.
ℓ
15
",regularization aggiunge magnitudo quadrato pesi norma ecluidea coef ciente penalit
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#15,15,"Dropout - motivazioni
Abbiamo visto come modelli semplici possono garantire la generalizzazione. 
Possiamo intervenire (1) riducendo il numero delle dimensioni, o (2) 
riducendone l'importanza 
 (
2
 regularization), oppure (3) imponendo che la 
funzione stimata sia 
 smooth
  cioè poco sensibile a piccoli cambiamenti 
dell'input.  
Alcune teorie mettono in correlazione la smoothness con la capacità di 
essere resilienti alle perturbazioni nell'input. In base ad esse è stata proposta 
la tecnica di 
 iniettare
  rumore durante la forward propagation negli strati 
intermedi. L'obiettivo è minimizzare la situazione in cui un layer si 
specializza solo su un sottoinsieme di pattern di attivazione del layer 
precedente (
 co-adaptation
 ). 
Nella pratica, si disabilitano una frazione di nodi del layer precedente così 
da contribuire con un valore pari a 0 nell'input del layer attuale
ℓ
16",dropout motivazioni visto modelli semplici possono garantire possiamo intervenire riducendo numero dimensioni riducendone limportanza oppure imponendo funzione stimata smooth cio poco sensibile piccoli cambiamenti dellinput alcune teorie mettono correlazione smoothness capacit essere resilienti perturbazioni nellinput base esse stata proposta tecnica iniettare rumore durante forward propagation strati intermedi lobiettivo minimizzare situazione layer specializza solo sottoinsieme pattern attivazione layer precedente adaptation pratica disabilitano frazione nodi layer precedente cos contribuire valore pari nellinput layer attuale
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#16,16,"Dropout (1)
Nel 
dropout
  si assegna ad ogni nodo una probabilità 
 p
 di essere disattivato 
(ignorato) in un certo step durante la fase di forward e backward propagation, 
ad eccezione dell'output layer.  
•
p
 è un iperparametro chiamato 
 dropout rate
  (es. p=0.5).  
•
Ogni attivazione di un layer intermedia è sostituita con:  
•
Nel caso fosse 0 i gradienti svaniscono durante il backpropagation.  
Dopo la fase di training (es. in produzione) tutti i nodi saranno attivati.  
Ad ogni step abbiamo una diversa con
 ﬁ
gurazione di rete. 
 Con N nodi 
possiamo avere 2
N
 con
ﬁ
gurazioni diverse, tutte addestrate per lo stesso scopo.
17
",dropout dropout assegna ogni nodo probabilit essere disattivato ignorato certo step durante fase forward backward propagation eccezione delloutput layer iperparametro chiamato dropout rate ogni attivazione layer intermedia sostituita con caso gradienti svaniscono durante dopo fase training produzione nodi attivati ogni step diversa gurazione rete nodi possiamo avere gurazioni diverse tutte addestrate stesso scopo
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#17,17,"Dropout (2)
Una impresa funziona meglio senza un dipendente?  
•
Sì, se i lavoratori sanno adattarsi, cioè: ognuno si occupa di più cose, 
maggiore cooperazione, e non contare solo sui vicini.  
Garantisce reti più 
 robuste 
 e con capacità di 
 generalizzazione
 . 
Si ottiene un incremento delle prestazioni del 
 1-2% 
 per
ﬁ
no nelle architetture 
più ottimizzate.
18",dropout impresa funziona meglio senza dipendente lavoratori sanno adattarsi cio ognuno occupa cose maggiore cooperazione contare solo vicini garantisce reti robuste capacit ottiene incremento prestazioni architetture ottimizzate
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#18,18,"Dropout - esempio
19
senza Dropout con Dropout",dropout esempio senza dropout dropout
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#19,19,"Dropout: altre considerazioni
Una 
 rete complessa
  con molti parametri facilmente incorpora 
dipendenze che rappresentano feature dei dati di ingresso di scarso 
interesse (
 over
ﬁ
tting
).  
•
Se ad ogni step proponiamo dati a diverse con
 ﬁ
gurazioni di layer è 
meno probabile che un certo peso si focalizzi su una feature poco 
signi
ﬁ
cativa.  
La tecnica dropout 
 raddoppia circa il numero di iterazioni per 
raggiungere la convergenza
 , ma il 
 tempo di addestramento per una 
epoca è più breve 
 dato che ho meno nodi funzionanti.  
Per avere aggiornamenti più lenti si può considerare un singolo mini-
batch per ogni con
 ﬁ
gurazione considerata.
20",dropout altre considerazioni rete complessa molti parametri facilmente incorpora dipendenze rappresentano feature dati ingresso scarso interesse tting ogni step proponiamo dati diverse gurazioni layer meno probabile certo peso focalizzi feature poco signi cativa tecnica dropout raddoppia circa numero iterazioni raggiungere convergenza tempo addestramento epoca breve dato meno nodi funzionanti avere aggiornamenti lenti pu considerare singolo mini batch ogni gurazione considerata
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#2,2,"Richiami: Over
 ﬁ
tting
Le reti deep contengono molti parametri che mirano a modellare un insieme 
vasto di funzioni, anche complesse.  
L'obiettivo dell'
 addestramento
  è ottenere una rete che mostra 
 buone 
prestazioni sia sul training set, sia in produzione 
 (cioè su dati mai visti).  
•
In queste condizioni si ha 
 generalizzazione
 . 
Il 
test set  
permette di 
 valutare l'over
 ﬁ
tting
 del modello 
 ﬁ
nale testandolo su 
dati mai visti in precedenza durante il training, ma con distribuzione di 
probabilità simile.  
•
Se un modello 
 ﬁ
tta
 i dati di training e di test contemporaneamente, si ha 
minimo over
 ﬁ
tting.  
Il 
validation set
  è usato più raramente per 
 valutare la combinazione migliore 
degli iperparametri
  durante lo sviluppo della rete. Non è impiegato durante il 
training né Nonostante ciò, le sue caratteristiche possono essere parzialmente 
rappresentate all'interno della rete, 
 rendendo la valutazione meno oggettiva
 .
3",richiami tting reti deep contengono molti parametri mirano modellare insieme vasto funzioni complesse lobiettivo dell addestramento ottenere rete mostra buone prestazioni training set produzione cio dati mai visti condizioni test set permette valutare lover tting modello nale testandolo dati mai visti precedenza durante training distribuzione probabilit simile modello tta dati training test minimo tting validation set usato raramente valutare combinazione migliore iperparametri durante sviluppo rete impiegato durante training nonostante ci caratteristiche possono essere parzialmente rappresentate allinterno rete rendendo valutazione meno oggettiva
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#20,20,"Dropout e analogia col boosting
Supponiamo di avere un problema di 
 classi
 ﬁ
cazione
 . Il 
dropout  
interpreta la rete come un insieme (molto grande) di classi
 ﬁ
catori 
“
weak
 ”.  
•
Durante l’addestramento 
 disattivo una parte della rete per 
sfruttare solo un sotto-modello alla volta
 . 
•
L'
accuratezza dei singoli sotto-modelli è minore di quella che 
potrei ottenere addestrando l'intera rete 
 su tutto il training set.  
•
Ma alla 
 ﬁ
ne considero la 
 rete nella sua interezza
 , cioè con tutti i 
sotto-modelli attivati, 
 ottenendo un aumento delle prestazioni
 . 
•
Nel 
boosting si suppongono modelli indipendenti
  mentre nel 
dropout c’è inevitabilmente dipendenza
  dovuta alla condivisione 
dei parametri tra sotto-modelli.
21",dropout analogia boosting supponiamo avere problema classi cazione dropout interpreta rete insieme molto grande classi catori weak durante laddestramento disattivo parte rete sfruttare solo sotto modello volta accuratezza singoli sotto modelli minore potrei ottenere addestrando lintera rete training set considero rete interezza cio sotto modelli attivati ottenendo aumento prestazioni boosting suppongono modelli indipendenti mentre dropout c inevitabilmente dipendenza dovuta condivisione parametri sotto modelli
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#21,21,"Dropout nella pratica
Dal punto di vista operativo, con 
 p=0.5,
  durante il test ogni nodo di 
un qualsiasi hidden layer riceve il doppio degli input rispetto alla 
fase di training.  
•
Dopo il training è importante moltiplicare il valore degli input per  
1-p
 o avremmo dei segnali di ingresso con magnitudine troppo 
elevata. In alternativa, si può scalare l'output di ogni neurone.  
Durante lo sviluppo della rete, se notiamo che il modello mostra 
over
ﬁ
tting possiamo introdurre il dropout, ovvero incrementare 
 p
. 
Se mostra unde
 ﬁ
tting lo decrementiamo.  
Dropconnect
  è una variazione del dropout, dove sono gli archi ad 
essere disattivati.
22",dropout pratica punto vista operativo durante test ogni nodo qualsiasi hidden layer riceve doppio input rispetto fase training dopo training importante moltiplicare valore input segnali ingresso magnitudine troppo elevata alternativa pu scalare loutput ogni neurone durante sviluppo rete notiamo modello mostra tting possiamo introdurre dropout ovvero incrementare mostra unde tting decrementiamo dropconnect variazione dropout archi essere disattivati
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#22,22,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?",dropout rete multi layer consideriamo dropout ogni layer
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#23,23,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.",dropout rete multi layer consideriamo dropout ogni layer hidden layers creare diverse gurazioni rete addestrare singolarmente
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#24,24,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe. ",dropout rete multi layer consideriamo dropout ogni layer hidden layers creare diverse gurazioni rete addestrare singolarmente consideriamo output layer genera feedback necessario addestrare gurazione corrente caso classi cazione omettiamo nodo layer output otteniamo comportamento rete classe
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#25,25,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe.  
Lo possiamo usare nel 
 input layer 
 perché permette di addestrare 
il modello ignorando alcune feature in ingresso che possono 
in
ﬂ
uenzare negativamente l'addestramento (es. p=0.8)  
E simile ad una feature selection.",dropout rete multi layer consideriamo dropout ogni layer hidden layers creare diverse gurazioni rete addestrare singolarmente consideriamo output layer genera feedback necessario addestrare gurazione corrente caso classi cazione omettiamo nodo layer output otteniamo comportamento rete classe possiamo usare input layer permette addestrare modello ignorando alcune feature ingresso possono uenzare negativamente laddestramento simile feature selection
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#26,26,"Dropout
10-dropout
  (python)
",dropout dropout python
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#27,27,"Max-Norm regularization
La 
Max-norm regularization
  introduce il 
 vincolo sul modulo dei 
pesi
 con un iperparametro 
 r
: 
 ,            dove
  indica la 
 2
-norm  
Ad ogni training step normalizziamo i pesi:  
 
Riducendo 
 r
, oltre a regolarizzare i pesi, si affronta anche il 
vanishing/exploding problem.  
w
2
≤
r
 ⋅
2
ℓ
w
←
w
r
w
2",max norm regularization max norm regularization introduce vincolo modulo pesi iperparametro indica norm ogni training step normalizziamo pesi riducendo oltre regolarizzare pesi affronta problem
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#28,28,"Data Augumentation
La 
data augumentation
  genera nuove istanze da dare in input
 , 
aumentando la dimensione del training set.  
Nel caso delle immagini (
 image augumentation
 ), si automatizza 
il processo con tecniche tradizionali quali:  
•
Ruotare, spostare, ridimensionare, aggiungere un rumore, copie 
speculari, variazioni di luce e contrasto, etc.  
•
Es. fare crop dell'immagine in modo che il soggetto compaia in 
diverse posizioni, modi
 ﬁ
care l'intensità dei colori per ridurre la 
relativa sensitività del modello.  
Lo scopo e (1) rendere la rete meno dipendente da queste 
variazioni e (2) incrementare il set di training nel caso ci fossero 
un numero insuf
 ﬁ
ciente di istanze.",data augumentation data augumentation genera nuove istanze dare input aumentando dimensione training set caso immagini image augumentation automatizza processo tecniche tradizionali quali ruotare spostare ridimensionare aggiungere rumore copie speculari variazioni luce contrasto etc fare crop dellimmagine modo soggetto compaia diverse posizioni modi care lintensit colori ridurre relativa sensitivit modello scopo rendere rete meno dipendente variazioni incrementare set training caso numero insuf ciente istanze
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#29,29,"Data Augumentation in Keras
11-data_augmentation.ipynb
",data augumentation keras
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#3,3,"Richiami: Over
 ﬁ
tting
Per ridurre l'over
 ﬁ
tting si può intervenire:  
•
Cambiando la struttura della rete
  (es. riducendo il numero di nodi/pesi/
layer).  
•
Alterando i valori del parametri
  durante l'addestramento.
4",richiami tting ridurre lover tting pu intervenire cambiando struttura rete riducendo numero nodipesi layer alterando valori parametri durante
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#30,30,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Con 
modello sparso
  indichiamo una versione ""sempli
 ﬁ
cata"" di 
modello tipicamente più complesso, utile per elaboratori con 
meno risorse computazionali.  
Ad esempio: mini computers e smartphones.",sparse model elenca modi creare modelli sparsi modello sparso indichiamo versione sempli cata modello tipicamente complesso utile elaboratori meno risorse computazionali esempio mini computers smartphones
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#31,31,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0",sparse model elenca modi creare modelli sparsi volta addestrato modello possono azzerare parametri vicini
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#32,32,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0  
La 
 1
 regularization incrementa il numero di parametri vicino 
allo 0 che possono essere azzerati  
Il 
FTRLOptimizer
  è una altro algoritmo adatto per questo scopo.
ℓ",sparse model elenca modi creare modelli sparsi volta addestrato modello possono azzerare parametri vicini regularization incrementa numero parametri vicino possono essere azzerati loptimizer altro algoritmo adatto scopo
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#33,33,"Tool: Gradient Descent Visualization
θ1
θ2loss",tool gradient descent visualization loss
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#34,34,"Richiami 
 
 
 
 
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
35Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ
 s←s+∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵAdaGradAdam",richiami momentum prop prop mm ss j j ss j j ada grad adam
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#35,35,"Qualche indicazione pratica
Per problemi di classi
 ﬁ
cazione, inizia da una con
 ﬁ
gurazione di default,  
come la seguente:  
Oppure cerca modelli pre-addestrati per compiti uguali o simili.  
Modi
 ﬁ
ca la con
 ﬁ
gurazione intervenendo:  
•
Se 
converge troppo lentamente incrementa il learning rate  
•
Se converge ma 
 con performance non adeguate
 , prova un 
 learning schedule
 , es. 
exponential decay.  
•
Se 
il training set è troppo piccolo, fai data augumentation
",qualche indicazione pratica problemi classi cazione inizia gurazione default seguente oppure cerca modelli pre addestrati compiti uguali simili modi gurazione intervenendo converge troppo lentamente incrementa learning rate converge performance adeguate prova learning schedule exponential decay training set troppo piccolo data augumentation
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#36,36,"Kaggle: piattaforma per competizioni ML-based
Ogni competizione consiste in un dataset di training e uno di test.  
Il partecipante suddivide il training set in due, una parte per la 
validazione, oppure opera una cross-fold validation.  
Il test set completo rimane privato 
 ﬁ
no alla 
 ﬁ
ne della competizione.
37
https://www.kaggle.com/c/digit-recognizer/data",kaggle piattaforma competizioni based ogni competizione consiste dataset training test partecipante suddivide training set due parte validazione oppure opera cross fold validation test set completo rimane privato competizione recognizerdata
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#37,37,"Over
 ﬁ
tting: un caso reale
Il ranking 
 ﬁ
nale viene calcolato sul 
 test set
 .
38
Differenza rispetto al training (e validation) set pubblico
Scendendo si hanno di solito valori negativi: approcci che 
si comportano molto bene nel training ma non nel test set.",tting caso reale ranking nale viene calcolato test set differenza rispetto training validation set pubblico scendendo solito valori negativi approcci comportano molto bene training test set
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#38,38,"La regola del 30
La 
regola del 30  
è un semplice procedimento empirico adatto per 
classi bilanciate
  (cioè con lo stesso numero di istanze per ogni label).  
Fornisce una idea 
 se un incremento di prestazioni è signi
 ﬁ
cativo o 
meno
  (es. dovuto solo al caso).  
Se dopo aver aggiornato il classi
 ﬁ
catore ottengo un incremento 
(o decremento) di accuratezza che riguarda almeno 30 istanze, 
allora il miglioramento (peggioramento) è signi
 ﬁ
cativo.  
39",regola regola semplice procedimento empirico adatto classi bilanciate cio stesso numero istanze ogni label fornisce idea incremento prestazioni signi cativo meno dovuto solo caso dopo aver aggiornato classi catore ottengo incremento decremento accuratezza riguarda almeno istanze allora miglioramento peggioramento signi cativo
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#39,39,"La regola del 30
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima 
percentuale per dire che l’incremento di accuratezza è signi
 ﬁ
cativo? 
40",regola set validazione istanze qual differenza minima percentuale dire lincremento accuratezza signi cativo
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#4,4,"Richiami: Over
 ﬁ
tting
5Training/Validation
 Produzione/
Test
label:A
label:J
",richiami tting produzione test labela labelj
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#40,40,"La regola del 30: soluzione
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima percentuale per 
dire che l’incremento di accuratezza è signi
 ﬁ
cativo?  
L’incremento percentuale si calcola:  
Esempio:  
Se N = 1000 -> 3%  
Se N = 3000 -> 1%  
Se N = 30.000 -> 0.1%  
Seguendo la regola, è meglio usare un validation set ampio, così anche 
incrementi (es. 0.1%) possono essere tenuti in considerazione.  
Indicazioni più accurate sono ottenute con 
 test di signi
 ﬁ
catività
 .
41(N+30)−N
N⋅100",regola soluzione set validazione istanze qual differenza minima percentuale dire lincremento accuratezza signi cativo lincremento percentuale calcola esempio seguendo regola meglio usare validation set ampio cos incrementi possono essere tenuti considerazione indicazioni accurate ottenute test signi cativit nn
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#41,41,"Esercizio su Deep NN
Costruisci una rete Deep, con 5 layer hidden da 100 nodi l'uno, 
inizializzazione Xavier e He, e funzione di attivazione ELU  
Usa la Adam optimization con early stopping.  
Impiega il dataset di cifre MNIST, ma solo da 0 a 4. Usa come output 
un layer softmax da 5 neuroni.  
Ricordati di salvare periodicamente i checkpoints, e il modello 
 ﬁ
nale.  
Fai tuning sugli iperparametri usando la cross-validation, e vedi se 
puoi incrementare la precisione.  
Prova ad aggiungere la Batch normalization e confronta le curve di 
learning. Converge prima? Produce un modello migliore?  
Secondo te c'è over
 ﬁ
tting sul training set? Prova ad aggiungere il 
dropout ad ogni layer e valuta miglioramenti.
42",esercizio deep costruisci rete deep layer hidden nodi luno xavier funzione attivazione usa adam optimization early stopping impiega dataset cifre solo usa output layer softmax neuroni ricordati salvare periodicamente checkpoints modello nale tuning iperparametri usando cross validation vedi puoi incrementare precisione prova aggiungere batch normalization confronta curve learning converge prima produce modello migliore secondo tting training set prova aggiungere dropout ogni layer valuta miglioramenti
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#42,42,"Esercizio sul Transfer Learning
Crea una nuova Deep NN e riusa i parametri degli hidden layer della 
rete precedente. Congelali e rimpiazza il layer softmax con uno 
nuovo.  
Addestra la rete sulle cifre 5-9, usando solo 100 immagini per cifra, e 
vedi quanto impiega. Nonostante le poche immagini riesci ad avere 
una buona precisione?  
Prova a fare caching dei layer congelati, e addestra di nuovo il 
modello. Quanto è veloce ora?  
Prova di nuovo usando solo 4 hidden layer. La precisione aumenta?  
Ora scongela i primi 2 layer e continua il training. Ottieni maggiori 
performance?
43",esercizio transfer learning crea nuova deep riusa parametri hidden layer rete precedente congelali rimpiazza layer softmax nuovo addestra rete cifre usando solo immagini cifra vedi impiega nonostante poche immagini riesci avere buona precisione prova fare caching layer congelati addestra nuovo modello veloce ora prova nuovo usando solo hidden layer precisione aumenta ora scongela primi layer continua training ottieni maggiori performance
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#43,43,"Esercizio sul Pretraining su auxiliary task
Costruiamo una Deep NN che confronta due cifre MNIST per veri
 ﬁ
care se sono le 
stesse. Dopodiché impieghiamo gli stessi layer 
 ﬁ
nali della rete per addestrare un 
classi
 ﬁ
catore MNIST su pochissimi dati di training.  
Inizia da 2 Deep NN (A e B), simili a quanto costruito nel esercizio su Deep NN. 
Aggiungi un singolo layer di output che connette l'output di ambedue le reti. Usa la 
funzione concat() di Tensor
 ﬂ
ow con axis=1. Usa quanto ottieni come input al nuovo 
output layer. L'output layer contiene un singolo nodo e usa la logistic come funzione 
di attivazione.  
Suddividi MNIST in 2 sets: primo split da 55,000 immagini, secondo split da 5,000. 
Crea una funzione che genera un batch dove ogni istanza è una coppia di immagini 
prese dallo split #1. Metà devono appartenere alla classe ""stessa classe"" (label 0), 
l'altra metà ""classi diverse"" (label 1).  
Addestra la rete sul training set. Per ogni coppia manda in input in simultanea 
l'immagina da A e l'immagine da B.  
Ora crea una nuova rete riutilizzando e congelando i pesi degli hidden layers di A e 
aggiungendo una softmax layer di 10 nodi. Addestra la rete sullo split #2 e vedi se 
ottieni prestazioni elevate avendo solo 500 immagini per classe.
44",esercizio pretraining auxiliary task costruiamo deep confronta due cifre veri care stesse dopodich impieghiamo layer nali rete addestrare classi catore pochissimi dati training inizia deep simili costruito esercizio deep aggiungi singolo layer output connette loutput ambedue reti usa funzione concat tensor axis usa ottieni input nuovo output layer loutput layer contiene singolo nodo usa logistic funzione attivazione suddividi sets primo split immagini secondo split crea funzione genera batch ogni istanza coppia immagini prese split met devono appartenere classe stessa classe label laltra met classi diverse label addestra rete training set ogni coppia manda input simultanea limmagina limmagine ora crea nuova rete riutilizzando congelando pesi hidden layers aggiungendo softmax layer nodi addestra rete split vedi ottieni prestazioni elevate solo immagini classe
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#5,5,"Affrontare l'Over
 ﬁ
tting
Valori dei pesi limitati in modulo signi
 ﬁ
cano spesso modelli meno complessi, e meno 
in
ﬂ
uenzati da 
 ﬂ
uttuazioni statistiche dei dati in input.  
•
Valori elevati nei pesi implicano attivazioni molto diverse per leggere variazioni in input.  
Tranne nei casi di training set molto grandi, si impiegano sempre 
 tecniche di 
regolarizzazione
 , tra le quali:  
•
Early stopping
 : 
•
terminare l'addestramento quando le performance degradano  
•
 1
 e 
 2
 regularization (o weight regularization)
 :  
•
penalizzare il modello in base alla magnitudo dei pesi  
•
Dropout
 : 
•
per ogni layer ignorare alcuni input durante l'addestramento  
•
Max-Norm regularization (o weight constraint)
 :  
•
introdurre un range di ammissibilità per il valore dei pesi  
•
Data Augumentation (non regolarizza i pesi, ma aumenta la dimensione del training set)
 : 
•
modi
 ﬁ
care il training set, es. aggiungendo del rumore
ℓ
ℓ
6",affrontare lover tting valori pesi limitati modulo signi cano spesso modelli meno complessi meno uenzati uttuazioni statistiche dati input valori elevati pesi implicano attivazioni molto diverse leggere variazioni input tranne casi training set molto grandi impiegano sempre tecniche quali early stopping terminare laddestramento quando performance degradano regularization weight regularization penalizzare modello base magnitudo pesi dropout ogni layer ignorare alcuni input durante laddestramento max norm regularization weight constraint introdurre range ammissibilit valore pesi data augumentation non regolarizza pesi aumenta dimensione training set modi care training set aggiungendo rumore
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#6,6,"Richiami: Over
 ﬁ
tting
7
Complessità del modello",richiami tting complessit modello
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#7,7,"Richiami: bias e varianza 
High Validation error
High Test errorSi
SiNo
No
Done! •Bigger mode l
•Train longer  
•New model architecture 
•More data  
•Regularization  
•New model architecture Bias 
(unde ﬁt)
Varianc e
(over ﬁt)
",richiami bias varianza high validation error high test error done bigger mode train longer new model architecture more data regularization new model architecture bias unde varianc over
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#8,8,"Over
 ﬁ
tting e regolarizzazione
Il procedimento di training 
 ﬁ
nora seguito è:  
•
addestrare
  il modello su un training set, e valutare l'
 errore di 
generalizzazione
  su holdout data (test set).  
La differenza di performance tra i due set si chiama 
 generalization gap
 . Se 
la differenza è elevata si ha 
 over
ﬁ
tting
 sul training data.  
Nello scenario del DL, prendendo l'esempio del task della classi
 ﬁ
cazione, 
si hanno tipicamente modelli complessi a suf
 ﬁ
cienza per 
 ﬁ
ttare
 ogni istanza 
di training, anche per training set molto grandi. Farebbe pensare che per 
ridurre il generalization error siamo costretti a introdurre regolarizzazioni 
(es. riducendo la complessità, vincoli sul valore dei parametri).  
In realtà si nota come nel DL si raggiungano spesso 0 training error, perciò 
l'unico aspetto da ottimizzare è il generalization error. Inoltre, contrario alla 
logica, l'errore si può ridurre anche rendendo l'architettura più complessa 
(es. più layer e nodi). I progettisti hanno più possibilità di affrontare 
l'over
 ﬁ
tting rispetto alle architetture NN tradizionali.
9",tting procedimento training nora seguito addestrare modello training set valutare errore holdout data test set differenza performance due set chiama generalization gap differenza elevata tting training data scenario prendendo lesempio task classi cazione tipicamente modelli complessi suf cienza ttare ogni istanza training training set molto grandi pensare ridurre generalization error costretti introdurre riducendo complessit vincoli valore parametri realt nota raggiungano spesso training error perci lunico aspetto ottimizzare generalization error inoltre contrario logica lerrore pu ridurre rendendo larchitettura complessa layer nodi progettisti possibilit affrontare lover tting rispetto architetture tradizionali
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#9,9,"Ispirazione ai modelli non parametrici
Gli approcci parametrici possono essere de
 ﬁ
niti in vari modi, es. sono 
basati su modelli statistici che rappresentano i parametri con distribuzioni 
standard. Nei modelli nonparametrici la variabilità dei parametri è più 
ampia e ci sono meno vincoli da rispettare (es. su media, varianza).  
Spesso i modelli nonparametrici confrontano le istanze e si basano 
sull'ipotesi che istanze simili in input producono output simili (es. k-NN).  
Un altro modo per caratterizzare i modelli nonparametrici è sulla 
complessità che tende a crescere al crescere del numero di dati disponibili 
di training.  
Le reti NN sono spesso viste come modelli non parametrici
 . Si hanno un 
numero molto abbondate di parametri che tendono a interpolare i training 
data.
10",ispirazione modelli parametrici approcci parametrici possono essere niti vari modi basati modelli statistici rappresentano parametri distribuzioni standard modelli nonparametrici variabilit parametri ampia meno vincoli rispettare media varianza spesso modelli nonparametrici confrontano istanze basano sullipotesi istanze simili input producono output simili altro modo caratterizzare modelli nonparametrici complessit tende crescere crescere numero dati disponibili training reti spesso viste modelli parametrici numero molto abbondate parametri tendono interpolare training data
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #1
1",deep learning universit roma tre dipartimento ingegneria anno accademico recurrent neural networks parte
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#1,1,"Sommario
Nodi e layers ricorrenti  
•
Calcolo degli output  
Predizione  
Architetture RNN  
•
Sequence-to-sequence  
•
Sequence-to-vector  
•
Vector-to-sequence  
•
Encoder-decoder  
Memory cells  
•
LSTM  
•
GRU",sommario nodi layers ricorrenti calcolo output predizione architetture sequence sequence sequence vector vector sequence encoder decoder memory cells
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#10,10,"Architetture RNN (1) 
Ci sono vari tipi di architetture RNN, che dipendono dal task che si vuole 
affrontare.  
La rete 
 sequence-to-sequence
  è utile per task di 
 predizione
 .  
•
Supponiamo di avere la quotazione di chiusura di un titolo in borsa, misurata 
negli ultimi N giorni. La rete deve produrre in output le stesse quotazioni 
traslate di un giorno nel futuro.  
La rete 
 sequence-to-vector
  è simile alla precedente ma 
 scarta tutti i valori in 
output tranne l'ultimo
 . 
•
Se in input abbiamo una sequenza di 
 id
 di parole, l'ultimo output può 
corrispondere al 
 sentiment
  (es. -1 [hate], +1 [love).
11
",architetture vari tipi architetture dipendono task vuole affrontare rete sequence sequence utile task predizione supponiamo avere quotazione chiusura titolo borsa misurata ultimi giorni rete deve produrre output quotazioni traslate giorno futuro rete sequence vector simile precedente scarta valori output tranne lultimo input sequenza parole lultimo output pu corrispondere sentiment hate love
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#11,11,"Architetture RNN (2) 
La rete 
 vector-to-sequence
  prende in input ripetutamente lo stesso vettore per 
una successione di steps e produce una sequenza in output.  
•
Se il vettore in input corrisponde ad una immagine, possiamo addestrare la 
rete per produrre una descrizione testuale associata (sequenza di parole).
12
",architetture rete vector sequence prende input ripetutamente stesso vettore successione steps produce sequenza output vettore input corrisponde immagine possiamo addestrare rete produrre descrizione testuale associata sequenza parole
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#12,12,"Architetture RNN (3) 
In
ﬁ
ne si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
vector-to-sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio.  
•
Una rete 
 sequence-to-sequence
  non è adatta poiché l'intera frase. Le ultime 
parole dell'input potrebbero in
 ﬂ
uenza l'inizio dell'output, mentre la rete 
traduce ogni parola via via che l'input è reso disponibile. Inoltre le lunghezze 
dell'input e output potrebbero non corrispondere.
13
",architetture pu combinare rete sequence vector encoder vector sequence decoder ottenendo rete encoder decoder encoder pu rappresentare frase linguaggio singolo vettore viene impiegato poi decoder generare frase diverso linguaggio rete sequence sequence adatta poich lintera frase ultime parole dellinput potrebbero uenza linizio delloutput mentre rete traduce ogni parola via via linput reso disponibile inoltre lunghezze dellinput output potrebbero corrispondere
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#13,13,"RNN: Addestramento 
L'addestramento di una RNN richiede l'
 unrolling through time
  e l'uso della 
tecnica 
 backpropagation through time
  (
BPTT
 ). 
•
La prima passata corrisponde alla 
 forward
  pass tradizionale (frecce 
tratteggiate).  
•
L'output è valutato con una 
 funzione di costo  
 . Per talune 
architetture la funzione può ignorare alcuni output.  
•
Il gradiente della funzione di costo è propagato 
 backward
  (frecce continue) e 
i parametri aggiornati di conseguenza.
C
(
Y
(
0
)
,
Y
(
1
)
,
⋯
,
Y
(
T
)
)
14
In questo esempio la funzione  
è valutata con gli ultimi 3 
output, e perciò i gradienti non 
transitano per Y (0) e Y (1).
Da notare che i medesimi 
parametri W,b sono impiegati 
ad ogni step. La 
backpropagation considera 
tutti gli steps per fare 
l'aggiornamento.",addestramento laddestramento richiede unrolling time luso tecnica backpropagation time prima passata corrisponde forward pass tradizionale frecce tratteggiate loutput valutato funzione costo talune architetture funzione pu ignorare alcuni output gradiente funzione costo propagato backward frecce continue parametri aggiornati conseguenza esempio funzione valutata ultimi output perci gradienti transitano notare medesimi parametri impiegati ogni step backpropagation considera steps fare
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#14,14,"Time series: Predizione (forecasting)
Analizziamo le seguenti 
 time series
 :  
•
numero orario di utenti attivi su un sito web,  
•
temperatura giornaliera in un certo luogo  
•
situazione 
 ﬁ
nanziare di una società misurata trimestralmente con metriche 
multiple (es. reddito, debito, etc).  
Le prime due sono 
 univariate  
time series
  perché valutiamo temporalmente 
una singola metrica, l'ultima è una 
 multivariate  
time series
 . 
La predizione di un valore in un tempo futuro è chiamato 
 forecasting
 . 
Con 
imputation
  si intende stimare un valore mancante all'interno della time 
series.  
Le RNN si usano spesso per fare 
 forecasting
  e 
imputation
 .
15",time series predizione forecasting analizziamo seguenti time series numero orario utenti attivi sito web temperatura giornaliera certo luogo situazione nanziare societ misurata trimestralmente metriche multiple reddito debito etc prime due univariate time series valutiamo temporalmente singola metrica lultima multivariate time series predizione valore tempo futuro chiamato forecasting imputation intende stimare valore mancante allinterno time series usano spesso fare forecasting imputation
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#15,15,"RNN e Keras (1)
Generiamo 
 time series
  in modo random:  
def 
generate_time_series
 (
batch_size
 , 
n_steps
)
:
    
# valori random in [0,1); il parametro di rand è lo shape
    freq1, freq2, offsets1, offsets2 = np.random.rand(
 4
, batch_size, 
 1
)
    
# n_steps valori nell'intervallo 0, 1 equamente spaziati
    time = np.linspace(
 0
, 
1
, n_steps)
    series = 
 0.5
 * np.sin((time - offsets1) * (freq1 * 
 10
 + 
10
))  
#   wave 1
    series += 
 0.2
 * np.sin((time - offsets2) * (freq2 * 
 20
 + 
20
)) 
# + wave 2
    series += 
 0.1
 * (np.random.rand(batch_size, n_steps) - 
 0.5
)   
# + noise
    
return
 series[..., np.newaxis].astype(np.float32)
Dove 
batch_size
  sono il numero di 
 time series
  da generare con lunghezza 
n_steps
 . Le serie sono 
 univariate
 . La funzione restituisce un array NumPy di 
dimensioni [
 batch_size
 , 
n_steps
 , 1].  
Ogni serie è generata come somma di due funzioni 
 seno
 di ampiezza 
 ﬁ
ssa ma 
frequenza e fase random, e con aggiunta di rumore.  
16",keras generiamo time series modo random def batchsize nsteps valori random parametro rand shape freq freq offsets offsets nprandomrand batchsize nsteps valori nellintervallo equamente spaziati time nplinspace nsteps series npsintime offsets freq wave series npsintime offsets freq wave series nsteps noise return series batchsize numero time series generare lunghezza nsteps serie univariate funzione restituisce array num dimensioni batchsize nsteps ogni serie generata somma due funzioni seno ampiezza ssa frequenza fase random aggiunta rumore
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#16,16,"RNN e Keras (2)
Creiamo training set, validation set e test set:  
n_steps = 
 50
series = generate_time_series(
 10000
, n_steps + 
 1
)
X_train, y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-1
]
X_valid, y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-1
]
X_test, y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-1
]
X_train
  contiene 7000 time series di lunghezza 50 steps, e ha dimensioni 
[7000,50,1]  
X_valid
  contiene 2000 time series  
X_test
  contiene 1000 time series  
Poiché vogliamo un 
 forecast
  di un singolo valore per time series, il vettore 
colonna target ha dimensioni [7000,1]  
17",keras creiamo training set validation set test set nsteps series nsteps xtrain ytrain series nsteps series xvalid yvalid series nsteps series xtest ytest series nsteps series xtrain contiene time series lunghezza steps dimensioni xvalid contiene time series xtest contiene time series poich vogliamo forecast singolo valore time series vettore colonna target dimensioni
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#17,17,"RNN e Keras (3)
Per valutare il modello introduciamo degli approcci 
 baseline
 , con cui 
confrontarci.  
Un semplice modello stima il valore futuro facendolo coincidere con l'ultimo 
valore nella time series (
 naive forecoasting
 ). 
>>> y_pred = X_valid[:, 
 -1
]
>>> np.mean(keras.losses.mean_squared_error(y_valid, y_pred))
0.020211367
•
Sebbene banale, ottiene buone prestazioni: 
 Mean squared error (MSE) di 0.02  
Un altro approccio è impiegare una rete 
 fully connected
 . Ad esempio con un 
singolo layer, perciò si riduce ad una combinazione lineare dei valori della 
time series in ingresso.  
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 50
, 
1
]),
    keras.layers.Dense(
 1
)
]
)
•
Con la con
 ﬁ
gurazione: MSE loss, Adam optimizer, 20 epoche di training; si 
ottiene un MSE di 0.004.
18",keras valutare modello introduciamo approcci baseline confrontarci semplice modello stima valore futuro facendolo coincidere lultimo valore time series naive forecoasting ypred xvalid ypred sebbene banale ottiene buone prestazioni mean squared error altro approccio impiegare rete fully connected esempio singolo layer perci riduce combinazione lineare valori time series ingresso model gurazione loss adam optimizer epoche training ottiene
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#18,18,"RNN e Keras (4)
Implementiamo una semplice RNN, con un layer con un singolo nodo con la 
funzione Keras 
 SimpleRNN
 .  
model = keras.models.Sequential(
 [
  keras.layers.SimpleRNN(1, input_shape=[None, 1]
 )
]
)
Come dimensione dell'input impostiamo 
 None
  poiché una RNN elabora 
 time 
series
  di qualsiasi lunghezza e non occorre speci
 ﬁ
carla anticipatamente.  
Di default la 
 SimpleRNN
  usa la attivazione 
 tangente iperbolica
 .  
Il primo output viene elaborato con 
 h
(init)
=0
 e 
x
(0)
 pari al valore in input al 
primo step. Il nodo calcola la somma pesata dei 2 contributi e valuta la 
tangente iperbolica al risultato, ottenendo il primo valore in output 
 y
0
. Nella 
SimpleRNN
  tale valore corrisponde al valore per lo stato 
 h
(0)
.  
Al successivo step, lo stesso nodo prende in input il successivo input 
 x
(0) 
e lo 
stato 
 h
(0)
 e ripete l'elaborazione.  
L'unico valore in output corrisponde 
 y
49
. Se si vogliono ottenere tutti i valori in 
output impostare 
 return_sequences=True
 .
19",keras implementiamo semplice layer singolo nodo funzione keras simple model dimensione dellinput impostiamo none poich elabora time series qualsiasi lunghezza occorre speci carla default simple usa attivazione tangente iperbolica primo output viene elaborato init pari valore input primo step nodo calcola somma pesata contributi valuta tangente iperbolica risultato ottenendo primo valore output simple tale valore corrisponde valore stato successivo step stesso nodo prende input successivo input stato ripete lelaborazione lunico valore output corrisponde vogliono ottenere valori output impostare
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#19,19,"RNN e Keras (5)
Una volta compilato e sottoposto a 
 ﬁ
t (con
 ﬁ
gurazione: 20 epoche, Adam op.), 
tale modello raggiunge un MSE di 0.014, perciò al di sotto del modello 
lineare.  
•
Il modello lineare ha un totale di 51 parametri, cioè un parametro per ogni 
input e il bias. Nella SimpleRNN abbiamo un singolo parametro per input, 
uno per l'hidden state e per il bias, cioè 3 parametri in totale.  
•
Un SimpleRNN è una rete troppo semplice per avere questo task.
20",keras volta compilato sottoposto con gurazione epoche adam tale modello raggiunge perci sotto modello lineare modello lineare totale parametri cio parametro ogni input bias simple singolo parametro input lhidden state bias cio parametri totale simple rete troppo semplice avere task
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo assunto input per i nostri modelli di tipo vettoriale, dove ogni 
elemento 
 x
j
 corrisponde ad un attributo (o feature). Perciò possiamo 
raggruppare facilmente i dati in formato tabellari 
 istanze 
 x
 attributi
 . 
Successivamente abbiamo considerato immagini, dove per ogni coordinata 
abbiamo il valore del pixel. In questo scenario abbiamo introdotto le CNN, 
capaci di implementare logiche gerarchiche e gestire proprietà di 
invarianza.  
Come possiamo trattare input sotto forma di sequenze, come time series 
prediction, video analysis, etc?  
Oppure affrontare task che producono in output sequenze come l'
 image 
captioning, speech synthesis, 
 e
 music generation.
3",motivazioni assunto input modelli tipo vettoriale ogni elemento corrisponde attributo feature perci possiamo raggruppare facilmente dati formato tabellari istanze attributi successivamente considerato immagini ogni coordinata valore pixel scenario introdotto capaci implementare logiche gerarchiche gestire propriet invarianza possiamo trattare input sotto forma sequenze time series prediction video analysis etc oppure affrontare task producono output sequenze image captioning speech synthesis music generation
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#20,20,"Trend e stagionalità (seasonality)
Ci sono molti altri modelli per il forecast di time series, come il 
 weighted 
moving average
  e l'
autoregressive integrated moving average 
 (
ARIMA
 ). 
Alcune modelli richiedono di 
 rimuovere preliminarmente trend e stagionalità 
nei dati, ad esempio:  
•
Se i visitatori di un sito web crescono stabilmente 10% al mese, occorre 
rimuovere questa variazione dai dati in input. Una volta ottenuta la 
predizione si può reintegrare al valore 
 ﬁ
nale.  
•
Per predire la vendita di creme solari, occorre preliminarmente rimuovere la 
stagionalità annuale associata ai mesi estivi. Per esempio, rimuovendo al 
valore attuale il valore nell'anno precedente (
 differencing
 ). Si può reintegrare 
al valore 
 ﬁ
nale ottenuto.  
Le RNN non richiedono generalmente questi preprocessamenti, anche se 
possono aumentare le prestazioni, poiché la rete non è costretta ad 
apprenderli.
21",trend stagionalit seasonality molti altri modelli forecast time series weighted moving average autoregressive integrated moving average alcune modelli richiedono rimuovere preliminarmente trend stagionalit dati esempio visitatori sito web crescono stabilmente mese occorre rimuovere variazione dati input volta ottenuta predizione pu reintegrare valore nale predire vendita creme solari occorre preliminarmente rimuovere stagionalit annuale associata mesi estivi esempio rimuovendo valore attuale valore nellanno precedente differencing pu reintegrare valore nale ottenuto richiedono generalmente possono aumentare prestazioni poich rete costretta apprenderli
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#21,21,"Deep RNN: considerazioni
Una DeepRNN raggiunge un MSE di 0.003.  
Una architettura più adatta avrebbe un ultimo layer con un singolo valore in 
output per time step. Ma in questo caso avremmo un 
 hidden state  
rappresentato con un solo valore, che non avrebbe molta utilità. Una 
DeepRNN sfrutta tutti gli hidden states dei layer precedente per ""trasportare"" 
l'informazione necessaria per produrre l'ultimo output, e il contributo 
dell'hidden dell'ultimo layer risulta assai limitato.  
Possiamo sostituire il layer in output con un layer fully connected (o Dense). 
L'accuratezza non è alterata, il tempo di addestramento si riduce leggermente 
e possiamo scegliere qualsiasi funzione di attivazione.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 1
)
])
22",deep considerazioni deep raggiunge architettura adatta ultimo layer singolo valore output time step caso hidden state rappresentato solo valore molta utilit deep sfrutta hidden states layer precedente trasportare linformazione necessaria produrre lultimo output contributo dellhidden dellultimo layer risulta assai limitato possiamo sostituire layer output layer fully connected dense laccuratezza alterata tempo addestramento riduce leggermente possiamo scegliere qualsiasi funzione attivazione model true inputshape none
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#22,22,"Predizione di più dati
Possiamo tentare di stimare più valori temporalmente futuri, impi  
Elenchiamo alcuni approcci:  
•
Usare l'output come input nello step successivo ottenendo un valore alla 
volta  
•
Simile al precedente ma in output prediciamo contemporaneamente più 
valori ma considerando una unica loss (
 sequence-to-vector
 ) 
•
Simile al precedente ma con una loss per ogni valore predetto (
 sequence-to-
sequence
 )
23",predizione dati possiamo tentare stimare valori temporalmente futuri impi elenchiamo alcuni approcci usare loutput input step successivo ottenendo valore volta simile precedente output prediciamo valori considerando unica loss sequence vector simile precedente loss ogni valore predetto sequence sequence
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#23,23,"Predizione di più dati - uno dato alla volta
Possiamo tentare di stimare più valori temporalmente futuri.  
Una possibilità è impiegare il modello attuale, ottenere l'output e 
concatenarlo al predente input, ottenendo un secondo input e così via.  
•
Ad esempio, per predire 10 dati:  
series = generate_time_series(
 1
, n_steps + 
 10
)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for
 step_ahead 
 in 
range
(
10
):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=
 1
)
Y_pred = X[:, n_steps:]
Otteniamo un MSE=0.029. L'approccio 
 naive
  ottiene 0.223, ma il modello 
lineare 0.0188, ed è più accurato e veloce da addestrare.  
La Deep RNN rimane valida se limitiamo il numero di valori da predire.
24",predizione dati dato volta possiamo tentare stimare valori temporalmente futuri possibilit impiegare modello attuale ottenere loutput concatenarlo predente input ottenendo secondo input cos via esempio predire dati series nsteps xnew ynew series nsteps series nsteps xnew stepahead range ypredone npnewaxis ypredone axis ypred nsteps otteniamo lapproccio naive ottiene modello lineare accurato veloce addestrare deep rimane valida limitiamo numero valori predire
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#24,24,"Predizione di più dati - sequence-to-vector
Una seconda opzione è addestrare la RNN per predire 10 valori 
contemporaneamente.  
•
Usiamo la 
 sequence-to-vector
 , ma con 10 valori in output invece di 1.  
Intanto cambiamo i valori target:  
series = generate_time_series(
 10000
, n_steps + 
 10
)
X_train, Y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-10
:, 
0
]
X_valid, Y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-10
:, 
0
]
X_test, Y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-10
:, 
0
]
L'output layer consisterà di 10 nodi:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 10
)
]
)
E si potranno predire 10 valori in modo simile:  
Y_pred = model.predict(X_new)
Ora l'MSE è di 0.008, migliore del modello lineare.
25",predizione dati sequence vector seconda opzione addestrare predire valori usiamo sequence vector valori output invece intanto cambiamo valori target series nsteps xtrain ytrain series nsteps series xvalid yvalid series nsteps series xtest ytest series nsteps series loutput layer consister nodi model true inputshape none potranno predire valori modo simile ypred ora migliore modello lineare
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#25,25,"Predizione di più dati - sequence-to-sequence
Un ulteriore modello da impiegare è il 
 sequence-to-sequence
 , dove le 10 
predizioni sono comunque ottenute sequenzialmente step-by-step.  
•
Il vantaggio è avere una 
 loss
 ad ogni step, perciò più gradienti che saranno 
usati per aggiornare il modello, non solo seguendo un approccio 
 through-time,  
ma direttamente dagli output generati, come avviene nelle reti non ricorrenti.  
Al primo step il modello produrrà in output la predizione per gli step da 1 a 10, 
allo step successivo le predizioni da 2 a 11, e così via. Il target avrà la stessa 
lunghezza dell'input.  
•
Sebbene in output otteniamo una parte dei valori usati in input, l'input 
corrente consiste sempre in valori apparsi nel passato. Sarebbe scorretto 
impiegare valori del dataset che temporalmente sono da considerarsi futuri.  
Creiamo le sequenze target di 10 elementi:  
Y = np.empty((
 10000
, n_steps, 
 10
)) 
# each target is a sequence of 10D vectors
for
 step_ahead 
 in 
range
(
1
, 
10
 + 
1
):
    Y[:, :, step_ahead - 
 1
] = series[:, step_ahead:step_ahead + n_steps, 
 0
]
Y_train = Y[:
 7000
]
Y_valid = Y[
 7000
:
9000
]
Y_test = Y[
 9000
:]
26",predizione dati sequence sequence ulteriore modello impiegare sequence sequence predizioni comunque ottenute sequenzialmente step step vantaggio avere loss ogni step perci gradienti usati aggiornare modello solo seguendo approccio time direttamente output generati avviene reti ricorrenti primo step modello produrr output predizione step step successivo predizioni cos via target stessa lunghezza dellinput sebbene output otteniamo parte valori usati input linput corrente consiste sempre valori apparsi passato scorretto impiegare valori dataset temporalmente considerarsi futuri creiamo sequenze target elementi npempty nsteps target sequence vectors stepahead range stepahead series nsteps ytrain yvalid ytest
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#26,26,"Predizione di più dati - sequence-to-sequence
Per avere un modello 
 sequence-to-sequence
  impostiamo 
return_sequences=True
  per ogni layer, compreso l'ultimo. Ad ogni step 
valutiamo l'output del layer FC.  
•
Keras fornisce il 
 TimeDistributed
  layer, adatto ad essere valutato ad ogni step. 
I valori in input vengono automaticamente ridimensionati cosicché ogni step 
è trattato come una istanza separata  
•
[
batch size, time steps, input dim.
 ] 
 [
batch size × time steps, input dim.
 ] 
•
Nell'esempio abbiamo 20 nodi nel layer 
 SimpleRNN
 . L'output sarà una 
sequenza e non un singolo vettore. Il layer Dense viene applicato in modo 
indipendente ad ogni step.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
→
27",predizione dati sequence sequence avere modello sequence sequence impostiamo ogni layer compreso lultimo ogni step valutiamo loutput layer keras fornisce time distributed layer adatto essere valutato ogni step valori input vengono automaticamente ridimensionati cosicch ogni step trattato istanza separata batch size time steps input dim batch size time steps input dim nellesempio nodi layer simple loutput sequenza singolo vettore layer dense viene applicato modo indipendente ogni step model true inputshape none true
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#27,27,"Predizione di più dati - sequence-to-sequence
L'output nell'ultimo step è impiegato per la predizione e valutazione.  
Sebbene usiamo la MSE su tutti gli output, per la valutazione ci limitiamo a 
usare una metrica 
 custom
  che elabora l'MSE sull'ultimo step.  
def 
last_time_step_mse
 (
Y_true
, 
Y_pred
):
    
return
 keras.metrics.mean_squared_error(Y_true[:, 
 -1
], Y_pred[:, 
 -1
])
optimizer = keras.optimizers.Adam(lr=
 0.01
)
model.
compile
(loss=
""mse""
, optimizer=optimizer, metrics=[last_time_step_mse])
Si ottiene MSE di 0.006, 25% meglio del modello precedente.  
È possibile combinare i due approcci: predire 10 valori, concatenarli ai dati in 
input e predire i successivi 10, ottenendo sequenze di lunghezza arbitraria.  
Nota: Il 
 Montecarlo Dropout
  (
MC Dropout
 ) è spesso inclusa in ogni cella per 
omettere in modo random parte degli input e degli hidden state.  
28",predizione dati sequence sequence loutput nellultimo step impiegato predizione valutazione sebbene usiamo output valutazione limitiamo usare metrica custom elabora sullultimo step def ytrue ypred return ypred optimizer model compile loss mse ottiene meglio modello precedente possibile combinare due approcci predire valori concatenarli dati input predire successivi ottenendo sequenze lunghezza arbitraria nota montecarlo dropout dropout spesso inclusa ogni cella omettere modo random parte input hidden state
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#28,28,"Predizione di più dati: limiti (1)
Per addestrare una RNN su sequenze molto lunghe occorre creare 
 reti molto 
deep
 , coi noti problemi di 
 instabilità dei gradienti
  (es. tempo di 
apprendimento troppo lungo, o instabile).  
Inoltre la rete fa più fatica a ricordare le informazioni iniziali della sequenza.  
Alcune tecniche viste possono essere nuovamente applicate (es. dropout, 
optimizers più adatti alla architettura deep).  
Le 
ReLU  
non sono adatte
  per le 
 RNN
 . 
•
Supponiamo che la discesa del gradiente aggiorni i parametri in modo da 
incrementare leggermente l'output. Siccome ad ogni step sono usati gli stessi 
parametri, anche l'output al successivo step può essere leggermente 
incrementato, e così via, 
 ﬁ
no a valori troppo elevati o instabili. 
 Una funzione 
che non satura non può prevenire questo
 .  
•
Anche i gradienti possono assumere valori troppo elevati, perciò sono utili 
tecniche quali il 
 Gradient clipping.
29",predizione dati limiti addestrare sequenze molto lunghe occorre creare reti molto deep noti problemi instabilit gradienti tempo apprendimento troppo lungo instabile inoltre rete fatica ricordare informazioni iniziali sequenza alcune tecniche viste possono essere nuovamente applicate dropout optimizers adatti architettura deep adatte supponiamo discesa gradiente aggiorni parametri modo incrementare leggermente loutput siccome ogni step usati parametri loutput successivo step pu essere leggermente incrementato cos via valori troppo elevati instabili funzione satura pu prevenire gradienti possono assumere valori troppo elevati perci utili tecniche quali gradient clipping
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#29,29,"Predizione di più dati: limiti (2)
La 
Batch normalization
  non mostra sperimentalmente la stessa ef
 ﬁ
cacia 
rispetto alle reti deep tradizionali e non ottiene bene
 ﬁ
ci. 
•
Teoricamente un layer BN può essere aggiunto ad ogni memory cell, e 
interverrà dopo ogni step, sia sugli input correnti sia sull'hidden state (dello 
step precedente).  
•
Ma il layer BN sarà usato ad ogni step, con gli stessi parametri, senza 
considerare la scala di valori e l'offset degli input e dell'hidden state attuali.  
Nota: un tecnica simile ma più adatta è la 
 Layer normalization
 , ma invece di 
normalizzare rispetto al batch, normalizza rispetto alla dimensione delle 
features.
30",predizione dati limiti batch normalization mostra stessa cacia rispetto reti deep tradizionali ottiene bene teoricamente layer pu essere aggiunto ogni memory cell interverr dopo ogni step input correnti sullhidden state dello step precedente layer usato ogni step parametri senza considerare scala valori loffset input dellhidden state attuali nota tecnica simile adatta layer normalization invece normalizzare rispetto batch normalizza rispetto dimensione features
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#3,3,"Introduzione
Una 
 time series
  consiste in una serie di misurazioni indicizzate con un 
ordine temporale.  
•
Es. ultima quotazione giornaliera di un titolo 
 ﬁ
nanziario, situazione oraria del 
meteo, traiettoria di una automobile  
Le 
Recurrent Neural Networks
  (
RNN
 ) sono architetture di reti neurali 
adatte ad analizzare time series e stimare misure mancanti o future.  
Rispetto alle 
 CNN
  possono elaborare dati in ingresso con lunghezza 
arbitraria non pre
 ﬁ
ssata, più adatte in certi contesti.  
•
Es. analisi di una frase per fare una traduzione automatica o speech-to-text  
Ciononostante non sono le uniche architetture per 
 time series
 . 
•
Reti
 fully-connected 
 sono sempre adatte per sequenze di lunghezza 
limitata, mentre sequenze molto lunghe possono essere elaborate da 
ﬁ
ltri convoluzionali.
4",introduzione time series consiste serie misurazioni indicizzate ordine temporale ultima quotazione giornaliera titolo nanziario situazione oraria meteo traiettoria automobile recurrent neural networks architetture reti neurali adatte analizzare time series stimare misure mancanti future rispetto possono elaborare dati ingresso lunghezza arbitraria pre ssata adatte certi contesti analisi frase fare traduzione automatica speech text ciononostante uniche architetture time series reti fully connected sempre adatte sequenze lunghezza limitata mentre sequenze molto lunghe possono essere elaborate ltri convoluzionali
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#30,30,"RNN più recenti
Le celle introdotte 
 ﬁ
nora soffrono del problema del 
 vanishing
  (e exploding) 
gradient. Il gradient clipping o altre tecniche, sebbene risolvano il problema, 
non permettono alle RNN di analizzare sequenze lunghe.  
Per tale motivo sono state introdotte le 
 memory cells
 , cioè unità di 
elaborazione che mantengono lo stato memorizzato e lo propagano alle celle 
successive evitando che ""svanisca"" a causa dei gradienti troppo bassi.  
Le 
Long Short-Term Memory (LSTM)
  sono le prime memory cell introdotte in 
letteratura, le 
 Gated Recurrent Unit (GRU)
  ne sono una versione sempli
 ﬁ
cata. 
Nelle 
 Bidirectional Recurrent Neural Networks
  si sfruttano le informazioni 
raccolte negli step precedenti e successivi per determinare l'output nello step 
corrente.
31",recenti celle introdotte nora soffrono problema vanishing exploding gradient gradient clipping altre tecniche sebbene risolvano problema permettono analizzare sequenze lunghe tale motivo state introdotte memory cells cio unit elaborazione mantengono stato memorizzato propagano celle successive evitando svanisca causa gradienti troppo bassi long short term memory prime memory cell introdotte letteratura gated recurrent unit versione sempli cata bidirectional recurrent neural networks sfruttano informazioni raccolte step precedenti successivi determinare loutput step corrente
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#31,31,"Celle LSTM - motivazioni
Le 
LSTM
  sono memory cells introdotte per dotare la cella di memoria 
 a lungo 
termine 
 utile per riconoscere pattern di segnale più estesi.  
Oltre alla rappresentazione 
 long-term
 , determinata dai pesi che sono appresi 
durante il training, le celle hanno una memoria
  short-term
  capace di 
rappresentare le attivazioni ef
 ﬁ
mere. Tale memoria viene condivisa da una 
cella alla successiva.  
All'interno delle memory cells, oltre allo stato, esistono una serie di 
 gate 
controllers
  che determinano quali input in
 ﬂ
uenzano lo stato, se lo stato deve 
essere azzerato (o dimenticato) e come lo stato in
 ﬂ
uenza l'output della cella.  
•
Perciò nella LSTM esistono meccanismi dedicati sia per aggiornare lo stato, 
sia per azzerarlo.  
I gate sono governati da parametri che sono stimati durante l'apprendimento.
32",celle motivazioni memory cells introdotte dotare cella memoria lungo termine utile riconoscere pattern segnale estesi oltre long term determinata pesi appresi durante training celle memoria short term capace rappresentare attivazioni mere tale memoria viene condivisa cella successiva allinterno memory cells oltre stato esistono serie gate controllers determinano quali input uenzano stato stato deve essere azzerato dimenticato stato uenza loutput cella perci esistono meccanismi dedicati aggiornare stato azzerarlo gate governati parametri stimati durante
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#32,32,"Celle LSTM e Keras
Keras ne sempli
 ﬁ
ca l'uso con la funzione 
 LSTM
 : 
model = keras.models.Sequential([
    keras.layers.LSTM(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.LSTM(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
O impiegando la cella general purpose 
 RNN
  che può assumere come 
argomento 
 LSTMCell
 , utile per creare celle 
 custom
 , con lo svantaggio di 
perdere parte delle ottimizzazioni GPU:  
model = keras.models.Sequential([
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
,
                     input_shape=[
 None
, 
1
]),
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
Successivamente vedremo una implementazione con le funzionalità
  d2l
.
33",celle keras keras sempli luso funzione model keraslayersl true inputshape none keraslayersl true impiegando cella general purpose pu assumere argomento mcell utile creare celle custom svantaggio perdere parte ottimizzazioni model keraslayersr mcell true inputshape none keraslayersr mcell true successivamente vedremo implementazione funzionalit
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#33,33,"Celle LSTM: Architettura (1)
L'architettura di una cella 
 LSTM
  è la seguente:  
Esistono 4 gates (
 FC
) i cui input sono: l'
 hidden state
  dello step precedente 
 h
(t-1) 
e l'input corrente 
 x
(t)
.  
I gate sono: 
 forget gate
 , 
input gate
 , 
output gate
 , e 
input node
 . I relativi output, 
f(t)
, 
i(t)
, 
o(t)
 e 
g(t)
; sono determinati da una rete fully connected (FC). Hanno 
tutti funzione di attivazione 
 logistic
 , tranne l'
 input node
  che impiega la 
 tanh
.
34
",celle architettura larchitettura cella seguente esistono gates input sono hidden state step precedente linput corrente gate sono forget gate input gate output gate input node relativi output determinati rete fully connected funzione attivazione logistic tranne input node impiega tanh
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#34,34,"Celle LSTM: Architettura (2)
Possiamo interpretare i gate nel seguente modo:  
•
L'
input gate
  determina quanto dell'input corrente deve essere aggiunto ad 
 c
(t) 
che assume il ruolo di stato corrente.  
•
Il 
forget gate 
 in
ﬂ
uenza quanto tenere e quanto dimenticare dello stato interno 
precedente 
 c
(t-1)
.  
•
L'
output gate
  quanto la cella corrente in
 ﬂ
uenzerà l'output 
 y
(t)
. 
•
L'
input node
  rappresenta la computazione di una cella ricorrente tradizionale.
35
",celle architettura possiamo interpretare gate seguente modo input gate determina dellinput corrente deve essere aggiunto assume ruolo stato corrente forget gate uenza tenere dimenticare stato interno precedente output gate cella corrente uenzer loutput input node rappresenta computazione cella ricorrente tradizionale
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#35,35,"Celle LSTM: Architettura (3)
Per esempio, se il 
 forget gate
  fosse sempre 1 e l'
 input gate
  fosse 0, lo stato 
 c
(t-1) 
rimarrebbe imperturbato negli step futuri. Nella realtà, i gate saranno addestrati 
in modo da perturbare lo stato in funzione degli input analizzati dalla cella.  
•
Questa tecnica basata su gate affronta il 
 vanishing gradient problem  
garantendo che gli stati possano propagarsi temporalmente per molti step.  
L'
input node
  produce 
 g
(t)
 e si comporta come una cella ""base"", ma nella LSTM 
una parte rilevante del output del cella base è memorizzato nello stato interno 
c(t)
, e il resto scartato. La suddivisione tra output e stato è più netta. 
36
",celle architettura esempio forget gate sempre input gate stato rimarrebbe imperturbato step futuri realt gate addestrati modo perturbare stato funzione input analizzati cella tecnica basata gate affronta vanishing gradient problem garantendo stati possano propagarsi temporalmente molti step input node produce comporta cella base parte rilevante output cella base memorizzato stato interno resto scartato suddivisione output stato netta
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#36,36,"Celle LSTM: Architettura (4)
L'output della cella 
 h(t), 
 corrispondente al valore y di una cella tradizionale, è 
generato prendendo il valore 
 tanh
 dello stato interno corrente 
 c(t)
 e calcolando 
una moltiplicazione element-wise con il valore ottenuto dall'
 output gate
 . 
•
Se l'
output gate
  è 1 lo stato interno in
 ﬂ
uenzerà i layer successivi (in una 
architettura multilayer) nello step corrente. Se è 0 lo stato non li in
 ﬂ
uenzerà.  
•
È sempre possibile che lo stato interno si propaghi per molti step, e che non 
in
ﬂ
uenzi l'output a causa dell'
 output gate 
 che lo inibisce, 
 ﬁ
no ad un certo 
step in cui il gate potrà invertire il valore. Per tale motivo 
 h(t)
 è visto come 
stato 
 short-term,
  mentre 
 c(t) 
long-term
 .
37
",celle architettura loutput cella corrispondente valore cella tradizionale generato prendendo valore tanh stato interno corrente calcolando moltiplicazione element wise valore ottenuto dall output gate output gate stato interno uenzer layer successivi architettura multilayer step corrente stato uenzer sempre possibile stato interno propaghi molti step uenzi loutput causa dell output gate inibisce certo step gate potr invertire valore tale motivo visto stato short term mentre long term
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#37,37,"Celle LSTM: Architettura (5)
In sintesi, la 
 LSTM
  è in grado di riconoscere sequenze lunghe, per mezzo dell'
 input 
gate
, memorizzarlo in uno stato long-term, e preservarlo 
 ﬁ
nché è giudicato 
importante, per mezzo del
  forget gate
 , e ripescarlo quando necessario.  
•
Per tale motivo le LSTM hanno ottenuto buoni risultati nell'analisi di pattern, anche molto estesi, in 
time series, testi, audio, etc.  
In termini analitici, per una singola istanza in input si ha:  
•
dove 
 W
xi
, 
W
xf
, 
W
xo
,
W
xg
 sono le matrici dei pesi dei 4 layer per le connessioni con 
l'input vector 
 x
(t)
. 
•
W
hi
, 
W
hf
, 
W
ho
,
W
hg
 sono le matrici dei pesi dei 4 layer per le connessioni con lo stato 
short-term precedente 
 h
(t-1)
. 
•
b
i
, 
b
f
, 
b
o
,
b
g
 sono i bias, inizializzati a 1 invece di 0 per evitare di ""dimenticare"" tutto 
all'inizio del training.
38
",celle architettura sintesi grado riconoscere sequenze lunghe mezzo dell input gate memorizzarlo stato long term preservarlo nch giudicato importante mezzo forget gate ripescarlo quando necessario tale motivo ottenuto buoni risultati nellanalisi pattern molto estesi time series testi audio etc termini analitici singola istanza input matrici pesi layer connessioni linput vector matrici pesi layer connessioni stato short term precedente bias inizializzati invece evitare dimenticare allinizio training
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#38,38,"Celle LSTM, Keras e d2l
11-memory_cells.ipynb
39",celle keras
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#39,39,"Celle LSTM: Peephole connections
In una cella LSTM tradizionale i gate controllers analizzano 
 x
(t)
 e 
h
(t-1)
. Può 
essere utile dargli la possibilità di usare le informazioni nello stato long-term.  
Le 
peephole connections
  aggiungono il precedente stato long-term 
 c
(t-1) 
all'input dei controllers del 
 forget
  e 
input
  gate. Lo stato long-term corrente 
 c
(t)
 è 
aggiunto all'input controller dell'output gate.  
Non sempre ci sono miglioramenti,  
perciò si può tentare di usarli e valutare.  
In Keras non c'è supporto uf
 ﬁ
ciale alla cella con 
 peephole connections
 , ma si 
può creare un layer RNN generico e passargli 
 PeepholeLSTMCell
  al suo 
costruttore.
40
",celle peephole connections cella tradizionale gate controllers analizzano pu essere utile dargli possibilit usare informazioni stato long term peephole connections aggiungono precedente stato long term allinput controllers forget input gate stato long term corrente aggiunto allinput controller delloutput gate sempre miglioramenti perci pu tentare usarli valutare keras supporto ciale cella peephole connections pu creare layer generico passargli peephole cell costruttore
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#4,4,"Alcuni task con dati temporali
Speech recognition  
Music generation  
Sentiment classi
 ﬁ
cation  
DNA sequence analysis  
Machine translation  
(Video) Activity recognition
“It was a bright cold day in 
April, and the clocks were 
striking thirteen
“I loved this so much. I crap out 
on books about 40 pages in about 
90% of the time.”
Ø  
o few inputs
ACAAGATGCCATTGTCCCCCGGCCTCCTGCTGC ACAAGATG CCATTGTCCCCCGGCCTCCT GCTGC
“Ho corso per arrivare in orario.” “I ran to get on time.”
Alzarsi -> In piedi -> Camminare",alcuni task dati temporali speech recognition music generation sentiment classi cation sequence analysis machine translation video activity recognition it bright cold day april clocks striking thirteen loved much crap books pages time inputs ho corso arrivare orario ran get time alzarsi piedi camminare
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#40,40,"Celle GRU - motivazioni
Dopo le LSTM sono state studiate altre architetture che potessero mantenere i 
vantaggi ma con meno risorse di calcolo necessarie.  
Le celle 
 Gated Recurrent Unit (GRU)
 , con un numero minore di gate, sono 
state proposte per tale scopo, 
41",celle motivazioni dopo state studiate altre architetture potessero mantenere vantaggi meno risorse calcolo necessarie celle gated recurrent unit numero minore gate state proposte tale scopo
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#41,41,"Celle GRU
Le celle 
 Gated Recurrent Unit
  (
GRU
 ) sono una versione sempli
 ﬁ
cata, e con 
meno parametri, delle LSTM. In molti task mostrano prestazioni simili con 
tempi di addestramento ridotti.  
Le sempli
 ﬁ
cazioni sono le seguenti:  
•
Entrambi i vettori di stato sono fusi in un singolo vettore 
 h
(t)
. 
•
Un singolo 
 update gate  
z
(t)
 rappresenta una fusione del 
 forget
  e 
input gate
 . 
La funzione 
 keras.layers.GRU
  è impiegata in modo simile a SimpleRNN e 
LSTM.
42
",celle celle gated recurrent unit versione sempli cata meno parametri molti task mostrano prestazioni simili tempi addestramento ridotti sempli cazioni seguenti entrambi vettori stato fusi singolo vettore singolo update gate rappresenta fusione forget input gate funzione keraslayersg impiegata modo simile simple
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#42,42,"Celle GRU (2)
Intuitivamente il 
 reset gate
  r(t)
 controlla quanto dello stato precedente 
vogliamo mantenere nelle successive elaborazioni.  
L'
update gate  
z(t)
 controlla quanto il nuovo stato sia copia dello stato 
precedente.  
Entrambi i gate sono implementati con una FC e funzione di attivazione 
sigmoid
 , perciò con output in (0,1).
43
",celle intuitivamente reset gate controlla stato precedente vogliamo mantenere successive elaborazioni update gate controlla nuovo stato copia stato precedente entrambi gate implementati funzione attivazione sigmoid perci output
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#43,43,"Celle GRU (3)
Il 
hidden state candidato h(t) 
 (candidato poiché dobbiamo ancora sommare la 
componente del 
 update gate
 ) sarà generato combinando insieme 
 x(t)
 e 
l'output del reset gate 
 r(t)
, e impiegando una funzione di attivazione 
 tanh
. 
Quando il  
reset gate  
ha output pari a 1, otteniamo una RNN tradizionale. Se il 
gate
 genera 0, l'hidden state candidato coincide con l'output della FC con 
 x(t) 
come input. Perciò l'hidden state sarà resettato. 
44
",celle hidden state candidato candidato poich dobbiamo ancora sommare componente update gate generato combinando insieme loutput reset gate impiegando funzione attivazione tanh quando reset gate output pari otteniamo tradizionale gate genera lhidden state candidato coincide loutput input perci lhidden state resettato
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#44,44,"Celle GRU (4)
Il 
hidden state h(t)  
dipende dal 
 update gate
 , che determina quanto il nuovo 
stato corrisponde al vecchio oppure al nuovo stato candidato.  
Quando l'
 update gate
  è 1, manteniamo lo stato così com'è, e l'informazione 
x(t) non sarà considerata per alterarlo. Perciò ignoriamo lo step corrente nella 
catena di correlazioni che stiamo rappresentando con lo stato. Se l'output del 
gate è 0, lo stato corrisponde al candidato che abbiamo appena creato.
45
",celle hidden state dipende update gate determina nuovo stato corrisponde vecchio oppure nuovo stato candidato quando update gate manteniamo stato cos com linformazione considerata alterarlo perci ignoriamo step corrente catena correlazioni rappresentando stato loutput gate stato corrisponde candidato appena creato
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#5,5,"Nodi Ricorrenti
Finora abbiamo considerato reti neurali 
 feedforward
 , dove le attivazioni si 
propagano
  dall'input all'output layer.   
Le 
RNN
  sono simili alle reti feedforward, ma hanno connessioni anche 
 verso i 
layer precedenti
 , creando una specie di ciclo.  
La più semplice 
 RNN
  consiste in un 
 nodo ricorrente 
 (o
 recurrent neuron
 ) 
che 
riceve l'input 
 x
, produce in output 
 y,
 e lo stesso output viene 
 riproposto
  in input.  
•
Ad ogni 
 iterazione  
t
, (o 
step
, o 
frame
 ), il nodo ricorrente riceve l'input 
 x
(t)
 e 
l'output precedente 
 y
(t-1)
. Il valore 
 y
(t)
 alla prima iterazione si considera pari a 0.  
La RNN si può rappresentare esplicitando l'asse temporale (
 unrolling the 
network through time
 ).
6
",nodi ricorrenti finora considerato reti neurali feedforward attivazioni propagano dallinput alloutput layer simili reti feedforward connessioni verso layer precedenti creando specie ciclo semplice consiste nodo ricorrente recurrent neuron riceve linput produce output stesso output viene riproposto input ogni iterazione step frame nodo ricorrente riceve linput loutput precedente valore prima iterazione considera pari pu rappresentare esplicitando lasse temporale unrolling network time
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#6,6,"Nodi Ricorrenti e Layers
Se 
x
(t) 
e 
y
(t-1)
 sono vettori, i parametri che de
 ﬁ
niscono il comportamento di un 
nodo ricorrente consistono in due vettori di pesi: 
 w
x
 e 
w
y
.  
L'
output  
di un singolo nodo
  si ricava nel modo usuale:  
 
Un
 layer di nodi ricorrenti 
 comprende più nodi, ed i parametri saranno 
perciò rappresentati da due matrici 
  e 
 .
y
(
t
)
=
σ
(
w
T
x
x
(
t
)
+
w
T
y
y
(
t
−
1
)
+
b
)
W
x
W
y
layer di nodi ricorrenti",nodi ricorrenti layers vettori parametri niscono comportamento nodo ricorrente consistono due vettori pesi output singolo nodo ricava modo usuale layer nodi ricorrenti comprende nodi parametri perci rappresentati due matrici layer nodi ricorrenti
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#7,7,"Nodi ricorrenti: calcolo degli output
Nel caso più generale di
  un layer di nodi ricorrenti 
 con un input costituito da 
vettori
 , cioè istanze rappresentate con più features:  
  dove:  
•
  è una matrice 
 m
n
nodi
, che contiene gli output del layer di 
 n
nodi
 nodi 
ricorrenti, per ognuna delle 
 m
 istanze all'interno del mini-batch,  
•
  è una matrice 
 m
n
inputs
, dove 
 n
inputs
 sono il numero di features in input,  
•
  è la matrice 
 n
inputs
 n
nodi
 dei pesi delle connessioni per le istanze in input,  
•
  è la matrice 
 n
nodi
n
nodi
 dei pesi delle connessioni per i valori in output 
ottenuti nello step precedente.  
•
Si può dire che una RNN è una feedforward NN dove i parametri di ogni 
layer sono condivisi (cioè sono gli stessi) per tutti i time steps.
Y
(
t
)
=
σ
(
x
(
t
)
W
x
+
y
(
t
−
1
)
W
y
+
b
)
y
(
t
)
×
x
(
t
)
×
W
x
×
W
y
×
8",nodi ricorrenti calcolo output caso generale layer nodi ricorrenti input costituito vettori cio istanze rappresentate features dove matrice nodi contiene output layer nodi nodi ricorrenti ognuna istanze allinterno mini batch matrice inputs inputs numero features input matrice inputs nodi pesi connessioni istanze input matrice nodi nodi pesi connessioni valori output ottenuti step precedente pu dire feedforward parametri ogni layer condivisi cio stessi time steps
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#8,8,"Nodi ricorrenti: forma compatta
Le matrici dei pesi 
  e 
   sono spesso 
 concatenate
  verticalmente in una 
singola matrice (
 n
inputs
+n
nodi
)
n
nodi 
La notazione 
  rappresenta la concatenazione delle matrici 
  
In questo modo si ottiene la seguente 
 forma compatta
 : 
   con    
È chiaro che 
  è funzione di 
  e 
 , quest'ultimo è funzione di 
  e 
, che è funzione di 
  e 
 , e così via.  
Di conseguenza  
dipende da tutti i valori in input 
 ﬁ
no a 
t=0
. 
Si può dire che il nodo contiene memoria di tutti gli input precedenti. In realtà 
i pattern che può riconoscere non sono lunghi tipicamente più di 10 steps.
W
x
W
y
×
[
X
(
t
)
Y
(
t
−
1
)
]
X
(
t
)
 e 
Y
(
t
−
1
)
σ
(
[
X
(
t
)
Y
(
t
−
1
)
]
W
+
b
)
 W
=
[
W
x
W
y
]
Y
(
t
)
 X
(
t
)
Y
(
t
−
1
)
 X
(
t
−
1
)
Y
(
t
−
2
)
 X
(
t
−
2
)
Y
(
t
−
3
)
Y
(
t
)
9",nodi ricorrenti forma compatta matrici pesi spesso concatenate verticalmente singola matrice inputs nodi nodi notazione rappresenta concatenazione matrici modo ottiene seguente forma compatta chiaro funzione questultimo funzione funzione cos via conseguenza dipende valori input pu dire nodo contiene memoria input precedenti realt pattern pu riconoscere lunghi tipicamente steps
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#9,9,"Memory Cells
Una rete neurale in grado di tenere traccia degli stati in cui si è trovata nelle 
passate iterazioni si chiama 
 memory cell
  (o 
cell
). 
•
Un singolo
  recurrent node,
  o un layer di tali nodi, è una 
 cella
 elementare, in 
grado di riconoscere piccoli patterns, tipicamente non più lunghi di 10 steps.  
Indichiamo 
 stato
  di una cella all'istante 
 t
 con la notazione 
 , dove 
 h
 sta per 
hidden
 . Lo stato dipende dall'input corrente e dallo stato precedente:  
 
•
Anche l'
 output  
 dipende dalle stesse quantità.  
Nelle celle elementari 
 output
  e 
stato  
coincidono
 , ma nelle celle più 
complesse non sempre accade, come nel seguente esempio:
h
(
t
)
h
(
t
)
=
f
(
h
(
t
−
1
)
,
x
(
t
)
)
y
(
t
)
10
",memory cells rete neurale grado tenere traccia stati trovata passate iterazioni chiama memory cell cell singolo recurrent node layer tali nodi cella elementare grado riconoscere piccoli patterns tipicamente lunghi steps indichiamo stato cella allistante notazione hidden stato dipende dallinput corrente stato precedente output dipende quantit celle elementari output stato coincidono celle complesse sempre accade seguente esempio
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #2
1",deep learning universit roma tre dipartimento ingegneria anno accademico recurrent neural networks parte
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#1,1,"Sommario
1d convolution per sequenze  
WaveNet  
Deep RNN  
Bidirectional RNN  
Encoder-decoder e Keras  
Esercizi",sommario convolution sequenze wave net deep bidirectional encoder decoder keras esercizi
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#10,10,"Bidirectional RNN - motivazioni
Finora abbiamo visto scenari di predizione dove un valore in output dipende 
dai valori precedenti (es. predizione di una parola data una frase iniziale).  
In altri task è utile considerare il contesto di un valore in entrambe le 
direzioni, es. Part-of-speech tagging.  
•
Ad esempio, nel seguente task tentiamo di predire il token mancante dal 
testo dato come input:
11
",bidirectional motivazioni finora visto scenari predizione valore output dipende valori precedenti predizione parola data frase iniziale altri task utile considerare contesto valore entrambe direzioni part speech tagging esempio seguente task tentiamo predire token mancante testo dato input
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#11,11,"Bidirectional RNN
Nelle Bidirectional RNN abbiamo 2 layer unidirezionali con direzioni opposte, 
che operano sul medesimo input. Nel primo layer, il primo input è 
 x
1
 e l'ultimo 
x
T
, nel secondo il primo input è 
 x
T
 e l'ultimo 
 x
1
. 
L'output è generato concatenando l'output dei 2 layers.  
•
Nel caso multilayer, l'output diverrà l'input dei successivi 2 layers 
bidirezionali, e così via 
 ﬁ
no al layer di output.  
In Keras sono implementate con il parametro 
 bidirectional=
 True
.
12
",bidirectional bidirectional layer unidirezionali direzioni opposte operano medesimo input primo layer primo input lultimo secondo primo input lultimo loutput generato concatenando loutput layers caso multilayer loutput diverr linput successivi layers bidirezionali cos via layer output keras implementate parametro bidirectional true
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#12,12,"Architettura Encoder-decoder - Keras
14-encoder_decoder_interfaces.ipynb
13
",architettura encoder decoder keras
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#13,13,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?
14",applicazioni puoi immaginare possibili applicazioni sequence sequence sequence vector vector sequence
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#14,14,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?  
Sequence-to-sequence: previsioni meteo, machine translation (con Encoder-
decoder), video captioning, speech to text, music generation, identi
 ﬁ
care 
accordi nella musica.  
Sequence-to-vector: classi
 ﬁ
care brani musicali in base al genere, analizzare il 
sentimento di una recensione di un libro, predire quale parola sta pensando un 
paziente afasico in base ai segnali di impianti cerebrali, stimare la probabilità 
di vedere un certo 
 ﬁ
lm in base ai 
 ﬁ
lm visti in passato.  
Vector-to-sequence: image captioning, creare una playlist di musica in base agli 
embedding dell'artista corrente, generare una melodia in base a dei parametri, 
identi
 ﬁ
care pedoni in una foto.
15",applicazioni puoi immaginare possibili applicazioni sequence sequence sequence vector vector sequence sequence sequence previsioni meteo machine translation con encoder decoder video captioning speech text music generation identi care accordi musica sequence vector classi care brani musicali base genere analizzare sentimento recensione libro predire parola pensando paziente afasico base segnali impianti cerebrali stimare probabilit vedere certo base visti passato vector sequence image captioning creare playlist musica base embedding dellartista corrente generare melodia base parametri identi care pedoni foto
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#15,15,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?
16",dimensioni dimensioni deve avere linput layer cosa rappresenta ogni dimensione riguardo output
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#16,16,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?  
Un layer RNN deve avere input 3 dimensionali: la prima dimensione è la 
dimensione del batch (cioè il numero di time series), la seconda rappresenta il 
dimensione temporale, e la terza indica il numero di features per step.  
L'output sarà ancora 3 dimensionale, con le stesse 2 dimensioni dell'input, ma 
con l'ultima dimensione uguale al numero di nodi. 
17",dimensioni dimensioni deve avere linput layer cosa rappresenta ogni dimensione riguardo output layer deve avere input dimensionali prima dimensione dimensione batch cio numero time series seconda rappresenta dimensione temporale terza indica numero features step loutput ancora dimensionale dimensioni dellinput lultima dimensione uguale numero nodi
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#17,17,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?
18",parametro returnsequence vuoi costruire sequence sequence quali layer devono avere riguarda sequence vector
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#18,18,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?  
Per una sequence-to-sequence, il parametro è True per tutti i layer.  
Per una sequence-to-vector, il parametro è True per tutti gli RNN layers eccetto 
l'ultimo layer, impostato a False.
19",parametro returnsequence vuoi costruire sequence sequence quali layer devono avere riguarda sequence vector sequence sequence parametro true layer sequence vector parametro true layers eccetto lultimo layer impostato false
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#19,19,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?
20",forecasting supponi avere time series univariate campionamento giornaliero vuoi fare forecasting prossimi giorni architettura impieghi
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#2,2,"1d convolution per le sequenze
Sebbene popolari, 
 LSTM
  e 
GRU
  non sono adatte a sequenze che contengono 
pattern signi
 ﬁ
cativi che si estendo per molti steps (es. 100). Una alternativa è 
ridurre
  la lunghezza delle sequenze in input.  
Impieghiamo le 
 1d convolution
  sulle sequenze in input considerando come 
profondità la dimensione temporale piuttosto che spaziale. Fissiamo segmenti 
di dimensioni prede
 ﬁ
nita sulle sequenze in input per creare tali sequenze che 
corrispondono alle dimensioni del kernel.  
Estendiamo l'approccio considerando più 
 ﬁ
ltri 1d convolution.  Ogni 
 ﬁ
ltro 
riconoscerà determinati pattern.  
•
Ad esempio, con 10 kernels, l'output complessivo del layer consisterà in 10 
sequenze 1-dimensionali, tutte della stessa lunghezza, o una singola 
sequenza 10-dimensionale.  
Possiamo avere reti che alternano layer 1d convolution e layer ricorrenti, ed 
eventualmente layer di pooling. In questo modo le celle analizzeranno dati 
temporali più 
 compatti
 . Oppure possiamo avere reti costituite interamente da 
moduli convolutivi (es. WaveNet).
3",convolution sequenze sebbene popolari adatte sequenze contengono pattern signi cativi estendo molti steps alternativa ridurre lunghezza sequenze input impieghiamo convolution sequenze input considerando profondit dimensione temporale piuttosto spaziale fissiamo segmenti dimensioni prede nita sequenze input creare tali sequenze corrispondono dimensioni kernel estendiamo lapproccio considerando ltri convolution ogni ltro riconoscer determinati pattern esempio kernels loutput complessivo layer consister sequenze dimensionali tutte stessa lunghezza singola sequenza dimensionale possiamo avere reti alternano layer convolution layer ricorrenti eventualmente layer pooling modo celle analizzeranno dati temporali compatti oppure possiamo avere reti costituite interamente moduli convolutivi wave net
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#20,20,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?  
L'architettura più semplice è una sequence-to-vector, cioè uno stack di RNN 
layers (tutti con return_sequences=True eccetto il primo), con 7 nodi nel layer 
di output. Si addestra il modello con 
 ﬁ
nestre random dalle time series (es. 
sequence di 30 giorni consecutivi e un vettore contenente i valori dei successivi 
7 giorni come target).  
In alternativa si imposta return_sequences=True per tutti i layer creando una 
sequence-to-sequence. Per l'addestramento si usano random windows con la 
stessa lunghezza del target. 
21",forecasting supponi avere time series univariate campionamento giornaliero vuoi fare forecasting prossimi giorni architettura impieghi larchitettura semplice sequence vector cio stack layers tutti eccetto primo nodi layer output addestra modello nestre random time series sequence giorni consecutivi vettore contenente valori successivi giorni target alternativa imposta layer creando sequence sequence laddestramento usano random windows stessa lunghezza target
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#21,21,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?
22",training quali maggiori dif colt training puoi affrontarle
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#22,22,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?  
Le due maggiori problematiche sono l'instabilità dei gradienti e la short-term 
memory limitata. I problemi peggiorano in presenza di sequenze molto lunghe.  
Per affrontarli si usano learning rate più bassi, funzioni di attivazioni che 
saturano ed eventualmente gradient clipping, layer normalization o dropout ad 
ogni step. Per la short-term memory, si impiegano celle LSTM o GRU.
23",training quali maggiori dif colt training puoi affrontarle due maggiori problematiche linstabilit gradienti short term memory limitata problemi peggiorano presenza sequenze molto lunghe affrontarli usano learning rate bassi funzioni attivazioni saturano eventualmente gradient clipping layer normalization dropout ogni step short term memory impiegano celle
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#23,23,"RNN - LSTM
Rappresenta l'architettura LSTM gra
 ﬁ
camente.
24",rappresenta larchitettura gra camente
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#24,24,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?
25",conv vorresti impiegare conv allinterno
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#25,25,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?  
Una RNN opera sequenzialmente: per calcolare l'output al tempo t, deve prima 
calcolare gli output degli step precedenti. Questo rende impossibile 
parallelizzare l'elaborazione.  
La 1d conv non mantiene uno stato tra elaborazioni successive perciò e 
facilmente parallelizzabile. Non essendo ricorrente, è meno affetta da gradienti 
instabili.  
Più 1d conv possono processare l'input riducendo la risoluzione temporale 
(downsampling) permettendo di analizzare time series molto lunghe.  
Infatti la WaveNet analizza time series impiegando solo 1d conv.
26",conv vorresti impiegare conv allinterno opera calcolare loutput tempo deve prima calcolare output step precedenti rende impossibile parallelizzare lelaborazione conv mantiene stato elaborazioni successive perci facilmente ricorrente meno affetta gradienti instabili conv possono processare linput riducendo risoluzione temporale downsampling permettendo analizzare time series molto lunghe infatti wave net analizza time series impiegando solo conv
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#26,26,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video? 
27",scenario architettura impiegheresti classi care video
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#27,27,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video?  
Prendiamo un frame per secondo e lo diamo in input a una rete 
convoluzionale. L'output della CNN è passato in input a una sequence-to-
vector RNN, il cui output è passato a una layer softmax, ottenendo una 
distribuzione di probabilità sulle classi.  
La funzione di costo può essere una cross entropy.  
Per usare l'audio si possono impiegare layer 1d conv, per ridurre la risoluzione 
da migliaia di audio frames per secondo a 1 solo per secondo, così da 
sincronizzarsi rispetto ai frame, e concatenare l'output con l'input alla 
sequence-to-vector.
28",scenario architettura impiegheresti classi care video prendiamo frame secondo diamo input rete convoluzionale loutput passato input sequence vector output passato layer softmax ottenendo distribuzione probabilit classi funzione costo pu essere cross entropy usare laudio possono impiegare layer conv ridurre risoluzione migliaia audio frames secondo solo secondo cos sincronizzarsi rispetto frame concatenare loutput linput sequence vector
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#28,28,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow.
29
",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#29,29,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow. 
DOWNLOAD_ROOT = 
 ""http://download.tensorflow.org/data/""
FILENAME = 
 ""quickdraw_tutorial_dataset_v1.tar.gz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/quickdraw""
 ,
                                extract=
 True
)
quickdraw_dir = Path(filepath).parent
train_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""training.tfrecord-*""
 )])
eval_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""eval.tfrecord-*""
 )])
with 
open
(quickdraw_dir / 
 ""eval.tfrecord.classes""
 ) 
as
 test_classes_file:
    test_classes = test_classes_file.readlines()
    
with 
open
(quickdraw_dir / 
 ""training.tfrecord.classes""
 ) 
as
 train_classes_file:
    train_classes = train_classes_file.readlines()
assert
 train_classes == test_classes
class_names = [name.strip().lower() 
 for
 name 
in
 train_classes]
sorted
(class_names)
30",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor filepath cachesubdir extract true quickdrawdir trainfiles sorted strpath path evalfiles sorted strpath path evaltfrecord open quickdrawdir testclasses open quickdrawdir trainclasses assert trainclasses testclasses classnames name trainclasses sorted classnames
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#3,3,"1d convolution per le sequenze: esempio
Il modello include una 
 1d conv 
 che opera una sorta di 
 downsampling
  delle 
sequenze in input di un fattore 2 impiegano uno stride 2. Il kernel è più grande 
dello stride perciò tutta l'informazione verrà considerata.  
Riducendo la lunghezza in input sarà più facile per la GRU riconoscere pattern 
più lunghi.  
model = keras.models.Sequential([
    keras.layers.Conv1D(filters=
 20
, kernel_size=
 4
, strides=
 2
, 
padding=
 ""valid""
,
                        input_shape=[
 None
, 
1
]),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, 
metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train[:, 
 3
::
2
], epochs=
 20
,
                    validation_data=(X_valid, Y_valid[:, 
 3
::
2
]))
•
Nota: Avendo kernel di dimensione 4, è opportuno ignorare i primi 3 step nei valori target, e 
fare dowsampling dei target di un fattore 2.
4",convolution sequenze esempio modello include conv opera sorta downsampling sequenze input fattore impiegano stride kernel grande stride perci tutta linformazione verr considerata riducendo lunghezza input facile riconoscere pattern lunghi model dfilters kernelsize strides padding valid inputshape none keraslayersg true keraslayersg true model compile loss mse optimizer adam history ytrain epochs yvalid nota kernel dimensione opportuno ignorare primi step valori target fare dowsampling target fattore
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#30,30,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
def 
parse
(
data_batch
 ):
    feature_descriptions = {
        
 ""ink""
: tf.io.VarLenFeature(dtype=tf.float32),
        
 ""shape""
: tf.io.FixedLenFeature([
 2
], dtype=tf.int64),
        
 ""class_index""
 : tf.io.FixedLenFeature([
 1
], dtype=tf.int64)
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[
 ""ink""
])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), 
 -1
, 
3
])
    lengths = examples[
 ""shape""
][:, 
0
]
    labels = examples[
 ""class_index""
 ][:, 
0
]
    
return
 sketches, lengths, label
 s
def 
quickdraw_dataset
 (
filepaths
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                      
 n_parse_threads
 =
5
, 
n_read_threads
 =
5
, 
cache
=
False
)
:
    dataset = tf.data.TFRecordDataset(filepaths
 ,
                                      num_parallel_reads=n_read_threads
 )
    
if
 cache
:
        dataset = dataset.cache(
 )
    
if
 shuffle_buffer_size
 :
        dataset = dataset.shuffle(shuffle_buffer_size
 )
    dataset = dataset.batch(batch_size
 )
    dataset = dataset.
 map
(parse, num_parallel_calls=n_parse_threads
 )
    
return
 dataset.prefetch(
 1
)
31",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor def parse databatch ink tfiovar len shape tfiofixed len feature classindex tfiofixed len feature dtypetfint examples flatsketches ink sketches lengths examples shape labels examples classindex return sketches lengths label def filepaths batchsize none nparsethreads nreadthreads cache false dataset tfdatat frecord cache dataset datasetcache dataset dataset dataset dataset map parse return
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#31,31,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
train_set = quickdraw_dataset(train_files, shuffle_buffer_size=
 10000
)
valid_set = quickdraw_dataset(eval_files[:
 5
]
)
test_set = quickdraw_dataset(eval_files[
 5
:]
)
def 
draw_sketch
 (
sketch
, 
label
=
None
)
:
    origin = np.array([[
 0
., 
0
., 
0
.]]
)
    sketch = np.r_[origin, sketch
 ]
    stroke_end_indices = np.argwhere(sketch[:, 
 -1
]==
1
.)[:, 
0
]
    coordinates = np.cumsum(sketch[:, :
 2
], axis=
 0
)
    strokes = np.split(coordinates, stroke_end_indices + 
 1
)
    title = class_names[label.numpy()] 
 if
 label 
is 
not 
None 
else 
""Try to guess""
    plt.title(title
 )
    plt.plot(coordinates[:, 
 0
], -coordinates[:, 
 1
], 
""y:""
)
    
for
 stroke 
 in
 strokes
 :
        plt.plot(stroke[:, 
 0
], -stroke[:, 
 1
], 
"".-""
)
    plt.axis(
 ""off""
)
def 
draw_sketches
 (
sketches
 , 
lengths
, 
labels
)
:
    n_sketches = 
 len
(sketches
 )
    n_cols = 
 4
    n_rows = (n_sketches - 
 1
) // n_cols + 
 1
    plt.figure(figsize=(n_cols * 
 3
, n_rows * 
 3.5
)
)
    
for
 index, sketch, length, label 
 in 
zip
(
range
(n_sketches), sketches, lengths, labels)
 :
        plt.subplot(n_rows, n_cols, index + 
 1
)
        draw_sketch(sketch[:length], label
 )
    plt.show()
32",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor trainset validset testset def drawsketch sketch label none origin nparray sketch nprorigin sketch coordinates axis strokes title label none else try guess plttitletitle coordinates stroke strokes stroke pltaxis off def drawsketches sketches lengths labels nsketches len sketches ncols nrows nsketches ncols nrows index sketch length label zip range nsketches sketches lengths labels ncols index label pltshow
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#32,32,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
for
 sketches, lengths, labels 
 in
 train_set.take(
 1
)
:
    draw_sketches(sketches, lengths, labels
 )
lengths = np.concatenate([lengths 
 for
 _, lengths, _ 
 in 
train_set.take(
 1000
)]
)
plt.hist(lengths, bins=
 150
, density=
 True
)
plt.axis([
 0
, 
200
, 
0
, 
0.03
]
)
plt.xlabel(
 ""length""
 )
plt.ylabel(
 ""density""
 )
plt.show(
 )
def 
crop_long_sketches
 (
dataset
, 
max_length
 =
100
)
:
    
return
 dataset.
 map
(
lambda
 inks, lengths, labels: 
(inks[:, :max_length], labels)
 )
cropped_train_set = crop_long_sketches(train_set
 )
cropped_valid_set = crop_long_sketches(valid_set
 )
cropped_test_set = crop_long_sketches(test_set
 )
33",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor sketches lengths labels trainsettake lengths labels lengths lengths trainsettake bins density true pltaxis pltxlabel length pltylabel density pltshow def dataset maxlength return dataset map lambda inks lengths labels inks maxlength labels
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#33,33,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
model = keras.models.Sequential(
 [
    keras.layers.Conv1D(
 32
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 64
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 128
, kernel_size=
 3
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.LSTM(
 128
, return_sequences=
 True
)
,
    keras.layers.LSTM(
 128
)
,
    keras.layers.Dense(
 len
(class_names), activation=
 ""softmax""
 )
]
)
optimizer = keras.optimizers.SGD(lr=
 1e-2
, clipnorm=
 1
.
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 ,
              optimizer=optimizer
 ,
              metrics=[
 ""accuracy""
 , 
""sparse_top_k_categorical_accuracy""
 ]
)
history = model.fit(cropped_train_set, epochs=
 2
,
                    validation_data=cropped_valid_set
 )
y_test = np.concatenate([labels 
 for
 _, _, labels 
 in
 test_set]
 )
y_probas = model.predict(test_set)
34",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor model kernelsize strides activation relu normalization kernelsize strides activation relu normalization kernelsize strides activation relu normalization keraslayersl true keraslayersl len classnames activation softmax optimizer gdlr clipnorm model compile loss metrics accuracy history epochs ytest labels testset yprobas
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#34,34,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas)
 )
n_new = 
 10
Y_probas = model.predict(sketches
 )
top_k = tf.nn.top_k(Y_probas, k=
 5
)
for
 index 
in 
range
(n_new)
:
    plt.figure(figsize=(
 3
, 
3.5
)
)
    draw_sketch(sketches[index]
 )
    plt.show(
 )
    
print
(
""Top-5 predictions:""
 .
format
(index + 
 1
)
)
    
for
 k 
in 
range
(
5
)
:
        class_name = class_names[top_k.indices[index, k]
 ]
        proba = 
 100
 * top_k.values[index, k
 ]
        
 print
(
""  {}. {} {:.3f}%""
 .
format
(k + 
1
, class_name, proba)
 )
    
print
(
""Answer: {}""
 .
format
(class_names[labels[index].numpy()])
 )
model.save(
 ""my_sketchrnn""
 )
35",sketch dataset addestra modello classi cazione sketch dataset disponibile dentro tensor yprobas nnew yprobas topk index range nnew pltshow print top predictions format index range classname proba print format classname proba print answer format modelsave mysketchrnn
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#35,35,"RNN - Generazione di musica
Scarica il dataset Bach chorales e scompattalo. Consiste in 382 corali composti 
da Johann Sebastian Bach. Ogni corale è lungo da 100 a 640 time steps, e ogni 
step contiene 4 interi, dove ogni interno corrisponde alla nota su un piano. Lo 0 
indica che che non si suona alcuna nota.  
Addestra un modello ricorrente o convoluzionale, o entrambi, che può predire 
il successivo step (4 note), data una sequenza del corale. Usa quello modello 
per generare musica in stile Bach, ad esempio dando in input l'inizio di un 
corale e ottenendo la predizione che userai come successivo input.  
In
ﬁ
ne dai un'occhiata al Google Coconet model.  
36",generazione musica scarica dataset bach chorales scompattalo consiste corali composti johann sebastian bach ogni corale lungo time steps ogni step contiene interi ogni interno corrisponde nota piano indica suona alcuna nota addestra modello ricorrente convoluzionale entrambi pu predire successivo step note data sequenza corale usa modello generare musica stile bach esempio dando input linizio corale ottenendo predizione userai successivo input unocchiata google coconet model
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#36,36,"RNN - Generazione di musica
DOWNLOAD_ROOT = 
 ""https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/""
FILENAME = 
 ""jsb_chorales.tgz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/jsb_chorales""
 ,
                                extract=
 True
)
jsb_chorales_dir = Path(filepath).parent
train_files = 
 sorted
(jsb_chorales_dir.glob(
 ""train/chorale_*.csv""
 ))
valid_files = 
 sorted
(jsb_chorales_dir.glob(
 ""valid/chorale_*.csv""
 ))
test_files = 
 sorted
(jsb_chorales_dir.glob(
 ""test/chorale_*.csv""
 ))
import
 pandas 
 as
 pd
def 
load_chorales
 (
filepaths
 ):
    
return
 [pd.read_csv(filepath).values.tolist() 
 for
 filepath 
 in
 filepaths]
train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)
train_chorales[
 0
]
notes = set()
for
 chorales 
 in
 (train_chorales, valid_chorales, test_chorales):
    
for
 chorale 
 in
 chorales:
        
 for
 chord 
in
 chorale:
            notes |= set(chord)
n_notes = 
 len
(notes)
min_note = 
 min
(notes - {
 0
})
max_note = 
 max
(notes)
37",generazione musica filepath cachesubdir extract true trainfiles sorted validfiles sorted testfiles sorted import pandas def loadchorales filepaths return filepath filepaths trainchorales validchorales testchorales trainchorales notes set chorales validchorales testchorales chorale chorales chord chorale notes setchord nnotes len notes minnote min notes maxnote max notes
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#37,37,"RNN - Generazione di musica
assert
 min_note == 
 36
assert
 max_note == 
 81
from
 IPython.display 
 import
 Audio
def 
notes_to_frequencies
 (
notes
):
    
# Frequency doubles when you go up one octave; there are 12 semi-tones
    
# per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    
return 
2
 ** ((np.array(notes) - 
 69
) / 
12
) * 
440
def 
frequencies_to_samples
 (
frequencies
 , 
tempo
, 
sample_rate
 ):
    note_duration = 
 60
 / tempo 
 # the tempo is measured in beats per minutes
    
# To reduce click sound at every beat, we round the frequencies to try to
    
# get the samples close to zero at the end of each note.
    frequencies = np.
 round
(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(
 0
, note_duration, n_samples)
    sine_waves = np.sin(
 2
 * np.pi * frequencies.reshape(
 -1
, 
1
) * time)
    
# Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 
 9
.).reshape(
 -1
, 
1
)
    
return
 sine_waves.reshape(
 -1
)
def 
chords_to_samples
 (
chords
, 
tempo
, 
sample_rate
 ):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[
 -1
:]] 
# make last note a bit longer
    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)
                     
 for
 melody 
 in
 freqs.T], axis=
 0
)
    n_fade_out_samples = sample_rate * 
 60
 // tempo 
 # fade out last note
    fade_out = np.linspace(
 1
., 
0
., n_fade_out_samples)**
 2
    merged[-n_fade_out_samples:] *= fade_out
    
return
 merged
38",generazione musica assert minnote assert maxnote pythondisplay import audio def notes frequency doubles one octave semi tones octave note octave note number return def frequencies tempo samplerate noteduration tempo tempo measured beats minutes reduce click sound every beat round frequencies try get samples close zero end note frequencies round noteduration frequencies noteduration nsamples samplerate time nplinspace noteduration nsamples sinewaves npsin nppi time removing notes frequencies includes note silence sinewaves frequencies reshape return def chords tempo samplerate freqs freqs nprfreqs freqs make last note bit longer merged tempo samplerate melody freqst axis samplerate tempo fade last note fadeout nplinspace merged fadeout return merged
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#38,38,"RNN - Generazione di musica
def 
play_chords
 (
chords
, 
tempo
=
160
, 
amplitude
 =
0.1
, 
sample_rate
 =
44100
, 
filepath
 =
None
):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    
if
 filepath:
        
 from
 scipy.io 
 import
 wavfile
        samples = (
 2
**
15
 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        
 return
 display(Audio(filepath))
    
else
:
        
 return
 display(Audio(samples, rate=sample_rate))
for
 index 
in 
range
(
3
):
    play_chords(train_chorales[index])
def 
create_target
 (
batch
):
    X = batch[:, :
 -1
]
    Y = batch[:, 
 1
:] 
# predict next note in each arpegio, at each step
    
return
 X, Y
def 
preprocess
 (
window
):
    window = tf.where(window == 
 0
, window, window - min_note + 
 1
) 
# shift values
    
return
 tf.reshape(window, [
 -1
]) 
# convert to arpegio
def 
bach_dataset
 (
chorales
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                 
 window_size
 =
32
, 
window_shift
 =
16
, 
cache
=
True
):
    
def 
batch_window
 (
window
):
        
 return
 window.batch(window_size + 
 1
)
    
def 
to_windows
 (
chorale
):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 
 1
, window_shift, drop_remainder=
 True
)
        
 return
 dataset.flat_map(batch_window)
    chorales = tf.ragged.constant(chorales, ragged_rank=
 1
)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).
 map
(preprocess)
    
if
 cache:
        dataset = dataset.cache()
    
if
 shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.
 map
(create_target)
    
return
 dataset.prefetch(
 1
)
39",generazione musica def playchords chords tempo amplitude samplerate filepath none samples amplitude tempo samplerate filepath scipyio import wavfile samples samplerate samples return else return index range def createtarget batch batch batch predict next note arpegio step return def preprocess window window tfwherewindow window window minnote shift values return convert arpegio def bachdataset chorales batchsize none windowsize windowshift cache true def batchwindow window return def towindows chorale dataset dataset windowshift dropremainder true return chorales raggedrank dataset dataset map preprocess cache dataset datasetcache dataset dataset dataset dataset map createtarget return
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#39,39,"RNN - Generazione di musica
train_set = bach_dataset(train_chorales, shuffle_buffer_size=
 1000
)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)
n_embedding_dims = 
 5
model = keras.models.Sequential([
    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,
                           input_shape=[
 None
]),
    keras.layers.Conv1D(
 32
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 48
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 2
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 64
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 4
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 96
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 8
),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(
 256
, return_sequences=
 True
),
    keras.layers.Dense(n_notes, activation=
 ""softmax""
 )
])
model.summary()
optimizer = keras.optimizers.Nadam(lr=
 1e-3
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 , optimizer=optimizer,
              metrics=[
 ""accuracy""
 ])
model.fit(train_set, epochs=
 20
, validation_data=valid_set)
model.save(
 ""my_bach_model.h5""
 )
model.evaluate(test_set)
40",generazione musica trainset validset testset model inputshape none kernelsize padding causal activation relu kernelsize padding causal activation relu dilationrate kernelsize padding causal activation relu dilationrate kernelsize padding causal activation relu dilationrate keraslayersl true activation softmax modelsummary optimizer model compile loss metrics accuracy epochs modelsave
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#4,4,"Architettura WaveNet
Le rete convolutiva 
 WaveNet
  impiega più layer 1d conv, dove ad ogni layer si 
raddoppia la lunghezza della LRF, chiamato anche 
 dilatation rate.
  In questo 
modo ogni layer raddoppia i dati analizzati rispetto al layer precedente.  
•
I primi layer riconoscono pattern 
 short-term
 , gli ultimi i pattern estesi.  
•
Per dilatation >1, i layer ignoreranno alcuni campioni all'interno del LRF che 
però saranno considerati nei layer precedenti.  
Il training è più rapido rispetto alle RNN non essendoci collegamenti ricorrenti.  
L'output può essere accodato all'input successivo per fare predizione (es. 
generazione voce umana).
5
stack of conv layers",architettura wave net rete convolutiva wave net impiega layer conv ogni layer raddoppia lunghezza chiamato dilatation rate modo ogni layer raddoppia dati analizzati rispetto layer precedente primi layer riconoscono pattern short term ultimi pattern estesi dilatation layer ignoreranno alcuni campioni allinterno per considerati layer precedenti training rapido rispetto essendoci collegamenti ricorrenti loutput pu essere accodato allinput successivo fare predizione generazione voce umana stack conv layers
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#40,40,"RNN - Generazione di musica
def 
generate_chorale
 (
model
, 
seed_chords
 , 
length
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note = model.predict_classes(arpegio)[:
 1
, 
-1
:]
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
seed_chords = test_chorales[
 2
][:
8
]
play_chords(seed_chords, amplitude=
 0.2
)
new_chorale = generate_chorale(model, seed_chords, 
 56
)
play_chords(new_chorale)
def 
generate_chorale_v2
 (
model
, 
seed_chords
 , 
length
, 
temperature
 =
1
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note_probas = model.predict(arpegio)[
 0
, 
-1
:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=
 1
)
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
41",generazione musica def model seedchords length arpegio arpegio chord range length note range nextnote arpegio nextnote axis arpegio arpegio arpegio minnote return shape seedchords testchorales amplitude newchorale seedchords def model seedchords length temperature arpegio arpegio chord range length note range rescaledlogits temperature nextnote numsamples arpegio nextnote axis arpegio arpegio arpegio minnote return shape
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#41,41,"RNN - Generazione di musica
new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 0.8
)
play_chords(new_chorale_v2_cold, filepath=
 ""bach_cold.wav""
 )
new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.0
)
play_chords(new_chorale_v2_medium, filepath=
 ""bach_medium.wav""
 )
new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.5
)
play_chords(new_chorale_v2_hot, filepath=
 ""bach_hot.wav""
 )
play_chords(test_chorales[
 2
][:
64
], filepath=
 ""bach_test_4.wav""
 )
42",generazione musica seedchords temperature filepath bachcoldwav seedchords temperature filepath seedchords temperature filepath bachhotwav filepath
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#5,5,"6
1
2
3
4
https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio
Nella 
 WaveNet
  l'output layer ha la 
stessa dimensionalità temporale 
dell'input.  
Il singolo valore in output è prodotto 
da una 
 softmax
 , perciò con 
distribuzione sulle categorie 
disponibili.  
Le 
dilated convolution
  sono simili ai 
layer convolutivi con pooling e 
stride, ma in questo caso l'output ha 
la stessa dimensione dell'input.  
",generative model raw audio wave net loutput layer stessa dimensionalit temporale dellinput singolo valore output prodotto softmax perci distribuzione categorie disponibili dilated convolution simili layer convolutivi pooling stride caso loutput stessa dimensione dellinput
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#6,6,"WaveNet: esempio
Impostando il 
 padding  
causal
  si garantisce che l'input non conterrà dati oltre a 
quello attuale.  
Il parametro 
 dilatation_rate
  de
ﬁ
nisce l'architettura WaveNet.  
L'ultimo layer è convolutivo con 10 
 ﬁ
ltri di dimensione 1 senza funzione di 
attivazione. Ogni conv layer produce una sequenza della stessa lunghezza 
dell'input, cosicché possiamo usare i target senza ridimensionarli.  
Nell'esempio manca il layer softmax impiegato nell'esempio precedente.  
model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[
 None
, 
1
]))
for
 rate 
in
 (
1
, 
2
, 
4
, 
8
) * 
2
:
    model.add(keras.layers.Conv1D(filters=
 20
, kernel_size=
 2
, padding=
 ""causal""
 ,
                                  activation=
 ""relu""
, dilation_rate=rate))
model.add(keras.layers.Conv1D(filters=
 10
, kernel_size=
 1
))
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=
 20
,
                    validation_data=(X_valid, Y_valid))
7",wave net esempio impostando padding causal garantisce linput conterr dati oltre attuale parametro dilatationrate nisce larchitettura wave net lultimo layer convolutivo ltri dimensione senza funzione attivazione ogni conv layer produce sequenza stessa lunghezza dellinput cosicch possiamo usare target senza nellesempio manca layer softmax impiegato nellesempio precedente model none rate dfilters kernelsize padding causal activation relu dfilters kernelsize model compile loss mse optimizer adam history ytrain epochs yvalid
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#7,7,"Deep RNN
Finora abbiamo visto RNN con un singolo hidden layer ricorrente, uno strato 
di input e uno di output. Le memory cell permettono di creare correlazioni 
che in
 ﬂ
uenza step anche distanti tra loro (direzione temporale).  
Nelle Deep RNN si vogliono identi
 ﬁ
care correlazioni anche tra input e output 
nello stesso step (direzione input-output). Per questo si considerano più layer 
stacked 
 sequence-to-sequence.  
•
Il primo layer produce una sequenza in output di lunghezza T, che sarà 
l'input del successivo layer.  
•
Ogni cella perciò dipenderà dai valori  
del layer negli step precedente, e dai  
valori generati dai layer precedenti nello  
stesso step.  
Architetture comuni di RNN hanno  
lunghezza (
 numero di step
 ) nel range  
64-2056 e profondità in 1-8.
8
",deep finora visto singolo hidden layer ricorrente strato input output memory cell permettono creare correlazioni uenza step distanti direzione temporale deep vogliono identi care correlazioni input output stesso step direzione input output considerano layer stacked sequence sequence primo layer produce sequenza output lunghezza linput successivo layer ogni cella perci dipender valori layer step precedente valori generati layer precedenti stesso step architetture comuni lunghezza numero step range profondit
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#8,8,"Deep RNN - Keras (1)
12-deep_rnn.ipynb
9",deep keras deeprnnipynb
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#9,9,"Deep RNN - Keras (2)
In alternativa alla classe GRU possiamo operare uno stacking impiegando 
Sequential:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.SimpleRNN(
 1
)
])”
Nota
 : ricordati di impostare return_sequences=
 True
 per ogni layer (tranne 
l'ultimo se ci interessa in output solo l'ultimo valore), altrimenti l'output del 
layer sarà 2D (solo l'ultimo valore) e si crea un mismatch con l'input atteso in 
3D dal successivo layer.
10",deep keras alternativa classe possiamo operare stacking impiegando sequential model true inputshape none true nota ricordati impostare true ogni layer tranne lultimo interessa output solo lultimo valore altrimenti loutput layer solo lultimo valore crea mismatch linput atteso successivo layer
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Attention mechanisms e Transformers
1",deep learning universit roma tre dipartimento ingegneria anno accademico attention mechanisms transformers
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#1,1,"Sommario
Beam search  
Attention mechanism  
Multi-head attention  
Self-attention  
Transformers  
",sommario beam search attention mechanism multi head attention self attention transformers
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#10,10,"Beam search (2)
La complessità è pari a 
 O
(
k·
|
Y
|·
T'
)
, dove 
 T'
 è il numero massimo di token 
della sequenza in output, e 
 Y
 è il vocabolario.  
Al contrario dell'approccio greedy, la beam search permette di scegliere alcuni 
token meno probabili, sebbene la frase nel suo complesso generi accuracy 
migliori.  
Una ricerca esaustiva di tutte le possibili combinazioni richiederebbe 
complessità 
 O
(|
Y
|
T'
).
11",beam search complessit pari numero massimo token sequenza output vocabolario contrario dellapproccio greedy beam search permette scegliere alcuni token meno probabili sebbene frase complesso generi accuracy migliori ricerca esaustiva tutte possibili combinazioni richiederebbe complessit
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#11,11,"Attention cues
Il meccanismo si ispira a studi di neuroscienze cognitive, dove si tenta di dare 
attenzione solo ad una parte degli stimoli generati dal sistema di visione.  
•
le 
nonvolitional cues
  (
keys
) sono legate alla visibilità dell'oggetto 
nell'ambiente (es. tazza di caffè rossa su un tavolino grigio),  
•
le 
volitional cue
  (o 
query
 ) dipendono dal task che stiamo seguendo (es. 
leggere un libro su un tavolo).  
Se abbiamo dei 
 sensory inputs
  da analizzare, la 
 query
  interagisce con le 
 keys 
per selezionare gli input più corretti.  
L'
attention pooling
  aggrega gli input per generare l'output.
12
",attention cues meccanismo ispira studi neuroscienze cognitive tenta dare attenzione solo parte stimoli generati sistema visione nonvolitional cues keys legate visibilit delloggetto nellambiente tazza caff rossa tavolino grigio volitional cue query dipendono task seguendo leggere libro tavolo sensory inputs analizzare query interagisce keys selezionare input corretti attention pooling aggrega input generare loutput
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#12,12,"Attention pooling e Keras
Ci sono vari modi di implementare l'attention pooling. Qui diamo un esempio 
basato sul modello di regressione Nadaraya-Watson kernel.  
Generiamo un dataset arti
 ﬁ
ciale con questo modello:  
con epsilon generato con distribuzione normale media 0 e varianza 0.5, e 50 
istanze di training e test.  
class 
NonlinearData
 (
d2l
.
DataModule
 ):
    
def 
__init__
 (
self
, 
n
, 
batch_size
 ):
        
 self
.save_hyperparameters()
        f = 
 lambda
 x: 
2
 * tf.sin(x) + x**
 0.8
        
 self
.x_train = tf.sort(tf.random.uniform((n,
 1
)) * 
5
, 
0
)
        
 self
.y_train = f(
 self
.x_train) + tf.random.normal((n,
 1
))
        
 self
.x_val = tf.
 range
(
0
, 
5
, 
5.0
/n)
        
 self
.y_val = f(
 self
.x_val)
    
def 
get_dataloader
 (
self
, 
train
):
        arrays = (
 self
.x_train, 
 self
.y_train) 
 if
 train 
else
 (
self
.x_val, 
 self
.y_val)
        
 return 
self
.get_tensorloader(arrays, train)
n = 
50
data = NonlinearData(n, batch_size=
 10
)
13
",attention pooling keras vari modi implementare lattention pooling qui diamo esempio basato modello regressione nadaraya watson kernel generiamo dataset arti ciale modello epsilon generato distribuzione normale media varianza istanze training test class nonlinear data data module def init self batchsize self lambda tfsinx self xtrain self ytrain self xtrain self xval range self yval self xval def getdataloader self train arrays self xtrain self ytrain train else self xval self yval return self train data nonlinear datan batchsize
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#13,13,"Attention pooling e Keras (2)
Gra
ﬁ
chiamo gli esempi di training (cerchi), il ground truth senza rumore 
(curva blu) la funzione generata per la prediction (tratteggiata rossa).  
Proviamo con l'estimator più facile: 
 average pooling
  sui dati di input:  
y_hat = tf.repeat(tf.reduce_mean(data.y_train), n)
plot_kernel_reg(y_hat)
def 
plot_kernel_reg
 (
y_hat
):
    d2l.plot(data.x_val, [data.y_val, y_hat.numpy()], 
 'x'
, 
'y'
, legend=[
 'Truth'
, 
'Pred'
],
             xlim=[
 0
, 
5
], ylim=[
 -1
, 
5
])
    d2l.plt.plot(data.x_train, data.y_train, 
 'o'
, alpha=
 0.5
);
14",attention pooling keras gra chiamo esempi training cerchi ground truth senza rumore curva blu funzione generata prediction tratteggiata rossa proviamo lestimator facile average pooling dati input yhat def plotkernelreg yhat datayval yhatnumpy legend truth pred xlim ylim dataytrain alpha
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#14,14,"Attention pooling e Keras (3)
Nel seguente nonparametric attention pooling chiamato 
 Nadaraya-Watson 
kernel regression 
 pesiamo gli output in base alla posizione degli input.  
dove K è il kernel. Generalizzandolo (non serve ora studiare i dettagli del 
regressore) possiamo de
 ﬁ
nire un qualsiasi 
 attention pooling
  nel seguente 
modo:  
dove 
 x
 è la 
 query
 , e (
x
i
,y
i
) e la coppia 
 chiave-valore
 . Perciò ogni valore 
 y
i
 è 
pesato e si può pensare come una distribuzione di probabilità sull'insieme 
chiavi-valore.  
15
",attention pooling keras seguente nonparametric attention pooling chiamato nadaraya watson kernel regression pesiamo output base posizione input kernel non serve ora studiare dettagli regressore possiamo nire qualsiasi attention pooling seguente modo query coppia chiave valore perci ogni valore pesato pu pensare distribuzione probabilit sullinsieme chiavi valore
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#15,15,"Attention pooling e Keras (4)
Gra
ﬁ
cando l'output del nuovo modello otteniamo:  
def 
diff
(
queries
, 
keys
):
    
return
 tf.reshape(queries, (
 -1
, 
1
)) - tf.reshape(keys, (
 1
, 
-1
))
def 
attention_pool
 (
query_key_diffs
 , 
values
):
    attention_weights = tf.nn.softmax(- query_key_diffs**
 2
/
2
, axis=
1
)
    
return
 tf.matmul(attention_weights, values), attention_weights
y_hat, attention_weights = attention_pool(
    diff(data.x_val, data.x_train), data.y_train)
plot_kernel_reg(y_hat)
16
",attention pooling keras gra cando loutput nuovo modello otteniamo def diff queries keys return def attentionpool querykeydiffs values tfnnsoftmax axis return values yhat attentionpool dataxtrain dataytrain
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#16,16,"Attention pooling e Keras (5)
Analizzando i pesi generati dell'attention pooling, con le 
 query
  come 
validation inputs
  e 
keys
 come 
 training inputs
 , notiamo come all'avvicinarsi dei 
valori tra 
 query
  e 
chiave
 , i pesi sono più signi
 ﬁ
cativi:  
d2l.show_heatmaps([[attention_weights]],
                  xlabel=
 'Sorted training inputs'
 ,
                  ylabel=
 'Sorted validation inputs'
 )
17
",attention pooling keras analizzando pesi generati dellattention pooling query validation inputs keys training inputs notiamo allavvicinarsi valori query chiave pesi signi cativi xlabel sorted training inputs ylabel sorted validation inputs
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#17,17,"Attention Scoring functions
L'output dell'
 attention mechanism
  possiamo valutarlo con una 
 softmax
  e 
interpretarlo come distribuzione di probabilità sui valori che sono in paio con 
le chiavi.  
18
",attention scoring functions loutput dell attention mechanism possiamo valutarlo softmax interpretarlo distribuzione probabilit valori paio chiavi
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#18,18,"Multi-head attention
L'attention mechanism potrebbe richiedere di analizzare dipendenze su vari 
intervalli (short e long-range) all'interno delle sequenze. Invece di un singolo 
pooling, possiamo generare 
 h
 proiezioni lineari indipendenti. Gli 
 h
 output 
sono concatenati e passati ad una combinazione lineare 
 ﬁ
nale per produrre 
l'output. Ognuna delle 
 h 
attention pooling
  è chiamato 
 head
 .
19
",multi head attention lattention mechanism potrebbe richiedere analizzare dipendenze vari intervalli short long range allinterno sequenze invece singolo pooling possiamo generare proiezioni lineari indipendenti output concatenati passati combinazione lineare nale produrre loutput ognuna attention pooling chiamato head
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#19,19,"Self-attention e positional encoding
Supponiamo che in input all'attention mechanism diamo una sequenza di 
tokens. I tokens rappresentano perciò sia le query, le chiavi e i valori. Ogni 
query è relativa e tutte le coppie chiave-valore e genera un output. Per tale 
motivo si parla di 
 self-attention
 . 
Si può dimostrare facilmente che le CNN e i self-attention possono essere 
implementati con computazioni parallele, sebbene sequenze molto lunghe 
penalizzano molto i self-attention.  
Possiamo aggiungere informazioni aggiuntive, come quelle associate alla 
posizione, alla rappresentazione in input del self-attention, poiché durante i 
calcoli queste informazioni vengono ignorate, a differenza delle RNN.
20",self attention positional encoding supponiamo input allattention mechanism diamo sequenza tokens tokens rappresentano perci query chiavi valori ogni query relativa tutte coppie chiave valore genera output tale motivo parla self attention pu dimostrare facilmente self attention possono essere implementati computazioni parallele sebbene sequenze molto lunghe penalizzano molto self attention possiamo aggiungere informazioni aggiuntive associate posizione input self attention poich durante calcoli informazioni vengono ignorate differenza
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#2,2,"Introduzione
In una architettura 
 encoder-decoder,
  durante la traduzione di un testo notiamo 
come alcune parole generate dal decoder dipendano da poche parole in input 
al encoder. Se le frasi sono molte lunghe, una RNN fa fatica a identi
 ﬁ
care tali 
dipendenze.  
Gli 
attention mechanism 
 introdotti nel 2014 da Bahdanau et al.
(1)
 risolvono in 
parte le limitazioni della memoria delle RNN, arrivando a processare frasi di 
30 parole circa.  
Gli attention mechanism sono alla base dell'architettura 
 Transformers
 , che è 
lo stato dell'arte nel campo dell'NLP in molti task, es. machine language 
translation, conversational chatbots, e per migliorare le performance dei 
search engines.  
L'obiettivo degli 
 attention mechanism 
 è assegnare un livello di importanza alle 
features e sfruttarlo per agevolare il raggiungimento di un certo task. 
3 (1) https://arxiv.org/abs/1409.0473",introduzione architettura encoder decoder durante traduzione testo notiamo alcune parole generate decoder dipendano poche parole input encoder frasi molte lunghe fatica identi care tali dipendenze attention mechanism introdotti bahdanau risolvono parte limitazioni memoria arrivando processare frasi parole circa attention mechanism base transformers stato dellarte campo delln molti task machine language translation conversational chatbots migliorare performance search engines lobiettivo attention mechanism assegnare livello importanza features sfruttarlo agevolare raggiungimento certo task
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#20,20,"Attention mechanism e Encoder-decoder (1)
Nell'architettura 
 encoder-decoder con 
 attention mechanism
 , oltre all'ultimo 
hidden state propagato dal encoder al decoder (non visibile nel disegno), 
inviamo al decoder tutti i valori generati in output dal encoder
 . 
•
Ad ogni step, il 
 decoder
  calcola una combinazione lineare dei valori ottenuti 
in output dal encoder così da determinare su quale parola porre l'attenzione 
al successivo step.  
•
Il peso 
  è riferito al 
 i
-esimo output, allo step 
 t
-esimo...
 α
(
t
,
i
)
21
Nell'esempio, se  è 
maggiore di  e , 
allora il decoder 
assegnerà maggiore 
attenzione al termine 
""milk"" nello step corrente .
La restante elaborazione 
coincide l'architettura 
originale.α(3,2)
α(3,0)α(3,1)Questa con ﬁgurazione 
speci ﬁca di attention 
mechanism è anche 
chiamata:  
Bahdanau attention .  
 
Dato che concatena gli 
output del encoder con gli 
hidden state, si chiama 
anche: concatenative 
attention , o additive 
attention .",attention mechanism encoder decoder encoder decoder attention mechanism oltre allultimo hidden state propagato encoder decoder non visibile disegno inviamo decoder valori generati output encoder ogni step decoder calcola combinazione lineare valori ottenuti output encoder cos determinare parola porre lattenzione successivo step peso riferito esimo output step esimo nellesempio maggiore allora decoder assegner maggiore attenzione termine milk step corrente restante elaborazione coincide larchitettura gurazione speci ca attention mechanism chiamata bahdanau attention dato concatena output encoder hidden state chiama anche concatenative attention additive attention
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#21,21,"Attention mechanism e Encoder-decoder (2)
I valori 
  sono generati da una rete neurale chiamata 
 alignment model  
(o 
attention layer)
  addestrata con il resto del encoder-decoder.  
•
Consiste in una 
 time-distributed Dense layer
  con un singolo nodo, che 
riceve tutti gli output dal encoder, concatenati con l'hidden state del decoder 
estratti dallo step precedente.  
•
Il layer produce una serie di valori e
 (3,0)
, e
(3,1)
, etc; che indicano 
 quanto ogni 
output è allineato con l'hidden state precedente
 . La 
softmax
  normalizza tali 
valori.
α
(
t
,
i
)
22
 rappresenta l'hidden 
state del decoder .
La rete densa richiede il 
calcolo di n2 parametri, 
supponendo n la 
lunghezza delle frasi in 
input e output. Ma se non 
abbiamo frasi lunghissime 
la complessità è ancora 
praticabile. h(2)",attention mechanism encoder decoder valori generati rete neurale chiamata alignment model attention layer addestrata resto encoder decoder consiste time distributed dense layer singolo nodo riceve output encoder concatenati lhidden state decoder estratti step precedente layer produce serie valori etc indicano ogni output allineato lhidden state precedente softmax normalizza tali valori rappresenta lhidden state decoder rete densa richiede calcolo parametri supponendo lunghezza frasi input output frasi lunghissime complessit ancora praticabile
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#22,22,"Image captioning
In questo task occorre generare un testo signi
 ﬁ
cativo in linguaggio naturale 
che descrive una immagine. In altre parole dobbiamo dotare l'algoritmo di 
capacità di ""
 comprensione""
 . 
Usiamo un 
 encoder-decoder
 , dove il 
 decoder
  sfrutta l'
 attention mechanism
 . 
L'
encoder
  è una CNN, e le features sono estratte dal layer convolutivo. 
L'
attention mechanism
  avrà perciò informazione posizionale codi
 ﬁ
cata 
nell'input. Il 
 decoder
  usa lo stato precedente, il token generato in precedenza 
e un context vector per generare il nuovo token.
23 ...
",image captioning task occorre generare testo signi cativo linguaggio naturale descrive immagine altre parole dobbiamo dotare lalgoritmo capacit comprensione usiamo encoder decoder decoder sfrutta attention mechanism encoder features estratte layer convolutivo attention mechanism perci informazione posizionale codi cata nellinput decoder usa stato precedente token generato precedenza context vector generare nuovo token
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#23,23,"Image caption e Visual Attention
Il 
context vector
  è generato dall'
 attention mechanism 
 a partire dalle features 
della CNN nell'encoder. Esso rappresenta i pesi per ogni location spaziale 
dell'output dell'encoder (
 visual attention
 ).  
Ad ogni step il decoder usa l'attention model per identi
 ﬁ
care le giusta 
porzione dell'immagine da analizzare per poi per generare la frase.
24
",image caption visual attention context vector generato dall attention mechanism partire features nellencoder esso rappresenta pesi ogni location spaziale delloutput dellencoder visual attention ogni step decoder usa lattention model identi care giusta porzione dellimmagine analizzare poi generare frase
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#24,24,"Explainability
Nel ML con 
 explainability
  si intende la capacità del modello di descrivere il 
suo comportamento in termini comprensibili all'uomo.  
•
Interpretability
  è un concetto simile, ma legato alle relazioni causa-effetto 
del modello, e perciò sulla capacità di stimare un certo output in base a una 
certa con
 ﬁ
gurazione di input. Si può avere interpretability senza 
explainability.  
Utile quando si vuole comprendere un certo output, eventualmente errato.  
•
Es. l'output ""un lupo che si muove sulla neve"" prodotto quando c'è un cane 
come input può dipendere dal fatto che il modello si focalizza sulla presenza 
della neve per classi
 ﬁ
care l'animale.  
I 
modelli DL 
 sono molto complessi e spesso 
 dif
ﬁ
cilmente esplorabili
 . 
Un tentativo è creare modelli interpretabili (es. alberi di decisione) a partire 
dagli output di un modello non interpretabile
(3)
, e usarli per costruire le 
motivazioni di un certo output.
25 (3) https://arxiv.org/abs/1602.04938",explainability explainability intende capacit modello descrivere comportamento termini comprensibili alluomo concetto simile legato relazioni causa effetto modello perci capacit stimare certo output base certa gurazione input pu avere senza explainability utile quando vuole comprendere certo output eventualmente errato loutput lupo muove neve prodotto quando cane input pu dipendere fatto modello focalizza presenza neve classi care lanimale modelli molto complessi spesso dif cilmente esplorabili tentativo creare modelli interpretabili alberi decisione partire output modello interpretabile usarli costruire motivazioni certo output
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#25,25,"Architettura Transformer - motivazioni
Computazionalmente, i modelli di attention e le 
CNN sono più veloci rispetto all RNN. I Transformer 
sono unicamente basati su tali modelli.  
In ""Attention is all you need""
(4)
, un team di Google 
propose l'architettura 
 Transformer
 , dove il task della 
traduzione dei testi si affronta senza RNN, ma 
principalmente con 
 layer embedding
 , 
dense layers
  e 
di 
normalization
 .  
Inizialmente proposti nel task 
 seq2seq
  sul testo, 
sono stati poi usati in svariati altri domini, es. 
visione, speech, reinforcement learning.  
L'encoder
  mappa le sequenze in input in una 
rappresentazione continua latente che incapsula 
tutte le informazioni rilevanti della sequenza.  
I multi-head attention creano associazioni tra una 
parola e le altre con un sistema di pesi.
26
",architettura transformer motivazioni modelli attention veloci rispetto transformer unicamente basati tali modelli attention need team google propose larchitettura transformer task traduzione testi affronta senza principalmente layer embedding dense layers normalization inizialmente proposti task seqseq testo stati poi usati svariati altri domini visione speech reinforcement learning lencoder mappa sequenze input continua latente incapsula tutte informazioni rilevanti sequenza multi head attention creano associazioni parola altre sistema pesi
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#26,26,"Architettura Transformer - (1)
Ad alto livello possiamo notare uno stack di layer 
multipli che si ripetono (
 N
 volte). Ognuno di questi 
macro-layer ha sotto layer.  
Nell'encoder si ha un 
 multi-head self-attention
  e un 
positionwise feed-forward network
 .  
Nell'
 encoder self-attention
 , queries, keys a values 
sono ottenuti dall'output del layer precedente. In 
modo simile alla ResNet, abbiamo connessioni 
residue.  
Lo stack del decoder oltre layer simili all'encoder 
abbiamo un ulteriore layer 
 encoder-decoder 
attention
  nel mezzo, che prende in input l'output 
del layer precedente nel decoder, e keys e values 
ottenuti dall'encoder. 
27
",architettura transformer alto livello possiamo notare stack layer multipli ripetono volte ognuno macro layer sotto layer nellencoder multi head self attention positionwise feed forward network nell encoder self attention queries keys values ottenuti dalloutput layer precedente modo simile res net connessioni residue stack decoder oltre layer simili allencoder ulteriore layer encoder decoder attention mezzo prende input loutput layer precedente decoder keys values ottenuti dallencoder
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#27,27,"Architettura Transformer - (2)
Nel decoder self-attention, queries, keys e values 
sono ottenuti dal layer precedente.  
Ogni posizione nel decoder interessa tutte le 
posizioni viste 
 ﬁ
no alla posizione corrente. Infatti 
nel training i dati sono noti, ma in produzione 
possiamo generare token che dipendono solo dai 
token già generati.  
La 
positionwise feed-forward network
  è composta 
da 2 layer FC e prende in input (batch size, number 
of time steps/sequence length in tokens, number of 
hidden units/feature dimension) e produce in output 
(batch size, number of time steps, ffn_num_outputs).  
I transfomer mantengono la proprietà 
 auto-
regressive
 , cioè l'output dipende linearmente dai 
valori prodotti in precedenza e da un termine 
stocastico.
28
",architettura transformer decoder self attention queries keys values ottenuti layer precedente ogni posizione decoder interessa tutte posizioni viste posizione corrente infatti training dati noti produzione possiamo generare token dipendono solo token gi generati positionwise feed forward network composta layer prende input batch size number time stepssequence length tokens number hidden unitsfeature dimension produce output batch size number time steps transfomer mantengono propriet auto regressive cio loutput dipende linearmente valori prodotti precedenza termine stocastico
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#28,28,"Architettura Transformer e NLP: dettagli (1)
29 (4) https://arxiv.org/abs/1706.03762
L'input si pre-processa come prima, ottenendo 
una
 rappresentazione in uno spazio a 512 
dimensioni
  (cioè uno shape [batch size, max 
input sentence length, 512]) mediante 
 word 
embeddings
 . 
L'output del decoder ha sempre forma di 
distribuzione di probabilità ([batch size, max 
output sentence length, vocabulary length])  
Il 
decoder
  prende in input la frase target 
traslata di 1 posizione.  
Ad ognuno dei 
 N
 livelli, l'output del 
 encoder  
è inviato in input al 
 encoder-decoder attention  
nel corrispondete livello del 
 decoder
 .EncoderDecoder",architettura transformer dettagli linput pre processa prima ottenendo spazio dimensioni cio shape batch size max input sentence length mediante word embeddings loutput decoder sempre forma distribuzione probabilit batch size max output sentence length vocabulary length decoder prende input frase target traslata posizione ognuno livelli loutput encoder inviato input encoder decoder attention corrispondete livello decoder encoder decoder
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#29,29,"Architettura Transformer e NLP: dettagli (2)
In produzione ancora una volta l'output del decoder (una nuova parola) verrà 
accodata all'input del decoder allo step successivo.
30 (4) https://arxiv.org/abs/1706.03762
Sia encoder sia decoder, oltre agli layer 
embedding, hanno 
 5
N skip connections
 , 
ognuna seguita da una layer di 
normalizzazione
 . 
Le 
positionwise feed-forward
  network sono 
reti MLP
  tradizionali con 2 Dense layer 
ciascuna, il primo layer con attivazione 
ReLU, il secondo senza attivazione. Il 
 layer 
di output
  è una layer denso con softmax.  
Tutti i layer sono 
 time-distributed
 , cosicché 
ogni parola è trattata indipendentemente 
dalle altre.
×
EncoderDecoder",architettura transformer dettagli produzione ancora volta loutput decoder una nuova parola verr accodata allinput decoder step successivo encoder decoder oltre layer embedding skip connections ognuna seguita layer normalizzazione positionwise feed forward network reti tradizionali dense layer ciascuna primo layer attivazione secondo senza attivazione layer output layer denso softmax layer time distributed cosicch ogni parola trattata altre encoder decoder
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#3,3,"Introduzione
Nell'esempio sono evidenziate features ricavate dall'
 attention mechanism 
 che 
mettono in correlazione features anche molto distanti tra loro.
4
",introduzione nellesempio evidenziate features ricavate dall attention mechanism mettono correlazione features molto distanti loro
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#30,30,"Architettura Transformer e NLP: dettagli (3)
Ma se la generazione delle parole è indipendente una dall'altra, e non 
abbiamo RNN, come può funzionare?
31 (4) https://arxiv.org/abs/1706.03762
Il modulo 
 multi-head attention
  codi
 ﬁ
ca ogni 
relazione di una parola con tutte le altre nella 
stessa frase, in modo da evidenziale le 
relazioni più importanti (
 self-attention
 ). 
•
Es. In “They welcomed the Queen of the 
United Kingdom”, il termine queen sarà più 
legato cone 
 united
  e 
kingdom
  rispetto a 
 they 
e 
welcomed
 . 
Il modulo 
 masked multi-head attention
  si 
comporta in modo simile, ma si limita a 
considerare la parola precedente.  
Il 
multi-head attention
  del decoder analizza le 
parole nella frase in input e si focalizza sui 
termini più importanti per la traduzione (es. 
""Queen"").",architettura transformer dettagli generazione parole indipendente dallaltra pu funzionare modulo multi head attention codi ogni relazione parola tutte altre stessa frase modo evidenziale relazioni importanti self attention they welcomed queen united kingdom termine queen legato cone united kingdom rispetto welcomed modulo masked multi head attention comporta modo simile limita considerare parola precedente multi head attention decoder analizza parole frase input focalizza termini importanti traduzione queen
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#31,31,"Architettura Transformer e NLP: dettagli (5)
Ma se la generazione delle parole è indipendente una dall'altra, come può 
funzionare?
32 (4) https://arxiv.org/abs/1706.03762
I 
positional embeddings
 , che sono dati in 
input al 
 encoder
  e 
decoder
  insieme agli 
embedding tradizionali, 
 rappresentano la 
posizione di un termine rispetto agli altri in 
una certa frase
 .  
Sono aggiunti ai 
 word embedding
  poiché il 
multi-head attention laye
 r ignora posizione 
e ordine delle parole nella frase, come pure 
gli altri layer  essendo tutti 
 layer time-
distributed
 . 
 ",architettura transformer dettagli generazione parole indipendente dallaltra pu funzionare positional embeddings dati input encoder decoder insieme embedding tradizionali rappresentano posizione termine rispetto altri certa frase aggiunti word embedding poich multi head attention laye ignora posizione ordine parole frase pure altri layer layer time distributed
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#32,32,"Keras: Transformer
In Keras una versione di Attention basata su 
 scaled dot-product
  è 
implementata in keras.layers.Attention.  
encoder_outputs = Z
Z = decoder_in
for
 N 
in 
range
(
6
):
    Z = keras.layers.Attention(use_scale=
 True
, causal=
 True
)([Z, Z])
    Z = keras.layers.Attention(use_scale=
 True
)([Z, encoder_outputs])
outputs = keras.layers.TimeDistributed(
    keras.layers.Dense(vocab_size, activation=
 ""softmax""
 ))(Z)
33 ...",keras transformer keras versione attention basata scaled dot product implementata encoderoutputs decoderin range true causal true true outputs distributed activation softmax
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#33,33,"Demo Transformers e NLP
https://transformer.huggingface.co/  
34 ...",demo transformers
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#4,4,"Richiamo: Architetture encoder-decoder
Si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
 vector-to-
sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio. 
5
",richiamo architetture encoder decoder pu combinare rete sequence vector encoder vector sequence decoder ottenendo rete encoder decoder encoder pu rappresentare frase linguaggio singolo vettore viene impiegato poi decoder generare frase diverso linguaggio
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#5,5,"Encoder/Decoder in Keras (1)
L'interfaccia 
 encoder
  può prendere in input una sequenza di lunghezza 
variabile X.  
class 
Encoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
call
(
self
, 
X
, *
args
):
        
 raise
 NotImplementedErro
 r
Il 
decoder
  prende l'output dei decoder per tramutarlo nello stato.  
class 
Decoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
init_state
 (
self
, 
enc_outputs
 , *
args
):
        
 raise
 NotImplementedError
    
def 
call
(
self
, 
X
, 
state
):
        
 raise
 NotImplementedError
6",encoderdecoder keras linterfaccia encoder pu prendere input sequenza lunghezza variabile class encoder keras layers layer def init self super init later additional arguments length excluding padding def call self args raise implemented erro decoder prende loutput decoder tramutarlo stato class decoder keras layers layer def init self super init later additional arguments length excluding padding def initstate self encoutputs args raise implemented error def call self state raise implemented error
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#6,6,"Encoder/Decoder in Keras (2)
L'architettura completa:  
class 
EncoderDecoder
 (
d2l
.
Classifier
 ):
   
def 
__init__
 (
self
, 
encoder
, 
decoder
):
        super().
 __init__
 ()
        
 self
.encoder = encoder
        
 self
.decoder = decoder
    
def 
call
(
self
, 
enc_X
, 
dec_X
, *
args
):
        enc_outputs = 
 self
.encoder(enc_X, *args, training=
 True
)
        dec_state = 
 self
.decoder.init_state(enc_outputs, *args
 )
        
 # Return decoder output only
        
 return 
self
.decoder(dec_X, dec_state, training=
 True
)[
0
]
7",encoderdecoder keras larchitettura completa class encoder decoder classifier def init self encoder decoder super init self encoder encoder self decoder decoder def call self enc dec args encoutputs self encoderenc args training true decstate self args return decoder output return self decoderdec decstate training true
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#7,7,"Esempio: Machine Translation (1)
In questo caso input e output sono sequenze di lunghezza variabile. La 
sequenza in input è tradotta in una rappresentazione nascosta/latente 
 ﬁ
xed-
shape.  
La sequenza in output è generata 
 token-by-token
 : data l'attuale sequenza in 
input, e i token precedenti generati in output. Durante l'addestramento il 
token da generare sarà estratto dai dati ground-truth. L'
 hidden state 
dell'
encoder
  viene dato in input ad ogni step di decoding. L'output generato 
sarà il nuovo input del decoder nello step successivo.  
Nota: se ignoriamo 
 l'encoder
 , il 
decoder
  corrisponde ad un 
 language model
 . 
Nell'esempio abbiamo frasi tokenizzate, dove <eos> corrisponde a end-of-
sequence. Ad ogni istanze iniziale, si impiega un tag <bos> per indicare 
l'inizio della sequenza
8
",esempio machine translation caso input output sequenze lunghezza variabile sequenza input tradotta xed shape sequenza output generata token token data lattuale sequenza input token precedenti generati output durante laddestramento token generare estratto dati ground truth hidden state dell encoder viene dato input ogni step decoding loutput generato nuovo input decoder step successivo nota ignoriamo lencoder decoder corrisponde language model nellesempio frasi tokenizzate eos corrisponde end sequence ogni istanze iniziale impiega tag bos indicare linizio sequenza
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#8,8,"Esempio: Machine Translation (2)
L'encoder
  può essere implementato con una RNN (es. GRU) uni o bi-
direzionale.  
L'output layer del 
 decoder
  sarà una FC che genera la distribuzione di 
probabilità sui token in output.  
La 
loss
 sarà una basata sulla 
 cross-entropy
 . 
Usualmente si usano sequenze di padding per frasi di lunghezza variabile, in 
input e output. Tali padding non intervengono nel calcolo della loss.
9
",esempio machine translation lencoder pu essere implementato uni direzionale loutput layer decoder genera distribuzione probabilit token output loss basata cross entropy usualmente usano sequenze padding frasi lunghezza variabile input output tali padding intervengono calcolo loss
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#9,9,"Beam search (1)
Nell'architettura precedente il token generato è quello con più alta 
probabilità, 
 ﬁ
no a quando non è generato il token <eos>. Seguiamo una 
strategia 
 greedy
 , 
basata sui passati token generati e la variabile di contesto 
 c
, 
che rappresenta la frase in input:  
Nella 
 beam search
  scegliamo i 
 k
 token candidati più probabili. 
Successivamente teniamo in considerazioni i 
 k
 token per la generazione del 
nuovo token, e così via.
10
",beam search precedente token generato alta probabilit quando generato token eos seguiamo strategia greedy basata passati token generati variabile contesto rappresenta frase input beam search scegliamo token candidati probabili successivamente teniamo considerazioni token generazione nuovo token cos via
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Autoencoders
1",deep learning universit roma tre dipartimento ingegneria anno accademico autoencoders
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#1,1,"Sommario
Language models: recenti sviluppi  
Autoencoders  
Stacked Autoencoders  
Fashion MNIST dataset  
Visualizzazione con t-SNE  
Unsupervised training con Stacked autoencoders  
Convolutional Autoencoders  
Recurrent Autoencoders  
Denoising Autoencoders  
Sparse Autoencoders  
Variational Autoencoders  
Semantic interpolation",sommario language models recenti sviluppi autoencoders stacked autoencoders fashion dataset visualizzazione unsupervised training stacked autoencoders convolutional autoencoders recurrent autoencoders denoising autoencoders sparse autoencoders variational autoencoders semantic interpolation
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#10,10,"Rappresentazioni latenti
Latent representation learning
  (LRL), o 
 Latent variable modeling 
 (LVM), è una 
tecnica di apprendimento automatico che tenta di inferire le variabili latenti 
da misurazioni empiriche da variabili osservabili. Tali variabili latenti non 
possono essere misurate direttamente e quindi devono essere dedotte.  
Una o più variabili latenti costituiscono congiuntamente uno 
 spazio latente
  o 
una
 rappresentazione latente
 . Questa rappresentazione è solitamente una 
forma 
 compatta
  dello spazio impiegato per rappresentare le misurazioni 
empiriche, cioè consiste in un numero di variabili latenti inferiore alla 
dimensionalità delle misurazioni.
11 ...",latenti latent representation learning latent variable modeling tecnica apprendimento automatico tenta inferire variabili latenti misurazioni empiriche variabili osservabili tali variabili latenti possono essere misurate direttamente quindi devono essere dedotte variabili latenti costituiscono congiuntamente spazio latente latente solitamente forma compatta spazio impiegato rappresentare misurazioni empiriche cio consiste numero variabili latenti inferiore dimensionalit misurazioni
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#11,11,"Autoencoders
Gli 
autoencoders
  apprendono 
 rappresentazioni latenti
  dei dati senza 
l'impiego di approcci supervisionati.  
Inoltre possono essere impiegati per il 
 unsupervised pretraining
 , e per 
generare casualmente nuovi dati 
 che risultano simili a dati già visti in 
precedenza (es. visi di persone), sebbene non sempre realistici.  
•
Con le più recenti 
 Generative adversarial networks
  (
GANs
 ), che spesso 
includono anche moduli di autoencoders, suddividono il processo in 2 parti: 
generazione e discrimazione. In questi casi il realismo è maggiore.  
•
https://thispersondoesnotexist.com/  
https://thisrentaldoesnotexist.com/  
https://github.com/jantic/DeOldify    
Inoltre le GAN possono incrementare la risoluzione delle immagini, 
aggiungere colore alle immagini b/w, photo editing come rimpiazzare oggetti, 
convertire un disegno in una foto realistica, predire il successo frame in un 
video, creare/incrementare dataset per l'addestramento, etc.
12 ...",autoencoders autoencoders apprendono latenti dati senza limpiego approcci supervisionati inoltre possono essere impiegati unsupervised pretraining generare casualmente nuovi dati risultano simili dati gi visti precedenza visi persone sebbene sempre realistici recenti generative adversarial networks ans spesso includono moduli autoencoders suddividono processo parti generazione discrimazione casi realismo maggiore oldify inoltre possono incrementare risoluzione immagini aggiungere colore immagini photo editing rimpiazzare oggetti convertire disegno foto realistica predire successo frame video dataset etc
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#12,12,"Rappresentazione dei dati ef
 ﬁ
ciente
Un 
autoencoder
  può avere una architettura piuttosto comune, es. MLP, dove 
input e output hanno hanno medesima dimensione.  
•
Nel seguente esempio l'
 hidden layer
  consiste in 2 soli nodi, mentre l'
 output 
e
 l'input layer 
 di 3 nodi. Lo scopo del 
 decoder
  (
output layer
 ) è ricostruire 
l'input a partire dalla rappresentazione creata dall'
 encoder
 .  
•
Se la rappresentazione dell'encoder ha meno dimensioni rispetto all'input, 
l'
autoencoder
  si chiama 
 undercomplete
 . 
•
La
 loss di ricostruzione
  valuta la differenza dell'output generato rispetto 
all'input.
13 ...
",dati ciente autoencoder pu avere architettura piuttosto comune input output medesima dimensione seguente esempio hidden layer consiste soli nodi mentre output linput layer nodi scopo decoder output layer ricostruire linput partire creata dall encoder dellencoder meno dimensioni rispetto allinput autoencoder chiama undercomplete loss ricostruzione valuta differenza delloutput generato rispetto allinput
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#13,13,"Autoencoders
Se l'
autoencoder 
 usa 
attivazioni lineari
  e la 
 MSE
 come funzione di costo, 
allora otteniamo un modello simile alla 
 Principal Component Analysis 
 (
PCA
). 
Nel seguente esempio proiettiamo istanze da un dataset 3d in 2d.  
from
 tensorflow 
 import
 keras
encoder = keras.models.Sequential([keras.layers.Dense(
 2
, input_shape=[
 3
])])
decoder = keras.models.Sequential([keras.layers.Dense(
 3
, input_shape=[
 2
])])
autoencoder = keras.models.Sequential([encoder, decoder])
autoencoder.
 compile
(loss=
""mse""
, optimizer=keras.optimizers.SGD(lr=
 0.1
))
Possiamo addestrarlo e impiegarlo per ottenere le rappresentazioni latenti:  
history = autoencoder.fit(X_train, X_train, epochs=
 20
)
codings = encoder.predict(X_train)
14 ...
",autoencoders autoencoder usa attivazioni lineari funzione costo allora otteniamo modello simile principal component analysis seguente esempio proiettiamo istanze dataset tensorflow import keras encoder inputshape decoder inputshape autoencoder decoder autoencoder compile loss mse gdlr possiamo addestrarlo impiegarlo ottenere latenti history xtrain epochs codings
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#14,14,"Stacked Autoencoders
Gli 
stacked autoencoders
  (o 
deep autoencoders
 ) sono autoencoders 
organizzati su più layer, spesso in modo speculare.  
•
Non è mai consigliato creare autoencoders troppo complessi per non 
penalizzare il grado di generalizzazione su istanze in input non presenti nel 
dataset di training, su cui il modello non è capace di determinare attivazioni 
signi
ﬁ
cative.  
Nel caso 
 MNIST
  possiamo creare una architettura con 784 inputs, 100 nodi 
nel primo hidden layer, 30 nodi in quello centrale, un altro da 100 e l'output 
layer.
15 ...
",stacked autoencoders stacked autoencoders deep autoencoders autoencoders organizzati layer spesso modo speculare mai consigliato creare autoencoders troppo complessi penalizzare grado istanze input presenti dataset training modello capace determinare attivazioni signi cative caso possiamo creare architettura inputs nodi primo hidden layer nodi centrale altro loutput layer
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#15,15,"Scaled Exponential Linear Units
La funzione di attivazione 
 Scaled Exponential Linear Units
  (
SELU
 ) 
è simile alla 
ELU ed è de
 ﬁ
nita nel seguente modo:  
 
 
La SELU non si annulla per valore < 0, a differenza della ReLU.  
Si può ipotizzare che la SELU implementi un ulteriore tipo di normalizzazione 
""interna"" che supporti l'invarianza tra media e varianza tra i layer, oltre alle 
due normalizzazioni già note:  
•
Input normalization (
 es. quando scaliamo i dati in ingresso)  
•
Batch normalization
f
(
x
)
=
λ
x
,
if 
x
>
0
f
(
x
)
=
λ
α
(
e
x
−
1
)
 altrimenti
16
",scaled exponential linear units funzione attivazione scaled exponential linear units simile nita seguente modo annulla valore differenza pu ipotizzare implementi ulteriore tipo normalizzazione interna supporti linvarianza media varianza layer oltre due normalizzazioni gi note input normalization quando scaliamo dati ingresso batch normalization altrimenti
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#16,16,"Keras: Stacked Autoencoders
L'implementazione è simile a una MLP. Nell'esempio usiamo una funzione di 
attivazione SELU, e invece delle MSE impieghiamo la 
 binary cross-entropy
  loss  
per accelerare la convergenza.  
stacked_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
),
])
stacked_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])
stacked_ae.
 compile
(loss=
""binary_crossentropy""
 ,
                   optimizer=keras.optimizers.SGD(lr=
 1.5
))
history = stacked_ae.fit(X_train, X_train, epochs=
 10
,
                         validation_data=[X_valid, X_valid])
17 (13) https://arxiv.org/pdf/1706.02515.pdf",keras stacked autoencoders simile nellesempio usiamo funzione attivazione invece impieghiamo binary cross entropy loss accelerare convergenza stackedencoder activation selu activation selu stackeddecoder activation selu inputshape activation sigmoid stackedae stackedae compile loss gdlr history xtrain epochs xvalid
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#17,17,"`
Per comprendere se l'output è corretto è utile visualizzarlo. Nel caso del 
dataset Fashion MNIST si ha:  
def 
plot_image
 (
image
):
    plt.imshow(image, cmap=
 ""binary""
 )
    plt.axis(
 ""off""
)
def 
show_reconstructions
 (
model
, 
n_images
 =
5
):
    reconstructions = model.predict(X_valid[:n_images])
    fig = plt.figure(figsize=(n_images * 
 1.5
, 
3
))
    
for
 image_index 
 in 
range
(n_images):
        plt.subplot(
 2
, n_images, 
 1
 + image_index)
        plot_image(X_valid[image_index])
        plt.subplot(
 2
, n_images, 
 1
 + n_images + image_index)
        plot_image(reconstructions[image_index])
show_reconstructions(stacked_ae)
18 ...
",comprendere loutput corretto utile visualizzarlo caso dataset fashion def plotimage image cmap binary pltaxis off def model nimages reconstructions fig imageindex range nimages pltsubplot nimages imageindex pltsubplot nimages nimages imageindex
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#18,18,"t-Distributed Stochastic Neighbourh 
t-Distributed Stochastic Neighbourh Embedding (t-SNE)
  è un algoritmo non 
supervisionato usato per la visualizzazione dei dati.  
Basato su una tecnica di riduzione della dimensionalità non lineare che punta 
a raggruppare punti simili tra loro in spazi con poche dimensioni preservando 
la struttura dei dati originali.  
Sfrutta la distribuzione t-Student per il calcolo della similarità tra 2 punti nello 
spazio ridotto e sulla Kullback–Leibler divergence.  
È poco affetto dagli outliers.
19 ...",distributed stochastic neighbourh distributed stochastic neighbourh embedding algoritmo supervisionato usato visualizzazione dati basato tecnica riduzione dimensionalit lineare punta raggruppare punti simili spazi poche dimensioni preservando struttura dati originali sfrutta distribuzione student calcolo similarit punti spazio ridotto divergence poco affetto outliers
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#19,19,"Visualizzare un dataset con Autoencoders
Sebbene esistano tecniche avanzate di riduzione della dimensionalità e la 
visualizzazione dei dati, gli 
 autoencoders
  sono capaci di ridurre notevolmente 
le dimensioni di un dataset con molti istanze e molte features. Perciò 
possiamo sfruttarlo per generare input verso approcci più tradizionali, anche 
di visualizzazione.  
Sfruttiamo 
 t-distributed stochastic neighbor embedding
  (
t
-
SNE
) implementato 
in Scikit-Learn per la visualizzazione 2d.  
from
 sklearn.manifold 
 import
 TSNE
X_valid_compressed = stacked_encoder.predict(X_valid)
tsne = TSNE()
X_valid_2D = tsne.fit_transform(X_valid_compressed)
plt.scatter(X_valid_2D[:, 
 0
], X_valid_2D[:, 
 1
], c=y_valid, s=
 10
, cmap=
""tab10""
)
20 ...",visualizzare dataset autoencoders sebbene esistano tecniche avanzate riduzione dimensionalit visualizzazione dati autoencoders capaci ridurre notevolmente dimensioni dataset molti istanze molte features perci possiamo sfruttarlo generare input verso approcci tradizionali sfruttiamo distributed stochastic neighbor embedding implementato scikit learn visualizzazione import tsne xvalid xvalid cyvalid cmap tab
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#2,2,"Language Models: recenti sviluppi (1)
ELMo
(6)
 Embeddings from Language Models: rappresentazioni contestuali 
ottenute da un approccio 
 Deep bidirectional language model (biLM) 
addestrato su larghi dataset testuali. Gli stati generati dalla rete sono associati 
ai testi in modo da creare rappresentazioni latenti.   
ULMFiT
(7)
 Universal Language Model Fine-tuning: basato su 
 self-supervised 
learning
  con una architettura 
 LSTM
  a 3 layer dove sono richiesti meno dati (es. 
100 istanze) per l'addestramento sfruttando il transfer learning. State-of-the-art 
per la classi
 ﬁ
cazione NLP.
3(6) https://arxiv.org/abs/1802.05365  
(7) https://arxiv.org/abs/1801.06146  
",language models recenti sviluppi lmo embeddings language models contestuali ottenute approccio deep bidirectional language model addestrato larghi dataset testuali stati generati rete associati testi modo creare latenti universal language model fine tuning basato self supervised learning architettura layer richiesti meno dati istanze laddestramento sfruttando transfer learning state art classi cazione
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#20,20,"Fashion MNIST: Autoencoders e t-SNE
Fashion MNIST sottoposto a 
 autoencoders
  e 
t-SNE
 :
21 ...
",fashion autoencoders fashion sottoposto autoencoders
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#21,21,"Unsupervised training con Stacked autoencoders
Seguendo la 
 ﬁ
loso
ﬁ
a del 
 transfer learning
 , possiamo addestrare un 
autoencoder
  su un grande dataset di dati 
 unlabeled
 , e 
riutilizzare i parametri 
ottenuti nei primi layer 
 con un dataset più limitato di dati 
 labeled
  nel task 
principale di interesse.  
•
Dati 
 unlabeled
  si trovano facilmente sul web, es. immagini, testi, mentre i 
dati labeled sono molto preziosi poiché richiedono molte ore-uomo per 
creare valori target.
22 ...
",unsupervised training stacked autoencoders seguendo loso transfer learning possiamo addestrare autoencoder grande dataset dati unlabeled riutilizzare parametri ottenuti primi layer dataset limitato dati labeled task principale interesse dati unlabeled trovano facilmente web immagini testi mentre dati labeled molto preziosi poich richiedono molte ore uomo creare valori target
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#22,22,"Autoencoders: Tying weights (1)
Per 
autoencoders
  simmetrici è possibile creare 
 vincoli
  tra i valori dei parametri 
nei layer speculari (
 tying weights
 ) in modo da dimezzare i parametri da 
stimare durante l'apprendimento.  
In Keras costruiamo un Dense layer per impiegare i pesi di un layer 
precedente; attenzione: occorre trasporli prima di impiegarli nella decodi
 ﬁ
ca. 
class 
DenseTranspose
 (
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
dense
, 
activation
 =
None
, **
kwargs
):
        
 self
.dense = dense
        
 self
.activation = keras.activations.get(activation)
        super().
 __init__
 (**kwargs
 )
    
def 
build
(
self
, 
batch_input_shape
 ):
        
 self
.biases = 
 self
.add_weight(name=
 ""bias""
, initializer=
 ""zeros""
,
                                      shape=[
 self
.dense.input_shape[
 -1
]])
        super().build(batch_input_shape
 )
    
def 
call
(
self
, 
inputs
):
        z = tf.matmul(inputs, 
 self
.dense.weights[
 0
], 
transpose_b
 =
True
)
        
 return 
self
.activation(z + 
 self
.biases)
23 ...",autoencoders tying weights autoencoders simmetrici possibile creare vincoli valori parametri layer speculari tying weights modo dimezzare parametri stimare durante keras costruiamo dense layer impiegare pesi layer precedente attenzione occorre trasporli prima impiegarli decodi class dense transpose keras layers layer def init self dense activation none kwargs self dense dense self activation super init kwargs def build self self biases self bias initializer zeros shape self def call self inputs self denseweights transposeb true return self activationz self biases
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#23,23,"Autoencoders: Tying weights (2)
La costruzione della rete impiega i nuovi layer per legarli con i precedenti:  
dense_1 = keras.layers.Dense(
 100
, activation=
 ""selu""
)
dense_2 = keras.layers.Dense(
 30
, activation=
 ""selu""
)
tied_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    dense_1,
    dense_2
])
tied_decoder = keras.models.Sequential([
    DenseTranspose(dense_2, activation=
 ""selu""
),
    DenseTranspose(dense_1, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])
24 ...",autoencoders tying weights costruzione rete impiega nuovi layer legarli precedenti dense activation selu dense activation selu tiedencoder dense dense tieddecoder dense activation selu dense activation sigmoid tiedae tieddecoder
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#24,24,"Greedy layerwise training
Invece di addestrare tutti i layer contemporaneamente possiamo farlo uno step 
alla volta, aggiungendo un layer dopo aver addestrato il precedente (
 greedy 
layerwise training
 ). 
Dopo il primo step codi
 ﬁ
co tutto il dataset per mezzo del primo autoencoder 
(
phase 1
 ). Uso il nuovo dataset per addestrare un secondo autoencoder (
 phase 
2
). In
ﬁ
ne metto tutti i layer insieme (
 phase 3
 ) 
•
Tale tecnica è attualmente poco popolare a causa di tecniche più recenti.
25 ...
",greedy layerwise training invece addestrare layer possiamo farlo step volta aggiungendo layer dopo aver addestrato precedente greedy layerwise training dopo primo step codi dataset mezzo primo autoencoder phase uso nuovo dataset addestrare secondo autoencoder phase metto layer insieme phase tale tecnica attualmente poco popolare causa tecniche recenti
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#25,25,"Convolutional Autoencoders
Le architetture di 
 autoencoders
  viste non sono adatte per le immagini, cioè 
input con grandi dimensionalità.  
Le 
convolutional autoencoders
  impieghiamo dei 
 layer convoluzionali 
 per 
ridurre la dimensionalità
  incrementando la profondità del modello durante la 
codi
ﬁ
ca. 
Il 
decoder
  deve fare l'inverso: ridurre la profondità ed aumentare la risoluzione 
(
upsampling
 ). Si impiegano 
 transpose convolutional layers
  che operano in 
modo inverso alle convolution layer tradizionali.  
Ecco un esempio per Fashion MNIST:  
conv_encoder = keras.models.Sequential([
    keras.layers.Reshape([
 28
, 
28
, 
1
], input_shape=[
 28
, 
28
]),
    keras.layers.Conv2D(
 16
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 32
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 64
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
)
]
)
...
26 ...",convolutional autoencoders architetture autoencoders viste adatte immagini cio input grandi dimensionalit convolutional autoencoders impieghiamo layer convoluzionali ridurre dimensionalit incrementando profondit modello durante codi decoder deve fare linverso ridurre profondit aumentare risoluzione upsampling impiegano transpose convolutional layers operano modo inverso convolution layer tradizionali ecco esempio fashion convencoder inputshape kernelsize padding same activation selu pool dpoolsize kernelsize padding same activation selu pool dpoolsize kernelsize padding same activation selu pool dpoolsize
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#26,26,"Convolutional Autoencoders
conv_decoder = keras.models.Sequential([
    keras.layers.Conv2DTranspose(
 32
, kernel_size=
 3
, strides=
 2
, padding=
 ""valid""
,
                                 activation=
 ""selu""
,
                                 input_shape=[
 3
, 
3
, 
64
]),
    keras.layers.Conv2DTranspose(
 16
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""selu""
),
    keras.layers.Conv2DTranspose(
 1
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])
27 ...",convolutional autoencoders convdecoder dtranspose kernelsize strides padding valid activation selu inputshape dtranspose kernelsize strides padding same activation selu dtranspose kernelsize strides padding same activation sigmoid convae convdecoder
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#27,27,"Recurrent Autoencoders
Per dati 
 time series
  abbiamo visto come le RNN sono una valida alternativa alle 
FC. 
I 
recurrent autoencoder 
 hanno un 
 encoder
  tipicamente 
 sequence-to-vector 
 che 
""comprime"" l'input in una rappresentazione vettoriale, mentre il decoder è 
vector-to-sequence
 . 
Il seguente 
 autoencoder
  processa sequenze di qualsiasi lunghezza, con 28 
dimensioni considerate per singolo step. L'input possono essere immagini 
Fashion MNIST che saranno processate una riga di pixel alla volta.  
•
Il
 RepeatVector layer 
 del decoder garantisce che l'input vector al decoder sarà 
inviato per intero ad ogni step.  
recurrent_encoder = keras.models.Sequential([
    keras.layers.LSTM(
 100
, return_sequences=
 True
, input_shape=[
 None
, 
28
]),
    keras.layers.LSTM(
 30
)
])
recurrent_decoder = keras.models.Sequential([
    keras.layers.RepeatVector(
 28
, input_shape=[
 30
]),
    keras.layers.LSTM(
 100
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 28
, activation=
 ""sigmoid""
 ))
])
recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])
28 ...",recurrent autoencoders dati time series visto valida alternativa recurrent autoencoder encoder tipicamente sequence vector comprime linput vettoriale mentre decoder vector sequence seguente autoencoder processa sequenze qualsiasi lunghezza dimensioni considerate singolo step linput possono essere immagini fashion processate riga pixel volta repeat vector layer decoder garantisce linput vector decoder inviato intero ogni step keraslayersl true inputshape none keraslayersl vector inputshape keraslayersl true activation sigmoid recurrentae
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#28,28,"Denoising Autoencoders (1)
Nelle 
 denoising autoencoders
(14)
 in input abbiamo immagini a cui 
aggiungiamo del rumore, e in output ci sono le versioni originali: stiamo 
addestrando la rete a 
 rimuovere il rumore
 .  
•
Il rumore può essere gaussiano, oppure con un random switch-off degli input 
(es. tramite tecniche simili al Dropout).
29 (14) https://jmlr.csail.mit.edu/papers/v11/vincent10a
",denoising autoencoders denoising autoencoders input immagini aggiungiamo rumore output versioni originali addestrando rete rimuovere rumore rumore pu essere gaussiano oppure random switch input tramite tecniche simili dropout
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#29,29,"Denoising Autoencoders (2)
Codi
ﬁ
ca e output con Fashion MNIST  
dropout_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    
keras.layers.Dropout(
 0.5
),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activ
                       “    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
)
])
dropout_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])
30 ...
",denoising autoencoders codi output fashion dropoutencoder activation selu activ activation selu activation selu dropoutdecoder activation selu inputshape activation sigmoid dropoutae
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#3,3,"Self-supervised learning
Con 
self-supervised learning  
si intende l'addestramento di una modello in assenza di 
un dataset suf
 ﬁ
cientemente grande in termini di valori target riguardo il task di 
interesse principale.  
In tali casi si sfruttano le stessi istanze presentate in input per creare dei nuovi target 
secondari, distinti da quello iniziale, ma comunque af
 ﬁ
ni. In tal modo la rete può 
identi
 ﬁ
care alcune features salienti impiegabili nel task principale (
 knowledge transfer 
process
 ).  
•
Esempi di task secondari sono
 : identi
 ﬁ
care relazioni sostantivo-verbo o frase-
aggettivo (dominio NLP); due immagini, una ruotata, ed aspettarsi l'angolo di 
rotazione in output alla rete (dominio immagini).  
Sebbene i dataset secondari siano più facili da costruire, non sono suf
 ﬁ
cienti per 
risolvere il problema principale. ma riducono il tempo totale necessario per la fase di 
training del task principale. Una ulteriore fase di addestramento su un dataset ridotto 
(es. quello disponibile inizialmente) rendono la rete ef
 ﬁ
cace anche sul task di interesse 
primario.  
È fondamentale scegliere un task secondario che, durante l'addestramento, generi un 
sottoinsieme di features utili anche per il task principale.  
Attenzione: è un approccio distinto dal 
 unsupervised pretraining
 .
4",self supervised learning self supervised learning intende laddestramento modello assenza dataset suf cientemente grande termini valori target riguardo task interesse principale tali casi sfruttano istanze presentate input creare nuovi target secondari distinti iniziale comunque tal modo rete pu identi care alcune features salienti impiegabili task principale knowledge transfer process esempi task secondari identi care relazioni sostantivo verbo frase aggettivo dominio due immagini ruotata aspettarsi langolo rotazione output rete dominio immagini sebbene dataset secondari facili costruire suf cienti risolvere problema principale riducono tempo totale necessario fase training task principale ulteriore fase addestramento dataset ridotto disponibile inizialmente rendono rete cace task interesse primario fondamentale scegliere task secondario che durante generi sottoinsieme features utili task principale attenzione approccio distinto unsupervised pretraining
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#30,30,"Sparse Autoencoders (1)
Negli 
 sparse autoencoders 
 introduciamo un termine nella funzione di costo che 
favorisce un numero limitato di nodi ""attivi"" nel layer di coding
 , cioè quello che 
è associato allo spazio che stiamo costruendo.  
•
In altre parole, forziamo la rete a rappresentare ogni input con poche attivazioni, 
e perciò 
 ogni nodo attivo rappresenterà un numero limitato di feature molto 
signi
ﬁ
cative
 . 
Con la funzione di attivazione 
 sigmoid
 , che pone una sorta di vincolo sulle 
codi
ﬁ
che in [0,1], e con la 
 ℓ
1
 regularization
  al layer di coding, otteniamo il 
seguente codice Keras:  
sparse_l1_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ),
    
keras.layers.ActivityRegularization(l1=
 1e-3
)
  # vedi lucido seguente
])
sparse_l1_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])
31 ...",sparse autoencoders sparse autoencoders introduciamo termine funzione costo favorisce numero limitato nodi attivi layer coding cio associato spazio costruendo altre parole forziamo rete rappresentare ogni input poche attivazioni perci ogni nodo attivo rappresenter numero limitato feature molto signi cative funzione attivazione sigmoid pone sorta vincolo codi regularization layer coding otteniamo seguente codice keras activation selu activation sigmoid vedi lucido seguente activation selu inputshape activation sigmoid sparselae
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#31,31,"Sparse Autoencoders (2)
Il layer 
 ActivityRegularization
  restituisce gli stessi input, ma ha l'effetto 
collaterale di aggiungere una
  training loss che coincide con la somma dei valori 
assoluti dei suoi input
 . In questo modo forziamo la rete, sia a produrre 
codi
ﬁ
che vicine allo 0
 , sia a ricostruire l'output corretto; perciò avremo 
codi
ﬁ
che con pochi valori, ma molto signi
 ﬁ
cativi, diversi da 0.  
Un modo alternativo è 
 misurare una sorta di ""sparsity"" calcolata durante 
l'apprendimento
  e, se si discosta da un valore target, 
 penalizziamo la rete
 . La 
ricaviamo con l'
 attivazione media
  per ogni nodo nel coding layer nell'intero 
training batch, che avrà una dimensione suf
 ﬁ
ciente per stimare correttamente 
tali valori.  
Successivamente introduciamo la 
 sparsity loss
  che penalizza i nodi troppo 
attivi, o i nodi non suf
 ﬁ
cientemente attivi.  
•
Es. Se l'average per un nodo è 0.3, e la target sparsity è 0.1, penalizziamo in 
modo da ridurre l'attivazione aggiungendo ad esempio l'
 errore quadratico  
(0.3-0.1)2  alla funzione di cost.  
•
Una alternativa migliore è usare 
 Kullback–Leibler (KL)
 , che deriva dei gradienti 
più signi
 ﬁ
cativi interpretando le 2 attivazioni come distribuzioni di probabilità.
32 ...",sparse autoencoders layer activity regularization restituisce input leffetto collaterale aggiungere training loss coincide somma valori assoluti input modo forziamo rete produrre codi vicine ricostruire loutput corretto perci codi pochi valori molto signi cativi diversi modo alternativo misurare sorta sparsity calcolata durante lapprendimento discosta valore target penalizziamo rete ricaviamo attivazione media ogni nodo coding layer nellintero training batch dimensione suf ciente stimare correttamente tali valori successivamente introduciamo sparsity loss penalizza nodi troppo attivi nodi suf cientemente attivi laverage nodo target sparsity penalizziamo modo ridurre lattivazione aggiungendo esempio errore quadratico funzione cost alternativa migliore usare deriva gradienti signi cativi interpretando attivazioni distribuzioni probabilit
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#32,32,"Sparsity loss
Sparsity loss
  ricavata con diverse metriche:
33 ...
",sparsity loss sparsity loss ricavata diverse metriche
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#33,33,"Keras: Sparse Autoencoders
Sparse autoencoders con la KL-divergence:  
K = keras.backend
kl_divergence = keras.losses.kullback_leibler_divergence
class 
KLDivergenceRegularizer
 (
keras
.
regularizers
 .
Regularizer
 ):
    
def 
__init__
 (
self
, 
weight
, 
target
=
0.1
):
        
 self
.weight = weight
        
 self
.target = target
    
def 
__call__
 (
self
, 
inputs
):
        mean_activities = K.mean(inputs, axis=
 0
)
        
 return 
self
.weight * (
            kl_divergence(
 self
.target, mean_activities) +
            kl_divergence(
 1
. - 
self
.target, 
 1
. - mean_activities))
        
..
.
kld_reg = KLDivergenceRegularizer(weight=
 0.05
, target=
 0.1
)
sparse_kl_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ,”
                       activity_regularizer=kld_reg)
])
sparse_kl_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])
34 ...",keras sparse autoencoders sparse autoencoders divergence kerasbackend kldivergence class ldivergence regularizer keras regularizers regularizer def init self weight target self weight weight self target target def call self inputs meanactivities kmeaninputs axis return self weight kldivergence self target kldivergence self target kldreg ldivergence target activation selu activation sigmoid activation selu inputshape activation sigmoid sparseklae
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#34,34,"Sparse Autoencoders e attivazioni
Dopo la fase di training su Fashion MNIST notiamo come circa il 70% delle 
attivazioni è prossima a 0, e che gran parte dei neuroni (90%) ha attivazione 
media tra 0.1 e 0.2.
35 ...
",sparse autoencoders attivazioni dopo fase training fashion notiamo circa attivazioni prossima gran parte neuroni attivazione media
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#35,35,"Variational Autoencoders (1)
I 
variational autoencoders 
 sono molto diffusi. Sono distinti dai precedenti 
poiché sono in parte 
 probabilistici
 , cioè una parte dell'output è generato in 
modo random, e 
 generativi
 , cioè possono generare nuove istanze che 
sembrano campionate dal training set. 
36 (15) https://arxiv.org/abs/1312.6114
Hanno una architettura simile agli altri 
autoencoders, ma all'interno 
l'encoder produce un vettore 
 codi
ﬁ
ca 
media  
 e un vettore 
 deviazione 
standard  
.  
L'
effettiva codi
 ﬁ
ca
 della istanza in 
input sarà generata per mezzo di una 
distribuzione gaussiana con tali 
parametri.  
Durante il training la loss tende a 
raggruppare le codi
 ﬁ
che in modo da 
generare una ""nuvola gaussiana"" di 
punti.
μ
σ",variational autoencoders variational autoencoders molto diffusi distinti precedenti poich parte probabilistici cio parte delloutput generato modo random generativi cio possono generare nuove istanze sembrano campionate training set architettura simile altri autoencoders allinterno lencoder produce vettore codi media vettore deviazione standard effettiva codi istanza input generata mezzo distribuzione gaussiana tali parametri durante training loss tende raggruppare codi modo generare nuvola gaussiana punti
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#36,36,"Variational Autoencoders (2)
La 
funzione di costo
  consiste in due loss: la 
 reconstruction loss 
 che impone 
che l'output sia fedele all'input, e una 
 latent loss 
 che spinge ad avere 
codi
ﬁ
che come se fossero campionate da una distribuzione gaussiana, de
 ﬁ
nita 
per mezzo della KL-divergence.  
37 (15) https://arxiv.org/abs/1312.6114
La forma analitica contiene dettagli 
per limitare l'informazione trasmessa 
al coding layer, ma sempli
 ﬁ
cando si 
ottiene la seguente 
 latent loss
 : 
K 
è la dimensione delle codi
 ﬁ
che e 
 i 
indica l'i-esima componente della 
codi
ﬁ
ca.  
•
Impiegando la log(
 ) invece di 
  si 
ottiene 
 più stabilità
 .
σ
 σ
",variational autoencoders funzione costo consiste due loss reconstruction loss impone loutput fedele allinput latent loss spinge avere codi campionate distribuzione gaussiana nita mezzo divergence forma analitica contiene dettagli limitare linformazione trasmessa coding layer sempli cando ottiene seguente latent loss dimensione codi indica esima componente codi impiegando log invece ottiene stabilit
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#37,37,"Keras: Variational Autoencoders (1)
In Keras creiamo un 
 Sampling
  layer che campiona una istanza dalla distribuzione 
gaussiana  
class 
Sampling
 (
keras
.
layers
.
Layer
):
    
def 
call
(
self
, 
inputs
):
        mean, log_var = inputs
        
 return
 K.random_normal(tf.shape(log_var)) * K.exp(log_var / 
 2
) + mean
Non avendo un modello strettamente sequenziale usiamo le 
 Functional API
  di Keras, 
adatte per architetture particolari, ad esempio con topologie non lineari, pesi condivisi 
tra layer, o input e output multipli.  
Nel codice del 
 encoder
  con Functional API notiamo la rappresentazione esplicita dei 
dati ricavati dalla rete (es. 
 z, codings_mean, codings_log_var
  etc):  
codings_size = 1
 0
inputs = keras.layers.Input(shape=[
 28
, 
28
])
z = keras.layers.Flatten()(inputs)
z = keras.layers.Dense(
 150
, activation=
 ""selu""
)(z)
z = keras.layers.Dense(
 100
, activation=
 ""selu""
)(z)
codings_mean = keras.layers.Dense(codings_size)(z)  
 # 
μ
codings_log_var = keras.layers.Dense(codings_size)(z)  
 # 
γ
codings = Sampling()([codings_mean, codings_log_var])
variational_encoder = keras.Model(
    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])
38 ...",keras variational autoencoders keras creiamo sampling layer campiona istanza distribuzione gaussiana class sampling keras layers layer def call self inputs mean logvar inputs return kexplogvar mean modello strettamente sequenziale usiamo functional keras adatte architetture particolari esempio topologie lineari pesi condivisi layer input output multipli codice encoder functional notiamo esplicita dati ricavati rete codingsmean codingslogvar etc codingssize inputs activation selu activation selu codingsmean codingslogvar codings kerasmodel codings
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#38,38,"Keras: Variational Autoencoders (2)
Creiamo il 
 decoder
 , in questo caso potevamo usare anche l'approccio Keras 
Sequential.  
decoder_inputs = keras.layers.Input(shape=[codings_size])
x = keras.layers.Dense(
 100
, activation=
 ""selu""
)(decoder_inputs)
x = keras.layers.Dense(
 150
, activation=
 ""selu""
)(x)
x = keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 )(x)
outputs = keras.layers.Reshape([
 28
, 
28
])(x)
variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])
Creiamo il modello e de
 ﬁ
niamo la 
 latent_loss
  e 
reconstruction_loss
 , e 
addestriamo con 
 RMSprop
  optimizer, adatto in questa con
 ﬁ
gurazione:  
_, _, codings = variational_encoder(inputs)
reconstructions = variational_decoder(codings)
variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])
latent_loss = 
 -0.5
 * K.
sum
(
    
1
 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),
    axis=
 -1
)
variational_ae.add_loss(K.mean(latent_loss) / 
 784
.)
variational_ae.
 compile
(loss=
""binary_crossentropy""
 , optimizer=
 ""rmsprop""
 )
history = variational_ae.fit(X_train, X_train, epochs=
 50
, batch_size=
 128
,
                             validation_data=[X_valid, X_valid])
39 ...",keras variational autoencoders creiamo decoder caso potevamo usare lapproccio keras sequential decoderinputs activation selu activation selu activation sigmoid outputs creiamo modello niamo latentloss addestriamo msprop optimizer adatto gurazione codings reconstructions variationalae latentloss sum codingslogvar axis variationalae compile loss optimizer rmsprop history xtrain epochs batchsize xvalid
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#39,39,"Generare immagini stile Fashion MNIST
Generiamo nuove istanze campionando in modo causale dalla distribuzione 
gaussiana:  
codings = tf.random.normal(shape=[
 12
, codings_size])
images = variational_decoder(codings).numpy(
 )
Le istanze in output, un po' fuzzy, sono abbastanza verosimili:
40 ...
",generare immagini stile fashion generiamo nuove istanze campionando modo causale distribuzione gaussiana codings codingssize images istanze output fuzzy abbastanza verosimili
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#4,4,"Self-supervised learning - esempio
Nel dominio delle immagini possiamo considerare come task secondari quelli 
il cui obiettivo è ricostruire una immagine manipolata, es. distorta, ruotata.  
Nel task 
 patches
 , estraiamo più segmenti dall'immagine e cerchiamo di 
determinare la relazione tra essi (es. posizione relativa tra 2 segmenti).  
•
Es
. prendiamo una patch 
 X
 a caso dall'immagine, ed otteniamo le 8 patches 
che la circondano 
 Y
i
. Usiamo coppie di patches (
 X,Y
i
) come input per 
determinare la posizione della patch 
 Y
i
. Oppure diamo in input tutte le 9 
patches in ordine random e chiediamo alla rete di ""risolvere il puzzle"".
5
",self supervised learning esempio dominio immagini possiamo considerare task secondari obiettivo ricostruire immagine manipolata distorta ruotata task patches estraiamo segmenti dallimmagine cerchiamo determinare relazione essi posizione relativa segmenti prendiamo patch caso dallimmagine otteniamo patches circondano usiamo coppie patches input determinare posizione patch oppure diamo input tutte patches ordine random chiediamo rete risolvere puzzle
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#40,40,"Variational Autoencoders e semantic interpolation
Invece di interpolare due immagini nel ""dominio dei pixel"", possiamo 
interpolare nel dominio latente 
 costruito dall'
 autoencoder
 . 
•
Deriviamo la rappresentazione dal coding layer di due immagini in input, 
interpoliamole e decodi
 ﬁ
chiamole.  
codings_grid = tf.reshape(codings, [
 1
, 
3
, 
4
, codings_size])
larger_grid = tf.image.resize(codings_grid, size=[
 5
, 
7
])
interpolated_codings = tf.reshape(larger_grid, [
 -1
, codings_size])
images = variational_decoder(interpolated_codings).numpy()
41 ...
Le immagini nel box sono 
quelle originali, quelle 
senza sono l'interpolazione 
di quelle adiacenti.",variational autoencoders semantic interpolation invece interpolare due immagini dominio pixel possiamo interpolare dominio latente costruito dall autoencoder deriviamo coding layer due immagini input interpoliamole decodi chiamole codingsgrid codingssize largergrid size codingssize images immagini box originali senza adiacenti
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#5,5,"Language Models: recenti sviluppi (2)
GPT
(8)
 sfrutta il 
 unsupervised pretraining
  con una  architettura 
 Transform
  con 
stack di 12 moduli, addestrata su un dataset esteso con tecniche 
 self-
supervised
 .  
•
Necessita di un 
 ﬁ
ne-tuned training per impiegarla su task speci
 ﬁ
ci (es. 
classi
 ﬁ
cazione, misura di similarità, question answering).  
•
GPT-2
(9)
 è una versione estesa con 1.5 miliardi di parametri, con modelli 
disponibili online.  
•
GPT-3
  è estesa a 175 miliardi di parametri. Le APIs sono disponibili ma 
l'accesso è previa veri
 ﬁ
ca.
6(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2",language models recenti sviluppi sfrutta unsupervised pretraining architettura transform stack moduli addestrata dataset esteso tecniche self supervised necessita tuned training impiegarla task speci classi cazione misura similarit question answering versione estesa miliardi parametri modelli disponibili online estesa miliardi parametri pis disponibili laccesso previa veri glui
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#6,6,"Language Models: recenti sviluppi (3)
GPT-2 output
7(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2
",language models recenti sviluppi output glui
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#7,7,"Language Models: recenti sviluppi (4)
BERT
(10)
 Bidirectional Encoder Representations from Transformers: sviluppata 
da Google, simile alla GPT, impiega 
 self-supervised pretraining
  con approccio 
bidirezionale. È stata pre-addestrata su due task:  
•
Ogni parola in una frase ha il 15% di probabilità di essere 
 mascherata
 . Il 
compito della rete è di indovinarla.  
•
Date due frasi, predire se sono consecutive.  
Altri approcci recenti usano CNN con 
 masked 2d-conv
  per il task di 
trasformazione sequence-to-sequence
(11)
, o RNN dove ogni nodo risulta 
indipendente dall'altro, garantendo apprendimenti su sequenze molto più 
lunghe
(12)
.
8(10) https://arxiv.org/abs/1810.04805  
(11) https://arxiv.org/abs/1808.03867(12) https://arxiv.org/abs/1803.04831  ",language models recenti sviluppi bidirectional encoder representations transformers sviluppata google simile impiega self supervised pretraining approccio bidirezionale stata pre addestrata due task ogni parola frase probabilit essere mascherata compito rete indovinarla date due frasi predire consecutive altri approcci recenti usano masked conv task trasformazione sequence sequence ogni nodo risulta indipendente dallaltro garantendo apprendimenti sequenze molto lunghe
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#8,8,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14
9 ...",dati ciente riusciresti memorizzare due sequenze
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#9,9,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14  
Se riconosci il pattern ""tutti i numeri pari dal 50 al 14"" ti sarà più facile 
ricordare la seconda.
10 ...",dati ciente riusciresti memorizzare due sequenze riconosci pattern tutti numeri pari facile ricordare seconda
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Generative Adversarial Networks
1",deep learning universit roma tre dipartimento ingegneria anno accademico generative adversarial networks
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#1,1,"Sommario
Apprendimento discriminativo e generativo  
Generatie adversarial networks (GANs)  
Deep Convolutional Generative Adversarial Networks",sommario apprendimento discriminativo generativo generatie adversarial networks ans deep convolutional generative adversarial networks
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#10,10,"GAN e Keras: Generatore e Discriminatore
   
for
 epoch 
in 
range
(num_epochs):
        timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
)  
# loss_D, loss_G, num_examples
        
 for
 (X,) 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(
                mean=
 0
, stddev=
 1
, shape=(batch_size, latent_dim))
            metric.add(update_D(X, Z, net_D, net_G, loss, optimizer_D),
                       update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
        
 # Visualizzazione dei dati generati
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, shape=(
 100
, latent_dim))
        fake_X = net_G(Z)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].scatter(data[:, 
 0
], data[:, 
 1
])
        animator.axes[
 1
].scatter(fake_X[:, 
 0
], fake_X[:, 
 1
])
        animator.axes[
 1
].legend([
 ""real""
, 
""generated""
 ])
        
 # Visualizzazione delle loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch + 
 1
, (loss_D, loss_G))
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec'
 )
11",keras generatore discriminatore epoch range numepochs timer dltimer metric loss loss numexamples dataiter batchsize xshape mean stddev latentdim net net loss optimizer update net net loss optimizer batchsize visualizzazione dati generati stddev shape latentdim fake net animatoraxes cla animatoraxes data animatoraxes scatterfake fake animatoraxes legend real generated visualizzazione loss loss loss metric metric metric metric loss loss print loss loss loss loss metric timerstop examplessec
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#11,11,"GAN e Keras: Generatore e Discriminatore
Speci
 ﬁ
chiamo gli iperparametri per fare 
 ﬁ
tting di una distribuzione gaussiana:  
lr_D, lr_G, latent_dim, num_epochs = 
 0.05
, 
0.005
, 
2
, 
20
train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G,
      latent_dim, data[:
 100
].numpy())
> 
loss_D 
0.693
, loss_G 
 0.693
, 
333.2
 examples/sec
12
",keras generatore discriminatore speci chiamo iperparametri fare tting distribuzione gaussiana latentdim numepochs trainnet net dataiter numepochs latentdim data numpy loss loss examplessec
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#12,12," Deep Convolutional Generative Adversarial 
Nelle GAN abbiamo visto come i campioni generati provengano perloppiù da 
distribuzioni uniformi o normali, che sono poi trasformati in istanze che 
corrispondono alle distribuzioni di un certo dataset di dati reali.  
Per generare campioni più complessi (es. immagini fotorealistiche) sono 
necessarie architetture più complesse come le 
 Deep Convolutional GANs 
(DCGAN)
 . 
13",deep convolutional generative adversarial visto campioni generati provengano perloppi distribuzioni uniformi normali poi trasformati istanze corrispondono distribuzioni certo dataset dati reali generare campioni complessi immagini necessarie architetture complesse deep convolutional ans
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#13,13,"DCGAN - Keras (1)
Il dataset è la collezione di Pokemon sprites, ottenuto da pokemondb.  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
d2l.DATA_HUB[
 'pokemon'
 ] = (d2l.DATA_URL + 
 'pokemon.zip'
 ,
                           
 'c065c0e2593b8b161a2d7873e42418bf6a21106c'
 )
data_dir = d2l.download_extract(
 'pokemon'
 )
batch_size = 
 256
pokemon = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir, batch_size=batch_size, image_size=(
 64
, 
64
)
)
Ridimensiono ogni immagini in 64x64. I valori sono in [0,1], mentre il generatore usa la 
 tanh
 e 
genera campioni con pixel in [-1,1]. Normalizziamo i dati con media e deviazione standard pari 
a 0.5.  
def 
transform_func
 (
X
):
    X = X / 
 255
.
    X = (X - 
 0.5
) / (
0.5
)
    
return
 X
data_iter = pokemon.
 map
(
lambda
 x, y: (transform_func(x), y),
                        num_parallel_calls=tf.data.experimental.AUTOTUNE)
data_iter = data_iter.cache().shuffle(buffer_size=
 1000
).prefetch(
    buffer_size=tf.data.experimental.AUTOTUNE)
14",keras dataset collezione pokemon sprites ottenuto pokemondb import tensorflow pip install apost import tensorflow dld pokemon dld pokemonzip datadir pokemon batchsize pokemon datadir imagesize ridimensiono ogni immagini valori mentre generatore usa tanh genera campioni pixel normalizziamo dati media deviazione standard pari def transformfunc return dataiter pokemon map lambda dataiter prefetch
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#14,14,"DCGAN - Keras (2)
d2l.set_figsize(figsize=(
 4
, 
4
))
for
 X, y 
in
 data_iter.take(
 1
):
    imgs = X[:
 20
, :, :, :] / 
 2
 + 
0.5
    d2l.show_images(imgs, num_rows=
 4
, num_cols=
 5
)
Il generatore deve mappare una 
 noise variabile  
 e un vettore di dimensione 
 d
 ad una  
immagine 64x64.  
Usiamo la 
 Conv2DTranspose
  per incrementare  
la risoluzione in input, seguita da una 
 batch normalization  
e attivazione ReLU.  
class 
G_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
strides
=
2
, 
padding
=
""same""
,
                 **
 kwargs
):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d_trans = tf.keras.layers.Conv2DTranspose(
            out_channels, kernel_size, strides, padding, use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.ReLU()
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d_trans(X)))
z
∈
ℝ
d
15
",keras dataitertake imgs numrows numcols generatore deve mappare noise variabile vettore dimensione immagine usiamo conv dtranspose incrementare risoluzione input seguita batch normalization attivazione class gblock keras layers layer def init self outchannels kernelsize strides padding same kwargs super init kwargs self convdtrans dtranspose outchannels kernelsize strides padding usebias false self batchnorm normalization self activation def call self return self activation self batchnorm self
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#15,15,"DCGAN - Keras (3)
Di default abbiamo
  kernel 4x4, stride 2x2 e same padding.  
Con un input 16x16, il generatore raddoppia larghezza e altezza dell'input.  
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))  
# creiamo un dato sintetico
g_blk = G_block(
 20
)
g_blk(x).shape
> TensorShape([2, 32, 32, 20]
 )
Se usiamo un kernel 4x4, stride 1x1 e zero padding, con un input 1x1, l'output avrà 
larghezza e altezza incrementati di 3.  
x = tf.zeros((2, 1, 1, 3)
 )
# padding=""valid"" corresponds to no padding
g_blk = G_block(
 20
, strides=
 1
, padding=
 ""valid""
)
g_blk(x).shape
> TensorShape([2, 4, 4, 20])
16
",keras default kernel stride padding input generatore raddoppia larghezza altezza dellinput tfzeros creiamo dato sintetico gblk gblock gblkxshape tensor shape usiamo kernel stride zero padding input loutput larghezza altezza incrementati tfzeros paddingvalid corresponds padding gblk gblock strides padding valid gblkxshape tensor shape
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#16,16,"DCGAN - Keras (4)
Il 
generatore
  consiste in 4 blocchi base che incrementano ampiezza e altezza 
da 1 a 32. Inizialmente mappa le variabili latenti in 64x8 canali, e poi 
dimezza i canali ogni volta. In
 ﬁ
ne, un
  transposed convolution layer 
 genera 
l'output raddoppiando la dimensione a 64x64 e riducendo i canali a 3 per 
rispettare l'output desiderato. La funzione di attivazione 
 tanh
 è usata per 
generare output in (-1,1).  
n_G = 
64
net_G = tf.keras.Sequential([
    
# Output: (4, 4, 64 * 8)
    G_block(out_channels=n_G*
 8
, strides=
 1
, padding=
 ""valid""
),
    G_block(out_channels=n_G*
 4
), 
# Output: (8, 8, 64 * 4)
    G_block(out_channels=n_G*
 2
), 
# Output: (16, 16, 64 * 2)
    G_block(out_channels=n_G), 
 # Output: (32, 32, 64)
    
# Output: (64, 64, 3)
    tf.keras.layers.Conv2DTranspose(
        
 3
, kernel_size=
 4
, strides=
 2
, padding=
 ""same""
, use_bias=
 False
,
        activation=
 ""tanh""
)
])
17",keras generatore consiste blocchi base incrementano ampiezza altezza inizialmente mappa variabili latenti canali poi dimezza canali ogni volta transposed convolution layer genera loutput raddoppiando dimensione riducendo canali rispettare loutput desiderato funzione attivazione tanh usata generare output net output strides padding valid output output output output dtranspose kernelsize strides padding same usebias false activation tanh
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#17,17,"Richiami: Leaky ReLU
La leaky ReLU è  utile per affrontare il dying ReLU.  
alphas = [
 0
, 
.2
, 
.4
, 
.6
, 
.8
, 
1
]
x = tf.
range
(
-2
, 
1
, 
0.1
)
Y = [tf.keras.layers.LeakyReLU(alpha)(x).numpy() 
 for
 alpha 
in
 alphas]
d2l.plot(x.numpy(), Y, 
 'x'
, 
'y'
, alphas)
18
",richiami leaky leaky utile affrontare dying alphas range alpha alphas alphas
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#18,18,"DCGAN - Keras (5)
Il blocco base del discriminatore è un convolution layer seguito da 
 batch 
normalization
  (tranne per l'input layer) e leaky ReLU activation. Gli 
iperparametri sono simili a quelli impiegati al blocco generatore.  
class 
D_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
                 
 strides
=
2
, 
padding
=
""same""
, 
alpha=
0.2
, **kwargs):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d = tf.keras.layers.Conv2D(out_channels, kernel_size,
                                             strides, padding,  
                                      use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.LeakyReLU(alpha)
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d(X))
 )
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))
d_blk = D_block(
 20
)
d_blk(x).shape
> TensorShape([2, 8, 8, 20])
19",keras blocco base discriminatore convolution layer seguito batch normalization tranne linput layer leaky activation iperparametri simili impiegati blocco generatore class dblock keras layers layer def init self outchannels kernelsize strides padding same alpha kwargs super init kwargs self convd doutchannels kernelsize strides padding usebias false self batchnorm normalization self activation lualpha def call self return self activation self batchnorm self convdx tfzeros dblk dblock dblkxshape tensor shape
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#19,19,"DCGAN - Keras (6)
Per un input shape 16x16 e un kernel 4x4 e stride 2 e same padding:  
n_D = 
64
net_D = tf.keras.Sequential([
    D_block(n_D), 
 # Output: (32, 32, 64)
    D_block(out_channels=n_D*
 2
), 
# Output: (16, 16, 64 * 2)
    D_block(out_channels=n_D*
 4
), 
# Output: (8, 8, 64 * 4)
    D_block(out_channels=n_D*
 8
), 
# Outupt: (4, 4, 64 * 64)
    
# Output: (1, 1, 1)
    tf.keras.layers.Conv2D(
 1
, kernel_size=
 4
, use_bias=
 False
)
]
)
x = tf.zeros((
 1
, 
64
, 
64
, 
3
))
net_D(x).shape
> TensorShape([1, 1, 1, 1]) # Predizione: Singolo valore
20
",keras input shape kernel stride padding net dblockn output output output outupt output kernelsize usebias false tfzeros net dxshape tensor shape predizione singolo valore
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#2,2,"Apprendimento discriminativo e generativo
Finora abbiamo trattato il 
 discriminative learning
 , cioè un apprendimento 
capace di distinguere le differenti istanze, cioè le relative caratteristiche, e 
classi
 ﬁ
carle, o fare predizione. In molti task arriviamo a livelli di accuratezza 
comparabili a quelli umani.  
Ci sono altri casi in cui vogliamo analizzare grossi dataset senza labels per 
creare un modello che ne descrive le caratteristiche. Con tale modello 
possiamo creare esempi di dato 
 sintetici
  che assomigliano a quelli reali. Tale 
approccio si chiama 
 generative learning
 . 
•
Es. le reti ricorrenti sono un esempio di un modello discriminativo che può 
essere impiegato anche per generare nuove istanze.
3",apprendimento discriminativo generativo finora trattato discriminative learning cio apprendimento capace distinguere differenti istanze cio relative classi carle fare predizione molti task arriviamo livelli accuratezza comparabili umani altri casi vogliamo analizzare grossi dataset senza labels creare modello descrive tale modello possiamo creare esempi dato sintetici assomigliano reali tale approccio chiama generative learning reti ricorrenti esempio modello discriminativo pu essere impiegato generare nuove istanze
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#20,20,"Richiami: Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
s
+
ϵ
β
1
21Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘s+ϵ",richiami adam optimization adam adaptive moment estimation combinazione momentum optimization prop indica literazione corrente rispetto momentum prima espressione introduce decay gradienti espressione utili incrementare valore allinizio training valori iniziali pari momentum prop prop mm ss j js
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#21,21,"DCGAN - Keras (7)
Rispetto alle GAN usiamo lo stesso 
 learning rate
  per il generatore e 
discriminatore essendo architetture simili. Portiamo 
  in Adam da 0.9 (spesso 
usato come default) a 0.5.  
Decrementiamo lo 
 smooth
  del momentum, la weighted moving average 
esponenziale dei passati gradienti, per tenere traccia più puntuale delle 
variazioni rapide dei gradienti a causa dell'instabilità creata dal discriminatore-
generatore.  
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr
, 
latent_dim
 ,
          
 device
=d2l.try_gpu()):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_hp = {
 ""lr""
: lr, 
""beta_1""
 : 
0.5
, 
""beta_2""
 : 
0.999
}
    optimizer_D = tf.keras.optimizers.Adam(**optimizer_hp)
    optimizer_G = tf.keras.optimizers.Adam(**optimizer_hp)
β
1
22",keras rispetto usiamo stesso learning rate generatore discriminatore architetture simili portiamo adam spesso usato default decrementiamo smooth momentum weighted moving average esponenziale passati gradienti tenere traccia puntuale variazioni rapide gradienti causa creata discriminatore generatore def train net net dataiter numepochs latentdim device loss crossentropy fromlogits true net stddev shapewshape net stddev shapewshape optimizerhp beta beta optimizer optimizer
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#22,22,"DCGAN - Keras (8)
    animator = d2l.Animator(xlabel=
 'epoch'
, ylabel=
 'loss'
,
                          xlim=[
 1
, num_epochs], nrows=
 2
, figsize=(
 5
, 
5
),
                          legend=[
 'discriminator'
 , 
'generator'
 ]
)
    animator.fig.subplots_adjust(hspace=
 0.3
)
    
for
 epoch 
in 
range
(
1
, num_epochs + 
 1
):
 
       timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
) 
# loss_D, loss_G, num_examples
        
 for
 X, _ 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(mean=
 0
, stddev=
 1
,
                                 shape=(batch_size, 
 1
, 
1
, latent_dim))
            metric.add(d2l.update_D(X, Z, net_D, net_G, loss,  
                                                           optimizer_D),
                       d2l.update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
23",keras animator epoch ylabel loss xlim numepochs nrows figsize legend discriminator generator epoch range numepochs timer dltimer metric loss loss numexamples dataiter batchsize xshape stddev latentdim net net loss optimizer dlupdate net net loss optimizer batchsize
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#23,23,"DCGAN - Keras (9)
        
 # Visualizziamo i dati generti
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, 
                                        shape=(
 21
, 
1
, 
1
, latent_dim))
        
 # Normalizziamo i dati generati in (0,1)
        fake_x = net_G(Z) / 
 2
 + 
0.5
        imgs = tf.concat([tf.concat([fake_x[i*
 7
+j] 
for
 j 
in 
range
(
7
)],
                                    axis=
 1
)
                          
 for
 i 
in 
range
(
len
(fake_x) // 
 7
)], axis=
 0
)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].imshow(imgs)
        
 # Visualizziamo le loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch, (loss_D, loss_G)
 )
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec on  
                                      
 {
str
(device._device_name)}
 '
)
24",keras visualizziamo dati generti stddev shape latentdim normalizziamo dati generati fakex net imgs range axis range len fakex axis animatoraxes cla animatoraxes imshowimgs visualizziamo loss loss loss metric metric metric metric loss loss print loss loss loss loss metric timerstop examplessec str
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#24,24,"DCGAN - Keras (10)
latent_dim, lr, num_epochs = 
 100
, 
0.0005
, 
40
train(net_D, net_G, data_iter, num_epochs, lr, latent_dim)
> loss_D 0.217, loss_G 3.687, 2310.5 examples/sec on /GPU:
 0
25
",keras latentdim numepochs trainnet net dataiter numepochs latentdim loss loss examplessec
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#3,3,"Generative adversarial networks
Nel 2014 sono state introdotte le 
 Generative adversarial networks (GAN)
 , un 
modello che sfrutta un approccio 
 discriminativo
  per generare modelli 
generativi:  
•
L'idea è che un modello generativo è buono se non riusciamo a distinguere i 
dati generati da quelli reali.  
Dal punto di vista statistico corrisponde ad un 
 2-sample test
 : misurare se due 
sequenze di istanze 
 X
= {
x
1
, ..., 
x
n
} e 
X'
= {
x'
1
, ..., 
x'
n
} sono ottenute dalla stessa 
distribuzione.  
Nelle GAN tale test è usato dal modello generativo per adattarsi a creare 
istanze sempre più simili ai casi reali.  
•
In pratica, cerchiamo di ""bidonare"" il classi
 ﬁ
catore reale/fake. 
4",generative adversarial networks state introdotte generative adversarial networks modello sfrutta approccio discriminativo generare modelli generativi lidea modello generativo buono riusciamo distinguere dati generati reali punto vista statistico corrisponde sample test misurare due sequenze istanze ottenute stessa distribuzione tale test usato modello generativo adattarsi creare istanze sempre simili casi reali pratica cerchiamo bidonare classi catore realefake
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#4,4,"Generative adversarial networks (GANs)
L'architettura include un 
 generative network
 , nel nostro caso una deep 
network, che ha lo scopo di generare istanze simili a quelle reali (es. segnale 
di voce umana, immagini di visi). Il 
 discriminative network
  cerca di 
distinguere dati reali da quelli generate (o fake).  
Il 
discriminator
  è implementato come un classi
 ﬁ
catore binario che produce 
uno scalare per ogni input 
 x 
(es. una FC con 1 layer e funzione di attivazione 
sigmoid
  per convertire lo scalare in probabilità). Assumiamo che la label 
corrispondente sia 1 per una istanza da dati reali, 0 per una fake creata dal 
generatore.  
Il generatore mira a generare una immagine più  
vicina possibile alle immagini reali, e per ottenere  
dal discriminatore il relativo output corrispondente  
a ""il dato e' real"".
5
",generative adversarial networks ans larchitettura include generative network caso deep network scopo generare istanze simili reali segnale voce umana immagini visi discriminative network cerca distinguere dati reali generate fake discriminator implementato classi catore binario produce scalare ogni input layer funzione attivazione sigmoid convertire scalare probabilit assumiamo label corrispondente istanza dati reali fake creata generatore generatore mira generare immagine vicina possibile immagini reali ottenere discriminatore relativo output corrispondente dato real
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#5,5,"Generative adversarial networks (GANs)
Il 
discriminatore
  mira a distinguere immagini generate da immagini reali minimizzando 
la 
cross-entropy loss:  
 
dove 
 D
(x) = 1/(1 + 
 e
-o
) è la probabilità ottenuta con la 
 sigmoid
  a partire dallo scalare 
 o.  
Collezionando in modo casuale 
  (es. con distribuzione normale), dove 
  riveste il 
compito di 
 variabile latente,
  il compito del 
 generatore
  è di bidonare il discriminatore per 
classi
 ﬁ
care 
 x'=G(z)
  come ""dato reale"", cioè vogliano D(G(z)) ≈ 1.  
In altre parole, dato un discriminatore D, aggiorniamo i parametri del generatore per 
massimizzare la 
 cross-entropy loss 
 quando y=0, cioè 
 dato fake
 : 
 
Se il generatore si comporta in modo ottimale, D(x') è circa 1, cosicché la loss è vicina 
allo 0, e perciò i gradienti sono assai ridotti per generare progressi per il discriminatore. 
Minimizzeremo perciò la seguente loss:  
 
che è il feed x'=G(z) nel discriminatore dando il label 1.  
min
 D
{
−
y
 log 
D
(
x
)
−
(
1
−
y
)
 log
(
1
−
D
(
x
)
)
}
z
∈
ℝ
D
z
max
 G
{
−
(
1
−
y
)
 log 
(
1
−
D
(
G
(
z
)
)
)
}
=
max
 G
{
−
 log 
(
1
−
D
(
G
(
z
)
)
)
}
min
 G
{
−
y
 log 
(
D
(
G
(
z
)
)
)
}
=
min
 G
{
−
 log 
(
D
(
G
(
z
)
)
)
}
6",generative adversarial networks ans discriminatore mira distinguere immagini generate immagini reali minimizzando cross entropy loss probabilit ottenuta sigmoid partire scalare collezionando modo casuale distribuzione normale riveste compito variabile latente compito generatore bidonare discriminatore classi care xgz dato reale cio vogliano dgz altre parole dato discriminatore aggiorniamo parametri generatore massimizzare cross entropy loss quando cio dato fake generatore comporta modo ottimale circa cosicch loss vicina perci gradienti assai ridotti generare progressi discriminatore minimizzeremo perci seguente loss feed xgz discriminatore dando label min log log max log max log min log min log
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#6,6,"GAN e Keras (1)
Generiamo dati con un modello gaussiano:  
X = tf.random.normal((1000, 2), 0.0, 1
 )
A = tf.constant([[1, 2], [-0.1, 0.5]]
 )
b = tf.constant([1, 2], tf.float32
 )
data = tf.matmul(X, A) + 
 b
Otteniamo una gaussiana traslata in modo arbitrario con media 
 b
 e covarianza 
A
T
A
. 
d2l.set_figsize(
 )
d2l.plt.scatter(data[:100, 0].numpy(), data[:100, 1].numpy())
 ;
print(f'The covariance matrix is\n{tf.matmul(A, A, transpose_a=True)}'
 )
> The covariance matrix i
 s
> [[1.01 1.95
 ]
> [1.95 4.25]
 ]
batch_size = 
 8
data_iter = d2l.load_array((data,), batch_size)
7
",keras generiamo dati modello gaussiano tfconstant tffloat data tfmatmulx otteniamo gaussiana traslata modo arbitrario media covarianza numpy data numpy printfthe covariance matrix covariance matrix batchsize dataiter batchsize
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#7,7,"GAN e Keras: Generatore e Discriminatore
Il generatore è un semplice layer lineare.  
net_G = tf.keras.layers.Dense(2
 )
Per il discriminatore usiamo una MLP a 3 layer:  
net_D = tf.keras.models.Sequential(
 [
    tf.keras.layers.Dense(5, activation=""tanh"", input_shape=(2,))
 ,
    tf.keras.layers.Dense(3, activation=""tanh"")
 ,
    tf.keras.layers.Dense(1
 )
]
)
De
ﬁ
niamo una funzione per aggiornare il 
 discriminatore
 : 
def 
update_D
 (
X
, 
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_D
 ):
    batch_size = X.shape[
 0
]
    ones = tf.ones((batch_size,)) 
 # Labels corrispondenti ai dati reali
    zeros = tf.zeros((batch_size,)) 
 # Labels corrispondenti ai dati fake
    
# Ignoriamo i gradienti per `net_G` all'interno di GradientTape
    fake_X = net_G(Z)
    
with
 tf.GradientTape() 
 as
 tape:
        real_Y = net_D(X)
        fake_Y = net_D(fake_X)
        loss_D = (loss(ones, tf.squeeze(real_Y)) + loss(
            zeros, tf.squeeze(fake_Y))) * batch_size / 
 2
    grads_D = tape.gradient(loss_D, net_D.trainable_variables)
    optimizer_D.apply_gradients(
 zip
(grads_D, net_D.trainable_variables))
    
return
 loss_D
8",keras generatore discriminatore generatore semplice layer lineare net discriminatore usiamo layer net niamo funzione aggiornare discriminatore def update net net loss optimizer batchsize xshape ones labels corrispondenti dati reali zeros labels corrispondenti dati fake ignoriamo gradienti net allinterno gradient tape fake net tfgradient tape tape real net fake net dfake loss lossones loss zeros batchsize grads net optimizer zip grads net return loss
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#8,8,"GAN e Keras: Generatore e Discriminatore
Il generatore sarà aggiornato in modo simile. Riutilizziamo la cross-entropy 
loss ma cambiamo la label dei dati fake da 0 a 1  
def 
update_G
 (
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_G
 ):
    batch_size = Z.shape[
 0
]
    ones = tf.ones((batch_size,))
    
with
 tf.GradientTape() 
 as
 tape:
        fake_X = net_G(Z)
 
       fake_Y = net_D(fake_X)
       loss_G = loss(ones, tf.squeeze(fake_Y)) * batch_size
    grads_G = tape.gradient(loss_G, net_G.trainable_variables)
    optimizer_G.apply_gradients(
 zip
(grads_G, net_G.trainable_variables))
    
return
 loss_G
Sia il discriminatore sia il generatore operano una
  logistic regression binaria 
con cross-entropy loss. Usiamo 
 Adam
  per rendere smooth il processo di 
training. Ad ogni iterazione, prima aggiorniamo il discriminatore e poi il 
generatore. 
9",keras generatore discriminatore generatore aggiornato modo simile riutilizziamo cross entropy loss cambiamo label dati fake def update net net loss optimizer batchsize zshape ones tfgradient tape tape fake net fake net dfake loss lossones batchsize grads net optimizer zip grads net return loss discriminatore generatore operano logistic regression binaria cross entropy loss usiamo adam rendere smooth processo training ogni iterazione prima aggiorniamo discriminatore poi generatore
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#9,9,"GAN e Keras: Generatore e Discriminatore
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr_D
, 
lr_G
, 
latent_dim
 , 
data
):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_D = tf.keras.optimizers.Adam(learning_rate=lr_D)
    optimizer_G = tf.keras.optimizers.Adam(learning_rate=lr_G)
    animator = d2l.Animator(
        xlabel=
 ""epoch""
, ylabel=
 ""loss""
, xlim=[
 1
, num_epochs], nrows=
 2
,
        figsize=(
 5
, 
5
), legend=[
 ""discriminator""
 , 
""generator""
 ])
    animator.fig.subplots_adjust(hspace=
 0.3
)
   ...
10",keras generatore discriminatore def train net net dataiter numepochs latentdim data loss crossentropy fromlogits true net stddev shapewshape net stddev shapewshape optimizer optimizer animator dlanimator xlabel epoch ylabel loss xlim numepochs nrows figsize legend discriminator generator
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recommender Systems
1",deep learning universit roma tre dipartimento ingegneria anno accademico recommender systems
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#1,1,"Sommario
MovieLens dataset  
AutoRec  
Implicit feedback (richiami)ù  
Neural Collaborative Filtering (NCF)  
Caser e Sequence-aware Recsys  
Factorization Machines e Deep FM",sommario movie lens dataset auto rec implicit feedback richiami neural collaborative filtering caser sequence aware recsys factorization machines deep
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#10,10,"Neural Collaborative Filtering for Personalized Ranking
L'output del penultimo layer di entrambe le reti è concatenato è dato in input 
al NeuMF layer:
11
",neural collaborative filtering personalized ranking loutput penultimo layer entrambe reti concatenato dato input neu layer
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#11,11,"Sequence-aware recommender systems
Spesso gli utenti operano una sequenza di azioni nei servizi online il cui 
ordine temporale può essere signi
 ﬁ
cativo nel processo di raccomandazione.  
Il modello 
 Caser 
 (Convolutional sequence embedding recommendation 
model) sfrutta le CNN, in particolare 
 horizontal
  e 
vertical
  convolutional 
networks, per identi
 ﬁ
care rispettivamente pattern sequenziali 
 union-level
  e 
point-level
  di tipo short-term.  
I pattern 
 point-level
  identi
 ﬁ
cano l'in
 ﬂ
uenza di un item all'interno di una 
sequenza verso un certo item target. L'union-level analizza l'in
 ﬂ
uenza di varie 
azioni fatte sul valore target (es. l'acquisto di latte e burro può implicare 
l'acquisto di farina).  
I bisogni di lungo termine sono rappresentati nei layer FC 
 ﬁ
nali.
12",sequence aware recommender systems spesso utenti operano sequenza azioni servizi online ordine temporale pu essere signi cativo processo modello caser convolutional sequence embedding recommendation model sfrutta particolare horizontal vertical convolutional networks identi care rispettivamente pattern sequenziali union level point level tipo short term pattern point level identi cano lin uenza item allinterno sequenza verso certo item target lunion level analizza lin uenza varie azioni fatte valore target lacquisto latte burro pu implicare lacquisto farina bisogni lungo termine rappresentati layer nali
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#12,12,"Sequence-aware recommender systems
Supponiamo che ogni utente u sia associato ad una sequenza di items 
. Se prendiamo i passati 
 L
 items, possiamo costruire una 
matrice che rappresenta le interazioni passati con tali items rispetto al time 
step 
t
. 
Dove 
  rappresenta sempre lo spazio di embedding e 
 q
i
 indica la 
 i
-
ma riga. 
  è usata per ottenere i bisogni transienti dell'utente 
 u
 per 
il time step 
 t
, ed è l'input per i successivi convolutional layers:  
•
L'horizontal layer ha 
 d 
ﬁ
ltri orizzontali 
 . 
•
Il vertical layer ha d' 
 ﬁ
ltri verticali  
Dopo una serie di operatori convoluzionali e di pooling otteniamo gli output 
 e 
 :
S
u
=
(
S
u
1
,
⋯
,
S
u
|
S
u
|
)
Q
∈
ℝ
n
×
k
E
(
u
,
t
)
∈
ℝ
L
×
k
F
j
∈
ℝ
h
×
k
,
i
≤
j
≤
d
,
h
=
{
1,
⋯
,
L
}
G
j
∈
ℝ
L
×
1
,
i
≤
j
≤
d
′ 
o
∈
ℝ
d
o
′ 
∈
ℝ
d
′ 
13
",sequence aware recommender systems supponiamo ogni utente associato sequenza items prendiamo passati items possiamo costruire matrice rappresenta interazioni passati tali items rispetto time step rappresenta sempre spazio embedding indica riga usata ottenere bisogni transienti dellutente time step linput successivi convolutional layers lhorizontal layer ltri orizzontali vertical layer ltri verticali dopo serie operatori convoluzionali pooling otteniamo output
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#13,13,"Sequence-aware recommender systems
Gli output sono concatenati e dati in input ad una MLP per ricavarne 
rappresentazioni ad alto livello:  
L'output 
  indica i bisogni a breve termine dell'utente.  
I bisogni a lungo termine dell'utente sono ricavati:  
dove 
  è una ulteriore embedding matrix, e  
  è la 
 user 
embedding matrix
  per i bisogni a lungo termine. 
  e 
  sono la 
u
-ma riga e 
 i
-ma riga rispettivamente di 
 P
 e 
V
.
z
∈
ℝ
k
V
∈
ℝ
n
×
2
k
P
∈
ℝ
m
×
k
p
u
∈
ℝ
k
v
i
∈
ℝ
2
k
14
",sequence aware recommender systems output concatenati dati input ricavarne alto livello loutput indica bisogni breve termine dellutente bisogni lungo termine dellutente ricavati ulteriore embedding matrix user embedding matrix bisogni lungo termine riga riga rispettivamente
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#14,14,"Sequence-aware recommender systems
L'architettura generale di Caser è così rappresentata:
15
",sequence aware recommender systems larchitettura generale caser cos rappresentata
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#15,15,"Addestramento e architetture sequenziali
In modo simile all'addestramento RNN, in presenza di dati con timestamp che 
rappresentano azioni tra utenti e items (es. l'utente ha lasciato un rating su un 
ﬁ
lm), possiamo costruire un dataset di addestramento creando sequenze di 
dimensione prede
 ﬁ
nita, ad esempio:
16
",addestramento architetture sequenziali modo simile presenza dati timestamp rappresentano azioni utenti items lutente lasciato rating possiamo costruire dataset addestramento creando sequenze dimensione prede nita esempio
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#16,16,"Factorization Machines
Le FM sono algoritmi supervisionati che possono essere impiegati in contesti 
di classi
 ﬁ
cazione, regressione e ranking. Si ispirano a modelli di regressione 
lineare, modelli di MF e Support vector machines con kernel polinomiali.  
Mostrano vantaggi in caso di dataset sparsi riducendo notevolmente il tempo 
di addestramento. Inoltre individuano più facilmente correlazioni signi
 ﬁ
cative 
tra i dati.  
Se indichiamo con 
  il vettore delle feature per una certa istanza, e con 
y la label numerica associata (es. 4.5 oppure click/no-click), formalizziamo il 
modello in questo modo:  
dove 
  è il bias globale, 
  sono i pesi per la i-ma variabile, 
 sono i feature embeddings, e 
 v
i
 è la i-ma riga di 
 V
, <v
 i
,v
j
> è il 
prodotto vettoriale tra i 2 vettori è modella l'interazione tra la 
 i
-ma e 
 j
-ma 
feature.
x
∈
ℝ
d
w
0
∈
ℝ
 w
∈
ℝ
d
V
∈
ℝ
d
×
k
17
",factorization machines algoritmi supervisionati possono essere impiegati contesti classi cazione regressione ranking ispirano modelli regressione lineare modelli support vector machines kernel polinomiali mostrano vantaggi caso dataset sparsi riducendo notevolmente tempo addestramento inoltre individuano facilmente correlazioni signi cative dati indichiamo vettore feature certa istanza label numerica associata oppure clickno click formalizziamo modello modo bias globale pesi variabile feature embeddings riga prodotto vettoriale vettori modella linterazione feature
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#17,17,"Factorization Machines
Nell'espressione precedente si può notare una prima componente che 
rappresenta il modello di regressione lineare, mentre il secondo estende un 
modello di MF:  
Se la feature 
 i
 rappresenta un item, e la feature 
 j
 un utente, il terzo termine è il 
prodotto scalare tra i due embedding, uno dell'utente ed uno dell'item. 
18
",factorization machines precedente pu notare prima componente rappresenta modello regressione lineare mentre secondo estende modello feature rappresenta item feature utente terzo termine prodotto scalare due embedding dellutente dellitem
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#18,18,"Deep Factorization Machines
In alcuni scenari l'approccio lineare delle FM non è suf
 ﬁ
ciente per 
rappresentare correlazioni e patterns complessi. Ma è possibile integrare 
approcci ""deep"" nel FM per rappresentare interazioni tra features nei dati.  
Nel 
DeepFM
  la componente FM e deep sono combinate in modo 
 parallelo
 . La 
FM è simile all'architettura originale. La deep è implementata con una MLP. 
L'input/embeddings delle 2 componenti è il medesimo, l'output è 
 sommato  
per creare la predizione 
 ﬁ
nale.  
La DeepFM si ispira allearchitetture RecSys chiamate 
 wide & deep
 . In tali 
architetture la predizione combina due pipeline:  
•
la 
memorizzazione
  mira a rappresentare co-occorrenze frequenti tra items o 
features nei dati storici. Si implementa con un modello lineare (es. logistic 
regression)  
•
la 
generalizzazione
  punta a implementare la ""transitività"" delle correlazioni, 
cioè esplorare combinazioni signi
 ﬁ
cative tra features che non sono state mai 
incontrate nel passato. La pipeline è generalmente basata su una MLP.
19",deep factorization machines alcuni scenari lapproccio lineare suf ciente rappresentare correlazioni patterns complessi possibile integrare approcci deep rappresentare interazioni features dati deep componente deep combinate modo parallelo simile originale deep implementata componenti medesimo loutput sommato creare predizione nale deep ispira rec sys chiamate wide deep tali architetture predizione combina due pipeline memorizzazione mira rappresentare occorrenze frequenti items features dati storici implementa modello lineare logistic regression punta implementare transitivit correlazioni cio esplorare combinazioni signi cative features state mai incontrate passato pipeline generalmente basata
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#19,19,"Deep Factorization Machines
Supponiamo che l'output della FM sia 
 . Indichiamo con 
  il vettore 
delle feature latenti del campo 
 i
-mo.  
L'input della componente deep è la concatenazione degli embeddings di tutti 
i campi associati alle 
 f
 feature categoriche date in input:  
La rete neurale è cosi de
 ﬁ
nita: 
L'output 
  è combinato con il precedente per generare l'output 
 ﬁ
nale:  
 
̂
y
(
F
M
)
e
i
∈
ℝ
k
̂
y
(
D
N
N
)
̂
y
=
σ
(
h
a
t
y
(
D
N
N
)
+
̂
y
(
D
N
N
)
)
20
",deep factorization machines supponiamo loutput indichiamo vettore feature latenti campo linput componente deep concatenazione embeddings campi associati feature categoriche date input rete neurale cosi nita loutput combinato precedente generare loutput nale
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#2,2,"Motivazioni
I 
sistemi di raccomandazione
  sono strumenti chiave in molti scenari: e-
commerce, siti per la fruizione di musica e video (es. Spotify, Net
 ﬂ
ix), app 
stores, pubblicità, etc.  
•
Alcune conferenze internazionali speci
 ﬁ
che nel settore (es. RecSys) 
attraggono i maggiori players che fanno a gara per aggiudicarsi i migliori 
ricercatori.  
Supponiamo nel resto dei lucidi che alcuni argomenti sia già noti dai 
precedenti corsi:  
•
Collaborative 
 ﬁ
ltering  
•
Explicit e Implicit feedback  
•
Recommendation tasks (es. rating vs top-n vs sequence aware 
recommendation
3",motivazioni sistemi raccomandazione strumenti chiave molti scenari commerce siti fruizione musica video spotify net app stores pubblicit etc alcune conferenze internazionali speci settore rec sys attraggono maggiori players gara aggiudicarsi migliori ricercatori supponiamo resto lucidi alcuni argomenti gi noti precedenti corsi collaborative ltering explicit implicit feedback recommendation tasks rating top sequence aware recommendation
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#20,20,"Deep Factorization Machines
L'architettura DeepFM è la seguente:
21
",deep factorization machines larchitettura deep seguente
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#3,3,"MovieLens dataset
Il dataset più popolare nel mondo accademico 
 RecSys
 . Ne esistono diverse 
versioni in base alla quantità di dati contenuti.  
•
In 
MovieLens 100K
  sono contenuti 100.000 ratings espressi in una scala da 1 
a 5, da 943 utenti su 1682 
 ﬁ
lm. Ogni utente ha espresso rating su almeno 20 
ﬁ
lm. Il formato del dataset è 
 csv
. 
•
http://
 ﬁ
les.grouplens.org/datasets/movielens/ml-100k.zip  
Tecniche quali 
 Matrix Factorization
  sono state in in grado di individuare 
patterns chiave per ottenere migliori risultati rispetto ad approcci più 
tradizionali. Ma si limitano a catturare patterns e correlazioni di tipo lineare. 
4",movie lens dataset dataset popolare mondo accademico rec sys esistono diverse versioni base quantit dati contenuti movie lens contenuti ratings espressi scala utenti ogni utente espresso rating almeno formato dataset csv http kzip tecniche quali matrix factorization state grado individuare patterns chiave ottenere migliori risultati rispetto approcci tradizionali limitano catturare patterns correlazioni tipo lineare
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#4,4,"MovieLens dataset
MovieLens
  100K
  vs 
1M
5
",movie lens dataset movie lens
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#5,5,"AutoRec
In 
AutoRec
  si impiega un paradigma di Collaborative Filtering basato su 
autoencoders. Invece di rappresentare la matrice user-ratings in un spazio 
latente, o di impiegare le stesse istanze di input anche per l'output come nel 
caso degli autoencoders visti in precedenza, si segue un approccio alternativo:  
•
in 
input
  si hanno un le interazioni utente-item osservate  
•
in 
output
  ci si aspetta l'intera matrice delle interazioni utente-item  
Esistono architetture AutoRec 
 user-based 
 e 
item-based
 . Qui vedremo le 
seconde ma è facile immaginare le prime per analogia.
6",auto rec auto rec impiega paradigma collaborative filtering basato autoencoders invece rappresentare matrice user ratings spazio latente impiegare istanze input loutput caso autoencoders visti precedenza segue approccio alternativo input interazioni utente item osservate output aspetta lintera matrice interazioni utente item esistono architetture auto rec user based item based qui vedremo seconde facile immaginare prime analogia
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#6,6,"(Item-based) AutoRec
Indichiamo con 
  la i-ma colonna della matrice dei ratings. I valori di rating 
sconosciuti saranno 0.  
La rete AutoRec la possiamo de
 ﬁ
nire formalmente:  
 
dove f e g sono funzioni di attivazione, W e V matrici di pesi, 
  e 
b
 sono 
biases, 
  la ricostruzione della i-ma colonna.  
La funzione da ottimizzare è la seguente:  
 
dove il primo modulo considera solo i 
 ratings
  noti.
R
*
i
h
(
R
*
i
)
=
f
(
W
⋅
g
(
V
⋅
R
*
i
+
μ
)
+
b
)
μ
h
(
R
*
i
)
argmin
W
,
V
,
μ
,
b
M
∑
i
=
1
|
|
R
*
i
−
h
(
R
*
i
)
|
|
2
+
λ
(
|
|
W
|
|
2
F
+
|
|
V
|
|
2
F
)
)
7",item based auto rec indichiamo colonna matrice ratings valori rating sconosciuti rete auto rec possiamo nire formalmente funzioni attivazione matrici pesi biases ricostruzione colonna funzione ottimizzare seguente primo modulo considera solo ratings noti argmin
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#7,7,"Richiami: Implicit Feedback
I 
rating espliciti
  (es. valutazioni da 1 a 5) sono generalmente scarsi nei servizi 
di raccomandazione. Inoltre valori mancanti di rating possono essere 
erroneamente interpretati, es.: forme di feedback negativi invece di rating che 
devono essere ancora speci
 ﬁ
cati. 
Si tendono a sfruttare altre fonti che possono essere interpretate come forme di 
implicit feedback
 . 
•
Es. clicks, acquisti, visite, wish lists.
8",richiami implicit feedback rating espliciti valutazioni generalmente scarsi servizi inoltre valori mancanti rating possono essere erroneamente interpretati forme feedback negativi invece rating devono essere ancora speci cati tendono sfruttare altre fonti possono essere interpretate forme implicit feedback clicks acquisti visite wish lists
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#8,8,"Neural Collaborative Filtering for Personalized Ranking
Il 
Neural Collaborative Filtering (NCF)  
framework con implicit feedback 
sfrutta la capacità di 
 non-linearità 
 delle reti neurali.  
È composto da 2 reti, una basata su Generalized Matrix Factorization, l'altra 
consiste in una MLP.  
L'output delle 2 reti è concatenato per generale la predizione 
 ﬁ
nale. Se in 
AutoRec puntavamo a predire i rating, NCF produce una lista di 
raccomandazioni con score associato ad ogni item della lista.
9",neural collaborative filtering personalized ranking neural collaborative filtering framework implicit feedback sfrutta capacit linearit reti neurali composto reti basata generalized matrix factorization laltra consiste loutput reti concatenato generale predizione nale auto rec puntavamo predire rating produce lista raccomandazioni score associato ogni item lista
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#9,9,"Neural Collaborative Filtering for Personalized Ranking
La 
GMF
  è un approccio di MF implementato con reti neurali. L'input è il 
prodotto element-wise (Hadamard product) tra le rappresentazioni latenti degli 
utenti e degli item:  
Dove 
 p
u
 e 
q
i
 sono rispettivamente la u-ma riga di 
 P
 e q-ma riga di 
 Q
, dove 
 e 
 . L'output è la previsione di score dell'utente 
 u
 per 
l'item 
 i
. 
La 
MLP
 prende in input le rappresentazioni degli utenti e item, ignorando lo 
spazio latente della GMF. Lo scopo è individuare correlazioni aggiuntive con 
operazioni non lineari.
P
∈
ℝ
m
×
k
Q
∈
ℝ
n
×
k
10
",neural collaborative filtering personalized ranking approccio implementato reti neurali linput prodotto element wise hadamard product latenti utenti item rispettivamente riga riga loutput previsione score dellutente litem prende input utenti item ignorando spazio latente scopo individuare correlazioni aggiuntive operazioni lineari
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning e Natural Language Processing
1",deep learning universit roma tre dipartimento ingegneria anno accademico deep learning natural language processing
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#1,1,"Sommario
DL e NLP: motivazioni  
word2vec  
skip-gram  
CBOW  
GloVe  
fastText  
BERT",sommario motivazioni wordvec skip gram glo fast text
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#10,10,"word2vec: skip-gram (training)
Ci poniamo l'obiettivo di massimizzare la probabilità, cioè minimizzare la 
funzione:  
Se impieghiamo lo SGD, usiamo sequenze brevi per stimare il gradiente 
stocastico e aggiornare il modello. La stima è basta sul gradiente del logaritmo 
della probabilità condizionata data una coppia 
 w
o
 e 
w
c
. 
Una volta terminato l'apprendimento, i vettori 
 v
i
 sono tipicamente impiegati 
come 
 embedding
  associati ad un termine.
11
",wordvec skip gram training poniamo lobiettivo massimizzare probabilit cio minimizzare funzione impieghiamo usiamo sequenze brevi stimare gradiente stocastico aggiornare modello stima basta gradiente logaritmo probabilit condizionata data coppia volta terminato vettori tipicamente impiegati embedding associati termine
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#11,11,"word2vec: Continuous Bag of Words (CBOW)
Simile allo skip-gram ma assume che le parole contestuali generico la parola 
centrale.  
Essendoci più parole contestuali, i vettori sono mediati. La probabilità 
condizionata di generare un termine 
  dati i termini contestuali 
  è 
la seguente:  
Se consideriamo una sequenza di lunghezza T abbiamo:
w
c
 w
o
1
,
⋯
,
w
o
2
m
12
",wordvec continuous bag words simile skip gram assume parole contestuali generico parola centrale essendoci parole contestuali vettori mediati probabilit condizionata generare termine dati termini contestuali seguente consideriamo sequenza lunghezza abbiamo
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#12,12,"word2vec: recap
Diagramma riassuntivo dei 2 modelli:
13
CBOW model Skip-gram model
t-word embedding t-word embeddingmatrix  
Vxdmatrix
dxV",wordvec recap diagramma riassuntivo modelli model skip gram model word embedding word embeddingmatrix vxdmatrix
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#13,13,"Word Embedding with Global Vectors (GloVe)
Le co-occorrenze tra termini rappresentano informazioni importanti per 
costruire gli embeddings. Indichiamo con 
 q
ij
 la probabilità condizionata 
 P(w
 j
|
w
i
)
 nel modello 
 skip-gram
 : 
La parola 
 w
i
 può presentarsi molte volte in un corpus. Tutte le parole 
contestuali che co-occorrono con 
 w
i
 creano un multiset, dove 
 x
ij
 indica il 
numero di volte che la parola 
 w
j 
co-occorre con 
 w
i
. La loss function è:  
Indichiamo con 
 x
i
 il numero di parole contestuali dove compare wi come 
parola centrale, e avendo 
 p
ij
=x
ij
/x
i
, otteniamo:
14
",word embedding global vectors glo occorrenze termini rappresentano informazioni importanti costruire embeddings indichiamo probabilit condizionata modello skip gram parola pu presentarsi molte volte corpus tutte parole contestuali occorrono creano multiset indica numero volte parola occorre loss function indichiamo numero parole contestuali compare parola centrale otteniamo
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#14,14,"Word Embedding with Global Vectors (GloVe)
La sommatoria interna è la cross-entropy tra la probabilità condizionata 
 q
ij 
relativa alla predizione generata dal modello, e 
 p
ij
 ottenuta analizzando le 
statistica dell'intero corpus.  
Per ridurre la complessità computazionale (soprattutto per generare 
 q
ij
) e per 
mitigare gli effetti generate dai termini che compaiono di rado nel corpus ma 
che possono assumere importanza elevata dalla cross entropy, il modello 
GloVe introduce alcune varianti.  
La nuova 
 loss function
  è la seguente:  
dove si introducono ad ogni parola sono associati 2 bias, 
 b
i
 per le parole 
centrali e 
 c
i
 per le parole impiegate nel contesto; il primo e ultimo termine nel 
termine a quadrato sono il termine di loss, e 
 h(x
ij
)
 genera un peso associato al 
termine di loss.
15
",word embedding global vectors glo sommatoria interna cross entropy probabilit condizionata relativa predizione generata modello ottenuta analizzando statistica dellintero corpus ridurre complessit computazionale soprattutto generare mitigare effetti generate termini compaiono rado corpus possono assumere importanza elevata cross entropy modello glo introduce alcune varianti nuova loss function seguente introducono ogni parola associati bias parole centrali parole impiegate contesto primo ultimo termine termine quadrato termine loss genera peso associato termine loss
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#15,15,"fastText model
Ci sono relazioni morfologiche comuni tra molti vocaboli, es., tra 
 help
 e 
helps, 
helped, helping
 ; tra 
dog
 e 
dogs
 e tra 
 cat
 e 
cats
; tra 
boy
 e 
boyfriend
  e tra 
 girl
 e 
girlfriend
 . Modelli come skip-gram ignorano queste relazioni, poiché ognuno 
di questi termini è rappresentato da un vettore distinto.  
Il modello 
 fastText
  usa 
subword embeddings
 , dove ogni 
 subword
  è un 
 n-gram 
di caratteri. Ad ogni subword è associato un vettore.  
•
Per esempio, la parola ""where"" genera le subwords “<wh”, “whe”, “her”, 
“ere”, “re>” impiegando una 
 ﬁ
nestra di lunghezza 3.  
La rappresentazione di un termine 
 v
w
 sarà la somma delle sue subwords 
 z
g
: 
Il resto del modello è basato su skip-gram.
16
",fast text model relazioni morfologiche comuni molti vocaboli help helps helped helping dog dogs cat cats boy boyfriend girl girlfriend modelli skip gram ignorano relazioni poich ognuno termini rappresentato vettore distinto modello fast text usa subword embeddings ogni subword gram caratteri ogni subword associato vettore esempio parola where genera subwords wh whe her ere re impiegando nestra lunghezza termine somma subwords resto modello basato skip gram
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#16,16,"Modelli context-indipendent e context-sensitive
Nei modelli precedenti, data una parola, il vettore generato non dipende dal 
contesto attuale (approccio 
 context-independent
 ). Termini polisemici o 
relazioni semantiche del linguaggio naturale saranno perciò ignorate.  
Modelli come 
 ELMo
  combinano le rappresentazioni intermedie ottenute da 
LSTM bidirezionali per ottenere una rappresentazione che dipende dalla 
sequenza in input (approccio 
 context-sensitive
 ).  
•
La rappresentazione così ottenuta è solitamente combinata con quella 
ottenuta in modo context-independent (es. tramite GloVe) nei task successivi. 
Il modello impiegato da ELMo deve essere speci
 ﬁ
co per il task che si andrà 
ad affrontare, e perciò rimarrà costante.  
Per evitare di avere diversi modelli per ogni task, GPT pre-addestra un 
language model che sarà usato per rappresentare sequenze testuali. I 
parametri saranno poi 
 ﬁ
ne-tuned
  in base all'ouput del task successivo. GPT è 
basato su Transformers. Il contesto analizzato da GPT sarà limitato alla parte 
antecedente al termine attuale, perciò non si analizza il contesto a destra del 
termine. 
17",modelli context indipendent context sensitive modelli precedenti data parola vettore generato dipende contesto attuale approccio context independent termini polisemici relazioni semantiche linguaggio naturale perci ignorate modelli lmo combinano intermedie ottenute bidirezionali ottenere dipende sequenza input approccio context sensitive cos ottenuta solitamente combinata ottenuta modo context independent tramite glo task successivi modello impiegato lmo deve essere speci task andr affrontare perci rimarr costante evitare avere diversi modelli ogni task pre addestra language model usato rappresentare sequenze testuali parametri poi tuned base allouput task successivo basato transformers contesto analizzato limitato parte antecedente termine attuale perci analizza contesto destra termine
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#17,17,"Bidirectional Encoder Representations from Transformers (BERT)
BERT combina i due approcci appena descritti, rappresentando l'intero 
contesto mediante un approccio bidirezionale.  
È basato su Transformer encoders pre-addestrati. Un output layer speci
 ﬁ
co per 
il task da affrontare sarà di volta in volta addestrato da zero. 
18
",bidirectional encoder representations transformers combina due approcci appena descritti rappresentando lintero contesto mediante approccio bidirezionale basato transformer encoders pre addestrati output layer speci task affrontare volta volta addestrato zero
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#18,18,"Bidirectional Encoder Representations from Transformers (BERT)
L'input di BERT può essere una singolo testo o coppie di testi.  
Oltre agli 
 positional
  embedding, si impiegano anche 
 segment
  e 
token  
embeddings. Infatti, a differenza delle RNN, i Transformer richiedono tecniche 
speci
 ﬁ
che per rappresentare internamente l'ordine relativo in cui i termini 
compaiono tra loro. Tali embedding sono ricavati durante la fase di training.
19
",bidirectional encoder representations transformers linput pu essere singolo testo coppie testi oltre positional embedding impiegano segment token embeddings infatti differenza transformer richiedono tecniche speci rappresentare internamente lordine relativo termini compaiono loro tali embedding ricavati durante fase training
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#19,19,"Bidirectional Encoder Representations from Transformers (BERT)
Come pretraining (auxiliary) task si impiega il 
 Masked Language modeling
 . 
Dato un corpus testuale, il 15% dei tokens saranno selezionati in modo 
random per il task di predizione. Al loro posto sarà presente un tag <mask>, 
es: 
•
“this movie is great” becomes “this movie is <mask>”  
Un ulteriore auxiliary task speci
 ﬁ
co nello scenario in cui si hanno 2 testi in 
input è il 
 Next sentence prediction
 . Dal corpus si estraggono coppie di frasi 
consecutive, e altrettante coppie di frasi che non sono consecutive. Il task è di 
classi
 ﬁ
cazione binaria.
20",bidirectional encoder representations transformers pretraining auxiliary task impiega masked language modeling dato corpus testuale tokens selezionati modo random task predizione posto presente tag mask this movie great becomes this movie mask ulteriore auxiliary task speci scenario testi input next sentence prediction corpus estraggono coppie frasi consecutive altrettante coppie frasi consecutive task classi cazione binaria
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#2,2,"DL e NLP 
Durante l'apprendimento di tecniche ML abbiamo spesso bisogno di grosse 
moli di dati 
 labelled
  per implementare approcci supervisionati.  
Alcune architetture DL hanno la capacità di riconoscere pattern e 
caratteristiche anche complesse in tali dati, ma dataset adeguati per 
l'addestramento non sono disponibili.  
Per tale motivo sono stati proposti vari approcci come il 
 self-supervised 
learning
 , per analizzare dati un modo non supervisionato (
 auxiliary task, es. 
predire una parte mancante del testo) e costruire rappresentazioni utili per 
supportare l'apprendimento (tipicamente supervisionato) in task più speci
 ﬁ
ci.  
Avendo un dataset di testo, l'input può essere costruito impiegando singole 
parole o n-grams formati da lettere, utili per catturare informazioni 
morfologiche delle parole. L'output è tipicamente una rappresentazione 
vettoriale associata ad ogni parola (
 embedding
 ), indipendente dal contesto in 
cui sarà presente in seguito.
3",durante lapprendimento tecniche spesso bisogno grosse moli dati labelled implementare approcci supervisionati alcune architetture capacit riconoscere pattern caratteristiche complesse tali dati dataset adeguati laddestramento disponibili tale motivo stati proposti vari approcci self supervised learning analizzare dati modo supervisionato auxiliary task predire parte mancante testo costruire utili supportare lapprendimento tipicamente supervisionato task speci dataset testo linput pu essere costruito impiegando singole parole grams formati lettere utili catturare informazioni morfologiche parole loutput tipicamente vettoriale associata ogni parola embedding indipendente contesto presente seguito
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#20,20,"Bidirectional Encoder Representations from Transformers (BERT)
BERT raggiunge prestazioni elevate su numero categorie di tasks, es.:  
•
single text classi
 ﬁ
cation 
 (e.g., sentiment analysis),  
•
text pair classi
 ﬁ
cation
  (e.g., date due domande di Quora determinare se sono 
simili o no),  
•
question answering
 ,  
•
text tagging
  (e.g., named entity recognition)
21",bidirectional encoder representations transformers raggiunge prestazioni elevate numero categorie tasks single text classi cation sentiment analysis text pair classi cation date due domande quora determinare simili question answering text tagging named entity recognition
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#3,3,"Esempio di auxiliary task
4
inputsliding-window
output (training set)
  ",esempio auxiliary task inputsliding window output training set
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#4,4,"Esempio di embeddings
Embeddings relativi a termini che identi
 ﬁ
cano 115 nazioni estratti da un 
corpus testuale, rappresentati su un piano 2d.
5   
",esempio embeddings embeddings relativi termini identi cano nazioni estratti corpus testuale rappresentati piano
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#5,5,"Esempio di operazioni su embeddings
Essendo vettori, possiamo fare operazioni sugli embeddings, es:  
•
vector(“paris”)−vector(“france”)+vector(""germany"")  
Impiegando il modello di embeddings 
 GloVe
  addestrato sul testa estatto da 
Wikipedia otteniamo:  
•
berlin: 0.8015347  
•
paris: 0.7623165     
•
munich: 0.7013252     
•
leipzig: 0.6616945    
•
germany: 0.6540700 
6   ",esempio operazioni embeddings vettori possiamo fare operazioni embeddings impiegando modello embeddings glo addestrato testa estatto wikipedia otteniamo berlin paris munich leipzig germany
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#6,6,"DL e NLP 
Le rappresentazioni pretrained ottenute con approcci non supervisionati sono 
successivamente impiegate su architetture di DL in base al task da risolvere.
7
",pretrained ottenute approcci supervisionati successivamente impiegate architetture base task risolvere
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#7,7,"word2vec
Il modello impiega 2 reti: 
 skip-gram
  e 
continuos bag of words
  (CBOW).  
Il training è basato sulla stima delle probabilità condizionate di predire una 
certa parola in base a termini che occorrono nel suo intorno. Si segue sempre 
un approccio non supervisionato.
8",wordvec modello impiega reti skip gram continuos bag words training basato stima probabilit condizionate predire certa parola base termini occorrono intorno segue sempre approccio supervisionato
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#8,8,"word2vec: skip-gram
Assume che un termine può generare il testo circostante in una sequenza.  
Supponiamo di considerare la sequenza 
 “the”, “man”, “loves”, “his”, “son”
 ; e 
considerare il termine 
 loves
  con parola centrale, e una 
 ﬁ
nestra di 2 termini 
intorno al termine centrale.  
Il modello skip-gram valuta la seguente probabilità condizionata:  
Se assumiamo che i termini siano generati in modo indipendente tra loro, 
possiamo riscriverla:
9
",wordvec skip gram assume termine pu generare testo circostante sequenza supponiamo considerare sequenza the man loves his son considerare termine loves parola centrale nestra termini intorno termine centrale modello skip gram valuta seguente probabilit condizionata assumiamo termini generati modo indipendente loro possiamo riscriverla
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#9,9,"word2vec: skip-gram
Ogni parola con indice 
 i
 ha associati 2 vettori d-dimensionali, 
  e 
. Il primo impiegato quando la parola è usata centralmente, l'altro 
quando la parola appare nel contesto.  
La probabilità di generare un certo termine contestuale con indice 
 o
 dato il 
termine centrale con indice 
 c
 è de
 ﬁ
nita mediante una operazione softmax nel 
seguente modo:  
Data una sequenza di testo lunga 
 T
, dove 
  indica la parola posizionata allo 
step 
t
, e assumendo che le parole contestuali siano generate in modo 
indipendente tra loro, per una 
 ﬁ
nestra di lunghezza 
 m
, la probabilità di 
generare tutti i termini contestuali è de
 ﬁ
nita nel seguente modo:
v
i
∈
ℝ
d
u
i
∈
ℝ
d
w
(
t
)
10
",wordvec skip gram ogni parola indice associati vettori dimensionali primo impiegato quando parola usata centralmente laltro quando parola appare contesto probabilit generare certo termine contestuale indice dato termine centrale indice nita mediante operazione softmax seguente modo data sequenza testo lunga indica parola posizionata step assumendo parole contestuali generate modo indipendente loro nestra lunghezza probabilit generare termini contestuali nita seguente modo
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#0,0,!1Introduzione,introduzione
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#1,1,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!2
",cos fisicala fisica disciplina propone fornire spiegazione fenomeni naturali
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#10,10,"Misura delle grandezze fisicheEsempio: per misura della larghezza L di una lavagna occorre confrontare la larghezza della lavagna con uno standard di misura delle lunghezze: 
!11L{}=LL⎡⎣⎤⎦Risultato del confrontoGrandezza fisica da misurareLunghezza standard• Se [L]=metro            → {L} = 3,5    [L]=m   →   L = 3,5 m • Se [L]=centimetro    → {L} = 350     [L]=cm   →   L = 350 cm • Se [L]=piede             → {L} = 11,5    [L]=ft     →   L = 11,5 ft • Se [L]=pollice           → {L} = 138    [L]=in     →  L = 138 in La grandezza è sempre la stessa, ma cambiano sia la parte numerica che quella relativa allo standard di misura utilizzato",misura grandezze fisiche esempio misura larghezza lavagna occorre confrontare larghezza lavagna standard misura lunghezze lrisultato confronto grandezza fisica misurare lunghezza standard lmetro lcentimetro lcm lpiede lft lpollice lin grandezza sempre stessa cambiano parte numerica relativa standard misura utilizzato
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#11,11,"Misura delle grandezze fisicheLa misura è identificata da due elementi: • La parte numerica (numero)  {L} • Lo standard usato (l’unità di misura) [L] 
!12L={L}[L]Devono essere specificati entrambi!!!",misura grandezze fisiche misura identificata due elementi parte numerica numero standard usato lunit misura llldevono essere specificati entrambi
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#12,12,"Dimensioni delle grandezze fisicheGrandezze principali (che useremo nel corso) • Lunghezza L, Tempo T, Massa M, Intensità di corrente I
!13e ( alcune) grandezze derivate: • Superficie S=[L2], V olume V=[L3] • Frequenza F=[1/T]=[T-1]  • Velocità V=[L/T]=[LT-1], accelerazione A=[L/T2]=[LT-2] • Tensione elettrica V=[ML2I-1T-3]• Grandezza generica  [X]=[MαLβTγI𝛿] 𝛼,𝛽,𝛾,𝛿 sono dette dimensioni della grandezza fisica",dimensioni grandezze fisiche grandezze principali che useremo corso lunghezza tempo massa intensit corrente alcune grandezze derivate superficie olume frequenza ftt velocit vltl accelerazione altl tensione elettrica grandezza generica xm dette dimensioni grandezza fisica
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#13,13,"Dimensioni nelle formuleOgni formula ﬁsica è una relazione tra grandezze ﬁsiche → sono due relazioni, una sui numeri e una sulle unità di misura
!14",dimensioni formule ogni formula sica relazione grandezze siche due relazioni numeri unit misura
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#14,14,"Unità di misura (standard di misura)Gli standard devono soddisfare i criteri: • Essere stabili nel tempo • Essere precisi • Essere “facilmente” riproducibili in ogni parte del mondo (universo)
!15Dal 20 maggio 2019 si utilizzano nuove definizioni",unit misura standard misuragli standard devono soddisfare criteri essere stabili tempo essere precisi essere facilmente riproducibili ogni parte mondo universo maggio utilizzano nuove definizioni
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#15,15,"Unità di tempo: il secondoScelta di un fenomeno periodico:  •Giorno solare medio. Diviso in  - 24 ore, 60 minuti primi, 60 minuti secondo - 1 giorno = 86400 secondi  (minuti secondi) • 1967: un secondo corrisponde a 9.192.631.770 oscillazioni dell’isotopo di Cesio 133 tra lo stato fondamentale e il suo primo stato eccitato (invariato al 20/5/2019)!16
",unit tempo secondo scelta fenomeno periodico giorno solare medio diviso ore minuti primi minuti secondo giorno secondi minuti secondi secondo corrisponde oscillazioni dellisotopo cesio stato fondamentale primo stato eccitato invariato
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#16,16,"Unità di lunghezza: il metroProdotto della rivoluzione francese (1795)•Deﬁnizione originale– 1 metro = 1/10 000 000 della distanza tra polo nord ed equatore •Deﬁnizione successiva (1889): distanza tra due tacche di una sbarra di platino-iridio (campione di Sèvres)•1983: Lo standard di tempo è ben deﬁnito; la velocità della luce è una costante universale:– 1 metro = distanza percorsa dalla luce in 1/299 792 458 secondi(invariato al 20/5/2019)!17
",unit lunghezza metro prodotto rivoluzione francese originale metro distanza polo nord equatore denizione successiva distanza due tacche sbarra platino iridio campione svres standard tempo ben denito velocit luce costante universale metro distanza percorsa luce
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#17,17,"Unità di corrente: l’ampereFino al 20/5/2019 L’intensità di corrente che, se mantenuta in due conduttori lineari paralleli di lunghezza infinita e sezione trascurabile, posti a un metro di distanza l’uno dall’altro nel vuoto, produce tra questi una forza pari a 2×10-7 newton per ogni metro di lunghezza. Oggi:  L’ampere sarà definito dal valore numerico della carica elementare fissato a 1,602176634×10-19 coulomb e sarà realizzato attraverso speciali circuiti che contano gli elettroni.!18
",unit corrente lampere fino lintensit corrente che mantenuta due conduttori lineari paralleli lunghezza infinita sezione trascurabile posti metro distanza luno dallaltro vuoto produce forza pari newton ogni metro lunghezza oggi lampere definito valore numerico carica elementare fissato coulomb realizzato attraverso speciali circuiti contano elettroni
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#18,18,"Unità di massa: il kilogrammoProdotto della rivoluzione francese (1795) Intenzione: 1 kg = massa di 1 dm3 di acqua a 4 gradi centigradi Fino al 20/5/2019 Definizione: 1kg =  massa di un cilindro campione di platino iridio di 39 mm di altezza e 39 mm di diametro!19
",unit massa kilogrammo prodotto rivoluzione francese intenzione massa acqua gradi centigradi fino definizione massa cilindro campione platino iridio altezza diametro
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#19,19,"Unità di massa: il kilogrammoOggi:  Sarà ridefinito in termini della costante di Planck, sarà realizzato attraverso una speciale bilancia elettromagnetica (detta bilancia di Kibble) e non sarà più necessario riferirsi al campione di Sèvres. il chilogrammo diventa la massa controbilanciata da un certa quantità di corrente, dove entra in gioco la costante di Planck.
!20
",unit massa kilogrammo oggi ridefinito termini costante planck realizzato attraverso speciale bilancia detta bilancia kibble necessario riferirsi campione svres chilogrammo diventa massa certa quantit corrente entra gioco costante planck
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#2,2,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!3Fino al XVII secolo la Fisica era considerata come filosofia della natura (spinta più da considerazioni filosofiche)Il senso moderno del termine è stato introdotto da Galileo Galilei, partendo dalla definizione di Metodo Scientifico",cos fisicala fisica disciplina propone fornire spiegazione fenomeni naturali fino secolo fisica considerata filosofia natura spinta considerazioni filosoficheil senso moderno termine stato introdotto galileo galilei partendo definizione metodo scientifico
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#20,20,"Sistema Metrico DecimaleUn insieme di unità di misura costituisce un sistema: Sistema MKS: metro, kilogrammo, secondo (rinominato in SI nel 1970: Sistema Internazionale) Sistema cgs: centimetro, grammo, secondo Sistema metrico decimale: i multipli ed i sottomultipli sono potenze di 10: Multipli prefisso  sottomultipli prefisso 10 deca (da)  10-1 deci   (d) 102 etto (h)  10-2 centi  (c) 103 kilo  (k)                 10-3 milli  (m) 106 mega (M)  10-6 micro  (µ) 109 giga (G)  10-9 nano (n) Esempi: 1 mm, 2 µm, 5 ns, 20 km, 4 hg!21",sistema metrico decimale insieme unit misura costituisce sistema sistema metro kilogrammo secondo rinominato sistema internazionale sistema cgs centimetro grammo secondo sistema metrico decimale multipli sottomultipli potenze multipli prefisso sottomultipli prefisso deca deci etto centi kilo milli mega micro giga nano esempi
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#21,21,"Esempio
!22Una macchina percorre una curva semicircolare di raggio R=50 m con una velocità di v = 20 m/s. Calcolare l’accelerazione della macchina.
Risultato: l’accelerazione vale: Analisi dimensionale: [a]=[LT-2]Suggerimento: l’accelerazione (a) si misura in m/s2. La formula da usare è una delle seguenti:",esempio macchina percorre curva semicircolare raggio velocit calcolare laccelerazione macchina risultato laccelerazione vale analisi dimensionale suggerimento laccelerazione misura formula usare seguenti
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#22,22,"Esercizio
!23Determinare quanti secondi ci sono in un anno solare;Quanto pesa un metro cubo di acqua?Enrico Fermi amava dire che faceva lezioni che duravano tipicamente un microsecolo. A quanti minuti corrisponde un microsecolo?365.25×24×60×60=31,556,7361dm3→1kg1m3=1000dm3→1000kg100×365.25×24×60=52,594,560 minuti in un secoloUn microsecolo corrisponde a 52.59456 minuti ",esercizio determinare secondi anno solarequanto pesa metro cubo acquaenrico fermi amava dire lezioni duravano tipicamente microsecolo minuti corrisponde minuti secolo microsecolo corrisponde minuti
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#23,23,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.ithttps://www.unibo.it/sitoweb/lorenzo.rinaldi/
!24",lorenzo rinaldi dipartimento fisica
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#3,3,"Il Metodo Scientifico-SperimentaleAlla base del metodo Scientifico c’è l’Esperimento: i processi della Natura sono schematizzati in Modelli da verificare sperimentalmente
!4
...tra le sicure maniere di conseguire la verità è l’anteporre l’esperienza a qualsivoglia discorso, non sendo possibile che una sensata esperienza sia contraria al vero... ",metodo scientifico sperimentale base metodo scientifico c lesperimento processi natura schematizzati modelli verificare tra sicure maniere conseguire verit lanteporre lesperienza qualsivoglia discorso sendo possibile sensata esperienza contraria vero
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#4,4,"Il Metodo Scientifico-SperimentaleNessun modello teorico risulta essere valido universalmente Le teorie risultano essere valide entro ben determinati limiti esempio:  •piccole distanze: serve la “teoria dei quanti” •elevate velocità: serve la “teoria della relatività” 
!5",metodo scientifico sperimentale nessun modello teorico risulta essere valido universalmente teorie risultano essere valide entro ben determinati limiti esempio piccole distanze serve teoria quanti elevate velocit serve teoria relativit
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#5,5,"Il Metodo Scientifico-SperimentaleLe teorie fisiche sono validate tramite osservazioni sperimentali Gli esperimenti devono essere realizzati per determinare con precisione (MISURARE) in maniera RIPRODUCIBILE le grandezze fisiche.
!6Le grandezze Fisiche sono quantità che servono per descrivere i fenomeni naturali in maniera oggettiva (esempio: tempo, spazio, massa,…) 
",metodo scientifico sperimentale teorie fisiche validate tramite osservazioni sperimentali esperimenti devono essere realizzati determinare precisione maniera grandezze fisiche grandezze fisiche quantit servono descrivere fenomeni naturali maniera oggettiva esempio tempo spazio massa
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#6,6,"Grandezze Fisiche
!7Grandezza fisica: proprietà o caratteristica di un oggetto o di un fenomeno che può essere quantificata (→ misurata)
Esempi: 
lunghezze, durate, velocità, forza, temperatura, pressioneodori, intelligenza, bello, brutto…
Controesempi: 
",grandezze fisiche grandezza fisica propriet caratteristica oggetto fenomeno pu essere quantificata misurata esempi lunghezze durate velocit forza temperatura pressioneodori intelligenza bello brutto controesempi
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#7,7,"Grandezze principali e derivate Lunghezza e V olume • Il volume V di un cubo di lato L: V=L3
!8
L In un viaggio di T=1 h, ho percorso L=100 km spostandomi ad una velocità v=100 km/h • 3 grandezze: durata, distanza, velocità •1 relazione tra le grandezze v=L/Tlunghezza e tempo sono grandezze principali V olume e velocità sono grandezze derivate",grandezze principali derivate lunghezza olume volume cubo lato viaggio percorso spostandomi velocit kmh grandezze durata distanza velocit relazione grandezze vltlunghezza tempo grandezze principali olume velocit grandezze derivate
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#8,8,"Grandezze principali e derivate
!9In Fisica ci sono 7 grandezze principali, tutte le altre sono derivabili da esselunghezza tempo massa temperatura intensità di corrente elettrica intensità luminosa quantità di sostanzaMECCANICAELETTROMAGNETISMO",grandezze principali derivate fisica grandezze principali tutte altre derivabili esselunghezza tempo massa temperatura intensit corrente elettrica intensit luminosa quantit sostanza
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#9,9,"Misura delle grandezze fisicheMisura: processo di determinazione di una grandezza fisica Operativamente: misura=confronto della grandezza che ci interessa con uno standard (una misura campione di quel tipo di grandezza)Le grandezze Fisiche sono definite in Modo Operativo: il modo di misurare la grandezza ne fissa la definizione Le grandezze Fisiche sono definite da tutte le possibili operazioni di misurazione
!10",misura grandezze fisiche misura processo determinazione grandezza fisica operativamente grandezza interessa standard una misura campione quel tipo grandezzale grandezze fisiche definite modo operativo modo misurare grandezza fissa definizione grandezze fisiche definite tutte possibili operazioni misurazione
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#0,0,VETTORI  CdS Ingegneria Informatica A.A. 2019/20,ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#1,1,"!2Grandezze fisiche•Grandezze scalari: completamente definite da un numero ed una unità di misura –Esempi: distanza, lunghezza, periodo, pressione, temperatura •Grandezze vettoriali: completamente definite da 3 numeri e da una unità di misura o da un numero, una unità di misura, una direzione ed un verso –Esempi: spostamenti, forze, velocità, accelerazione, campi elettrici e magnetici, … •Grandezze tensoriali: definite da più di 3 numeri ed una unità di misura –Esempi: momento d’inerzia, matrice di rotazione, …",grandezze scalari completamente definite numero unit misura esempi distanza lunghezza periodo pressione temperatura grandezze vettoriali completamente definite numeri unit misura numero unit misura direzione verso esempi spostamenti forze velocit accelerazione campi elettrici magnetici grandezze tensoriali definite numeri unit misura esempi momento dinerzia matrice rotazione
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#10,10,"!11Proprietà associativa della somma
⃗a+⃗c",propriet associativa somma ac
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#11,11,"!12Differenza tra vettori•Definizione:OABOAB−⃗bvettore opposto (stesso modulo e direzione, ma con verso opposto)⃗d=⃗a−⃗b=⃗a+(−⃗b)",differenza bbvettore opposto stesso modulo direzione verso
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#12,12,"Somma e differenza
!13⃗a⃗d=⃗a−⃗b⃗b⃗c=⃗a+⃗b",somma differenza
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#13,13,"!14Moltiplicazione per uno scalare•Si può definire come moltiplicazione tra un numero naturale n ed un vettore     come una somma ripetuta:•Generalizzando, si può definire come  moltiplicazione tra un numero reale λ ed un vettore      come vettore di direzione pari ad      modulo pari a            e verso concorde con     se             , verso opposto se    È un vettore!",moltiplicazione scalaresi pu definire moltiplicazione numero naturale vettore somma pu definire moltiplicazione numero reale vettore vettore direzione pari modulo pari verso concorde verso opposto vettore
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#14,14,"!15Moltiplicazione per scalare: proprietà•La moltiplicazione per uno scalare gode delle proprietà commutative, associative e distributive sia rispetto agli scalari che ai vettori:•Inoltre:",moltiplicazione scalare proprietla moltiplicazione scalare gode propriet commutative associative distributive rispetto scalari
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#15,15,"!16Prodotto scalareAssocia a due vettori arbitrari uno scalare:θa⋅b=abcosϑ
a⋅b=abb
a⋅b=aba",prodotto scalare associa due vettori arbitrari ababb ababa
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#16,16,!17                   : casi notevoli•Vettori in direzione opposta:a⋅b=abcosϑ•Vettori paralleli:a⋅b=ab>0•Vettori ortogonali:a⋅b=0•La componente: –Sia      un versorea⋅ˆu=aˆucosϑ==acosϑ=au,casi direzione componente sia
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#17,17,"!18Prodotto scalare: proprietà•Il prodotto scalare gode della proprietà commutativa, distributiva sulla somma:•Quadrato di un vettore:DEFINIZIONE  DI MODULO!  a⋅b=b⋅aa⋅b+c()=a⋅b+a⋅cλa⋅b()=λa()⋅b=a⋅λb()   a⋅a=a2=a2=a2  ⇒a=a⋅a",prodotto scalare proprietil prodotto scalare gode propriet commutativa distributiva sommaquadrato vettored aaa
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#18,18,"!19Moduli di somme e di differenze
   a+b=a+b()2=a+b()⋅a+b()=  =a⋅a+a⋅b+b⋅a+b⋅b   a+b=a2+b2+2abcosϑ   a−b=a−b()2=a−b()⋅a−b()=  =a⋅a−a⋅b−b⋅a+b⋅b   a−b=a2+b2−2abcosϑ",moduli somme differenze
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#19,19,"!20Prodotto vettore•Associa a due vettori un terzo vettore:
Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destraModulo: area del parallelogrammaVerso convenzionale",prodotto vettoreassocia due vettori terzo vettore modulo direzione piano vettori verso regola mano destra modulo area parallelogramma verso convenzionale
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#2,2,!3Stazione: 2.2 km in direzione nord-est,stazione direzione nord est
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#20,20,"!21Prodotto vettore•Associa a due vettori un terzo vettore:Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destra
",prodotto vettoreassocia due vettori terzo vettoremodulo direzione piano vettori verso regola mano destra
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#21,21,!22Prodotto vettore: proprietà•Il prodotto vettore (o vettoriale) gode della proprietà anticommutativa e distributiva sulla somma: •Il prodotto vettore non gode della proprietà associativa: •Caso notevole:,prodotto vettore proprietil prodotto vettore vettoriale gode propriet anticommutativa distributiva somma il prodotto vettore gode propriet associativa caso notevole
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#22,22,"!23Doppio prodotto misto
Proprietà:V=a∧b⋅c=a∧b()⋅ch=c⋅versa∧b() a∧b⋅c=b∧c⋅a=c∧a⋅b a∧b⋅c=a⋅b∧c",doppio prodotto misto
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#23,23,"!24Sistemi di riferimento•I vettori sono entità astratte, indipendenti da come sono rappresentate.AB•Per convenienza pratica i vettori si descrivono bene utilizzando il concetto di SISTEMA DI RIFERIMENTO, costituito in estrema sintesi da un punto privilegiato detto origine e da un insieme di vettori campione (vettori di base)",sistemi riferimentoi vettori entit astratte indipendenti rappresentatea bper convenienza pratica vettori descrivono bene utilizzando concetto costituito estrema sintesi punto privilegiato detto origine insieme vettori campione vettori base
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#24,24,!25Spazio unidimensionale•Ogni vettore può essere scritto come:O In uno spazio unidimensionale ogni vettore può essere espresso come uno scalare (la componente) moltiplicato il versore dell’asse (sempre lo stesso).a+b=auˆu+buˆu=au+bu()ˆua=a⋅a=auˆu⋅auˆu=au2(ˆu⋅ˆu)=au,spazio vettore pu essere scritto comeo spazio unidimensionale ogni vettore pu essere espresso scalare componente moltiplicato versore dellasse sempre
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#25,25,"!26Spazio bidimensionale: vettori nel piano•Scelgo 2 assi ortogonali x,y: 
OXYˆi⋅ˆj=0",spazio bidimensionale vettori pianoscelgo assi ortogonali xyij
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#26,26,"Esempio di spazio bi-dimensionale
!27
(C; 4)",esempio spazio dimensionale
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#27,27,"!28Spazio tridimensionale
•Scelgo 3 assi ortogonali x,y,z: ",spazio tridimensionale scelgo assi ortogonali xyz
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#28,28,"!29Vettori di base nello spazio
1ˆˆˆˆˆˆ=⋅=⋅=⋅kkjjii0ˆˆˆˆˆˆ=⋅=⋅=⋅ikkjjiˆi∧ˆi=ˆj∧ˆj=ˆk∧ˆk=0",vettori base spazio
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#29,29,"!30Operazioni nella rappresentazione cartesiana
a⋅b=ca⋅b=(axˆi+ayˆj+azˆk)⋅(bxˆi+byˆj+bzˆk)==axbxˆi⋅ˆi+axbyˆi⋅ˆj+axbzˆi⋅ˆk+aybxˆj⋅ˆi+aybyˆj⋅ˆj+aybzˆj⋅ˆk++azbxˆk⋅ˆi+azbyˆk⋅ˆj+azbzˆk⋅ˆk==axbx+ayby+azbz=c",operazioni cartesiana
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#3,3,"!4Vettore nel piano
ABModuloDirezioneVersoVettore libero 1 direzione nello spazio 1 verso 1 modulo (intensità)Prototipo: vettore spostamento",vettore piano bmodulo direzione verso vettore libero direzione spazio verso modulo vettore spostamento
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#30,30,"!31Prodotto vettoriale
",prodotto vettoriale
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#31,31,"Esercizio A•Sianoˆˆˆˆˆˆ21322aijkbijk=−+=−+−!!1.Trovare i moduli 2.Trovare il vettore somma ed il vettore differenza 3.Calcolare  4.Calcolare  5.Trovare l’angolo compreso!3232,23cabdab=+=−!!!!!!abλ=⋅!!",esercizio moduli trovare vettore somma vettore differenza calcolare calcolare trovare langolo
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#32,32,"Esercizio Nel piano XY, la componente x di un vettore v vale -25, quella y +40. Quanto vale il modulo del vettore? Quanto vale l’angolo compreso fra v e l’asse delle ascisse? 
!33",esercizio piano componente vettore vale vale modulo vettore vale langolo compreso fra lasse ascisse
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#33,33,!34Esercizio 1•Sia1.Trovare i moduli 2.Trovare l’angolo compreso 3.Trovare il vettore somma ed il vettore differenza 4.Trovare un vettore perpendicolare ad entrambi,esercizio siatrovare moduli trovare langolo compreso trovare vettore somma vettore differenza trovare vettore perpendicolare entrambi
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#34,34,"!35Esercizio 3•Una barca naviga in direzione Nord-Est per 15 km, successivamente vira in direzione Sud e prosegue per 10 km, quindi vira nuovamente in direzione Ovest e percorre altri 5 km. Trovare la distanza percorsa e la distanza dal punto di partenza.NESO",esercizio una barca naviga direzione nord est successivamente vira direzione sud prosegue quindi vira nuovamente direzione ovest percorre altri trovare distanza percorsa distanza punto partenzan
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#35,35,"Esercizio Nella somma a+b = c il vettore a ha modulo 12 e forma un angolo di 40° rispetto al semiasse positivo delle ascisse, mentre il vettore c ha modulo 15 ed è diretto con un angolo di 20° in senso antiorario rispetto al semiasse negativo delle ascisse. Calcolare il modulo e la direzione (rispetto al semiasse positivo delle ascisse) di b. 
!36",esercizio somma vettore modulo forma angolo rispetto semiasse positivo ascisse mentre vettore modulo diretto angolo senso antiorario rispetto semiasse negativo ascisse calcolare modulo direzione rispetto semiasse positivo ascisse
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#36,36,"Esercizio Dati nel piano cartesiano i punti A = (1, 1), B = (3, 4) e  C = (5, 2), determinare il valore dell’angolo formato dai segmenti CA e CB e l’area del triangolo ABC. 
!37",esercizio dati piano cartesiano punti determinare valore dellangolo formato segmenti larea triangolo
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#37,37,"EsercizioDeterminare il volume del parallelepipedo individuato dai vettori   ˆˆˆˆˆˆˆ2,3,32ajkbjcjkιι=−+=−=−+−!!!
!38",esercizio determinare volume parallelepipedo individuato vettori
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#38,38,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it www.unibo.it/docenti/lorenzo.rinaldi
!39",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#4,4,"!5Versore•Versore: vettore di modulo unitario, adimensionaleUn versore individua un asse orientatoAB",vettore modulo unitario adimensionale versore individua asse orientato
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#5,5,"I versori dove non te li aspetti
!6",versori aspetti
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#6,6,"!7LA componente ed IL componente
vu = v cosθla componente
(vu = v cosθ u) il componenteLA componente è una grandezza scalare!IL componente è un vettore (il vettore componente lungo una direzione)",componente componente cosla componente cos componente componente grandezza scalarei componente vettore vettore componente lungo direzione
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#7,7,!8Algebra dei vettori•I vettori liberi costituiscono un’algebra –È definita l’operazione somma tra due vettori –È definita l’operazione di moltiplicazione tra un vettore ed uno scalare •Inoltre: sono definiti un prodotto esterno ed uno interno –Prodotto scalare: –Prodotto vettoriale:,algebra vettorii vettori liberi costituiscono unalgebra definita loperazione somma due vettori definita loperazione moltiplicazione vettore scalare inoltre definiti prodotto esterno interno prodotto scalare prodotto vettoriale
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#8,8,"!9Somma tra due vettori•Prototipo: somma tra due vettori spostamentoABCD
Regola del parallelogramma: Il vettore somma è dato dalla diagonale (C-A) del  Parallelogramma costruito  con i vettori (B-A) e (C-B)B≡C⃗c=⃗a+⃗b=(D−A)",somma due somma due vettori spostamento regola vettore somma dato diagonale parallelogramma costruito vettori
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#9,9,"!10Proprietà commutativa della somma•La somma gode della proprietà commutativa: 
•È un risultato sperimentale, non teorico, valido nel nostro ambiente. Ci sta dicendo che lo spazio fisico in cui viviamo è in buona approssimazione uno spazio euclideo.",propriet commutativa sommala somma gode propriet commutativa risultato sperimentale teorico valido ambiente dicendo spazio fisico viviamo buona approssimazione spazio euclideo
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#0,0,CINEMATICA CdS Ingegneria InformaticaA.A. 2019/20 ,ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#1,1,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#10,10,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#11,11,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#12,12,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#13,13,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#14,14,"se a(t)=λ costante   ⇒da2dt=0 per ipotesida2dt=da⋅a()dt=dadt⋅a+a⋅dadt=2a⋅dadt≡0⇒a⊥dadt
",at costante dadt
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#15,15,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#16,16,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#17,17,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#18,18,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#19,19,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#2,2,"•La terra non ruota solo su se stessa: ruota intorno al Sole a una velocità superiore a 110.000 km/h.
Qual è la nostra VELOCITÀ?Vi sembra di essere seduti immobili mentre ascoltate la lezione?
",la terra ruota solo stessa ruota intorno sole velocit superiore kmh qual itvi sembra essere seduti immobili mentre ascoltate lezione
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#20,20,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#21,21,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#22,22,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#23,23,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#24,24,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#25,25,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#26,26,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#27,27,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#28,28,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#29,29,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#3,3,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#30,30,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#31,31,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#32,32,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#33,33,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#34,34,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#35,35,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#36,36,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#37,37,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#38,38,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#39,39,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#4,4,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#40,40,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#41,41,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#42,42,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#43,43,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#44,44,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#45,45,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#46,46,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#47,47,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#48,48,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#49,49,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#5,5,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#50,50,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#51,51,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#52,52,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#53,53,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#54,54,"Moti periodici•Un fenomeno è detto periodico se, a partire da un istante qualsiasi t, le sue caratteristiche si ripresentano inalterate dopo un certo intervallo di tempo T, detto periodo. •Quantità caratteristiche: –       ,  periodo fondamentale; –         , frequenza (numero di T contenuti nell’unità di tempo); –          , pulsazione (numero di giri compiuti nell’unità di tempo sulla traiettoria chiusa) υ=1Tω0=2πTTmin
",moti periodiciun fenomeno detto periodico partire istante qualsiasi caratteristiche ripresentano inalterate dopo certo intervallo tempo detto periodo quantit periodo fondamentale frequenza numero contenuti nellunit tempo pulsazione numero giri compiuti nellunit tempo traiettoria chiusa t ttmin
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#55,55,Esempio di moto periodicoMoto circolare uniforme:→v=costantexy !r•In coordinate cartesiane:Tutte le equazioni:hanno la stessa famiglia di soluzioni:,esempio moto periodico moto circolare rin coordinate equazionihanno stessa famiglia soluzioni
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#56,56,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#57,57,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#58,58,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#59,59,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#6,6,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#60,60,"Moti relativi
",moti relativi
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#61,61,"Trasformazione della velocità (opz)
",trasformazione velocit opz
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#62,62,"Formule di Poisson (opz)•Quindi:
",formule poisson opzquindi
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#63,63,"Trasformazione della velocità (opz)•Posizione:
",trasformazione velocit
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#64,64,"Trasformazione dell’accelerazione (opz)
",trasformazione opz
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#65,65,"Trasformazione dell’accelerazione
",trasformazione
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#66,66,"SR in moto rettilineo uniforme
",moto rettilineo uniforme
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#67,67,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.itwww.unibo.it/docenti/lorenzo.rinaldi
",lorenzo rinaldi dipartimento fisica
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#68,68,"Argomenti opzionali
",argomenti opzionali
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#69,69,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#7,7,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#70,70,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#71,71,"SR in rotazione uniforme
",rotazione uniforme
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#72,72,"Esercizio•Nei pressi di un incrocio a 90° tra due strade si urtano due macchine che viaggiavano rispettivamente a 40 km/h e 50 km/h. Determinare la velocità relativa dell’urto (velocità di una macchina come misurata da un osservatore solidale con l’altra) quando: –L’urto è frontale –L’urto è un tamponamento –L’urto avviene tra due macchine che viaggiavano su due strade a 90° tra loro.
",esercizionei pressi incrocio due strade urtano due macchine viaggiavano rispettivamente kmh kmh determinare velocit relativa dellurto velocit macchina misurata osservatore solidale laltra quando lurto frontale lurto tamponamento lurto avviene due macchine viaggiavano due strade loro
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#73,73,"Caso 1: tamponamento
",caso tamponamento
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#74,74,"Caso 2: urto frontale
",caso urto frontale
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#75,75,"Caso 3: urto a 90 gradi
",caso urto gradi
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#76,76,"Esercizio•Su una giostra costituita da una piattaforma rotante si trova un bambino con in mano una pallina. La giostra ruota con una velocità angolare pari a 0.5 s-1 quando, il bambino, che si trova a 4 m dall’asse di rotazione, lancia la pallina con una velocità iniziale pari a 3 m/s. Calcolare la velocità che ha la pallina per un osservatore solidale con il terreno quando il bambino lancia la pallina: –Verso l’asse di rotazione della giostra –In direzione radiale –In orizzontale a 90° dalla direzione radiale.",eserciziosu giostra costituita piattaforma rotante trova bambino mano pallina giostra ruota velocit angolare pari quando bambino trova dallasse rotazione lancia pallina velocit iniziale pari calcolare velocit pallina osservatore solidale terreno quando bambino lancia pallina verso lasse rotazione giostra in direzione radiale in orizzontale direzione radiale
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#77,77,"Impostazione della soluzione
",impostazione soluzione
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#78,78,"Esercizio •Calcolare i moduli delle velocità e dell’accelerazione di un corpo fermo sulla superficie terreste a 45° di latitudine rispetto ad un SR con origine nel centro della terra e assi rivolti verso le stelle fisse.
",esercizio calcolare moduli velocit corpo fermo superficie terreste latitudine rispetto origine centro terra assi rivolti verso stelle fisse
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#8,8,,
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#9,9,,
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#0,0,Moti in SR NON INERZIALI CdS Ingegneria Informatica A.A. 2019/20 ,moti ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#1,1,"LAURA FABBRI  -
Moti in SR in moto relativo: cinematica
!7Cinematica: movimento è un concetto relativo, legato al SR scelto.ES: oggetto lasciato cadere sul vagone di un treno in moto:  - Cade lungo la verticale per un osservatore sul treno,  - Compie una traiettoria parabolica per osservatore a terra.Entrambi i moti sono veri rispetto al loro SR.  Cambia la descrizione di posizione, velocità…. Un SR può essere solo più “conveniente” computazionalmente
",moti moto relativo cinematica cinematica movimento concetto relativo legato sceltoe oggetto lasciato cadere vagone treno moto cade lungo verticale osservatore treno compie traiettoria parabolica osservatore terraentrambi moti veri rispetto cambia descrizione posizione velocit pu essere solo conveniente
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#10,10,"LAURA FABBRI  -
Cosa misura una bilancia  in ascensore?
!50
Ascensore fermo:Ascensore in salita con      costante. Se l’ascensore sale, un corpo fermo in esso sentirà una forza fittizia diretta come  Ascensore in discesa con      costante. Se l’ascensore scende, un corpo fermo in esso sentirà una forza fittizia diretta come  Caso limite: caduta libera→P→/u1D445/u1D463’’",cosa misura bilancia ascensore ascensore fermoascensore salita costante lascensore sale corpo fermo esso sentir forza fittizia diretta ascensore discesa costante lascensore scende corpo fermo esso sentir forza fittizia diretta caso limite caduta liberapu d
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#2,2,"LAURA FABBRI  -
Moti in SR in moto relativo: dinamica
!11Due principi fondamentali:•Tutti i sistemi di riferimento inerziali sono equivalenti;•Nei SRI le leggi della fisica sono le stesse e per il secondo principioCosa succede se studio il moto in un SR NON INERZIALE?",moti moto relativo dinamica due principi sistemi riferimento inerziali leggi fisica secondo principio cosa succede studio moto
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#3,3,"LAURA FABBRI  -
Moti in SR Non inerziali
!14
Es: treno in moto con velocità costante. Ragazzo seduto sul treno con un cubetto di ghiaccio sul vassoio. Due SR: S solidale a un osservatore a terra    S’ solidale con l’osservatore sul trenoIn S: sul cubetto non agisce nessuna forza -> si muove con la stessa velocità del SRIn S’: sul cubetto non agisce nessuna forza -> è fermo nel SR ",moti inerziali treno moto velocit costante ragazzo seduto treno cubetto ghiaccio vassoio due solidale osservatore terra solidale losservatore treno cubetto agisce nessuna forza muove stessa velocit rin cubetto agisce nessuna forza fermo
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#4,4,"LAURA FABBRI  -
Moti in SR Non inerziali
!19
Se treno in moto decelera improvvisamente….In S’ il cubetto vola fuori dal vassoio come se fosse sottoposto a una forza in avanti. È reale?Forza reale: attrito esercitato tra treno e binari, che ha coinvolto tutti gli oggetti solidali al treno in moto. Forza non ha agito sugli oggetti sul treno non solidali ad esso. Moto improvviso non dovuto a forze sull’oggetto ma a forze sul SR che non è più inerziale",moti inerziali treno moto decelera cubetto vola fuori vassoio sottoposto forza avanti realeforza reale attrito esercitato treno binari coinvolto oggetti solidali treno moto forza agito oggetti treno solidali esso moto improvviso dovuto forze sulloggetto forze inerziale
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#5,5,"LAURA FABBRI  -
Sistemi di riferimento non inerziali
!23•Esiste una classe di sistemi di riferimento in cui NON vale il secondo principio della dinamica: sistemi di riferimento non inerziali •I SR non inerziali sono tutti quelli in moto accelerato rispetto ad un SRI. Es: veicolo in partenza, veicolo in frenata, piattaforma rotante….•Nel SR non inerziale compaiono forze dette fittizie dovute all’accelerazione del nuovo SR.•In un SR non inerziale possiamo scrivere il secondo principio a patto di usare come risultante delle forze sia quelle reali che quelle fittizie",sistemi riferimento inerziali esiste classe sistemi riferimento vale secondo principio dinamica sistemi riferimento inerziali inerziali moto accelerato rispetto veicolo partenza veicolo frenata piattaforma rotantenel inerziale compaiono forze dette fittizie dovute nuovo rin inerziale possiamo scrivere secondo principio patto usare risultante forze reali fittizie
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#6,6,"LAURA FABBRI  -
Forze fittizie
!30
‘‘‘‘‘‘‘SS’
Forza di CoriolisForza centrifuga→/u1D439′",forze fittizie s forza coriolis forza centrifugau
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#7,7,"LAURA FABBRI  -
Forza centrifuga
!35
-In S (SRI) solidale alla strada agisce una forza reale: forza centripeta;-Oggetti dentro la macchina non sentono l’azione dell’attrito fra ruote e strade e tendono a mantenere il moto rettilineo per il primo principio.  -In S’ (SR NON I) solidale alla macchina: osservatore dentro la macchina si sente spinto verso l’esterno dalla forza centrifuga: •Forza fittizia; •Stesso modulo e direzione della forza centripeta ma verso oppostoForza a cui è soggetto un corpo in moto curvilineo: es macchina in curva",forza centrifuga solidale strada agisce forza reale forza centripeta oggetti dentro macchina sentono lazione dellattrito fra ruote strade tendono mantenere moto rettilineo primo principio solidale macchina osservatore dentro macchina sente spinto verso lesterno forza centrifuga forza fittizia stesso modulo direzione forza centripeta verso opposto forza soggetto corpo moto curvilineo macchina curva
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#8,8,"LAURA FABBRI  -
Forza di Coriolis
!40Piattaforma che ruota con velocità angolare costante e corpo lanciato radialmente con velocità iniziale non nulla.In S SRI solidale al terreno moto della pallina rettilineo uniforme poichè non agiscono forze (primo principio).In S’ SR non I solidale alla piattaforma: pallina risente della forza fittizia di CoriolisyxˆjˆiForza a cui è soggetto un corpo in moto in un sistema di riferimento in rotazione
Traiettoria circolare verso destra rispetto osservatore in S’→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′",forza coriolis piattaforma ruota velocit angolare costante corpo lanciato radialmente velocit iniziale nullain solidale terreno moto pallina rettilineo uniforme poich agiscono forze primo principioin solidale piattaforma pallina risente forza fittizia coriolisyxji forza soggetto corpo moto sistema riferimento rotazione traiettoria circolare verso destra rispetto osservatore su cu au du
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#9,9,"LAURA FABBRI  -
Forza di Coriolis
!45
•Le masse d’aria si spostano dall’alta pressione H alla bassa pressione L: vento di ciclone; •H e L separate di 1000 km; •Emisfero settentrionale: correnti d’aria tendono verso L deviando a destra; •Vortice ciclonico che ruota in senso antiorario nell’emisfero nord e in senso orario nell’emisfero sudResponsabile di molti fenomeni visibili: •Sbilanciata usura dei binari dei treni orientati secondo i meridiani: treno da nord a sud usura maggiormente il binario di destra; •Moto dei gravi su lunghe distanze (missili…); •Circolazione dei venti→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′",forza coriolis le masse daria spostano dallalta pressione bassa pressione vento ciclone separate emisfero settentrionale correnti daria tendono verso deviando destra vortice ciclonico ruota senso antiorario nellemisfero nord senso orario nellemisfero sud responsabile molti fenomeni visibili sbilanciata usura binari treni orientati secondo meridiani treno nord sud usura maggiormente binario destra moto gravi lunghe distanze missili circolazione ventiu cu au du
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#0,0,"Forza: dinamometro•Definizione operativa della forza. •Dinamometro: strumento graduato contente una molla ideale, elastica, deformabile.
!1
0
01
02
03Calibrazione del dinamometro tramite peso campione: unità kg-forza",forza operativa forza dinamometro strumento graduato contente molla ideale elastica deformabile calibrazione dinamometro tramite peso campione unit forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#1,1,"Modello del filo inestensibile•Filo ideale senza massa, in grado di trasportare una forza (TENSIONE) senza allungarsi.
!2
01
01
01
01
Il filo è in grado di trasportare una tensione.  Il dinamometro si allinea al filo.Ciò che misura un dinamometro è un vettore: -Direzione (del filo) -Verso (il filo tira) -Intensità (scala graduata)La forza è un vettore",modello filo ideale senza massa grado trasportare forza senza allungarsi filo grado trasportare tensione dinamometro allinea filoci misura dinamometro vettore direzione del filo verso filo tira intensit scala graduatala forza vettore
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#10,10,"Esercizio 2•Un acrobata, stando nel punto di mezzo di una fune lunga 18 m, esercita una forza di 700 N e fa abbassare la fune di 1.5 m rispetto alle estremità. Determinare la tensione T della fune.
!11
P!",esercizio un acrobata punto mezzo fune lunga esercita forza abbassare fune rispetto estremit determinare tensione fune
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#11,11,"Esercizio 3•Una sfera di peso 4 kg-f si ferma tra due piani inclinati di 30° e 60°. Determinare le reazioni vincolari delle superfici.
!12
P!
P!",esercizio una sfera peso ferma due piani inclinati determinare reazioni vincolari superfici
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#2,2,"03
Come funziona un dinamometro?•Il dinamometro misura una forza       esterna generando una forza         tale che
!3
03
F!F−!dinFkl=−Δ!!""""Legge di HookeestF!dinF!
0estdinFF+=!!!",funziona dinamometroil dinamometro misura forza esterna generando forza tale ffdin fkllegge hookeest fdin estdin
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#3,3,"Natura vettoriale delle forze
!4
02
03
021F!2F!3F!23FF+!!1230FFF++=!!!!In condizioni statiche! (Macchina di Atwood)",natura vettoriale forze fin condizioni statiche macchina atwood
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#4,4,"Quiete, equilibrio e statica
!5Equilibrio: se un sistema (insieme di punti o di corpi) inizialmente quiete in un dato SdR, pur soggetto a forze rimane in quiete, allora esso si trova in uno stato di equilibrio.Quiete: un punto (o un corpo) è in quiete in un dato SdR, se il punto (o ogni punto del corpo) ha una velocità nulla in ogni istante di tempo (è e rimane fermo). Assenza di velocità!
Statica: studio delle forze nei sistemi in stato di equilibrioEquilibrio stabile: piccole variazioni nel sistema portano a piccoli spostamenti dalla posizione di equilibrio Equilibrio instabile: piccole variazioni nel sistema portano a grandi spostamenti
",quiete equilibrio statica equilibrio sistema insieme punti corpi inizialmente quiete dato pur soggetto forze rimane quiete allora esso trova stato punto corpo quiete dato punto ogni punto corpo velocit nulla ogni istante tempo rimane fermo assenza velocit statica studio forze sistemi stato equilibrio equilibrio stabile piccole variazioni sistema portano piccoli spostamenti posizione equilibrio equilibrio instabile piccole variazioni sistema portano grandi spostamenti
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#5,5,"Statica del punto materiale•Risultato sperimentale: il punto è in quiete se:
!61F!2F!
3F!1234RFFFF=+++!!!!!
4F!
12340RFFFF=+++=!!!!!!Risultante delle forze applicate al puntoCondizione necessaria per l’equilibrio di un punto materiale è che si annulli la risultante        di tutte le forze ad esso applicate.R!",statica punto sperimentale punto quiete forze applicate punto condizione necessaria lequilibrio punto materiale annulli risultante tutte forze esso applicater
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#6,6,"Studio statico delle forzeFORZA PESO
!7
01!P!FdinIdea: applicare ad un corpo una forza tramite il dinamometro, adattando verso, direzione e modulo fino a raggiungere l’equilibrio!Fdin+ EQ ⇒!R=0!R=!Fdin+ ?
Ad ogni punto materiale posto in prossimità della superficie terrestre risulta applicata una forza diretta lungo la verticale, verso il basso, con intensità dipendente dal corpo materiale.!P=−!Fdin",studio statico forze pfdin idea applicare corpo forza tramite dinamometro adattando verso direzione modulo fino raggiungere rrfdin ogni punto materiale posto prossimit superficie terrestre risulta applicata forza diretta lungo verticale verso basso intensit dipendente corpo
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#7,7,"REAZIONE VINCOLARE
!8
!P!RV!P+ EQ ⇒!R=!P+!RV!RV=−!P
!F
Quando la superficie di un corpo materiale C, giungendo a contatto con la superficie di un corpo materiale V (vincolo) esercita su tale superficie una forza perpendicolare F, determina una deformazione di V che esercita a sua volta su C una forza RV uguale e contraria ad F   㱺  RV: normale alla superficie, uscente e di modulo dipendente dalla forza applicata F  CV!RV",rpr vp quando superficie corpo materiale giungendo contatto superficie corpo materiale vincolo esercita tale superficie forza perpendicolare determina deformazione esercita volta forza uguale contraria normale superficie uscente modulo dipendente forza applicata
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#8,8,"!9Un vincolo impedisce alcuni movimenti del corpo considerato e ne consente altri (es.: rotaia treno, cardine porta, piano su cui è appoggiato un oggetto, ecc.). Per impedire i movimenti vietati dei corpi, i vincoli debbono esercitare sui corpi delle forze, dette forze vincolari o reazioni vincolari.Le forze vincolari sono a priori sconosciute, in quanto debbono adeguarsi alle circostanze per neutralizzare le forze attive che potrebbero causare movimenti vietati.
Vincolo",vincolo impedisce alcuni movimenti corpo considerato consente altri rotaia treno cardine porta piano appoggiato oggetto ecc impedire movimenti vietati corpi vincoli debbono esercitare corpi forze dette forze vincolari reazioni vincolarile forze vincolari priori sconosciute debbono adeguarsi circostanze neutralizzare forze attive potrebbero causare movimenti vietati vincolo
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#9,9,"Vincoli ideali o lisci•Vincolo ideale o liscio: vincoli che non offrono resistenza apprezzabile quando le forze tendono a produrre degli spostamenti tangenziali rispetto alla loro superficie
!10
PF!VR!
PF!VR!•In caso contrario, se c’è resistenza ai movimenti tangenziali, parleremo di vincolo scabro (forze d’attrito)",vincoli ideali liscivincolo ideale liscio vincoli offrono resistenza apprezzabile quando forze tendono produrre spostamenti tangenziali rispetto superficie rin caso contrario c resistenza movimenti tangenziali parleremo vincolo scabro forze dattrito
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#0,0,DINAMICA CdS Ingegneria InformaticaA.A. 2019/20 ,ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#1,1,"Concetto di forza
",concetto forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#10,10,"Formulazione esplicita del 2° principioNewton: “La forza è uguale alla massa per l’accelerazione."" 
",formulazione esplicita principio newton la forza uguale massa
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#11,11,"Unità di misura della forza
",unit misura forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#12,12,"Forza peso: misura della massa inerzialeN corpi con pesi
",forza peso misura massa inerziale corpi pesi
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#13,13,"Misura della massa inerziale
",misura massa inerziale
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#14,14,"Principi fondamentali•Il secondo principio NON è una definizione di forza
",principi fondamentaliil secondo principio definizione forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#15,15,"Indipendenza delle azioni simultanee
",indipendenza azioni simultanee
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#16,16,"Relazione tra moto e cause•Tutti i problemi di determinazione del moto di un corpo a partire dalle forze che agiscono sono problemi inversi di cinematica
",relazione moto causetutti problemi determinazione moto corpo partire forze agiscono problemi inversi cinematica
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#17,17,"Moto circolare uniforme
nF!Rappresentazione intrinseca della forza
Moto rettilineo
",moto circolare uniforme intrinseca forza moto rettilineo
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#18,18,"Moto circolare uniforme
",moto circolare uniforme
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#19,19,"Caduta dei graviGrave: punto materiale o oggetto in moto a causa del suo peso
",caduta gravi grave punto materiale oggetto moto causa peso
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#2,2,"Concetto di forza
",concetto forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#20,20,"Tutti i corpi cadono nello stesso modo
",corpi cadono stesso modo
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#21,21,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
",punto materiale inizialmente per fermo soggetto accelerazione pari nellintervallo tempo nellintervallo tempo determinare velocit posizione nellistante esercizio
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#22,22,"Piano Inclinato liscio
",piano inclinato liscio
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#23,23,"Forza elastica / Legge di Hooke•k costante elastica della molla. [k]=[MT-2]
",forza elastica legge hookek costante elastica molla
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#24,24,"Oscillatore armonico unidimensionale
",oscillatore armonico unidimensionale
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#25,25,"Regime delle piccole oscillazioni•Osservazione: ogni sistema in prossimità di un punto di equilibrio stabile si comporta come un oscillatore armonico
",regime piccole ogni sistema prossimit punto equilibrio stabile comporta oscillatore armonico
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#26,26,"Pendolo sempliceGalileo: osservazione del moto del lampadario nel Duomo di Pisa
",pendolo semplice galileo osservazione moto lampadario duomo pisa
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#27,27,"Pendolo semplice
",pendolo semplice
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#28,28,"Pendolo semplice II
",pendolo semplice
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#29,29,"Nota storica•Le oscillazioni di un pendolo hanno costituito un primo sistema meccanico per misurare il tempo
",nota storicale oscillazioni pendolo costituito primo sistema meccanico misurare tempo
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#3,3,"Forze fondamentali
",forze fondamentali
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#30,30,"Forza di attrito statico
",forza attrito statico
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#31,31,"Forza di attrito statico
",forza attrito statico
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#32,32,"Piano inclinato ruvidoProblema: sapendo che                , qual è il valore massimo di α per cui il corpo NON si muove?
",piano inclinato ruvido problema sapendo qual valore massimo corpo muove
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#33,33,"Importanza dell’attrito statico
",importanza dellattrito statico
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#34,34,"Importanza dell’attrito statico
(/)(/)1SSrocciametallogommaasfaltoµµ≈≪Indipendente dall’area di contattoASF!",importanza dellattrito statico dallarea contatto
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#35,35,"EsercizioUn mattone è appoggiato su una scanalatura rettilinea ruvida inclinata di un angolo α=35° rispetto ad un piano orizzontale e raccordato nel punto B con un pavimento orizzontale. Le due superfici hanno lo stesso coefficiente di attrito cinetico µc = 0,4. All’istante t = 0 il mattone viene lasciato in quiete da una altezza h = 3 m (punto A). Studiare il moto del mattone calcolando la velocità massima e la lunghezza totale del percorso.
",esercizio mattone appoggiato scanalatura rettilinea ruvida inclinata angolo rispetto piano orizzontale raccordato punto pavimento orizzontale due superfici stesso coefficiente attrito cinetico allistante mattone viene lasciato quiete altezza punto studiare moto mattone calcolando velocit massima lunghezza totale percorso
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#36,36,"Esercizio – Passo 1
",esercizio passo
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#37,37,"Esercizio – Passo 2
Distanza percorsa: ",esercizio passo distanza percorsa
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#38,38,"Esercizio•  Una pallina di massa M=0,2 kg è ferma tra una superficie verticale ed un piano inclinato di un angolo α=15°, come mostrato in figura. Determinare le reazioni vincolari della superficie verticale e del piano inclinato.
",esercizio pallina massa ferma superficie verticale piano inclinato angolo mostrato figura determinare reazioni vincolari superficie verticale piano inclinato
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#39,39,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
",punto materiale inizialmente per fermo soggetto accelerazione pari nellintervallo tempo nellintervallo tempo determinare velocit posizione nellistante esercizio
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#4,4,"Galileo Galilei (1564-1642)Qual è il moto di un corpo non soggetto ad alcuna forza?
",galileo galilei qual moto corpo soggetto alcuna forza
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#40,40,"EsercizioUn proiettile di massa M viene sparato orizzontalmente da un cannone fermo posto su una altura che si eleva di h=50 m rispetto alla pianura circostante. Determinare: 1)il modulo v  della velocità con cui si deve sparare il proiettile affinché colpisca un bersaglio nella pianura e che dista orizzontalmente dal cannone di D=250 m; 2)l’angolo con cui il proiettile colpisce il bersaglio;  3)la velocità scalare del proiettile quando colpisce il bersaglio.
",esercizio proiettile massa viene sparato orizzontalmente cannone fermo posto altura eleva rispetto pianura circostante determinare modulo velocit deve sparare proiettile affinch colpisca bersaglio pianura dista orizzontalmente cannone langolo proiettile colpisce bersaglio velocit scalare proiettile quando colpisce bersaglio
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#41,41,"EsercizioUna molla ideale, di costante elastica k, è sospesa in verticale tramite un aggancio in alto. Ad un certo istante (t=0) si applica una massa m all’altro estremo della molla, che viene quindi lasciata libera. Trovare il moto del punto nella direzione verticale. In presenza di un piccolo attrito, dove si fermerà il punto?
",esercizio molla ideale costante elastica sospesa verticale tramite aggancio alto certo istante applica massa allaltro estremo molla viene quindi lasciata libera trovare moto punto direzione verticale presenza piccolo attrito fermer punto
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#42,42,"EsercizioIl sistema meccanico in ﬁgura è costituito da tre corpi uguali di massa m, un ﬁlo inestensibile ed una superﬁcie ruvida con coefﬁciente di attrito statico 0.6 e coefﬁciente di attrito cinetico 0.4. Determinare: 1) se il sistema è in condizioni di staticità; 2) la tensione nel ﬁlo; 3) cosa succede se il corpo 3 è eliminato dal sistema.
",esercizio sistema meccanico gura costituito tre corpi uguali massa lo inestensibile supercie ruvida coefciente attrito statico coefciente attrito cinetico determinare sistema condizioni staticit tensione lo cosa succede corpo eliminato sistema
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#5,5,"Primo Principio della Dinamica
➡criterio cinematico per stabilire quando su di un punto materiale non agiscono forze. 
",primo principio dinamica criterio cinematico stabilire quando punto materiale agiscono forze
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#6,6,"Classe di Sistemi di Riferimento Inerziali
",classe sistemi riferimento inerziali
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#7,7,"Esiste un SRI privilegiato?S ed S’ sono due SRI: come posso distinguerli sperimentalmente operando solo all’interno di un SRI ?
",esiste privilegiatos due posso distinguerli operando solo allinterno
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#8,8,Approssimazioni di SRI1.Sistema solidale alla terra (SR principale in statica) 2.Sistema con origine nel centro della terra e assi rivolti verso le “stelle fisse”  3.Sistema con origine nel centro del Sole e assi rivolti verso le stelle fisse 4.Sistema con origine nel centro della nostra galassia e assi rivolti verso le galassie più lontane ,approssimazioni risistema solidale terra principale statica sistema origine centro terra assi rivolti verso stelle fisse sistema origine centro sole assi rivolti verso stelle fisse sistema origine centro galassia assi rivolti verso galassie lontane
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#9,9,"Principi fondamentali
",principi fondamentali
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#0,0,"LAVORO ed ENERGIA CdS Ingegneria Informatica A.A. 2019/20
1",ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#1,1,Lavoro ed Energia: definizioni intuitive•Lavoro: caratteristica di una forza di operare uno spostamento •L’energia è la capacità di produrre lavoro •Il lavoro è il processo attraverso il quale una certa quantità di energia si trasferisce da un corpo a un altro. •Ingredienti per una definizione più rigorosa di Lavoro: forza e movimento,lavoro energia definizioni caratteristica forza operare spostamento lenergia capacit produrre lavoro il lavoro processo attraverso certa quantit energia trasferisce corpo altro ingredienti definizione rigorosa lavoro forza movimento
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#10,10,"Lavoro di una forza elastica
11
Esempio: lavoro compiuto da una molla compressa da l1 fino all’ espansione l2δℒ=⃗F⋅d⃗l=(−kx̂ı)⋅(̂ıdx)=−kxdx(̂ı⋅̂ı)=−kxdxℒ1,2=∫x2x1⃗F⋅d⃗l=−k∫x2x1xdx−k[x22]x2x1=−k2x22+k2x21=−k2(l2−l0)2+k2(l1−l0)2ℒ1,2=−k2(x22−x21)",lavoro forza elastica esempio lavoro compiuto molla compressa fino all espansione
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#11,11,"Lavoro della forza peso
12
SARA VALENTINETTI  -
Stessa conclusione se al posto del piano inclinato abbiamo un profilo curvo.Lavoro infinitesimoLavoro totale
𝑧1𝑧2 ℒ1,2=mghh = differenza di quota a cui si porta il punto
𝑑𝑙𝑧1𝑧2Esempio: punto materiale di massa m scivola su un piano liscio inclinato di un angolo  da un punto P1 a un punto P2 a differenza di quota hδℒ=⃗F⋅d⃗l=(−mĝk)⋅(̂ıdx+̂kdz)==−mg(̂k⋅̂ı)−mg(̂k⋅̂k)=−mgdzℒ1,2=∫P2P1⃗F⋅d⃗l=−mg∫z2z1dz=−mg(z2−z1)=mgh>0",lavoro forza peso stessa conclusione posto piano inclinato profilo curvolavoro infinitesimo lavoro totale mghh differenza quota porta punto esempio punto materiale massa scivola piano liscio inclinato angolo punto punto differenza quota
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#12,12,"Proprietà additiva dei lavori
13Punto materiale soggetto a N forze, equivale a un punto soggetto alla risultante delle forzeLavoro infinitesimo di ciascuna forza:Lavoro infinitesimo totale:Date n forze Fi , applicate allo stesso punto P, che si muove lungo una propria curva  dal punto A al punto B,  il lavoro complessivo è dato da….ℓLo spostamento è lo stesso per ogni forza perché agiscono tutte sulla stessa particella che compie un tratto di traiettoria.
Somma dei lavori delle singole forze.δℒ=⃗F⋅d⃗lδℒtot=δℒ1+δℒ2+...=⃗F1⋅d⃗l+⃗F2⋅d⃗l+...=(⃗F1+⃗F2+...)⋅d⃗l=(∑i⃗Fi)⋅d⃗l=⃗R⋅d⃗lℒℓtot=∫BAℓ⃗R⋅d⃗l=∫BAℓ(∑i⃗Fi)⋅d⃗l=∫BAℓ(∑i⃗Fi⋅d⃗l)=∑i∫BAℓ⃗Fi⋅d⃗l=∑iℒℓi",propriet additiva lavori punto materiale soggetto forze equivale punto soggetto risultante forze lavoro infinitesimo ciascuna forzalavoro infinitesimo totaledate forze applicate stesso punto muove lungo propria curva punto punto lavoro complessivo dato da spostamento stesso ogni forza agiscono tutte stessa particella compie tratto traiettoria somma lavori singole ardlb afidlii
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#13,13,"Potenza di una forzaDef: capacità di produrre lavoro per unità di tempo
14•Per un punto materiale:Nuova definizione di lavoroLavoro compiuto da una forza per unità di tempo durante un intervallo di tempo infinitesimo P=δℒdtP=δℒdt=⃗F⋅d⃗ldt=⃗F⋅d⃗ldt=⃗F⋅⃗vP=⃗F⋅⃗vδℒ=Pdt⟹ℒ=∫Pdt",potenza forza def capacit produrre lavoro unit tempo per punto materialenuova definizione lavoro lavoro compiuto forza unit tempo durante intervallo tempo infinitesimo pdt
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#14,14,"Analisi dimensionale
15LavoroL⎡⎣⎤⎦=F⋅ds⎡⎣⎤⎦=N⋅m⎡⎣⎤⎦=kg⋅ms2⋅m⎡⎣⎢⎤⎦⎥=MLT−2L⎡⎣⎤⎦⇒L⎡⎣⎤⎦=ML2T−2⎡⎣⎤⎦Unitá di misura: SI-MKS  Joule(J)=N⋅mPotenzaP⎡⎣⎤⎦=LΔt⎡⎣⎢⎤⎦⎥=F⋅dsΔt⎡⎣⎢⎤⎦⎥=N⋅ms⎡⎣⎢⎤⎦⎥=kg⋅ms2⋅m⋅1s⎡⎣⎢⎤⎦⎥=MLT−2LT−1⎡⎣⎤⎦⇒P⎡⎣⎤⎦=ML2T−3⎡⎣⎤⎦Unitá di misura: SI-MKS  Watt(W)=Joule/s",analisi dimensionale lavoro lt llm tunit misura joulejnm potenza lt tunit misura wattwjoules
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#15,15,"Esercizio
16Determinare la potenza istantanea sviluppata durante la caduta su un piano inclinato di un angolo  alto h da un punto A in cima al piano ad un punto B in fondo al piano da un punto materiale di massa m.α",esercizio determinare potenza istantanea sviluppata durante caduta piano inclinato angolo alto punto cima piano punto fondo piano punto materiale massa
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#16,16,"Teorema delle Forze Vive
17
Es: Corpo in moto con velocità  su piano orizzontale liscio contro molla. Corpo comprime molla perdendo velocità. Molla esercita forza tale che  e  opposti e       v⃗Fdxℒ<0•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.",teorema forze vive corpo moto velocit piano orizzontale liscio molla corpo comprime molla perdendo velocit molla esercita forza tale opposti scalare legato forza spostamento maxwell il lavoro latto viene realizzata modificazione deformazione spostamento configurazione sistema materiale forze modificazione oppongono il lavoro forma energia macchina compie lavoro trasferisce energia corpo allaltro
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#17,17,"Teorema delle Forze Vive
18•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.
Alla fine del moto il corpo è fermo e molla compressa esercita forza che tende a ridistenderla, in grado di rimettere in moto il corpo. In questo caso  e  hanno stesso verso e     ⃗Fdxℒ>0Relazione fra velocità e lavoroSperimentalmente  ⃗vfinale=−⃗viniziale",teorema forze vive lavoro scalare legato forza spostamento maxwell il lavoro latto viene realizzata modificazione deformazione spostamento configurazione sistema materiale forze modificazione oppongono il lavoro forma energia macchina compie lavoro trasferisce energia corpo allaltro fine moto corpo fermo molla compressa esercita forza tende ridistenderla grado rimettere moto corpo caso stesso verso fdx relazione fra velocit lavoro
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#18,18,"Teorema delle Forze Vive
19Descrive il lavoro compiuto da un sistema di forze qualunque (attive, vincolari, interne, esterne, di interazione o apparenti), su un sistema meccanico qualunque (puntiforme, esteso, rigido, non rigido, vincolato, ecc.). Teorema delle forze vive per il punto materiale:Lavoro compiuto da tutte le forze per spostare corpo da A a B lungo un tratto di traiettoriaSostituisco la definizione di d⃗lProprietà delle derivate principio: risultante di tutte le forzeℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅d⃗ld⃗l=⃗vdt⟹ℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdtℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdt=∫BAm12dv2dtdt=12m∫BAdv2=12m[v2]BA=12mv2B−12mv2A",teorema forze vive descrive lavoro compiuto sistema forze qualunque attive vincolari interne esterne interazione apparenti sistema meccanico qualunque puntiforme esteso rigido rigido vincolato ecc teorema forze vive punto compiuto tutte forze spostare corpo lungo tratto traiettoria sostituisco definizione dl propriet derivate principio risultante tutte forze abb afdlb abb afdlb amdvdtvdt abb afdlb amdvdtvdtb advmvb amv bmv
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#19,19,"Teorema delle Forze Vive
20Il lavoro compiuto dalla risultante delle forze che agiscono su un sistema meccanico qualunque, nel passaggio da una configurazione A ad un’altra B, è uguale alla corrispondente variazione dell’energia cinetica di tale sistema.Se  forza ha accelerato il corpo compiendo un lavoro positivoℒ>0⟹vB>vA→Se forza ha decelerato il corpo compiendo un lavoro negativoℒ<0⟹vB<vA→Energia Cinetica: 1. Ha le dimensioni del lavoro       2. Non è  mai negativa  (T>=0)[𝑇]=[12𝑚𝑣2]=[𝑀𝐿2𝑇−2]→JouleT=12mv2ℒA,B=12mv2B−12mv2A=TB−TA",teorema forze vive lavoro compiuto risultante forze agiscono sistema meccanico qualunque passaggio configurazione unaltra uguale corrispondente variazione dellenergia cinetica tale sistemase forza accelerato corpo compiendo lavoro positivov ase forza decelerato corpo compiendo lavoro negativov aenergia cinetica dimensioni lavoro mai negativa tmv abmv bmv bt
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#2,2,"Lavoro ed Energia: MacchineUna macchina è un dispositivo vincolato capace di spostare il punto di applicazione di una forza, chiamata “resistente”, sfruttando un’altra forza chiamata “motrice”.
Una macchina “vantaggiosa” sposta il punto di applicazione di una forza resistente utilizzando una forza motrice di modulo più piccolo.carrucolapiano inclinatoleva",lavoro energia macchine macchina dispositivo vincolato capace spostare punto applicazione forza chiamata resistente sfruttando unaltra forza chiamata motrice macchina vantaggiosa sposta punto applicazione forza resistente utilizzando forza motrice modulo inclinatoleva
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#20,20,"Energia Potenziale
21
Lavoro sul corpo (teorema delle forze vive):Corpo in moto su un piano orizzontale liscio contro una molla ideale •velocità iniziale del carrello v0,  •velocità finale nulla poiché comprime una molla che esercita una forza opposta allo spostamento del corpo provocandone l’arresto.ℒcorpo=Tfin−Tin=12mv2fin−12mv2in=0−12mv20<0",energia potenziale lavoro corpo teorema forze vivecorpo moto piano orizzontale liscio molla ideale velocit iniziale carrello velocit finale nulla poich comprime molla esercita forza opposta spostamento corpo provocandone
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#21,21,"Energia Potenziale
22•Molla inizialmente in quiete si comprime per effetto di una forza premente.  •Chi produce la forza compressiva è il carrello e l’entità della compressione è una misura della forza agente.  •Forza reagente della molla è uguale e opposta alla forza premente.Lavoro sulla molla (teorema delle forze vive):   
Dal punto di vista della molla…
ℒmolla=Tfin−Tin=12mv2fin−12mv2in=12mv20−0=−ℒcorpo>0",energia potenziale molla inizialmente quiete comprime effetto forza premente chi produce forza compressiva carrello lentit compressione misura forza agente forza reagente molla uguale opposta forza prementelavoro molla teorema forze vive punto vista molla
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#22,22,"Energia Potenziale
23•Corpo in ragione della velocità compie un lavoro positivo sulla molla comprimendola; •Energia di un corpo: possibilità di un corpo di compiere un lavoro positivo; •Energia del carrello in moto si trasferisce gradualmente alla molla; •Quando il carrello si ferma, tutta la sua energia cinetica iniziale è trasferita alla molla compiendo un lavoro positivo su di essa; •Molla immagazzina l‘energia del corpo comprimendosi; •Molla poi rilascia gradualmente l’energia immagazzinata distendensosi e imprimendo al corpo una velocità uguale e contraria: restituisce energia cinetica al carrello; •energia totale immagazzinata dalla molla ridiventa interamente energia cinetica",energia potenziale corpo ragione velocit compie lavoro positivo molla comprimendola energia corpo possibilit corpo compiere lavoro positivo energia carrello moto trasferisce gradualmente molla quando carrello ferma tutta energia cinetica iniziale trasferita molla compiendo lavoro positivo essa molla immagazzina lenergia corpo comprimendosi molla poi rilascia gradualmente lenergia immagazzinata distendensosi imprimendo corpo velocit uguale contraria restituisce energia cinetica carrello energia totale immagazzinata molla ridiventa interamente energia cinetica
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#23,23,"Energia Potenziale
24
0Lavoro forza elastica:Molla compressa di una certa quantità a ad un certo tempo t>0Teorema forze vive:Uguagliando:Energia iniziale: cineticaEnergia totale istantanea durante la compressioneLavoro che sarebbe in grado di fornire la molla ridistendendosi -> misura dell’energia propria immagazzinata dalla molla: Energia potenzialeLa somma dell’energia cinetica e di quella potenziale si conserva IN QUESTO moto.ℒel=Tfin−Tin=12mv2−12mv20ℒel=∫finin⃗Fel⋅d⃗l=∫finin(−kx̂ı)⋅(̂ıdx)=∫finin−kxdx=−k[x22]finin=−kx2212mv2−12mv20=−kx22⟹12mv2+kx22=12mv20kx22",energia potenziale lavoro forza elasticamolla compressa certa quantit certo tempo teorema forze iniziale cinetica energia totale istantanea durante compressione lavoro grado fornire molla ridistendendosi misura dellenergia propria immagazzinata molla energia potenziale somma dellenergia cinetica potenziale conserva
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#24,24,"Esercizio
25Un blocco di ghiaccio è in moto su una salita inclinata di  Sapendo che all’inizio la sua velocità è pari a v = 9 m/s e che il coefficiente di attrito dinamico è pari a , di quanto si sposta lungo il piano inclinato il blocco di ghiaccio prima di fermarsi?α=6∘μc=0.07",esercizio blocco ghiaccio moto salita inclinata sapendo allinizio velocit pari coefficiente attrito dinamico pari sposta lungo piano inclinato blocco ghiaccio prima
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#25,25,"Esercizio
26Un blocco P di massa m = 3 kg si muove di moto rettilineo su un piano orizzontale scabro nella direzione dell’asse di una molla non deformata, di cui va a colpire uno degli estremi, mentre l’altro è bloccato a un supporto verticale fisso. La molla, di costante elastica k = 300 N/m, viene compressa di  Sapendo che il coefficiente di attrito dinamico fra P e il piano è , determinare: 1) I lavori compiuti durante tale compressione dalla forza elastica e dalla forza di attrito; 2) Il modulo della velocità di P nel momento in cui colpisce la molla. δ=8cmμc=0.25",esercizio blocco massa muove moto rettilineo piano orizzontale scabro direzione dellasse molla deformata colpire estremi mentre laltro bloccato supporto verticale fisso molla costante elastica viene compressa sapendo coefficiente attrito dinamico fra piano determinare lavori compiuti durante tale compressione forza elastica forza attrito modulo velocit momento colpisce molla cmc
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#26,26,"Esercizio
27Un cubetto P di massa m scivola lungo il segmento AB disposto lungo un piano inclinato di un angolo  rispetto alla direzione orizzontale. Il coefficiente di attrito dinamico passa dal valore massimo di ½ alla sommità A al valore 0 alla base B secondo una legge del tipo  dove e k sono costanti positive e s è la distanza da A di un generico punto di AB. Sapendo che  e che P è partito da fermo in A, calcolare il modulo v della sua velocità all’istante in cui arriva in B in termini di  e della variazione di quota h fra A e B.Ah𝛼B",esercizio cubetto massa scivola lungo segmento disposto lungo piano inclinato angolo rispetto direzione orizzontale coefficiente attrito dinamico passa valore massimo sommit valore base secondo legge tipo costanti positive distanza generico punto sapendo partito fermo calcolare modulo velocit allistante arriva termini variazione quota fra bah
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#27,27,"Alcuni concetti matematici
28•Derivate parziali: primo e secondo ordine, miste… •Differenziali; •Campi: scalari, vettoriali…",alcuni concetti matematici derivate parziali primo secondo ordine miste differenziali campi scalari vettoriali
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#28,28,"Derivate parziali
29Se una funzione esiste per ogni valore della variabile nel dominio, derivate parziali al primo ordine:Se le derivate parziale al primo ordine esistono per ogni valore della variabile nel dominio, derivate parziali al secondo ordine:
Derivate parziali miste (l’ordine non influenza)𝜕𝑧2Es: ∂f(x,y,z)∂xx0,y0,z0=limΔx→0f(x0+Δx,y0,z0)Δx∂f(x,y,z)∂yx0,y0,z0=limΔy→0f(x0,y0+Δy,z0)Δy∂f(x,y,z)∂zx0,y0,z0=limΔy→0f(x0,y0,z0+Δz)Δz∂2f(x,y,z)∂x∂y,∂2f(x,y,z)∂y∂z,∂2f(x,y,z)∂x∂zf(x,y,z)=x3−y2+3z",derivate parziali funzione esiste ogni valore variabile dominio derivate parziali primo ordinese derivate parziale primo ordine esistono ogni valore variabile dominio derivate parziali secondo ordine derivate parziali miste lordine influenza
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#29,29,"DifferenzialiSia  una funzione a 3 variabili. Quanto varia il valore della funzione se ci spostiamo da un punto  a un punto infinitamente vicino  ?f(x0+dx,y0+dy,z0+dz)=f(x0,y0,z0)+∂f∂xP0dx+∂f∂yP0dy+∂f∂zP0dzDifferenzialedF=f(x0+dx,y0+dy,z0+dz)−f(x0,y0,z0)=∂f∂xdx+∂f∂ydy+∂f∂zdzPiù ordini successivi
30",differenziali funzione variabili varia valore funzione spostiamo punto punto infinitamente vicino pdxfy pdyfz pdz differenzialed ordini successivi
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#3,3,"Definizione di lavoro infinitesimo
4
P1P2
xyzOLavoro infinitesimo compiuto da  durante uno spostamento infinitesimo   la quantità scalare:⃗Fd⃗lPer definire lavoro infinitesimo compiuto da una forza:In un intervallo di tempo   i, punto si sposta da P1 a P2 :    ΔtΔ⃗r=⃗r2−⃗r1-Regione di spazio in cui agisce  -Punto P si muove lungo linea curva   ⃗FℓSe  piccolo,             tangente ΔtΔ⃗r→d⃗l=̂utdlLavoro infinitesimo  perché non è un differenziale esatto (in generale non dipende solo dagli estremi in cui si integra).δLδℒ=⃗F⋅d⃗lΔ⃗rℓ",definizione lavoro infinitesimo xyz olavoro infinitesimo compiuto durante spostamento infinitesimo quantit scalarefdl definire lavoro infinitesimo compiuto forzain intervallo tempo punto sposta trrr regione spazio agisce punto muove lungo linea curva f piccolo tangente trdlutdl lavoro infinitesimo differenziale esatto generale dipende solo estremi integra lfdlr
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#30,30,"CampiCampo scalare: una grandezza scalare funzione delle coordinate spaziali U(x,y,z) definita ovunque dentro una certa regione di spazio. Superficie di livello: luogo geometrico dei punti dove la funzione scalare assume un valore costante prefissato  U(x,y,z) = costante -> infinite superficiCampo vettoriale: un vettore applicato funzione delle coordinate spaziali               definito ovunque dentro una certa regione di spazioLinee di forza: una o più linee sempre tangenti al vettore del campo. Le linee di forza sono più fitte dove il modulo del vettore è maggiore.31",campi campo scalare grandezza scalare funzione coordinate spaziali uxyz definita ovunque dentro certa regione spazio superficie livello luogo geometrico punti funzione scalare assume valore costante prefissato uxyz costante infinite superfici campo vettoriale vettore applicato funzione coordinate spaziali definito ovunque dentro certa regione spazio linee forza linee sempre tangenti vettore campo linee forza fitte modulo vettore maggiore
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#31,31,"Campi di forze conservativi
32In generale il lavoro di una forza per spostare un punto materiale su un tratto AB di traiettoria dipende dalla traiettoriayzx0AB..12Per il teorema delle forze vive:Le velocità agli estremi sono diverse a seconda che si percorra la curva 1 o la 2.ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗l⟹ℒ1(A,B)≠ℒ2(A,B)ℒ1(A,B)=12m(vB)2−12m(vA)2ℒ2(A,B)=12m(v′",campi forze conservativi generale lavoro forza spostare punto materiale tratto traiettoria dipende traiettoriayzx teorema forze vivele velocit estremi diverse seconda percorra curva abb bmv
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#32,32,"Campi di forze conservativi
33Campo di forza conservativo: forza posizionale che, spostando il suo punto di applicazione da A a B, punti qualunque del dominio di esistenza, compie un lavoro che è indipendente dalla particolare traiettoria seguita, ma dipendente soltanto dagli estremi A e B. 
ℒA,B=∫BA⃗F⋅d⃗lℒ1(A,B)=ℒ2(A,B)=ℒ3(A,B)=...=ℒA,B",campi forze conservativi campo forza conservativo forza posizionale che spostando punto applicazione punti qualunque dominio esistenza compie lavoro indipendente particolare traiettoria seguita dipendente soltanto estremi abb
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#33,33,"Campi di forze conservativi: 1a proprietà
34
AB12Campo conservativo:
1a Proprietà
Lavoro su una curva chiusa di una forza conservativa (circuitazione) è nulloCondizione necessaria (se il campo è conservative allora la circuitazione è nulla) e sufficiente (se la circuitazione è nulla allora il campo è conservativo)ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗lℒA,B=∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹∫BA1⃗F⋅d⃗l−∫BA2⃗F⋅d⃗l=0∫BA1⃗F⋅d⃗l+∫AB2⃗F⋅d⃗l=0⟹ℒ=∮⃗F⋅d⃗l
ℒ=∮⃗F⋅d⃗l",campi forze conservativi propriet campo conservativo propriet lavoro curva chiusa forza conservativa circuitazione nullo condizione necessaria campo conservative allora circuitazione nulla sufficiente circuitazione nulla allora campo afdl abb afdlb afdlb afdlb afdlb afdla fdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#34,34,"Campi di forze conservativi: 2a proprietà 
35 funzione scalare definita in ogni punto dello spazio legata al valore della forza in quell punto. Fissata a meno di una costante additiva arbitraria: se  soddisfa la relazione anche  lo faU=U(x,y,z)U(x,y,z)U′",campi forze conservativi propriet funzione scalare definita ogni punto spazio legata valore forza quell punto fissata meno costante additiva arbitraria soddisfa relazione
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#35,35,"Campi di forze conservativi: 2a proprietà 
Esiste una  funzione scalare U(P), dipendente solo dalla posizione e dalla forza, detta potenziale tale che2a Proprietàyzx0BA..123Percorso AB: A->O->B
ℒA,B=∫BA1⃗F⋅d⃗l=∫0A2⃗F⋅d⃗l+∫03B⃗F⋅d⃗l=−∫A02⃗F⋅d⃗l+∫03B⃗F⋅d⃗l==−[U(A)−U(0)]+[U(B)−U(0)]=U(B)−U(A)ℒA,B=U(B)−U(A)36",campi forze conservativi propriet esiste funzione scalare dipendente solo posizione forza detta potenziale tale chea proprietyzx percorso abb afdl afdl abubua
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#36,36,"Energia potenzialeAl posto di U(P) si preferisce introdurre V(P)=−U(P)
37•V(P) misura la capacità che ha il punto P di produrre lavoro quando il punto materiale ritorna all’origine.2a ProprietàEsiste una funzione scalare V(P), dipendente solo dalla posizione e dalla forza, detta energia potenziale tale cheLe prime due proprietà devono essere mutualmente dimostrabili.ℒA,B=U(B)−U(A)=V(A)−V(B)V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l",energia potenziale posto preferisce introdurre vpup vp misura capacit punto produrre lavoro quando punto materiale ritorna alloriginea propriet esiste funzione scalare dipendente solo posizione forza detta energia potenziale tale prime due propriet devono essere mutualmente dimostrabili pfdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#37,37,"Forze conservative 3a proprietà
38Campo conservativo è un differenziale esattoPer definizioneFxdx+Fydy+Fzdz=−∂V∂xdx−∂V∂ydy−∂V∂zdzdV=∂V∂xdx+∂V∂ydy+∂V∂zdzUguagliandoδℒ=⃗F⋅d⃗l=Fxdx+Fydy+Fzdz=dU=−dV",forze conservative propriet campo conservativo differenziale esatto definizione ud
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#38,38,"Forze conservative 3a proprietà
39Operatore vettoriale (operatore simbolico)  nabla
3a ProprietàLa forza è col segno meno il gradiente dell’energia potenziale NB: l’operatore nabla non è un vettore, è un operatore che agisce sulle funzioni, come la derivata o l’integrale. Il risultato dell’operazione dipende al tipo di funzione a cui è applicato. ",forze conservative propriet operatore vettoriale operatore simbolico nabla propriet forza segno meno gradiente dellenergia potenziale loperatore nabla vettore operatore agisce funzioni derivata lintegrale risultato delloperazione dipende tipo funzione applicato
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#39,39,"Operatore Nabla
40
Nabla:Gradiente di una funzione scalare
Divergenza di un campo vettoriale
Rotore di un campo vettoriale
È un vettoreÈ uno scalareÈ un vettoreÈ un operatore",operatore nabla nablagradiente funzione scalare divergenza campo vettoriale rotore campo vettoriale vettore scalare vettore operatore
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#4,4,"Se chiamo   la componente della forza lungo la tangente allo spostamento allora  Ft=Fcosθ
Definizione di lavoro infinitesimo
5Lavoro infinitesimo compiuto da una forza:Il lavoro infinitesimo è il prodotto dello spostamento per la componente della forza lungo lo spostamentoSe la forza è  allo spostamento:        ⊥δℒ=0Es:
NB:definizioni valgono per qualsiasi forza, non è detto sia quella che causa il moto!δℒ=⃗F⋅d⃗l=|⃗F||d⃗l|cosθ=Fdlcosθδℒ=Ftdlδℒpeso=0δℒforza⃗F≠0",chiamo componente forza lungo tangente spostamento allora ftfcos definizione lavoro infinitesimo lavoro infinitesimo compiuto forzail lavoro infinitesimo prodotto spostamento componente forza lungo spostamento forza spostamento bdefinizioni valgono qualsiasi forza detto causa
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#40,40,"Significato dell’operatore gradienteL’operatore gradiente restituisce un vettore diretto lungo la direzione in cui aumenta più velocemente la funzione scalare.
41Campo scalare
xy
Superfici (linee) di livello
Vettore applicato!
Diretto dove f(x,y) aumenta e       alle superfici di livello⊥",significato delloperatore gradiente loperatore gradiente restituisce vettore diretto lungo direzione aumenta velocemente funzione scalare campo scalare superfici linee livello vettore applicato diretto fxy aumenta superfici livello
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#41,41,"Forze conservative 4a proprietà
423a proprietàRotoreSostituisco la prima nella seconda:Proprietà delle derivate parziali seconde per funzioni continue e derivabili:∂2V∂x∂y=∂2V∂y∂x∂2V∂x∂z=∂2V∂z∂x∂2V∂y∂z=∂2V∂z∂y𝜕𝑧",forze conservative propriet propriet rotore sostituisco prima derivate parziali seconde funzioni continue derivabili vxy vyx vxz vzx vyz vzy
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#42,42,"Forze conservative 4a proprietà
4a pr oprietà:  se il campo è conservativo il suo rotore é nulloCondizione necessaria e sufficiente affinché un campo di forze sia conservativo è che il rotore si annulli in tutti i punti del campo.Modo facile e pratico per verificare se un campo è conservativo:𝜕𝑧
43",forze conservative propriet opriet campo conservativo rotore nullo condizione necessaria sufficiente affinch campo forze conservativo rotore annulli punti campomodo facile pratico verificare campo conservativo
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#43,43,"ℒ=∮⃗F⋅d⃗lRiepilogo: Forze conservative
44
1a Proprietà
2a ProprietàEsiste una funzione scalare V(P) (=-U(P)), detta energia potenziale, tale che
ℒA,B=V(A)−V(B)
3a Proprietà
4a Proprietà
Tutte le proprietà sono simultaneamente necessarie e sufficienti (la verifica di una implica tutte le altre)Forze posizionali il cui lavoro non dipende mai dal percorso ma solo dal punto di partenza e dal punto di arrivo.",fdl riepilogo forze conservative propriet propriet esiste funzione scalare detta energia potenziale tale abvavb propriet propriet tutte propriet simultaneamente necessarie sufficienti verifica implica tutte altreforze posizionali lavoro dipende mai percorso solo punto partenza punto arrivo
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#44,44,"Calcoli di energia potenziale
45yz
xP(t)O1Data una forza conservativa, trovare l’energia potenziale
2AB
V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗lℒ0,P=ℒ1(0,P)=ℒ2(0,P)=ℒ(0,A,B,P)",calcoli energia potenziale pto data forza conservativa trovare lenergia potenziale
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#45,45,"Calcoli di energia potenziale
46
1. Scelgo un percorso arbitrario su una spezzata2. Applico la definizione di energia potenziale sul percorso sceltoIn coordinate cartesiane:V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l",calcoli energia potenziale scelgo percorso arbitrario spezzata applico definizione energia potenziale percorso scelto coordinate pfdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#46,46,"47Esercizio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)=",esercizio calcolare lenergia elettrostatica sfera raggio rin distribuita uniformemente carica condensit acostante r certa regione spazio presenti due campi determinarea gradiente kxyk xyb due campi essere considerato elettrostatico consideri campofx
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#47,47,"Esercizio   Sia dato un punto materiale di massa M su cui agisce una forza conservativa di energia potenziale:                                Sapendo che le costanti α e β sono positive, determinare:   1) l’espressione della forza;   2) le dimensioni e le unità di misura delle costanti α e β;    3) l’accelerazione del corpo quando passa per il punto P(0,L,L).
48
",esercizio dato punto materiale massa agisce forza conservativa energia potenziale sapendo costanti positive determinare lespressione forza dimensioni unit misura costanti laccelerazione corpo quando passa punto pll
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#48,48,"Conservazione dell’energia meccanica
49Sistema meccanico con: -Vincoli ideali -Forze attive conservativeTeo. forze viveCampi conservativiUguagliando:Energia meccanica:E=T+VTeorema della conservazione dell’energia meccanica: Per un sistema meccanico sottoposto a vincoli tutti ideali ed a forze non vincolari tutte conservative, l’energia meccanica E si conserva, ossia la somma fra l’energia cinetica T e  l’energia potenziale totale V, rimane costante durante il moto. 
Dimensionalmente:                    JouleE⎡⎣⎤⎦=T⎡⎣⎤⎦=V⎡⎣⎤⎦NB: A e B sono punti sulla traiettoria, l’energia si conserva lungo la traiettoria
ℒA,B=V(A)−V(B)
ℒA,B=T(B)−T(A)ℒA,B=T(B)−T(A)=V(A)−V(B)⟹T(A)+V(A)=T(B)+V(B)",conservazione dellenergia meccanica sistema meccanico con vincoli ideali forze attive conservative teo forze vive campi conservativi meccanicaetv teorema conservazione dellenergia meccanica sistema meccanico sottoposto vincoli ideali forze vincolari tutte conservative lenergia meccanica conserva ossia somma fra lenergia cinetica lenergia potenziale totale rimane costante durante moto joule punti traiettoria lenergia conserva lungo traiettoria abvavb abtbta
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#49,49,"Conservazione dell’energia meccanica
50
x
x
E1E2Corpo 1: Stato liberox1x≥x1x2x3Corpo 2: Stato legatox2≤x≤x3Curva nera:  V(x) energia potenzialeIn una certa regione di spazio E è costante Se V aumenta  T diminuisce  e viceversaMoto possibile solo nelle regioni di spazio in cui                        per def di TE≥V",conservazione dellenergia meccanica corpo stato corpo stato legatoxxx curva nera energia potenziale certa regione spazio costante aumenta diminuisce viceversa moto possibile solo regioni spazio def ev
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#5,5,"Definizione di lavoro
6
AB
xyzOIl lavoro totale compiuto dalla forza su un punto materiale in un intervallo di tempo in cui il punto si sposta da A a B è la somma di tutti i lavori infinitesimi:d⃗l1d⃗l2d⃗l3
Il lavoro compiuto da una generica forza, il cui punto di applicazione P si sposta da A a B lungo una linea , è l’integrale esteso a tale linea del prodotto scalare fra la forza  e lo spostamento infinitesimo :⃗Fℓ⃗Fd⃗lℓℒ=∑iδℒ=∑i⃗Fi⋅d⃗liℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l",definizione lavoro xyz oil lavoro totale compiuto forza punto materiale intervallo tempo punto sposta somma lavori lavoro compiuto generica forza punto applicazione sposta lungo linea lintegrale esteso tale linea prodotto scalare fra forza spostamento infinitesimo afdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#50,50,"Esempi: forza elastica
51Verifichiamo se è conservativa:  ?⃗∇∧⃗F=0
Forza elastica:
La forza elastica è conservativa⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(∂(ky)∂z−∂(kz)∂y)+̂𝚥(∂(kz)∂x−∂(kx)∂z)+̂k(∂(kx)∂y−∂(ky)∂x)=⃗0",esempi forza elastica verifichiamo conservativa f forza elastica forza elastica
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#51,51,"Potenziale elastico
52yzxP(t)OABV(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,0,0)0kxdx+∫(x,y,0)(x,0,0)kydy+∫(x,y,z)(x,y,0)kzdz==kx22+ky22+kz22=k2(x2+y2+z2)=k|⃗r2|2V(P)=k2(x2+y2+z2)=k|⃗r2|2",potenziale elastico yzx pto calcolata percorso
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#52,52,"Esempi: forza pesoForza peso:
53
La forza peso è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(−∂(−mg)∂y)+̂𝚥(∂(−mg)∂x)+0̂k=⃗0",esempi forza peso forza peso forza peso conservativa verifichiamo conservativa
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#53,53,"Potenziale gravitazionale
54yzxP(t)OAB𝑉(𝑃)=𝑚𝑔𝑧
V(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,y,z)(x,y,0)mgdz=mgz",potenziale gravitazionale yzx pto ab calcolata percorso
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#54,54,"Esempi: forza costanteForza costante:
55
Una forza costante è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂fy∂z−∂fz∂y)+̂𝚥(∂fz∂x−∂fx∂z)+̂k(∂fx∂y−∂fy∂x)=⃗0",esempi forza costante forza costante forza costante conservativa verifichiamo conservativa
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#55,55,"Potenziale di una forza costante
56yzxP(t)OAB𝑉(𝑃)=−𝑓𝑥𝑥−𝑓𝑦𝑦−𝑓𝑧𝑧
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0fxdx−∫(x,y,0)(x,0,0)fydy−∫(x,y,z)(x,y,0)fzdz==−fx∫(x,0,0)0dx−fy∫(x,y,0)(x,0,0)dy−fz∫(x,y,z)(x,y,0)dz=−fxx−fyy−fzz",potenziale forza costante yzx pto
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#56,56,"Esempi: campo centrale  a simmetria sfericaForza centrale a simmetria sferica:
57Verifichiamo se è conservativa:
Tutti i campi centrali a simmetria sferica sono conservativixyz
O funzione scalare della sola posizione   è un’energia potenziale se è possibile trovare una funzione scalare t.c  (forza è conservativa).F(r)drF(r)dr=−dVF(r)dr=−dV⟹F(r)=−dV/drd⃗l=̂u⊥(dl⊥)+̂ur(dr)δℒ=⃗F⋅d⃗l=F̂ur⋅(̂u⊥dl⊥+̂urdr)=F(ur⋅̂u⊥dl⊥+ur⋅̂urdr)=Fdrd⃗l=(dl⊥)̂u⊥+(dlr)̂ur=0=1⃗F(⃗r)=F(r)̂ur
ℒA,B=∫BAF(r)dr=−∫BAdV=V(rB)−V(rA)AB",esempi campo centrale simmetria sferica forza centrale simmetria sferica verifichiamo conservativa campi centrali simmetria sferica conservativixyz funzione scalare sola posizione unenergia potenziale possibile trovare funzione scalare forza frdrd vfrdrd vfrd abb afrdrb vvr bvr
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#57,57,"•sono arrivato qua •(mancano le animazioni)
58",sono arrivato qua mancano animazioni
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#58,58,"Lavoro di una forza di attrito dinamico
59Lavoro lungo la traiettoria 2:
BLavoro lungo la traiettoria 1:Lavoro da A a B della forza di attrito dinamico:1
ATutte le forze di attrito (dinamico, viscoso) NON sono mai conservative⃗F=−μcN̂ut=−μcN⃗vvℒ1(A,B)=∫BA1⃗F⋅d⃗l=∫BA1(−μcN̂ut)⋅(̂utdl)2=−μcN∫BA1dl=−μcNLA1B<0ℒ2(A,B)=∫BA2⃗F⋅d⃗l=∫BA2(−μcN̂ut)⋅(̂utdl)=−μcN∫BA2dl=−μcNLA2B<0LA1B≠LA2B⟹ℒ1(A,B)≠ℒ2(A,B)",lavoro forza attrito dinamico lavoro lungo traiettoria lavoro lungo traiettoria lavoro forza attrito dinamico tutte forze attrito dinamico viscoso mai nutc nvvabb afdlb ac nb adlc babb afdlb ac nb adlc bl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#59,59,"Lavoro di forze conservative e non
60
Teo. Forze vive ℒtot=T(B)−T(A)Lavoro totale ℒtot=ℒcons+ℒncCampi conservativi ℒcons=V(A)−V(B)Il lavoro delle forze non conservative è dato dalla variazione dell’energia meccanica totaleIn presenza di forze d’attrito, generalmente, si ha ℒnc<0⟹E(B)<E(A)Forze dissipativePunto materiale soggetto ad una forza totale: somma di 2 contributi ℒA,B=∫BA⃗F⋅d⃗l=∫BA(⃗Fcons+⃗Fnc)⋅d⃗l=∫BA⃗Fcons⋅d⃗l+∫BA⃗Fnc⋅d⃗lT(B)−T(A)=V(A)−V(B)+ℒncℒnc=[T(B)+V(B)]−[T(A)+V(A)]=E(B)−E(A)",lavoro forze conservative teo forze vive totale totconsnc campi conservativi lavoro forze conservative dato variazione dellenergia meccanica totale presenza forze dattrito generalmente dissipative punto materiale soggetto forza totale somma contributi abb afdlb afconsdlb afncdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#6,6,"Graficamente
7
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsBIl lavoro infinitesimo in un tratto di s è pari all’area tratteggiatadlδℒ=Ftdlℓ",graficamente piano rappresentiamo funzione dellascissa curvilinea funzioni particolare traiettoria variano cambiando percorso fissata certa traiettoriafts ftss bftss bil lavoro infinitesimo tratto pari allarea
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#60,60,"Esercizio•Un carrello viene lanciato con una velocità iniziale v lungo un binario orizzontale che poi presenta un avvolgimento circolare verticale di raggio R = 4 m. Calcolare, nell’ipotesi di assenza di attriti,  il minimo valore vmin che deve essere dato alla velocità v affinché il carrello compia il “giro della morte” senza staccarsi dai binari.
61
",esercizioun carrello viene lanciato velocit iniziale lungo binario orizzontale poi presenta avvolgimento circolare verticale raggio calcolare nellipotesi assenza attriti minimo valore vmin deve essere dato velocit affinch carrello compia giro morte senza staccarsi binari
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#61,61,"EsercizioUn punto materiale di massa m=30 g è inizialmente fermo su di un profilo circolare liscio di raggio R=20 cm ad una altezza H=R/2 rispetto al piano orizzontale. Scendendo lungo il profilo il punto incontra in A un piano orizzontale liscio su cui è vincolata in B una molla di costante elastica  k =0,1 kg/s2, inizialmente a riposo. Determinare: a)le componenti tangenziale (aT) e centripeta (aN)  dell’accelerazione del punto nel punto iniziale; b)la reazione vincolare nel punto A; c)la compressione massima della molla. 
62
mRKA
R
B",esercizio punto materiale massa inizialmente fermo profilo circolare liscio raggio altezza rispetto piano orizzontale scendendo lungo profilo punto incontra piano orizzontale liscio vincolata molla costante elastica kgs inizialmente riposo determinare ale componenti tangenziale centripeta punto punto iniziale bla reazione vincolare punto cla compressione massima molla
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#62,62,"EsercizioUna cassa, di massa M=7 kg è  inizialmente in moto su un piano orizzontale liscio con una velocità di v =8 m/s ad una distanza D =6 m da un piano ruvido inclinato di  α=15° rispetto alla direzione orizzontale. Sapendo che la cassa si ferma dopo aver percorso L = 8 m sul piano inclinato, determinare  a)il coefficiente di attrito dinamico del piano inclinato,  b)il lavoro fatto dalla forza di attrito sul piano inclinato,  c)indicare (motivando la risposta) se, raggiunta la quota massima la cassa ridiscende il piano o si ferma.
63
",esercizio cassa massa inizialmente moto piano orizzontale liscio velocit distanza piano ruvido inclinato rispetto direzione orizzontale sapendo cassa ferma dopo aver percorso piano inclinato determinare ail coefficiente attrito dinamico piano inclinato bil lavoro fatto forza attrito piano inclinato cindicare motivando risposta raggiunta quota massima cassa ridiscende piano ferma
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#63,63,"EsercizioUn corpo di massa M = 12 kg scende da un piano inclinato di α=30° rispetto ad una direzione orizzontale. Sapendo che il corpo parte da fermo, che si abbassa di una quota h = 2 m, che il piano è ruvido e con un coefficiente di attrito dinamico µd=0,2, determinare la sua velocità finale.
64",esercizio corpo massa scende piano inclinato rispetto direzione orizzontale sapendo corpo parte fermo abbassa quota piano ruvido coefficiente attrito dinamico determinare velocit finale
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#7,7,"Graficamente
8
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsB
Il lavoro totale è pari all’area sotto la curva compresa fra i due estremi fra cui si sposta il punto materialeℒ=∫BAFtdlℓ",graficamente piano rappresentiamo funzione dellascissa curvilinea funzioni particolare traiettoria variano cambiando percorso fissata certa traiettoriafts ftss bftss lavoro totale pari allarea sotto curva compresa fra due estremi fra sposta punto materialeb aftdl
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#8,8,"Esempi
91.
AB
costante in modulo, direzione e verso ℓℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFtdl=Ft∫BAℓdl=Ftℓ2. costante in moduloFt=|⃗F|cosθ=Fcosθℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFcosθdl=Fcosθ∫BAℓdl=FℓcosθIn generale in coordinate cartesiane: forza posizionale⃗F(x,y,z)=Fx(x,y,z)̂ı+Fy(x,y,z)̂𝚥+Fz(x,y,z)̂kd⃗l=dx̂ı+dŷ𝚥+dẑkIntegrale generalmente non scomponibile!
AB
𝜗𝜗𝜗𝜗ℓℒ=∫BAℓ⃗F(x,y,z)⋅d⃗l=∫BAℓ[Fx(x,y,z)dx+Fy(x,y,z)dy+Fz(x,y,z)dz]",esempi costante modulo direzione verso abb afdlb ftdlftb adlft costante modulo afdlb fcosdlfcosb adlfcos generale coordinate cartesiane forza integrale generalmente scomponibile b
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#9,9,"Esercizio
10Calcolare il lavoro della forzacon k e h costanti che agisce sul piano (x,y) sulle traiettorie: 1)Lungo un segmento rettilineo che congiunge l’origine con un punto A=(a,b); 2)Lungo l’arco di parabola OA avente vertice nell’origine e per asse l’asse x.xyOA",esercizio calcolare lavoro forzacon costanti agisce piano traiettorie lungo segmento rettilineo congiunge lorigine punto aab lungo larco parabola avente vertice nellorigine asse lasse xxy
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#0,0,Terzo Principio della Dinamica CdS Ingegneria Informatica A.A. 2019/20 ,terzo principio dinamica ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#1,1,"Sviluppo1)Modello del punto materiale troppo povero per descrivere tutta la realtà; 2)Dinamica dei sistemi di punti materiali; 3)Riscrittura  della  in modo opportuno; 4)Terzo principio della dinamica⃗F=m⃗a
2",punto materiale troppo povero descrivere tutta realt dinamica sistemi punti materiali riscrittura modo opportuno terzo principio dinamicafma
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#10,10,"Derivate rispetto al tempo
Rappresenta TUTTE le forze REALI che agiscono sul punto i-esimoPossiamo distinguere tra le forze dovute agli altri punti del sistema  (forze INTERNE al sistema) e forze dovute a tutto ciò che non è il sistema (forze ESTERNE al sistema, dovute all’ambiente). Analogamente per i momenti→𝑄=𝑁∑𝑖=1→𝑞𝑖=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1𝑑→𝑞𝑖𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖→𝑃𝑜=𝑁∑𝑖=1→𝑝𝑖=𝑁∑𝑖=1𝑚𝑖→𝑟𝑖∧→𝑣𝑖𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1𝑑→𝑝𝑖𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑟𝑖∧→𝐹𝑖
11",derivate rispetto tempo rappresenta forze agiscono punto esimo possiamo distinguere forze dovute altri punti sistema forze sistema forze dovute ci sistema forze sistema dovute allambiente analogamente
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#11,11,"Forze interne ed esterneTipiche forze interne: vincoli tra punti materiali, fili, sbarre interne al sistema, molle o sistemi di attrazione/repulsione tra punti del sistema Tipiche forze esterne: forze peso, vincoli tra il sistema e l’esterno, tensioni tra il sistema e l’esterno
Piano verticaleInterneEsterne
Piano orizzontale
Piano verticale
12",forze interne esterne tipiche forze interne vincoli punti materiali fili sbarre interne sistema molle sistemi punti sistema tipiche forze esterne forze peso vincoli sistema lesterno tensioni sistema lesterno piano verticale interne esterne piano orizzontale piano verticale
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#12,12,"Separazione tra forze interne ed esterne
Per un sistema isolato si ha:Attenzione:  risultato parziale→𝐹𝐸𝑆𝑇=0, →𝑀𝐸𝑆𝑇=0𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1(→𝐹𝐼𝑁𝑇𝑖+→𝐹𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1(→𝑀𝐼𝑁𝑇𝑖+→𝑀𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇
13",separazione forze interne esterne sistema isolato haattenzione risultato
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#13,13,"Verifiche sperimentaliQuanto valgono nei sistemi isolati?Studio il sistema Terra-Luna o Giove-suoi satelliti o altri sistemi:
Risultato sperimentale nuovo: nei sistemi isolati si osserva sempre: Nei sistemi isolati la quantità di moto e il momento angolare del sistema sono costanti nel tempo.𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇
𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=014",verifiche sperimentali valgono sistemi isolatistudio sistema terra luna giove satelliti altri sistemi risultato sperimentale nuovo sistemi isolati osserva sempre sistemi isolati quantit moto momento angolare sistema costanti 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#14,14,"Sistema isolato semplice
Le due forze interne agiscono su una retta d’azione che passa per i due punti materiali
 e : forze interne al sistema di due punti⃗F1⃗F2
O
→𝐹𝐼𝑁𝑇=→0→→𝐹1+→𝐹2=→0⟹→𝑀𝐼𝑁𝑇=→𝑟1∧→𝐹1+→𝑟2∧→𝐹2=→0→→𝑟1∧→𝐹1+→𝑟2∧(−→𝐹1)=→0→→𝑟1∧→𝐹1−→𝑟2∧→𝐹1=(→𝑟1−→𝑟2)∧→𝐹1=→0(→𝑟1−→𝑟2)∥→𝐹115→𝐹2=−→𝐹1⃗F1⃗F2",sistema isolato semplice due forze interne agiscono retta dazione passa due punti materiali forze interne sistema due puntiff
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#15,15,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storica
16",terzo principio dinamica ogni volta corpo esercita forza altro corpo secondo esercita primo forza vettorialmente opposta stessa retta storica
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#16,16,Terzo principio della dinamica•Col secondo principio prevediamo il moto di un punto materiale sulla base della forza agente su di esso:  •Per avere una forza  occorre almeno un altro corpo che agisca sul punto materiale •Il secondo principio dice come si muove il punto materiale soggetto ad una forza ma non cosa succede al corpo che tale forza la provoca  serve il terzo principio→𝐹=𝑚→𝑎⃗F→17,terzo principio dinamicacol secondo principio prevediamo moto punto materiale base forza agente esso per avere forza occorre almeno altro corpo agisca punto materiale il secondo principio dice muove punto materiale soggetto forza cosa succede corpo tale forza provoca serve terzo
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#17,17,"Terzo principio della dinamica  per sistemi di punti materiali•Per ogni punto si suppone di poter distinguere fra le forze agenti sul punto i-esimo quella dovuta al punto j-esimo •Si soppone valere sempre la sovrapposizione degli effetti cioè se  è la forza che 2 esercita su 1 e  è la forza che 3 esercita su 1 allora  •Se valgono queste condizioni allora il terzo principio è estendibile a N corpi applicandolo ad ogni possibile coppia di punti→𝐹1,2→𝐹1,3→𝐹1=→𝐹1,2+→𝐹1,3→𝐹𝑖=𝑁−1∑𝑗=1→𝐹𝐼𝑁𝑇𝑖,𝑗+→𝐹𝐸𝑆𝑇𝑖Sul punto i-esimo agiscono tutte le forze interne dovute agli altri N-1 punti e le forze esterneSe agiscono solo forze interne: il sistema è isolato  →𝐹𝐸𝑆𝑇𝑖=→0⟹𝑑→𝑄𝑑𝑡=018",terzo principio dinamica sistemi punti materialiper ogni punto suppone poter distinguere fra forze agenti punto esimo dovuta punto esimo si soppone valere sempre sovrapposizione effetti cio forza esercita forza esercita allora se valgono condizioni allora terzo principio estendibile corpi applicandolo ogni possibile coppia punto esimo agiscono tutte forze interne dovute altri punti forze esterne agiscono solo forze interne sistema isolato
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#18,18,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storicaFormulazione alternativaSe in un SRI, osserviamo che su un corpo (A) si esercita una forza allora esisterà almeno un altro corpo (B) responsabile di tale forza. Su questo corpo B agirà una forza vettorialmente opposta a quella su A e con la stessa retta d’azione.NB: le due forze sono applicate in due punti di applicazione diversi ovvero I due corpi!19",terzo principio dinamica ogni volta corpo esercita forza altro corpo secondo esercita primo forza vettorialmente opposta stessa retta storica formulazione alternativa osserviamo corpo esercita forza allora esister almeno altro corpo responsabile tale forza corpo agir forza vettorialmente opposta stessa retta dazionen due forze applicate due punti applicazione diversi ovvero due corpi
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#19,19,"Terzo principio, formulazione modernaSemplice, diretto, modernoSu sistemi isolati
Nulli per il terzo principio (sperimentale)Nulli in un sistema isolatoQuantità di moto e momento angolare si conservano per sistemi isolati.In un Sistema di Riferimento Inerziale,  e calcolato rispetto ad un polo O qualunque si conservano per sistemi isolati.→𝑄→𝑃0 𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=0
20",terzo principio formulazione moderna semplice diretto moderno sistemi isolati nulli terzo principio sistema isolato quantit moto momento angolare conservano sistemi isolatiin sistema riferimento inerziale calcolato rispetto polo qualunque conservano sistemi isolati 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#2,2,"Quantità di moto di un punto materialeSi definisce la quantità di moto di un punto come:Se la massa è costante:Secondo principio:Se la massa è variabile: quale delle due è corretta?oppure[→𝑞]=[𝑚→𝑣]=[𝑀𝐿𝑇−1]→𝑘𝑔∙𝑚𝑠→𝐹=𝑚→𝑎=𝑚𝑑→𝑣𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡
→𝐹=𝑑→𝑞𝑑𝑡→𝐹=𝑑→𝑞𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡=𝑑𝑚𝑑𝑡→𝑣+𝑚𝑑→𝑣𝑑𝑡3",quantit moto punto materiale definisce quantit moto punto comese massa principiose massa variabile due
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#20,20,"Conseguenze del terzo principio2 corpi su un piano orizzontale tenuti insieme da una molla compressa tramite un filo ideale
21
Terzo principio: poiché il sistema è isolatoIn diverse circostanze è possibile ottenere dei risultati di dinamica SENZA conoscere le forze in gioco
→𝑄𝑖𝑛𝑖𝑧=→0Tagliando il filo i corpi si muovono per effetto della di moto rettilineo uniforme in direzione opposta→𝐹=𝑚→𝑎 →𝑄𝑓𝑖𝑛=𝑚1→𝑣1+𝑚2→𝑣2→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛→→0=𝑚1→𝑣1+𝑚2→𝑣2→→𝑣2=−𝑚1𝑚2→𝑣1",conseguenze terzo principio corpi piano orizzontale tenuti insieme molla compressa tramite filo ideale terzo principio poich sistema isolato diverse circostanze possibile ottenere risultati dinamica conoscere forze gioco tagliando filo corpi muovono effetto moto rettilineo uniforme direzione opposta
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#21,21,Urti CdS Ingegneria Informatica A.A. 2019/20 ,urti ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#22,22,"UrtiSi ha un urto quando due corpi, che si muovono a velocità diverse, interagiscono (p.es. vengono a contatto) e, in un intervallo di tempo molto breve (rispetto al contesto), modificano sostanzialmente le proprie velocità.
23
",urti urto quando due corpi muovono velocit diverse interagiscono pes vengono contatto intervallo tempo molto breve rispetto contesto modificano sostanzialmente proprie velocit
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#23,23,"Forze d’urto – forze impulsive
24
Forze impulsive",forze durto forze impulsive forze impulsive
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#24,24,"Urti collineari di punti materiali
25
e = 0 : urto perfettamente anelastico e = 1 : urto perfettamente elasticoEmpiricamente Prima dell’urtoDopo l’urto
NB.: Trattasi di relazioni tra le componenti dei vettori lungo l’asse x, le quali includono il segno.v0,1x−v0,2x>0→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛𝑣1,𝑥−𝑣2,𝑥=−𝑒(𝑣01,𝑥−𝑣02,𝑥)0≤𝑒≤1",urti collineari punti materiali urto perfettamente anelastico urto perfettamente elastico empiricamente prima dellurto dopo lurto trattasi relazioni componenti vettori lungo lasse quali includono
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#25,25,"Urti collineari di punti materiali
26
Conservazione della quantità di moto (e del momento angolare).
Relazione fra le velocità
m1 = m2
e = 0
Urto anelastico
m1 = m2
e = 1
Urto elastico",urti collineari punti materiali conservazione quantit moto momento angolare relazione fra velocit urto anelastico urto elastico
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#26,26,"Energia cineticaFacendo un po’ di conti … :
e = 1
E = costante T=12m1v1x2+12m2v2x2T0=12m1v01x2+12m2v02x2
In un urto perfettamente elastico l’energia cinetica si conserva
e = 0
ΔE ≤  0 In un urto perfettamente anelastico l’energia cinetica diminuisce27",energia cinetica po conti costante urto perfettamente elastico lenergia cinetica conserva urto perfettamente anelastico lenergia cinetica diminuisce
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#27,27,"Urti in sistemi non isolatiSe gli urti avvengono in sistemi non isolati a causa della presenza di forze esterne o vincoli esterni, il terzo principio (formulazione conservativa) non è sempre applicabileSe l’urto è quasi istantaneo, sono molto più importanti le forze impulsive e si può trascurare l’effetto della forza peso. Si ha una quasi conservazione di quantità di moto e momento angolare tra prima e dopo l’urto. Vale in generale per forze esterne LIMITATE.Se le forze esterne hanno una direzione definita, si ha la conservazione della quantità di moto nelle direzioni perpendicolari.
Esempio: urto di due palloni che si scontrano in aria. E’ presente una forza esterna: quella peso.
28",urti sistemi isolati urti avvengono sistemi isolati causa presenza forze esterne vincoli esterni terzo principio formulazione conservativa sempre applicabile lurto quasi istantaneo molto importanti forze impulsive pu trascurare leffetto forza peso quasi conservazione quantit moto momento angolare prima dopo lurto vale generale forze esterne ese forze esterne direzione definita conservazione quantit moto direzioni perpendicolari esempio urto due palloni scontrano aria presente forza esterna peso
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#28,28,"Urti: riassunto
29",urti riassunto
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#29,29,"EsercizioUn corpo di massa m=1 kg è in moto rettilineo uniforme ad una velocità v=10 m/s, su un piano liscio, quando entra in una regione permanendovi per t=0.1 s in cui perde velocità scalare. All’uscita della regione il corpo ha una velocità di v=9 m/s. Determinare:  1)la forza media che ha frenato il corpo,  2)il lavoro della forza frenante e  3)il coefficiente di attrito se si tratta di una forza di attrito cinetico. 
30",esercizio corpo massa moto rettilineo uniforme velocit piano liscio quando entra regione permanendovi perde velocit scalare alluscita regione corpo velocit determinare forza media frenato corpo lavoro forza frenante coefficiente attrito tratta forza attrito cinetico
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#3,3,"Situazioni di massa variabile•Moto di una goccia d’acqua che cade in presenza di vapor d’acqua saturo  à la massa aumenta •Moto di un aereo in condizioni di tempo brutto con formazione di ghiaccio sulle ali à la massa aumenta •Moto di un razzo che si muove bruciando carburante à la massa diminuisce •Relatività: la massa dipende dalla velocità: •Dato sperimentale: la forza varia con la massa!È più generale della 
m(v)=m01−vc()2→𝐹=𝑑→𝑞𝑑𝑡4",situazioni massa variabilemoto goccia dacqua cade presenza vapor dacqua saturo massa aumenta moto aereo condizioni tempo brutto formazione ghiaccio ali massa aumenta moto razzo muove bruciando carburante massa diminuisce relativit massa dipende velocit dato sperimentale forza varia massa generale
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#30,30,"EsercizioDue punti materiali di massa m1=1 kg e m2=3 kg sono uniti da un filo inestensibile che risulta sempre in tensione. Sapendo che i due punti si muovono su un piano ideale senza attrito, che costituiscono un sistema isolato e che il punto 1 ha equazioni del moto date da :    (nelle unità del SI) trovare la tensione del filo e l’accelerazione del punto 2. 
31",esercizio due punti materiali massa uniti filo inestensibile risulta sempre tensione sapendo due punti muovono piano ideale senza attrito costituiscono sistema isolato punto equazioni moto date nelle unit trovare tensione filo laccelerazione punto
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#31,31,"EsercizioDa una pistola con canna lunga L=15 cm esce un proiettile di massa m=5 g con velocità v=180 m/s. Trovare la forza media che ha spinto il proiettile dentro la canna e il tempo che impiega il proiettile a percorrere la canna della pistola dal momento dello sparo.
32",esercizio pistola canna lunga esce proiettile massa velocit trovare forza media spinto proiettile dentro canna tempo impiega proiettile percorrere canna pistola momento sparo
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#32,32,"EsercizioDue corpi A e B di massa 2 kg si scontrano fra loro. Le velocità prima dell’urto sono   Dopo l’urto Tutte le velocità sono date in metri al secondo. Qual è la velocità finale di B? Quanta energia cinetica guadagna o perde nell’urto il corpo B? L’urto è elastico? →𝑣𝐴,𝑖=15^𝑖+30^𝑗→𝑣𝐵,𝑖=−10^𝑖+5^𝑗→𝑣𝐴,𝑓=−5^𝑖+20^𝑗
33",esercizio due corpi massa scontrano fra loro velocit prima dellurto dopo lurto tutte velocit date metri secondo qual velocit finale energia cinetica guadagna perde nellurto corpo lurto elastico
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#33,33,"EsercizioUna palla di stucco con una massa di 5 g ed una velocità v1 = 4 m/s compie una collisione diretta e perfettamente anelastica con una palla da biliardo inizialmente ferma e che ha una massa di 500 g. Determinare la velocità comune delle due palle dopo l’urto e le energie cinetiche prima e dopo l’urto dei diversi corpi.  - trascurare gli effetti di rotolamento -
34",esercizio palla stucco massa velocit compie collisione diretta perfettamente anelastica palla biliardo inizialmente ferma massa determinare velocit comune due palle dopo lurto energie cinetiche prima dopo lurto diversi corpi trascurare effetti rotolamento
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#34,34,"EsercizioUna pallina di gomma, di massa m=20 g, viene lasciata cadere in verticale da una altezza h=100 cm misurata rispetto ad un pavimento orizzontale. La pallina rimbalza esattamente in verticale e raggiunge una altezza di h' = 90 cm.  Qual è il coefficiente di restituzione del pavimento? A che altezza arriverà il successivo rimbalzo?
35",esercizio pallina gomma massa viene lasciata cadere verticale altezza misurata rispetto pavimento orizzontale pallina rimbalza esattamente verticale raggiunge altezza qual coefficiente restituzione pavimento altezza arriver successivo rimbalzo
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#35,35,"EsercizioDue carrelli, di massa rispettivamente M=50 kg e 2M si muovono uniti su un binario orizzontale rettilineo ad una velocità costante v=10 m/s. Tra i due carrelli, tenuti uniti da un gancio, vi è un respingente (molla) compresso di 25 cm e di costante elastica k=80000 N/m. Se ad un certo punto il gancio si rompe, trovare le velocità finali dei due carrelli.
36",esercizio due carrelli massa rispettivamente muovono uniti binario orizzontale rettilineo velocit costante due carrelli tenuti uniti gancio respingente molla compresso costante elastica certo punto gancio rompe trovare velocit finali due carrelli
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#36,36,"EsercizioUn proiettile di massa mP = 4 kg viene sparato in orizzontale da un cannone posto su un carrello e avente una massa complessiva di MC = 3 000 kg. Sapendo che la velocità di uscita del proiettile è di vP = 350 m/s, determinare la velocità iniziale di rinculo del cannone.
37",esercizio proiettile massa viene sparato orizzontale cannone posto carrello avente massa complessiva sapendo velocit uscita proiettile determinare velocit iniziale rinculo cannone
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#37,37,"Esercizio (pendolo balistico)Un proiettile, di massa m e velocità v diretta in orizzontale, colpisce in modo totalmente anelastico un peso di massa M appeso al soffitto tramite un filo inestensibile. A seguito dell’urto il peso inizia una oscillazione. Trovare la relazione tra la velocità del proiettile e la massima altezza del peso rispetto alla sua posizione di riposo.
38",esercizio pendolo balisticoun proiettile massa velocit diretta orizzontale colpisce modo totalmente anelastico peso massa appeso soffitto tramite filo inestensibile seguito dellurto peso inizia oscillazione trovare relazione velocit proiettile massima altezza peso rispetto posizione riposo
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#38,38,"Esercizio Un corpo di 2 kg viene spinto contro una molla di costante elastica pari a 200 N/m fino a comprimerla di 15 cm. Lasciato andare, la molla lo spinge su una superficie orizzontale fino a che non si arresta dopo un percorso di 75 cm. Qual e’ il coefficiente di attrito dinamico tra blocco e superficie?
3939",esercizio corpo viene spinto molla costante elastica pari fino comprimerla lasciato andare molla spinge superficie orizzontale fino arresta dopo percorso qual coefficiente attrito dinamico blocco superficie
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#39,39,"EsercizioDue sferette di masse m1 e m2, vincolate a muoversi su un piano verticale, sono collegate ad uno stesso punto fisso O attraverso due fili flessibili inestensibili, entrambi di lunghezza l e massa trascurabile (vincoli ideali). Inizialmente la sferetta m2 è in posizione di equilibrio stabile, mentre la sferetta m1 con il filo teso è trattenuta ad una quota h rispetto alla posizione di m2. In seguito, m1 viene lasciata libera di muoversi e va a urtare m2. Nell’ipotesi che l’urto sia istantaneo e completamente anelastico, calcolare:   1) il modulo v1 della velocità con cui m1 urta m2;   2) la quota massima h’ raggiunta dal sistema    dopo l’urto e   3) la perdita di energia cinetica.
40
",esercizio due sferette masse vincolate muoversi piano verticale collegate stesso punto fisso attraverso due fili flessibili inestensibili entrambi lunghezza massa trascurabile vincoli ideali inizialmente sferetta posizione equilibrio stabile mentre sferetta filo teso trattenuta quota rispetto posizione seguito viene lasciata libera muoversi urtare nellipotesi lurto istantaneo completamente anelastico calcolare modulo velocit urta quota massima raggiunta sistema dopo lurto perdita energia cinetica
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#4,4,"ImpulsoL’azione di una forza in un intervallo di tempo dt provoca una variazione infinitesima della quantità di moto
Impulso:Viceversa: da una variazione infinitesima della quantità di moto si può risalire alla forza agente.⃗ℐ=∫t2t1⃗Fdt=∫t2t1d⃗q=⃗q(t2)−⃗q(t2)=Δ⃗q[⃗ℐ]=[Δ⃗q]=[MLT−1]5",impulso lazione forza intervallo tempo provoca variazione infinitesima quantit moto variazione infinitesima quantit moto pu risalire forza lt
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#40,40,"EsercizioUn sistema meccanico, che si trova inizialmente fermo ad una altezza h = 1,2 m dal pavimento, è costituito da una pallina di massa m1 = 10 g collocata in equilibrio (instabile) sopra una pallina di massa m2 = 5m1. A un certo istante, il sistema viene lasciato libero di cadere. Assumendo che ogni urto sia perfettamente elastico e trascurando le dimensioni delle palline, determinare:  1)l’altezza a cui rimbalza la pallina più leggera;  2)la velocità con cui arriva a terra la seconda pallina dopo l’urto.
41",esercizio sistema meccanico trova inizialmente fermo altezza pavimento costituito pallina massa collocata equilibrio instabile sopra pallina massa certo istante sistema viene lasciato libero cadere assumendo ogni urto perfettamente elastico trascurando dimensioni palline determinare laltezza rimbalza pallina leggera velocit arriva terra seconda pallina dopo lurto
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#41,41,"EsercizioUna pallina di massa 2m viene lanciata verso l’alto da una quota z=0 ad una velocità v=10 m/s esattamente nello stesso istante in cui un’altra pallina di massa m, posta ad una quota h=5 m viene lasciata cadere sulla verticale della prima pallina.  1) Se l’urto tra le palline e’ elastico, quanto tempo impiega la prima pallina ad arrivare a terra? 2) Se l’urto e’ completamente anelastico, quanto tempo ci mettono le palline ad arrivare a terra?    (considerare g=10 m/s2)
42",esercizio pallina massa viene lanciata verso lalto quota velocit esattamente stesso istante unaltra pallina massa posta quota viene lasciata cadere verticale prima pallina lurto palline elastico tempo impiega prima pallina arrivare terra lurto completamente anelastico tempo mettono palline arrivare terra considerare
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#5,5,"Teorema dell’impulsoForze impulsive: forze che agiscono per un periodo di tempo limitato
Primo principio  con la quantità di motoSe m è costante    costante    Se m costante e     costante    Teorema dell’impulso: l’impulso di una forza applicata ad un punto materiale provoca la variazione della sua quantità di moto.Forma integrale del secondo principio della dinamica:  nota la forza anche la variazione della quantità di moto è nota; nota la variazione della quantità di moto è nota la forza media che ha agito nell’intervallo di tempo dt.⃗ℐ=∫t2t1⃗Fdt=Δ⃗q
⃗ℐ=∫t2t1⃗Fdt=Δ⃗q=m(⃗v2−⃗v1)6",teorema dellimpulso forze impulsive forze agiscono periodo tempo limitato primo principio quantit moto costante costante costante costante teorema dellimpulso limpulso forza applicata punto materiale provoca variazione quantit motoforma integrale secondo principio dinamica nota forza variazione quantit moto nota nota variazione quantit moto nota forza media agito nellintervallo tempo
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#6,6,"⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)Momento angolare
xyz
O
P
Punto materiale di massa m con velocità  ⃗vMomento angolare o  momento della quantità di moto rispetto al polo O: 
Rispetto al polo F: P
F
Osservazione: il vettore quantità di moto è un vettore applicato nel punto P
7⃗pF=(⃗r−⃗rF)∧⃗q",angolare xyz punto materiale massa velocit momento angolare momento quantit moto rispetto polo rispetto polo osservazione vettore quantit moto vettore applicato punto frr fq
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#7,7,"Momento angolare nel piano
Y
O
Velocità: componente radiale più tangenziale
Il momento angolare: - Dipende dalla velocità trasversa, non da quella radiale - È un vettore  al piano definito da  e  - È diverso da zero solo quando c’è una rotazione - È costante in un moto circolare uniforme⊥→𝑟→𝑣velocità angolare
8⃗v=⃗vr+⃗vt=vr̂ur+vt̂ut=·r̂ur+r·φ̂ut̂ur̂utφ⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)⃗p0=⃗r∧⃗q=m(r̂ur)∧(·r̂ur+r·φ̂ut)=mr2·φ(̂ur∧̂ut)=mr2·φ̂k·φ=dφdt=ω",momento angolare piano velocit componente radiale tangenziale momento angolare dipende velocit trasversa radiale vettore piano definito diverso zero solo quando c rotazione costante moto circolare angolare
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#8,8,"d⃗p0dt=⃗r∧⃗F=⃗M0Derivata del momento angolareDerivando:La derivata del momento angolare é uguale al momento della forza agente sul punto materiale rispetto allo stesso polo.Il momento delle forze è nullo se: -La forza agente è nulla (punto isolato da altri corpi) -Vettore posizione e forza sono paralleli  Se il momento delle forze è nullo, il momento angolare è costante in modulo direzione e verso: la traiettoria giace su un piano. 9⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)d⃗p0dt=d(⃗r∧⃗q)dt=d⃗rdt∧⃗q+⃗r∧d⃗qdt=⃗v∧⃗q+⃗r∧⃗F",derivata momento angolare derivandola derivata momento angolare uguale momento forza agente punto materiale rispetto stesso poloil momento forze nullo forza agente nulla punto isolato altri corpi vettore posizione forza paralleli momento forze nullo momento angolare costante modulo direzione verso traiettoria giace piano
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#9,9,"Sistemi di punti materialiUn insieme di N punti materiali di masse mi costituisce un sistema di punti materiali 
xyz
OSRI
12iDef: massa del sistema di punti materiali:
NM=mii=1N∑Def: Quantità di moto del sistema di punti materiali: 
Def: Momento della quantità di moto (o momento angolare): (momento risultante del sistema)10⃗P0=N∑i=1⃗pi=N∑i=1⃗ri∧⃗qi=N∑i=1mi⃗ri∧⃗vi",sistemi punti materiali insieme punti materiali masse costituisce sistema punti materiali xyz def massa sistema punti materiali mmii ndef quantit moto sistema punti materiali def momento quantit moto momento angolare momento risultante
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#0,0,Dinamica dei Sistemi CdS Ingegneria Informatica A.A. 2019/20 ,dinamica sistemi ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#1,1,"Equazioni cardinali 
2Dal principio di indipendenza delle azioni simultanee: le forze ed i momenti interni rimangono nulli anche in presenza di forze e momenti delle forze esterni.6 equazioni scalari! Descrivono esattamente: 1.Il moto di un punto 2.Il moto di 2 punti 3.Il moto di un corpo rigido𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇Equazioni cardinali della dinamica dei sistemiChe cosa descrivono per un sistema generico di N punti materiali?",equazioni cardinali principio indipendenza azioni simultanee forze momenti interni rimangono nulli presenza forze momenti forze esterni equazioni scalari descrivono esattamente moto punto moto punti moto corpo equazioni cardinali dinamica sistemi cosa descrivono sistema generico punti materiali
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#10,10,"Teorema del momento angolare
11A cosa sono dovute le variazioni del momento angolare totale di un sistema di punti?Consideriamo un polo O’ mobile (non necessariamente il CM)
O
O’
Derivando:=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−𝑁∑𝑖=1𝑚𝑖→𝑣𝑂′",teorema momento angolare cosa dovute variazioni momento angolare totale sistema polo mobile non necessariamente
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#11,11,"Teorema del momento angolare
12O
O’
Estensione della seconda equazione cardinale al caso di un polo mobile:  seconda equazione cardinale generalizzataUsando il primo teorema del centro di massa−→𝑣𝑂′",teorema momento angolare estensione seconda equazione cardinale caso polo mobile seconda equazione cardinale generalizzata usando primo teorema centro massa
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#12,12,"Teorema del momento angolare: se il polo O’ è fisso nel SRI o coincide con il CM, l’evoluzione nel tempo del momento angolare è determinata dal momento risultante delle forze esterne.Teorema del momento angolare
13Il secondo termine è nullo quando: 1- O’ è fermo nel SRI 2- il CM è fermo nel SRI 3- il polo O’ coincide con il CM 4- 
Sempre, anche  quando il CM si muove!
In uno di questi casi𝑑→𝑃𝑂′",teorema momento angolare polo fisso coincide levoluzione tempo momento angolare determinata momento risultante forze esterneteorema momento angolare secondo termine nullo quando fermo fermo polo coincide sempre quando muove casi
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#13,13,"Equazioni cardinali
14
Descrivono il moto di un sistema di N punti materiali attraverso il suo CMSistema di equazioni non completo: non si può descrivere il moto di N punti con sole 2 equazioni vettoriali, ma queste forniscono una indicazione globale su come si muove il CM e l’evoluzione del momento angolare calcolato rispetto al CM.Per un sistema di punti materialiEquazioni cardinali:  moto di 1 punto, 2 punti, corpo rigido",equazioni cardinali descrivono moto sistema punti materiali attraverso msistema equazioni completo pu descrivere moto punti sole equazioni vettoriali forniscono indicazione globale muove levoluzione momento angolare calcolato rispetto mper sistema punti materiali equazioni cardinali moto punto punti corpo rigido
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#14,14,"Energie di un sistema di punti
15Osservazione: la forza ed il lavoro sono grandezze additive Anche l’energia (cinetica, potenziale, meccanica) è una grandezza additiva.Definiamo energia cinetica di un sistema:
Definiamo energia potenziale di un sistema soggetto solo a forze conservative interne o esterne:
Analogamente definiremo Energia Meccanica di un sistema:
",energie sistema punti osservazione forza lavoro grandezze additive lenergia cinetica potenziale meccanica grandezza energia cinetica sistema definiamo energia potenziale sistema soggetto solo forze conservative interne esterne analogamente definiremo energia meccanica sistema
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#15,15,"Teorema di König
16
Usiamo coordinate intrinseche: 
Energia cinetica come calcolata nel SR del CM (SR intrinseco)Energia cinetica nel SRI di un punto di massa M  con velocità pari a quella del CM
TCM=
⃗Q′",teorema knig usiamo coordinate intrinseche energia cinetica calcolata cinetica punto massa velocit pari q
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#16,16,T=T′,tt
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#17,17,"Sistema di punti soggetti a forza peso
18O
CM
Ricordando la definizione di CM:
⟹𝑀→𝑟𝐶𝑀=∑𝑁𝑖=1𝑚𝑖→𝑟𝑖",sistema punti soggetti forza peso ricordando definizione
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#18,18,"Sistema di punti soggetti a forza peso
19O
CM
Un sistema di punti soggetto alla forza peso si comporta come un unico punto materiale coincidente con il CM avente massa M
",sistema punti soggetti forza peso sistema punti soggetto forza peso comporta unico punto materiale coincidente avente massa
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#19,19,"Esercizio
20
Un proiettile è lanciato con una velocità di 20 m/s ad un angolo di 30° rispetto l’orizzontale. Nel corso della sua traiettoria esplode suddividendosi in due frammenti, uno dei quali ha massa doppia rispetto quell’altro. I due frammenti colpiscono il suolo nello stesso istante. Il frammento di massa minore colpisce il suolo a 20 m dal punto di lancio. In quale punto colpisce il suolo il secondo frammento?",esercizio proiettile lanciato velocit angolo rispetto lorizzontale corso traiettoria esplode suddividendosi due frammenti quali massa doppia rispetto quellaltro due frammenti colpiscono suolo stesso istante frammento massa minore colpisce suolo punto lancio punto colpisce suolo secondo frammento
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#2,2,Equazioni cardinali -Per N punti materiali servono N equazioni vettoriali del tipo  quindi 3N equazioni scalari; -Le equazioni cardinali sono al massimo 6 equazioni scalari  mancano 3N-6 equazioni scalari che diano informazioni mancanti (es: vincoli che legano fra loro i punti come nel caso dei corpi rigidi)→𝐹=𝑚→𝑎⟹Per N punti materiali le equazioni cardinali forniscono solo informazioni parziali:  non forniscono informazioni sul singolo punto ma danno informazioni collettive.  Che cosa descrivono le equazioni cardinali per un sistema di N punti materiali?  È possibile trovare un elemento del sistema che sia descritto dalle equazioni cardinali? 3,equazioni cardinali punti materiali servono equazioni vettoriali tipo quindi equazioni scalari equazioni cardinali massimo equazioni scalari mancano equazioni scalari diano informazioni mancanti vincoli legano fra punti caso corpi punti materiali equazioni cardinali forniscono solo informazioni parziali forniscono informazioni singolo punto danno informazioni collettive cosa descrivono equazioni cardinali sistema punti materiali possibile trovare elemento sistema descritto equazioni cardinali
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#20,20,"Sistemi continui
21Sistemi non puntiformi: insiemi “densi” di punti àsistemi continui (estesi). Per tali sistemi la grandezza (dimensione lineare) è importante.  Possiamo caratterizzarli attraverso una nuova quantità geometrica:      Volume V     [L3] àm3Anche un sistema continuo è dotato della proprietà Massa del Sistema:          Massa M     [M] àkg
M=∫dm=∫Vρ(⃗r)dτDef: densità volumetrica puntuale (locale) di massa: 
dm,dτρ(⃗r)=dmdτdm=ρ(⃗r)dτDef: densità volumetrica media di massa: 
M,τ",sistemi continui sistemi puntiformi insiemi densi punti sistemi continui estesi tali sistemi grandezza dimensione lineare importante possiamo caratterizzarli attraverso nuova quantit geometrica volume sistema continuo dotato propriet massa sistema massa kg mdmvrd def densit volumetrica puntuale locale massa def densit volumetrica media massa
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#21,21,"Legame tra sistemi di punti e sistemi estesi
22
Sistema di punti
Sistema esteso
Un sistema continuo può essere pensato come un sistema di N punti materiali, con Nà+∞ 
M=∫dm=∫Vρ(⃗r)dτρ(⃗r)=dmdτ
M=∫dm=∫Vρ(⃗r)dτ∫f(⃗r,⃗v)dm=∫Vf(⃗r,⃗v)ρ(⃗r)dτ",legame sistemi punti sistemi estesi sistema punti sistema esteso sistema continuo pu essere pensato sistema punti materiali n
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#22,22,"Esempio: centro di massa
23
Sistema di punti
Sistema continuo
Esempio: cubo omogeneo di lato L
xzy⃗rCM=∫V⃗rρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫V⃗rρ(⃗r)dτMxCM=∫Vxρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vxρ(⃗r)dτMyCM=∫Vyρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vyρ(⃗r)dτMzCM=∫Vzρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vzρ(⃗r)dτM",esempio centro massa sistema punti sistema continuo esempio cubo omogeneo lato xzyr
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#23,23,"SISTEMI PIANI
24Se un sistema continuo volumetrico ha una dimensione sempre costante allora può essere trattato come un sistema continuo pianoEsempi: foglio di carta, lastra metallica, tavola di legno, muro
Def: densità superficiale media di massa: 
Def: densità superficiale puntuale (locale): 
Dimensionalmente:
Se il sistema esteso ha uno spessore costante pari a D:
",sistema continuo volumetrico dimensione sempre costante allora pu essere trattato sistema continuo piano esempi foglio carta lastra metallica tavola legno muro def densit superficiale media massa def densit superficiale puntuale locale sistema esteso spessore costante pari
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#24,24,"¯λ=MLSistemi lineari
25Se un sistema continuo volumetrico ha due dimensioni sempre costanti allora può essere trattato come un sistema continuo lineareEsempi: corda, filo, sbarra, palo, colonna, pilastroDef: densità lineare media: 
Def: densità lineare puntuale (locale): 
[¯λ]=[ML−1]kg/m",m lsistemi lineari sistema continuo volumetrico due dimensioni sempre costanti allora pu essere trattato sistema continuo lineare esempi corda filo sbarra palo colonna pilastro def densit lineare media def densit lineare puntuale locale m lkgm
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#25,25,"Esercizio
26Una sbarra di lunghezza L è collocata lungo l’asse x con un estremo nell’origine (0<x<L). Determinare la coordinata x del CM sapendo che la sbarra ha una densità lineare pari a:
xL0Caso 1:
Caso 2:
Caso 3:
",esercizio sbarra lunghezza collocata lungo lasse estremo nellorigine determinare coordinata sapendo sbarra densit lineare pari caso caso caso
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#26,26,"Esercizio
27Trovare le coordinate del CM di un triangolo rettangolo isoscele di lato L e densità superficiale σ costante.
yxO
dx
Verificare che 
",esercizio trovare coordinate triangolo rettangolo isoscele lato densit superficiale costante verificare
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#27,27,"Corpi rigidi
28
",corpi rigidi
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#28,28,"Moto del corpo rigido
29Sistema di N=1 punto 
3 variabili dinamicheSistema rigido di N=2 punti 
6 variabili dinamiche dei punti - 1 vincolo = 5 variabili dinamiche indipendenti
Sistema rigido di N=3 punti 3x3=9 variabili dei punti - 3 vincoli = 6 variabili indipendenti
Sistema rigido di N>3 punti Ogni punto in più introduce 3 variabili dinamiche del punto e 3 vincoli
Nel caso del corpo rigido il moto è descrivibile da sole 6 equazioni.
6 variabili dinamiche indipendenti",moto corpo rigido sistema punto variabili dinamiche sistema rigido punti variabili dinamiche punti vincolo variabili dinamiche indipendenti sistema rigido punti variabili punti vincoli variabili indipendenti sistema rigido punti ogni punto introduce variabili dinamiche punto vincoli caso corpo rigido moto descrivibile sole equazioni variabili dinamiche indipendenti
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#29,29,"Quali variabili dinamiche?
30La descrizione completa ne richiede 6. Ho la libertà di scegliere quali.
ABCon le 6 variabili così definite posso descrivere la posizione del corpo rigido nello spazio. Sono convenienti dal punto di vista della dinamica?
Suggerimento: 3 coordinate del CM + 3 variabili angolari6 eq. in 6 incogniteEsempio:  •3 coordinate del punto A + 3 coordinate del punto B – 1 vincolo sulla distanza AB = 5 variabili. •1 angolo di rotazione attorno all’asse AB
Equazioni  cardinali per sistema di punti",quali variabili dinamiche descrizione completa richiede libert scegliere quali bcon variabili cos definite posso descrivere posizione corpo rigido spazio convenienti punto vista dinamica suggerimento coordinate variabili angolari incognite esempio coordinate punto coordinate punto vincolo distanza variabili angolo rotazione attorno allasse equazioni cardinali sistema punti
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#3,3,"Centro di Massa
4O
CM
Sia dato un sistema di N punti materiali descritti in un sistema di riferimento inerziale, si definisceCentro di massa:
3mmL
L/43L/4CM
Punto geometrico definito dal vettore posizione   “interno al sistema”, ma non necessariamente appartenente al sistema. E’ una caratteristica del sistema di punti e non del sistema di riferimento usato.→𝒓𝑪𝑴",centro massa dato sistema punti materiali descritti sistema riferimento inerziale definisce centro massa punto geometrico definito vettore posizione interno sistema necessariamente appartenente sistema caratteristica sistema punti sistema riferimento usato
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#30,30,"Moto generico di un corpo rigido
31Due possibili moti indipendenti:
2.Moto rotatorio puro attorno ad un asse passante per il CM che è fisso    Tutti i punti compiono un moto circolare attorno all’asse istantaneo di rotazione
Vale ancora:Due possibili moti indipendenti:1.Moto traslatorio puro.   - Tutti i punti hanno la stessa velocità (del CM)  - Traiettorie dei punti sono tutte parallele  - Moto descritto dalla prima equazione cardinale
CM
 Il moto più generico possibile è un moto roto-traslatorio, dove il CM si muove seguendo la prima equazione cardinale ed il corpo fa un moto rotatorio attorno ad un asse istantaneo di rotazione e solo se l’asse di rotazione passa per il CM il moto è descritto dalla seconda equazione cardinale. ",moto generico corpo rigido due possibili moti indipendenti moto rotatorio puro attorno asse passante fisso punti compiono moto circolare attorno allasse istantaneo rotazione vale ancoradue possibili moti traslatorio puro punti stessa velocit del traiettorie punti tutte parallele moto descritto prima equazione cardinale moto generico possibile moto roto traslatorio muove seguendo prima equazione cardinale corpo moto rotatorio attorno asse istantaneo rotazione solo lasse rotazione passa moto descritto seconda equazione cardinale
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#31,31,"Moto di un corpo rigido
32
Equazioni cardinali per i sistemi sono separate per il moto del CM e per l’evoluzione del momento angolare.Prima equazione cardinale analoga a  per il punto materiale. Ben nota.→𝐹=𝑚→𝑎Seconda equazione cardinale è la vera novità per il moto dei corpi estesi. La studiamo in dettaglio nel caso più semplice: il CM non ha moto traslatorio e utilizzo il sistema di riferimento intrinseco (moto rotatorio puro)",moto corpo rigido equazioni cardinali sistemi separate moto levoluzione momento angolareprima equazione cardinale analoga punto materiale ben nota seconda equazione cardinale vera novit moto corpi estesi studiamo dettaglio caso semplice moto traslatorio utilizzo sistema riferimento intrinseco moto rotatorio puro
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#32,32,"Moto rotatorio puro
33
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare  ⃗ωIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Legge di trasformazione delle velocità tra due sistemi di riferimento in moto relativo⃗vi=⃗v′",moto rotatorio puro scelgo lorigine sistema intrinseco suppongo fermo unica equazione cardinale utile teorema fisso lunico moto possibile rotazione attorno asse fisso passante velocit angolare sistema intrinseco origine solidale corpo rigido punti corpo rigido fermi slegge trasformazione velocit due sistemi riferimento moto relativoviv
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#33,33,"Moto rotatorio puro
34
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Nulli perché i due sistemi di riferimento si muovono reciprocamente di solo moto rotatorio.⃗vi=⃗v′",moto rotatorio puro scelgo lorigine sistema intrinseco suppongo fermo unica equazione cardinale utile teorema fisso lunico moto possibile rotazione attorno asse fisso passante velocit angolare sistema intrinseco origine solidale corpo rigido punti corpo rigido fermi snulli due sistemi riferimento muovono reciprocamente solo moto
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#34,34,"Moto rotatorio puro
35
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’ perché  per la scelta del sistema S’ →𝑟𝑖=→𝑟′",moto rotatorio puro scelgo lorigine sistema intrinseco suppongo fermo unica equazione cardinale utile teorema fisso lunico moto possibile rotazione attorno asse fisso passante velocit angolare sistema intrinseco origine solidale corpo rigido punti corpo rigido fermi scelta sistema 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#35,35,"Moto rotatorio puro
36
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Momento angolare per sistemi di punti materiali.Momento angolare per sistemi estesi.⃗vi=⃗v′",moto rotatorio puro scelgo lorigine sistema intrinseco suppongo fermo unica equazione cardinale utile teorema generale vettore direzione coincide fisso lunico moto possibile rotazione attorno asse fisso passante velocit angolare sistema intrinseco origine solidale corpo rigido punti corpo rigido fermi smomento angolare sistemi punti angolare sistemi estesiviv
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#36,36,"Momento angolare di un sistema rigido
37
Proprietà del doppio prodotto vettoriale:2)  ⃗ri(⃗ω⋅⃗ri)=(xîı+yî𝚥+zîk)⋅(xiωx+yiωy+ziωz)=1) ⃗ωr2i=ωxr2îı+ωyr2î𝚥+ωzr2îk⃗ri=(xîı+yî𝚥+zîk)
=̂ı(ωxx2i+ωyxiyi+ωzxizi)+̂𝚥(ωxxiyi+ωyy2i+ωzyizi)+̂k(ωxxizi+ωyyizi+ωzz2i)⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)⃗PCM=N∑i=1mi⃗ri∧(ω∧⃗ri)=N∑i=1mi⃗ωr2i−N∑i=1mi⃗ri(⃗ω⋅⃗ri)⃗a∧⃗b∧⃗c=⃗b(⃗a⋅⃗c)−⃗c(⃗a⋅⃗b)",momento angolare sistema rigido propriet doppio prodotto vettoriale
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#37,37,"Momento angolare di un sistema rigido
38Sostituisco le espressioni trovate in precedenza=N∑i=1mi(ωxr2îı+ωyr2î𝚥+ωzr2îk)+−N∑i=1mi[̂ı(ωxx2i+ωyxiyi+ωzxizi)++̂𝚥(ωxxiyi+ωyy2i+ωzyizi)++̂k(ωxxizi+ωyyizi+ωzz2i)]⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",momento angolare sistema rigido sostituisco espressioni trovate
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#38,38,"Momento angolare di un sistema rigido
39            =̂ı𝑁∑𝑖=1𝑚𝑖[(𝜔𝑥𝑟2𝑖−𝜔𝑥𝑥2𝑖−𝜔𝑦𝑥𝑖𝑦𝑖−𝜔𝑧𝑥𝑖𝑧𝑖)]++̂𝚥𝑁∑𝑖=1𝑚𝑖[(𝜔𝑦𝑟2𝑖−𝜔𝑥𝑥𝑖𝑦𝑖−𝜔𝑦𝑦2𝑖−𝜔𝑧𝑦𝑖𝑧𝑖)]+̂k𝑁∑𝑖=1𝑚𝑖[(𝜔𝑧𝑟2𝑖−𝜔𝑥𝑥𝑖𝑧𝑖−𝜔𝑦𝑦𝑖𝑧𝑖−𝜔𝑧𝑧2𝑖)]Raccolgo tutti i termini diretti lungo lo stesso versore⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",momento angolare sistema rigido termini diretti lungo stesso versorep
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#39,39,"Momento angolare di un sistema rigido
40
Si è sostituito: 𝑟2𝑖−𝑥2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑥2𝑖=𝑦2𝑖+𝑧2𝑖𝑟2𝑖−𝑦2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑦2𝑖=𝑥2𝑖+𝑧2𝑖𝑟2𝑖−𝑧2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑧2𝑖=𝑥2𝑖+𝑦2𝑖E ordino secondo le componenti di →𝜔⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",momento angolare sistema rigido sostituito ordino secondo componenti p
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#4,4,"Centro di Massa
5Centro di massa:
Equazione vettoriale  corrisponde a 3 equazioni scalari⇒𝑥𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑥𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑥𝑖𝑦𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑦𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑦𝑖𝑧𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑧𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑧𝑖",centro massa centro massa equazione vettoriale corrisponde equazioni
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#40,40,"Momento angolare di un sistema rigido
41
Compaiono dei termini uguali nelle posizioni simmetriche. ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",momento angolare sistema rigido compaiono termini uguali posizioni simmetriche
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#41,41,"Momento angolare di un sistema rigido
42
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎I: tensore d’inerzia Matrice 3x3 simmetrica
",momento angolare sistema rigido generale vettore direzione coincide tensore dinerzia matrice simmetrica
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#42,42,"Momento d’inerzia
43
in generale non sono paralleli.
problema agli autovalori/autovettoriI=I0100010001⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟In casi particolari il tensore d’inerzia è diagonale e proporzionale al tensore unitario
Indipendentemente dalla sua forma, per un corpo rigido generico esistono tre direzioni (detti assi principali d’inerzia) per cui  : →𝑷∥→𝝎→𝑷=𝝀→𝝎Esempi: - Sfera di raggio R e massa M:    
              - Cubo di lato L e massa M:    
⃗P=I⃗ω=λ⃗ω(I−1λ)⃗ω=0→(I−1λ)=0",momento dinerzia generale paralleli problema casi particolari tensore dinerzia diagonale proporzionale tensore unitario forma corpo rigido generico esistono tre direzioni detti assi principali dinerzia esempi sfera raggio massa cubo lato massa
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#43,43,"Momento d’inerzia
44problema agli autovalori/autovettoriè la matrice d’inerzia simmetrica  esistono sempre 3 autovalori e 3 autovettori che diagonalizzano la matrice𝐼 →𝐼=𝐼𝑥𝑥000𝐼𝑦𝑦000𝐼𝑧𝑧,= momenti principali d’inerzia Per tale matrice  sono gli assi principali d’inerzia.Ixx,Iyy,Izẑı,̂𝚥,̂k(I−1λ)⃗ω=0→(I−1λ)=0",momento dinerzia problema matrice dinerzia simmetrica esistono sempre autovalori autovettori diagonalizzano matrice momenti principali dinerzia tale matrice assi principali
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#44,44,"Momento d’inerzia
45Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z (velocità angolare solo lungo l’asse z) si ha:
Per sistemi di punti materialiPer sistemi estesi⃗P=I⃗ω=Ixx000Izz000Izz(00ω)=Izzω̂k⃗P=Izzω̂kIzz=∫V(x2+y2)ρdτ",momento dinerzia lasse asse principale dinerzia allora quando lasse rotazione coincide lasse velocit angolare solo lungo lasse sistemi punti materiali sistemi izz
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#45,45,"Rotazioni attorno all’asse z:⃗P=Iω̂k
46z
xy
Prendo un sistema di N punti materiali simmetrico rispetto all’asse z in moto rotatorio con velocità  attorno ad un asse coincidente con l’asse di simmetria. →𝜔Sistemi simmetrici rispetto ad un asse hanno nell’asse di simmetria un asse principale
Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z si ha con →𝑃=𝐼𝑧𝑧→𝜔=𝐼𝑧𝑧𝜔^𝑘 𝐼𝑧𝑧=∑𝑁𝑖=1𝑚𝑖(𝑥2𝑖+𝑦2𝑖)",rotazioni attorno allasse zpik prendo sistema punti materiali simmetrico rispetto allasse moto rotatorio velocit attorno asse coincidente lasse simmetria sistemi simmetrici rispetto asse nellasse simmetria asse principale lasse asse principale dinerzia allora quando lasse rotazione coincide lasse 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#46,46,"Rotazioni attorno all’asse ⃗P=Iω̂k
47Per un sistema di N punti materiali simmetrico rispetto all’asse z
I    (cvd)→𝑃=𝐼→𝜔=𝐼𝑥𝑥𝐼𝑥𝑦0𝐼𝑥𝑦𝐼𝑦𝑦000𝐼𝑧𝑧00𝜔^𝑘=𝐼𝑧𝑧𝜔^𝑘z
xy
Per un sistema di N puntiPer un sistema esteso
Izz=∫V(x2+y2)ρdτ",rotazioni attorno allasse pik sistema punti materiali simmetrico rispetto allasse sistema punti sistema esteso
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#47,47,"Dinamica rotazionale
48Dinamica rotazionale:
Analoga a :
Stessa struttura, stesse soluzioni. in generale è una variabile dinamica vettoriale descritta da 3 variabili scalari di tipo angolare che possono essere:  •2 variabili per indicare la direzione del vettore •1 variabile per l’intensità della velocità angolare.→𝜔𝑑→𝑃𝐶𝑀𝑑𝑡=→𝑀𝐸𝑆𝑇𝐶𝑀→𝑃=𝐼→𝜔𝑑→𝑣𝐶𝑀𝑑𝑡=→𝐹𝐸𝑆𝑇𝑀⟹𝑑→𝑣𝐶𝑀=→𝐹𝐸𝑆𝑇𝑀𝑑𝑡⇒→𝑣𝐶𝑀=𝑡∫0→𝐹𝐸𝑆𝑇𝑀𝑑𝑡+→𝑣0",dinamica rotazionale dinamica rotazionale analoga stessa struttura soluzioni generale variabile dinamica vettoriale descritta variabili scalari tipo angolare possono essere variabili indicare direzione vettore variabile lintensit velocit
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#48,48,"Dinamica rotazionale
49
Caso più semplice: moti con asse di rotazione fisso (z): →𝜔=𝜔^𝑘
 diretto lungo l’asse z→𝑀𝐸𝑆𝑇𝐶𝑀=𝑀𝐸𝑆𝑇𝐶𝑀^𝑘𝐼𝑧𝑧𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀→𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧⟹𝑑𝜔=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡⇒Il momento d’inerzia rappresenta per la dinamica rotazionale ciò che la massa rappresenta nel moto traslatorio: fornisce l’inerzia del corpo rigido ad essere messo in moto rotatorio.𝜗(𝑡)=𝑡∫0𝜔(𝑡)𝑑𝑡+𝜗0𝜔(𝑡)=𝑡∫0𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡+𝜔0",dinamica rotazionale caso semplice moti asse rotazione fisso diretto lungo lasse momento dinerzia rappresenta dinamica rotazionale ci massa rappresenta moto traslatorio fornisce linerzia corpo rigido essere messo moto
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#49,49,"Esempio
50Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx =2𝑚(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)=⃗v1=d⃗r1dt=−·θRsinθ̂ı+·θRcosθ̂𝚥⃗v2=d⃗r2dt=−d⃗r1dt=−⃗v1⃗PCM=m⃗r1∧⃗v1+m⃗r2∧⃗v2=m⃗r1∧⃗v1+m(−⃗r1)∧⃗(−v1)=2m⃗r1∧⃗v1=2m⃗r1∧⃗v1=2m(Rcosθ̂ı+Rsinθ̂𝚥)∧(−R·θsinθ̂ı+R·θcosθ̂𝚥)==2𝑚˙𝜃𝑅2(𝑐𝑜𝑠2𝜃+𝑠𝑒𝑛2𝜃)^𝑘=2𝑚˙𝜃𝑅2^𝑘",esempio due punti uguale massa legati filo lungo ruotano piano orizzontale soggetti momento forze costante diretto modo perpendicolare piano moto rsin
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#5,5,"Primo teorema del Centro di Massa
6Velocità del Centro di massa:
Centro di massa:
Derivando:
Ricordando:⟹⟹",primo teorema centro massa velocit centro massa centro massa derivando ricordando
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#50,50,"Esempio
51Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx→𝑃𝐶𝑀=𝐼→𝜔⟹2𝑚˙𝜃𝑅2^𝑘=𝐼→𝜔⟹{𝐼=2𝑚𝑅2→𝜔=˙𝜃^𝑘Caso  MEST =0  ⟹
𝑑𝑃𝐶𝑀𝑑𝑡=𝑀𝐸𝑆𝑇→𝑃𝐶𝑀=2𝑚˙𝜃𝑅2^𝑘Seconda equazione cardinaleCaso  MEST=cost  ⟹
  ˙𝜃(𝑡)=˙𝜃0+𝛼𝑡𝜃(𝑡)=𝜃0+˙𝜃0𝑡+12𝛼𝑡2",esempio due punti uguale massa legati filo lungo ruotano piano orizzontale soggetti momento forze costante diretto modo perpendicolare piano moto caso seconda equazione cardinale caso tcost
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#51,51,"Momenti d’inerzia di solidi
52Sbarra omogenea di massa M e lunghezza L: 
I=λx2dx−L2L2∫=λx33⎡⎣⎢⎤⎦⎥−L2L2=λ2L33⋅8=MLL33⋅4=ML212Disco omogeneo di raggio R e massa M: 
σ=MS=MπR2,dS=2πrdrI=σr22πrdr0R∫=2πσr44⎡⎣⎢⎤⎦⎥0R=2πMπR2R44=MR22Piastra rettangolare omogenea di lati a e b:
σ=MS=Mab,dS=dxdy
-a/2a/2b/2-b/2-L/2L/2",momenti dinerzia solidi sbarra omogenea massa lunghezza ixdxl lm llm disco omogeneo raggio massa sm srdr irrdr piastra rettangolare omogenea lati smabd sdxdy aab
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#52,52,"Teorema di Huygens-Steiner
53Calcoliamo il momento d’inerzia rispetto ad un asse passante a distanza D                            dal CM (asse lungo z) per un sistema rigido di N punti materiali.
CMxyy’x’z’z
Per definizioneIntroduco il SR intrinseco
Il momento d’inerzia rispetto ad un asse qualunque è sempre pari al momento d’inerzia calcolato rispetto ad un asse parallelo a quello dato ma passante per il CM aumentato della quantità MD2 con D distanza tra i due assi.
",teorema huygens steiner calcoliamo momento dinerzia rispetto asse passante distanza asse lungo sistema rigido punti materiali mxyyxzz definizione introduco intrinseco momento dinerzia rispetto asse qualunque sempre pari momento dinerzia calcolato rispetto asse parallelo dato passante aumentato quantit distanza due assi
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#53,53,"Teorema di König per corpi rigidi
54Energia cinetica di un sistema di punti materialiVelocità dei punti nel sistema del CM
αd
T=T'+TCM=12mivi'2i∑+12MvCM2
Energia cinetica di rotazioneEnergia cinetica di traslazioneCome si calcola l’energia cinetica totale di un corpo rigido?Ipotesi semplificata: corpo in rotazione istantanea attorno a un asse passante per il CM diretto lungo z.",teorema knig corpi rigidi energia cinetica sistema punti materiali velocit punti sistema ttt energia cinetica rotazione energia cinetica traslazione calcola lenergia cinetica totale corpo rigidoipotesi semplificata corpo rotazione istantanea attorno asse passante diretto lungo
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#54,54,"Statica dei corpi rigidi•Quando un corpo rigido è in condizioni statiche? (ànon si muove)
55
Equazioni cardinali della Dinamica dei sistemiR: Quando ogni punto del corpo è e rimane fermo!                      il corpo non trasla e non ruota!
Controllo forze e momenti esterni e questo garantisce che il corpo resti fermo per il 1°, 2° e 3° principio!",statica corpi rigidiquando corpo rigido condizioni statiche non muove equazioni cardinali dinamica sistemi quando ogni punto corpo rimane fermo corpo trasla ruota controllo forze momenti esterni garantisce corpo resti fermo principio
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#55,55,"Macchina di AtwoodDiscutere il moto dei due oggetti 1 e 2 appesi tra loro su una carrucola tramite un filo ideale nel caso: 1) la carrucola sia ideale; 2) la carrucola sia reale. 
56
",macchina atwood discutere moto due oggetti appesi carrucola tramite filo ideale caso carrucola ideale carrucola reale
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#56,56,"EsercizioUn’asta omogenea di sezione trascurabile, di massa m e lunghezza l giace su un piano orizzontale liscio inizialmente ferma ed incernierata in uno degli estremi. Ad un certo istante un punto materiale di massa 2m che si muove con velocità v0 urta in modo totalmente anelastico e perpendicolarmente l’asta nel suo centro. Calcolare le espressioni:  1)Della velocità angolare del sistema dopo l’urto; 2)Della reazione vincolare che agisce sul sistema dopo l’urto.57",esercizio unasta omogenea sezione trascurabile massa lunghezza giace piano orizzontale liscio inizialmente ferma incernierata estremi certo istante punto materiale massa muove velocit urta modo totalmente anelastico lasta centro calcolare espressioni della velocit angolare sistema dopo lurto della reazione vincolare agisce sistema dopo lurto
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#57,57,"EsercizioUna forza costante di 1960 N applicata tangenzialmente al bordo di un disco di raggio R=100 cm ne fa variare la velocità angolare da 4 s-1 a 2 s-1 in 30 s. Determinare: -il momento d’inerzia della ruota attorno al suo asse;  -il modulo della variazione del momento angolare nei 30 sec considerati;  -l’angolo descritto dalla ruota in questo intervallo di tempo -l’energia cinetica persa.
58",esercizio forza costante applicata tangenzialmente bordo disco raggio variare velocit angolare determinare momento dinerzia ruota attorno asse modulo variazione momento angolare sec considerati langolo descritto ruota intervallo tempo lenergia cinetica persa
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#58,58,"EsercizioUn disco omogeneo di massa M = 0.4 kg e raggio R = 10 cm viene appoggiato in verticale su un piano inclinato di 30° rispetto l’orizzontale. Sapendo che il disco scende rotolando senza strisciare, determinare la velocità di traslazione del disco dopo aver compiuto 2 m sul piano inclinato.
59",esercizio disco omogeneo massa raggio viene appoggiato verticale piano inclinato rispetto lorizzontale sapendo disco scende rotolando senza strisciare determinare velocit traslazione disco dopo aver compiuto piano inclinato
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#59,59,"EsercizioDue volani assimilabili a due dischi aventi massa e raggio rispettivamente di M1 = 187,5 kg, R1 = 80 cm, M2 = 120 kg e R2 = 50 cm ruotano attorno allo stesso asse fisso orizzontale coincidente con il loro asse di simmetria con velocità angolari di  e . Ad un certo istante I due volani vengono messi a contatto. Calcolare la velocità angolare finale trascurando gli effetti transienti.𝜔1=33 𝑟𝑎𝑑/𝑠𝜔2=2𝜔1
60",esercizio due volani assimilabili due dischi aventi massa raggio rispettivamente ruotano attorno stesso asse fisso orizzontale coincidente asse simmetria velocit angolari certo istante due volani vengono messi contatto calcolare velocit angolare finale trascurando effetti 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#6,6,"Secondo teorema del Centro di Massa
7Accelerazione del Centro di massa:
Prima equazione cardinale→𝑎𝐶𝑀=𝑑→𝑣𝐶𝑀𝑑𝑡=𝑑(→𝑄𝑀)𝑑𝑡=1𝑀𝑑→𝑄𝑑𝑡=1𝑀→𝐹𝐸𝑆𝑇
Analogia formale  (e sostanziale) con: 
La 1a equazione cardinale descrive il moto di un punto fittizio che è il CM. Se il sistema non è soggetto a forze esterne, il CM si muove con velocità costante. ",secondo teorema centro massa accelerazione centro massa prima equazione analogia formale sostanziale con equazione cardinale descrive moto punto fittizio sistema soggetto forze esterne muove velocit costante
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#60,60,"EsercizioUna Colonna di marmo di massa M = 600 kg ha la forma di un parallelepipedo a base quadrata di lato L = 30 cm e altezza h = 2.5 m ed è appoggiata in vertical su un piano ruvido inclinato di un angolo  rispetto l’orizzontale. Schematizzando la colonna come una figura piana che appoggia sul piano inclinator nei punti A e B distanti L determinare: 1)Il valore Massimo dell’angolo che permette la stabilità 2)La forza di attrito statica necessaria alla stabilità 3)Il minimo valore del coefficiente di attrito statico necessario per tenere ferma la colonna se 𝛼𝛼=5°
61
AB",esercizio colonna marmo massa forma parallelepipedo base quadrata lato altezza appoggiata vertical piano ruvido inclinato angolo rispetto lorizzontale schematizzando colonna figura piana appoggia piano inclinator punti distanti determinare valore massimo dellangolo permette stabilit forza attrito statica necessaria stabilit minimo valore coefficiente attrito statico necessario tenere ferma colonna 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#61,61,"EsercizioDue punti materiali di massa M ruotano nel piano (x,y) attorno all’origine seguendo le equazioni del moto: Determinare le forze esterne ed i momenti delle forze esterne che agiscono sul sistema al tempo t=0.  
62θ(t)=α2t2+ϖ0t",esercizio due punti materiali massa ruotano piano attorno allorigine seguendo equazioni moto determinare forze esterne momenti forze esterne agiscono sistema tempo ttt
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#62,62,"EsercizioUn disco di massa M = 0.5 kg, raggio R = 0.2 m e spessore trascurabile ha densità superficiale . Supponendo che il disco sia disposto orizzontalmente e ruoti attorno ad un asse verticale passante per il suo centro con velocità angolare  = 4 rad/s, calcolare l’energia cinetica del sistema.σ=kr⃗ω
63",esercizio disco massa raggio spessore trascurabile densit superficiale supponendo disco disposto orizzontalmente ruoti attorno asse verticale passante centro velocit angolare rads calcolare lenergia cinetica sistemakr
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#63,63,"Esercizio
64Una sbarra omogenea di massa M e lunghezza L è appesa al soffitto tramite un filo collegato al suo centro di massa. La sbarra si muove in un piano orizzontale (x,y) e il filo esercita un debole momento delle forze dato da                          .       Calcolare il periodo del movimento.
xy
θ
",esercizio sbarra omogenea massa lunghezza appesa soffitto tramite filo collegato centro massa sbarra muove piano orizzontale filo esercita debole momento forze dato calcolare periodo movimento
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#7,7,"Sistema di riferimento del CM
8
Posizione del CM rispetto al CMVelocità del CM rispetto al CM
Calcoliamo la posizione del CM nel sistema intrinsecoIl CM definisce un punto importante per capire la dinamica del sistema. La prima equazione cardinale riguarda il moto di questo punto.  Che cosa descrive la seconda equazione cardinale?E’ conveniente introdurre un nuovo sistema di riferimento S’ (in generale NON inerziale) che esalti il ruolo del CM: SR Intrinseco con origine coincidente col CM.
O
CM=O’
→𝑟𝑖
→𝑟𝐶𝑀",sistema riferimento posizione rispetto mvelocit rispetto calcoliamo posizione sistema intrinseco definisce punto importante capire dinamica sistema prima equazione cardinale riguarda moto punto cosa descrive seconda equazione cardinalee conveniente introdurre nuovo sistema riferimento generale inerziale esalti ruolo intrinseco origine coincidente mo 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#8,8,"Terzo teorema del centro di massa
9Riscriviamo il momento angolare nel SRI usando il sistema intrinseco:
=𝑁∑𝑖=1𝑚𝑖(→𝑟′",terzo teorema centro massa riscriviamo momento angolare usando sistema intrinseco 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#9,9,"Terzo teorema del centro di massa
10
Spin o momento angolare intrinseco
Terzo teorema del centro di massa: il momento angolare rispetto ad un polo O di un sistema di punti materiali è in ogni istante uguale alla somma del momento angolare del sistema calcolato nel sistema di riferimento del centro di massa e del momento angolare rispetto allo stesso polo O di un punto materiale di massa pari alla massa totale M del sistema collocato nel CM.⃗P0=⃗P′",terzo teorema centro massa spin momento angolare intrinseco terzo teorema centro massa momento angolare rispetto polo sistema punti materiali ogni istante uguale somma momento angolare sistema calcolato sistema riferimento centro massa momento angolare rispetto stesso polo punto materiale massa pari massa totale sistema collocato mpp
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#0,0,Campo Gravitazionale CdS Ingegneria Informatica A.A. 2019/20 ,campo gravitazionale ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#1,1,"Moto dei pianeti
2Meccanica diventa disciplina coerente dopo un’accurata e attendibile descrizione del moto dei pianeti: moto in assenza di attriti studiabile per lungo tempo -> metodo scientifico facilmente applicabile: Comprensione del moto -> previsione del moto -> verifica sperimentale.Principali risultati grazie a : -Tycho Brahe (1546-1601): misura di precisione delle posizioni dei pianeti -Johannes Kepler (1571-1630): formulazione leggi empiriche sui moti dei pianeti a partire dai dati di Brahe
",moto pianeti meccanica diventa disciplina coerente dopo unaccurata attendibile descrizione moto pianeti moto assenza attriti studiabile lungo tempo metodo scientifico facilmente applicabile comprensione moto previsione moto verifica risultati grazie tycho brahe misura precisione posizioni pianeti johannes kepler formulazione leggi empiriche moti pianeti partire dati brahe
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#2,2,"Leggi di Keplero1.I pianeti descrivono orbite piane, ellittiche, di cui il Sole occupa uno dei due fuochi. 2.Il raggio vettore che unisce il centro del Sole con il centro del pianeta descrive aree uguali in tempi uguali. 3.I quadrati dei tempi che i pianeti impiegano a percorrere le loro orbite sono proporzionali al cubo del semiasse maggiore dell’orbita.3
a2T3=costante",leggi kepleroi pianeti descrivono orbite piane ellittiche sole occupa due fuochi raggio vettore unisce centro sole centro pianeta descrive aree uguali tempi uguali quadrati tempi pianeti impiegano percorrere orbite proporzionali cubo semiasse maggiore dellorbita tcostante
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#3,3,"Gravitazione universale
4•Cosa fa girare i pianeti? •Moto può avvenire anche in assenza di forza (principio di inerzia), ma serve una “spinta” centripeta per mantenere il corpo in traiettoria curva. •Newton: pianeti si muovono sottoposti alla forza di gravità che è la stessa che fa cadere i corpi a Terra. •Che forma ha questa forza?",gravitazione universale cosa girare pianeti moto pu avvenire assenza forza principio inerzia serve spinta centripeta mantenere corpo traiettoria curva newton pianeti muovono sottoposti forza gravit stessa cadere corpi terra che forma forza
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#4,4,"5Velocità areolare
A(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v",velocit areolare atlimt tms
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#5,5,"Gravitazione universale
61a legge di Keplero: il moto avviene su un piano.Velocità areolare2a legge di Keplero: la velocità areolare è costante in modulo.
2o principio dinamica ⃗A=12(P−O)∧⃗v=12⃗r∧⃗vd⃗Adt=12ddt(⃗r∧⃗v)=12(d⃗rdt∧⃗v+⃗r∧d⃗vdt)=12(⃗v∧⃗v+⃗r∧⃗a)=12⃗r∧⃗a=⃗0Campo centrale a simmetria sferica",gravitazione universale legge keplero moto avviene pianovelocit areolarea legge keplero velocit areolare costante modulo principio dinamica campo centrale simmetria sferica
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#6,6,"Gravitazione universale
73a legge di Keplero:Moto dei pianeti può essere schematizzato come moto circolare uniforme 
Stessa struttura di quanto ipotizzato dalla 2a leggeDallo studio dei moti celesti:  con M=massa attorno a cui ruota m     GM=4π2kCostante di gravitazione universaleG=6,672⋅10−11N⋅m2kg2a2T3=costanteT=2πω→ω=2πT⃗a(t)=⃗at+⃗an=··ŝut+v2ρ̂un=v2ρ̂unT2=kR3⃗Fcentripeta=m⃗ac=mv2R̂un=mω2R̂un=m4π2T2R̂un⟹⃗Fcentripeta=m4π2T2R̂un=m4π2kR3R̂un=−m4π2kR2̂ur",gravitazione universale legge kepleromoto pianeti pu essere schematizzato moto circolare uniforme stessa struttura ipotizzato legge studio moti celesti mmassa attorno ruota mk costante gravitazione universale g nmkga tcostante t runm runm runmk runmk rur
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#7,7,"Legge di gravitazione universale
8
Un qualsiasi punto materiale P1 di massa m1 esercita su un qualunque altro punto materiale P2 di massa m2 una forza gravitazionale F12 diretta secondo la congiungente di P1 con P2, sempre attrattiva, in modulo direttamente proporzionale al prodotto delle due masse e inversamente proporzionale al quadrato della distanza fra P1 e P2. •Per il terzo principio della dinamica se P1 esercita una forza su P2 allora P2 esercita una forza  su P1 uguale e contraria •Sul sistema agiscono due forze di risultante nulla ma applicate in punti di applicazione diversi -> il moto è uno solo •La forza gravitazionale è conservativa poiché è un campo centrale a simmetria sferica -> esiste un potenziale gravitazionale ⃗F12⃗F21conˆr=P2−P1",legge gravitazione universale qualsiasi punto materiale massa esercita qualunque altro punto materiale massa forza gravitazionale diretta secondo congiungente sempre attrattiva modulo direttamente proporzionale prodotto due masse inversamente proporzionale quadrato distanza fra per terzo principio dinamica esercita forza allora esercita forza uguale contraria sul sistema agiscono due forze risultante nulla applicate punti applicazione diversi moto solo la forza gravitazionale conservativa poich campo centrale simmetria sferica esiste potenziale gravitazionale
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#8,8,"Energia potenziale gravitazionale
9Campo conservativo
Costante arbitrariaScelgo r0→∞⇒V(∞)=−Gm1m2r0=0V(A)=−Gm1m2rAEnergia potenziale gravitazionale",energia potenziale gravitazionale campo conservativo costante arbitraria scelgo vagmmr aenergia potenziale gravitazionale
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#9,9,"Velocità di fuga
10
Velocità di fuga: velocità minima che occorre imprimere ad un corpo per far si che si allontani da un altro corpo senza ricadervi.Corpo in R si allontana in modo che arrivi all’infinito con velocità nullaConservazione dell’energia meccanica
12mvfuga2−GmMR=0⇒vfuga=2GMRG",velocit fuga velocit fuga velocit minima occorre imprimere corpo far allontani altro corpo senza ricadervicorpo allontana modo arrivi allinfinito velocit nulla conservazione dellenergia meccanica mvfugagm mrvfuga
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#0,0,1 Elettrostatica CdS Ingegneria Informatica A.A. 2019/20 ,elettrostatica ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#1,1,"2Fenomeni elettriciFenomeni elettrici (e magnetici) noti dall’antichità
Teoria completa dei fenomeni elettrici (e magnetici) nella seconda metà XIX secolo: Volta, Ampère, Faraday, Maxwell, Ørsted 
",fenomeni elettrici fenomeni elettrici magnetici noti dallantichit teoria completa fenomeni elettrici magnetici seconda met secolo volta ampre faraday maxwell rsted
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#10,10,"11Elettrizzazione per contatto
AC++++++++12Q+AB++++++++12Q+12Q+++++++++Fino a che punto possiamo suddividere (separare) la carica elettrica?
Limite della Natura la più piccola carica elettrica osservata fino ad ora in natura è quella dell’elettrone (-) e del protone (+)Cariche elettriche frazionar ie della carica elementari sono s tate ipotizzate  (quark confinati all’interno di protoni e neutroni) ma MAI osservate fino ad ora",elettrizzazione contatto qfino punto possiamo suddividere separare carica elettrica limite natura piccola carica elettrica osservata fino ora natura dellelettrone protone cariche elettriche frazionar carica elementari tate ipotizzate quark confinati allinterno protoni neutroni osservate fino ora
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#11,11,12La carica elettricaUnità di misura della carica elettrica nel Sistema Internazionale:  C  (Coulomb) Carica dell’elettrone:   qe= −1.6 × 10-19 C   Carica del protone:      qp= +1.6 × 10-19 C Limite sperimentale:                                                               ,carica elettrica unit misura carica elettrica sistema internazionale coulomb carica dellelettrone carica protone limite sperimentale
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#12,12,13La carica elettrica - esempiCarica degli elettroni in una goccia d’acqua (1g)  Ne=(Np)=3×1023     |Qe|=(|Qp|)=5×104 C  Forza tra due cariche da 1C ad 1m di distanza 9×109 N (equivalente a 100 Titanic!!)Carica in processi triboelettrici  |Q|=10-7C (1011 elettroni)1m1C1C×100,carica elettrica esempi carica elettroni goccia dacqua nenp forza due cariche distanza equivalente processi triboelettrici elettronim
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#13,13,"14Proprietà carica elettricaEsistono due tipi di cariche elettriche  •convenzionalmente positive e negative La carica elettrica è quantizzata •in natura le cariche sono multiple della carica elettrica elementare  |qe|= 1.6 × 10-19−19 C In un sistema isolato, la carica elettrica si conserva •il numero totale di cariche (negative e positive) rimane invariato ",propriet carica elettrica esistono due tipi cariche elettriche positive negative carica elettrica quantizzata in natura cariche multiple carica elettrica elementare sistema isolato carica elettrica conserva il numero totale cariche negative positive rimane invariato
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#14,14,15Interazioni tra cariche elettriche~F=m~aIpotesi iniziali (per il momento…) •Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra le cariche che interagiscono •Consideriamo solo cariche ferme (ELETTROSTATICA),interazioni cariche ipotesi iniziali per momento scegliamo sistema riferimento inerziale corpo soggetto forze muove velocit costante supponiamo vuoto spazio interposto cariche interagiscono consideriamo solo cariche ferme
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#15,15,"16Forza elettrostaticaBilancia di torsione (Coulomb, fine XVIII sec)
𝜃Avvicinando la cariche q2 e q1, si arriva ad una situazione di equilibrio in cui la forza elettrica è bilanciata dalla forza di torsione del pendolo Felettrica=Ftorsione∝𝜃  Dalla misura dell’angolo 𝜃 si ricava l'intensità della forza elettrica.q1, q2 cariche  r distanza tra le cariche 𝜃 angolo di torsione|Fel|/|q1||q2|r2Sperimentalmente si osserva: ricordiamoci che la forza è un vettore…",forza elettrostatica bilancia torsione coulomb fine sec avvicinando cariche arriva situazione equilibrio forza elettrica bilanciata forza torsione pendolo misura dellangolo ricava lintensit forza elettricaq cariche distanza cariche angolo osserva ricordiamoci forza vettore
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#16,16,"17Legge di Coulomb
z
y
x
q1q2SdR cartesiano ortogonaleForza esercitata dalla carica q1 sulla carica q2
Costante dielettrica del vuoto:q1 e q2  puntiformi~F12=14⇡""0q1q2r3~r~F12ha stessa direzione di~re verso che dipende dal segno delle cariche⃗F12=14πε0q1q2r2̂ur
(Farad verrà introdotto in seguito)ε0=8.85×10−12C2Nm2=8.85×10−12Fm14πε0=8.99×109Nm2C2⃗r=⃗r2−⃗r1⃗r1⃗r2⃗F12=q1q24πε0⃗r2−⃗r1|⃗r2−⃗r1|3⃗F12=14πε0q1q2r3⃗r",legge coulomb cartesiano ortogonale forza esercitata carica carica costante dielettrica vuotoq stessa direzione dire verso dipende segno farad verr introdotto nm
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#17,17,18Legge di Coulomb~F21=,legge coulombf
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#18,18,"19Esercizio
𝜃 l m,q m,q l Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡""0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2",esercizio esercizi fisica generale lorenzo elettrostatica vuoto due piccole palline sughero identiche massamhanno ugual caricaq esse appese due li dilunghezzal volta vincolati medesimo punto condizioni equilibrio due palline formanoun angolocon verticale determinare vale carica due palline dipiccoli tre cariche positive puntiformi disposte piano cartesiano punti coordinate quarta carica positivaq eposta punto coordinate determinarea forza sottoposta caricaq lenergia necessaria spostare caricaqdalla posizione iniziale allorigine sistema diriferimento
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#19,19,"20Forza elettrica vs forza gravitazionaleForza ElettrostaticaForza GravitazionaleHanno stessa forma (entrambe dipendono dall’inverso del quadrato), ma… A. la forza elettrica è molto più intensa della forza gravitazionale B.la massa è sempre positiva (forza gravitazionale sempre attrattiva)14πε0=8.99×109 Nm2C−2G=6.67×10−11kg−1m3s−2⃗FCoulomb=14πε0q1q2r2̂ur⃗FGravitazionale=−Gm1m2r2̂ur",forza elettrica forza gravitazionale forza elettrostatica forza gravitazionale stessa forma entrambe dipendono dallinverso quadrato ma forza elettrica molto intensa forza gravitazionale bla massa sempre positiva forza gravitazionale sempre
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#2,2,"3Fenomeni elettriciOsservazioni sperimentali (note da VI secolo A.C): oggetti di diversi materiali (es. vetro, plastica, ambra), dopo strofinio su panno di lana, se posti in vicinanza: •oggetti della medesima sostanza, si respingono •oggetti di sostanze diverse possono respingersi o attrarsi 
plastica
vetro
ambra
vetro
plastica
ambra
evidenza sperimentale esistenza di una forza",fenomeni elettrici osservazioni sperimentali note secolo oggetti diversi materiali vetro plastica ambra dopo strofinio panno lana posti vicinanza oggetti medesima sostanza respingono oggetti sostanze diverse possono respingersi attrarsi plastica vetro ambra vetro plastica ambra evidenza sperimentale esistenza forza
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#20,20,21EsempioCalcolare il rapporto tra le intensità della forza elettrica e di quella gravitazionale fra un elettrone ed un protone qe= −1.6 × 10-19 C       me= 1.9 × 10-31 kg  qp= +1.6 × 10-19 C       mp= 1.7 × 10-27 kg  G= 6.77 × 10-11 Nm-2kg-2 ,esempio calcolare rapporto intensit forza elettrica gravitazionale fra elettrone protone
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#21,21,"22Forza elettrostatica e principio di sovrapposizione
q3q2q1Sistema di N=3 cariche puntiformiForza totale sulla carica q1 è la somma vettoriale della forza        che la carica q2  eserciterebbe su q1 se q3 fosse assente e della forza          che la carica q3  eserciterebbe su q1 se q2 fosse assente⃗F1=⃗F21+⃗F31⃗F21⃗F31⃗F31⃗F1⃗F21",forza elettrostatica principio sovrapposizione qqq sistema cariche puntiformi forza totale carica somma vettoriale forza carica eserciterebbe assente forza carica eserciterebbe
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#22,22,"23Forza elettrostatica e principio di sovrapposizione
q
sistema di N cariche puntiformiForza totale sulla carica q è la somma vettoriale delle forze che le cariche qi eserciterebbero singolarmente su q se qj≠i fossero assentiqi⃗F=N∑i=1⃗Fi⃗ri⃗rivettore posizione da qi a qqj=N∑i=114πε0qqir3i⃗ri",forza elettrostatica principio sovrapposizione sistema cariche puntiformi forza totale carica somma vettoriale forze cariche eserciterebbero singolarmente qji posizione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#23,23,"24Il campo elettrostaticoLa forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza •una carica Q altera le proprietà dello spazio, introducendo un campo elettrico    di cui Q è la sorgente •una seconda carica q (carica esploratrice) sentirà una forza dovuta alla presenza della carica Q⃗E⃗F
  !=lim""V#0""q""V=dqdVDistribuzioni Continue di Carica (II) •!Infine se la carica è distribuita in un volume conviene descrivere la distribuzione della carica utilizzando la densità volumetrica di carica (misurata in C/m3): •!Vogliamo ora calcolare la forza esercitata da una distribuzione di carica descritta dalla densità volumetrica & su di una carica puntiforme q posta a una certa distanza. •!Un volumetto elementare dV situato nel punto P) di vettore posizionale    conterrà la carica elettrica: !r!!r!r!!""r  dVVqr!!   dq=!!""r()dV25!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Distribuzioni Continue di Carica (III) •!Il volumetto dV può essere considerato come una carica puntiforme e dunque possiamo applicare a esso la legge di Coulomb: •!Per il principio di sovrapposizione, la forza totale prodotta su q dalla carica contenuta nel volume V sarà la somma dei contribuiti di tutti i volumetti infinitesimi dV: d!F=14!""0#!$r()dVdq""#$%$q!r%!$r3!r%!$r()!F=14!""0q#!$r()!r%!$r3!r%!$r()dVV&'((&'((&'((26!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!r!!r!r!!""r  dVVq!F12=14!""0q1q2r3!r
Campo Elettrico •!La forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza. •!Possiamo pensare che la presenza di una carica elettrica q1 posta nel punto P1 alteri le proprietà dello spazio, introducendo in esso un campo elettrico. •!Poniamo una carica puntiforme Q nell’origine di una terna cartesiana di riferimento e una seconda carica puntiforme q a una certa distanza r. La forza agente su q si può scrivere: !rqQ!F!r()=14!""0Qqr2ˆr=q14!""0Qr2ˆr#$%&'(!E!r()""#$%$=q!E!r()27!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!F12=14!""0q1q2r2ˆr
Campo Elettrico (II) •!Possiamo allora definire campo elettrico di una carica puntiforme Q il campo vettoriale: e scrivere la forza agente su di una carica q situata nel punto di raggio vettore    come:   !F!r()=q!E!r()   !E!r()=14!""0Qr2ˆrr!
28!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!rqQQ⃗Eq⃗E=limq→0⃗Fq⃗F=q⃗Elimite va inteso in senso “fisico”: • q è quantizzata  •possiamo trascurare i fenomeni di induzione dovuti a q",campo elettrostatico forza coulomb pu essere riformulata utilizzando concetto campo forza una carica altera propriet spazio introducendo campo elettrico sorgente una seconda carica carica esploratrice sentir forza dovuta presenza carica qef vdistribuzioni continue carica infine carica distribuita volume conviene descrivere distribuzione carica utilizzando densit volumetrica carica misurata vogliamo ora calcolare forza esercitata distribuzione carica descritta densit volumetrica carica puntiforme posta certa distanza un volumetto elementare situato punto vettore posizionale conterr carica elettrica rrrr vvqr dqrd vdomenico galli fisica generale elettrostatica distribuzioni continue carica il volumetto pu essere considerato carica puntiforme dunque possiamo applicare esso legge coulomb per principio forza totale prodotta carica contenuta volume somma contribuiti volumetti infinitesimi galli fisica generale campo elettrico la forza coulomb pu essere riformulata utilizzando concetto campo forza possiamo pensare presenza carica elettrica posta punto alteri propriet spazio introducendo esso campo elettrico poniamo carica puntiforme nellorigine terna cartesiana riferimento seconda carica puntiforme certa distanza forza agente pu scrivere qfr qqrrq galli fisica generale campo elettrico possiamo allora definire campo elettrico carica puntiforme campo vettoriale scrivere forza agente carica situata punto raggio vettore come frqer qrrr domenico galli fisica generale inteso senso fisico quantizzata possiamo trascurare fenomeni induzione dovuti
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#24,24,"25Campo elettrostatico di una carica puntiforme
z
y
xQq⃗rIn un SdR cartesiano poniamo: •carica sorgente Q nell’origine •carica esploratrice q in posizione  •q≪Q (trascuriamo il campo elettrico generato da q)⃗r⃗F(⃗r)=14πε0qQr2̂ur⃗E(⃗r)=14πε0Qr2̂ur
campo elettrostatico di una carica puntiforme Qla carica q è soggetta alla forza:⃗E=q14πε0Qr2̂ur=q⃗E(⃗r)",campo elettrostatico carica puntiforme qqr cartesiano poniamo carica sorgente nellorigine carica esploratrice posizione qq trascuriamo campo elettrico generato qrur campo elettrostatico carica puntiforme qla carica soggetta forzaeq qrurqer
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#25,25,"26Campo elettrostatico di una carica puntiformeL’azione della carica Q sulla carica q viene separata in due fasi distinte: • La creazione, da parte della carica Q, di un campo elettrico          in ogni punto dello spazio; •L’accoppiamento nel punto     del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico.  Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (V olt/metro)⃗E(⃗r)⃗E(⃗r)⃗r",campo elettrostatico carica puntiforme lazione carica carica viene separata due fasi distinte creazione parte carica campo elettrico ogni punto spazio punto campo elettrico carica forza osservata carica stabilisce effetto locale carica campo elettrico sistema internazionale campo elettrico misura
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#26,26,"27Campo elettrico di una carica puntiforme
Campo centrale: •diretto come versore -uscente da Q positiva -entrante in Q negativa •modulo dipende solo da r ̂rIl campo elettrico è un campo vettoriale: per ogni punto dello spazio è associato un vettore
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!⃗E(⃗r)=14πε0Qr2̂ur",campo elettrico carica puntiforme campo centrale diretto versore uscente positiva entrante negativa modulo dipende solo campo elettrico campo vettoriale ogni punto spazio associato vettore campo elettrico in modo lazione carica carica viene separata due fasi distinte la creazione parte carica campo elettrico ogni punto spazio punto campo elettrico carica forza osservata carica stabilisce effetto locale carica campo elettrico nel sistema internazionale campo elettrico misura voltmetro dimensioni sono err irq qdomenico galli fisica generale elettrostatica campo elettrico il campo elettrico campo vettoriale ogni punto spazio associato vettore vettore campo elettrico domenico galli fisica generale integrale superficie funzione vettoriale sia data funzione vettoriale definita data superficie suddividiamo superficie certo numero superfici infini tesime prendiamo esse punti consideriamo somma nel limite superfici diventano infinitesime somma diventa lintegrale superficie domenico galli fisica generale piin piinv piin pind integrale superficie funzione vettoriale la superficie pu essere definita utilizzando parametri lintegrale superficie calcola quindi come domenico galli fisica generale campo elettrico in modo lazione carica carica viene separata due fasi distinte la creazione parte carica campo elettrico ogni punto spazio punto campo elettrico carica forza osservata carica stabilisce effetto locale carica campo elettrico nel sistema internazionale campo elettrico misura voltmetro dimensioni sono err irq qdomenico galli fisica generale elettrostatica campo elettrico il campo elettrico campo vettoriale ogni punto spazio associato vettore vettore campo elettrico domenico galli fisica generale integrale superficie funzione vettoriale sia data funzione vettoriale definita data superficie suddividiamo superficie certo numero superfici infini tesime prendiamo esse punti consideriamo somma nel limite superfici diventano infinitesime somma diventa lintegrale superficie domenico galli fisica generale piin piinv piin pind integrale superficie funzione vettoriale la superficie pu essere definita utilizzando parametri lintegrale superficie calcola quindi come domenico galli fisica generale er qrur
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#27,27,"28Principio di sovrapposizione del campo elettricosistema di N cariche puntiformiDimostriamo cheq
qi⃗ri⃗E⃗F=q⃗E⃗F=N∑i=1⃗Fi=qN∑i=1[14πε0qir3i⃗ri]
principio di sovrapposizione del campo elettrico ⃗E=N∑i=1⃗Ei⃗Ei=14πε0qir3i⃗ri=N∑i=114πε0qqir3i⃗ri=N∑i=1q[14πε0qir3i⃗ri]==qN∑i=1⃗Ei=q⃗E",principio sovrapposizione campo cariche puntiformi dimostriamo cheq principio sovrapposizione campo elettrico nieiqe
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#28,28,"29Distribuzioni continue di caricaSpesso la carica elettrica non è puntiforme ma può essere distribuita in un volume nello spazio, su di una superficie o lungo una linea⇢=l i m",distribuzioni continue carica spesso carica elettrica puntiforme pu essere distribuita volume spazio superficie lungo lineal
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#29,29,"30Campo elettrostatico da distribuzioni continue
z
y
x
P⃗r−⃗r′",campo elettrostatico distribuzioni continue prr
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#3,3,"4Elettrizzazione per strofinio (triboelettricità)In natura esistono due tipi di elettrizzazione a cui possiamo associare due tipologie di cariche elettriche Convenzionalmente: •elettrizzazione vetrosa     à carica elettrica positiva •elettrizzazione resinosa   à carica elettrica negativa • cariche dello stesso segno: forza repulsiva • cariche di segno opposto: forza attrattiva
",elettrizzazione strofinio natura esistono due tipi elettrizzazione possiamo associare due tipologie cariche elettriche vetrosa carica elettrica positiva resinosa carica elettrica negativa cariche stesso segno forza repulsiva cariche segno opposto forza attrattiva
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#30,30,"31Campo elettrostatico da distribuzioni continue
dl
dS
d𝜏Carica distribuita  in volume 𝜏Carica distribuita  su superficie SCarica distribuita  su linea l
Warning! formule generali da usare con attenzione: il calcolo degli integrali può risultare complesso, non fare confusione tra r (posizione del punto in cui si vuole calcolare il campo) e r’ (variabile di integrazione, relativa alla posizione delle cariche)⃗E(⃗r)=14πε0∫lλ(⃗r′",campo elettrostatico distribuzioni continue carica distribuita volume carica distribuita superficie carica distribuita linea warning formule generali usare attenzione calcolo integrali pu risultare complesso fare confusione posizione punto vuole calcolare campo variabile integrazione relativa posizione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#31,31,32Il campo elettrico è un campo conservativo?,campo elettrico campo conservativo
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#32,32,33PremessaFino ad ora ci siamo posti in condizioni statiche: le cariche sono ferme → ELETTROSTATICA Non abbiamo ancora studiato gli effetti delle cariche in moto   (esistono forze associate ai movimenti delle cariche?) Per il momento continuiamo la trattazione statica: il campo elettrostatico è conservativo?Andiamo a verificare una delle condizioni di conservatività dei campi ,premessa fino ora posti condizioni statiche cariche ferme ancora studiato effetti cariche moto esistono forze associate movimenti cariche momento continuiamo trattazione statica campo elettrostatico verificare condizioni conservativit campi
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#33,33,"34Circuitazione del campo elettrostaticoCalcoliamo la circuitazione del campo lungo la linea chiusa 𝛤 : circonferenza di raggio R centrata in Q 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!Qd⃗l=̂utdl
∮Γ⃗E⋅d⃗l=∮ΓQ4πε0r2̂ur⋅̂utdl`=0
Il campo elettrico (elettrostatico) generato da una carica puntiforme ferma è conservativo𝛤Circuitazione nullâr",circuitazione campo elettrostatico calcoliamo circuitazione campo lungo linea chiusa circonferenza raggio centrata teorema divergenza per comprendere significato teorema divergenza immaginiamo suddividere volume tanti cubetti infinitesimi volume per ogni cubetto visto ogni cubetto che facce vind ssivd domenico galli fisica generale vpv svind teorema divergenza distinguiamo ora facce cubetti facce interne facce esterne le facce interne separano cubetto cubetto adiacente le facce esterne parte frontiera volume totale sommando divergenze cubetti contributi flussi facce interne cancellano loro il flusso uscente cubetto verso cubetto adiacente opposto flusso cubetto cubetto si pertanto domenico galli fisica generale vvvind linee flusso campo elettrico come campi vettoriali campo elettrico pu rappresentare graficamente linee flusso linee campo ovvero linee tangenti ogni punto vettore campo elettrico orientate verso campo elettrico in numero unit superficie trasversale proporzionale modulo campo elettrico domenico galli fisica generale elettrostatica angolo solido come noto langolo piano radianti definito rapporto arco circonferenza centrata vertice raggio langolo solido definisce maniera analoga rapporto parte superficie sferica centrata vertice intercettata cono centrato vertice quadrato raggio sfera langolo solido misura steradianti domenico galli fisica generale edl campo elettrico generato carica puntiforme ferma conservativo circuitazione nullar
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#34,34,"35Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi∮Γ⃗E⋅d⃗l=0⃗∇∧⃗E=⃗0Il campo elettrostatico ha sempre circuitazione nullaIl campo elettrostatico è  irrotazionale  (non esistono linee di campo chiuse su loro stesse)Equazioni fondamentali dell’elettromagnetismo, applicate al caso statico (cariche ferme)",propriet campo elettrostatico campo elettrostatico eredita tutte propriet campi campo elettrostatico sempre circuitazione nulla campo elettrostatico irrotazionale non esistono linee campo chiuse fondamentali applicate caso statico cariche ferme
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#35,35,"36Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi
∃ una funzione scalare V(x,y,z):⃗E=−⃗∇VV(x,y,z) è il potenziale elettrostatico ⃗E⋅d⃗l=−dVè un differenziale esattoV(A)−V(B)=∫BA⃗E⋅d⃗lL’integrale non dipende dal percorsometodo per calcolare  il potenziale, partendo dal campo elettrostaticometodo per calcolare  il campo elettrico, partendo dal potenziale ∃ una funzione scalare V(x,y,z):⃗E=−⃗∇V",propriet campo elettrostatico campo elettrostatico eredita tutte propriet campi conservativi funzione scalare vxyz potenziale elettrostatico edld differenziale esatto vavbb aedl lintegrale dipende percorsometodo calcolare potenziale partendo campo calcolare campo elettrico partendo potenziale funzione scalare
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#36,36,"37Il potenziale elettrostaticoIl potenziale elettrostatico V(x,y,z) è una funzione scalare in ℝ3   Dato un campo elettrostatico, operativamente il potenziale si calcola integrando il differenziale esattodV=−⃗E⋅d⃗lIl potenziale è definito a meno di una costante additiva arbitraria La differenza di potenziale tra due punti è indipendente dalla costante arbitraria (è una grandezza misurabile → circuiti) integrale indefinitointegrale definitoV(A)−V(B)=∫BA⃗E⋅d⃗lV(x,y,z)=−∫⃗E⋅d⃗l+costL’unità di misura del potenziale nel S.I. è il Volt=Joule/Coulomb  (V)=(J)/(C)",potenziale elettrostatico potenziale elettrostatico vxyz funzione scalare dato campo elettrostatico operativamente potenziale calcola integrando differenziale esattod vedl potenziale definito meno costante additiva arbitraria differenza potenziale due punti indipendente costante arbitraria grandezza misurabile circuiti integrale definito vavbb aedl lunit misura potenziale vjc
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#37,37,"38Il potenziale elettrostatico: carica puntiformeV(⃗r)=−∫⃗E⋅d⃗l+cost
Qd⃗l=̂rdr+̂u⊥dl⊥̂u⊥dl⊥d⃗l̂urdr⃗E=Q4πε01r2̂urV(⃗r)=[−∫Q4πε01r2̂ur⋅(̂urdr+̂u⊥dl⊥)]+cost=[−∫Q4πε01r2(̂ur⋅̂urdr+̂ur⋅̂u⊥dl⊥]+costCalcoliamo V dall’integrale indefinito lungo una generica curva 𝛤  =[−Q4πε0∫drr2]+costV(⃗r)=14πε0Qr+cost𝛤in genere si fissa il potenziale nullo all’infinito:=−Q4πε0(−1r)+cost=14πε0Qr+cost⃗r`1`0V(⃗r→∞)=0⇒14πε0Q(r→∞)+cost=0⇒cost=0",potenziale elettrostatico carica puntiforme calcoliamo dallintegrale indefinito lungo generica curva vr qrcostin genere fissa potenziale nullo qrcostr vr
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#38,38,"39Il potenziale elettrostatico: carica puntiforme
QAB⃗Ecalcoliamo la differenza di potenziale tra i punti A e BΔVAB=VA−VB=∫BA⃗E⋅d⃗l=...=Q4πε0[−1r]BA=Q4πε0(1rA−1rB)=14πε0QrA−14πε0QrBrBrAVA=V(⃗rA)=14πε0QrAVB=V(⃗rB)=14πε0QrBAssumendo il potenziale nullo all’infinito (cost=0)",potenziale elettrostatico carica puntiforme abecalcoliamo differenza potenziale punti av bb aqr ar b a avr a bvr b bassumendo potenziale nullo allinfinito cost
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#39,39,40Principio di sovrapposizione del potenzialeDemo: basta usare la proprietà distributiva del prodotto vettorialeUn campo elettrostatico generato da N cariche discrete o da una distribuzione continua di carica è conservativo⃗∇∧⃗E=⃗∇∧(∑⃗Ei)=∑⃗∇∧⃗Ei=⃗0principio di sovrapposizionecampo da carica puntiforme irrotazionaleV(⃗r)=−∫⃗E⋅d⃗l=−∫(∑⃗Ei⋅d⃗l)=∑∫−⃗Ei⋅d⃗l=∑Vi(⃗r)Il potenziale elettrostatico generato da un sistema di cariche gode del principio di sovrapposizione,principio sovrapposizione potenziale demo basta usare propriet distributiva prodotto vettoriale campo elettrostatico generato cariche discrete distribuzione continua carica carica puntiforme irrotazionale potenziale elettrostatico generato sistema cariche gode principio sovrapposizione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#4,4,"5La struttura microscopica della materiaTutti i  materiali formati da atomi (e molecole) Gli atomi sono composti da •nucleo formato da protoni (carichi positivamente) e neutroni (neutri) •attorno al nucleo orbitano gli elettroni (carichi negativamente)
La Forza Elettromagnetica nella Fisica Moderna (II) •!La forza elettromagnetica è la forza dominante nel mondo fisico che conosciamo: –!Tiene uniti gli elettroni al nucleo negli atomi. –!Tiene uniti gli atomi nelle molecole; –!È all’origine delle forze elastiche; –!È all’origine delle forze di tensione delle funi; –!È all’origine delle forze di attrito; –!È all’origine delle forze di resistenza; –!È all’origine delle forze di tensione superficiale dei liquidi; –!È all’origine delle forze di urto; –!È all’origine delle reazioni vincolari. 9!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
La Forza Elettromagnetica nella Fisica Moderna (III) 
10!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Non hanno origine elettromagnetica poche forze comunemente note, tra cui: –!La forza peso (forza gravitazionale); –!La forza che mantiene i pianeti sulle loro orbite (forza gravitazionale); –!La forza che tiene uniti i quark nei nuclei degli atomi (forza nucleare forte). 
La Composizione della Materia molecolaatomonucleoelettrone
protoneneutronequark10 cm!810 cm!12
10 cm!1310 cm!13(<10 cm)!1811!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
I Costituenti della Materia: le Particelle Elementari (Fermioni) 
12!Domenico Galli – Fisica Generale B – 1. Elettrostatica!1 MeV/c2 = 1.783 ! 10–30 kg  Q=23eQ=!13eu d e !e c s µ""!µ""t b #""!#""elettrone up down neutrino elettronico neutrino muonico neutrino tauonico muone tauone charm strange top bottom m = 0 m = 0 m = 0 m = 0.5 MeV/c2 m = 8 MeV/c2 m = 15 MeV/c2 
m = 170000 MeV/c2 m = 4500 MeV/c2 m = 106 MeV/c2 m = 1800 MeV/c2 m = 1600 MeV/c2 m = 300 MeV/c2 leptoni quark Esistite subito dopo il Big Bang. Ora presenti nei raggi cosmici e negli acceleratori Q=!eMateria ordinaria 
1 e = 1.602 ! 10–19 C  
La materia ordinaria risulta complessivamente neutra  (stesso numero di protoni ed elettroni) Perché?",struttura microscopica materia materiali formati atomi molecole atomi composti nucleo formato protoni carichi positivamente neutroni neutri attorno nucleo orbitano elettroni carichi negativamente forza fisica moderna la forza forza dominante mondo fisico conosciamo tiene uniti elettroni nucleo atomi tiene uniti atomi molecole allorigine forze elastiche allorigine forze tensione funi allorigine forze attrito allorigine forze resistenza allorigine forze tensione superficiale liquidi allorigine forze urto allorigine reazioni vincolari domenico galli fisica generale elettrostatica forza fisica moderna domenico galli fisica generale origine poche forze comunemente note cui la forza peso forza la forza mantiene pianeti orbite forza la forza tiene uniti quark nuclei atomi forza nucleare forte composizione materia galli fisica generale elettrostatica costituenti materia particelle elementari fermioni domenico galli fisica generale qeu t elettrone neutrino elettronico neutrino muonico neutrino tauonico muone tauone charm strange top bottom leptoni quark esistite subito dopo big bang ora presenti raggi cosmici acceleratori materia ordinaria materia ordinaria risulta neutra stesso numero protoni elettroni perch
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#40,40,"41Potenziale: sistema di N cariche puntiformisistema di N cariche puntiformi
qi⃗riP(x,y,z)V(x,y,z)=N∑i=1Vi(x,y,z)=N∑i=114πε0qiriIl potenziale in un punto P(x,y,z) è dato dalla somma algebrica dei singoli potenziali generati dalle cariche qi singolarmente ",potenziale sistema cariche cariche puntiformi qiri potenziale punto pxyz dato somma algebrica singoli potenziali generati cariche singolarmente
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#41,41,"42Potenziale: sistemi continui di cariche
z
y
x
P(x,y,z)⃗r−⃗r′",potenziale sistemi continui cariche pxyzrr
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#42,42,"x
Exd2−d2
43EsempiSiano date due cariche uguali q+ posizionate sull’asse y di un SdR cartesiano a distanza d dall’origine. Determinare l’espressione del campo e del potenziale elettrostatico sull’asse x.
x
d
⃗E(x,0,0)=q2πε0x(x2+d2)3/2̂ı
y",exdd esempi date due cariche uguali posizionate sullasse cartesiano distanza dallorigine determinare lespressione campo potenziale elettrostatico sullasse
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#43,43,44EsempioDeterminare il campo ed il potenziale elettrostatico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 ⃗E=λ2πε0r̂ur ortogonale al filo,esempio determinare campo potenziale elettrostatico generato filo rettilineo indefinito depositata uniformemente carica densit lineare erur ortogonale filo
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#44,44,"z
Ez45EsempioDeterminare il campo elettrostatico sull’asse di un anello di raggio R su cui è depositata uniformemente una carica Q⃗E=Q4πε0z(z2+R2)32̂k",esempio determinare campo elettrostatico sullasse anello raggio depositata uniformemente carica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#45,45,46EsempioDeterminare il campo elettrostatico sull’asse di un disco di raggio R su cui è depositata uniformemente una carica Q⃗E=Qz2πε0R2[1|z|−1(z2+R2)12]̂k,esempio determinare campo elettrostatico sullasse disco raggio depositata uniformemente carica qeqz
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#46,46,"47EsempioDeterminare la differenza di potenziale elettrostatico tra due piani indefiniti paralleli, posti a distanza d, su cui è depositata uniformemente una densità superficiale di carica uguale ed opposta
  +𝜎-𝜎d",esempio determinare differenza potenziale elettrostatico due piani indefiniti paralleli posti distanza depositata uniformemente densit superficiale carica uguale opposta
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#47,47,48Esempio1.7Una sottile barra di plastica ha una densit` a lineare di carica positiva,esempio sottile barra plastica densit lineare carica positiva
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#48,48,"49Il lavoro della forza elettrostaticaSe il campo elettrostatico è conservativo ⇒ la forza elettrostatica è conservativaℒel=∫BA⃗Fel⋅d⃗l=∫BAq⃗E⋅d⃗l=q∫BA⃗E⋅d⃗l=q(VA−VB)=qΔVAB⃗Fel=q⃗EIl lavoro fatto dalla forza elettrostatica per spostare una carica q dalla posizione A alla posizione BLa forza elettrostatica (di Coulomb) è proporzionale al campo elettrico
Dato che la forza elettrostatica è conservativa, il lavoro non dipende dal percorso",lavoro forza elettrostatica campo elettrostatico conservativo forza elettrostatica afeldlb aqedlqb aedlqv av bq bfelqe lavoro fatto forza elettrostatica spostare carica posizione posizione forza elettrostatica coulomb proporzionale campo elettrico dato forza elettrostatica conservativa lavoro dipende percorso
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#49,49,50L’energia elettrostaticaPossiamo definire l’energia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale VUE=qVLa variazione di energia potenziale corrisponde alla variazione di energia cinetica Tin+Uin=Tfin+Ufin⇒ΔT=−ΔUEU si misura in Joule (J) In Fisica delle Particelle si usa l’elettronvolt: (energia cinetica di una carica elementare accelerata da un V olt) 1eV = qe𝛥V =(1.6×10-19 C)×(1V)=1.6×10-19 J Forza elettrostatica conservativa ⇒ energia meccanica totale (cinetica+potenziale) si conserva        ℰ=T+UE,lenergia elettrostatica possiamo definire lenergia potenziale elettrostatica carica situata punto spazio presente potenziale ueq vla variazione energia potenziale corrisponde variazione energia cinetica t misura joule fisica particelle usa lelettronvolt energia cinetica carica elementare accelerata olt qe forza elettrostatica conservativa energia meccanica totale conserva tu
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#5,5,6Lo strofinio produce uno spostamento di elettroni da un materiale all’altro.  Sfregando tra di loro i due materiali: •il più alto nella lista si carica ⊕ (cede elettroni) •il più basso nella lista si carica ⊝ (acquista elettroni)Serie triboelettricacuoio vetro capelli lana seta alluminio carta legno ambra gomma argento oro plastica PVC silicone teflonperché sono gli elettroni a spostarsi e non i protoni?,strofinio produce spostamento elettroni materiale allaltro sfregando due materiali il alto lista carica cede elettroni il basso lista carica acquista elettroniserie vetro capelli lana seta alluminio carta legno ambra gomma argento oro plastica silicone teflonperch elettroni spostarsi protoni
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#50,50,"51Moto di una carica in un campo elettrostatico Un oggetto di massa m e carica q posto in un campo elettrostatico è soggetto alla forza elettrostatica⃗F=q⃗E=m⃗a⃗a=d2⃗rdt2=qm⃗ENote le condizioni iniziali possiamo determinare le equazioni del moto Dato che il campo elettrostatico è conservativo, si può utilizzare anche la conservazione dell’energiaΔT=−ΔUe",moto carica campo elettrostatico oggetto massa carica posto campo elettrostatico soggetto forza note condizioni iniziali possiamo determinare equazioni moto dato campo elettrostatico conservativo pu utilizzare conservazione dellenergia t
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#51,51,"52Esempio: moto carica in campo costante
+𝜎Campo piano indefinitoDeterminare la velocità di una particella di massa m e carica q(+), inizialmente ferma (vA=0) su un piano uniformemente carico positivamente, dopo che ha percorso una distanza D
ABa=qmE=qmσ2ε0costante, moto uniformemente acceleratovB=vA+atxB=xA+vAt+12at2v2B−v2A=2a(xB−xA)vB=qmσε0DTB−TA=UA−UBTB=12mv2BTA=0UA−UB=q(VA−VB)=q∫BA⃗E⋅d⃗l==q∫BAσ2ε0dx=qσ2ε0(xB−xA)=qσ2ε0D12mv2B=qσ2ε0Dv2B=2qmσ2ε0DDin alternativa (conservazione energia)⃗E=σ2ε0̂ıx",esempio moto carica campo costante campo piano indefinito determinare velocit particella massa carica inizialmente ferma piano uniformemente carico positivamente dopo percorso distanza baqm moto uniformemente acceleratov aatx atatv bv aax bx bqm bt au bmv uau bqv av bqb aedlqb adxqx bx aq dmv bq bqm ddin alternativa conservazione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#52,52,"53Esempio: deflessione in doppio strato-𝜎+𝜎
xy
m, q+⃗v0=v0x̂ı⃗E=σε0̂𝚥
𝛼Calcolare l’angolo di deflessione di una particella di massa m e carica q che attraversa con velocità iniziale v0x un doppio strato di lunghezza LL",esempio deflessione doppio strato calcolare langolo deflessione particella massa carica attraversa velocit iniziale doppio strato lunghezza
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#53,53,"54EsempioTre particelle identiche, aventi massa m e carica q,  sono poste ai vertici di un triangolo equilatero di lato L. Inizialmente le cariche sono ferme. Ad un certo istante una delle tre cariche viene lasciata libera. Determinare la velocità che la carica acquista dopo aver percorso una distanza L (risolvere per m=2 kg, q=5𝜇C, L=3m)",esempio tre particelle identiche aventi massa carica poste vertici triangolo equilatero lato inizialmente cariche ferme certo istante tre cariche viene lasciata libera determinare velocit carica acquista dopo aver percorso distanza risolvere
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#54,54,"55Integrale di superficie una funzione vettorialeSiano date in ℝ3 una funzione vettoriale e una superficie S ⃗F(x,y,z)
nel limite N→∞ e 𝛥Si→0 , definiamo l’integrale di superficie di una funzione vettoriale
S𝛥SîniPi⃗F(Pi)αîniSuddividiamo S in N superfici infinitesime 𝛥Si e consideriamo su di esse i punti Pi(xi,yi,zi), i corrispondenti versori      normali a 𝛥Si  N∑i=1⃗F(Pi)⋅̂niΔSi=N∑i=1F(Pi)cosαiΔSi∬S⃗F⋅̂ndSconsideriamo  la somma ⃗F(x,y,z)",integrale superficie funzione vettoriale date funzione vettoriale superficie fxyz limite n si definiamo lintegrale superficie funzione vettoriale sini pifpiini suddividiamo superfici infinitesime consideriamo esse punti pixiyizi corrispondenti versori normali sini fpicosi sisfnd sconsideriamo somma fxyz
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#55,55,"56Flusso di un campo vettorialeIl concetto di flusso viene introdotto nello studio della dinamica dei fluidi Consideriamo un tubo (di sezione infinitesima) attraversato da un fluido incompressibile (es H20) con velocità     d⃗S=̂ndS⃗vIl flusso del fluido attraverso una sezione dS del tubo è definito:dΦ=⃗v⋅̂ndSNotazione alternativa:dΦ=⃗v⋅d⃗Srisolvendo il prodotto scalare:
̂n⃗vαdSd𝛴sezione trasversa d𝛴=dS cos𝛼dΦ=vdScosα=vdΣ",flusso campo vettoriale concetto flusso viene introdotto studio dinamica fluidi consideriamo tubo sezione infinitesima attraversato fluido incompressibile velocit dsnd sv flusso fluido attraverso sezione tubo snotazione prodotto scalare nvd sdsezione trasversa dd cosdvd scosvd
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#56,56,"57Flusso di un campo vettorialeConsiderando più tubi (di flusso) su una generica superficie S 
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso del campo vettoriale     attraverso la superficie S⃗vΦs(⃗v)=∬S⃗v⋅̂ndS",flusso campo vettoriale considerando tubi flusso generica superficie flusso campo vettoriale la quantit fluido attraversato tempo sezione tubo pari volume cilindro avente stessa base tubo unaltezza pari cio il flusso fluido pertanto domenico galli fisica generale flusso campo vettoriale possiamo esprimere flusso utilizzando sezione obliqua invece sezione trasversale si domenico galli fisica generale snsrv flusso campo vettoriale consideriamo ora caso velocit fluido uniforme sezione tubo caso esempio flusso laminare fluido viscoso velocit centro tubo maggiore velocit prossimit pareti in tal caso scomponiamo tubo tanti tubicini sezione trasversale infinitesima flusso attraverso qualunque sezione tubicino infinitesimo vale il flusso totale ottiene sommando flusso attraverso insieme tubicini coprono completamente sezione tubo domenico galli fisica generale ssdd scosdsd sdvdd svvdvd scosvind svolume fluido attraversa nellunit tempo superficie flusso campo vettoriale la superficie potrebbe essere piana lespressione ugualmente valida superfici infinitesime possono essere considerate piane prodotto scalare tiene conto inclinazione rispetto velocit domenico galli fisica generale fluido attraversa nellunit tempo superficie flusso campo vettoriale la quantit fluido attraversato tempo sezione tubo pari volume cilindro avente stessa base tubo unaltezza pari cio il flusso fluido pertanto domenico galli fisica generale flusso campo vettoriale possiamo esprimere flusso utilizzando sezione obliqua invece sezione trasversale si domenico galli fisica generale snsrv flusso campo vettoriale consideriamo ora caso velocit fluido uniforme sezione tubo caso esempio flusso laminare fluido viscoso velocit centro tubo maggiore velocit prossimit pareti in tal caso scomponiamo tubo tanti tubicini sezione trasversale infinitesima flusso attraverso qualunque sezione tubicino infinitesimo vale il flusso totale ottiene sommando flusso attraverso insieme tubicini coprono completamente sezione tubo domenico galli fisica generale ssdd scosdsd sdvdd svvdvd scosvind svolume fluido attraversa nellunit tempo superficie flusso campo vettoriale la superficie potrebbe essere piana lespressione ugualmente valida superfici infinitesime possono essere considerate piane prodotto scalare tiene conto inclinazione rispetto velocit domenico galli fisica generale fluido attraversa nellunit tempo superficie flusso campo vettoriale attraverso superficie
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#57,57,"58Linee di flusso di un campo vettoriale
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnConsideriamo la traiettoria 𝛾 di una particella del fluido  ➡  in ogni punto la traiettoria è tangente alla velocità vettoriale della particella La linea di flusso 𝛾 è una linea sempre tangente al vettore velocità delle particelle che si trovano nei punti della linea",linee flusso campo vettoriale linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn consideriamo traiettoria particella fluido ogni punto traiettoria tangente velocit vettoriale particella linea flusso linea sempre tangente vettore velocit particelle trovano punti linea
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#58,58,"59Linee di flusso del campo elettricoAnche per il campo elettrico possiamo rappresentare graficamente le linee di flusso (o linee di campo) • tangenti in ogni punto al vettore campo elettrico • orientate con il verso del campo elettrico • in numero (per unità di superficie trasversale), proporzionali al modulo del campo elettrico 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!",linee flusso campo elettrico campo elettrico possiamo rappresentare graficamente linee flusso linee campo tangenti ogni punto vettore campo elettrico orientate verso campo elettrico numero per unit superficie trasversale proporzionali modulo campo elettrico teorema divergenza per comprendere significato teorema divergenza immaginiamo suddividere volume tanti cubetti infinitesimi volume per ogni cubetto visto ogni cubetto che facce vind ssivd domenico galli fisica generale vpv svind teorema divergenza distinguiamo ora facce cubetti facce interne facce esterne le facce interne separano cubetto cubetto adiacente le facce esterne parte frontiera volume totale sommando divergenze cubetti contributi flussi facce interne cancellano loro il flusso uscente cubetto verso cubetto adiacente opposto flusso cubetto cubetto si pertanto domenico galli fisica generale vvvind linee flusso campo elettrico come campi vettoriali campo elettrico pu rappresentare graficamente linee flusso linee campo ovvero linee tangenti ogni punto vettore campo elettrico orientate verso campo elettrico in numero unit superficie trasversale proporzionale modulo campo elettrico domenico galli fisica generale elettrostatica angolo solido come noto langolo piano radianti definito rapporto arco circonferenza centrata vertice raggio langolo solido definisce maniera analoga rapporto parte superficie sferica centrata vertice intercettata cono centrato vertice quadrato raggio sfera langolo solido misura steradianti domenico galli fisica generale elettrostatica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#59,59,"Classificazione delle superfici • aperta: compatta e con bordo • chiusa: compatta e priva di bordo • orientabile: ha due facce
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnAperta e orientabile
Sfera: chiusa e orientabileToroide: chiusa e orientabileNastro di Möbius: aperta e non orientabileBottiglia  di Klein: chiusa e  non-orientabile60Superfici in ℝ3",classificazione superfici aperta compatta bordo chiusa compatta priva bordo orientabile due facce linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica nnnnnnn aperta orientabile sfera chiusa orientabile toroide chiusa orientabile nastro mbius aperta orientabile bottiglia klein chiusa orientabile superfici
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#6,6,"7Isolanti e conduttoriisolanti  •la carica elettrica resta localizzata  •vetro, plastica, gomma conduttori  •cariche libere di muoversi •metalli warning: classificazione un po’ riduttiva (liquidi, semiconduttori,…)                  nota: inizieremo con esempi di materiali isolanti, i conduttori saranno trattati in seguito",isolanti la carica elettrica resta localizzata vetro plastica gomma conduttori cariche libere muoversi metalli warning classificazione po riduttiva liquidi nota inizieremo esempi materiali isolanti conduttori trattati seguito
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#60,60,"61Superfici chiuse e orientabili in ℝ3Nelle superfici chiuse e orientabili, in ogni punto della superficie  possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi si utilizza la normale esterna   :  positivo il flusso uscente dal volume delimitato dalla superficie chiusa negativo il flusso entrante nel volume delimitato dalla superficie chiusân
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n",superfici chiuse orientabili superfici chiuse orientabili ogni punto superficie possiamo distinguere normale esterna normale interna convenzione calcolare flussi utilizza normale esterna positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusan linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica linee flusso campo vettoriale consideriamo ora traiettoria particella fluido essa ogni punto tangente velocit vettoriale particella definiamo quindi linea flusso linea sempre tangente vettore velocit particelle fluido trovano punti linea domenico galli fisica generale linee flusso campo vettoriale possiamo tracciare linee flusso tanto fitte maggiore velocit fluido pi precisamente possiamo tracciare linee modo numero linee flusso attraversa lunit superficie sezione trasversale proporzionale velocit fluido domenico galli fisica generale superfici chiuse orientabili una superficie chiusa compatta priva bordo una superficie orientabile due facce orientabile sola domenico galli fisica generale elettrostatica aperta orientabile chiusa orientabile sfera chiusa orientabile toro aperta orientabile nastro mbius chiusa orientabile bottiglia klein superfici chiuse orientabili nelle superfici chiuse orientabili pu distinguere normale esterna normale interna ogni punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza normale esterna questo equivale considerare positivo flusso uscente volume delimitato superficie chiusa negativo flusso entrante volume delimitato superficie chiusa domenico galli fisica generale elettrostatica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#61,61,"Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('62Superfici aperte e orientabili in ℝ3Nelle superfici aperte non possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi attraverso una superficie aperta si utilizza l’orientamento    indicato dalla regola della mano destra sulla base dell’orientamento della linea del bordo:̂n",superfici aperte nelle superfici aperte pu distinguere normale esterna normale interna punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza lorientamento indicato regola mano destra base linea bordo domenico galli fisica generale flusso campo vettoriale attraverso superficie chiusa orientabile consideriamo ora flusso velocit fluido attraverso superficie chiusa per semplicit consideriamo superficie totale cubo consideriamo positivo flusso uscente cubo negativo flusso entrante cubo se fluido incompressibile interno sorgenti produce fluido pozzi scarichi fluido scompare allora tanto fluido entra cubo esce il flusso attraverso superficie totale nullo il cerchietto attorno simbolo integrale indica superficie integrazione chiusa domenico galli fisica generale flusso campo vettoriale attraverso superficie chiusa orientabile se flusso attraverso superficie totale positivo allora dentro cubo presente sorgente produce fluido se flusso attraverso superficie totale negativo allora dentro cubo presente pozzo cio scarico fluido scompare domenico galli fisica generale totvvind loperatore divergenza domenico galli fisica generale funzione vettoriale posizione si definisce loperatore divergenza come loperatore divergenza applica funzione vettoriale risultato scalare superfici aperte orientabili superfici aperte possiamo distinguere normale esterna normale interna convenzione calcolare flussi attraverso superficie aperta utilizza lorientamento indicato regola mano destra base linea bordon
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#62,62,"63L’angolo solidorl𝛼Angolo piano rapporto tra arco di circonferenza l e raggio r
r𝛺𝛴Angolo solido rapporto tra la parte di superficie sferica 𝛴 intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera α=lr∈[0,2π[L’angolo solido si misura in steradianti (sr)Ω=Σr2∈[0,4π]dα=dlrinfinitesimoinfinitesimodΩ=dΣr2",langolo solidorl angolo piano rapporto arco circonferenza raggio r angolo solido rapporto parte superficie sferica intercettata cono centrato vertice quadrato raggio sfera solido misura steradianti
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#63,63,64Il flusso del campo elettricod𝛴̂nαdS⃗Eprendendo la superficie d𝛴 ortogonale al campo elettrico:Flusso infinitesimo del campo elettrico attraverso una superficie dSdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso del campo elettrico attraverso una superficie estesa SΦS(⃗E)=∬S⃗E⋅̂ndS=∬SEcosαdS=∬SEdΣdΣ=dScosα,flusso campo elettricodnd seprendendo superficie ortogonale campo infinitesimo campo elettrico attraverso superficie sd seend sed scosed flusso campo elettrico attraverso superficie estesa sesend ss ecosd ss eddd scos
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#64,64,"65Il flusso del campo elettricoConsideriamo ora una superficie chiusa contenente al suo interno una carica elettrica puntiforme q̂n
d𝛴dSqdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso attraverso l’intera superficie S  (             ):∬SdΩ=4πil flusso dipende solo dall’angolo solido perché E è radialeΦS(⃗E)=∬S⃗E⋅̂ndS=qε0Notazione per integrale su superficie chiusaFlusso infinitesimo attraverso un elemento dS:α
ΦS(⃗E)=∬SdΦS=∬S⃗E⋅̂ndS=q4πε0∬SdΩ=qε0=(q4πε0r2)(r2dΩ)=q4πε0dΩ⃗E",flusso campo elettrico consideriamo ora superficie chiusa contenente interno carica elettrica puntiforme qn dd sqd seend sed scosed flusso attraverso lintera superficie sdil flusso dipende solo dallangolo solido radiale sesend sq notazione integrale superficie chiusa flusso infinitesimo attraverso elemento sesd ssend
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#65,65,"66Il flusso del campo elettrico
d𝛴2d𝛴1
r1r2dΩ=dΣ1r21=dΣ2r22Se q è esterna alla superficie chiusa, il numero di linee di campo che entrano nella superficie è uguale al numero di linee di campo che escono dalla superficie
d𝛴2dS2q
d𝛴1dS1̂n1̂n2α1α2⃗E1⋅̂n1=cosα1<0⃗E2⋅̂n2=cosα2>0
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(−r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)=⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0Flusso attraverso l’intera superficie:Flusso infinitesimo:=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0ΦS(⃗E)=∬S⃗E⋅̂ndS=0",flusso campo elettrico dd esterna superficie chiusa numero linee campo entrano superficie uguale numero linee campo escono superficie dd dd sed send sed scosed sed send sed send sed scosed sed send sed scosed sed send sed scosed flusso attraverso lintera scosed sesend
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#66,66,"67Il flusso del campo elettricoSe all’interno della superficie chiusa ci sono N cariche qi puntiformi, per il principio di sovrapposizione del campo elettrico, il flusso vale: dove QS è la carica contenuta all’interno della superficie S q3q2q5q7q6q1q8q4qN×××S𝜏(S)QS=∑iqintQS=∭τ(S)ρdτΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Cariche discrete Cariche distribuite su continuo V olume 𝜏(S) contenuto in superficie S ",flusso campo elettrico allinterno superficie chiusa cariche puntiformi principio sovrapposizione campo elettrico flusso vale carica contenuta allinterno superficie nssq siqint qssd sesend cariche discrete cariche distribuite continuo olume contenuto superficie
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#67,67,68La Legge di Gauss del campo elettricoIl flusso del campo elettrico attraverso una superficie chiusa S è uguale al rapporto tra la carica elettrica QS contenuta all’interno della superficie e la costante dielettrica ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0,legge gauss campo elettrico flusso campo elettrico attraverso superficie chiusa uguale rapporto carica elettrica contenuta allinterno superficie costante dielettrica sesend
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#68,68,69EsempiDeterminare il campo elettrico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 (usando la legge di Gauss) ,esempi determinare campo elettrico generato filo rettilineo indefinito depositata uniformemente carica densit lineare usando legge gauss
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#69,69,70EsempiDeterminare il campo elettrico generato da un piano indefinito su cui è depositata uniformemente una carica con densità superficiale 𝜎 (usando la legge di Gauss),esempi determinare campo elettrico generato piano indefinito depositata uniformemente carica densit superficiale usando legge gauss
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#7,7,"8Elettrizzazione per induzione (elettrostatica)
Elettroscopio a foglieAvvicinando un corpo carico all’elettroscopio, le foglie metalliche (conduttori) si allontanano Le componenti metalliche “sentono"" la vicinanza di carica elettrica L’effetto svanisce quando si allontana la carica",elettrizzazione induzione elettroscopio foglie avvicinando corpo carico foglie metalliche conduttori allontanano componenti metalliche sentono vicinanza carica elettrica leffetto svanisce quando allontana carica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#70,70,71EsempiDeterminare il campo elettrico ed il potenziale generato da un guscio sferico di raggio R su cui è depositata uniformemente una carica Q,esempi determinare campo elettrico potenziale generato guscio sferico raggio depositata uniformemente carica
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#71,71,72EsempioSia data una sfera di raggio R contenente una carica Q distribuita uniformemente. a) Determinare il campo elettrostatico in tutto lo spazio b) Calcolare il potenziale in un generico punto  esterno alla sfera (assumendo nullo il potenziale all’infinito) c) Calcolare il potenziale in un generico punto  interno alla sfera (assumendo nullo il potenziale all’infinito) d) Calcolare la differenza di potenziale tra il centro e la superficie della sfera,esempio data sfera raggio contenente carica distribuita uniformemente determinare campo elettrostatico spazio calcolare potenziale generico punto esterno sfera assumendo nullo potenziale allinfinito calcolare potenziale generico punto interno sfera assumendo nullo potenziale allinfinito calcolare differenza potenziale centro superficie sfera
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#72,72,"73La divergenza di un campo vettoriale
Consideriamo il flusso di un campo  vettoriale     attraverso una superficie chiusa S che delimita un volume 𝜏⃗FΦS(⃗F)=∬S⃗F⋅̂ndSDividiamo idealmente il volume 𝜏  in due volumi 𝜏1 e 𝜏2, usando una superficie di separazione D (diaframma). Siano S1 e S2 le superfici chiuse che delimitano 𝜏1 e 𝜏2 (D⊂S1,S2)𝜏SD𝜏2𝜏1S1S2Possiamo riscrivere il flussoΦS(⃗F)=∬S1⃗F⋅̂ndS1+∬S2⃗F⋅̂ndS2̂n2̂n1i contributi al flusso attraverso D si annullano⃗F⋅̂n1D=−⃗F⋅̂n2D",divergenza campo vettoriale consideriamo flusso campo vettoriale attraverso superficie chiusa delimita volume f sfsfnd sdividiamo idealmente volume due volumi usando superficie separazione diaframma superfici chiuse delimitano dss sd possiamo riscrivere flusso sfsfnd ssfnd snni contributi flusso attraverso annullanofn dfn
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#73,73,"74La divergenza di un campo vettorialeSuddividendo il volume 𝜏 in N volumi 𝜏i , limitatati da altrettante superfici SiDefinizione di divergenza di un campo vettorialediv⃗F=limτi→0ΦSi(⃗F)τiΦSi(⃗F)=∬Si⃗F⋅̂nidSiΦS(⃗F)=N∑i=1ΦSi(⃗F)La divergenza è il flusso uscente per unità di volume  • è una grandezza scalare, funzione delle coordinate • può variare da punto a punto𝜏iSi⃗FS𝜏⃗∇=(∂∂x,∂∂y,∂∂z)=∂∂x̂ı+∂∂ŷ𝚥+∂∂ẑkdiv⃗F=⃗∇⋅⃗FUtilizzando l’operatore “nabla”:",divergenza campo vettoriale suddividendo volume volumi limitatati altrettante superfici definizione divergenza campo sifi si sfni sifla divergenza flusso uscente unit volume grandezza scalare funzione coordinate pu variare punto puntoi sif utilizzando loperatore nabla
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#74,74,"75Il teorema della divergenzaIl flusso di un campo vettoriale attraverso una superficie S chiusa è pari all’integrale sul volume 𝜏 (delimitato da S !!!) della divergenza di tale campo vettoriale ∬S⃗F⋅̂ndS=∭τdiv⃗Fdτ=N∑i=1τi∬Si⃗F⋅̂nidSiτiNel limite N →∞ e 𝜏i →d𝜏, sostituiamo 𝛴→∫∫∫ ⟶∭τdiv⃗FdτΦS(⃗F)=∬S⃗F⋅̂ndS=N∑i=1∬Si⃗F⋅̂nidSiIl teorema della divergenza è una relazione tra un integrale di superficie e un integrale di volume",teorema divergenza flusso campo vettoriale attraverso superficie chiusa pari allintegrale volume delimitato divergenza tale campo vettoriale sfnd sii limite d sostituiamo divfd sfsfnd teorema divergenza relazione integrale superficie integrale volume
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#75,75,"76La legge di Gauss in forma localeCombiniamo il teorema della divergenza e la legge di Gauss, in presenza di una distribuzione continua di carica∭τ(S)div⃗Edτ=∭τ(S)ρε0dτdiv⃗E=ρε0∬S⃗E⋅̂ndS=∭τ(S)div⃗Edτ∬S⃗E⋅̂ndS=∭τ(S)ρε0dτLegge di GaussTeorema della divergenzaGli integrali sono sullo stesso volume",legge gauss forma locale combiniamo teorema divergenza legge gauss presenza distribuzione continua ssd legge gauss teorema divergenza integrali stesso volume
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#76,76,"77Significato fisico della divergenzaLa divergenza di un campo ci da un’informazione sul comportamento locale delle linee di campo le linee di campo si incontrano nei punti in cui la divergenza del campo è diversa da zero: • convergono nel punto se il valore della divergenza è negativo • divergono dal punto se il valore della divergenza è positivo In un punto in cui la divergenza è nulla, le linee di campo non si incontrano Se un campo ha divergenza sempre nulla, allora esso si definisce solenoidale",significato fisico divergenza divergenza campo uninformazione comportamento locale linee campo linee campo incontrano punti divergenza campo diversa zero convergono punto valore divergenza negativo divergono punto valore divergenza positivo punto divergenza nulla linee campo incontrano campo divergenza sempre nulla allora esso definisce solenoidale
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#77,77,"78Significato fisico della divergenzadiv⃗E=ρε0Il campo elettrico ha divergenza non nulla solo nei punti in cui esiste una densità di carica Nel vuoto, la divergenza del campo elettrico è nulla 
z
y
x⃗r⃗r′",significato fisico campo elettrico divergenza nulla solo punti esiste densit carica vuoto divergenza campo elettrico nulla xrr
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#78,78,"79Potenziale e legge di GaussLegge di Gauss in forma locale⃗∇⋅⃗E=ρε0⃗E=−⃗∇V⃗∇⋅(−⃗∇V)=ρε0∇2V=−ρε0Campo elettrostaticoEquazione di Poisson
Il laplaciano del potenziale è proporzionale alla densità di carica Equazione alle derivate seconde, note le condizioni al contorno ammette un’unica soluzione∂2V∂x2+∂2V∂y2+∂2V∂z2=−ρε0",potenziale legge gauss legge gauss forma v campo elettrostatico equazione poisson laplaciano potenziale proporzionale densit carica equazione derivate seconde note condizioni contorno ammette ununica soluzione vx vy vz
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#79,79,80EsempioCalcolare la divergenza del campo e il flusso attraverso una superficie sferica di raggio R centrata nell’origine ⃗F=k⃗r,esempio calcolare divergenza campo flusso attraverso superficie sferica raggio centrata nellorigine fkr
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#8,8,"9Elettrizzazione per induzione (elettrostatica)
Elettrizzazione per induzione anche su materiali isolanti
Microscopicamente, le molecole della carta “risentono” la vicinanza di cariche elettriche ",elettrizzazione induzione elettrizzazione induzione materiali isolanti molecole carta risentono vicinanza cariche elettriche
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#80,80,"81Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#9,9,"10Elettrizzazione per contatto
In caso di contatto, parte della carica si trasferisce (e resta) sul conduttoreCaso particolare: due conduttori di stessa forma e dimensione; inizialmente A ha una carica Q+Dopo aver messo in contatto A e B, la carica si ridistribuisce in parti ugualiAB++++++++++++++++Q+
AB++++++++12Q+12Q+++++++++
Carica totale si conserva!",elettrizzazione contatto caso contatto parte carica trasferisce resta conduttore caso particolare due conduttori stessa forma dimensione inizialmente carica qdopo aver messo contatto carica ridistribuisce parti uguali carica totale conserva
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#0,0, Elettrostatica dei conduttori CdS Ingegneria Informatica A.A. 2019/20,elettrostatica conduttori ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#1,1,"2Materiali isolanti e conduttoriisolanti  •le carica elettrica restano localizzate, sono vincolate a muoversi all’interno delle molecole •Un campo elettrico esterno non produce movimento di cariche, se non su piccolissima scala: deformazione e orientamento delle molecole (azioni sui dipoli) conduttori  •cariche (elettroni di conduzione) libere di muoversi sul conduttore (moto su reticolo cristallino) •comportamento degli elettroni simile ad un gas •in presenza di un campo esterno o di un eccesso di carica, le cariche si redistribuiscono sul conduttore",materiali isolanti le carica elettrica restano localizzate vincolate muoversi allinterno molecole un campo elettrico esterno produce movimento cariche piccolissima scala deformazione orientamento molecole azioni dipoli conduttori cariche elettroni conduzione libere muoversi conduttore moto reticolo cristallino comportamento elettroni simile gas in presenza campo esterno eccesso carica cariche conduttore
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#10,10,"11Campo elettrico in prossimità della superficie dei conduttori
In presenza di un conduttore, le linee di campo esterne vengono deviate dalla presenza di addensamenti locali di carica sulla superficie del conduttoreVicino al conduttore le linee di campo esterne saranno sempre perpendicolari alla superficie",campo elettrico prossimit superficie conduttori presenza conduttore linee campo esterne vengono deviate presenza addensamenti locali carica superficie conduttore vicino conduttore linee campo esterne sempre perpendicolari superficie
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#11,11,12Campo elettrico in prossimità della superficie dei conduttori⃗E=ÊnCalcoliamo il flusso attraverso un cilindretto di dimensioni infinitesime • asse ortogonale a superficie conduttore • contributo al flusso solo da base esterna⃗E=0dΦ(E)=⃗E⋅̂ndS=EdSFlusso attraverso base infinitesimaCarica contenuta nel cilindro (intersezione con la superficie del conduttore)dQS=σdSapplicando la legge di GaussEdS=σε0dSE=σε0,campo elettrico prossimit superficie calcoliamo flusso attraverso cilindretto dimensioni infinitesime asse ortogonale superficie conduttore contributo flusso solo base sed sflusso attraverso base infinitesima carica contenuta cilindro intersezione superficie conduttored qsd sapplicando legge gauss sd se
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#12,12,"13Teorema di Coulomb⃗E=σε0̂nIl campo elettrostatico in prossimità dei conduttori è sempre ortogonale alla superficie del conduttore ed il modulo è proporzionale alla densità superficiale di carica La densità superficiale di carica 𝜎=𝜎(x,y,z) può variare sulla superficie, di conseguenza varierà anche l’intensità del campo elettrico Il campo elettrico subisce una discontinuità nel passaggio dall’esterno all’interno del conduttore",teorema coulomben campo elettrostatico prossimit conduttori sempre ortogonale superficie conduttore modulo proporzionale densit superficiale carica densit superficiale carica xyz pu variare superficie conseguenza varier lintensit campo elettrico campo elettrico subisce discontinuit passaggio dallesterno allinterno conduttore
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#13,13,"14Conduttori caviSulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
S⃗E=0ΦS(⃗E)=QSε0=0La prima affermazione si dimostra applicando la legge di Gauss, utilizzando la condizione che il campo elettrico interno al conduttore è nullo",conduttori cavi superficie interna conduttore cavo carica totale nulla osservano cariche localizzate se seq prima affermazione dimostra applicando legge gauss utilizzando condizione campo elettrico interno conduttore nullo
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#14,14,"15Conduttori cavi
-+++++----⃗E≠0⃗E=0𝛤Ipotesi (per assurdo): distribuzioni locali di carica sulla superficie interna⇒ campo all’interno della cavità non nullo ⇒ circuitazione lungo linea chiusa 𝛤 non-nulla⇒ violazione della conservatività del campo elettrostatico Sulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
",conduttori cavi ee ipotesi per assurdo distribuzioni locali carica superficie interna campo allinterno cavit nullo circuitazione lungo linea chiusa nulla violazione conservativit campo elettrostatico superficie interna conduttore cavo carica totale nulla osservano cariche localizzate
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#15,15,"16Schermo elettrostatico
  Se un conduttore dotato di cavità viene esposto a un campo elettrico esterno, il campo elettrico all’interno della cavità è comunque nullo e non vi sono cariche elettriche indotte sulla superficie della cavità stessa.    In altre parole il conduttore scherma l’interno della cavità dai campi elettrici all’esterno (gabbia di Faraday)",schermo elettrostatico conduttore dotato cavit viene esposto campo elettrico esterno campo elettrico allinterno cavit comunque nullo cariche elettriche indotte superficie cavit stessa altre parole conduttore scherma linterno cavit campi elettrici allesterno gabbia faraday
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#16,16,"17Induzione completa
+QQ’’=+Q+++
++++
+Q’=-Q--------⃗E≠0Poniamo una carica puntiforme all’interno della cavità di un conduttore neutroLa carica genera un campo con linee radiali che poi curvano per diventare perpendicolari alla superficie interna induzione completa: tutte le linee di forza si chiudono sul conduttore Sulla superficie interna si induce una carica Q’ complessivamente uguale e opposta a +QSGauss è salvo: Q+Q’=0Conduttore neutro ⇒ carica Q’’=+Q indotta sulla superficie esterna⃗E=0",induzione completa qq e poniamo carica puntiforme allinterno cavit conduttore neutro carica genera campo linee radiali poi curvano diventare perpendicolari superficie interna induzione completa tutte linee forza chiudono conduttore superficie interna induce carica uguale opposta sgauss salvo qq conduttore neutro carica qq indotta superficie esternae
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#17,17,"18Induzione completa
+QQ’’=+QQ’=-Q+++++++++++
++++
+--------⃗E≠0Poniamo all’interno della cavità una generica carica (anche su un conduttore)  Un conduttore cavo trasferisce sulla propria superficie esterna una carica uguale al valore complessivo delle cariche contenute all’interno della cavità.  ",induzione completa qq e poniamo allinterno cavit generica carica anche conduttore conduttore cavo trasferisce propria superficie esterna carica uguale valore complessivo cariche contenute allinterno cavit
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#18,18,"BB
19Potenziale elettrostatico nei conduttoriADifferenza di potenziale tra due punti del conduttoreVA−VB=∫BA⃗E⋅d⃗l=0⃗E=0A⃗E⊥d⃗l⇒VA=VB∀A,B
Tutti i punti del conduttore sono equipotenziali  (la differenza di potenziale tra due qualsiasi punti del conduttore è sempre nulla)",potenziale elettrostatico conduttori adifferenza potenziale due punti conduttore vav bb aedle aedlv bab punti conduttore equipotenziali differenza potenziale due qualsiasi punti conduttore sempre nulla
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#19,19,"20Potenziale di un conduttore sfericoUn conduttore carico (con carica Q), di forma sferica di raggio R è equivalente ad un guscio sferico uniformemente caricoCampo elettrico (calcolato con legge di Gauss):⃗E(r<R)=0⃗E(r>R)=14πε0Qr2̂urPer simmetria, la densità superficiale di carica deve essere uniforme (altrimenti avrei campi elettrici tangenti)
RQ",potenziale conduttore sferico conduttore carico con carica forma sferica raggio equivalente guscio sferico uniformemente carico campo elettrico calcolato legge qrur simmetria densit superficiale carica deve essere uniforme altrimenti campi elettrici tangenti
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#2,2,3Premesse~F=m~a•Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra i conduttori e le eventuali cariche esterne •Lavoriamo con conduttori solidi (es. metalli) •Poniamoci in condizioni di ELETTROSTATICA,sistema riferimento inerziale corpo soggetto forze muove velocit costante supponiamo vuoto spazio interposto conduttori eventuali cariche esterne lavoriamo conduttori solidi metalli poniamoci condizioni
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#20,20,21Potenziale di un conduttore sfericoCalcolo del potenziale in un generico punto a distanza r dal centro della sfera (assumendo V∞=0)V(r)=V(r)−V(∞)=∫∞r⃗E⋅d⃗rEsternamente (come carica puntiforme)V(r>R)=∫∞r⃗E⋅d⃗r=∫∞r14πε0Qr2dr=Q4πε0[−1r]∞r=14πε0QrV(r<R)=∫∞r⃗E⋅d⃗r=∫Rr⃗E(r<R)⋅d⃗l+∫∞R⃗E(r≥R)⋅d⃗l=InternamenteE(r)rRV(r)rRDiscontinuità del campo⃗E(r>R)=14πε0Qr2̂urCostante!=0+∫∞RQ4πε01r2dr=Q4πε0[−1r]∞R=Q4πε01R,potenziale conduttore sferico calcolo potenziale generico punto distanza centro sfera assumendo esternamente come carica err rvrr rdiscontinuit qrur costanter
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#21,21,"22Esempio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)=",esempio calcolare lenergia elettrostatica sfera raggio rin distribuita uniformemente carica condensit acostante r certa regione spazio presenti due campi determinarea gradiente kxyk xyb due campi essere considerato elettrostatico consideri campofx
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#22,22,"23Esempio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica",esempio consideri sistema formato volume sferico raggioain contenuta carica volume sottile guscio materiale conduttore raggiobba concentrico alvolume sferico depositata carica
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#23,23,"24Ridistribuzione delle caricheQ0
R1Siano date due sfere conduttrici di raggi R1 e R2 con R1 > R2 Inizialmente sulla prima sfera c’è una carica Q0, la seconda sfera è scarica Le sfere sono poste a distanza tale da poter trascurare effetti di induzione elettrostatica
Successivamente le sfere vengono connesse con un sottile cavo conduttore. Come si ridistribuisce la carica? 
R2",ridistribuzione cariche date due sfere conduttrici raggi inizialmente prima sfera c carica seconda sfera scarica sfere poste distanza tale poter trascurare effetti induzione elettrostatica successivamente sfere vengono connesse sottile cavo conduttore ridistribuisce carica
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#24,24,"25Ridistribuzione delle cariche
R1
R2Dobbiamo calcolare le cariche finali sulle due sfere: Q1 e Q2Per la conservazione della carica (il sistema è isolato): Q1 + Q2 =Q0Le due sfere unite formano un unico conduttore  ⇒ equipotenziale V1 = V2 Q1Q2V1=14πε0Q1R1V2=14πε0Q2R214πε0Q1R1=14πε0Q2R2Q1R2=Q2R1Q1R1=Q2R2",ridistribuzione cariche dobbiamo calcolare cariche finali due sfere conservazione carica sistema isolato due sfere unite formano unico conduttore equipotenziale v v r r
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#25,25,"26Ridistribuzione delle cariche
R1
R2Q1Q2Risolvendo il sistema: {Q1+Q2=Q0Q1R2=Q2R1{Q2=Q0−Q1Q1R2=(Q0−Q1)R1{Q2=Q0−Q1Q1(R1+R2)=Q0R1Q1=R1R1+R2Q0Q2=R2R1+R2Q0La carica si redistribuisce proporzionalmente al raggioCaso particolare R1 = R2 Q1=Q2=Q02",ridistribuzione cariche risolvendo sistema qqq rqqq qrrq carica redistribuisce raggio caso particolare qqq
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#26,26,"27Potere delle punte
R1
R2Q1Q2Cosa succede alle densità di carica (e ai campi elettrici delle sfere?)σ1=Q14πR21σ2=Q24πR22Q1=σ14πR21Q2=σ24πR22V1 = V2  ⇒Q1R1=Q2R2σ14πε0R21R1=σ14πε0R22R2σ1R1=σ2R2La densità superficiale di carica è maggiore sulla sfera più piccolaσ1=(R2R1)σ2⟶R1>R2σ2>σ1",potere punte cosa succede densit carica campi elettrici sfereq rq q q r r densit superficiale carica maggiore sfera piccolar
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#27,27,"28Potere delle punteConsideriamo un conduttore di una forma generica, con raggio di curvatura che varia da punto a punto della superficie.⃗E=σε0̂nIn vicinanza delle punte il campo elettrico                 può essere molto intenso La densità di cariche è inversamente proporzionale al raggio di curvatura 
maggiore addensamento di carica sulle punte
+ + + + + + + + + + + + + + ++++++++++++++++",potere punte consideriamo conduttore forma generica raggio curvatura varia punto punto vicinanza punte campo elettrico pu essere molto intenso densit cariche inversamente proporzionale raggio curvatura maggiore addensamento carica punte
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#28,28,"29Potere delle punte
In vicinanza delle punte dei conduttori le densità di carica elettrostatica ed i campi elettrostatici possono essere molto intensi Campi molto intensi possono causare l’espulsione di cariche dal conduttoreLe cariche espulse subiscono forti accelerazioni, guadagnando energia cineticaInteragendo con l’aria, provocano un riscaldamento del mezzo per cui si osservano “scintille”",potere punte vicinanza punte conduttori densit carica elettrostatica campi elettrostatici possono essere molto intensi campi molto intensi possono causare lespulsione cariche conduttore cariche espulse subiscono forti accelerazioni guadagnando energia cinetica interagendo laria provocano riscaldamento mezzo osservano scintille
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#29,29,"30Collegamento a terra
R1
R2Q0Poniamoci nella condizione limite: R1 ≫ R2 Inizialmente carica Q0 sul conduttore piccolo.Q1=R1R1+R2Q0⟶R1≫R2Q0Q2=R2R1+R2Q0⟶R1≫R20La carica fluisce interamente sul conduttore più grandeLa Terra può essere considerata come un enorme conduttore, da cui si capisce il significato di collegamento a terra (o messa a terra, ground)VT=Q4πε0RT⟶RT≈6400km0Collegando i due conduttori:In elettrotecnica si utilizza il potenziale di terra come valore di riferimento del potenzialeSimbolo  messa a terra",collegamento terra poniamoci condizione limite inizialmente carica conduttore piccoloqr qrr qrr carica fluisce interamente conduttore grande terra pu essere considerata enorme conduttore capisce significato collegamento terra messa terra groundv tq rtr tkm collegando due conduttoriin elettrotecnica utilizza potenziale terra valore riferimento potenziale simbolo messa terra
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#3,3,"4Conduttori in presenza di carica esterna
+++++++
+++++++
Conduttorebacchetta caricaoscilloscopio a foglieL’oscilloscopio misura la presenza di caricaL’oscilloscopio misura una maggiore presenza di caricaInduzione elettrostatica (spostamento di cariche sul conduttore)+++++++-------",conduttori presenza carica esterna foglie loscilloscopio misura presenza carica loscilloscopio misura maggiore presenza carica induzione elettrostatica spostamento cariche
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#30,30,"31Massa e messa a terra
TerraIn elettrotecnica la massa (chassis) è la scatola metallica di un’apparecchiatura elettrica Si comporta come una gabbia di Faraday La massa è utilizzata per assegnare il potenziale di riferimento comune delle componenti elettriche
massaguasto delle componenti elettriche ⇒ eccesso di cariche sulla massa (pericolo!)Collegando la massa a terra, si scaricano pericolosi eccessi di caricacomponenti  elettrici/elettronici",massa messa terra terra elettrotecnica massa chassis scatola metallica elettrica comporta gabbia faraday massa utilizzata assegnare potenziale riferimento comune componenti elettriche massaguasto componenti elettriche eccesso cariche massa massa terra scaricano pericolosi eccessi
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#31,31,"32Capacità di un conduttoreIl potenziale di un conduttore isolato è proporzionale alla carica presente sul conduttoreC=QVDefiniamo la capacità di un conduttoreNel S.I. la capacità si misura in Farad (F):  1F=1C/1VLa capacità quantifica l’attitudine di un conduttore ad accumulare carica ad un dato potenziale  La capacità dipende solo dalla forma e dalle dimensioni del conduttore e dal mezzo che lo circonda (nel nostro caso il vuoto, per ora)",capacit conduttore potenziale conduttore isolato proporzionale carica presente conduttore vdefiniamo capacit conduttore capacit misura farad vla capacit quantifica lattitudine conduttore accumulare carica dato potenziale capacit dipende solo forma dimensioni conduttore mezzo circonda nel caso vuoto ora
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#32,32,"33Capacità di un conduttore sferico
RQConsideriamo una sfera conduttrice di raggio R con carica QC=QV=QQ4πε0R=4πε0RLa capacità dipende solamente da fattori geometriciEsempiCapacità di una sfera di raggio R=1m nel vuoto: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++Capacità della Terra R=6400 km: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++",capacit conduttore sferico qconsideriamo sfera conduttrice raggio carica q r rla capacit dipende solamente fattori geometrici esempi capacit sfera raggio vuoto capacit conduttore dato conduttore isolato spazio potenziale elettrostatico risulta proporzionale carica presente conduttore stesso linverso costante proporzionalit viene chiamata capacit conduttore vuoto costante caratteristica forma geometrica dimensioni nel sistema internazionale capacit misura farad ovvero coulombvolt dimensioni sono domenico galli fisica generale elettrostatica conduttori metallici capacit conduttore si osservi inciso che definito farad costante dielettrica vuoto scrive calcoliamo ora capacit conduttore sferico visto carica conduttore potenziale segue che rconduttore sferico domenico galli fisica generale elettrostatica conduttori sor capacit conduttore se consideriamo sfera conduttrice raggio capacit sar il globo terrestre raggio capacit pari dunque minore milli farad domenico galli fisica generale elettrostatica conduttori metallici capacit conduttore allinterno cavit se conduttore avvicina altro conduttore neutro isolato aumenta capacit primo conduttore calcoliamo capacit sfera racchiusa cavit sferica conduttore con due superfici sferiche concentriche domenico galli fisica generale elettrostatica conduttori terra capacit conduttore dato conduttore isolato spazio potenziale elettrostatico risulta proporzionale carica presente conduttore stesso linverso costante proporzionalit viene chiamata capacit conduttore vuoto costante caratteristica forma geometrica dimensioni nel sistema internazionale capacit misura farad ovvero coulombvolt dimensioni sono domenico galli fisica generale elettrostatica conduttori metallici capacit conduttore si osservi inciso che definito farad costante dielettrica vuoto scrive calcoliamo ora capacit conduttore sferico visto carica conduttore potenziale segue che rconduttore sferico domenico galli fisica generale elettrostatica conduttori sor capacit conduttore se consideriamo sfera conduttrice raggio capacit sar il globo terrestre raggio capacit pari dunque minore milli farad domenico galli fisica generale elettrostatica conduttori metallici capacit conduttore allinterno cavit se conduttore avvicina altro conduttore neutro isolato aumenta capacit primo conduttore calcoliamo capacit sfera racchiusa cavit sferica conduttore con due superfici sferiche concentriche domenico galli fisica generale elettrostatica conduttori
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#33,33,"34CondensatoriIl condensatore è un sistema formato da due conduttori carichi per i quali si verifica induzione completa (tutte le linee di forza uscenti da un conduttore incontrano l’altro conduttore) I due conduttori sono le armature del condensatore Lo spazio interposto tra le armature è l’intercapedineLa capacità del condensatore è definita come rapporto tra la carica (presente con segno opposto sui due conduttori) e la differenza di potenziale tra i due conduttoriC=QΔV
+Q-Q++++++++++++____________La capacità di un condensatore dipende solo dalla geometria, dalla forma e dal materiale interposto tra i conduttoriSimbolo  condensatore",condensatori condensatore sistema formato due conduttori carichi quali verifica induzione completa tutte linee forza uscenti conduttore incontrano laltro conduttore due conduttori armature condensatore spazio interposto armature lintercapedine capacit condensatore definita rapporto carica presente segno opposto due conduttori differenza potenziale due conduttori cq capacit condensatore dipende solo geometria forma materiale interposto conduttori simbolo condensatore
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#34,34,"35Capacità di un condensatore pianoIl condensatore piano (condensatore a facce piane e parallele) è costituito da due armature piane di superficie S poste parallelamente a piccola distanza d (d≪S, trascuriamo effetti di bordo)
SdSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QIl sistema è equivalente al doppio strato⃗E={σε0̂n=QS1ε0interno0esternoCapacità:C=QΔV=QQdε0S=ε0Sd• proporzionale alla superficie delle armature • inversamente proporzionale alla distanza tra le armatureΔV=∫d0Edz=Ed=QdSε0",capacit condensatore piano condensatore piano condensatore facce piane parallele costituito due armature piane superficie poste parallelamente piccola distanza ds trascuriamo effetti bordo sistema equivalente doppio capacitcq qd sd proporzionale superficie armature inversamente proporzionale distanza armature vd edzedqd
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#35,35,"36Capacità di un condensatore sferico
R1+Q-QR2Un condensatore sferico è costituito da una sfera conduttrice di raggio R1 racchiusa all’interno di una cavità sferica di raggio R2 di un conduttore sfericoΔV=V1−V2=∫R2R1⃗E⋅d⃗r=Q4πε0∫R2R1drr2=Q4πε0[−1r]R2R1=Q4πε0(1R1−1R2)Differenza di potenziale tra le armatureCapacità del condensatore sfericoC=QΔV=QQ4πε0(1R1−1R2)=4πε0(R1R2R2−R1)Nel limite R1→ R2, definendo d=R2-R1 C=4πε0(R1R2R2−R1)⟶R1→R24πε0R2d=ε0Sdcapacità del condensatore piano",capacit condensatore sferico condensatore sferico costituito sfera conduttrice raggio racchiusa allinterno cavit sferica raggio conduttore sferico vvvr rq rdifferenza potenziale armature capacit condensatore sferico cq q rr rrnel limite definendo cr rd sdcapacit condensatore piano
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#36,36,"37Capacità di un condensatore cilindricoUn condensatore cilindrico è costituito da un cilindro conduttore di raggio R1 racchiuso all’interno di una cavità cilindrica di raggio R2 di un conduttore cilindrico (nell’approssimazione R1,R2≪h , trascurando eff. bordo)⃗E=Q2πε0hr̂rCampo elettrico internoR2R1hΔV=∫R2R1Edr=∫R2R1Qdr2πε0hr=Q2πε0hlnR2R1Differenza di potenziale tra le armatureC=QQ2πε0hlnR2R1=2πε0hlnR2R1CapacitàNel limite R1→ R2, definendo d=R2-R1 lnR2R1=lnR1+R2−R1R1=ln(1+R2−R1R1)=ln(1+dR1)≅dRC=2πε0hdR=ε02πRhd=ε0Sdcapacità del condensatore piano",capacit condensatore cilindrico condensatore cilindrico costituito cilindro conduttore raggio racchiuso allinterno cavit cilindrica raggio conduttore cilindrico rrh trascurando eff campo elettrico interno rh vr edrr differenza potenziale armature qhln rhln capacit limite definendo rln rrr rlnrr rlnd rd rchd r rhd sdcapacit condensatore piano
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#37,37,"38Sistemi di condensatori in paralleloI condensatori sono dispositivi dipolari  (hanno due capi di connessione)Connessione in parallelo (gli elementi circuitali sono alla stessa differenza di potenziale 𝛥V1=𝛥V2=VA-VB=𝛥VAB): Q1=C1𝛥V1=C1𝛥VAB Q2=C2𝛥V2=C2𝛥VABQTOT=Q1+Q2=(C1+C2)𝛥VAB=CTOT𝛥VABCTOT=C1+C2   
la capacità del sistema formato da due (o più) condensatori collegati in parallelo è uguale alla somma delle singole capacitàCTOT=∑CiC1C2+Q2-Q1VAVB-Q2+Q1",sistemi condensatori parallelo condensatori dispositivi dipolari hanno due capi parallelo gli elementi circuitali stessa differenza potenziale qc vc qc vc tcc capacit sistema formato due pi condensatori collegati parallelo uguale somma singole capacit otci
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#38,38,"39Sistemi di condensatori in serieConnessione in serie (gli elementi circuitali sono collegati con un solo polo in comune)Conduttore isolato e neutro -Q1+Q2=0 ⇒  Q1=Q2 I condensatori in serie hanno la stessa caricaC1C2+Q2+Q1VAVB-Q1-Q2VM=QC1+QC2=Q(1C1+1C2)=QCTOTVA−VB=(VA−VM)+(VM−VB)=1CTOT=1C1+1C2CTOT=C1C2C1+C21CTOT=∑1Ci
L’inverso della capacità del sistema formato da due o più condensatori collegati in serie è uguale alla somma degli inversi delle singole capacità ",sistemi condensatori serie connessione serie gli elementi circuitali collegati solo polo isolato neutro condensatori serie stessa carica cqq vmq vav av mv otc ot linverso capacit sistema formato due condensatori collegati serie uguale somma inversi singole capacit
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#39,39,"40Esempio
serie o parallelo?",esempio serie parallelo
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#4,4,"5Conduttori in presenza di carica esterna
+++++++In presenza di un campo elettrostatico esterno le cariche del conduttore si spostano fino a raggiungere una nuova condizione di equilibrio (𝛥t∼10-9 s)Equilibrio ⇒ cariche ferme ⇒ forza nulla ⇒ campo elettrico complessivamente nulloLe cariche del  conduttore si dispongono in maniera tale da generare un campo interno      (indotto) che annulla il campo esterno⃗E⃗E⃗E′",conduttori presenza carica esterna presenza campo elettrostatico esterno cariche conduttore spostano fino raggiungere nuova condizione equilibrio t sequilibrio cariche ferme forza nulla campo elettrico nullo cariche conduttore dispongono maniera tale generare campo interno indotto annulla campo esternoeee
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#40,40,"41Esercizio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica",esercizio consideri sistema formato volume sferico raggioain contenuta carica volume sottile guscio materiale conduttore raggiobba concentrico alvolume sferico depositata carica
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#41,41,"42Energia elettrostatica di un sistema di caricheEnergia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale V:  U=qV  Rappresenta il lavoro che bisogna fare sulla carica q per portarla dall’infinito al punto in cui il potenziale vale Vq1Per portare la prima carica nella posizione finale, non occorre fare lavoroPer portare la seconda carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q2⃗E1⋅d⃗l⃗r12q2=q2∫⃗E1⋅d⃗l=q2V1(r12)=q2q14πε0r12U12=q1q24πε0r12=U21Energia del sistema di due cariche:",energia elettrostatica sistema cariche energia potenziale elettrostatica carica situata punto spazio presente potenziale rappresenta lavoro bisogna fare carica portarla dallinfinito punto potenziale vale portare prima carica posizione finale occorre fare lavoro portare seconda carica occorre fare lavoro energia sistema due cariche
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#42,42,"43Energia elettrostatica di un sistema di caricheq1Per portare una terza carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q3⃗Etot⋅d⃗l=q3∫(⃗E1+⃗E2)⋅d⃗l⃗r12q2=q3[∫⃗E1⋅d⃗l+∫⃗E2⋅d⃗l]=q3[V1(r13)+V2(r23)]=⃗r13⃗r23q3=q3V1(r13)+q3V2(r23)=q3q14πε0r13+q3q24πε0r23U13=U31=q1q34πε0r13U23=U32=q2q34πε0r23UE=U12+U13+U23Energia elettrostatica del sistema di 3 cariche:",energia elettrostatica sistema caricheq portare terza carica occorre fare lavoro vrq ueuuu energia elettrostatica sistema cariche
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#43,43,44Energia elettrostatica di un sistema di caricheUij=qiqj4πε0rijUE=12(U12+U21+U13+U31+U23+U32)Energia elettrostatica del sistema di 3 cariche:Utilizzando una notazione compatta:Vi=3∑j=1j≠iqj4πε0rijUE=123∑i=1qiVi=123∑i=1qi3∑j=1j≠iqj4πε0rij,energia elettrostatica sistema cariche uijqiqjrij elettrostatica sistema notazione ueiqi
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#44,44,45Energia elettrostatica di un sistema di caricheL’energia elettrostatica totale di un sistema di N cariche puntiformi èqiqj⃗rijL’energia elettrostatica di un sistema è equivalente al lavoro necessario per portare le N cariche nella configurazione finale UE=12N∑i=1qiVi=12N∑i=1N∑j=1j≠iqiqj4πε0rij=N∑i=1N∑j>iqiqj4πε0rij,energia elettrostatica sistema cariche lenergia elettrostatica totale sistema cariche puntiformi qiqjrij lenergia elettrostatica sistema equivalente lavoro necessario portare cariche configurazione finale niqi ni
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#45,45,"46EsercizioEsercitazioni di Fisica Generale T2 - provvisorioLorenzo Rinaldi10/10/20171 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, determinare l’angolo✓che i due ﬁli formano con la verticale (risolvere nell’approssimazione✓⇡0 (R:✓=3qq216⇡✏0mgl2).1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏055+15p2+12p330=4.65J )1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1=",esercizio esercitazioni fisica generale provvisorio lorenzo elettrostatica vuoto due piccole palline sughero identiche massamhanno ugual caricaq esse appese due li dilunghezzal volta vincolati medesimo punto condizioni equilibrio determinare langoloche due li formano verticale risolvere tre cariche positive puntiformi disposte piano cartesiano punti coordinate quarta carica positivaq eposta punto coordinate determinarea forza sottoposta caricaq lenergia necessaria spostare caricaqdalla posizione iniziale allorigine sistema diriferimento tre cariche puntiformi poste vertici triangolo equilatero latoacm sapendo cheq
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#46,46,47Energia elettrostaticaNel caso in cui le cariche siano distribuite con una densità 𝜌 su un volume 𝜏UE=12∫τρVdτUtilizzando la legge di Gauss in forma locale: ρ=ε0⃗∇⋅⃗E⃗∇⋅(V⃗E)=V⃗∇⋅⃗E+⃗E⋅⃗∇VV⃗∇⋅⃗E=⃗∇⋅(V⃗E)−⃗E⋅⃗∇VUE=12∫τρVdτ=12∫τε0⃗∇⋅⃗EVdτUso le proprietà del prodotto scalareUE=ε02∫τ(⃗∇⋅(V⃗E)−⃗E⋅⃗∇V)dτUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ,energia elettrostatica caso cariche distribuite densit volume ue vd utilizzando legge gauss forma locale ue vde vd uso propriet prodotto scalare
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#47,47,48Densità di energia del campo elettrico⃗∇V=−⃗EUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ∫div⃗Fdτ=∮⃗F⋅̂ndSUE=ε02∮SV⃗E⋅̂ndS+∫τ⃗E⋅⃗EdτGli integrali vanno calcolati su tutto lo spazio in  cui è presente il campo elettrico Il campo elettrico si estende e si annulla all’infinito se la carica 𝜌 è localizzataIl flusso all’infinito è nullo (E si annulla all’infinito) ⃗E⋅⃗E=E2uE=12ε0E2densità di energia del campo elettrostaticoUE=∫spazio12ε0E2dτUE=∫spaziouEdτ,densit energia campo es vend seed integrali vanno calcolati spazio presente campo elettrico campo elettrico estende annulla allinfinito carica localizzata flusso allinfinito nullo annulla allinfinito eeeu edensit energia campo elettrostatico uespazio ed uespaziou ed
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#48,48,"49Densità di energia del campo elettrico
uE=12ε0E2densità di energia del campo elettrostatico (quantità di energia per unità di volume) L’energia elettrostatica è localizzata nel campo elettrico (e non nella carica)UE=∫spazio12ε0E2dτUE=∫spaziouEdτUE=12∫τρVdτuE=dUEdτEspressioni dell’energia elettrostaticavolume in cui è contenuta la caricavolume in cui è presente il campo elettrico",densit energia campo elettrico edensit energia campo elettrostatico quantit energia unit volume lenergia elettrostatica localizzata campo elettrico caricau espazio ed uespaziou ed ue vdu ued espressioni dellenergia contenuta caricavolume presente campo elettrico
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#49,49,"50Energia di un condensatoreSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+q-qCondensatore (piano) carico con carica q+dqdℒ=dqΔVq=dqqCIl lavoro complessivo per caricare completamente il condensatore dalla carica 0 alla carica Q:ℒ=∫Q0dℒ=∫Q0dqqC=1C∫Q0qdq=12Q2CL’energia elettrostatica accumulata in un condensatore è Ue=12Q2C=12CΔV2=12QΔVIl lavoro (di una forza esterna) per portare una carica +dq dall’armatura di destra a quella di sinistra è:",energia condensatore condensatore piano carico carica qdqddq vqdqq cil lavoro complessivo caricare completamente condensatore carica carica cqqdq clenergia elettrostatica accumulata condensatore vil lavoro forza esterna portare carica dallarmatura destra sinistra
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#5,5,"6Elettrizzazione per contatto
++++++++++++++++In caso di contatto parte della carica sulla bacchetta si trasferisce al conduttoreLa carica resta sul conduttore dopo aver rimosso il contatto (misurabile con oscilloscopio)
+++++++++++++ConduttoreConduttore⃗Econd=0Nuova situazione di equilibrio ⇒",elettrizzazione contatto caso contatto parte carica bacchetta trasferisce conduttore carica resta conduttore dopo aver rimosso contatto misurabile oscilloscopio nuova situazione equilibrio
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#50,50,"51Energia di un condensatoreIn un condensatore piano la capacità vale: Sd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QC=ε0SdRiscriviamo l’energia: La differenza di potenziale tra le armature: ΔV=EdL’energia è pari alla densità di energia integrata su tutto lo spazio dove si estende il campo (il campo è nullo esternamente al condensatore)densità di energia elettrostaticavolume interno del condensatoreUE=12CΔV2=12ε0Sd(Ed)2=12ε0dSE2=(12ε0E2)(dS)=uEτ=∫τuEdτ",energia condensatore condensatore piano capacit vale riscriviamo lenergia differenza potenziale armature ved lenergia pari densit energia integrata spazio estende campo campo nullo esternamente energia interno condensatore sdedd se eu ed
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#51,51,"52Energia del condensatore
Si può pensare di utilizzare un condensatore al posto di una batteria (chimica) ricaricabile? Svantaggi: •Ingombro. La densità di energia (energia per unità di volume) di un condensatore è enormemente minore di quella di una batteria. •Potenziale non costante. Mano mano che si scarica, la differenza di potenziale ai capi di un condensatore diminuisce (proporzionalmente alla carica).Vantaggi: •Velocità. Un condensatore si può caricare molto velocemente e può produrre intensità di corrente molto elevate scaricandosi (flash macchine fotografiche) •Durata. Una batteria si esaurisce dopo alcune migliaia di cicli di carica-scarica, mentre un condensatore ha una durata teoricamente illimitata.  •Basse temperature. Funzionano anche a -40° C, temperatura alla quale le normali batterie non sono in grado di operare. ",energia condensatore pu pensare utilizzare condensatore posto batteria chimica ricaricabile svantaggi ingombro densit energia energia unit volume condensatore enormemente minore batteria potenziale costante mano mano scarica differenza potenziale capi condensatore diminuisce velocit condensatore pu caricare molto velocemente pu produrre intensit corrente molto elevate scaricandosi flash macchine fotografiche durata batteria esaurisce dopo alcune migliaia cicli carica scarica mentre condensatore durata teoricamente illimitata basse temperature funzionano temperatura normali batterie grado operare
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#52,52,"53Forza tra le armature di un condensatoreLe armature di un condensatore hanno cariche opposte: si attraggonoSx+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QUE=12Q2C=12Q2xε0Steniamo fissa un’armatura e applichiamo una forza esterna opposta a quella attrattiva, in modo tale che il lavoro della forza esterna bilanci la variazione di energia del condensatore⃗F⃗FestdUE=δℒest=FestdxdUE=12Q2dxε0S=δℒest=Festdxpossiamo definire la pressione elettrostatica:Per calcolare la forza tra le armature di un condensatore piano partiamo dall’energiaForza tra le armature ⃗F=−⃗Fest=−Q22ε0Ŝnp=FS=Q22ε0S2=σ22ε0",forza armature condensatore armature condensatore cariche opposte attraggono qx steniamo fissa unarmatura applichiamo forza esterna opposta attrattiva modo tale lavoro forza esterna bilanci variazione energia qdx definire pressione calcolare forza armature condensatore piano partiamo dallenergia forza armature snpf sq s
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#53,53,"54EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p.",esempio sfigure dati due condensatori rispettivamente capacit disposti gura inizialmente armature condensatore poste ddp
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#54,54,"55EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p.",esempio sfigure dati due condensatori rispettivamente capacit disposti gura inizialmente armature condensatore poste ddp
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#55,55,"56Condensatori con dielettriciCosa succede se riempiamo con un materiale isolante l’intercapedine di un condensatore?+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  ++𝜎-𝜎-𝜎P𝜎PNel dielettrico le cariche non si muovono.Però a livello microscopico le molecole (dipolari) possono orientarsiSulle superfici del dielettrico a contatto con le armature del condensatore si osserva un eccesso di carica 𝜎P (carica di polarizzazione)Le cariche di polarizzazione creano un campo elettrico opposto al campo del condensatoreIl campo elettrico totale (e di conseguenza la differenza di potenziale) diminuisce La capacità del condensatore aumenta⃗E0⃗E′",condensatori dielettrici cosa succede riempiamo materiale isolante lintercapedine condensatore pnel dielettrico cariche muovonoper livello microscopico molecole dipolari possono orientarsi superfici dielettrico contatto armature condensatore osserva eccesso carica carica cariche polarizzazione creano campo elettrico opposto campo condensatore campo elettrico totale conseguenza differenza potenziale diminuisce capacit condensatore aumentaee
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#56,56,"57Il dipolo elettrico
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!-+   Il dipolo elettrico è un sistema formato da 2 cariche elettriche in quiete, di uguale valore assoluto ma segno opposto (Q e –Q), poste a una distanza fissata d.  
x
z
y+Q-QdMolti materiali isolanti sono formati da molecole che hanno una struttura “dipolare”. 
Definiamo il momento di dipolo ⃗p=(Qd)̂k
",dipolo elettrico teorema divergenza per comprendere significato teorema divergenza immaginiamo suddividere volume tanti cubetti infinitesimi volume per ogni cubetto visto ogni cubetto che facce vind ssivd domenico galli fisica generale vpv svind teorema divergenza distinguiamo ora facce cubetti facce interne facce esterne le facce interne separano cubetto cubetto adiacente le facce esterne parte frontiera volume totale sommando divergenze cubetti contributi flussi facce interne cancellano loro il flusso uscente cubetto verso cubetto adiacente opposto flusso cubetto cubetto si pertanto domenico galli fisica generale vvvind linee flusso campo elettrico come campi vettoriali campo elettrico pu rappresentare graficamente linee flusso linee campo ovvero linee tangenti ogni punto vettore campo elettrico orientate verso campo elettrico in numero unit superficie trasversale proporzionale modulo campo elettrico domenico galli fisica generale elettrostatica angolo solido come noto langolo piano radianti definito rapporto arco circonferenza centrata vertice raggio langolo solido definisce maniera analoga rapporto parte superficie sferica centrata vertice intercettata cono centrato vertice quadrato raggio sfera langolo solido misura steradianti domenico galli fisica generale elettrostatica dipolo elettrico sistema formato cariche elettriche quiete uguale valore assoluto segno opposto poste distanza fissata molti materiali isolanti formati molecole struttura dipolare definiamo momento dipolo pqdk
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#57,57,"58Azioni meccaniche su un dipolo elettricoCalcoliamo il momento della forza esercitato da un campo esterno su un dipolo
⃗M=⃗p∧⃗E
Dipolo Elettrico (IV) •!Si ha: 
•!Dunque il potenziale di un dipolo elettrico decresce con la distanza come 1/r2.      !pi!r=QdversP+!P!()i!r=Qdrcos!   V!r()""d#rQ4!""0dr2cos#=14!""01r2!pi!rr   V!r()""d#r14!""0!pi!rr3
9!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!
Dipolo Elettrico (V) •!Per calcolare il campo elettrico del dipolo scriviamo il potenziale in coordinate cartesiane e calcoliamo il gradiente:    Vx,y,z()!d""r14!""0xpx+ypy+zpzx2+y2+z2()32
   Exx,y,z()=!""V""x""d#r!14#$0""""xxpx+ypy+zpzx2+y2+z2()32==!14#$0pxx2+y2+z2()32!xpx+ypy+zpz()32x2+y2+z2()122xx2+y2+z2()3==14#$03xxpx+ypy+zpz()x2+y2+z2()52!pxx2+y2+z2()32%&'''()***=14#$03!pi!r()xr5!pxr3%&''()**10!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!
Dipolo Elettrico (VI) •!Ripetendo il calcolo per le componenti y e z si ottiene: •!Il campo elettrico di un dipolo elettrico decresce con la distanza come 1/r3:    !Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())
11!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!!Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())=14!""01r33!piˆr()ˆr#!p$%'(
Dipolo Elettrico (VII) •!Calcoliamo ora il momento della forza esercitato da un campo elettrico esterno su di un dipolo elettrico. •!Trattandosi di due forze di uguale modulo QE, medesima direzione e verso opposto, le cui rette di azione distano d sin !, si ha: 
Q!Qd– !pF!!F!!!Esind!+    !M=!p!!E   M=Fb=QE()dsin!()=Qd()Esin!()=pEsin!
12!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!M=FEdsinθ=(QE)dsinθ=(Qd)Esinθ=pEsinθLe due forze hanno stesso modulo QE, stessa direzione e verso opposto il momento delle forze (prendendo come polo una delle due cariche) è⃗M=⃗rd∧⃗FE",azioni meccaniche dipolo elettrico calcoliamo momento forza esercitato campo esterno dipolo mpe dipolo elettrico si dunque potenziale dipolo elettrico decresce distanza pirqdvers vrdr domenico galli fisica generale problema generale qrrxyzd dipolo elettrico per calcolare campo elettrico dipolo scriviamo potenziale coordinate cartesiane calcoliamo gradiente galli fisica generale problema generale dipolo elettrico ripetendo calcolo componenti ottiene il campo elettrico dipolo elettrico decresce distanza domenico galli fisica generale problema generale dipolo elettrico calcoliamo ora momento forza esercitato campo elettrico esterno dipolo elettrico trattandosi due forze uguale modulo medesima direzione verso opposto rette azione distano sin qqd ffesind mpe mfbq esin domenico galli fisica generale problema generale edsinq esin due forze stesso modulo stessa direzione verso opposto momento forze prendendo polo due cariche mrdf
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#58,58,"59Elettrostatica dei dielettrici+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |⃗E0−  +⃗pOgni singolo atomo/molecola del dielettrico ha un momento di dipolo elettrico ⃗p(⃗p=q⃗d)Ogni dipolo sentirà un momento delle forze e tenderà ad allinearsi con il campo:⃗M=⃗p∧⃗E0Definiamo il momento di dipolo medio          (media di tutti i dipoli) ⟨⃗p⟩sia                 il numero di atomi/molecole per unità di volumen=NΔτSi definisce il vettore polarizzazione ⃗P=n⟨⃗p⟩[C/m2] come densità di carica • indica il grado di allineamento degli atomi/molecole in un dielettrico",elettrostatica dielettrici e ogni singolo atomomolecola dielettrico momento dipolo elettrico ppqdogni dipolo sentir momento forze tender allinearsi campompe definiamo momento dipolo medio media dipoli psia numero atomimolecole unit volumenn definisce vettore polarizzazione pnpcm densit carica indica grado allineamento atomimolecole dielettrico
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#59,59,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L+𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
60Elettrostatica dei dielettrici|⃗P|=σpIl modulo del vettore polarizzazione è la densità di carica di polarizzazione⃗P=σp̂n⃗P=σp̂nIn un dielettrico isotropo e omogeneo le cariche di polarizzazione sono distribuite solo superficialmente (±𝜎P)Chiamiamo la carica libera (±𝜎L) quella sulle armature del condensatoreSi definisce il vettore spostamento elettrico⃗D=σL̂n⃗D=σL̂n",elettrostatica modulo vettore polarizzazione densit carica dielettrico isotropo omogeneo cariche polarizzazione distribuite solo pchiamiamo carica libera armature condensatore definisce vettore spostamento elettricod lnd ln
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#6,6,"7Carica interna al conduttore
SConsideriamo una generica superficie chiusa S interna al conduttore  ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Per la legge di GaussInternamente al conduttore il campo elettrico è nullo, quindi la carica interna ad S sarà sempre nullaQS=∭τ(S)ρdτ=0All’interno del conduttore non ci sono cariche in eccesso (cariche positive e negative hanno uguale densità)⃗E=0",carica interna conduttore consideriamo generica superficie chiusa interna conduttore sesend legge gauss internamente conduttore campo elettrico nullo quindi carica interna sempre nulla qssd allinterno conduttore cariche eccesso cariche positive negative uguale densite
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#60,60,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
61Elettrostatica dei dielettriciIl campo all’interno del dielettrico⃗E=⃗E0+⃗EP⃗EP=−σPε0̂n⃗E0=σLε0̂n⃗D=ε0⃗E+⃗P=⃗Dε0−⃗Pε0=σL̂nε0−σP̂nε0In un dielettrico isotropo e omogeneo i vettori campo elettrico, polarizzazione e spostamento sono paralleliIn un dielettrico isotropo e omogeneo si definisco le due quantità adimensionali suscettività dielettrica 𝜒 (𝜒≥0) e la costante dielettrica relativa 𝜀R (𝜀R≥1), legati dalla relazione 𝜒=𝜀R-1Il campo elettrico ed il vettore polarizzazione sono legati dalla relazione⃗P=ε0χ⃗E=ε0(εR−1)⃗E",elettrostatica dielettrici campo allinterno pe p pne ln pn dielettrico isotropo omogeneo vettori campo elettrico polarizzazione spostamento paralleli dielettrico isotropo omogeneo definisco due quantit adimensionali suscettivit dielettrica costante dielettrica relativa legati relazione campo elettrico vettore polarizzazione legati re
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#61,61,"62Elettrostatica dei dielettrici⃗P=ε0χ⃗E=ε0(εR−1)⃗E⃗D=ε0⃗E+⃗P⃗D=ε0⃗E+ε0(εR−1)⃗E=ε0εR⃗EUtilizzando il vettore spostamento elettrico, formuliamo la legge di Gauss (in forma locale e integrale) in funzione delle sole cariche libere 𝜌L e QL :⃗∇⋅⃗D=ρL∬⃗D⋅̂ndS=QLIn un dielettrico isotropo e omogeneo il vettore spostamento elettrico è proporzionale al campo elettrico",elettrostatica re re utilizzando vettore spostamento elettrico formuliamo legge gauss forma locale integrale funzione sole cariche libere d ldnd lin dielettrico isotropo omogeneo vettore spostamento elettrico proporzionale campo elettrico
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#62,62,"Capacità di un condensatore piano con dielettrico63Condensatori con dielettriciΔV=ΔV0εrC=QΔV=εrQΔV0=εrC0C=ε0εrSdSe riempiamo un condensatore con un dielettrico isotropo e omogeneo, il campo elettrico totale vale:
Capacità di un condensatore con dielettricoDi conseguenza, la differenza di potenziale tra le armature⃗E=⃗Dε0εR=σL̂nε01εR=⃗E0εRcampo elettrico con condensatore vuoto",capacit condensatore piano dielettrico condensatori dielettrici vr cq vr vr cr riempiamo condensatore dielettrico isotropo omogeneo campo elettrico totale vale capacit condensatore dielettrico conseguenza differenza potenziale ln re rcampo elettrico condensatore vuoto
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#63,63,64Costanti dielettriche relativematerialecostante dielettrica relativa 𝜀R Aria1.00059Acqua distillataca. 80Etanolo25Petrolio2.1Vetro comune5 ÷ 10Plexiglas3.40Mica8Ebanite2Paraffina2.1Glicerolo42.6Ossido di titanio90 ÷ 170Titanati di Ba-Sr1000 ÷ 10000,costanti dielettriche dielettrica relativa aria acqua distillataca etanolo petrolio vetro comune plexiglas mica ebanite paraffina glicerolo ossido titanio titanati
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#64,64,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
65",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#7,7,"8Carica superficiale di un conduttore La carica in eccesso (dovuto ad elettrizzazione per induzione o per contatto) si  dispone sulla superficie del conduttore Microscopicamente la carica occupa uno spessore di 10-10 m (dimensioni atomiche)Nei conduttori le cariche in eccesso si dispongono in superficie, in una configurazione tale che il campo elettrico interno al conduttore sia nullo
+++++++++++++++++++++++Conduttore elettrizzato
--++++++++++-----------Conduttore polarizzato per induzione elettrostatica100 pm",carica superficiale conduttore carica eccesso dovuto elettrizzazione induzione contatto dispone superficie conduttore carica occupa spessore dimensioni atomichenei conduttori cariche eccesso dispongono superficie configurazione tale campo elettrico interno conduttore nullo elettrizzato conduttore polarizzato induzione
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#8,8,"9Campo elettrico in prossimità della superficie dei conduttoriIn equilibrio elettrostatico le cariche si dispongono in superficieIl campo generato da tali cariche non può avere componenti tangenti alla superficie, altrimenti si osserverebbero movimenti di cariche⃗EEnEt⃗F⃗E=Ên
Il campo elettrico è sempre normale alla superficie dei conduttori",campo elettrico prossimit superficie conduttori equilibrio elettrostatico cariche dispongono superficie campo generato tali cariche pu avere componenti tangenti superficie altrimenti osserverebbero movimenti carichee etfeen campo elettrico sempre normale superficie conduttori
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#9,9,"10Campo elettrico in prossimità della superficie dei conduttoriIl campo elettrico è sempre normale alla superficie dei conduttoriSi dimostra in maniera formale calcolando la circuitazione del campo lungo una linea chiusa 𝛤 che interseca la superficieIl campo è nullo all’interno del conduttoreConservatività del campo elettrostatico⇒∫BA⃗E⋅d⃗l=∫BA⃗E⋅̂utdl=0⟺⃗E=ÊnSABCD0=∮L⃗E⋅d⃗l=∫BA⃗E⋅d⃗lAB+∫CB⃗E⋅d⃗lBC+∫DC⃗E⋅d⃗lCD+∫AD⃗E⋅d⃗lDA∫DC⃗E⋅d⃗lCD=0∫CB⃗E⋅d⃗lBC,∫AD⃗E⋅d⃗lDA⟶BC,AD→00d⃗lAB=̂utdlABSia 𝛤 un rettangolo di vertici ABCD • lati AB e CD sufficientemente piccoli e paralleli a S • lati BC e AD infinitesimi di ordine superiore rispetto a AB e CD
",campo elettrico prossimit superficie conduttori campo elettrico sempre normale superficie conduttori dimostra maniera formale calcolando circuitazione campo lungo linea chiusa interseca superficie campo nullo allinterno conduttore conservativit campo aedlb dledlb aedl abc bedl bcd cedl cda dedl dad cedl cdc bedl bca dedl dab ddl abutdl rettangolo vertici lati piccoli paralleli lati infinitesimi ordine superiore rispetto
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#0,0,1 Correnti elettriche CdS Ingegneria Informatica A.A. 2019/20 ,correnti elettriche ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#1,1,"2Corrente elettricaIn condizione statiche, il campo elettrico all’interno dei conduttori è sempre nullo altrimenti gli elettroni sarebbero accelerati e addio condizione staticaCosa succede se tramite un artificio esterno (generatore) si pone una differenza di potenziale (d.d.p.) tra due punti del conduttore?Gli elettroni di conduzione si mettono in moto ed il conduttore risulta percorso da una corrente elettrica ",corrente elettrica condizione statiche campo elettrico allinterno conduttori sempre nullo altrimenti elettroni accelerati addio condizione statica cosa succede tramite artificio esterno generatore pone differenza potenziale ddp due punti conduttoregli elettroni conduzione mettono moto conduttore risulta percorso corrente elettrica
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#10,10,11EsempioDeterminare numero di elettroni di conduzione e velocità di deriva in un filo di rame di raggio r=0.8mm percorso uniformemente da una corrente i=15A Il rame ha densità di massa 𝛿=8.96 g/cm3 e peso atomico A=6335 g/mol mediamente si avrà nC=1 elettrone di conduzione per atomon=nCδNAA=1×8.96 g cm−3×6.022×1023mol−16355 g mol−1=8.45×1022cm−3j=iS=iπr2=15Aπ×0.82×10−6 m=7.46×106 Am−2elettroni di conduzione per unità di volumedensità di correntevelocità di derivavd=jnqe=7.46×106Am−28.45×1022 cm−3×1.6×10−19As=0.55mmsquantità di carica in moto per unità di volumenqe=8.45×1022cm−3×1.6×10−19C=13.6×103 C/m3≈14 C/mm3,esempio determinare numero elettroni conduzione velocit deriva filo rame raggio rmm percorso uniformemente corrente rame densit massa gcm peso atomico gmol mediamente elettrone conduzione atomonn sir a amelettroni conduzione unit volumedensit am cm carica moto unit cm cmm
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#11,11,"12Conservazione della carica elettrica
Consideriamo una superficie S chiusa e orientata, interna ad un conduttoreil flusso di una corrente di densità j attraverso S è dato da⃗𝚥⃗𝚥̂ncarica che passa attraverso S nell’unità di tempo (corrente uscente) flusso positivo ⇒ carica diminuisce
Principio di conservazione della carica elettrica La carica che attraversa la superficie chiusa S è pari alla variazione di carica complessiva contenuta in SΔq=qout−qinΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=i=qin−qoutΔt=−ΔqΔt→Δt→0−dqdt=iuscente",conservazione carica elettrica consideriamo superficie chiusa orientata interna conduttoreil flusso corrente densit attraverso dato dancarica passa attraverso nellunit tempo corrente uscente flusso positivo carica diminuisce principio conservazione carica elettrica carica attraversa superficie chiusa pari variazione carica complessiva contenuta sqqoutqin ssnd
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#12,12,13Equazione di continuitàLa carica interna alla superficie S può essere scritta in funzione della densità di carica: q=∭τSρdτ𝜏S è il volume delimitato dalla superficie S=−∂∂t∭τSρdτ=∭τS(−∂ρ∂t)dτ∬S⃗𝚥⋅̂ndS=∭τS⃗∇⋅⃗𝚥dτΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=−dqdtteorema della divergenzastesso dominio di integrazione 𝜏S⃗∇⋅⃗𝚥=−∂ρ∂tequazione di continuità ,equazione continuit carica interna superficie pu essere scritta funzione densit carica q sd volume delimitato superficie st sd s sd ssnd sdqdtteorema dominio integrazione continuit
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#13,13,14Equazione di continuità⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza del vettore densità di corrente bilancia la variazione di caricaL’equazione descrive una situazione locale (o differenziale) in ogni punto del volume in cui scorre corrente.  Una variazione di cariche corrisponde ad un moto di cariche non solenoidale  (le cariche non si muovono su linee chiuse),equazione divergenza vettore densit corrente bilancia variazione carica lequazione descrive situazione locale differenziale ogni punto volume scorre corrente variazione cariche corrisponde moto cariche solenoidale cariche muovono linee chiuse
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#14,14,"15Condizioni stazionarie
Si hanno condizioni stazionarie se la carica entrante è pari alla carica uscente⃗𝚥⃗𝚥̂nΔq=qout−qin=0La carica q internamente a S si mantiene costanteΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0⃗∇⋅⃗𝚥=0Il flusso della densità di corrente è nulloIl campo densità di corrente è solenoidale (linee di campo sempre chiuse)−dqdt=iuscente=0",condizioni stazionarie condizioni stazionarie carica entrante pari carica carica internamente mantiene costante ssnd s flusso densit corrente nullo campo densit corrente solenoidale linee campo sempre
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#15,15,"16Prima legge di OhmConsideriamo un conduttore filiforme ai cui estremi c’è una differenza di potenziale Internamente al filo scorre una corrente proporzionale alla differenza di potenzialeLa costante di proporzionalità tra l’intensità di corrente e la differenza di potenziale è la resistenza elettricaΔV=RiTale relazione (prima legge di Ohm) è una legge empirica, valida a temperature ordinarie costanti La resistenza si misura in Ohm (Ω)    1Ω=1V/1Asimbolo circuitale della resistenza",prima legge ohm consideriamo conduttore filiforme estremi c differenza potenziale internamente filo scorre corrente proporzionale differenza potenziale costante proporzionalit lintensit corrente differenza potenziale resistenza elettrica vri tale relazione prima legge ohm legge empirica valida temperature ordinarie costanti resistenza misura ohm asimbolo circuitale resistenza
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#16,16,"17Seconda legge di OhmLa resistenza di un conduttore omogeneo, filiforme di lunghezza l e sezione S vale R=ρRlSR=ρRlSresistività elettrica dipende dalla natura del materiale si misura in ΩmMaterialeResistività (Ωm)Argento1,62 × 10−8Rame1,68 x 10−8Oro2,35 × 10−8Alluminio2,75 × 10−8Tungsteno5,25 × 10−8Ferro9,68 × 10−8Platino10,6 × 10−8Acqua di mare2.00 × 10−1Acqua potabiletra 2.00×101 e 2.00×103Silicio puro (non drogato)2,5 × 103Vetrotra 1010   e 1014Ariatra 1.30×1016 e 3.30×1016Quarzo fusocirca 1016",seconda legge ohm resistenza conduttore omogeneo filiforme lunghezza sezione vale sr sresistivit elettrica dipende natura materiale misura materiale resistivit margento rame oro alluminio tungsteno ferro platino acqua mare acqua potabiletra silicio puro non drogato vetrotra ariatra quarzo fusocirca
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#17,17,"18Leggi di Ohm in forma locale
dSdl⃗𝚥Nell’interno di un conduttore, consideriamo un sottile cilindro di base dS e lunghezza dl percorso da una corrente di densità ⃗𝚥VAVBsia dV=VA-VB la differenza di potenziale ai capi del cilindro (VA>VB)dV=Rdi=ρRdldSdiper le due leggi di Ohmdi=jdSdV=Edl⃗𝚥=σC⃗E⃗E=ρR⃗𝚥E=ρRjσC=1ρRConduttività  (o conducibilità) elettricail vettore densità di corrente ha stessa direzione e verso del campo elettrico",leggi ohm forma locale sdl nellinterno conduttore consideriamo sottile cilindro base lunghezza percorso corrente densit vbsia differenza potenziale capi cilindro vrdi rdld sdiper due leggi ohmdijd vedl cee r rj rconduttivit conducibilit elettricail vettore densit corrente stessa direzione verso campo elettrico
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#18,18,"19Resistenze in serieVA
VBVMDue (o più) resistenze in serie sono attraversate dalla stessa corrente i (per equazione di continuità)R1R2i{VA−VM=R1iVM−VB=R2i(VA−VM)+(VM−VB)=VA−VB=(R1+R2)isomma membro a membroRTOT=∑iRiRTOT=R1+R2
la resistenza del sistema formato da due (o più) resistenze collegate in serie è uguale alla somma delle singole resistenzeApplicando la legge di Ohm (caduta ohmica) ai capi di ciascuna resistenza",resistenze serie mdue pi resistenze serie attraversate stessa corrente per equazione continuitr riv av mri vmv briv av mv av brrisomma membro membro oti otrr resistenza sistema formato due pi resistenze collegate serie uguale somma singole resistenze applicando legge ohm caduta ohmica capi ciascuna resistenza
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#19,19,"20Resistenze in parallelo
VBVAR1R2i1i2Due (o più) resistenze in parallelo hanno la stessa differenza di potenziale VA-VBi1=VA−VBR1i2=VA−VBR2i=(VA−VB)(1R1+1R2)=VA−VBRTOTi=i1+i2=VA−VBR1+VA−VBR2=
L’inverso della resistenza del sistema formato da due o più resistenze collegate in parallelo è uguale alla somma degli inversi delle singole resistenze Applicando la legge di Ohm ai capi di ciascuna resistenza1RTOT=1R1+1R21RTOT=∑i1Ri",resistenze parallelo rii due pi resistenze parallelo stessa differenza potenziale biv av briv av briv av av tiiiv av brv av linverso resistenza sistema formato due resistenze collegate parallelo uguale somma inversi singole resistenze applicando legge ohm capi ciascuna resistenza oti
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#2,2,"3Modello di Drude-LorentzSe la d.d.p. è costante nel tempo, lo sarà anche il campo elettrico e la forza sugli elettroniCi si aspetta che il moto sia uniformemente accelerato (forza e accelerazioni costanti)Sperimentalmente, però, si trova che la velocità media degli elettroni è proporzionale al campo⟨⃗ve⟩∝⃗E⟨⃗ae⟩∝⃗EModello di Drude-Lorentz  gli elettroni si comportano come cariche libere di un gas nel reticolo cristallino, soggette al campo elettrico ed interagenti con le cariche del reticolo 
_
_
+
+
+
+
+
+
+
+
+
+
+
+⃗E=−⃗∇V",modello drude lorentz ddp costante tempo campo elettrico forza elettroni aspetta moto uniformemente accelerato forza accelerazioni per trova velocit media elettroni proporzionale modello drude lorentz elettroni comportano cariche libere gas reticolo cristallino soggette campo elettrico interagenti cariche reticolo ev
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#20,20,"Esempio
21
Esempio
22metallica quadrata di spessored/2 e latoL/2. Determinare il lavoro fatto per introdurre interamente lalastra all’interno del condensatore. (R:L=",esempio esempio metallica quadrata spessored lato determinare lavoro fatto introdurre interamente lalastra allinterno condensatore
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#21,21,"22Effetto JouleQuando una corrente i scorre attraverso un conduttore filiforme, la carica che attraversa una sezione S in un tempo dt è: dq=i dt Il lavoro compiuto dal campo elettrico nello spostamento della carica nell’intervallo dt èδℒ=dU=ΔVdq=ΔVidt=(Ri)idt=Ri2dtLa potenza (energia per unità di tempo) spesa dal campo elettrico per sostare la carica èP=dUdt=Ri2La potenza viene persa negli urti degli elettroni di conduzione con gli atomi del conduttore, i  quali aumentano la propria energia vibrazionale (la potenza viene dissipata in calore)
Effetto Joule aumento della temperatura del conduttore attraversato da correnteP=iΔV=ΔV2R",effetto joule quando corrente scorre attraverso conduttore filiforme carica attraversa sezione tempo dqi lavoro compiuto campo elettrico spostamento carica nellintervallo d vdq potenza energia unit tempo spesa campo elettrico sostare carica udtri potenza viene persa urti elettroni conduzione atomi conduttore quali aumentano propria energia vibrazionale potenza viene dissipata calore effetto joule aumento temperatura conduttore attraversato corrente pi
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#22,22,"23Effetto Joule: interpretazione microscopicaLavoro compiuto dal campo sugli N elettroni contenuti in un volume d𝜏 in un tempo dt=ndτqe⃗E⋅d⃗l=⃗E⋅⃗𝚥dτdtdPdτ=δℒdτdt=⃗E⋅⃗𝚥
Effetto Joule in forma locale Relazione locale che esprime la potenza per unità di volume come prodotto scalare del campo elettrico per la densità di correnten=Ndτδℒ=NqeΔV=ndτqe⃗E⋅⃗vddt=⃗E⋅(nqe⃗vd)dτdt",effetto joule interpretazione microscopica lavoro compiuto campo elettroni contenuti volume tempo effetto joule forma locale relazione locale esprime potenza unit volume prodotto scalare campo elettrico densit
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#23,23,"24Superconduttori
La resistività è funzione lineare della temperaturaρR=ρ0(1+αT)Alcuni metalli (Hg, Al, Pb, Ti, Zn, …) o altre leghe al di sotto di una temperatura critica Tc prossima allo zero assoluto (0°K=-273.15 °C) mostrano una resistività nullaIn tali condizioni di superconduttività, le correnti circolano senza dissipazione di energia e i superconduttori non si riscaldano, anche con correnti molto intense𝜌0,𝛼 costanti T temperatura in °K ",superconduttori resistivit funzione lineare temperatura r talcuni metalli altre leghe sotto temperatura critica prossima zero assoluto mostrano resistivit nulla tali condizioni correnti circolano senza dissipazione energia superconduttori riscaldano correnti molto intense costanti temperatura
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#24,24,"25Generatori di forza elettromotriceSi è  detto che per avere una corrente in un conduttore è necessario stabilire una differenza di potenziale in due punti del conduttore  Per loro natura i conduttori sono equipotenziali. Per forzare una d.d.p occorre connettere il conduttore ad un generatore di forza elettromotrice (o generatore elettrico)Consideriamo un semplice circuito formato da un generatore (pila o batteria) e da una resistenzaIn tale circuito la circuitazione del campo elettrico è diversa da zero (altrimenti non avremmo corrente)
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG∮⃗E⋅d⃗l=∮ρR⃗𝚥⋅d⃗l≠0",generatori forza elettromotrice detto avere corrente conduttore necessario stabilire differenza potenziale due punti conduttore natura conduttori equipotenziali forzare ddp occorre connettere conduttore generatore forza elettromotrice generatore semplice circuito formato generatore pila batteria resistenza tale circuito circuitazione campo elettrico diversa zero altrimenti corrente generatori elettrici segue generatore debbono essere forze natura elettrica quali conservative determinano moto cariche pile batterie avvengono reazioni chimiche ossidoriduzione quali energeticamente favorito movimento cariche campo elettrico dinamo alternatori presente campo magnetico muove cariche elettriche direzione opposta campo elettrico generatore van der graaf unazione meccanica esterna trasporta cariche elettriche direzione opposta campo elettrico domenico galli fisica generale corrente vgedl rdl
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#25,25,"26Generatori di forza elettromotriceNel circuito il campo avrà due componenti
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG⃗E=⃗Es+⃗Em⃗Es⃗E=⃗Es+⃗EmAll’interno del generatore si deve aggiungere il campo elettromotore        (NON conservativo)⃗EmLe forze interna ai generatori sono non conservative (di natura chimica o altro). Il loro effetto è quello di trasportare e mantenere le cariche interne ad una differenza di potenziale 𝛥V=V2-V1Nei conduttori si avrà solo campo elettrostatico⃗Es",generatori forza elettromotrice circuito campo due componenti generatori elettrici segue generatore debbono essere forze natura elettrica quali conservative determinano moto cariche pile batterie avvengono reazioni chimiche ossidoriduzione quali energeticamente favorito movimento cariche campo elettrico dinamo alternatori presente campo magnetico muove cariche elettriche direzione opposta campo elettrico generatore van der graaf unazione meccanica esterna trasporta cariche elettriche direzione opposta campo elettrico domenico galli fisica generale corrente allinterno generatore deve aggiungere campo elettromotore forze interna generatori conservative natura chimica altro effetto trasportare mantenere cariche interne differenza potenziale conduttori solo campo
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#26,26,"27Generatori di forza elettromotrice∮⃗E⋅d⃗l=∮(⃗Es+⃗Em)⋅d⃗l=∮⃗Es⋅d⃗l+∮⃗Em⋅d⃗lV2V1⃗Es⃗Em⃗EsIl campo elettromotore è definito solo internamente al generatore, non è conservativo e la sua circuitazione è definita forza elettromotrice =ℰ
ℰ=∫21⃗Em⋅d⃗l=−∫21⃗ES⋅d⃗l=V2−V1=ΔVIn condizioni stazionarie (generatore non connesso al circuito) le cariche sono ferme, pertanto ∮(⃗Es+⃗Em)⋅d⃗l=0La forza elettromotrice è uguale alla differenza di potenziale (Tensione del generatore)",generatori forza vesemes campo elettromotore definito solo internamente generatore conservativo circuitazione definita forza elettromotrice sdlvv vin condizioni stazionarie generatore connesso circuito cariche ferme pertanto forza elettromotrice uguale differenza potenziale tensione generatore
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#27,27,"28Generatori di forza elettromotriceGeneratori ideali  • la tensione ai capi del generatore si mantiene costanteGeneratori reali  • la tensione ai capi del generatore presenta una caduta ohmica • occorre considerare la resistenza interna del generatore (in serie al circuito)+_
+_simbolo circuitale generatore idealesimbolo circuitale generatore reale",generatori forza elettromotrice generatori ideali tensione capi generatore mantiene costante generatori reali tensione capi generatore presenta caduta ohmica occorre considerare resistenza interna generatore serie circuito simbolo circuitale generatore idealesimbolo circuitale generatore reale
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#28,28,"Prima legge di Kirchhoff (dei nodi)
29+i1
S1
+i2-i3-i4-i5S
S2S5S4S3In condizioni stazionarie (fissato un intervallo 𝛥t, la carica entrante deve bilanciare la carica uscente) ΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0=∑entrantiik−∑uscentiik∬Sk⃗𝚥k⋅̂nkdSk={+ikentrantenelnodo−ikuscentedalnodo∬S⃗𝚥⋅̂ndS=∑k∬Sk⃗𝚥k⋅̂nkdSkConsideriamo N fili che si congiungono in un nodo Siano Si le superfici di intersezione tra S e le sezioni dei fili 
Prima legge di Kirchhoff (dei nodi) In qualunque nodo di un circuito la corrente totale entrante è uguale alla corrente uguale uscente∑nodoik==∑entrantiik−∑uscentiik=0i1+i2−i3−i4−i5=0i1+i2=i3+i4+i5",prima legge kirchhoff dei nodi condizioni stazionarie fissato intervallo carica entrante deve bilanciare carica uscente ssnd skskknkd consideriamo fili congiungono nodo superfici intersezione sezioni fili prima legge kirchhoff dei nodi qualunque nodo circuito corrente totale entrante uguale corrente uguale
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#29,29,"Legge di Ohm generalizzata
30Prendiamo in considerazione un circuito aperto (ramo)iA+_+_BCDRR1R2𝓔1𝓔2Fissiamo arbitrariamente un verso di percorrenza della corrente ( es. da A verso D)In condizioni stazionare la corrente entrante in A è pari a quella uscente da DCiascun elemento del circuito è percorso dalla stessa corrente i (tutti gli elementi sono in serie)",legge ohm generalizzata prendiamo considerazione circuito aperto ramoi r fissiamo arbitrariamente verso percorrenza corrente verso din condizioni stazionare corrente entrante pari uscente ciascun elemento circuito percorso stessa corrente tutti elementi serie
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#3,3,"4
_
_
+
+
+
+
+
+
+
+
+
+
+
+Gli elettroni subiscono urti, cedendo energia cineticaModello di Drude-Lorentz
⃗ae=qeme⃗EII principio dinamicaNell’intervallo di tempo tra due urti consecutivi l’elettrone si muove di moto uniformemente accelerato:Nell’urto sulle cariche positive, l’elettrone cede energia • l’elettrone rallenta • gli atomi del reticolo aumentano la loro energia vibrazionale (gli atomi del reticolo vibrano sempre a T>0° K)",gli elettroni subiscono urti cedendo energia cinetica modello drude lorentz aeqemee principio dinamica nellintervallo tempo due urti consecutivi lelettrone muove moto uniformemente cariche positive lelettrone cede energia lelettrone rallenta atomi reticolo aumentano energia vibrazionale gli atomi reticolo vibrano sempre
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#30,30,"Legge di Ohm generalizzata
31A+_+_BCDRR1R2𝓔1𝓔2Applichiamo la prima legge di Ohm ai capi dei vari elementiVA-VB=Ri              Caduta di potenziale ai capi di RVB-VC=R1i-𝓔1       Caduta di potenziale ai capi di R1, il generatore 𝓔1 fa salire il potenzialeVC-VD=R2i+𝓔2     Caduta di potenziale ai capi di R2, il generatore 𝓔2 fa scendere il potenzialeVA-VD=Ri+R1i+R2i+𝓔2-𝓔1 =(R+R1+R2)i+𝓔2-𝓔1  Differenza di potenziale ai capi dell’intero ramo   ",legge ohm generalizzata r applichiamo prima legge ohm capi vari elementi bri caduta potenziale capi cri caduta potenziale capi generatore salire potenziale dri caduta potenziale capi generatore scendere potenziale dririri rrri differenza potenziale capi dellintero ramo
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#31,31,"Legge di Ohm generalizzata
32A+_+_BCDRR1R2𝓔1𝓔2+_VA-VD+(𝓔1-𝓔2)=RTOT i “Fissato”  il verso della corrente, stabiliamo anche il verso in cui diminuisce il potenziale (le cariche positive della corrente fluisco dal potenziale maggiore a quello minore)Convenzione dei generatori in un circuito (segno della tensione) + se la corrente “entra” nel polo negativo ed “esce” dal polo positivo -  se la corrente “entra” nel polo positivo ed “esce” dal polo negativo +_+_",legge ohm generalizzata r fissato verso corrente stabiliamo verso diminuisce potenziale cariche positive corrente fluisco potenziale maggiore generatori circuito segno tensione corrente entra polo negativo esce polo positivo corrente entra polo positivo esce polo negativo
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#32,32,"Legge di Ohm generalizzata
33",legge ohm generalizzata
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#33,33,"Seconda legge di Kirchhoff (delle maglie)
34A+_+_BCDRR1R2𝓔1𝓔2RConsideriamo un ramo chiuso (maglia)Connettendo i due capi, la differenza di potenziale si annulla: 𝛥V=0La legge di Ohm viene riformulata:XkEk=RTOTi
Seconda legge di Kirchhoff (o delle maglie) Su qualunque maglia di un circuito la caduta di potenziale è uguale  alla somma delle tensioni erogate dai generatori",seconda legge kirchhoff delle maglie r rconsideriamo ramo chiuso due capi differenza potenziale annulla legge ohm viene riformulataxk ekr seconda legge kirchhoff maglie qualunque maglia circuito caduta potenziale uguale somma tensioni erogate generatori
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#34,34,"Circuiti ideali e reali
35+_Circuiti elettrici costituiti da fili conduttori, resistenze, generatori e altri elementi collegati tra loroIn un circuito ideale, gli elementi hanno resistenza interna nulla (escluso resistenza)filo conduttoreresistenzacondensatoregeneratore+_In un circuito reale, gli elementi sono schematizzati introducendo elementi resistivi",circuiti ideali reali circuiti elettrici costituiti fili conduttori resistenze generatori altri elementi collegati circuito ideale elementi resistenza interna nulla escluso resistenzafilo circuito reale elementi schematizzati introducendo elementi resistivi
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#35,35,"Circuiti RC in regime transitorio
36+_T𝓔CRConsideriamo il circuito (ideale) formato da una resistenza, un condensatore a da un generatore di forza elettromotriceInizialmente l’interruttore T è aperto, il condensatore è scaricoAd un dato istante iniziale t=0 l’interruttore viene chiuso. Cosa succede nel circuito? Circola corrente? Potenziale ai capi di resistenza e condensatore? Carica sul condensatore?",circuiti regime transitorio consideriamo circuito ideale formato resistenza condensatore generatore forza elettromotrice inizialmente linterruttore aperto condensatore scarico dato istante iniziale linterruttore viene chiuso cosa succede circuito circola corrente potenziale capi resistenza condensatore carica condensatore
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#36,36,"Circuiti RC in regime transitorio
37𝛥VC𝛥VR+_T𝓔CRLe differenze di potenziale ai capi di R e C varieranno al passare del tempo:ΔVR(t)=Ri(t)ΔVC(t)=Q(t)Ci(t) corrente che circola nel circuitoQ(t) carica sul condensatore all’istante t=0 il condensatore è scarico Q(0)=0Applicando la legge delle maglie: ℰ=ΔVR(t)+ΔVC(t)ℰ=Ri(t)+Q(t)C",circuiti regime transitorio vc differenze potenziale capi varieranno passare tempo vrtrit vctqtcit corrente circola circuito carica condensatore allistante condensatore scarico applicando legge maglie vrt
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#37,37,"Circuiti RC in regime transitorio
38𝛥VC𝛥VR+_T𝓔CRℰ=Ri(t)+Q(t)CLa carica Q(t) che dal generatore fluisce verso il condensatore è legata alla corrente che circola nel circuito dalla relazionei(t)=dQ(t)dtQ(t)=∫t0i(t′",circuiti regime transitorio vc crritqtc carica generatore fluisce verso condensatore legata corrente circola circuito relazioneitd qtdt qttit
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#38,38,390=Rdidt+1CdQdt=Rdidt+iCCircuiti RC in regime transitorio𝛥VC𝛥VR+_T𝓔CRdidt=−iRCRisolviamo per separazione delle variabiliEquazione omogenea in i(t)dii=−dtRC∫i(t)i(0)di′,rdidt qdtrdidti ccircuiti regime transitorio vc crdidti risolviamo separazione variabili equazione omogenea itdiidt rcitidi
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#39,39,"Carica di un condensatore
40i(t)=ℰRe−tRC𝛥VC𝛥VR+_T𝓔CRCorrente che circola nel circuito in funzione del tempo=ℰR[−RCexp(−t′",carica condensatore it ret rc vc corrente circola circuito funzione tempo rr cexpt
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#4,4,"5Modello di Drude-LorentzSupponiamo che l’elettrone abbia un urto all’istante t. Sia  p(t)dt la probabilità di avere un urto in un intervallo [t, t+dt]. ⟨t⟩=∫∞0tp(t)dtIl tempo medio che intercorre tra due urti:nel tempo tra due urti consecutivi, la velocità aumenterà linearmente con l’accelerazione⃗ve=qeme⃗Etla velocità media di un elettrone sara:⟨⃗ve⟩=∫∞0⃗ve(t)p(t)dt=∫∞0qeme⃗Etp(t)dt=qeme⃗E⟨t⟩",modello drude lorentz supponiamo lelettrone urto allistante ptdt probabilit avere urto intervallo tdt ttptdt tempo medio intercorre due urtinel tempo due urti consecutivi velocit aumenter linearmente velocit media elettrone
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#40,40,"41Carica di un condensatore
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰRi(t)=ℰRe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ΔVR(t)=ℰe−tRCΔVR(t)=ℰe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰΔVC(t)=ℰ(1−e−tRC)
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0Q(t)=ℰC(1−e−tRC)ℰC",carica condensatore transitori circuito chiusura circuito ritfv rttfv domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito supponiamo ora che inizialmente deviatore trovi posizione condensatore completamente carico supponiamo poi certo istante deviatore venga commutato posizione avremo lequazione integrale derivando ottiene lequazione differenziale rtv ctrit rdidtt galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito risolvendo allistante iniziale dii rciiet itf ret rcdomenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito si ottiene inoltre citdttv retr cdttff rcr cetr cffetr cqtcv ctcfetr rtfetr ctfetr cqtcfetr rttv ctt galli fisica generale circuiti corrente continuar rvc bt rit ret transitori circuito chiusura circuito ritfv rttfv domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito supponiamo ora che inizialmente deviatore trovi posizione condensatore completamente carico supponiamo poi certo istante deviatore venga commutato posizione avremo lequazione integrale derivando ottiene lequazione differenziale rtv ctrit rdidtt galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito risolvendo allistante iniziale dii rciiet itf ret rcdomenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito si ottiene inoltre citdttv retr cdttff rcr cetr cffetr cqtcv ctcfetr rtfetr ctfetr cqtcfetr rttv ctt galli fisica generale circuiti corrente continuar rvc bt vrtet rc vrtet transitori circuito chiusura circuito ritfv rttfv domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito supponiamo ora che inizialmente deviatore trovi posizione condensatore completamente carico supponiamo poi certo istante deviatore venga commutato posizione avremo lequazione integrale derivando ottiene lequazione differenziale rtv ctrit rdidtt galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito risolvendo allistante iniziale dii rciiet itf ret rcdomenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito si ottiene inoltre citdttv retr cdttff rcr cetr cffetr cqtcv ctcfetr rtfetr ctfetr cqtcfetr rttv ctt galli fisica generale circuiti corrente continuar rvc bt vctet transitori circuito chiusura circuito ritfv rttfv domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito supponiamo ora che inizialmente deviatore trovi posizione condensatore completamente carico supponiamo poi certo istante deviatore venga commutato posizione avremo lequazione integrale derivando ottiene lequazione differenziale rtv ctrit rdidtt galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito risolvendo allistante iniziale dii rciiet itf ret rcdomenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito si ottiene inoltre citdttv retr cdttff rcr cetr cffetr cqtcv ctcfetr rtfetr ctfetr cqtcfetr rttv ctt galli fisica generale circuiti corrente continuar rvc qt cet rc
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#41,41,"42Scarica di un condensatoreTCRSia dato un circuito formato da un condensatore e una resistenza Q(0)=Q0Inizialmente l’interruttore T è aperto, il condensatore è carico con Q(0)=Q0Calcoliamo quanto vale l’energia dissipata sulla resistenza i(t)=dQ(t)dtL’equazione della maglia alla chiusura dell’interruttore èΔVR(t)+ΔVC(t)=0Ri(t)+Q(t)C=0RdQdt+QC=0",scarica condensatore rsia dato circuito formato condensatore resistenza inizialmente linterruttore aperto condensatore carico calcoliamo vale lenergia dissipata resistenza itd qtdt lequazione maglia chiusura vrt vct ritqtc qdtq
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#42,42,43Scarica di un condensatoreTCRQ(0)=Q0RdQdt+QC=0dQdt=−QRCdQQ=−dtRCPer separazione delle variabiliEq differenziale omogeneaQ(t)=Q0e−tRCCarica sul condensatorei(t)=−Q0RCe−tRC=−VcRe−tRCCorrente che circola nel circuitolnQ(t)Q(0)=−tRC,scarica condensatore rqq qdtq qdtq rcd qqdt separazione variabili differenziale omogenea qtqet carica rcet rcvc ret corrente circola circuitoln qtqt
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#43,43,"44Scarica di un condensatore
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
i(t)=−VcRe−tRC
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
Q0Q(t)=Q0e−tRC
−Q0RC=−VcR",scarica condensatore transitori circuito apertura circuito si noti carica condensatore diminuisce tempo tendendo valore limite commutando deviatore ottiene perci scarica condensatore domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito ritfr vttf cvt domenico galli fisica generale circuiti corrente continuar rvc domenico galli dipartimento fisica didattica itvc ret transitori circuito apertura circuito si noti carica condensatore diminuisce tempo tendendo valore limite commutando deviatore ottiene perci scarica condensatore domenico galli fisica generale circuiti corrente continuar rvc transitori circuito apertura circuito ritfr vttf cvt domenico galli fisica generale circuiti corrente continuar rvc domenico galli dipartimento fisica didattica qtqet rcvc
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#44,44,45Scarica di un condensatoreTCRQ(0)=Q0UR=∫∞0PRdt=∫∞0Ri2dt=∫∞0R[−VCRe−tRC]2dtL’energia dissipata è pari all’integrale della potenza nel tempo=12CV2C[−e−∞RC+e−0RC]=V2CR∫∞0e−2tRCdt=V2CR[−RC2e−2tRC]∞0UR=12CV2C=UCL’energia che era inizialmente accumulata nel condensatore viene interamente dissipata sulla resistenza,scarica condensatore rqq ur prdt ridt rv cret rcdt lenergia dissipata pari allintegrale potenza tempo cer ce rcv cret rcdtv crr cet rc clenergia inizialmente accumulata condensatore viene interamente dissipata resistenza
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#45,45,"DRAM 
46
Il condensatore può essere utilizzato come cella di memoria in alternativa al flip-flop Cella di memoria formata da condensatore + transistor Lo stato di carica del condensatore determina lo stato logico Il transistor è usato per pilotare la lettura/scrittura (funziona come un interruttore) Ad ogni lettura/scrittura, tutti i C di un array vengono ri-caricati/scaricatiLinea indirizziLinea dati",condensatore pu essere utilizzato cella memoria alternativa flip flop cella memoria formata condensatore transistor stato carica condensatore determina stato logico transistor usato pilotare funziona interruttore ogni array vengono linea indirizzi linea dati
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#46,46,"DRAM 
47
PRO economicità, alta densità, velocità di accesso ~10 ns (un po’ più lente delle SRAM)
CONS carica sui C diminuisce nel tempo (effetti dissipativi) necessario un circuito di “refresh” che faccia delle letture/scritture “fittizie” (con frequenza del kHz)  Problemi in ambienti ad elevata radiazione (centrali nucleari, detector, spazio): particelle cariche da raggi cosmici o da decadimenti radioattivi possono alterare gli stati  logici",economicit alta densit velocit accesso po lente carica diminuisce tempo effetti dissipativi necessario circuito refresh fittizie con frequenza problemi ambienti elevata radiazione centrali nucleari detector spazio particelle cariche raggi cosmici decadimenti radioattivi possono alterare stati logici
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#47,47,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
48",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#5,5,"6Modello di Drude-LorentzVelocità media o velocità di deriva proporzionale al campo: stessa direzione e verso opposto gli elettroni possiedono anche una velocità dovuta all’agitazione termica, ma si può dimostrare che essa ha valore medio nullo (perché casuale in ogni direzione) Valori tipici: velocità di termica a temperatura ambiente ~100 km/s velocità di deriva: qualche mm/s⃗vd=⟨⃗ve⟩=qeme⃗E⟨t⟩",modello drude lorentz velocit media velocit deriva proporzionale campo stessa direzione verso opposto elettroni possiedono velocit dovuta allagitazione termica pu dimostrare essa valore medio nullo perch casuale ogni direzione valori tipici velocit termica temperatura ambiente kms velocit deriva qualche
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#6,6,"7Intensità di correnteConsideriamo un conduttore all’interno del quale è mantenuta una differenza di potenziale VA-VB
Nel S.I. l’unità di misura della corrente è l’Ampere (A) (grandezza fisica fondamentale) 
SdqVAVBi=limΔt→0ΔqΔt=dqdtData una sezione S, interna al conduttore, definiamo la corrente elettrica come la quantità di carica che attraversa il conduttore per unità di tempo",intensit corrente consideriamo conduttore allinterno mantenuta differenza potenziale lunit misura corrente lampere grandezza fisica fondamentale sdq data sezione interna conduttore definiamo corrente elettrica quantit carica attraversa conduttore unit tempo
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#7,7,"8Intensità di correntei=dqdtLa carica che attraversa la superficie S è al netto delle cariche positive e negative Dal punto di vista sperimentale, in elettromagnetismo, il moto di una carica positiva è equivalente al moto di una carica negativa che procede in verso opposto
Sdq=dq++dq-VAVBConvenzione: verso positivo delle correnti quello in cui si muovono i portatori di carica positivi  la corrente ha verso opposto alla velocità di deriva degli elettroni",intensit correnteidqdt carica attraversa superficie netto cariche positive negative punto vista sperimentale moto carica positiva equivalente moto carica negativa procede verso opposto sdqdqdq bconvenzione verso positivo correnti muovono portatori carica positivi corrente verso opposto velocit deriva elettroni
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#8,8,"9Intensità di corrente
̂nα
dSdS´VAVB⟨⃗v+⟩Consideriamo un tubo (di flusso) cilindrico di sezione infinitesimafissiamo il verso della corrente concorde alla velocità di derivain un intervallo dt, avremo una quantità di carica dq (positiva) che attraversa il volume d𝜏 delimitato dalle superfici orientate S e S´  n=Ndτnumero di portatori di carica N per unità di volumecarica elementare (positiva)d𝜏dq=Ne+=nq+edτdτ=[(⃗vd⋅̂n)dt]dS(⃗vd⋅̂n)dtaltezza del cilindretto obliquo",intensit corrente n sv tubo flusso cilindrico sezione verso corrente concorde velocit derivain intervallo quantit carica positiva attraversa volume delimitato superfici orientate nndnumero portatori carica unit volumecarica elementare cilindretto obliquo
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#9,9,"10Densità di correnteDefiniamo il vettore densità di corrente elettricai=dqdt=∬S⃗𝚥⋅̂ndSRiscriviamo la carica che attraversa il volume d𝜏
̂nα
dSdS´VAVB⃗𝚥d𝜏
Corrente (infinitesima) che attraversa una superficie dSL’intensità di corrente è pari al flusso della densità di corrente attraverso la sezione del conduttore
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
⃗𝚥di=(dqdt)dS=⃗𝚥⋅̂ndSdq=nqe[(⃗vd⋅̂n)dt]dS=[(nqe⃗vd)⋅̂n]dSdt⃗𝚥=nqe⃗vd",densit corrente definiamo vettore densit corrente sriscriviamo carica attraversa volume n sv bd corrente infinitesima attraversa superficie slintensit corrente pari flusso densit corrente attraverso sezione conduttore flusso campo vettoriale la quantit fluido attraversato tempo sezione tubo pari volume cilindro avente stessa base tubo unaltezza pari cio il flusso fluido pertanto domenico galli fisica generale flusso campo vettoriale possiamo esprimere flusso utilizzando sezione obliqua invece sezione trasversale si domenico galli fisica generale snsrv flusso campo vettoriale consideriamo ora caso velocit fluido uniforme sezione tubo caso esempio flusso laminare fluido viscoso velocit centro tubo maggiore velocit prossimit pareti in tal caso scomponiamo tubo tanti tubicini sezione trasversale infinitesima flusso attraverso qualunque sezione tubicino infinitesimo vale il flusso totale ottiene sommando flusso attraverso insieme tubicini coprono completamente sezione tubo domenico galli fisica generale ssdd scosdsd sdvdd svvdvd scosvind svolume fluido attraversa nellunit tempo superficie flusso campo vettoriale la superficie potrebbe essere piana lespressione ugualmente valida superfici infinitesime possono essere considerate piane prodotto scalare tiene conto inclinazione rispetto velocit domenico galli fisica generale fluido attraversa nellunit tempo superficie flusso campo vettoriale la quantit fluido attraversato tempo sezione tubo pari volume cilindro avente stessa base tubo unaltezza pari cio il flusso fluido pertanto domenico galli fisica generale flusso campo vettoriale possiamo esprimere flusso utilizzando sezione obliqua invece sezione trasversale si domenico galli fisica generale snsrv flusso campo vettoriale consideriamo ora caso velocit fluido uniforme sezione tubo caso esempio flusso laminare fluido viscoso velocit centro tubo maggiore velocit prossimit pareti in tal caso scomponiamo tubo tanti tubicini sezione trasversale infinitesima flusso attraverso qualunque sezione tubicino infinitesimo vale il flusso totale ottiene sommando flusso attraverso insieme tubicini coprono completamente sezione tubo domenico galli fisica generale ssdd scosdsd sdvdd svvdvd scosvind svolume fluido attraversa nellunit tempo superficie flusso campo vettoriale la superficie potrebbe essere piana lespressione ugualmente valida superfici infinitesime possono essere considerate piane prodotto scalare tiene conto inclinazione rispetto velocit domenico galli fisica generale fluido attraversa nellunit tempo superficie didqdtd snd sdtnqevd
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#0,0,1 Cmpi magnetici stazionari CdS Ingegneria Informatica A.A. 2019/20 ,cmpi magnetici stazionari ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#1,1,"2Fenomeni magneticiI fenomeni magnetici sono noti dall’antichità  (Talete, Archimede, Cinesi…) Il minerale magnetite (FeO+Fe2O3+FeO4) ha la capacità di attrarre oggetti contenenti ferro o materiali ferrosi
Esistenza forze magnetiche
Limatura di ferro vicino ad una calamita è attratta maggiormente dagli estremi (poli magnetici) in cui sembra si concentri la forza",fenomeni magnetici fenomeni magnetici noti dallantichit talete archimede cinesi minerale magnetite ofe ofe capacit attrarre oggetti contenenti ferro materiali ferrosi esistenza forze magnetiche limatura ferro vicino calamita attratta maggiormente estremi poli magnetici sembra concentri forza
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#10,10,"Rotore e circuitazione del campo magnetico
11
Le linee del campo magnetico sono sempre chiuse  𝛤La circuitazione lungo una generica linea chiusa 𝛤 sarà in generale non nullaAnche il rotore del campo magnetico (thm Stokes) sarà in generale non nullo⃗∇∧⃗B≠0
Il campo magnetico NON è conservativo∮Γ⃗B⋅d⃗l≠0",rotore circuitazione campo magnetico linee campo magnetico sempre chiuse circuitazione lungo generica linea chiusa generale nulla rotore campo magnetico thm stokes generale nullob campo magnetico
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#11,11,"Magneti, cariche elettriche, correnti
12Le forze a cui sono sottoposti gli aghi magnetici corrispondono a quelle dei dipoli elettrici, piuttosto che a quelle delle cariche singoleNon ci sono interazioni tra magneti e cariche elettriche fermeCosa succede se avviciniamo un magnete a delle cariche in movimento ? (filo percorso da corrente)
Consideriamo un esperimento in cui colleghiamo un filo conduttore ad un generatore  di f.e.m. Poniamo un ago magnetico vicino al tratto di filo rettilineo",magneti cariche elettriche correnti forze sottoposti aghi magnetici corrispondono dipoli elettrici piuttosto cariche singole interazioni magneti cariche elettriche ferme cosa succede avviciniamo magnete cariche movimento filo percorso corrente consideriamo esperimento colleghiamo filo conduttore generatore fem poniamo ago magnetico vicino tratto filo rettilineo
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#12,12,"Esperimento di Oersted (1820)
13
A circuito aperto, l’ago non sente nessuna forza e resta fermoChiudendo il circuito, nel filo passa corrente e l’ago si orienta perpendicolarmente al filoInvertendo la polarità del generatore, l’ago ruota in senso opposto",esperimento oersted circuito aperto lago sente nessuna forza resta fermo chiudendo circuito filo passa corrente lago orienta filo invertendo polarit generatore lago ruota senso opposto
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#13,13,"Esperimento di Faraday (1821)
14
Poniamo un filo conduttore in un campo magneticoSe nel conduttore passa corrente, esso sente una forzapossiamo bilanciare (→ misurare) la forza con dei pesi",esperimento faraday poniamo filo conduttore campo magnetico conduttore passa corrente esso sente forzapossiamo bilanciare misurare forza pesi
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#14,14,"Esperimento di Ampère (1820)
15
Esperimento con due fili rettilinei e paralleli percorsi da corrente
I fili si attraggono se le correnti hanno lo stesso versoI fili si respingono se le correnti hanno verso opposto",esperimento ampre esperimento due fili rettilinei paralleli percorsi corrente fili attraggono correnti stesso verso fili respingono correnti verso opposto
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#15,15,"Cariche in movimento e campi magnetici
16Si osservano interazioni di tipo magnetico tra: •magneti •magneti e fili percorsi da corrente  •fili percorsi da correntePossiamo concludere che le correnti generano dei campi magneticiMa le correnti sono cariche in movimento
I campi magnetici sono generati da cariche in movimento sia macroscopicamente (correnti) che microscopicamente (magneti)Domanda: cariche in movimento sono l’unico modo per generare campi magnetici?I movimenti possono essere anche microscopici (elettroni che orbitano attorno ai nuclei, all’interno delle calamite)",cariche movimento campi magnetici osservano interazioni tipo magnetico tra magneti magneti fili percorsi corrente fili percorsi corrente possiamo concludere correnti generano campi magnetici correnti cariche movimento campi magnetici generati cariche movimento correnti cariche movimento lunico modo generare campi magneticii movimenti possono essere microscopici elettroni orbitano attorno nuclei allinterno calamite
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#16,16,"Magnetostatica nel vuoto
17Consideriamo un circuito in corrente stazionaria i e consideriamo un piccolo tratto      che sia  •libero di muoversi su connessioni flessibili e mediante un dinamometro. •elettricamente neutro •orientato con il verso della corrente •immerso in un campo magnetico d⃗ld⃗FIl tratto di filo     subisce una forza     con le seguenti caratteristiche:d⃗l|d⃗F|∝i|d⃗l|d⃗F⊥d⃗ld⃗F=0Quando la corrente (    )  e il campo magnetico sono parallelid⃗l
iRdinamometro a molle𝓔(entrante nel piano)⃗Bd⃗l",magnetostatica vuoto consideriamo circuito corrente stazionaria consideriamo piccolo tratto libero muoversi connessioni flessibili mediante dinamometro elettricamente neutro orientato verso corrente immerso campo magnetico dldf tratto filo subisce forza seguenti quando corrente campo magnetico parallelidl rdinamometro molleentrante pianobdl
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#17,17,"Seconda legge di Laplace
18d⃗F=id⃗l∧⃗BUn tratto di filo percorso da corrente ed immerso in un campo di induzione magnetica subisce una forza descritta da:
Definizione operativa del campo induzione magnetica⃗Bla direzione ed il verso di       sono determinati dalla corrente che circola nel filod⃗l
Regola della mano destra",seconda legge laplace dfidlb tratto filo percorso corrente immerso campo induzione magnetica subisce forza descritta definizione operativa campo induzione magneticabla direzione verso determinati corrente circola filodl regola mano destra
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#18,18,19Seconda legge di Laplaced⃗F=id⃗l∧⃗BCosa succede a livello microscopico nel filo?Una sezione dS del filo sarà attraversata da una densità di corrente di modulo j=i/dSid⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτdi=⃗𝚥⋅̂ndS⃗𝚥 orientato come d⃗lForza magnetica sull’intero volume del filodτ volume infinitesimo⃗F=∫filo⃗𝚥∧⃗BdτForza magnetica su un volume infinitesimod⃗Fτ=⃗𝚥∧⃗Bdτ,seconda legge cosa succede livello microscopico filouna sezione filo attraversata densit corrente modulo jid sidlid sdld s orientato dl forza magnetica sullintero volume filod volume forza magnetica volume
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#19,19,"Forza magnetica su cariche puntiformi
20La densità di corrente era stata definita come:⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di derivaLa forza magnetica per unità di volume diventad⃗Fτ=⃗𝚥∧⃗Bdτ=nq⃗vd∧⃗Bdτ=Nq⃗vd∧⃗B⃗F=q⃗v∧⃗BIn base a questa relazione, possiamo generalizzare al caso di una singola carica puntiforme q che in moto con velocità    , in presenza di un campo di induzione magnetica    , subisce una forza  (forza di Lorentz)  ⃗B⃗v",forza magnetica cariche puntiformi densit corrente stata definita numero portatori carica unit volumevelocit deriva forza magnetica unit volume base relazione possiamo generalizzare caso singola carica puntiforme moto velocit presenza campo induzione magnetica subisce forza forza lorentz bv
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#2,2,"Fenomeni magnetici
3Le calamite esercitano forze tra di loro, che possono essere attrattive o repulsive In analogia con l’elettrostatica, possiamo introdurre la definizione di poli magnetici NORD e SUD La definizione deriva dal fatto che la Terra si comporta come una calamita in una calamita il polo sud si orienta verso il sud geografico e il polo nord con il nord terrestre
S
N",fenomeni magnetici calamite esercitano forze loro possono essere attrattive repulsive analogia possiamo introdurre definizione poli magnetici definizione deriva fatto terra comporta calamita calamita polo sud orienta verso sud geografico polo nord nord terrestre
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#20,20,"Forza di Lorentz
21⃗F=q⃗v∧⃗BMetodo alternativo per definire il campo induzione magnetica (usando una singola carica)Tale relazione è puntuale (vale in ciascun punto dello spazio) ed è più precisa della seconda legge di Laplace (definita su un tratto     )d⃗lDall’espressione della Forza di Lorentz ricaviamo che il campo magnetico ha le dimensioni di una forza su carica e velocità. Nel S.I. il campo magnetico si misura in Tesla (T)  1T=1V 1s/1m2 ",forza lorentz fqvb metodo alternativo definire campo induzione magnetica usando singola caricatale relazione puntuale vale ciascun punto spazio precisa seconda legge laplace definita tratto dl forza lorentz ricaviamo campo magnetico dimensioni forza carica velocit campo magnetico misura tesla
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#21,21,"Forza di Lorentz
22⃗F=q⃗v∧⃗BIn presenza di un campo di induzione magnetica: •Cariche ferme non soggette a forza di Lorentz  •Cariche in movimento soggette a forza di Lorentz 
La forza di Lorentz è sempre perpendicolare al campo induzione magnetica 
La forza di Lorentz è sempre perpendicolare alla velocità  (centripeta)  
La forza di Lorentz non compie lavoro sulla carica in moto (è conservativa???)
direzione della forza data dalla regola della mano destraF=qvBsinαModulo della forza di Lorentz𝛼",forza lorentz fqvb presenza campo induzione magnetica cariche ferme soggette forza lorentz cariche movimento soggette forza lorentz forza lorentz sempre perpendicolare campo induzione magnetica forza lorentz sempre perpendicolare velocit centripeta forza lorentz compie lavoro carica moto direzione forza data regola mano destra fqv bsin modulo forza lorentz
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#22,22,"Forza di Lorentz generalizzata
23⃗F=q⃗E+q⃗v∧⃗BSe sono presenti sia un campo elettrico che un campo magnetico la forza di Lorentz si scrive⃗F=q(⃗E+⃗v∧⃗B)Le cariche elettriche interagiscono con il campo elettrico ed il campo magnetico •Cariche ferme sentono solo gli effetti del campo elettrico •Cariche in moto sentono sia l’effetto del campo elettrico che del campo magneticoCosa succede che se cambiamo Sistema di Riferimento? (esempio, se scegliamo un SdR solidale con la carica in moto?)Le leggi della Fisica devono essere invarianti: non devono dipendere dal SdR.  Importante indizio del fatto che campo elettrico e campo magnetico sono strettamente legati: sono due aspetti della stessa entità fisica: il campo elettromagnetico",forza lorentz generalizzata fqeqvb presenti campo elettrico campo magnetico forza lorentz cariche elettriche interagiscono campo elettrico campo magnetico cariche ferme sentono solo effetti campo elettrico cariche moto sentono leffetto campo elettrico campo magnetico cosa succede cambiamo sistema riferimento esempio scegliamo solidale carica motole leggi fisica devono essere invarianti devono dipendere importante indizio fatto campo elettrico campo magnetico strettamente legati due aspetti stessa entit fisica campo
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#23,23,"Moto di cariche in campi magnetici
24Studiamo il moto di una carica q che si muove con velocità costante, perpendicolare ad un campo magnetico uniformeLa forza di Lorentz è ortogonale a velocità e campo magnetico. Forza e velocità sono complanari. ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗F⃗FPer calcolare il raggio di curvatura R dell’orbita ricordiamo che nella cinematica di un moto curvilineo l’accelerazione è⃗a=dvdt̂ut+v2R̂n⃗vcostanteForza centripeta: moto circolare uniforme⃗v⃗vR",moto cariche campi magnetici studiamo moto carica muove velocit costante perpendicolare campo magnetico uniforme forza lorentz ortogonale velocit campo magnetico forza velocit complanari bff calcolare raggio curvatura dellorbita ricordiamo cinematica moto curvilineo laccelerazione advdtutv rnvcostante forza centripeta moto circolare uniformevv
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#24,24,"Moto di cariche in campi magnetici
25⃗F=m⃗a=mv2R̂n⃗F=q⃗v∧⃗B=qvB̂n̂n=⃗v∧⃗Bvbsinα=1mv2R=qvBForza centripetaForza di Lorentzdirezione e verso della forza di LorentzLa forza di Lorentz è centripetaR=mvqBRaggio di curvatura⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BR⃗F⃗F⃗v⃗v",moto cariche campi magnetici fmamv rnfqvbqv rqv bforza centripeta forza verso forza lorentz forza lorentz centripeta rmvq braggio curvatura rffvv
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#25,25,"Moto di cariche in campi magnetici
26Calcoliamo il periodo di rotazione⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ La velocità angolare (o frequenza angolare)ω=vR=vqBmv=qBm(T=2πω)Il periodo e la frequenza non dipendono né dal raggio né dalla velocità T=2πRv=2πvmvqB=2πmqB⃗F⃗F⃗v⃗v⃗BR",moto cariche campi magnetici calcoliamo periodo rotazione velocit angolare frequenza angolarev rvq bmvq bmtil periodo frequenza dipendono raggio velocit rvvmvq bmq bffvvb
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#26,26,"Circuito in campo magnetico
27Utilizziamo la seconda legge di Laplace per determinare le azioni meccaniche cui è soggetto un circuito percorso da corrente  immerso in un campo magnetico  d⃗F=id⃗l∧⃗BSupponiamo che il circuito sia: •rigido (non cambia forma) •la corrente i sia mantenuta costante da un generatore di f.e.m. (anche se vedremo che B tende a modificare la corrente nel circuito…)La forza totale sul circuitoIl momento (delle forze) totale sul circuito⃗rDistanza tre dl e il polo⃗F=i∮d⃗l∧⃗B⃗M=∮⃗r∧d⃗F=i∮⃗r∧(d⃗l∧⃗B)",circuito campo magnetico utilizziamo seconda legge laplace determinare azioni meccaniche soggetto circuito percorso corrente immerso campo magnetico dfidlb supponiamo circuito sia rigido non cambia forma la corrente mantenuta costante generatore fem anche vedremo tende modificare corrente circuitola forza totale circuito momento delle forze totale circuitor distanza tre
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#27,27,"Spira in un campo magnetico
28Consideriamo il caso semplice di una spira rettangolare di lati a e b immersa in un campo induzione magnetica uniforme (diretto lungo l’asse z).⃗B̂n1ba234𝜃Calcoliamo la forza agente su ogni lato⃗F1=∫1id⃗l∧⃗B=∫1iBdl̂𝚥=ilB̂𝚥i⃗F1l=axy⃗F2=∫2id⃗l∧⃗B=∫2iBdl(−̂ı)=−ilB̂ıl=b⃗F3=∫3id⃗l∧⃗B=∫3iBdl(−̂𝚥)=−ilB̂𝚥=−⃗F1⃗F4l=al=b⃗Ftot=∑⃗Fi=0La forza totale sulla spira è nulla⃗F2⃗F3⃗F4=∫4id⃗l∧⃗B=∫4iBdl̂ı=ilB̂ı=−⃗F2z",spira campo magnetico consideriamo caso semplice spira rettangolare lati immersa campo induzione magnetica uniforme diretto lungo lasse zbnba calcoliamo forza agente ogni bdlil bdlil bdlil forza totale spira bdlil bfz
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#28,28,"Spira in un campo magnetico
29zSe il sistema è visto dall’alto:⃗B̂n1ba234𝜃ixyzTuttavia il momento delle forze sarà non nulloCalcoliamo il momento rispetto al centro della spira⃗r1⃗M1=⃗r1∧⃗F1=0⃗F1⃗r1//⃗F1⃗F4⃗r2⃗B
̂n𝜃ixb/2b/2𝜃𝜃⃗M3=⃗r3∧⃗F3=0⃗r3//⃗F3⃗F2⃗M2=⃗r2∧⃗F2=(b2)(iaB)sinθ(̂𝚥)⃗M4=⃗r4∧⃗F4=(b2)(iaB)sinθ(̂𝚥)⃗r4⃗Mtot=⃗M1+⃗M2=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è diretto verso l’alto (lungo asse di rotazione)",spira campo magnetico sistema visto tuttavia momento forze nullo calcoliamo momento rispetto centro snb momento forze diretto verso lalto lungo asse rotazione
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#29,29,"Momento magnetico di una spira
30⃗M=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è proporzionale alla corrente e al prodotto vettoriale tra superficie della spira orientata e campo induzione magneticaDefiniamo il momento magnetico della spira di area S percorsa da corrente i ⃗m=iŜnS=ab superficie della spiraè il versore normale alla spira orientato in verso tale che esso vede circolare la corrente in verso antiorario (regola della mano destra)̂n
̂n⃗M=⃗m∧⃗BIl momento delle forze è uguale al prodotto vettoriale del momento magnetico della spira per il campo induzione magnetica(si dimostra che la relazione vale per spire di qualsiasi forma                     )d⃗m=îndS",momento magnetico spira snb momento forze proporzionale corrente prodotto vettoriale superficie spira orientata campo induzione magnetica definiamo momento magnetico spira area percorsa corrente mi sn sab superficie spira versore normale spira orientato verso tale esso vede circolare corrente verso antiorario regola mano destran nmmb momento forze uguale prodotto vettoriale momento magnetico spira campo induzione magneticasi dimostra relazione vale spire qualsiasi forma dmind
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#3,3,"Interazioni tra calamite
4
Poli opposti (N-S) si attraggonoPoli stesso segno (N-N o S-S) si respingono",interazioni calamite poli opposti attraggono poli stesso segno respingono
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#30,30,"Teorema di equivalenza di Ampère
31
Una spira percorsa da corrente immersa in un campo magnetico si comporta come un dipolo magnetico elementare (ago magnetico) di momento                , perpendicolare al piano della spira e orientato con la regola della mano destra⃗m=iŜnSulla spira agisce un momento di forze solo se il campo magnetico ed il momento della spira formano un angolo 𝜃≠0 La coppia di forze è nulla quando campo magnetico e momento magnetico sono allineati (𝜃=0)La relazione tra momento delle forze su una spira e campo induzione è analoga al dipolo elettrico immerso in un campo elettrico⃗M=⃗p∧⃗E",teorema equivalenza ampre spira percorsa corrente immersa campo magnetico comporta dipolo magnetico elementare ago magnetico momento perpendicolare piano spira orientato regola mano destrami sn spira agisce momento forze solo campo magnetico momento spira formano angolo coppia forze nulla quando campo magnetico momento magnetico allineati la relazione momento forze spira campo induzione analoga dipolo elettrico immerso campo
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#31,31,"Esempio
32v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.",esempio figure disco isolante raggio spessore trascurabile uniformemente carico carica ruota velocit aangolare allasse passante centro determinarea campo magneticobnel centro discob momento magneticomdel disco spira quadrata lato percorsa correntei senso antiorario posta unaregione spazio presente campo magnetico uniforme avente intensit sapendo duelati spira paralleli campo magnetico calcolarea forza agente spirab momento forzemagente spira consideri circuito rappresentato gura tratto semicircolare circuito immerso uncampo magnetico determinare forza agisce circuito rv rxy figure legge amp ere determinare campo magnetico generato solenoide cilindrico raggio rcomposto danspire perunit lunghezza percorse corrente stazionariai
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#32,32,"Galvanometro
33Il galvanometro è uno strumento utilizzato per misurare piccole intensità di corrente
Il momento delle forze magnetiche sulla spira è bilanciato dal momento delle forze elasticheMolla a spiraleMmolla=−kαk costante elastica 𝛼 angolo di aperturaAll’equilibrio⃗Mmolla=⃗MMi=kαSBSistema fatto in modo che 𝜃≈90° 𝜃≈90° MM=−iSBsinθ≃−iSBMisura della corrente",galvanometro galvanometro strumento utilizzato misurare piccole intensit corrente momento forze magnetiche spira bilanciato momento forze elastiche molla spirale mmollakk costante elastica angolo apertura mik sistema fatto modo mi sbsini misura corrente
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#33,33,"Motore elettrico
34Il motore elettrico trasforma energia elettrica in energia meccanica
La spira percorsa da corrente è messa in rotazione dall’interazione con il campo magneticoPer mantenere la rotazione sempre nello stesso senso si usano delle spazzole in contatto sul commutatore per invertire il verso della corrente nella spira",motore elettrico motore elettrico trasforma energia elettrica energia meccanica spira percorsa corrente messa rotazione campo magnetico mantenere rotazione sempre stesso senso usano spazzole contatto commutatore invertire verso corrente spira
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#34,34,"Altoparlante
35
impulso elettrico modulato dalla frequenza sonoraIl filo è collegato rigidamente al cono di cartoneQuando nel filo passa corrente (variabile nel tempo, modulata sulla frequenza sonora), esso sente la forza magnetica e mette in vibrazione l’altoparlante La vibrazione del cono produce onde sonore (conversione di energia elettrica in energia meccanica delle onde sonore)",altoparlante impulso elettrico modulato frequenza sonora filo collegato rigidamente cono cartone quando filo passa corrente variabile tempo modulata frequenza sonora esso sente forza magnetica mette vibrazione laltoparlante vibrazione cono produce onde sonore conversione energia elettrica energia meccanica onde sonore
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#35,35,"Prima legge di Laplace
36
Evidenze sperimentali mostrano che i fili percorsi da corrente generano campi magneticid⃗B=μ0i4πd⃗l∧̂urr2d⃗B=μ0i4πd⃗l∧⃗rr3Consideriamo un tratto di filo infinitesimo      percorso da corrente i. Sperimentalmente si osserva che il campo magnetico generato a distanza    vale: ⃗rd⃗ld⃗lentrante se     e nel piano del foglio⃗rd⃗lxyz⃗r⃗B⨂iLa costante 𝜇0 è la permeabilità magnetica del vuotoμ0=4π×10−7VsmA=4π×10−7NA2=4π×10−7HmHenry (H)  1H=1𝛺 1s",prima legge laplace evidenze sperimentali mostrano fili percorsi corrente generano campi consideriamo tratto filo infinitesimo percorso corrente osserva campo magnetico generato distanza vale piano costante permeabilit magnetica vuoto vsm a na henry
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#36,36,"Prima legge di Laplace
37d⃗lxyz⃗Bi⨂⃗r−⃗r′",prima legge laplace
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#37,37,"Prima legge di Laplace
38|d⃗B|=μ0i4πdlsinθr2Modulo del campo magnetico:d⃗lxyz⃗r⃗B⨂iθL’angolo 𝜃 è tra la direzione della corrente e la posizione del punto in cui calcoliamo il campo magnetico se sin𝜃=0;180°  ⇒ dB=0: lungo la direzione della corrente non viene generato campo magnetico dB∝1r2come la legge di Coulomb per le cariche puntiformidB∝idipende dall’intensità della corrente, e quindi dal numero di portatori di caricadB⊥d⃗ldB⊥d⃗rperpendicolare al piano definito da corrente e posizione",prima legge laplace modulo campo langolo direzione corrente posizione punto calcoliamo campo magnetico sin lungo direzione corrente viene generato campo magnetico brcome legge coulomb cariche puntiformid bidipende dallintensit corrente quindi numero portatori caricad bdld piano definito corrente posizione
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#38,38,"Legge di Biot-Savart
39Determinare il campo induzione magnetica generato da un filo rettilineo di lunghezza indefinita, percorso da corrente i 
⃗B=μ0i2πr̂utLegge di Biot-Savart• il campo magnetico ha intensità inversamente proporzionale alla distanza dal filo • le linee di campo sono circonferenze nel piano trasverso al filo, centrate sul filo stesso • L’orientazione delle linee di campo segue la regola della mano destra ",legge biot savart determinare campo induzione magnetica generato filo rettilineo lunghezza indefinita percorso corrente birut legge biot savart campo magnetico intensit inversamente proporzionale distanza filo linee campo circonferenze piano trasverso filo centrate filo stesso lorientazione linee campo segue regola mano destra
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#39,39,"Forza tra due fili percorsi da corrente
40
L’esperimento di Ampère evidenzia la forza tra due fili percorsi da correnteConsideriamo due fili rettilinei di lunghezza indefinita, paralleli, posti a distanza d, percorsi da correnti i1 e i2 (iniziamo con il caso di correnti equiverse)di1i2Il filo 1 genera a distanza d un campo magnetico ⃗B1⨂B1=μ0i12πdun tratto di filo dl2 sente una forza magneticad⃗F12=i2d⃗l2∧⃗B1d⃗l2(II Legge Laplace)",forza due fili percorsi corrente lesperimento ampre evidenzia forza due fili percorsi corrente consideriamo due fili rettilinei lunghezza indefinita paralleli posti distanza percorsi correnti iniziamo caso correnti equiversedii filo genera distanza campo magnetico tratto filo sente forza legge laplace
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#4,4,"Campo magnetico
5In analogia con l’elettrostatica, viene naturale introdurre un campo vettoriale      detto  campo magnetico⃗Bconvenzione: le linee di forza del campo magnetico entrano nel polo sud e escono dal polo nord Le linee di campo sono tangenti alla direzione lungo la quale si allineano gli aghi magneticiL’intensità è proporzionale al momento delle forze sull’ago
S
N
S
N
S
N
S
N
S
N
S
NIl campo      può essere anche definito come campo induzione magnetica⃗B",campo magnetico analogia viene naturale introdurre campo vettoriale detto campo linee forza campo magnetico entrano polo sud escono polo nord linee campo tangenti direzione lungo allineano aghi magnetici lintensit proporzionale momento forze sullago campo pu essere definito campo induzione magneticab
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#40,40,"41d⨂d⃗F12=i2d⃗l2∧⃗B1Forza tra due fili percorsi da correntedF12=i2dl2B1sinθ=i2dl2μ0i12πd𝜃=90°Forza sul filo 2:Modulo della forzadF12=μ02πi1i2ddl2i1i2Direzione di dF12: perpendicolare ai fili, diretta da 2 verso 1 Analogamente, sul filo 1dF21=μ02πi1i2ddl1d⃗F21=iid⃗l1∧⃗B2=−d⃗F21La forza dF21 esercitata dal filo 2 sul filo 1 è uguale e opposta (attrattiva)d⃗F12d⃗l2⃗B1",forza due fili percorsi corrented fidl filo modulo forzad direzione perpendicolare fili diretta verso analogamente filo forza esercitata filo filo uguale opposta
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#41,41,"Forza tra due fili percorsi da corrente
42d𝜃=90°i1i2⨂Se le correnti correnti i1 e i2 sono dirette in verso opposto le forze tra i fili saranno anch’esse opposte e repulsivePer il terzo principio della dinamica, le forze tra i due fili interagenti devono sempre essere uguali e opposteSu un tratto di filo L finito, basta integrare su dl|⃗F|=μ02πi1i2dLForza per unità di lunghezzadFdl=μ02πi1i2dd⃗F12d⃗l2⃗B1",forza due fili percorsi corrente diise correnti correnti dirette verso opposto forze fili anchesse opposte repulsive terzo principio dinamica forze due fili interagenti devono sempre essere uguali opposte tratto filo finito basta integrare lforza unit lunghezzad
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#42,42,"Definizione operativa della corrente
43Un ampere è l'intensità di corrente elettrica che, se mantenuta in due conduttori lineari paralleli, di lunghezza infinita e sezione trasversale trascurabile, posti a un metro di distanza l'uno dall'altro nel vuoto, produce tra questi una forza pari a 2 × 10-7 N per ogni metro di lunghezza.Tale definizione fissa anche il valore di 𝜇0 . La definizione operativa della corrente (e quindi della carica elettrica) sono fatte attraverso la misura di una forza  ",definizione operativa corrente ampere lintensit corrente elettrica che mantenuta due conduttori lineari paralleli lunghezza infinita sezione trasversale trascurabile posti metro distanza luno dallaltro vuoto produce forza pari ogni metro lunghezzatale definizione fissa valore definizione operativa corrente quindi carica elettrica fatte attraverso misura forza
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#43,43,"Campi magnetici da cariche puntiformi in moto
44d⃗B=μ0i4πd⃗l∧̂urr2Se esprimiamo la corrente in funzione della densità di corrente:id⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτ⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di deriva=μ04π⃗𝚥∧⃗rr3dτ=Nμ04πq⃗vd∧⃗rr3La prima legge di Laplace può essere riformulataCampo magnetico generato da N portatori di caricaUna singola carica in movimento genera un campo magnetico che a distanza r dalla carica vale⃗B=μ04πq⃗v∧⃗rr3",campi magnetici cariche puntiformi moto esprimiamo corrente funzione densit sdld numero portatori carica unit volumevelocit prima legge laplace pu essere riformulata campo magnetico generato portatori carica singola carica movimento genera campo magnetico distanza carica
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#44,44,"Campi magnetici da cariche puntiformi in moto
45⃗B=μ04πq⃗v∧⃗rr3Tale formula vale in un Sistema di Riferimento in cui q si muove con velocità vIn un SdR in cui la carica è ferma si ha che B=0 !!!Ricordiamo che a distanza r, la carica genera un campo elettrico⃗E=q4πε0⃗rr3Ammettendo che questa relazione sia valida anche per cariche in motoq⃗rr3=4πε0⃗E⃗B=μ04π⃗v∧q⃗rr3=⃗B=μ0ε0⃗v∧⃗E=1c2⃗v∧⃗Ec=1μ0ε0Chiara relazione tra campi elettrico e magnetico generati da una carica in motovelocità della luce nel vuoto…=3×108m/sμ04π⃗v∧⃗E4πε0",campi magnetici cariche puntiformi moto tale formula vale sistema riferimento muove velocit carica ferma ricordiamo distanza carica genera campo ammettendo relazione valida cariche chiara relazione campi elettrico magnetico generati carica motovelocit luce
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#45,45,"Campo da spira circolare
46Determinare il campo induzione magnetica sull’asse di una spira circolare di raggio R percorsa da corrente i 
Bz==μ0i2R2(R2+z2)3/2=μ02πm(R2+z2)3/2⃗m=iŜk=iπR2̂k",campo spira circolare determinare campo induzione magnetica sullasse spira circolare raggio percorsa corrente bzi ski rk
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#46,46,"Esempio
474.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava",esempio spettrometro massa vedi gura fascio ioni viene prima fatto passare attraverso unselettore velocit costituito condensatore piano genera campo nelladirezione immerso campo magnetico xa caricaqviene lanciata direzione yin corrispondenza foro lamina blocca lecariche deve essere velocit ava
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#47,47,"Esempio
484.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava",esempio spettrometro massa vedi gura fascio ioni viene prima fatto passare attraverso unselettore velocit costituito condensatore piano genera campo nelladirezione immerso campo magnetico xa caricaqviene lanciata direzione yin corrispondenza foro lamina blocca lecariche deve essere velocit ava
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#48,48,"Esempio
49v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.",esempio figure disco isolante raggio spessore trascurabile uniformemente carico carica ruota velocit aangolare allasse passante centro determinarea campo magneticobnel centro discob momento magneticomdel disco spira quadrata lato percorsa correntei senso antiorario posta unaregione spazio presente campo magnetico uniforme avente intensit sapendo duelati spira paralleli campo magnetico calcolarea forza agente spirab momento forzemagente spira consideri circuito rappresentato gura tratto semicircolare circuito immerso uncampo magnetico determinare forza agisce circuito rv rxy figure legge amp ere determinare campo magnetico generato solenoide cilindrico raggio rcomposto danspire perunit lunghezza percorse corrente stazionariai
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#49,49,"Flusso del campo magnetico
50Abbiamo già dimostrato che il campo magnetico è solenoidale⃗∇⋅⃗B=0Per il teorema della divergenza, il flusso del campo magnetico attraverso una qualsiasi superficie chiusa sarà nullo: NON esistono cariche magnetiche isolateIl flusso attraverso una superficie aperta avrà un suo valore, non necessariamente nullo, ci torneremo in seguito…∬Saperta⃗B⋅̂ndS∬Schiusa⃗B⋅̂ndS=∭τ(S)⃗∇⋅⃗B=0",flusso campo magnetico gi dimostrato campo magnetico teorema divergenza flusso campo magnetico attraverso qualsiasi superficie chiusa nullo esistono cariche magnetiche isolate flusso attraverso superficie aperta valore necessariamente nullo torneremo sschiusabnd ssb
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#5,5,"6Campo magnetico
La limatura di ferro si orienta con il campo magnetico delle calamite
",campo magnetico limatura ferro orienta campo magnetico calamite
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#50,50,"Circuitazione del campo magnetico
51Dal momento che le linee di forza del campo magnetico sono sempre chiuse, ci aspettiamo che la circuitazione può essere non-nullaSemplificando, calcoliamo la circuitazione del campo magnetico generato da un filo rettilineo indefinito percorso da corrente iCalcoliamo la circuitazione lungo una linea chiusa e orientata 𝛤 che concatena il filo. Su un tratto infinitesimo:îtrd𝜙=μ0i2πrrdϕ̂ut⋅d⃗l=rdϕProiezione su circonferenza (arco di circonferenza) ∮Γ⃗B⋅d⃗l=∫2π0μ0i2πdϕ=±μ0iSegno dipende da corrente (regola mano destra)𝛤d⃗l⃗B⋅d⃗l=μ0i2πr̂ut⋅d⃗l⃗B",circuitazione campo magnetico momento linee forza campo magnetico sempre chiuse aspettiamo circuitazione pu essere nulla semplificando calcoliamo circuitazione campo magnetico generato filo rettilineo indefinito percorso corrente calcoliamo circuitazione lungo linea chiusa orientata concatena filo tratto proiezione circonferenza arco circonferenza segno dipende corrente regola mano
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#51,51,"Circuitazione del campo magnetico
52Se invece la linea chiusa 𝛤  non “concatena” il filo:i𝛤⃗B⋅d⃗l1=μ0i2πr1̂ut⋅d⃗l1=μ0i2πr1r1dϕd⃗l1⃗B⋅d⃗l2=μ0i2πr2̂ut⋅d⃗l2=μ0i2πr2r2(−dϕ)per ogni angolo d𝜙 ci saranno sempre due tratti precorsi in verso oppostole due proiezioni sottendono lo stesso angolo, quindi il contributo alla circuitazione è nullo∮Γ⃗B⋅d⃗l=0d𝜙d⃗l2⃗B⃗B",circuitazione campo magnetico invece linea chiusa concatena ogni angolo sempre due tratti precorsi verso oppostole due proiezioni sottendono stesso angolo quindi contributo circuitazione
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#52,52,"Legge di Ampère
53Il segno delle correnti si valuta usando la regola della mano destra, rispetto al verso di percorrenza della curva orientata 𝛤
La circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate ∮Γ⃗B⋅d⃗l=μ0conc∑kikLegge di Ampère fornisce un metodo per il calcolo del campo magnetico in particolari condizioni di simmetria",legge ampre segno correnti valuta usando regola mano destra rispetto verso percorrenza curva orientata circuitazione campo magnetico proporzionale somma correnti concatenate legge ampre fornisce metodo calcolo campo magnetico particolari condizioni simmetria
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#53,53,"54Circuitazione del campo magneticoPossiamo prendere un numero qualsiasi di correnti concatenate, su circuiti di forma arbitraria
∮Γ1⃗B⋅d⃗l=0∮Γ2⃗B⋅d⃗l=μ0(i1−i2)∮Γ3⃗B⋅d⃗l=μ0(−i1+i2−i3)∮Γ1⃗B⋅d⃗l=μ0i1∮Γ2⃗B⋅d⃗l=μ0(−i2−i3)∮Γ3⃗B⋅d⃗l=0",circuitazione campo magnetico possiamo prendere numero qualsiasi correnti concatenate circuiti forma arbitraria
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#54,54,"Densità di corrente concatenata
55Consideriamo N fili, ciascuno di sezione Sk, percorsi da correnti ikCiascuna corrente può essere scritta in funzione della densità di corrente:ik=∬⃗𝚥k⋅̂nkdSk
i1-i2i3𝛤SS1S2S3La somma delle correnti concatenate alla curva 𝛤 conc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSDove S è una generica superficie orientata che ha per bordo 𝛤 e  jc è la densità di corrente concatenata ",densit corrente concatenata consideriamo fili ciascuno sezione percorsi correnti ciascuna corrente pu essere scritta funzione densit ii somma correnti concatenate curva skscnd sdove generica superficie orientata bordo densit corrente concatenata
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#55,55,"56Il teorema di StokesConsideriamo una superficie S aperta orientata avente come bordo una linea chiusa orientata 𝛤 
𝛤S(𝛤)̂n̂n
Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('𝛤∮Γ⃗F⋅d⃗lDefiniamo la circuitazione del campo lungo la linea chiusa orientata 𝛤 ",teorema stokes consideriamo superficie aperta orientata avente bordo linea chiusa orientata snn superfici aperte nelle superfici aperte pu distinguere normale esterna normale interna punto superficie per convenzione calcolare flussi attraverso superficie chiusa utilizza lorientamento indicato regola mano destra base linea bordo domenico galli fisica generale flusso campo vettoriale attraverso superficie chiusa orientabile consideriamo ora flusso velocit fluido attraverso superficie chiusa per semplicit consideriamo superficie totale cubo consideriamo positivo flusso uscente cubo negativo flusso entrante cubo se fluido incompressibile interno sorgenti produce fluido pozzi scarichi fluido scompare allora tanto fluido entra cubo esce il flusso attraverso superficie totale nullo il cerchietto attorno simbolo integrale indica superficie integrazione chiusa domenico galli fisica generale flusso campo vettoriale attraverso superficie chiusa orientabile se flusso attraverso superficie totale positivo allora dentro cubo presente sorgente produce fluido se flusso attraverso superficie totale negativo allora dentro cubo presente pozzo cio scarico fluido scompare domenico galli fisica generale totvvind loperatore divergenza domenico galli fisica generale funzione vettoriale posizione si definisce loperatore divergenza come loperatore divergenza applica funzione vettoriale risultato scalare definiamo circuitazione campo lungo linea chiusa orientata
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#56,56,57Il teorema di StokesIl flusso del rotore di un campo vettoriale attraverso una superficie S aperta e orientata è uguale alla circuitazione del campo vettoriale lungo il bordo 𝛤 di tale superficie∬S(Γ)(⃗∇∧⃗F)⋅̂ndS=∮Γ⃗F⋅d⃗lIl teorema di Stokes mette in relazione un integrale di superficie con un integrale di linea ,teorema stokes flusso rotore campo vettoriale attraverso superficie aperta orientata uguale circuitazione campo vettoriale lungo bordo tale sfdl teorema stokes mette relazione integrale superficie integrale linea
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#57,57,"Il rotore del campo magnetico
58Riscriviamo la legge di Ampère in funzione della densità di corrente concatenataconc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSS è una generica superficie con bordo 𝛤 Applichiamo il teorema di Stokes:∮Γ⃗B⋅d⃗l=μ0conc∑kik=μ0∬S⃗𝚥C⋅̂ndS∮Γ⃗B⋅d⃗l=∬S⃗∇∧⃗B⋅̂ndS=μ0∬S⃗𝚥C⋅̂ndSL’uguaglianza è vera per qualsiasi superficie S con bordo 𝛤 
Legge di Ampère in forma locale ⃗∇∧⃗B=μ0⃗𝚥In ogni punto dello spazio, il rotore del campo magnetico è proporzionale alla densità di corrente in quel punto",rotore campo magnetico riscriviamo legge ampre funzione densit corrente skscnd generica superficie bordo applichiamo teorema cnd ss cnd sluguaglianza vera qualsiasi superficie bordo legge ampre forma locale b ogni punto spazio rotore campo magnetico proporzionale densit corrente quel punto
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#58,58,"Esempio
59Calcolare il campo di un filo di lunghezza indefinita percorso da corrente i utilizzando la legge di Ampère",esempio calcolare campo filo lunghezza indefinita percorso corrente utilizzando legge ampre
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#59,59,"Esempio
60Determinare in tutto lo spazio il campo magnetico generato da un cilindro conduttore di raggio R e lunghezza indefinita percorso uniformemente da una corrente di intensità i ",esempio determinare spazio campo magnetico generato cilindro conduttore raggio lunghezza indefinita percorso uniformemente corrente intensit
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#6,6,"Campo magnetico terrestre
7
Un ago magnetico libero di ruotare si orienta  con la linea di campo che esce dal polo nord (del magnete) e entra dal polo sud (del magnete)Ciò significa che la Terra si comporta come un magnete le cui linee di campo escono dal polo sud geografico ed entrano nel polo nord geografico.Convenzionalmente il polo nord magnetico coincide con il polo sud geografico",campo magnetico terrestre ago magnetico libero ruotare orienta linea campo esce polo nord del magnete entra polo sud del magneteci significa terra comporta magnete linee campo escono polo sud geografico entrano polo nord polo nord magnetico coincide polo sud geografico
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#60,60,"Esempio
61v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.
⃗B=μonîk=μ0NLîk̂kCampo interno al solenoide (ideale)Esternamente il campo è nullo",esempio figure disco isolante raggio spessore trascurabile uniformemente carico carica ruota velocit aangolare allasse passante centro determinarea campo magneticobnel centro discob momento magneticomdel disco spira quadrata lato percorsa correntei senso antiorario posta unaregione spazio presente campo magnetico uniforme avente intensit sapendo duelati spira paralleli campo magnetico calcolarea forza agente spirab momento forzemagente spira consideri circuito rappresentato gura tratto semicircolare circuito immerso uncampo magnetico determinare forza agisce circuito rv rxy figure legge amp ere determinare campo magnetico generato solenoide cilindrico raggio rcomposto danspire perunit lunghezza percorse corrente stazionariai bonik nlikk campo interno solenoide campo nullo
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#61,61,"Esempio
626.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2",esempio determinare campo magnetico solenoide toroidale raggio maggiore raggio internoa dotatodi nspire percorse correnteib nir cavo coassiale lunghezza indenita formato due conduttori primo cilindrico raggioae cavo raggio internobe raggio esternoc due conduttori percorsi correnti uniformi diugual modulo verso opposto due conduttori vuoto determinare campo induzione magneticain spazio
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#62,62,"Magnetismo nella materia
63Cosa succede se riempiamo la parte interna di un solenoide rettilineo ideale?Si osserverà una variazione del campo magnetico: alluminio, platino, sodio: leggero aumento   → materiali PARAMAGNETICIferro, nichel, cobalto: considerevole aumento → materiali FERROMAGNETICI
materiali organici, rame, argento: leggera diminuzione  → materiali DIAMAGNETICII materiali ferromagnetici restano magnetizzati ",magnetismo materia cosa succede riempiamo parte interna solenoide rettilineo idealesi osserver variazione campo magnetico alluminio platino sodio leggero aumento materiali ciferro nichel cobalto considerevole aumento materiali materiali organici rame argento leggera diminuzione materiali materiali ferromagnetici restano magnetizzati
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#63,63,"64Momento magnetico orbitalePer spiegare il magnetismo nella materia occorre partire dalla struttura microscopicaIn un modello molto semplificato possiamo pensare gli elettroni più esterni in rotazione intorno al nucleoPartiamo dal caso più semplice: l’atomo di idrogenoEssendo la forza coulombiana centripetaricaviamo la velocità di rotazione:14πε0qeqpr2H=mev2rHRH=5.3×10−11m
RH=5.3×10−11mme=9.1×10−31kg|qe|=|qp|=1.6×10−19Cv=14πε0qeqpmerH=2.2×106m/s",momento magnetico orbitale spiegare magnetismo materia occorre partire struttura microscopica modello molto semplificato possiamo pensare elettroni esterni rotazione intorno nucleo partiamo caso semplice latomo idrogeno forza coulombiana velocit hmevr hm cvqeqpmer hms
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#64,64,65Momento magnetico orbitalepossiamo pensare che un elettrone che ruota intorno al nucleo genera una correnteil momento magnetico dell’elettronei=−qeTdove il periodoT=2πRHvdefinendo il momento angolare orbitale:⃗po=⃗RH∧me⃗vmo=iS=iπR2H=−qev2πRHπR2H=−qev2RHmememo=iS=iπR2H=−qev2πRHπR2H==−qev2RHmeme⃗mo=−qe2me⃗po,momento magnetico pensare elettrone ruota intorno nucleo genera correnteil momento magnetico tdove periodo rhvdefinendo momento angolare orbitalepor hmevmoi si hqev rh hqev rhmememoi si hqev rh hqev
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#65,65,"Momento magnetico di spin
66Oltre al momento magnetico orbitale, si può osservare che gli elettroni hanno un ulteriore momento magnetico di spin (come se gli elettroni ruotassero intorno al proprio asse)⃗ms=−qeme⃗psIl momento magnetico totale (o intrinseco) è dato da una combinazione di momento orbitale e momento di spin. L’accoppiamento è descritto dalle leggi della meccanica quantisticaIn un generico atomo, il momento magnetico dipende dagli elettroni più esterniIn assenza di campi magnetici esterni, il momento magnetico totale macroscopico è nullo, perché i momenti magnetici degli atomi sono orientati casualmente e la loro somma vettoriale è nulla
",momento magnetico spin oltre momento magnetico orbitale pu osservare elettroni ulteriore momento magnetico spin come elettroni ruotassero intorno proprio momento magnetico totale intrinseco dato combinazione momento orbitale momento spin laccoppiamento descritto leggi meccanica quantistica generico atomo momento magnetico dipende elettroni esterni assenza campi magnetici esterni momento magnetico totale macroscopico nullo momenti magnetici atomi orientati casualmente somma vettoriale nulla
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#66,66,"Materiali diamagnetici
67In presenza di campo magnetico esterno occorre fare delle distinzioniLa maggior parte dei materiali ha atomi con momento magnetico nullo. In questi materiali, l’effetto di un campo esterno è quello di deviare la traiettoria degli elettroni in moto (forza di Lorenz), inducendo una variazione di velocità (l’elettrone si allontana dal nucleo) e quindi una diminuzione della frequenza di rotazione (precessione di Larmor)L’effetto complessivo è una diminuzione del momento magnetico, che va ad opporsi leggermente al campo magnetico esternoTali materiali sono chiamati diamagnetici (in genere hanno un numero pari di elettroni e struttura simmetrica)
",materiali diamagnetici presenza campo magnetico esterno occorre fare distinzioni maggior parte materiali atomi momento magnetico nullo materiali leffetto campo esterno deviare traiettoria elettroni moto forza lorenz inducendo variazione velocit lelettrone allontana nucleo quindi diminuzione frequenza rotazione precessione complessivo diminuzione momento magnetico opporsi leggermente campo magnetico esterno tali materiali chiamati diamagnetici genere numero pari elettroni struttura simmetrica
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#67,67,"Materiali paramagnetici
68I materiali paramagnetici hanno atomi con momento angolare intrinseco diverso da zero
I materiali paramagnetici sono caratterizzati da un numero dispari di elettroni  o da strutture atomiche asimmetricheGli atomi si comportano come dipoli magnetici che per effetto di un campo magnetico esterno tendono ad allinearsi  con il campo magnetico esterno, contribuendo ad aumentarne leggermente il valore
B",materiali paramagnetici materiali paramagnetici atomi momento angolare intrinseco diverso zero materiali paramagnetici caratterizzati numero dispari elettroni strutture atomiche asimmetriche atomi comportano dipoli magnetici effetto campo magnetico esterno tendono allinearsi campo magnetico esterno contribuendo aumentarne leggermente valore
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#68,68,"Vettore magnetizzazione
69Definiamo il vettore magnetizzazione come il prodotto del momento angolare intrinseco medio del materiale per il numero di atomi per unità di volume⟨⃗m⟩⃗M=n⟨⃗m⟩=Ndτ⟨⃗m⟩dipende dai momenti magnetici orbitali e di spinIl campo magnetico totale nella materia dipenderà dal vettore magnetizzazione:⃗B=⃗B0+μ0⃗MPossiamo definire la densità di corrente di magnetizzazione⃗jM=⃗∇∧⃗MDa cui ricaviamo le relazione⃗∇∧⃗B=⃗∇∧(⃗B0+μ0⃗M)==⃗∇∧⃗B0+μ0⃗∇∧⃗M=Legge di Ampère in forma locale=μ0⃗J+μ0⃗JM",vettore magnetizzazione definiamo vettore magnetizzazione prodotto momento angolare intrinseco medio materiale numero atomi unit momenti magnetici orbitali spin campo magnetico totale materia dipender vettore possiamo definire densit corrente mm ricaviamo ampre forma
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#69,69,"Il vettore H
70⃗∇∧⃗B=μ0(⃗J+⃗JM)Il campo magnetico totale B è generato dalle correnti di conduzione e dalle correnti di magnetizzazione
Partendo dalla relazione⃗∇∧⃗B=μ0⃗J+μ0⃗∇∧⃗M⃗∇∧(⃗B−μ0⃗Mμ0)=⃗JDefiniamo il vettore H che descrive il campo magnetico nella materia,  in funzione solo delle correnti di conduzione lungo i fili⃗H=⃗B−μ0⃗Mμ0=⃗Bμ0−⃗M⃗∇∧⃗H=⃗J⃗B=μ0⃗H+μ0⃗M",vettore mil campo magnetico totale generato correnti conduzione correnti magnetizzazione partendo definiamo vettore descrive campo magnetico materia funzione solo correnti conduzione lungo
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#7,7,"Poprietà del campo magnetico
8La forza magnetica tra due calamite potrebbe essere descritta con una formula simile alla legge di Coulomb (fine 1700)⃗FM=kMm1m2r2̂urm1 e m2 sono le “cariche magnetiche” kM è una costante magneticaLa forza magnetica è proporzionale al prodotto delle cariche magnetiche ed inversamente proporzionale al quadrato della distanza Attrattiva per cariche magnetiche opposte, repulsiva per cariche magnetiche ugualiUnica analogia con forza elettrostatica di Coulomb!!",popriet campo magnetico forza magnetica due calamite potrebbe essere descritta formula simile legge coulomb fine mmmrurm cariche magnetiche costante magnetica forza magnetica proporzionale prodotto cariche magnetiche inversamente proporzionale quadrato distanza attrattiva cariche magnetiche opposte repulsiva cariche magnetiche uguali unica analogia forza elettrostatica coulomb
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#70,70,"Magnetismo nella materia
71Nei materiali diamagnetici e paramagnetici, omogenei e isotropi i campi B H e M sono paralleli, e vengono espressi dalle relazioni⃗B=μrμ0⃗HDove:μrPermeabilità magnetica relativa⃗M=(μr−1)⃗H=χm⃗Hχm=(μr−1)Suscettività magnetica   {negativa per diamagneticipositiva per paramagnetici(molto piccola 10-4 —10-6)⃗M=(1μ0−1μ0μr)⃗B",magnetismo materia materiali diamagnetici paramagnetici omogenei isotropi campi paralleli vengono espressi dover permeabilit magnetica magnetica negativa piccola
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#71,71,"Materiali ferromagnetici
72I materiali ferromagnetici microscopicamente hanno una configurazione elettronica per cui si creano forti interazioni tra momenti orbitali e momenti di spinTali interazioni comportano che momenti magnetici di atomi adiacenti si “accoppiano”, aumentando considerevolmente il loro effetto magnetico rispetto al singolo atomoAll’interno del materiale si creano regioni formate da numerosi dipoli allineati (domini di Weiss) I domini di Weiss hanno tipicamente volumi di 10-12 —10-12 m3 e contengono 1017 —1011 atomi 
Se il materiale non ha subito magnetizzazione, le direzioni dei momenti sono casuali",materiali ferromagnetici materiali ferromagnetici configurazione elettronica creano forti interazioni momenti orbitali momenti spin tali interazioni comportano momenti magnetici atomi adiacenti accoppiano aumentando effetto magnetico rispetto singolo atomo allinterno materiale creano regioni formate numerosi dipoli allineati domini weiss domini weiss tipicamente volumi contengono atomi materiale subito direzioni momenti casuali
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#72,72,"73Materiali ferromagneticiQuando un materiale ferromagnetico viene posto in un campo magnetico esterno i momenti si allineano con il campo magnetico, generando un allargamento (una fusione) dei domini di Weiss
Ponendo campi magnetici sempre più intensi, si arriva ad una condizione di saturazioneIl materiale mantiene una magnetizzazione residua anche fuori dal campo magneticoI domini di Weiss vengono distrutti se il materiale viene riscaldato fino ad una temperatura critica (di Curie),che per il Fe vale ~1000°K",materiali ferromagnetici quando materiale ferromagnetico viene posto campo magnetico esterno momenti allineano campo magnetico generando allargamento una fusione domini weiss ponendo campi magnetici sempre intensi arriva condizione saturazione materiale mantiene magnetizzazione residua fuori campo magnetico domini weiss vengono distrutti materiale viene riscaldato fino temperatura critica curieche vale
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#73,73,"Ciclo di isteresi
74Per i materiali ferromagnetici la permeabilità magnetica non è costante, può essere molto elevata e dipende dalle correnti che generano il campo esterno e dalla storia di magnetizzazione. Inseriamo un cilindro di materiale ferromagnetico in un solenoide:
La curva a è detta di prima magnetizzazionediminuendo il campo H fino ad azzerarlo (curva b) nel materiale si ha una magnetizzazione residuaInvertendo il campo H, si raggiunge un valore critico HC per cui la magnetizzazione è nulla H generato da corrente nel solenoideCampo B del ferromagneteCampo M del ferromagnete",ciclo isteresi materiali ferromagnetici permeabilit magnetica costante pu essere molto elevata dipende correnti generano campo esterno storia inseriamo cilindro materiale ferromagnetico solenoide curva detta prima campo fino azzerarlo curva materiale magnetizzazione residua invertendo campo raggiunge valore critico magnetizzazione nulla generato corrente solenoide campo ferromagnete campo ferromagnete
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#74,74,"Memorie di massa magnetiche
75I supporti magnetici sono largamente utilizzati per l’archiviazione dei datiPer esempio gli hard disk sono formati da dischi di alluminio o vetro rivestiti da una pellicola di materiale ferromagneticoLa memorizzazione dell’informazione avviene associando un bit di magnetizzazione (verso di magnetizzazione) su un certo numero di domini di WeissLa densità di informazione è data dal numero di domini di Weiss che costituiscono un singolo bit, moltiplicato per la loro estensione superficiale media, rapportato alla superficie di archiviazione disponibileL’accesso ai dati avviene utilizzando testine magnetoresistive che variano la resistenza al variare del campo magnetico (in lettura) e viceversa (in scrittura)",memorie massa magnetiche supporti magnetici largamente utilizzati larchiviazione dati esempio hard disk formati dischi alluminio vetro rivestiti pellicola materiale ferromagnetico memorizzazione avviene associando bit magnetizzazione verso certo numero domini weiss densit informazione data numero domini weiss costituiscono singolo bit moltiplicato estensione superficiale media rapportato superficie archiviazione disponibile laccesso dati avviene utilizzando testine variano resistenza variare campo magnetico lettura viceversa scrittura
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#75,75,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
76",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#8,8,"Poli magnetici
9
Sperimentalmente, se si spezza una calamita si otterranno due nuove calamiteI poli magnetici esistono sempre a coppie di eguale valore e segno opposto: dipoli magneticiFino ad ora non è stato mai osservato un polo magnetico isolato (monopolo magnetico)Conseguenza: il campo magnetico ha proprietà molto diverse dal campo elettrostatico",poli magnetici spezza calamita otterranno due nuove calamite poli magnetici esistono sempre coppie eguale valore segno opposto dipoli magnetici fino ora stato mai osservato polo magnetico isolato monopolo campo magnetico propriet molto diverse campo elettrostatico
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#9,9,"Legge di Gauss per il campo magnetico
10
Le linee del campo magnetico sono sempre chiuse  (non possiamo isolare singoli poli magnetici)Il campo magnetico è solenoidale⃗∇⋅⃗B=0Di conseguenza (thm divergenza) scegliendo una qualunque superficie chiusa∬S⃗B⋅̂ndS=0La densità volumetrica di cariche magnetiche è sempre nulla (solo dipoli)S",legge gauss campo magnetico linee campo magnetico sempre chiuse non possiamo isolare singoli poli magneticiil campo magnetico conseguenza thm divergenza scegliendo qualunque superficie chiusasbnd densit volumetrica cariche magnetiche sempre nulla solo dipolis
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#0,0,1 Campi elettrici e magnetici variabili nel tempo CdS Ingegneria Informatica A.A. 2019/20 ,campi elettrici magnetici variabili tempo ingegneria informatica
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#1,1,"Campi elettrici in condizioni stazionarie
2⃗∇⋅⃗E=ρε0Legge di Gauss per il campo elettrico Forma integrale: il flusso del campo elettrico attraverso una superficie chiusa è proporzionale alla carica elettrica contenuta nella superficie Forma differenziale: Le cariche elettriche generano il campo elettricoΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0",campi elettrici condizioni stazionarie e legge gauss campo elettrico forma integrale flusso campo elettrico attraverso superficie chiusa proporzionale carica elettrica contenuta superficie forma differenziale cariche elettriche generano campo elettrico sesend
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#10,10,"Legge di Ampère e equazione di continuità
11⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza della densità di corrente compare nell’equazione di continuità (si veda cap. su correnti)In condizioni stazionarie (indipendenti dal tempo), la densità di carica è costante e la sua derivata è nulla.  In tale situazione , quindi ritroviamo che la legge di Ampère continua ad essere valida in condizioni stazionarie. Cosa succede nel caso più generale, in condizioni non necessariamente stazionarie?⃗∇⋅⃗𝚥=0",legge ampre equazione continuit t divergenza densit corrente compare nellequazione continuit veda cap correntiin condizioni stazionarie indipendenti tempo densit carica costante derivata nulla tale situazione quindi ritroviamo legge ampre continua essere valida condizioni stazionarie cosa succede caso generale condizioni necessariamente
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#11,11,"Legge di Ampère in condizioni non stazionarie
12⃗∇⋅⃗𝚥+∂ρ∂t=0Sostituiamo nell’equazione di continuità e invertiamo gli ordini di derivazioneDalla legge di Gauss in forma locale                             ricaviamo  ⃗∇⋅⃗E=ρε0ρ=ε0⃗∇⋅⃗E⃗∇⋅⃗𝚥+∂∂t(ε0⃗∇⋅⃗E)=0⃗∇⋅⃗𝚥+ε0⃗∇⋅∂⃗E∂t=0⃗∇⋅(⃗𝚥+ε0∂⃗E∂t)=0il vettore  ha sempre divergenza nulla!(⃗𝚥+ε0∂⃗E∂t)",legge ampre condizioni stazionarie t sostituiamo nellequazione continuit invertiamo ordini derivazione legge gauss forma locale ricaviamo vettore sempre divergenza
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#12,12,"tale vettore è la somma di due termini: • densità di corrente di conduzione    (dovuta a cariche in moto) • densità di corrente di spostamento              (dovuta a variazione di campo elettrico)Legge di Ampère-Maxwell
13(⃗𝚥+ε0∂⃗E∂t)⃗𝚥ε0∂⃗E∂t⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tAggiungendo il termine di densità di corrente di spostamento nell’equazione di Ampere, otteniamo la legge di Ampère-Maxwell",tale vettore somma due termini densit corrente conduzione dovuta cariche moto densit corrente spostamento dovuta variazione campo elettricolegge ampre maxwell aggiungendo termine densit corrente spostamento nellequazione ampere otteniamo legge ampre maxwell
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#13,13,"Legge di Ampère-Maxwell
14⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tIl rotore del campo magnetico è proporzionale alla somma della densità di corrente di conduzione  e alla variazione del campo elettrico⃗∇⋅(μ0⃗𝚥+μ0ε0∂⃗E∂t)=0In altre parole, il campo magnetico può essere generato da cariche in moto e da campi elettrici variabili nel tempoLa legge di Ampère-Maxwell è valida sempre, sia in regime stazionario che non stazionario. Infatti la divergenza della somma dei termini di densità di corrente di spostamento e conduzione è sempre nulla",legge ampre maxwell rotore campo magnetico proporzionale somma densit corrente conduzione variazione campo altre parole campo magnetico pu essere generato cariche moto campi elettrici variabili tempo legge ampre maxwell valida sempre regime stazionario stazionario infatti divergenza somma termini densit corrente spostamento conduzione sempre nulla
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#14,14,"Corrente di spostamento
15A partire dalla densità di corrente di spostamento ⃗𝚥S=ε0∂⃗E∂tDefiniamo la corrente di spostamento come il flusso della densità di corrente attraverso una superficie aperta S: La corrente di spostamento è proporzionale alla variazione del flusso del campo elettrico e non dipende da cariche in movimento.Si osserva una corrente di spostamento nelle regioni di spazio in cui c’è un campo elettrico variabile. Esempio: all’interno di un condensatore in regime transotorio (carica/scarica)is=∬S⃗𝚥s⋅̂ndS=∬Sε0∂⃗E∂t⋅̂ndS=ε0ddt∬S⃗E⋅̂ndS=ε0dΦS(⃗E)dt",corrente spostamento partire densit corrente spostamento set definiamo corrente spostamento flusso densit corrente attraverso superficie aperta corrente spostamento proporzionale variazione flusso campo elettrico dipende cariche movimentosi osserva corrente spostamento regioni spazio c campo elettrico variabile esempio allinterno condensatore regime transotorio ssetnd sddtsend sd sedt
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#15,15,"Legge di Ampère-Maxwell in forma integrale
16In forma integrale, la circuitazione del campo magnetico lungo una linea chiusa rimane proporzionale alla somma delle correnti concatenate, considerando sia le correnti di conduzione che le correnti di spostamento∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)",legge ampre maxwell forma integrale forma integrale circuitazione campo magnetico lungo linea chiusa rimane proporzionale somma correnti concatenate considerando correnti conduzione correnti
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#16,16,"Corrente di spostamento in condensatore
17Consideriamo un circuito RC in fase di scarica. Inizialmente sul condensatore si ha una carica Q0.  Alla chiusura dell’interruttore la carica sul condensatore varia con la legge:TCRQ(0)=Q0Q(t)=Q0e−tRCNel circuito si avrà una corrente di conduzione (dovuta alle cariche che fuoriescono dal condensatore):ic(t)=dQ(t)dt=−Q0RCe−tRC",corrente spostamento condensatore consideriamo circuito fase scarica inizialmente condensatore carica chiusura carica condensatore varia legget qtqet circuito corrente conduzione dovuta cariche fuoriescono qtdtq rcet
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#17,17,"Corrente di spostamento in condensatore
18Q(t)Supponiamo che il condensatore sia a facce piane e parallele. Nel condensatore carico con carica Q(t) c’è un campo elettrico (normale alla superficie S delle armature):Il campo elettrico dipende dal tempo, quindi nel condensatore si ha una densità di corrente di spostamento:  ⃗E=σε0̂n=Q(t)ε0Ŝn=Q0e−tRCε0Ŝn⃗𝚥s=ε0∂⃗E∂t=ε0∂∂t(Q0e−tRCε0S)̂n=−Q0SRCe−tRĈned una corrente di spostamento:is(t)=∬S⃗𝚥s⋅̂ndS=∬S−Q0SRCe−tRĈn⋅̂ndS=−Q0SRCe−tRC∬SdS=−Q0RCe−tRC⃗E",corrente spostamento condensatore qtsupponiamo condensatore facce piane parallele condensatore carico carica c campo elettrico normale superficie armatureil campo elettrico dipende tempo quindi condensatore densit corrente spostamento enqt snqet rc rc snq cet rcned corrente ssq cet rcnnd sq cet rcsd sq rcet rce
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#18,18,"Corrente di spostamento in condensatore
19ic(t)=is(t)=−Q0RCe−tRCNell’esempio del condensatore si trova che la corrente di conduzione e la corrente di spostamento hanno lo stesso valoreTale risultato è conseguenza dell’equazione di continuità, che lega le correnti alle variazioni di carica.𝛴⃗Eic(t)is(t)
S1S2𝛤Se infine poniamo 𝛴=S1+S2, ritroviamo la validità generale della legge di Ampère (Maxwell) Considerando una qualsiasi superficie chiusa 𝛴 che “avvolge” metà condensatore∮Γ⃗B⋅d⃗l=μ0∬S1⃗𝚥c⋅̂ndS=μ0∬S2⃗𝚥s⋅̂ndS∬Σ(⃗𝚥c+⃗𝚥s)⋅̂ndS=∬Σ(⃗𝚥c⋅̂n+⃗𝚥s⋅̂n)dS=∬Σ(jc−js)dS=0",corrente spostamento condensatore rcet nellesempio condensatore trova corrente conduzione corrente spostamento stesso valore tale risultato conseguenza dellequazione continuit lega correnti variazioni infine poniamo ss ritroviamo validit generale legge ampre maxwell considerando qualsiasi superficie chiusa avvolge met sssnd sjcjsd
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#19,19,"Esempio
206.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2",esempio determinare campo magnetico solenoide toroidale raggio maggiore raggio internoa dotatodi nspire percorse correnteib nir cavo coassiale lunghezza indenita formato due conduttori primo cilindrico raggioae cavo raggio internobe raggio esternoc due conduttori percorsi correnti uniformi diugual modulo verso opposto due conduttori vuoto determinare campo induzione magneticain spazio
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#2,2,"Campi elettrici in condizioni stazionarie
3Conservatività del campo elettrostatico⃗∇∧⃗E=0La circuitazione del campo elettrostatico lungo qualsiasi linea chiusa è nullaIrrotazionalità del campo elettrostatico: implica che il campo è conservativo e che possiamo definire il potenziale elettrostatico V tale che ⃗E=−⃗∇V∮Γ⃗E⋅d⃗l=0Il campo elettromotore in una pila non è conservativo. Tale relazione è verificata solamente nel caso stazionario. ",campi elettrici condizioni stazionarie conservativit campo circuitazione campo elettrostatico lungo qualsiasi linea chiusa nulla irrotazionalit campo elettrostatico implica campo conservativo possiamo definire potenziale elettrostatico tale campo elettromotore pila conservativo tale relazione verificata solamente caso stazionario
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#20,20,"Interazioni tra magneti e circuiti
21Abbiamo visto che le correnti generano campi magnetici (prima legge di Laplace, Biot-Savart) E’ vero anche il contrario?Se teniamo un magnete fermo vicino ad un circuito, in esso non si osserva corrente
Se muoviamo il magnete verso il circuito, allora si osserva una corrente (nell’intervallo in cui il magnete è in movimento)
Il movimento in verso opposto, “induce” nel circuito una corrente di segno opposto",interazioni magneti circuiti visto correnti generano campi magnetici prima legge laplace biot savart vero contrariose teniamo magnete fermo vicino circuito esso osserva corrente muoviamo magnete verso circuito allora osserva corrente magnete movimento movimento verso opposto induce circuito corrente segno opposto
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#21,21,"Interazioni tra circuiti percorsi da corrente
22
Un effetto analogo si osserva tra due circuiti posti in vicinanzaNel circuito di sinistra si osserva una corrente per un breve intervallo di tempo dopo la chiusura/apertura dell’interruttore (effetto transitorio con corrente variabile nel tempo)
",interazioni circuiti percorsi corrente effetto analogo osserva due circuiti posti vicinanza circuito sinistra osserva corrente breve intervallo tempo dopo effetto transitorio corrente variabile tempo
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#22,22,"Correnti indotte
23
Estraendo una spira fatta di materiale conduttore da una regione in cui è presente un campo magnetico, si misura una corrente sulla spira  • si ha corrente anche se il campo magnetico è uniforme• la corrente è massima se il piano della spira è ortogonale al campo magnetico• la corrente è nulla se il piano della spira è parallelo al campo magneticoDal momento che sul conduttore ci sono cariche libere, proviamo a spiegare il fenomeno in termini di forza di Lorentz",correnti indotte estraendo spira fatta materiale conduttore regione presente campo magnetico misura corrente spira corrente campo magnetico uniforme corrente massima piano spira ortogonale campo magnetico corrente nulla piano spira parallelo campo magnetico momento conduttore cariche libere proviamo spiegare fenomeno termini forza lorentz
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#23,23,"Correnti indotte
24⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BConsideriamo un sistema formato da due binari conduttori, paralleli e connessi elettricamente⃗vPoniamo una barretta conduttrice ortogonale ai binari e mettiamola in movimento con velocità costanteSe il sistema è posto in un campo magnetico (costante, uniforme, ortogonale al piano del circuito) nel circuito circola corrente, come se ci fosse un generatore di forza elettromotrice",correnti indotte consideriamo sistema formato due binari conduttori paralleli connessi poniamo barretta conduttrice ortogonale binari mettiamola movimento velocit costante sistema posto campo magnetico costante uniforme ortogonale piano circuito circuito circola corrente generatore forza elettromotrice
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#24,24,"Correnti indotte
25⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗FLe cariche libere sulla barretta sentono una forza di Lorentz:⃗v⃗F=qe⃗v∧⃗BLe cariche in un tratto dl è come se fossero sottoposte agli effetti di un campo elettromotoreN.B. gli elettroni si muovono verso l’alto, quindi la corrente convenzionalmente circola in verso orariod⃗ldℰ=⃗E⋅d⃗l=⃗Fqe⋅d⃗l=⃗v∧⃗B⋅d⃗l",correnti indotte bf cariche libere barretta sentono forza cariche tratto sottoposte effetti campo elettromotore elettroni muovono verso lalto quindi corrente circola verso
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#25,25,"Correnti indotte
26⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BLa velocità può essere scritta come d⃗ld⃗x⃗v=d⃗xdtIn un intervallo dt, la barretta si sarà spostata di un tratto dxdℰ=(⃗v∧⃗B)⋅d⃗l=(d⃗xdt∧⃗B)⋅d⃗lUtilizzando le proprietà del prodotto misto:dℰ=(d⃗xdt∧⃗B)⋅d⃗l=(d⃗l∧d⃗xdt)⋅⃗B=solo dx dipende dal tempo, B e  dl sono costanti=ddt[(d⃗l∧d⃗x)⋅⃗B]⃗v",correnti indotte velocit pu essere scritta dldxvdxdt intervallo barretta spostata tratto utilizzando propriet prodotto dipende tempo
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#26,26,"Induzione elettromagnetica
27⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗Bd⃗ld⃗x
d⃗l∧d⃗x=−̂n(dldx)=−̂ndSNegativo, perché “entrante” (verso opposto a B)dℰ=ddt[⃗B⋅(d⃗l∧d⃗x)]dℰ=−ddt[⃗B⋅̂ndS]⃗B⋅̂ndS=dΦS(⃗B)⃗vdSFlusso infinitesimo del campo magnetico attraverso dS",induzione bdldx snegativo entrante verso opposto sbnd sd sbvd sflusso infinitesimo campo magnetico attraverso
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#27,27,"Induzione elettromagnetica
28⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ 
ℰ=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtNel circuito si genera una forza elettromotrice indotta opposta (segno meno) alla variazione del flusso del campo magnetico concatenato con la spiraIntegrando su tutta l’area S spazzata dalla barretta 
Si può dimostrare che tale relazione è valida ogni volta in cui si verifica una variazione temporale del flusso concatenato del campo magnetico⃗Bd⃗ld⃗x⃗vS",induzione ddtsbnd sd sbdt circuito genera forza elettromotrice indotta opposta segno meno variazione flusso campo magnetico concatenato spira integrando tutta larea spazzata barretta pu dimostrare tale relazione valida ogni volta verifica variazione temporale flusso concatenato campo
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#28,28,"Legge di Faraday-Neumann-Lenz
29La variazione temporale del flusso di un campo magnetico “induce” una forza elettromotriceℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtLa forza elettromotrice indotta si oppone alla variazione del flusso che l’ha generata Tale legge rappresenta un ulteriore metodo per generare una corrente in un conduttore  (in aggiunta a forze elettrochimiche di pile e batterie)Il segno meno nell’equazione (storicamente attribuito di Lenz) è conseguenza del 3° principio della dinamica (azione-reazione) e quindi della conservazione dell’energia",legge faraday neumann lenz variazione temporale flusso campo magnetico induce forza sd sbdt forza elettromotrice indotta oppone variazione flusso lha generata tale legge rappresenta ulteriore metodo generare corrente conduttore aggiunta forze elettrochimiche pile batterieil segno meno nellequazione storicamente attribuito lenz conseguenza principio dinamica azione reazione quindi conservazione dellenergia
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#29,29,"Induzione elettromagnetica
30ℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dt1)area della spira variabile nel tempo 2)campo magnetico variabile nel tempo 3)moto relativo di una spira rispetto ad  campo magnetico  Con aggiunta di tutte le possibili combinazioni delle situazioni elencateConsiderando un generico circuito chiuso (una spira), il flusso del campo magnetico concatenato con la spira può variare al verificarsi di tre tre principali situazioni:",induzione sd sbdtarea spira variabile tempo campo magnetico variabile tempo moto relativo spira rispetto campo magnetico aggiunta tutte possibili combinazioni situazioni elencate considerando generico circuito chiuso una spira flusso campo magnetico concatenato spira pu variare verificarsi tre tre principali situazioni
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#3,3,"Campi magnetici in condizioni stazionarie
4⃗∇⋅⃗B=0Legge di Gauss per il campo magnetico Il flusso del campo magnetico attraverso una superficie chiusa è sempre nullo non possiamo isolare cariche magnetiche (monopoli)Il campo magnetico ha sempre divergenza nulla (è solenoidale). Le linee di campo sono sempre chiuse su loro stesse∬⃗B⋅̂ndS=0",campi magnetici condizioni stazionarie b legge gauss campo magnetico flusso campo magnetico attraverso superficie chiusa sempre nullo possiamo isolare cariche magnetiche monopoliil campo magnetico sempre divergenza nulla solenoidale linee campo sempre chiuse stessebnd
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#30,30,"Esempio
31Si consideri un circuito rettangolare con un lato di lunghezza L in movimento con velocità v0 costante. La resistenza totale del circuito vale R. Il circuito è completamente immerso in un campo magnetico costante ed uniforme, ortogonale al piano del circuito. Calcolare: a)l’espressione della corrente indotta nel circuito b)la forza necessaria per mantenere la velocità costanteCampo magnetico costante (e uniforme) e area della spira variabile⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ V0 L L6. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza 2R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza L dal conduttore fisso e si muove con velocità V0 costante verso destra. Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   7. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza 2L dal conduttore fisso e  s i  m u o v e  c o n  v e l o c i t à  2 V0 c o s t a n t e  v e r s o  d e s t r a .  Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   8. Un circuito elettrico è costituito da due binari conduttori paralleli di resistenza trascurabile posti ad una distanza 2D, da una conduttore fisso di resistenza 2R e da un’asta metallica AB di resistenza trascurabile che può scorrere senza attrito sui due binari (vedi figura). La posizione dell’asta AB varia nel tempo secondo la r e l a z i o n e  x ( t )  =  2 x0(1 - cosωt), con x0 ed ω costanti positive note. Il circuito è immerso in un campo induzione magnetica B, diretto perpendicolarmente al piano del circuito, la cui intensità varia nel tempo secondo la relazione B(t)=2B0(1 + cosωt), con B0 costante positiva nota. Determinare: a. la forza elettromotrice indotta nel circuito; b. il valore massimo iM dell’intensità di corrente che circola nel circuito; c. la forza che agisce sull’asta AB.       2V0 2L L
V(t) 2R xB2D A⃗B",esempio consideri circuito rettangolare lato lunghezza movimento velocit costante resistenza totale circuito vale circuito completamente immerso campo magnetico costante uniforme ortogonale piano circuito calcolare alespressione corrente indotta circuito bla forza necessaria mantenere velocit costante campo magnetico costante uniforme area spira variabile circuito vedi figura costituito due binari conduttori paralleli resistivit trascurabile posti distanza luno dallaltro collegati conduttore fisso resistenza unasta metallica anchessa resistivit trascurabile pu scorrere senza attrito due binari circuito immerso campo induzione magnetica variabile ktg diretto piano figura verso uscente costante positiva nota inizialmente lasta trova distanza conduttore fisso muove velocit costante verso destra determinare verso rotazione corrente circuito lespressione dellintensit corrente circola circuito lespressione modulo forza viene applicata allasta mantenerne costante velocit circuito vedi figura costituito due binari conduttori paralleli resistivit trascurabile posti distanza luno dallaltro collegati conduttore fisso resistenza unasta metallica anchessa resistivit trascurabile pu scorrere senza attrito due binari circuito immerso campo induzione magnetica variabile ktg diretto piano figura verso uscente costante positiva nota inizialmente lasta trova distanza conduttore fisso determinare verso rotazione corrente circuito lespressione dellintensit corrente circola circuito lespressione modulo forza viene applicata allasta mantenerne costante velocit circuito elettrico costituito due binari conduttori paralleli resistenza trascurabile posti distanza conduttore fisso resistenza unasta metallica resistenza trascurabile pu scorrere senza attrito due binari vedi figura posizione dellasta varia tempo secondo cost costanti positive note circuito immerso campo induzione magnetica diretto piano circuito intensit varia tempo secondo relazione cost costante positiva nota determinare forza elettromotrice indotta circuito valore massimo dellintensit corrente circola circuito forza agisce sullasta ab
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#31,31,"Campo magnetico variabile nel tempo e spira ferma
32S2S1Figure 15:7.3Una spira quadrata conduttrice di latol=20 cm e resistenzaR=0.1⌦si trova ad una distanza ﬁssaa=80cm da un ﬁlo rettilineo indeﬁnito percorso da una correntei. Due dei lati della spira sono paralleli al ﬁlo.Calcolare:a) il ﬂusso del campo magnetico generato dal ﬁlo , supponendo che la corrente sia costantei0=3A (",campo magnetico variabile tempo spira ferma figure spira quadrata conduttrice latol resistenza rsi trova distanza ssaacm lo rettilineo indenito percorso correntei due lati spira paralleli usso campo magnetico generato lo supponendo corrente costantei
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#32,32,"33Campo magnetico costante (non uniforme) e spira in movimento F1) Un circuito rigido quadrato, di lato L=100cm, è costituito di un filo di alluminio (resistività ρ=2.56 10-8 Ωm) di sezione S=10 mm2. Esso si trova nel piano xy con i lati paralleli ai due assi, ed è immerso (nel vuoto) in un campo di induzione magnetica uniforme di modulo Bz= 0,5T diretto lungo l’asse z nel verso positivo, limitato all’area grigia di figura. Il circuito, inizialmente tutto immerso nel campo magnetico, trasla con parallelamente all’asse x con velocità che viene mantenuta costante di modulo V0= 20 cm/s. Calcolare, giustificando:  1) il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) l’intensità  di tale corrente nel circuito durante il moto; 3) l’energia totale dissipata nel circuito per effetto Joule; 4) il lavoro effettuato per portare il circuito completamente fuori del campo.              F2) Una spira rigida a forma di triangolo equilatero di lato L=2m, massa M=100g, e resistenza R=10 Ω ,  s i  m u o v e  c o n  v e l o c i t à  c o s t a n t e  V0 =  1 0  m / s  l u n g o  l ’ a s s e  x .  N e l semipiano delle x positive è presente un campo induzione magnetica uniforme di modulo B=0.5 T diretto lungo z nel verso positivo, mentre nel semipiano delle x negative B è identicamente nullo. Calcolare: 1)  il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) il flusso di B c o n c a t e n a t o  c o n  i l  c i r c u i t o ,  n e l l ’ i s t a n t e  i n  c u i  m e t à  d e l l ’ a r e a  d e l  3) la corrente massima che circola nel circuito durante il moto; 4) l’espressione vettoriale della forza che agisce sul lato BC del circuito, all’istante       ijBv0L
ijBLABCUna spira quadrata conduttrice di lato L e resistenza R si muove con velocità costante v0 in una regione dove è presente un campo magnetico uniforme, limitato ad una regione rettangolare. a)determinare la corrente indotta sulla spira  b)il lavoro per estrarre la spira fuori dalla regione in cui è presente il campo magnetico c)l’energia dissipata per effetto Joule",campo magnetico costante non uniforme spira movimento circuito rigido quadrato lato lcm costituito filo alluminio resistivit sezione esso trova piano lati paralleli due assi immerso nel vuoto campo induzione magnetica uniforme modulo diretto lungo lasse verso positivo limitato allarea grigia figura circuito inizialmente immerso campo magnetico trasla parallelamente allasse velocit viene mantenuta costante modulo cms calcolare giustificando verso corrente indotta orario antiorario riferimento figura lintensit tale corrente circuito durante moto lenergia totale dissipata circuito effetto joule lavoro effettuato portare circuito completamente fuori campo spira rigida forma triangolo equilatero lato massa resistenza semipiano positive presente campo induzione magnetica uniforme modulo diretto lungo verso positivo mentre semipiano negative identicamente nullo calcolare verso corrente indotta orario antiorario riferimento figura flusso corrente massima circola circuito durante moto lespressione vettoriale forza agisce lato circuito allistante cuna spira quadrata conduttrice lato resistenza muove velocit costante regione presente campo magnetico uniforme limitato regione rettangolare adeterminare corrente indotta spira bil lavoro estrarre spira fuori regione presente campo magnetico clenergia dissipata effetto joule
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#33,33,"Generatore elettrico
34
Consideriamo un sistema di N spire rotanti con velocità angolare costante in un campo magnetico uniformesia S=area delle spire, 𝜑=𝜔t angolo tra vettore normale al piano della spira e campo magneticoin ogni istante il flusso valeΦ(⃗B)=N⃗B⋅̂nS=NBScosφ=NBScosωtnelle spire ci sarà una fem indotta:ℰ=−dΦ(⃗B)dt=−NBS(−ωsinωt)=NBSωsinωt
fem alternata
",generatore elettrico consideriamo sistema spire rotanti velocit angolare costante campo magnetico uniformesia sarea spire t angolo vettore normale piano spira campo magneticoin ogni istante flusso bscosn bscostnelle spire fem bssintn bssint fem alternata
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#34,34,"Correnti di Foucault
35Le correnti di Foucault (o correnti parassite) si osservano nei conduttori in presenza di campi magnetici il cui flusso varia nel tempo. Esse sono una conseguenza del fenomeno dell’induzione magnetica. Tali correnti sono dovute al moto degli elettroni causato dalle fem indotte nel conduttore
L’effetto di tali correnti è quello di creare campi magnetici che si oppongono alla variazione che le hanno generate: effetto “frenante”Per minimizzare gli effetti delle correnti parassite, occorre “tagliare” il conduttore
",correnti foucault correnti foucault correnti parassite osservano conduttori presenza campi magnetici flusso varia tempo esse conseguenza fenomeno dellinduzione magnetica tali correnti dovute moto elettroni causato fem indotte conduttore leffetto tali correnti creare campi magnetici oppongono variazione generate effetto frenanteper minimizzare effetti correnti parassite occorre tagliare conduttore
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#35,35,"Correnti di Foucault
36Le correnti di Foucault possono anche generare calore per effetto JouleTale meccanismo è alla base dei fornelli ad induzione
Perché non tutte le pentole funzionano sulle cucine ad induzione?",correnti foucault correnti foucault possono generare calore effetto joule tale meccanismo base fornelli induzione tutte pentole funzionano cucine induzione
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#36,36,"Forma locale della legge di FNL
37ℰ=∮Γ⃗E⋅d⃗l=∬SΓ⃗∇∧⃗E⋅̂ndSℰ=∮Γ⃗E⋅d⃗l=−ddt∬SΓ⃗B⋅̂ndS=∬SΓ−∂⃗B∂t⋅̂ndS⃗∇∧⃗E=−∂⃗B∂tApplichiamo il teorema di StokesCombinando con la legge di Faraday-Neumann-LenzIl campo E è detto campo elettrico indotto  Un campo magnetico variabile nel tempo è una sorgente di campo elettrico ",forma locale legge ssbtnd sebt applichiamo teorema stokes combinando legge faraday neumann lenz campo detto campo elettrico indotto campo magnetico variabile tempo sorgente campo elettrico
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#37,37,"Forma locale della legge di FNL
38⃗∇∧⃗E=−∂⃗B∂t• Il campo elettrico indotto dalla variazione di un campo magnetico ha rotore non-nullo: non è conservativoIn ogni punto dello spazio in cui è presente un campo magnetico variabile nel tempo, in quel punto si genera un campo elettrico• Il campo elettrico generato da cariche elettriche ha sempre rotore nullo ed è conservativo (campo elettrostatico)Il campo elettrico può essere generato da campi magnetici variabili nel tempo oppure da cariche elettriche",forma locale legge ebt campo elettrico indotto variazione campo magnetico rotore nullo conservativo ogni punto spazio presente campo magnetico variabile tempo quel punto genera campo elettrico campo elettrico generato cariche elettriche sempre rotore nullo conservativo campo campo elettrico pu essere generato campi magnetici variabili tempo oppure cariche elettriche
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#38,38,"Induzione mutua
39Per la prima legge di Laplace, il campo magnetico dipende linearmente dalla corrente che l’ha generato:d⃗B=μ0i4πd⃗l∧̂rr2Il flusso del campo magnetico sarà dunque proporzionale alla corrente:Φ(⃗B)=MiDove M è un coefficiente che dipende solamente dalla geometria (forma) del circuito percorso da correntei⃗B
Se le correnti sono variabili nel tempo:ℰind=−dΦ(⃗B)dt=−Mdidt",induzione mutua prima legge laplace campo magnetico dipende linearmente corrente lha flusso campo magnetico dunque proporzionale coefficiente dipende solamente geometria forma circuito percorso correnteib correnti variabili
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#39,39,"Induzione mutua
40Consideriamo due circuiti percorsi da correnti i1 e i2, che generano rispettivamente i campi magnetici B1 e B2 Il flusso di B1 attraverso il circuito 2 èΦ1(⃗B2)=M21i2Φ2(⃗B1)=M12i1Il flusso di B2 attraverso il circuito 1 èi1i2Si può dimostrare che M12=M21=MM è detto coefficiente di mutua induzioneNel sistema internazionale si misura in Henry (H)  1H=Tm2/A",induzione mutua consideriamo due circuiti percorsi correnti generano rispettivamente campi magnetici flusso attraverso circuito flusso attraverso circuito ii pu dimostrare mmm detto coefficiente mutua induzione sistema internazionale misura henry htma
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#4,4,"Campi magnetici in condizioni stazionarie
5∮Γ⃗B⋅d⃗l=μ0conc∑kik⃗∇∧⃗B=μ0⃗𝚥Legge di Ampère la circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate con la linea di circuitazioneIn forma locale, il rotore del campo magnetico è proporzionale alla densità di corrente. Il campo magnetico NON è conservativo Il campo magnetico è generato da correnti (cariche in movimento)",campi magnetici condizioni stazionarie legge ampre circuitazione campo magnetico proporzionale somma correnti concatenate linea circuitazione forma locale rotore campo magnetico proporzionale densit corrente campo magnetico conservativo campo magnetico generato correnti cariche movimento
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#40,40,"Esempio
41habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=",esempio hab figure solenoide torioidale costituito spire ciascuna raggiorcm raggio maggiore delsolenoide rcm lo lunghezza indenita posto lungo lasse toroide percorso verso laltoda corrrente variabile tempoi
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#41,41,"Autoinduzione
42i⃗BUn circuito percorso da corrente genera un campo magnetico Tale campo avrà un flusso concatenato con il circuito stessoSe la corrente varia nel temp, nel circuito si genererà una fem autoindottaΦ(⃗B)=LiL è detto coefficiente di autoinduzione (o induttanza) e si misura in Henryℰind=−dΦ(⃗B)dt=−LdidtLa fem autoindotta si oppone alla variazione di corrente che l’ha generata ",autoinduzione ib circuito percorso corrente genera campo magnetico tale campo flusso concatenato circuito stesso corrente varia temp circuito generer fem detto coefficiente autoinduzione induttanza misura fem autoindotta oppone variazione corrente lha generata
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#42,42,"Esempio
43Calcolare l’induttanza di un solenoide cilindrico ideale di lunghezza l formato da N spire circolari di raggio r 
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2SlSupponiamo che il solenoide sia percorso da una corrente i(t) variabile nel tempo. Internamente al solenoide vi è un campo magnetico (dipendente dal tempo): Il flusso del campo attraverso una singola spira vale ⃗BS=πr2area di una spiraB(t)=μ0Nli(t)Φspira(⃗B(t))=B(t)S=μ0Nli(t)πr2",esempio calcolare linduttanza solenoide cilindrico ideale lunghezza formato spire circolari raggio circuiti corrente alternata fisica generale march autoinduzione consideriamo solenoide percorso corrente variabile tempo esso genera campo magnetico entro volume cilindrico delimitato solenoide anchesso variabile tempo tale campo magnetico volta variabile tempo genera forza elettromotrice indotta solenoide sovrappone forza elettromotrice esterna questo fenomeno prende nome autoinduzione idomenico galli fisica generale circuiti corrente alternata autoinduzione se solenoide scorre corrente intensit numero spire unit lunghezza campo magnetico allinterno solenoide visto diretto lungo lasse solenoide intensit se larea sezione solenoide flusso tale campo magnetico concatenato spira vale ovvero numero totale spire lunghezza solenoide sitn galli fisica generale circuiti corrente alternata autoinduzione il flusso campo magnetico concatenato spire solenoide vale la forza elettromotrice autoindotta vale perci la costante chiamata coefficiente autoinduzione induttanza sldidt domenico galli fisica generale circuiti corrente supponiamo solenoide percorso corrente variabile tempo internamente solenoide campo magnetico dipendente tempo flusso campo attraverso singola spira vale srarea spira bt nlitr
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#43,43,"Esempio
44Il flusso attraverso l’intero solenoide sarà pari ad N volte il flusso attraverso una singola spira  
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BΦsolenoide(⃗B(t))=NΦspira(⃗B(t))=Nμ0Nli(t)πr2=μ0N2li(t)πr2L’induttanza L si calcola come il rapporto tra il flusso “autoindotto”  (autoflusso) e la corrente:L=Φsolenoide(⃗B)i(t)=μ0N2lπr2",esempio flusso attraverso lintero solenoide pari volte flusso attraverso singola spira circuiti corrente alternata fisica generale march autoinduzione consideriamo solenoide percorso corrente variabile tempo esso genera campo magnetico entro volume cilindrico delimitato solenoide anchesso variabile tempo tale campo magnetico volta variabile tempo genera forza elettromotrice indotta solenoide sovrappone forza elettromotrice esterna questo fenomeno prende nome autoinduzione idomenico galli fisica generale circuiti corrente alternata autoinduzione se solenoide scorre corrente intensit numero spire unit lunghezza campo magnetico allinterno solenoide visto diretto lungo lasse solenoide intensit se larea sezione solenoide flusso tale campo magnetico concatenato spira vale ovvero numero totale spire lunghezza solenoide sitn galli fisica generale circuiti corrente alternata autoinduzione il flusso campo magnetico concatenato spire solenoide vale la forza elettromotrice autoindotta vale perci la costante chiamata coefficiente autoinduzione induttanza sldidt domenico galli fisica generale circuiti corrente nlitr nlitr linduttanza calcola rapporto flusso autoindotto autoflusso nlr
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#44,44,"Esempio
45habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=",esempio hab figure solenoide torioidale costituito spire ciascuna raggiorcm raggio maggiore delsolenoide rcm lo lunghezza indenita posto lungo lasse toroide percorso verso laltoda corrrente variabile tempoi
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#45,45,"Circuiti con induttanze
46
Un solenoide inserito all’interno di un circuito percorso da corrente variabile nel tempo si comporta come un generatore di forza elettromotrice (fem autoindotta) con polarità opposta alla variazione di corrente
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BSimbolo circuitale dell’induttanza +_𝓔(t)ℰautoindotta=−dΦsolenoide(⃗B(t))dt=−Ldi(t)dtREquazione del circuitoℰ(t)−Ldi(t)dt=Ri(t)ℰ(t)+ℰautoindotta=Ri(t)La fem autoindotta si “oppone” alla variazione di corrente che l’ha generata",circuiti induttanze solenoide inserito allinterno circuito percorso corrente variabile tempo comporta generatore forza elettromotrice fem autoindotta polarit opposta variazione corrente circuiti corrente alternata fisica generale march autoinduzione consideriamo solenoide percorso corrente variabile tempo esso genera campo magnetico entro volume cilindrico delimitato solenoide anchesso variabile tempo tale campo magnetico volta variabile tempo genera forza elettromotrice indotta solenoide sovrappone forza elettromotrice esterna questo fenomeno prende nome autoinduzione idomenico galli fisica generale circuiti corrente alternata autoinduzione se solenoide scorre corrente intensit numero spire unit lunghezza campo magnetico allinterno solenoide visto diretto lungo lasse solenoide intensit se larea sezione solenoide flusso tale campo magnetico concatenato spira vale ovvero numero totale spire lunghezza solenoide sitn galli fisica generale circuiti corrente alternata autoinduzione il flusso campo magnetico concatenato spire solenoide vale la forza elettromotrice autoindotta vale perci la costante chiamata coefficiente autoinduzione induttanza sldidt domenico galli fisica generale circuiti corrente slb simbolo circuitale dellinduttanza requazione fem autoindotta oppone variazione corrente lha generata
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#46,46,"Induttanze in serie
47+_𝓔(t)RL1L2In serie, le due induttanze sono percorse dalla stessa correnteΔV=ΔV1+ΔV2=−L1di(t)dt−L2di(t)dt=−(L1+L2)di(t)dt=−Ltotdi(t)dtDifferenza di potenziale ai capi delle due induttanze
L’induttanza del sistema formato da due (o più) induttanze collegate in serie è uguale alla somma delle singole induttanzeLtot=∑iLitrascuriamo gli effetti di mutua induzione",induttanze serie tr serie due induttanze percorse stessa corrente differenza potenziale capi due induttanze linduttanza sistema formato due pi induttanze collegate serie uguale somma singole induttanze ltoti litrascuriamo effetti mutua induzione
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#47,47,"Induttanze in parallelo
48
+_𝓔(t)RL1L2In parallelo, le due induttanze sono alla stessa differenza di potenzialetrascuriamo gli effetti di mutua induzionedi1dt=−ΔVL1di2dt=−ΔVL2=−ΔVL1−ΔVL2=i=i1+i2Per la legge dei nodididt=di1dt+di2dt
L’inverso dell’induttanza del sistema formato da due o più induttanze collegate in parallelo è uguale alla somma degli inversi delle singole induttanza 1Ltot=1L1+1L2=−ΔV(1L1+1L2)=−ΔVLtot1Ltot=∑i1Li",induttanze parallelo tr parallelo due induttanze stessa differenza effetti mutua vldidt vl vl vliii legge linverso dellinduttanza sistema formato due induttanze collegate parallelo uguale somma inversi singole induttanza ltot l l vltot ltoti
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#48,48,"Energia magnetica
49
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗B+_𝓔(t)RL’induttanza percorsa da corrente variabile nel tempo si comporta come un generatore con polarità opposta alla variazione correnteInnalzare la corrente di un valore di equivale a far passare nell’induttanza una carica q in un tempo dt (dq=idt)Per spostare la carica occorre contrastare la fem autoindottaℰautoindotta=−Ldidtδℒ=−ℰautoindottadq=−(−Ldidt)(idt)Occorre fare un lavoro “contro” la forza elettromotrice autoindotta",energia magnetica circuiti corrente alternata fisica generale march autoinduzione consideriamo solenoide percorso corrente variabile tempo esso genera campo magnetico entro volume cilindrico delimitato solenoide anchesso variabile tempo tale campo magnetico volta variabile tempo genera forza elettromotrice indotta solenoide sovrappone forza elettromotrice esterna questo fenomeno prende nome autoinduzione idomenico galli fisica generale circuiti corrente alternata autoinduzione se solenoide scorre corrente intensit numero spire unit lunghezza campo magnetico allinterno solenoide visto diretto lungo lasse solenoide intensit se larea sezione solenoide flusso tale campo magnetico concatenato spira vale ovvero numero totale spire lunghezza solenoide sitn galli fisica generale circuiti corrente alternata autoinduzione il flusso campo magnetico concatenato spire solenoide vale la forza elettromotrice autoindotta vale perci la costante chiamata coefficiente autoinduzione induttanza sldidt domenico galli fisica generale circuiti corrente slbtr linduttanza percorsa corrente variabile tempo comporta generatore polarit opposta variazione corrente innalzare corrente valore equivale far passare nellinduttanza carica tempo dqidtper spostare carica occorre contrastare fem fare lavoro contro forza elettromotrice autoindotta
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#49,49,"Energia magnetica
50Se inizialmente nell’induttanza non circola corrente i(0)=0, per portare il circuito a corrente i occorre compiere un lavoroℒ=∫i0Lidi=12Li2δℒ=−ℰautoindottadq=−(−Ldidt)(idt)Lavoro per aumentare la corrente di un valore di
Il lavoro accumula energia nell’induttanza.Energia magnetica accumulata in un’induttanzaUB=12Li2",energia magnetica inizialmente nellinduttanza circola corrente portare circuito corrente occorre compiere lavoroi lidi aumentare corrente valore lavoro accumula energia magnetica accumulata uninduttanza
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#5,5,"Equazioni di Maxwell (caso stazionario)
6⃗∇⋅⃗E=ρε0⃗∇∧⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗B=μ0⃗𝚥Forma locale(differenziale)",equazioni maxwell caso stazionario forma
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#50,50,"Densità di energia magnetica
51
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BS=πr2Ricordando l’espressione dell’induttanza di un solenoideL=μ0N2lSIl campo magnetico vale:B=μ0Nlii=Blμ0NL’energia magnetica sarà pari aUB=12Li2=12(μ0N2lS)(Blμ0N)2=12(μ0N2lS)(B2l2μ20N2)=B22μ0(lS)volume del solenoideL’energia magnetica è il prodotto di una densità di energia per il volume del solenoide",densit energia magnetica circuiti corrente alternata fisica generale march autoinduzione consideriamo solenoide percorso corrente variabile tempo esso genera campo magnetico entro volume cilindrico delimitato solenoide anchesso variabile tempo tale campo magnetico volta variabile tempo genera forza elettromotrice indotta solenoide sovrappone forza elettromotrice esterna questo fenomeno prende nome autoinduzione idomenico galli fisica generale circuiti corrente alternata autoinduzione se solenoide scorre corrente intensit numero spire unit lunghezza campo magnetico allinterno solenoide visto diretto lungo lasse solenoide intensit se larea sezione solenoide flusso tale campo magnetico concatenato spira vale ovvero numero totale spire lunghezza solenoide sitn galli fisica generale circuiti corrente alternata autoinduzione il flusso campo magnetico concatenato spire solenoide vale la forza elettromotrice autoindotta vale perci la costante chiamata coefficiente autoinduzione induttanza sldidt domenico galli fisica generale circuiti corrente slb sr ricordando lespressione dellinduttanza solenoide sil campo magnetico valeb nliibl nlenergia magnetica pari li sbl sbl nbl svolume solenoide lenergia magnetica prodotto densit energia volume solenoide
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#51,51,"Densità di energia magnetica
52uB=B22μ0Definiamo la densità di energia del campo magnetico:L’energia magnetica è localizzata in ogni punto dello spazio in cui è presente il campo magneticoUB=∭spaziouBdτL’energia del campo magnetico si calcola come l’integrale sul volume in tutto lo spazio in cui è presente il campo magnetico",densit energia magnetica bb definiamo densit energia campo magnetica localizzata ogni punto spazio presente campo magnetico ubspaziou bd lenergia campo magnetico calcola lintegrale volume spazio presente campo magnetico
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#52,52,"Circuiti RL in regime transitorio
53Come abbiamo fatto per i condensatori, analizziamo un circuito composto da un generatore di forze elettromotrice costante, una resistenza e un’induttanza 
+_T𝓔LR
Inizialmente l’interruttore è aperto (non circola corrente i(0)=0, l’induttanza è scarica)Ad un dato istante iniziale t=0 l’interruttore viene chiuso. Scriviamo l’equazione della maglia:ℰ+ℰind=Riℰ−Ldidt=Ri",circuiti regime transitorio fatto condensatori analizziamo circuito composto generatore forze elettromotrice costante resistenza uninduttanza inizialmente linterruttore aperto non circola corrente linduttanza scaricaad dato istante iniziale linterruttore viene chiuso scriviamo lequazione
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#53,53,"Circuiti RL in regime transitorio
54ℰ−Ldidt=Rididt=−RL(i−ℰR)Separiamo le variabilidi(i−ℰR)=−RLdtIntegriamo tra i(0) e i(t) e tra t=0 e t∫i(t)i(0)di(i−ℰR)=∫t0−RLdtln(i−ℰR)i(t)i(0)=−RLtlni(t)−ℰRi(0)−ℰR=−RLti(t)−ℰRi(0)−ℰR=e−RLtImponendo la condizione iniziale i(0)=0i(t)−ℰR=−ℰRe−RLt",circuiti regime transitorio li rsepariamo variabilidii rr ldt integriamo rtr ldtlni ritir ltlnit ri rr ltit ri rer imponendo condizione iniziale iit r rer
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#54,54,"Circuiti RL in regime transitorio
55i(t)=ℰR(1−e−RLt)
Transitori in un Circuito RL. Chiusura del Circuito (IV) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!La quantità # = L/R, che ha le dimensioni di un tempo, viene detta costante di tempo del circuito. i0()=0""fR+i0e!RL0=fR+i0=0""i0=!fRit()=fR!fRe!RLt  it()=fR1!e!RLt""#$%&'
45!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
 Transitori in un Circuito RL. Chiusura del Circuito (V) •!Si ottiene inoltre: VR=Rit()=f1!e!RLt""#$%&'VL=Ldidtt()=LfR!e!RLt""#$%&'!RL""#$%&'=fe!RLtit()=fR1!e!RLt""#$%&'VRt()=f1!e!RLt""#$%&'VLt()=fe!RLt()****+****it()t!""#!##fRVRt()t!""#!##fVLt()t!""#!##046!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Chiusura del Circuito (VI) tfRi
tfRVfLVt47!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito •!Consideriamo il circuito in figura e supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con l’induttanza L percorsa da una corrente di intensità costante (i = f /R). •!Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione differenziale: •!L’integrale generale è: Ldidtt()+Rit()=0i0()=fR!""##$##  it()=i0e!RLt48!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0ℰRAndamento nella corrente in un circuito RL alla chiusura dell’interruttore L/R ha le dimensioni du un tempo (costante di tempo)inizialmente la corrente è nulla e si porta ad un valore asintoticoℰind=−Ldidt=−LℰRRLe−RLt⟶t→∞0in regime stazionario (t→∞ ) la fem autoindotta si annullal’induttanza si comporta come un filo a resistenza nullanell’induttanza vi è immagazzinata un’energia magneticaUB=12Li2",circuiti regime transitorio it rer transitori circuito chiusura circuito per trovare costante imponiamo condizione iniziale la quantit dimensioni tempo viene detta costante tempo circuito rier riif ritf rer itf rer domenico galli fisica generale circuiti corrente alternatar vli transitori circuito chiusura circuito si ottiene inoltre rritfer ltv lldidttlf rer ltr lfer ltitf rer ltv rtfer ltv ltfer rttf galli fisica generale circuiti corrente alternatar vli transitori circuito chiusura circuito rvf lvtdomenico galli fisica generale circuiti corrente alternatar vli transitori circuito apertura circuito consideriamo circuito figura supponiamo ora che inizialmente deviatore trovi posizione linduttanza percorsa corrente intensit costante supponiamo poi certo istante deviatore venga commutato posizione avremo lequazione differenziale lintegrale generale itier ltdomenico galli fisica generale circuiti corrente alternatar vli bt randamento corrente circuito chiusura dimensioni tempo costante corrente nulla porta valore ler lttin regime stazionario t fem autoindotta comporta filo resistenza immagazzinata unenergia magnetica
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#55,55,"56Circuiti RL in regime transitorioSia dato un circuito formato da un condensatore e un’induttanza Inizialmente l’interruttore T è aperto, l’induttanza è carica con UB=UoCalcoliamo quanto vale l’energia dissipata sulla resistenza L’equazione della maglia alla chiusura dell’interruttore èTLR
ℰind=Ri−Ldidt=Rididt=−RLiRisolvendo l’eq. differenziale per separazione delle variabili:dii=−RLdti(t)=i(0)e−RLtlni(t)i(0)=−RLt",circuiti regime transitorio dato circuito formato condensatore uninduttanza inizialmente linterruttore aperto linduttanza carica buo calcoliamo vale lenergia dissipata resistenza lequazione maglia chiusura risolvendo leq differenziale separazione ldtitier ltlnitir
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#56,56,"57Circuiti RL in regime transitorioi(t)=i(0)e−RLtUB=12Li(0)2La corrente iniziale si ricava dalla condizione iniziale di energia immagazzinata nell’induttanza
Transitori in un Circuito RL. Apertura del Circuito (II) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!Si ottiene inoltre: i0()=fR""i0e!RL0=i0=fR""i0=fR it()=fRe!RLtVR=Rit()=fe!RLtVL=Ldidtt()=LfRe!RLt!RL""#$%&'=!fe!RLt
49!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (III) •!Riassumendo: 
•!La corrente che scorre nel circuito dopo che è stato escluso il generatore di tensione prende il nome di extracorrente di apertura. it()=fRe!RLtVRt()=fe!RLtVLt()=!fe!RLt""#$$$%$$$it()t!""#!##0VRt()t!""#!##0VLt()t!""#!##0
50!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (IV) fRti
tfRVf!LVt51!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (V) •!Se dopo avere escluso il generatore il circuito rimane aperto, si osserva una scarica elettrica tra i contatti dell’interruttore. •!Il motivo è nel fatto che il flusso del campo magnetico nell’induttanza passa in un tempo estremamente breve dal valore iniziale f/R al valore finale 0. •!Segue che la derivata          è estremamente elevata, e con essa è estremamente elevata la f.e.m. autoindotta: ft()=!L""i""t=!L0!fR""t""t#0$#$$%  didt
52!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0i(0)=2UBLi(0)L’energia dissipata sulla resistenza per effetto Joule durante l’intero processo di scarica:UR=∫∞0Ri2dt=R∫∞0(i(0)e−RLt)2dt=R∫∞0i2(0)e−2RLtdt=R2UBL∫∞0e−2RLtdt=R2UBL[−L2Re−2RLt]∞0=UBTutta l’energia accumulata nell’induttanza viene dissipata per effetto Joule sulla resistenza",circuiti regime corrente iniziale ricava condizione iniziale energia immagazzinata nellinduttanza transitori circuito apertura circuito per trovare costante imponiamo condizione iniziale si ottiene inoltre rier lif rif itf rer vrritfer vlldidttlf rer ltr lfer domenico galli fisica generale circuiti corrente alternatar vli transitori circuito apertura circuito riassumendo la corrente scorre circuito dopo stato escluso generatore tensione prende nome extracorrente apertura itf rer vrtfer vltfer vrtt vltt domenico galli fisica generale circuiti corrente alternatar vli transitori circuito apertura circuito rti rvfl vtdomenico galli fisica generale circuiti corrente alternatar vli transitori circuito apertura circuito se dopo avere escluso generatore circuito rimane aperto osserva scarica elettrica contatti il motivo fatto flusso campo magnetico nellinduttanza passa tempo estremamente breve valore iniziale valore finale segue derivata estremamente elevata essa estremamente elevata fem autoindotta rtt didt domenico galli fisica generale circuiti corrente alternatar vli bti lilenergia dissipata resistenza effetto joule durante lintero processo scaricau r rltdtr le rltdtr ll re rltu btutta lenergia accumulata nellinduttanza viene dissipata effetto joule resistenza
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#57,57,"Esempio
58habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=",esempio hab figure solenoide torioidale costituito spire ciascuna raggiorcm raggio maggiore delsolenoide rcm lo lunghezza indenita posto lungo lasse toroide percorso verso laltoda corrrente variabile tempoi
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#58,58,"Esempio
59  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:4",esempio consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice interruttore inizialmente aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze lll tre resistenze rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze llll tre resistenze rrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema figure consideri circuito mostrato gura composto tre induttanze lll rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacita ccc determinare regime stazionarioa corrente elettrica circola tre resistenze rrb lenergia totale immagazzinata sistema cec potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice interruttore inizialmente aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze lll tre resistenze rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze llll tre resistenze rrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema figure consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice interruttore inizialmente aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze lll tre resistenze rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze llll tre resistenze rrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema figure consideri circuito mostrato gura composto tre induttanze lll rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacita ccc determinare regime stazionarioa corrente elettrica circola tre resistenze rrb lenergia totale immagazzinata sistema cec potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto due induttanze tre resistenze generatore resistenza interna fornisce forza elettromotrice interruttore inizialmente aperto determinare corrente elettrica circola tre resistenze funzione tempo determinare inoltre regime stazionario valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze lll tre resistenze rrrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema consideri circuito mostrato figura composto tre induttanze llll tre resistenze rrr generatore resistenza interna trascurabile fornisce forza elettromotrice due condensatori capacit determinare regime stazionario corrente elettrica circola tre resistenze valore potenziale punto lenergia totale immagazzinata sistema potenza dissipata sistema figure
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#59,59,"Le equazioni di Maxwell
60⃗∇⋅⃗E=ρε0∬S⃗E⋅̂ndS=QSε0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t∮Γ⃗E⋅d⃗l=−ddt∬S⃗B⋅̂ndS∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tForma differenzialeForma integrale∬S⃗B⋅̂ndS=0",equazioni maxwell forma differenziale forma
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#6,6,"Equazioni di Maxwell (caso stazionario)
7∮Γ⃗E⋅d⃗l=0∮Γ⃗B⋅d⃗l=μ0conc∑kikForma integrale∬S⃗E⋅̂ndS=QSε0∬S⃗B⋅̂ndS=0",equazioni maxwell caso stazionario forma ssbnd
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#60,60,"Le equazioni di Maxwell
61Le quattro equazioni di Maxwell descrivono completamente l’elettromagnetismo A partire da esse è possibile ricavare tutte le leggi dell’elettromagnetismo, dall’elettrostatica, alle correnti, alle forze elettriche e magnetiche Dalle equazioni di Maxwell si evince che i campi elettrico e magnetico sono strettamente legati tra di loro e che essi sono due modi di manifestarsi della stessa entità chiamata campo elettromagnetico Partendo dalle equazioni di Maxwell, si dimostra che il campo elettromagnetico si propaga attraverso onde elettromagnetiche, le quali hanno sempre una componente di campo elettrico e una di campo magnetico",equazioni maxwell quattro equazioni maxwell descrivono completamente partire esse possibile ricavare tutte leggi correnti forze elettriche magnetiche equazioni maxwell evince campi elettrico magnetico strettamente legati essi due modi manifestarsi stessa entit chiamata campo partendo equazioni maxwell dimostra campo propaga attraverso onde quali sempre componente campo elettrico campo magnetico
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#61,61,"Argomenti Facoltativi
62• Equazione delle onde elettromagnetiche • Onde elettromagnetiche piane • Teorema di Poynting ed energia trasportata dalle onde elettromagnetiche",argomenti facoltativi equazione onde onde piane teorema poynting energia trasportata onde
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#62,62,"Onde elettromagnetiche
63Prendiamo in considerazione le quattro equazioni di Maxwell in  assenza di cariche e di correnti di conduzione⃗∇⋅⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t⃗∇∧⃗B=μ0ε0∂⃗E∂t∇2⃗E=ε0μ0∂2⃗E∂t2Combinando le quattro relazioni e utilizzando le proprietà delle operazioni tra operatori si ricavano le due equazioni di D’Alambert per campo elettrico e magnetico∇2⃗B=ε0μ0∂2⃗B∂t2ε0μ0=1c2c=3×108 m/s velocità della luce nel vuoto",onde prendiamo considerazione quattro equazioni maxwell assenza cariche correnti combinando quattro relazioni utilizzando propriet operazioni operatori ricavano due equazioni dalambert campo elettrico velocit luce vuoto
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#63,63,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
64",lorenzo rinaldi dipartimento fisica astronomia
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#7,7,"Legge di Ampère su condensatore
8Scriviamo la legge di Ampère in funzione della densità di corrente ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSTale legge deve essere vera per qualsiasi superficie aperta S avente per bordo la linea chiusa 𝛤Applichiamo tale legge in un circuito con condensatore:
S1S2𝛤S1 interseca il filo  S2 passa nell’intercapedine del condensatore (senza intersecare il filo) Entrambe hanno come bordo la linea chiusa 𝛤",legge ampre condensatore scriviamo legge ampre funzione densit corrente bdls cnd stale legge deve essere vera qualsiasi superficie aperta avente bordo linea chiusa applichiamo tale legge circuito condensatore interseca filo passa condensatore senza intersecare filo entrambe bordo linea chiusa
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#8,8,"Legge di Ampère su condensatore
9
S1S2𝛤In condizioni stazionarie, nei rami di circuiti con condensatori non circola corrente quindi la circuitazione è nulla: legge di Ampère è soddisfatta per entrambe le superfici Cosa succede in regime transitorio, quando si ha una corrente:                   
La legge di Ampère                                         è valida solo in condizioni stazionarie ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSi(t)=ℰRe−tRCIn tal caso il flusso attraverso S1 è diverso da zero, mentre risulta nullo attraverso S2",legge ampre condensatore condizioni stazionarie rami circuiti condensatori circola corrente quindi circuitazione nulla legge ampre soddisfatta entrambe superfici cosa succede regime transitorio quando corrente legge ampre valida solo condizioni stazionarie bdls cnd sit ret tal caso flusso attraverso diverso zero mentre risulta nullo attraverso
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#9,9,"Legge di Ampère
10Oltre al caso del condensatore, la legge di Ampère presenta un altro problema formale⃗∇∧⃗B=μ0⃗𝚥⃗∇⋅(⃗∇∧⃗B)=μ0⃗∇⋅⃗𝚥⃗∇⋅(⃗∇∧⃗B)=0Si dimostra facilmente che la divergenza del rotore di un campo vettoriale è sempre nulla (qualunque sia il campo)⃗∇⋅⃗𝚥=?Non è vero invece che la divergenza della densità di corrente sia sempre nulla In quali condizioni è nulla? (il vettore densità di corrente è solenoidale?) Applicando l’operatore divergenza ad entrambi i membri dell’equazione di Ampère in forma differenziale:",legge ampre oltre caso condensatore legge ampre presenta altro problema dimostra facilmente divergenza rotore campo vettoriale sempre nulla qualunque vero invece divergenza densit corrente sempre nulla quali condizioni nulla vettore densit corrente solenoidale applicando loperatore divergenza entrambi membri dellequazione ampre forma differenziale
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al Machine Learning  
",machine learning universit roma tre dipartimento ingegneria anno accademico introduzione machine learning
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#1,1,"Introduzione al  
machine Learning
Intuitivamente, un sistema è in grado di apprendere se, 
attraverso la sua attività, è in grado di migliorare le 
proprie prestazioni.
Nell’IA, il miglioramento delle prestazioni coincide in 
generale con l’acquisizione di nuove conoscenze.
",introduzione machine learning intuitivamente sistema grado apprendere attraverso attivit grado migliorare proprie prestazioni nelli miglioramento prestazioni coincide generale lacquisizione nuove conoscenze
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#10,10,,
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#11,11,,
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#12,12,"metodi di apprendimento
Apprendimento supervisionato
Richiede che si apprenda una funzione partendo da esempi di input 
e output
Apprendimento non supervisionato
Richiede di imparare a riconoscere pattern o schemi nell’input 
senza alcuna indicazione speciﬁca dei valori di uscita.
Apprendimento per rinforzo
L’agente apprende in base al rinforzo (ricompensa) ottenuto.
",metodi apprendimento apprendimento supervisionato richiede apprenda funzione partendo esempi input output apprendimento supervisionato richiede imparare riconoscere pattern schemi nellinput senza alcuna indicazione specica valori uscita apprendimento rinforzo lagente apprende base rinforzo ricompensa ottenuto
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#13,13,"Tipici problemi di  
Machine Learning
Regression 
Classiﬁcation  
ClusteringUna tipica classiﬁcazione dei problemi affrontati in ML  
è la seguente:
",tipici problemi machine learning regression classication clustering tipica classicazione problemi affrontati seguente
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#14,14,"Applicazioni di  
Machine Learning
DEMO
",applicazioni machine learning
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#2,2,"Introduzione al  
machine Learning
Qualsiasi cambiamento in un sistema che gli permetta di 
avere prestazioni migliori la seconda volta, nella 
ripetizione dello stesso compito o di un altro compito 
tratto dalla stessa popolazione.
(Simon, 1984)
",introduzione machine learning qualsiasi cambiamento sistema permetta avere prestazioni migliori seconda volta ripetizione stesso compito altro compito tratto stessa popolazione simon
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#3,3,"Introduzione al  
machine Learning
A computer program is said to learn from experience E 
with respect to some class of tasks T and performance 
measure P, if its performance at tasks in T, as measured 
by P, improves with experience E .
(Mitchell, 1997)
",introduzione machine learning computer program said learn experience respect class tasks performance measure performance tasks measured improves experience mitchell
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#4,4,"Definizioni
Task T : obiettivo del sistema
Giocare a dama
Guidare un autoveicolo
Riconoscere parole pronunciate
Experience E : Insieme di addestramento dal quale apprendere
Partite giocate
Percorsi
.........
Performance measure P : misura della capacità di eseguire il 
task
Numero di partite vinte
Numero di parole classiﬁcate correttamente
",definizioni task obiettivo sistema giocare dama guidare autoveicolo riconoscere parole pronunciate experience insieme addestramento apprendere partite giocate percorsi performance measure misura capacit eseguire task numero partite vinte numero parole classicate correttamente
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#5,5,"Introduzione al  
machine Learning
Un elemento fondamentale dell’apprendimento è la 
capacità di valutare le proprie prestazioni, o almeno di 
accettare una valutazione dall’esterno.
Senza una valutazione, infatti, non sarebbe possibile 
parlare di miglioramento.
A sua volta, la valutazione delle prestazioni richiede la 
capacità di accettare un certo tipo di informazioni 
dall’ambiente esterno.
",introduzione machine learning elemento fondamentale capacit valutare proprie prestazioni almeno accettare valutazione dallesterno senza valutazione infatti possibile parlare miglioramento volta valutazione prestazioni richiede capacit accettare certo tipo informazioni dallambiente esterno
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#6,6,"Progetti Rilevanti nello 
Sviluppo del Machine Learning
1989 : Guida autoveicolo - ALVINN system (Pomerlau, 1989)
1995 : Classiﬁcazione nuove strutture astronomiche - NASA: classiﬁcazione 
oggetti celesti (Fayyad et al., 1995)
1992-95 : Backgammon - TD-Gammon (Tesauro, 1992, 1995): 
apprendimento su 1 milione di partite giocate contro se stesso.
2004 : DARPA introduce la “DARPA Grand Challenge”, una sﬁda per la 
guida autonoma di veicoli.
2006 : Geoffrey Hinton dell’Università di Toronto introduce un algoritmo di 
apprendimento veloce  per reti neurali artiﬁciali, che dà il via alla 
rivoluzione del Deep Learning.
",progetti rilevanti sviluppo machine learning guida autoveicolo system pomerlau classicazione nuove strutture astronomiche classicazione oggetti celesti fayyad backgammon gammon tesauro apprendimento milione partite giocate stesso introduce grand challenge sda guida autonoma veicoli geoffrey hinton delluniversit toronto introduce algoritmo apprendimento veloce reti neurali articiali via rivoluzione deep learning
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#7,7,,
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#8,8,,
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#9,9,,
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Algoritmo K-NN
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico algoritmo machine learning
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#1,1,"Sommario
Ripasso su Information Retrieval 
Algoritmo k-NN 
kd-trees per k-NN
 
2",sommario ripasso information retrieval algoritmo trees
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#10,10,"Modello Bag-of-Words
Un problema che emerge in questa semplice rappresentazione è 
relativa ai termini poco frequenti (“rare words”). 
In effetti, in tale rappresentazione tutti i termini sono considerati 
ugualmente importanti.  
In realtà certi termini hanno poca capacità discriminante ai ﬁni 
della determinazione della rilevanza di un documento (e.g., 
quando ne calcoliamo la distanza rispetto ad un altro).  
Ad esempio, nel caso di una collezione di documenti relativi 
all’industria automobilistica, è piuttosto probabile avere il termine 
“automobile” in quasi ogni documento. 
Tali termini dominerebbero dunque quelli più rari. 
 
11",modello bag words problema emerge semplice relativa termini poco frequenti rare words effetti tale termini considerati ugualmente importanti realt certi termini poca capacit discriminante ni determinazione rilevanza documento quando calcoliamo distanza rispetto altro esempio caso collezione documenti relativi allindustria piuttosto probabile avere termine automobile quasi ogni documento tali termini dominerebbero dunque rari
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#11,11,"Modello TF-IDF
Una rappresentazione alternativa che possiamo considerare è 
quella chiamata 
 tf-idf
. 
Come vedremo, questa rappresentazione enfatizza i termini 
“importanti”, individuati dalle seguenti caratteristiche: 
•
 appaiono frequentemente in un documento (“common locally”) 
•
 appaiono raramente nel corpus (“rare globally”) 
 
12",modello alternativa possiamo considerare chiamata idf vedremo enfatizza termini importanti individuati seguenti appaiono frequentemente documento common locally appaiono raramente corpus rare globally
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#12,12,"Modello TF-IDF
Deﬁniamo 
 Document Frequency
  (
df
) per il termine 
 t
 come il 
numero di documenti nel corpus che contengono 
 t
. 
Deﬁniamo inoltre l’
 Inverse Document Frequency
  come segue: 
dove N è la cardinalità del corpus. 
 
13idf t= logN
dft",modello deniamo document frequency termine numero documenti corpus contengono deniamo inoltre inverse document frequency segue cardinalit corpus idf log dft
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#13,13," 
14termine dft idft
car 18.165 1,65
auto 6.723 2,08
insurance 19.241 1,62
best 25.235 1,5ESEMPIO: 
Nella seguente tabella sono riportati alcuni esempi di valori df e idf 
relativi alla collezione Reuters, costituita da 806.791 documenti:
Modello TF-IDF",termine dft idft car auto insurance best seguente tabella riportati alcuni esempi valori idf relativi collezione reuters costituita documenti modello
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#14,14,"Modello TF-IDF
Il tf-idf è deﬁnito come segue: 
In sostanza il 
 tf-idf
 per un termine 
 t
 in un documento 
 d
 assegna al 
termine un peso nel documento che è: 
•
 molto elevato quando 
 t
 è molto frequente in un piccolo numero 
di documenti; 
•
 più basso quando il termine è poco frequente nel documento, 
oppure quando è presente in molti documenti; 
•
 il più basso quando il termine compare in tutti i documenti. 
 
15tf-idf t,d=t f t,d ·idft",modello idf denito segue sostanza idf termine documento assegna termine peso documento molto elevato quando molto frequente piccolo numero documenti basso quando termine poco frequente documento oppure quando presente molti documenti basso quando termine compare documenti idf tdt idft
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#15,15,"Metriche
Vediamo ora come possiamo calcolare la distanza tra due 
 item
.
 
16distanza( xi,xq)= |xi",metriche vediamo ora possiamo calcolare distanza due item distanza xixq
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#16,16,"Metriche
 
17distanza( xi,xq)=q
a1(xi[1]",metriche distanza xixqq axi
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#17,17,"Cosine Similarity
Una metrica largamente utilizzata per quantiﬁcare la similarità tra 
due documenti 
 x
i 
e 
x
q 
è la 
 cosine similarity
 , che si avvale della 
rappresentazione vettoriale dei documenti: 
 
18sim(xi,xq)=xT
i·xq
kxik·kxqk
dove il numeratore rappresenta il prodotto scalare tra i due vettori 
e il denominatore il prodotto tra i moduli dei due vettori. 
L’effetto del denominatore è dunque quello di normalizzare i 
vettori 
 x
i 
e 
x
q 
ottenendone i corrispondenti versori. Possiamo 
dunque riscrivere la precedente espressione come segue: 
sim(xi,xq)=ˆxT
i·ˆxq",cosine similarity metrica largamente utilizzata quanticare similarit due documenti cosine similarity avvale vettoriale documenti simxixqx ixq kxikkxqk numeratore rappresenta prodotto scalare due vettori denominatore prodotto moduli due vettori leffetto denominatore dunque normalizzare vettori ottenendone corrispondenti versori possiamo dunque riscrivere precedente espressione segue simxixqx ixq
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#18,18,"Consideriamo ad esempio i documenti in ﬁgura a), rappresentati 
mediante i vari 
 tf
. La quantità: 
 
19Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17Doc1 Doc2 Doc3
car 0,88 0,09 0,58
auto 0,10 0,71 0
insurance 0 0,71 0,70
best 0,46 0 0,41
Cosine Similarity
ha i valori 30,56, 46,84 e 41,30 per Doc1, Doc2 e Doc3. 
Applicando la normalizzazione otteniamo la ﬁgura b): 
a) 
 b) kxk=vuutdX
j=1x2
j",consideriamo esempio documenti gura rappresentati mediante vari quantit doc doc doc car auto insurance best doc doc doc car auto insurance best cosine similarity valori doc doc doc applicando normalizzazione otteniamo gura kxkvuutd
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#19,19,"La similarità deﬁnita in precedenza corrisponde al coseno 
dell’angolo tra i due vettori: 
 
20θ
01
1sim(xi,xq)=xT
i·xq
kxik·kxqk= cos( ✓)
ˆxi
ˆxq
Cosine Similarity",similarit denita precedenza corrisponde coseno dellangolo due vettori simxixqx ixq kxikkxqk cos xi xq cosine similarity
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#2,2,"Document Retrieval
 
3Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..
Supponiamo di avere disponibile un corpus di documenti: Come 
possiamo misurare la similarità tra di loro? Come possiamo 
effettuare ricerche? ",document retrieval diversamente esseri umani presumibilmente esempio informatici lapproccio sistemi simbolici affatto rispondere domanda lapproccio migliore provate pensare li accelerando sostituzione capitale potrebbe valere pena correre rischi precedenza tentativo denire li dopo conferenza dartmouth linteresse affrontare lettura occorre certa dimestichezza testo trovano inseriti la relazione matrici ora denita riessiva trasformazione pu ragione gran parte psico proseliti costoro massimo le ragioni instaurata stretta connessione il lettore pu essere sorpreso quantit spazio molta utilit galton convinto caratteri mortali ereditassero oltre ci galton memore la situazione tuttavia comple tamente diversa unarea pieno sviluppo modo semplice assistere clienti quasi sistemi sperimentali supponiamo avere disponibile corpus documenti possiamo misurare similarit loro possiamo effettuare ricerche
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#20,20,"K-NN: Complessità della ricerca 
 
21Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Il calcolo delle distanze tra documenti può essere molto pesante 
computazionalmente quando N è molto elevato: ",complessit ricerca diversamente esseri umani presumibilmente esempio informatici lapproccio sistemi simbolici affatto rispondere domanda lapproccio migliore provate pensare li accelerando sostituzione capitale potrebbe valere pena correre rischi precedenza tentativo denire li dopo conferenza dartmouth linteresse affrontare lettura occorre certa dimestichezza testo trovano inseriti la relazione matrici ora denita riessiva trasformazione pu ragione gran parte psico proseliti costoro massimo le ragioni instaurata stretta connessione il lettore pu essere sorpreso quantit spazio molta utilit galton convinto caratteri mortali ereditassero oltre ci galton memore modo semplice assistere clienti quasi sistemi sperimentali la situazione tuttavia comple tamente diversa unarea pieno sviluppo calcolo distanze documenti pu essere molto pesante quando molto elevato
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#21,21,"K-NN: Complessità della ricerca 
 
22
Dato un 
 query point
 , il costo della scansione su tutti i punti è: 
•
 O(N) per una query per 1-NN 
•
 O(N log k) per una query per k-NN 
Per rendere più efﬁciente la ricerca è possibile utilizzare una 
particolare struttura dati, i 
 KD-Trees
 . ",complessit ricerca dato query point costo scansione punti query log query rendere efciente ricerca possibile utilizzare particolare struttura dati trees
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#22,22,"KD-Trees
 
23
Permette un’organizzazione strutturata degli item: 
•
 partiziona ricorsivamente i data point in “axis aligned boxes”. 
Comporta un più efﬁciente pruning dello spazio di ricerca. 
Ottiene buoni risultati in dimensioni “low-medium”. 
Riferimenti: 
Bentley, J.L. “Multidimensional Binary Search Trees Used for Associative Searching”, in: 
Communications of the ACM , 18(9), 1975, pp. 509-517.
Friedman, J.H., Bentley, J.L., Finkel, R.A. “An Algorithm for Finding Best Matches in 
Logarithmic Expected Time”, in: ACM Transactions on Mathematical Software , 3(3), 1977, pp. 
209-226.",trees permette strutturata item partiziona ricorsivamente data point axis aligned boxes comporta efciente pruning spazio ricerca ottiene buoni risultati dimensioni low medium riferimenti bentley binary search trees used associative searching communications friedman bentley finkel an algorithm finding best matches logarithmic expected time transactions mathematical software
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#23,23,"KD-Trees
 
24
Costruzione dell’albero: 
Data Point x[1] x[2]
1 0,00 0,00
2 1,00 4,31
3 0,13 2,85
… … …
feature 1feature 2",trees costruzione dellalbero data point feature feature
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#24,24,"KD-Trees
 
25
Split relativo alla prima feature: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5",trees split relativo prima feature data point data point
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#25,25,"KD-Trees
 
26
Consideriamo ora la parte sinistra: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5
",trees consideriamo ora parte sinistra data point data point
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#26,26,"KD-Trees
 
27
Split relativo alla seconda feature: 
Data Point x[1] x[2]
3 0,13 2,85
… … …Data Point x[1] x[2]
1 0,00 0,00
… … …x[2] > 0,1 x[2] ≤ 0,1
0,1
",trees split relativo seconda feature data point data point
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#27,27,"KD-Trees
 
28
Si procede in tal modo ﬁno a completare l’albero: 
•split feature 
•split value 
•bounding box
x[1] > 0,5 x[1] ≤ 0,5
x[2] ≤ 0,1 x[2] > 0,1",trees procede tal modo no completare lalbero split feature split value bounding box
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#28,28,"KD-Trees
 
29
Esempi di bounding box: 
",trees esempi bounding box
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#29,29,"KD-Trees
 
30
Euristiche per effettuare le decisioni sugli splitting: 
•
 Scelta della dimensione (la più ampia, dim. alternate) 
•
 Valore della feature a cui effettuare lo split (mediana, centro 
del box) 
•
 Condizione di terminazione (numero di punti sotto una 
determinata soglia, larghezza del box sotto una determinata 
soglia)",trees euristiche effettuare decisioni splitting scelta dimensione ampia dim alternate valore feature effettuare split mediana centro box condizione terminazione numero punti sotto determinata soglia larghezza box sotto determinata soglia
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#3,3,"Nearest Neighbor
 
4Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare l’articolo più simile nel 
corpus di documenti disponibili: 
documento xqnearest neighbor",nearest neighbor diversamente esseri umani presumibilmente esempio informatici lapproccio sistemi simbolici affatto rispondere domanda lapproccio migliore provate pensare li accelerando sostituzione capitale potrebbe valere pena correre rischi precedenza tentativo denire li dopo conferenza dartmouth linteresse affrontare lettura occorre certa dimestichezza testo trovano inseriti la relazione matrici ora denita riessiva trasformazione pu ragione gran parte psico proseliti costoro massimo le ragioni instaurata stretta connessione il lettore pu essere sorpreso quantit spazio molta utilit galton convinto caratteri mortali ereditassero oltre ci galton memore storicamente modo semplice assistere clienti quasi sistemi sperimentali la situazione tuttavia comple tamente diversa unarea pieno sviluppo obiettivo dato documento trovare larticolo simile corpus documenti disponibili documento xqnearest neighbor
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#30,30,"KD-Trees
 
31
Dato un query point (in verde), attraversiamo l’albero alla ricerca 
del nearest neighbor. 
",trees dato query point verde attraversiamo lalbero ricerca nearest neighbor
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#31,31,"KD-Trees
 
32
Prima metà dell’area: 
",trees prima met dellarea
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#32,32,"KD-Trees
 
33
.. e così via … 
",trees cos via
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#33,33,"KD-Trees
 
34
Abbiamo raggiunto la foglia che contiene il query point: 
",trees raggiunto foglia contiene query point
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#34,34,"KD-Trees
 
35
Calcolo della distanza del NN tra i punti contenuti nella foglia: 
",trees calcolo distanza punti contenuti foglia
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#35,35,"KD-Trees
 
36
Backtrack e proviamo altri rami per ogni nodo visitato: 
",trees backtrack proviamo altri rami ogni nodo visitato
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#36,36,"KD-Trees
 
37
Valutiamo la distanza dal bounding box: 
",trees valutiamo distanza bounding box
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#37,37,"KD-Trees
 
38
La distanza è minore di quella corrente, perciò visitiamo i 
sottoalberi (in questo caso le foglie). La prima ha distanza 
minore: 
",trees distanza minore corrente perci visitiamo sottoalberi caso foglie prima distanza minore
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#38,38,"KD-Trees
 
39
Backtrack e visitiamo l’altra foglia: 
",trees backtrack visitiamo laltra foglia
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#39,39,"KD-Trees
 
40
La distanza dal bounding box è superiore alla minima, perciò 
possiamo potare il ramo: ",trees distanza bounding box superiore minima perci possiamo potare ramo
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#4,4,"Algoritmo 1-NN
 
5dist min = 1
nearest doc = ;
for i=1,. . . ,N
",algoritmo dist min nearest doc
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#40,40,"KD-Trees
 
41
Backtrack e proviamo altri rami per ogni nodo visitato: ",trees backtrack proviamo altri rami ogni nodo visitato
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#41,41,"KD-Trees
 
42
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: ",trees distanza bounding box superiore minima corrente perci possiamo potare ramo
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#42,42,"KD-Trees
 
43
Backtrack e proviamo altri rami per ogni nodo visitato: 
",trees backtrack proviamo altri rami ogni nodo visitato
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#43,43,"KD-Trees
 
44
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: 
",trees distanza bounding box superiore minima corrente perci possiamo potare ramo
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#44,44,"KD-Trees
 
45
Pruning complessivo: 
",trees pruning complessivo
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#45,45,"Riferimenti
 
46
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012.",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze apogeo edizione machine learning clustering retrieval university washington coursera flach machine learning art science algorithms make sense data cambridge university press murphy machine learning probabilistic approach press
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#5,5," 
6Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare i k articoli più simili nel 
corpus di documenti disponibili: 
documento xqk nearest neighbors
k Nearest Neighbors",diversamente esseri umani presumibilmente esempio informatici lapproccio sistemi simbolici affatto rispondere domanda lapproccio migliore provate pensare li accelerando sostituzione capitale potrebbe valere pena correre rischi precedenza tentativo denire li dopo conferenza dartmouth linteresse affrontare lettura occorre certa dimestichezza testo trovano inseriti la relazione matrici ora denita riessiva trasformazione pu ragione gran parte psico proseliti costoro massimo le ragioni instaurata stretta connessione il lettore pu essere sorpreso quantit spazio molta utilit galton convinto caratteri mortali ereditassero oltre ci galton memore storicamente modo semplice assistere clienti quasi sistemi sperimentali la situazione tuttavia comple tamente diversa unarea pieno sviluppo obiettivo dato documento trovare articoli simili corpus documenti disponibili documento xqk nearest neighbors nearest neighbors
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#6,6,"Algoritmo k-NN
 
7
Input: documento 
 x
q
 per la query e documenti 
 x
1
 , 
x
2
, … , 
 x
N 
Output: lista dei k documenti più vicini a 
 x
q 
lista kdist min = sort( ",algoritmo input documento query documenti output lista documenti vicini lista kdist min sort
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#7,7,"Criticità nella NN search
Per effettuare una ricerca dei nearest neighbors occorre risolvere i 
seguenti problemi: 
•
Come rappresentare gli item coinvolti (nel nostro esempio i 
documenti). 
•
Come valutare la distanza tra gli item, ossia deﬁnire una metrica 
che consenta di calcolare la similarità tra i vari item. 
 
8",criticit search effettuare ricerca nearest neighbors occorre risolvere seguenti problemi rappresentare item coinvolti nel esempio documenti valutare distanza item ossia denire metrica consenta calcolare similarit vari item
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#8,8,"Richiami su 
Rappresentazione dei Documenti
Vediamo ora due possibili metodi per la rappresentazione dei 
documenti non strutturati: 
•
 bag of words 
•
 tf-idf 
 (term frequency - inverse document frequency)  
 
9",richiami documenti vediamo ora due possibili metodi documenti strutturati bag words idf term frequency inverse document frequency
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#9,9,"Modello Bag-of-Words
In questo modello è ignorato l’esatto ordine dei termini nel 
documento. 
Viene preso in considerazione solo il numero di occorrenze (
 term 
frequency
 : 
tf
) di ogni termine nel documento. 
In tal modo è possibile rappresentare ogni documento mediante 
un vettore di occorrenze: 
 
10Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17",modello bag words modello ignorato lesatto ordine termini documento viene preso considerazione solo numero occorrenze term frequency ogni termine documento tal modo possibile rappresentare ogni documento mediante vettore occorrenze doc doc doc car auto insurance best
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Machine Learning con Python: 
Introduzione  
",machine learning universit roma tre dipartimento ingegneria anno accademico machine learning python introduzione
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#1,1,"Introduzione al 
Machine Learning con Python   
Testo consigliato:
",introduzione machine learning python testo consigliato
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#10,10,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#11,11,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#12,12,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#13,13,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#14,14,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#15,15,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#16,16,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#17,17,"I dati che useremo per il training e il test possono essere 
visti come segue:
",dati useremo training test possono essere visti segue
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#18,18,"Esempi di valori delle feature presenti in data:
",esempi valori feature presenti data
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#19,19,"Esempi di valori delle specie presenti in target :
",esempi valori specie presenti target
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#2,2,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#20,20,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#21,21,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#22,22,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#23,23,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#24,24,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#25,25,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#26,26,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#27,27,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#28,28,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#29,29,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#3,3,"Testo consigliato:
",testo consigliato
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#30,30,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#31,31,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#32,32,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#4,4,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#5,5,,
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#6,6,"Versioni linguaggio e librerie:
",versioni linguaggio librerie
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#7,7,"Cominciamo con un semplice esempio di classiﬁcation, 
utilizzando il data set Iris.
Questo è un famoso data set che contiene 150 esempi di 
ﬁori iris, descritti da 4 features (lunghezza e larghezza di 
petali e sepali) e appartenenti ad una di tre specie 
differenti:
Iris setosa
Iris versicolor  
Iris virginica  
",cominciamo semplice esempio classication utilizzando data set iris famoso data set contiene esempi ori iris descritti features lunghezza larghezza petali sepali appartenenti tre specie differenti iris setosa iris versicolor iris virginica
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#8,8,"Ecco un esempio di ﬁori iris relativo alle tre specie:
",ecco esempio ori iris relativo tre specie
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#9,9,,
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#0,0,"Intelligenza Artiﬁciale 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione (Ex02)
1",intelligenza articiale universit roma tre dipartimento ingegneria anno accademico esercitazione regressione
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Dataset Better Life Index 
Richiami: Model Selection, Simple Linear Regression, Funzione di Costo 
Libreria Scikit-learn 
Linear Regression in Python 
Esempio: Dataset Diabete 
Linear Regression e Predizione 
Esercitazione su dataset Better Life Index",sommario dataset better life index richiami model selection simple linear regression funzione costo libreria scikit learn linear regression python esempio dataset diabete linear regression predizione esercitazione dataset better life index
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#10,10,"Il modulo 
 linear_model
  di 
sklearn
  implementa l'addestramento basandosi 
su un modello lineare. La funzione di costo di default è la 
 RSS
. 
La funzione 
 ﬁt()
 prende come parametri due arrays 
 X
 e 
y
, effettua 
l'addestramento (o 
 ﬁtting
 ) e memorizza i coefﬁcienti nella variabile 
 coef_
 . 
Ad esempio: 
>>> 
from 
sklearn 
import
 linear_model 
>>> 
reg 
=
 linear_model
 .
LinearRegression() 
>>> 
reg
.
fit([[
0
, 
0
], [
1
, 
1
], [
2
, 
2
]], [
0
, 
1
, 
2
]) 
LinearRegression()  
>>> 
reg
.
coef_ 
array([0.5, 0.5]) 
Nell'esempio si impiegano 2 valori (cioè 2 features) per punto, e la retta ha 
2 coefﬁcienti 
 w
1
. Il valore di 
 w
0
 si ottiene con la variabile 
 intercept_
  del 
modello. 
Nota
 : l'underscore nel nome delle variabili indica che i valori sono ottenuti 
durante l'addestramento, e perciò non sono iperparametri del modello.
Linear Regression in Python
11",modulo linearmodel sklearn implementa laddestramento basandosi modello lineare funzione costo default funzione prende parametri due arrays effettua laddestramento tting memorizza coefcienti variabile coef esempio sklearn import linearmodel reg linearmodel linear regression reg fit linear regression reg coef array nellesempio impiegano valori cio features punto retta coefcienti valore ottiene variabile intercept modello nota lunderscore nome variabili indica valori ottenuti durante perci iperparametri modello linear regression python
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#11,11,"Il modulo 
 metrics
  di 
sklearn
  implementa varie misure di performance. 
https://scikit-learn.org/stable/modules/model_evaluation.html  
Nota: troviamo MSE ma non RSS.
Scikit-learn e le misure di performance
12
",modulo metrics sklearn implementa varie misure performance httpsscikit nota troviamo scikit learn misure performance
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#12,12,"Un dataset diabete è un dataset 
 toy 
(cioè utile per scopi didattici e per 
testare il codice)  
 disponibile all'interno della libreria scikit-learn. 
URL: 
 https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html   
https://scikit-learn.org/stable/datasets/toy_dataset.html   
442 istanze 
10 features reali normalizzate ove richiesto -.2 < x < .2 
age age in years
sex
bmi body mass index
bp average blood pressure
s1 tc, total serum cholesterol
s2 ldl, low-density lipoproteins
s3 hdl, high-density lipoproteins
s4 tch, total cholesterol / HDL
s5 ltg, possibly log of serum triglycerides level
s6 glu, blood sugar level
Target: intero nell'intervallo 25 - 346 che indica quanto la malattia sia 
accresciuta dopo 1 anno
Esempio: dataset diabete
13",dataset diabete dataset toy cio utile scopi didattici testare codice disponibile allinterno libreria scikit learn httpsscikit istanze features reali normalizzate ove richiesto age age years sex bmi body mass index average blood pressure total serum cholesterol ldl low density lipoproteins hdl high density lipoproteins tch total cholesterol ltg possibly log serum triglycerides level glu blood sugar level target intero nellintervallo indica malattia accresciuta dopo anno esempio dataset diabete
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#13,13,"Codice per impiegare il dataset: 
import 
matplotlib.pyplot  
as 
plt 
import 
numpy 
as 
np 
from 
sklearn 
import
 datasets, linear_model 
from 
sklearn.model_selection  
import
 train_test_split 
from 
sklearn.metrics  
import 
mean_squared_error
 , 
r2_score  
# Carico il dataset  
diabetes_X, diabetes_y 
 = 
datasets
 .
load_diabetes
 (return_X_y
 =
True
) 
# Mantengo solo la terza feature  
diabetes_X 
 =
 diabetes_X[:, 
 np
.
newaxis
, 
2
] 
# Suddivido il dataset in training/test 80/20%  
diabetes_X_train,diabetes_X_test,diabetes_y_train, diabetes_y_test 
 =    
  train_test_split(diabetes_X, diabetes_y,test_size=0.2) 
... 
Esercizio
 : completa il codice impiegando un modello lineare, 
visualizzando il valore dei coefﬁcienti e l'errore MSE.
Esempio Python: diabete (1)
14",codice impiegare dataset import plt import numpy sklearn import datasets linearmodel import sklearnmetrics import rscore carico dataset diabetes diabetesy datasets loaddiabetes return true mantengo solo terza feature diabetes diabetes newaxis suddivido dataset trainingtest diabetes diabetesytest esercizio completa codice impiegando modello lineare visualizzando valore coefcienti lerrore esempio python diabete
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#14,14,"# Istanzia un modello di regressione lineare  
regr 
= 
linear_model
 .
LinearRegression
 () 
# Addestramento con funzione di costo RMSE  
regr
.
fit(diabetes_X_train, diabetes_y_train) 
# Ricava le predizioni sul test set  
diabetes_y_pred 
 =
 regr
.
predict(diabetes_X_test) 
# Stampa i parametri del modello  
print
(
""Coefficients: 
 \n
""
, regr
.
coef_) 
# Valuto il MSE  
print
(
""Mean squared error: 
 %.2f
"" 
% 
mean_squared_error
 (diabetes_y_test, diabetes_y_pred)) 
plt
.
scatter
(diabetes_X_test, diabetes_y_test, color
 =
""black""
) 
plt
.
plot
(diabetes_X_test, diabetes_y_pred, color
 =
""blue""
, linewidth
 =
3
) 
plt
.
xticks
(()) 
plt
.
yticks
(()) 
plt
.
show
() 
# Coefficients:   [938.23786125]  
# Mean squared error: 2548.07
Esempio Python: diabete (2)
15
",istanzia modello regressione lineare regr linearmodel linear regression addestramento funzione costo regr fitdiabetes xtrain ricava predizioni test set diabetesypred regr xtest stampa parametri modello print coefficients regr coef valuto print mean squared error plt scatter diabetes xtest color black plt plot diabetes xtest color blue linewidth plt xticks plt yticks plt show coefficients mean squared error esempio python diabete
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#15,15,"Il modulo 
 linear_model
  permette facilmente di fare predizione sui dati. 
La funzione 
 predict()
  prende un array di istanze (una o più features) e 
ricava il valore in base al modello addestrato. 
X_new = [[
 22587
]] 
print
(model.predict(X_new))
Linear Regression e predizione
16",modulo linearmodel permette facilmente fare predizione dati funzione predict prende array istanze una features ricava valore base modello addestrato xnew print linear regression predizione
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#16,16,"Il problema consiste nel determinare i due parametri 
 w
. Chiaramente il 
modello può solo approssimare la correlazione tra i valori.  
Se facciamo più ipotesi, cioè creiamo più modelli, ci occorre una misura di 
performance (o di costo) per confrontarli e scegliere il più adatto.
Esempio: dataset Better Life Index (3)
17PIL pro capiteLivello di soddisfazione
PIL pro capitew0=8w1=-5×10-5
w0=4w1=5×10-5 w0=0w1=2×10-5w0=?
w1=?Livello di soddisfazione",problema consiste determinare due parametri chiaramente modello pu solo approssimare correlazione valori ipotesi cio creiamo modelli occorre misura performance costo confrontarli scegliere adatto esempio dataset better life index pro capite livello soddisfazione pro capiteww ww ww wlivello soddisfazione
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#17,17,"Accedi al seguente notebook dove i dati sono già caricati e formattati per gli step 
successivi:  
https://colab.research.google.com/drive/1apLqC0KAveOkkCT8JuO5kNQyj1GT5Hz9?usp=sharing   
Risolvi i seguenti esercizi: 
Esercizio #1
 : crea e addestra un modello lineare con funzione di costo RSS 
Esercizio #2
 : visualizza i parametri del modello 
Esercizio #3
 : prendi tre campioni random dal dataset e ricava la predizione in base 
al modello addestrato 
Esercizio #4
 : calcola RSS MSE e RMSE valutando i tre campioni 
Esercizio #5
 : suddividi il dataset in input in train e test con un rapporto 80/20 
Esercizio #6
 : addestra nuovamente il modello, e ricava RSS MSE e RMSE sui test set 
Esercizio #7
 : suddividi nuovamente il dataset ma con un rapporto 50/50. Valuta 
nuovamente le performance del modello e discuti eventuali differenze nei valori 
ottenuti.
Esercizio Python: Better Life Index
18",accedi seguente notebook dati gi caricati formattati step successivi kave okk nqyj hzuspsharing risolvi seguenti esercizi esercizio crea addestra modello lineare funzione costo esercizio visualizza parametri modello esercizio prendi tre campioni random dataset ricava predizione base modello addestrato esercizio calcola valutando tre campioni esercizio suddividi dataset input train test rapporto esercizio addestra nuovamente modello ricava test set esercizio suddividi nuovamente dataset rapporto valuta nuovamente performance modello discuti eventuali differenze valori ottenuti esercizio python better life index
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#18,18,"Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016
Testi di Riferimento
19",aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media andreas mller sarah guido introduction machine learning python guide data scientists oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami
Le tecniche di 
 Regressione
  ricadono nell'ambito dell'apprendimento 
Model-based
 , dove  
Si costruisce un modello che rappresenta le caratteristiche dei dati in 
ingresso (es. andamento).  
Tale modello verrà poi impiegato nella fase di 
 predizione
  su istanze in 
ingresso distinte da quelle impiegate durante l'apprendimento.
3
",richiami tecniche regressione ricadono nellambito model based costruisce modello rappresenta caratteristiche dati ingresso andamento tale modello verr poi impiegato fase predizione istanze ingresso distinte impiegate durante
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#3,3,"Datasets
Durante le esercitazioni faremo uso di vari datasets, alcuni reali, altri 
sintetici che ci permetteranno di mettere in evidenza vari aspetti e 
problematiche rilevanti nell'ambito dell'apprendimento automatico.
4",datasets durante esercitazioni uso vari datasets alcuni reali altri sintetici permetteranno mettere evidenza vari aspetti problematiche rilevanti nellambito automatico
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#4,4,"Esempio: dataset Better Life Index (1)
Dataset che lega il benessere (life satisfaction) con indicatori giudicati essenziali 
nella vita quotidiana (es. salario, livello istruzione), suddivisi per nazione. 
https://stats.oecd.org/index.aspx?DataSetCode=BLI  
5
",esempio dataset better life index dataset lega benessere life satisfaction indicatori giudicati essenziali vita quotidiana salario livello istruzione suddivisi nazione set codeb
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#5,5,"Esempio: dataset Better Life Index (2)
Valore del PIL (GDP) annuale 
https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD
6
",esempio dataset better life index valore annuale chw eoo dca ecw
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#6,6,"Se prendiamo i due dataset e creiamo un join, possiamo mettere in 
correlazione due variabili, es. PIL pro capite e livello di soddisfazione 
percepito. 
Si nota come i due valori siano correlati, sebbene non esattamente, con un 
legame lineare. 
Possiamo supporre che esista un modello 
 lineare
  (o 
ordinary least squares
 ) 
che leghi la soddisfazione con il valore del PIL (fase di 
 model selection
 ).
Richiami: Model selection
7
PIL pro capiteLivello di soddisfazione
",prendiamo due dataset creiamo join possiamo mettere correlazione due variabili pro capite livello soddisfazione percepito nota due valori correlati sebbene esattamente legame lineare possiamo supporre esista modello lineare ordinary least squares leghi soddisfazione valore fase model selection richiami model selection pro capite livello soddisfazione
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#7,7,"Richiami: Simple Linear Regression Model
I parametri del modello lineare sono 
 w
0
 e 
w
1
. 
Attenzione: non esiste un formalismo standard per rappresentare i 
parametri, a volte si impiega 
 θ
 o altri simboli. 
I parametri del modello lineare sono 
 w
0
 e 
w
1
.  
Adattando tali valori possiamo deﬁnire qualsiasi modello lineare.
8yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
x
PIL pro capiteLivello di soddisfazione",richiami simple linear regression model parametri modello lineare attenzione esiste formalismo standard rappresentare parametri volte impiega altri simboli parametri modello lineare adattando tali valori possiamo denire qualsiasi modello lineare yiwwxii pro capite livello soddisfazione
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#8,8,"Tipicamente is impiega una misura di costo basata sulla distanza tra valore 
esatto e valore determinato dal modello, come la 
 Residual Sum of Squares  
(RSS), sempre positiva, chiamata anche 
 Sum of Squared Residuals
  (SSR) o 
Sum of Squared estimate of Errors
  (SSE): 
Valori prossimi allo 
 0
 indicano un modello ideale. 
La 
Mean Square Error 
 (MSE), chiamata anche 
 Mean Squared Deviation  
(MSD), corrisponde alla RSS normalizzata sul numero di campioni.  
È utile per valutare il modello ﬁnale dopo l'addestramento.
Richiami: funzione di costo
9RSS( w0,w1)=NX
i=1(yi",tipicamente impiega misura costo basata distanza valore esatto valore determinato modello residual sum squares sempre positiva chiamata sum squared residuals sum squared estimate errors valori prossimi indicano modello ideale mean square error chiamata mean squared deviation corrisponde normalizzata numero campioni utile valutare modello nale dopo richiami funzione costo wwn iyi
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#9,9,"È la libreria con licenza aperta (BSD) più conosciuta di machine learning in 
Python. La prima release risale al 2010.  
https://scikit-learn.org/stable/   
Include gli algoritmi più popolari di classiﬁcazione, regressione, clustering 
(es. support-vector machines, random forests, gradient boosting, k-means e 
DBSCAN). 
Alcune parti del codice sono state scritte in modo altamente efﬁciente con 
varie tecnologie (vedi Cython) 
È facilmente interfacciabile con altre librerie per la gestione e il calcolo 
numerico di dati, es. NumPy (algebra lineare), SciPy (ottimizzazione, 
algebra lineare, analisi dei segnali, etc) e Pandas.
Richiami: la libreria Scikit-learn
10",libreria licenza aperta conosciuta machine learning python prima release risale httpsscikit include algoritmi popolari classicazione regressione clustering support vector machines random forests gradient boosting means alcune parti codice state scritte modo altamente efciente varie tecnologie vedi cython facilmente interfacciabile altre librerie gestione calcolo numerico dati num algebra lineare sci algebra lineare analisi segnali etc pandas richiami libreria scikit learn
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex03)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione regressione classicazione
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Richiami: Classiﬁcazione e Regressione, overﬁtting, underﬁtting 
4 datasets: Forge, Wave, Wisconsin breast cancer, Boston housing 
Classiﬁcazione k-Neighbors e Scikit-learn, decision boundaries 
Misura R
2 
k-Neighbors regression e Scikit-learn 
Esercizi su linear, Ridge e LASSO regressioni su vari dataset",sommario richiami classicazione regressione overtting undertting datasets forge wave wisconsin breast cancer boston housing classicazione neighbors scikit learn decision boundaries misura neighbors regression scikit learn esercizi linear ridge regressioni vari dataset
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#10,10,"Regression: Boston housing dataset
Il dataset di 506 istanze mira a predire il costo degli immobili residenziali in 
vari quartieri di Boston nel 1970, impiegando 13 features (es. il tasso di 
crimine, vicinanza al ﬁume, accessibilità alle autostrade). 
from 
sklearn.datasets 
 import 
load_boston
boston 
= 
load_boston
 ()
print
(
""Data shape: {}""
 .
format
(
boston
.
data
.
shape
))
> Data shape: (506, 13)
È possibile combinare due o più features creandone ulteriori non presenti nel 
dataset originale, attività che rientrano nella fase di 
 feature engineering, 
 dove 
si identiﬁcano o costruiscono le caratteristiche salienti. 
In questo esempio combiniamo 2 features alla volta: 
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
> X.shape: (506, 104)
Ora abbiamo 104 features, ottenute dalle 13 originali con tutte le 91 possibili 
combinazioni di coppie.
11",regression boston housing dataset dataset istanze mira predire costo immobili residenziali vari quartieri boston impiegando features tasso crimine vicinanza ume accessibilit autostrade import loadboston boston loadboston print data shape format boston data shape data shape possibile combinare due features creandone ulteriori presenti dataset originale attivit rientrano fase feature engineering identicano costruiscono caratteristiche salienti esempio combiniamo features volta mglearn datasets print xshape format shape xshape ora features ottenute originali tutte possibili combinazioni coppie
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#11,11,"Classiﬁcazione k-Neighbors (k-NN)
Nel caso più semplice l'algoritmo k-NN considera solo 1 vicino (k=1), che 
risulta il più vicino all'istanza su cui vogliamo esprimere una predizione. 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
1
)
Per k=3: 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
3
)
Per il forge dataset otteniamo:
12
",classicazione neighbors caso semplice lalgoritmo considera solo vicino risulta vicino allistanza vogliamo esprimere predizione mglearn plots nneighbors mglearn plots nneighbors forge dataset otteniamo
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#12,12,"Esercizio: Scikit-learn, k-NN e valutazione
La libreria Scikit-learn rende disponibile la classe 
 KNeighborsClassiﬁer
  per 
creare modelli basati sull'algoritmo k-NN. 
La funzione 
 score
 ()
 valuta l'accuracy media, cioè il numero di label 
correttamente stimate rispetto al totale delle istanze valutate. 
from 
sklearn.neighbors 
 import 
KNeighborsClassifier
model 
= 
KNeighborsClassifier
 (
n_neighbors
 =
3
)
model
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
clf
.
score
(
X_test
, 
y_test
)))
Esercizio
 : (1) prendere il dataset forge, (2) creare una partizione training/
test, (3) addestrare un classiﬁcatore KNeighborsClassiﬁer  
e (4) valutarne 
l'accuratezza. 
13",esercizio scikit learn valutazione libreria scikit learn rende disponibile classe neighbors classier creare modelli basati sullalgoritmo funzione score valuta laccuracy media cio numero label correttamente stimate rispetto totale istanze valutate import neighbors classifier model neighbors classifier nneighbors model fit xtrain ytrain print test set accuracy format clf score xtest ytest esercizio prendere dataset forge creare partizione training test addestrare classicatore neighbors classier valutarne laccuratezza
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#13,13,"k-NN e decision boundaries
In presenza di 2 features è possibile rappresentare su un piano 
 2d
 la classe 
che verrebbe assegnata dal modello per ogni punto del piano, così da 
riconoscere il conﬁne tra una label e l'altra. Sfruttiamo la libreria 
 mglearn
 : 
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
10
, 
3
))
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
 
 clf 
= 
KNeighborsClassifier
 (
n_neighbors
 =
n_neighbors
 )
.
fit
(
X
, 
y
)
  
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
True
, 
eps
=
0.5
, 
ax
=
ax
, 
alpha
=.
4
)
  
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
  
ax
.
set_title
 (
""{} neighbor(s)""
 .
format
(
n_neighbors
 ))
  
ax
.
set_xlabel
 (
""feature 0""
 )
  
ax
.
set_ylabel
 (
""feature 1""
 )
axes
[
0
]
.
legend
(
loc
=
3
)
Quali considerazioni possiamo fare?
14
",decision boundaries presenza features possibile rappresentare piano classe verrebbe assegnata modello ogni punto piano cos riconoscere conne label laltra sfruttiamo libreria mglearn fig axes plt subplots figsize nneighbors zip axes clf neighbors classifier nneighbors nneighbors fit mglearn plots clf fill true eps alpha mglearn settitle neighbors format nneighbors setxlabel feature setylabel feature axes legend loc quali considerazioni possiamo fare
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#14,14,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?
15
",decision boundaries segue modo migliore dati addestramento crea conne dolce modello semplice cosa succede corrisponde numero istanze dataset
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#15,15,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?  
Tutte le istanze avrebbero lo stesso neighbors e le predizioni sarebbero 
sempre le stesse.
16
",decision boundaries segue modo migliore dati addestramento crea conne dolce modello semplice cosa succede corrisponde numero istanze dataset tutte istanze stesso neighbors predizioni sempre stesse
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#16,16,"Esercizio: studio dell'accuracy
Colleziona le accuracy del classiﬁcatore KNeighborsClassiﬁer sul training 
set sia sul test set, al variare di k in [1,10], e valuta gli andamenti. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
66
)
training_accuracy 
 = 
[]
test_accuracy 
 = 
[]
...
plt
.
plot
(
neighbors_settings
 , 
training_accuracy
 , 
label
=
""training accuracy""
 )
plt
.
plot
(
neighbors_settings
 , 
test_accuracy
 , 
label
=
""test accuracy""
 )
plt
.
ylabel
(
""Accuracy""
 )
plt
.
xlabel
(
""n_neighbors""
 )
plt
.
legend
()
17",esercizio studio dellaccuracy colleziona accuracy classicatore neighbors classier training set test set variare valuta andamenti import cancer xtrain xtest ytrain ytest cancer data cancer target stratify cancer target randomstate testaccuracy plt plot label training accuracy plt plot testaccuracy label test accuracy plt ylabel accuracy plt xlabel nneighbors plt legend
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#17,17,"Esercizio: studio dell'accuracy
Con k=1 si ha una accuracy massima per il training set. Con 
 k
 più grandi la 
complessità del modello si riduce e l'accuracy decrementa. 
Al contrario, con 
 k=1 
l'accuracy sul test set è più bassa (circa 0.90), 
sintomo che il modello è 
 troppo complesso
 . Allo stesso modo con 
 k
 elevati 
l'accuracy 
 non è soddisfacente 
 poiché il  
modello è 
 troppo semplice
 . 
Per questo dataset un valore ottimale si ottiene intorno a k=6. 
Attenzione:  solitamente i graﬁci non sono sempre così 
 smooth
 .
18
",esercizio studio dellaccuracy accuracy massima training set grandi complessit modello riduce laccuracy decrementa contrario laccuracy test set bassa circa sintomo modello troppo complesso stesso modo elevati laccuracy soddisfacente poich modello troppo semplice dataset valore ottimale ottiene intorno attenzione solitamente graci sempre cos smooth
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#18,18,"k-neighbors regression
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
1
)
19
",neighbors regression richiami valore predetto corrisponde valore associato allistanza vicina caso mediano valori mglearn plots nneighbors
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#19,19,"k-neighbors regression (2)
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
3
)
20
",neighbors regression richiami valore predetto corrisponde valore associato allistanza vicina caso mediano valori mglearn plots nneighbors
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami: classiﬁcazione e regressione
Finora abbiamo visto problemi di regressione, dove si richiede di predire 
un valore numerico a partire da una istanza in ingresso. 
L'obiettivo della classiﬁcazione è assegnare una 
 label
 ad una istanza in 
ingresso.  
Se le label sono due si parla di 
 binary classiﬁcation
 , altrimenti 
 multiclass
 . 
Il dataset 
 iris
 è un esempio di multiclass classiﬁcation. 
Un modello ben addestrato mostra la capacità di generalizzare sui dati del 
test set, e in fase di produzione. 
Chiaramente se training set e test set hanno molte caratteristiche in 
comune, allora ci aspettiamo che il modello addestrato, se ben progettato, 
sia anche accurato.
3",richiami classicazione regressione finora visto problemi regressione richiede predire valore numerico partire istanza ingresso lobiettivo classicazione assegnare label istanza ingresso label due parla binary classication altrimenti multiclass dataset iris esempio multiclass classication modello ben addestrato mostra capacit generalizzare dati test set fase produzione chiaramente training set test set molte caratteristiche comune allora aspettiamo modello addestrato ben progettato accurato
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#20,20,"Performance: la misura 
 R
2
21
R
2
 è il 
coefﬁciente di determinazione
 , e indica la porzione di varianza della 
variabile y correttamente predetta dal modello (cioè dalle features impiegate), 
perciò è una misura di accuratezza. 
Assume valori in [0,1]. Per valori prossimi a 
 1
 il modello predice 
accuratamente il valore della variabile dipendente 
 y
 in base al valore delle 
features.  
Ad esempio: per 
 R
2
=0.83, il 17% della variazione nei dati non è rappresentato dal 
modello, o perché è dovuto al caso, o perché dipende da un features che non sono stata 
considerate. 
Per valori vicini a 0, il modello si comporta come un predittore che assume 
sempre il valor medio come output, perciò non tiene conto della varianza 
La funzione 
 score()
  del modello Python valuta il valore 
 R
2
 sui dati in input.R2=1−RSS
∑N
i=1(yi−¯y)2=1−∑N
i=1(yi−̂yi)2
∑N
i=1(yi−¯y)2=∑N
i=1(̂yi−¯y)2
∑N
i=1(yi−¯y)2",performance misura coefciente determinazione indica porzione varianza variabile correttamente predetta modello cio features impiegate perci misura accuratezza assume valori valori prossimi modello predice accuratamente valore variabile dipendente base valore features esempio variazione dati rappresentato modello dovuto caso dipende features stata considerate valori vicini modello comporta predittore assume sempre valor medio output perci tiene conto varianza funzione score modello python valuta valore dati inputrr iyiyi iyiyn iyiy iyiy
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#21,21,"scikit-learn: k-neighbors regression
La classe KNeighborsRegressor implementa l'algoritmo di regressione k-neighbors. 
Il parametro 
 n_neighbors
  corrisponde a 
 k
. 
reg 
= 
KNeighborsRegressor
 (
n_neighbors
 =
k
)
Esercizio
 : completa il codice con la classe suddetta e valuta i graﬁci che ottieni:  
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
15
, 
4
))
# create 1,000 data points, evenly spaced between -3 and 3
line 
= 
np
.
linspace
 (
-
3
, 
3
, 
1000
)
.
reshape
(
-
1
, 
1
)
# make predictions using 1, 3, or 9 neighbors
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
...
ax
.
plot
(
line
, 
reg
.
predict
(
line
))
ax
.
plot
(
X_train
, 
y_train
, 
'^'
, 
c
=
mglearn
.
cm2
(
0
), 
markersize
 =
8
)
ax
.
plot
(
X_test
, 
y_test
, 
'v'
, 
c
=
mglearn
.
cm2
(
1
), 
markersize
 =
8
)
ax
.
set_title
 (
""{} neighbor(s)\n train score: {:.2f} test score: {:.2f}""
 .
format
(
n_neighbors
 , 
reg
.
score
(
X_train
, 
y_train
),
reg
.
score
(
X_test
, 
y_test
)))
ax
.
set_xlabel
 (
""Feature""
 )
ax
.
set_ylabel
 (
""Target""
 )
axes
[
0
]
.
legend
([
""Model predictions""
 , 
""Training data/target""
 ,
         
 ""Test data/target""
 ], 
loc
=
""best""
)
22",scikit learn neighbors regression classe neighbors regressor implementa lalgoritmo regressione neighbors parametro nneighbors corrisponde reg neighbors regressor nneighbors esercizio completa codice classe suddetta valuta graci ottieni fig axes plt subplots figsize create data points evenly spaced line linspace reshape make predictions using neighbors nneighbors zip axes plot line reg predict line plot xtrain ytrain mglearn markersize plot xtest ytest mglearn markersize settitle neighborsn train score test score format nneighbors reg score xtrain ytrain reg score xtest ytest setxlabel feature setylabel target axes legend model predictions training datatarget test datatarget loc best
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#22,22,"scikit-learn: k-neighbors regression
Considerando più istanze durante la predizione si ottiene chiaramente una 
curva più 
 smooth
 .
23
",scikit learn neighbors regression considerando istanze durante predizione ottiene chiaramente curva smooth
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#23,23,"k-NN nella pratica
L'algoritmo ha due parametri principali: 
 k
 e la 
 misura di distanza
 . 
In generale, si possono usare bassi valori per 
 k
 (es. 5) sebbene occorra 
sperimentare il valore esatto in base al dataset.  
La 
misura euclidea
  si adatta bene in molti scenari. 
Il k-NN è spesso la scelta iniziale per la sua semplicità, ma in alcuni 
contesti non è adatto: 
Per training set molto grandi (numero di istanze e/o features) che 
causano tempi di predizione lenti, a meno di non precomputare 
l'output in una fase preliminare prima di impiegare l'algoritmo in 
produzione. 
Dataset sparsi, cioè con features spesso senza valore.
24",pratica lalgoritmo due parametri principali misura distanza generale possono usare bassi valori sebbene occorra sperimentare valore esatto base dataset misura euclidea adatta bene molti scenari spesso scelta iniziale semplicit alcuni contesti adatto training set molto grandi numero istanze features causano tempi predizione lenti meno precomputare loutput fase preliminare prima impiegare lalgoritmo produzione dataset sparsi cio features spesso senza valore
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#24,24,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
.
25",esercizio linear regression wave dataset esercizio applicare linear regression wave dataset istanze ricavare parametri modello valutare valore
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#25,25,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
. 
from 
sklearn.linear_model 
 import 
LinearRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
60
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
42
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""lr.coef_: {}""
 .
format
(
lr
.
coef_
))
print
(
""lr.intercept_: {}""
 .
format
(
lr
.
intercept_
 ))
> lr.coef_: [ 0.394]
> lr.intercept_: -0.031804343026759746
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.67
> Test set score: 0.66
Nota: coef_ è di tipo NumPy array, avendo dimensione pari al numero di 
features per istanza. 
Cosa possiamo dire con i valori di performance ottenuti?
26",esercizio linear regression wave dataset esercizio applicare linear regression wave dataset istanze ricavare parametri modello valutare valore import linear regression mglearn datasets makewave nsamples xtrain xtest ytrain ytest randomstate linear regression fit xtrain ytrain print lrcoef format coef print lrintercept format intercept lrcoef lrintercept print training set score format score xtrain ytrain print test set score format score xtest ytest training set score test set score nota coef tipo num array dimensione pari numero features istanza cosa possiamo dire valori performance ottenuti
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#26,26,"Esercizio: linear regression e wave dataset
> Training set score: 0.67
> Test set score: 0.66
Sono valori piuttosto bassi.  
I valori sul training e test set sono molto simili, sintomo di 
 underﬁtting
 .  
Per modelli lineari e dataset semplici (es. mono-dimensionali) esiste un 
rischio minore di fare overﬁtting data la semplicità del modello. 
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.
27",esercizio linear regression wave dataset training set score test set score valori piuttosto bassi valori training test set molto simili sintomo undertting modelli lineari dataset semplici mono dimensionali esiste rischio minore fare overtting data semplicit modello esercizio prova stesso approccio bostong housing dataset confronta performance
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#27,27,"Esercizio: linear regression e wave dataset
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.  
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
0
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.95
> Test set score: 0.61
La differenza tangibile tra training e test set è sintomo di overﬁtting. 
Occorre adattare il modello. 
28",esercizio linear regression wave dataset esercizio prova stesso approccio bostong housing dataset confronta performance mglearn datasets xtrain xtest ytrain ytest randomstate linear regression fit xtrain ytrain print training set score format score xtrain ytrain print test set score format score xtest ytest training set score test set score differenza tangibile training test set sintomo overtting occorre adattare modello
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#28,28,"Richiami: Ridge regression
Nella 
 ridge regression
  si implementa un forma semplice di 
regolarizzazione
 , cioè tecniche per affrontare il problema del overﬁtting. 
I parametri 
 w
 del modello lineare devono rispettare un vincolo 
aggiuntivo: il valore assoluto dei singoli parametri deve essere piccolo.  
Intuitivamente:
  ogni feature può avere un effetto limitato sul valore 
predetto dal modello. 
Prende il nome di L2 regularization. 
La funzione che rappresenta il costo nella ridge è la seguente:
29
",richiami ridge regression ridge regression implementa forma semplice cio tecniche affrontare problema overtting parametri modello lineare devono rispettare vincolo aggiuntivo valore assoluto singoli parametri deve essere piccolo intuitivamente ogni feature pu avere effetto limitato valore predetto modello prende nome regularization funzione rappresenta costo ridge seguente
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#29,29,"Scikit-learn: Ridge regression
La classe 
 Ridge
  nel modulo sklearn.linear_model implementa la ridge 
regression: 
clf 
=
 Ridge(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro 
 alpha,
  che per default assume valore 1. 
30",scikit learn ridge regression classe ridge modulo implementa ridge regression clf ridgealpha parametro controlla peso denito mediante parametro alpha default assume valore
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#3,3,"Richiami: overﬁtting e underﬁtting
Supponiamo di avere il seguente dataset che rappresenta la possibilità che 
un cliente acquisti una barca in base a certe sue caratteristiche: 
Se guardi questi dati, che proﬁlo di cliente potenzialmente interessato a 
comprare puoi identiﬁcare dalle features riportate?
4
",richiami overtting undertting supponiamo avere seguente dataset rappresenta possibilit cliente acquisti barca base certe guardi dati prolo cliente potenzialmente interessato comprare puoi identicare features riportate
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#30,30,"Esercitazione: Ridge regression
Esercizio
 : impiegare la ridge regression nel Boston housing dataset.  
Cosa ti aspetti dalle performance che ottieni rispetto alla linear regression 
senza regolarizzazione? 
Esercizio
 : ricava gli score per 
 λ
 pari a 0.1 e 10. Cosa ti aspetti? 
Esercizio
 : crea un graﬁco 2d dove visualizzi i parametri dei tre modelli 
ridge
 , 
ridge10
  e 
ridge01
 . Cosa ti aspetti nella distribuzione dei parametri? 
Esercizio
 : Come pensi che vari lo score 
 R
2
, sul training e sul test set, al 
variare del numero di istanze usate durante l'addestramento?
31",esercitazione ridge regression esercizio impiegare ridge regression boston housing dataset cosa aspetti performance ottieni rispetto linear regression senza esercizio ricava score pari cosa aspetti esercizio crea graco visualizzi parametri tre modelli ridge ridge ridge cosa aspetti distribuzione parametri esercizio pensi vari score training test set variare numero istanze usate durante
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#31,31,"Richiami: LASSO
Nel modello 
 LASSO
  si impiega la 
 L1-regularization
 , dove alcuni parametri 
assumono valore esattamente pari a 0, ignorando perciò alcune features. 
Può essere interpretato come una sorta di 
 feature selection
 , cioè un 
processo per selezionare le feature più rilevanti nel task in esame. 
Il vantaggio è avere un modello più semplice, più veloce da addestrare, che 
considera solo le features più rilevanti.
32
",richiami modello impiega regularization alcuni parametri assumono valore esattamente pari ignorando perci alcune features pu essere interpretato sorta feature selection cio processo selezionare feature rilevanti task esame vantaggio avere modello semplice veloce addestrare considera solo features rilevanti
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#32,32,"Scikit-learn: LASSO
La classe 
 Lasso
  nel modulo sklearn.linear_model implementa il modello 
LASSO:  
clf 
=
 Lasso(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro alpha, che per default assume valore 1. 
Esercizio
 : impiegare LASSO nel Boston housing dataset. Cosa ti aspetti 
dalle performance che ottieni rispetto alla linear e Ridge regression?
33",scikit learn classe lasso modulo implementa modello clf lassoalpha parametro controlla peso denito mediante parametro alpha default assume valore esercizio impiegare boston housing dataset cosa aspetti performance ottieni rispetto linear ridge regression
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#33,33,"Esercitazione: LASSO
Esercizio
 : impiega LASSO nel Boston housing dataset 
Esercizio
 : prova a variare nuovamente 
 λ
 per migliorare le performance. 
34",esercitazione esercizio impiega boston housing dataset esercizio prova variare nuovamente migliorare performance
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#34,34,"Ridge e LASSO: considerazioni
Solitamente si impiega la Ridge come primo approccio.  
Nel caso ci siano molte features, ma solo un sottoinsieme verosimilmente 
rilevanti, LASSO risulta la scelta migliore. 
LASSO inoltre produce modelli più semplici e più facilmente interpretabili 
rispetto a Ridge, utile per investigare il dataset nelle fasi iniziali. 
Scikit-learn implementa la classe 
 ElasticNet
  che combina i due approcci e 
ottiene ottime performance, ma con due iperparametri da impostare, uno 
per L1 e uno per L2 regularization.
35",ridge considerazioni solitamente impiega ridge primo approccio caso molte features solo sottoinsieme verosimilmente rilevanti risulta scelta migliore inoltre produce modelli semplici facilmente interpretabili rispetto ridge utile investigare dataset fasi iniziali scikit learn implementa classe elastic net combina due approcci ottiene ottime performance due iperparametri impostare regularization
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#35,35,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
36",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#4,4,"Richiami: overﬁtting e underﬁtting (2)
Cliente di 
 45 anni o più
 , 
meno di 3 ﬁgli
  o 
non divorziato
 . 
Questa ""regola"" è al 
 100%
  accurata. 
Ma una regola sull'età del tipo età=66 OR 52 OR 53 OR 58 è altrettanto 
accurata. 
Dobbiamo ricordarci che il modello dovrà funzionare altrettanto 
accuratamente su dati mai visti in precedenza. 
Le regole che abbiamo escogitato sembrano funzionare, ma sono troppo 
speciﬁche per le istanze del nostro dataset. Se nel test set abbiamo istanze 
simili, allora questo semplice modello può funzionare, ma non è detto che 
funzioni anche in produzione.
5",richiami overtting undertting cliente anni meno gli divorziato regola accurata regola sullet tipo et altrettanto accurata dobbiamo ricordarci modello dovr funzionare altrettanto accuratamente dati mai visti precedenza regole escogitato sembrano funzionare troppo speciche istanze dataset test set istanze simili allora semplice modello pu funzionare detto funzioni produzione
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#5,5,"Richiami: overﬁtting e underﬁtting (3)
Il nostro obiettivo è sempre trovare il modello più semplice che abbia 
buone performance anche sul test set. 
Costruire un modello troppo complesso rispetto ai dati disponibili crea 
overﬁtting
 .  
Il modello è troppo speciﬁco per le istanze nel training set ma non è capace di 
generalizzare sui dati nel test set. 
Un modello troppo semplice rispetto ai dati disponibili può creare 
fenomeni di 
 underﬁtting
 , cioè scarse performance perﬁno nel training set 
poiché non riesce a catturare tutte le caratteristiche e legami tra le features.
6
",richiami overtting undertting obiettivo sempre trovare modello semplice buone performance test set costruire modello troppo complesso rispetto dati disponibili crea overtting modello troppo specico istanze training set capace generalizzare dati test set modello troppo semplice rispetto dati disponibili pu creare fenomeni undertting cio scarse performance perno training set poich riesce catturare tutte caratteristiche legami features
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#6,6,"4 datasets
Introduciamo 4 datasets utili per osservare come si comportano diversi 
algoritmi di machine learning implementati in scikit-learn. 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Wisconsin Breast Cancer dataset
  (classiﬁcazione) 
Boston housing dataset
  (regressione)
7",datasets introduciamo datasets utili osservare comportano diversi algoritmi machine learning implementati scikit learn forge dataset wave dataset regressione wisconsin breast cancer dataset boston housing dataset regressione
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#7,7,"Classiﬁcazione: Forge dataset
26 istanze, 2 features per istanza, e 2 classi: 
# codice per ottenere il dataset
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
# grafico le istanze
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 ], 
loc
=
4
)
plt
.
xlabel
(
""First feature""
 )
plt
.
ylabel
(
""Second feature""
 )
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
8
",classicazione forge dataset istanze features istanza classi codice ottenere dataset mglearn datasets makeforge grafico istanze mglearn plt legend class class loc plt xlabel first feature plt ylabel second feature print xshape format shape
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#8,8,"Regressione: wave dataset
Singola feature per istanza, singolo valore reale in output. 
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
40
)
plt
.
plot
(
X
, 
y
, 
'o'
)
plt
.
ylim
(
-
3
, 
3
)
plt
.
xlabel
(
""Feature""
 )
plt
.
ylabel
(
""Target""
 )
Per dataset così piccoli è sempre utile studiare le caratteristiche delle 
istanze su graﬁci.
9
",regressione wave dataset singola feature istanza singolo valore reale output mglearn datasets makewave nsamples plt plot plt ylim plt xlabel feature plt ylabel target dataset cos piccoli sempre utile studiare caratteristiche istanze graci
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#9,9,"Classiﬁcazione: Wisconsin Breast Cancer dataset
Misure cliniche associate a patologie tumorali, con label '
 benigno
 ' '
maligno
 '  
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
print
(
""cancer.keys(): \n{}""
 .
format
(
cancer
.
keys
()))
> cancer.keys():
> dict_keys(['feature_names', 'data', 'DESCR', 'target', 'target_names'])
print
(
""Shape of cancer data: {}""
 .
format
(
cancer
.
data
.
shape
))
> Shape of cancer data: (569, 30)
print
(
""Sample counts per class:\n{}""
 .
format
(
{
n
: 
v 
for 
n
, 
v 
in 
zip
(
cancer
.
target_names
 , 
np
.
bincount
 (
cancer
.
target
))}))
> Sample counts per class: {'benign': 357, 'malignant': 212}
print
(
""Feature names:\n{}""
 .
format
(
cancer
.
feature_names
 ))
> Feature names:
['mean radius' 'mean texture' 'mean perimeter' 'mean area'
'mean smoothness' 'mean compactness' 'mean concavity'
'mean concave points' 'mean symmetry' 'mean fractal dimension'
'radius error' 'texture error' 'perimeter error' 'area error'
'smoothness error' 'compactness error' 'concavity error'
'concave points error' 'symmetry error' 'fractal dimension error'
'worst radius' 'worst texture' 'worst perimeter' 'worst area'
'worst smoothness' 'worst compactness' 'worst concavity'
'worst concave points' 'worst symmetry' 'worst fractal dimension']
10",classicazione wisconsin breast cancer dataset misure cliniche associate patologie tumorali label benigno maligno import cancer print cancerkeys format cancer keys cancerkeys data target print shape cancer data format cancer data shape shape cancer data print sample counts classn format zip cancer targetnames bincount cancer target sample counts class benign malignant print feature namesn format cancer featurenames feature names mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension radius error texture error perimeter error area error smoothness error compactness error concavity error concave points error symmetry error fractal dimension error worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Alberi di Decisione
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico classicazione alberi decisione machine learning
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#1,1,"Sommario
Introduzione ai Decision Trees 
Esempio di applicazione 
Feature split learning 
Decision Stump 
Algoritmo greedy decision tree learning 
Classiﬁcazione mediante Decision Trees
 
2",sommario introduzione decision trees esempio applicazione feature split learning decision stump algoritmo greedy decision tree learning classicazione mediante decision trees
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#10,10,"Learning Goal 
 
11
Il nostro obiettivo è dunque quello di costruire un albero di 
decisione che minimizzi il Classiﬁcation Error sui dati di 
training, calcolato mediante la metrica di qualità che 
abbiamo deﬁnita. 
Purtroppo questo è un task estremamente difﬁcile: 
•abbiamo un numero esponenziale di possibili alberi da considerare  
•problema NP-hard 
•possiamo però utilizzare delle euristiche che funzionano bene in 
pratica",learning goal obiettivo dunque costruire albero decisione minimizzi classication error dati training calcolato mediante metrica qualit denita purtroppo task estremamente difcile abbiamo numero esponenziale possibili alberi considerare problema hard possiamo per utilizzare euristiche funzionano bene pratica
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#11,11,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto” e consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai diversi valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
12Vediamo informalmente come poter procedere per costruire un albero di 
decisione:",algoritmo greedy decision tree learning cominciamo albero vuoto consideriamo esempi disponibili selezioniamo feature migliore possiamo partizionare split dati base diversi valori essa pu assumere ogni split altre operazioni fare costruire foglia previsione altrimenti continua costruzione dellalbero partire split considerando vediamo informalmente poter procedere costruire albero decisione
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#12,12,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
13Primo problema:
feature
 selection",algoritmo greedy decision tree learning cominciamo albero vuoto consideriamo esempi disponibili selezioniamo feature migliore possiamo partizionare split dati base vari valori essa pu assumere ogni split altre operazioni fare costruire foglia previsione altrimenti continua costruzione dellalbero partire split considerando primo problema feature selection
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#13,13,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
14Secondo problema:
stopping conditions",algoritmo greedy decision tree learning cominciamo albero vuoto consideriamo esempi disponibili selezioniamo feature migliore possiamo partizionare split dati base vari valori essa pu assumere ogni split altre operazioni fare costruire foglia previsione altrimenti continua costruzione dellalbero partire split considerando secondo problema stopping conditions
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#14,14,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
15Chiamata ricorsiva:
chiamata ricorsiva",algoritmo greedy decision tree learning cominciamo albero vuoto consideriamo esempi disponibili selezioniamo feature migliore possiamo partizionare split dati base vari valori essa pu assumere ogni split altre operazioni fare costruire foglia previsione altrimenti continua costruzione dellalbero partire split considerando chiamata ricorsiva chiamata ricorsiva
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#15,15,"Predizioni con Decision Stump 
[feature selection]
 
1622  18
SicuroRoot node: relativo a tutte le osservazioni. 
22: output “Sicuro” 
18: output “Rischioso” 
Ora dobbiamo selezionare una feature  
(feature selection problem)",predizioni decision stump feature selection sicuro root node relativo tutte osservazioni output sicuro output rischioso ora dobbiamo selezionare feature feature selection problem
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#16,16,"Predizioni con Decision Stump 
[feature: Reputazione]
 
17Reputazione22  18
SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Se scegliamo “Reputazione”:",predizioni decision stump feature reputazione reputazione sicuro scarsa eccellente sufciente scegliamo reputazione
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#17,17,"Decision Stump 
[feature: Reputazione]
 
18SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
set  ŷ = “majority value” ",decision stump feature reputazione sicuro reputazione rischioso sicuro scarsa eccellente sufciente set majority value
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#18,18,"Decision Stump 
[feature: Reputazione]
 
19SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori",decision stump feature reputazione sicuro reputazione rischioso sicuro scarsa eccellente sufciente errori errori errori
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#19,19,"Decision Stump 
[feature: Durata]
 
20SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14Se scegliamo “Durata”:
4 errori 6 errori",decision stump feature durata sicuro durata rischioso anni anni scegliamo durata errori errori
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#2,2,"Alberi di Decisione 
Vediamo ora un altro metodo per la classiﬁcazione, molto 
utile nella pratica. 
Un albero di decisione prende come ingresso un oggetto o 
una situazione descritta da un insieme di attributi (features) e 
restituisce una “decisione”. 
Effettua dunque una “classiﬁcazione” della situazione 
presentata in input.  
 
3",alberi decisione vediamo ora altro metodo classicazione molto utile pratica albero decisione prende ingresso oggetto situazione descritta insieme attributi features restituisce decisione effettua dunque situazione presentata input
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#20,20,"Selezione della migliore feature 
[feature selection]
 
21SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Dobbiamo deﬁnire un criterio per la scelta della migliore feature:
vs.",selezione migliore feature feature selection sicuro durata rischioso anni anni sicuro reputazione rischioso sicuro scarsa eccellente sufciente dobbiamo denire criterio scelta migliore feature
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#21,21,"Selezione della migliore feature 
[feature selection]
 
22SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 erroriPer far questo consideriamo gli errori già visti in precedenza …….
vs.",selezione migliore feature feature selection sicuro durata rischioso anni anni sicuro reputazione rischioso sicuro scarsa eccellente sufciente errori errori errori errori errori far consideriamo errori gi visti precedenza
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#22,22," 
23SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 errori…… e usiamoli per calcolare il Classiﬁcation Error per ogni feature:
vs.4+4
22 + 18=0 .24+6
22 + 18=0 .25
Scegliamo la feature con il Classiﬁcation Error più basso.
Selezione della migliore feature 
[feature selection]",sicuro durata rischioso anni anni sicuro reputazione rischioso sicuro scarsa eccellente sufciente errori errori errori errori errori usiamoli calcolare classication error ogni feature scegliamo feature classication error basso selezione migliore feature feature selection
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#23,23,"Calcolo Classiﬁcation Error 
Abbiamo dunque diviso il calcolo del Classiﬁcation Error in 
due fasi: 
1.
 Per ogni nodo relativo ad un sottoinsieme dei dati, ottenuto 
considerando uno dei possibili valori della feature 
d’interesse, assegniamo il valore della majority class del 
nodo (
 ŷ
 = “majority class”). 
2.
 Calcolo del Classiﬁcation Error considerando come  
predizione per ogni nodo considerato quella assegnata nel 
passo precedente. 
 
24",calcolo classication error dunque diviso calcolo classication error due fasi ogni nodo relativo sottoinsieme dati ottenuto considerando possibili valori feature dinteresse assegniamo valore majority class nodo majority class calcolo classication error considerando predizione ogni nodo considerato assegnata passo precedente
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#24,24,"Algoritmo per  
Feature Split Selection 
Dato un sottoinsieme M di osservazioni disponibili (nodo 
dell’albero): 
• 
∀
 feature 
 ɸ
j
(
x
): 
•
 Split dei dati M in  base ai valori della feature 
 ɸ
j
(
x
). 
•
 Calcolo del Classiﬁcation Error per il Decision Stump 
della feature 
 ɸ
j
(
x
). 
•
 Scelta della feature 
 ɸ
j*
(
x
) con il Classiﬁcation Error più 
basso. 
 
25",algoritmo feature split selection dato sottoinsieme osservazioni disponibili nodo dellalbero feature split dati base valori feature calcolo classication error decision stump feature scelta feature classication error basso
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#25,25,"Tree Learning 
[recursive stump learning]
 
26SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9    0 9    4 4    14
costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Sufﬁciente costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Scarsa 
foglia dell’alberoLa costruzione dell’albero si effettua come segue:",tree learning recursive stump learning sicuro reputazione scarsa eccellente sufciente costruire decision stump sotto insieme dati cui reputazione sufciente costruire decision stump sotto insieme dati cui reputazione scarsa foglia dellalbero costruzione dellalbero effettua segue
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#26,26,"Tree Learning 
[secondo livello]
 
27SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0",tree learning secondo livello sicuro reputazione scarsa eccellente sufciente durata rischioso sicuro anni anni
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#27,27,"Tree Learning 
[secondo livello]
 
28SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0Reddito
RischiosoAlto Modesto
0     9 4     5
altro 
decision 
stump",tree learning secondo livello sicuro reputazione scarsa eccellente sufciente durata rischioso sicuro anni anni reddito rischioso alto modesto altro decision stump
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#28,28,"Tree Learning 
[terzo livello]
 
29Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3",tree learning terzo livello scarsa reddito rischioso alto modesto sicuro rischioso durata anni anni
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#29,29,"Tree Learning 
[stopping conditions]
 
30Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3 stopping conditions?",tree learning stopping conditions scarsa reddito rischioso alto modesto sicuro rischioso durata anni anni stopping conditions
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#3,3,"Esempio di applicazione 
[valutazione richiesta prestito]
 
4Richiesta 
PrestitoModello di 
ClassiﬁcazioneSicuro
Rischioso
Input: xi(Output: y i = +1)
(Output: y i = -1)
Vediamo un esempio di applicazione, relativo alla 
valutazione di richieste di prestito da parte di un cliente alla 
propria banca:",esempio applicazione valutazione richiesta prestito richiesta prestito modello classicazione sicuro rischioso input xioutput output vediamo esempio applicazione relativo valutazione richieste prestito parte cliente propria banca
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#30,30,"Stopping Conditions 
La costruzione di un ramo dell’albero si ferma quando arriviamo 
ad un nodo nel quale si veriﬁca una delle seguenti condizioni: 
1.
 Gli esempi relativi al nodo sono tutti di uno stesso tipo (e.g., 
tutti 
Sicuro
  o tutti 
 Rischioso
 ): scegliamo come foglia il valore in 
questione. 
2.
 Gli esempi relativi al nodo sono di tipo diverso, e non ci sono 
più feature da considerare: scegliamo come foglia il majority 
value. 
3.
 Nel nodo non ci sono più esempi, ma c’è ancora qualche 
feature non considerata nel percorso che porta a quel nodo: 
valore di default (e.g., maggioranza nodo genitore). 
 
31",stopping conditions costruzione ramo dellalbero ferma quando arriviamo nodo verica seguenti condizioni esempi relativi nodo stesso tipo sicuro rischioso scegliamo foglia valore questione esempi relativi nodo tipo diverso feature considerare scegliamo foglia majority value nodo esempi c ancora qualche feature considerata percorso porta quel nodo valore default maggioranza nodo genitore
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#31,31,"Algoritmo greedy decision tree 
learning 
1. Start da un nodo relativo a M esempi 
2. Feature Selection 
3. Per ogni split: 
if
  Stopping Condition 
then
: costruire la foglia con la previsione 
 ŷ 
else
:  decision_tree_learning(nodo relativo allo split) 
 
32decision_tree_learning (nodo) 
Chiamata RicorsivaNon ci sono altre 
operazioni da fareSelezione Feature  
per dividere i dati",algoritmo greedy decision tree learning start nodo relativo esempi feature selection ogni split stopping condition costruire foglia previsione else relativo split nodo chiamata ricorsiva altre operazioni fare selezione feature dividere dati
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#32,32,"Algoritmo per fare previsioni 
mediante Decision Tree 
Vediamo ora il semplice algoritmo che implementa la funzione 
T(
x
), ossia l’algoritmo che, a fronte di un ingresso 
 x
i
, visita l’albero 
di decisione costruito nella fase di training e fornisce in output una 
previsione 
 ŷ
i
: 
 
33 
if
 tree_node corrente è una foglia 
         
 then
: 
return
  majority class dei punti relativi alla foglia 
        
 else
: 
•
next_node = ﬁglio di tree_node il cui valore della feature 
corrisponde all’input 
•
return
  predict(next_node, input) predict (tree_node, input) ",algoritmo fare previsioni mediante decision tree vediamo ora semplice algoritmo implementa funzione ossia lalgoritmo che fronte ingresso visita lalbero decisione costruito fase training fornisce output previsione treenode corrente foglia return majority class punti relativi foglia else nextnode glio treenode valore feature corrisponde allinput return input predict treenode input
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#33,33,"Riferimenti
 
34
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning classication university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#4,4,"Esempio di applicazione 
Nel formulare questo problema come un problema di 
apprendimento dobbiamo anzitutto decidere quali proprietà, 
o attributi (features), sono disponibili per descrivere esempi 
(osservazioni) nel dominio. 
In genere, alcune delle caratteristiche prese in considerazione 
i tali casi sono le seguenti: 
•
  reputazione cliente (e.g., ha pagato regolarmente vecchi prestiti?) 
•
reddito cliente 
•
durata prestito  
•
  altre informazioni personali (età, motivo per il prestito, ecc.)  
 
5",esempio applicazione formulare problema problema apprendimento dobbiamo anzitutto decidere quali propriet attributi features disponibili descrivere esempi osservazioni dominio genere alcune caratteristiche prese considerazione tali casi seguenti reputazione cliente pagato regolarmente vecchi prestiti reddito cliente durata prestito altre informazioni personali et motivo prestito ecc
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#5,5,"Decision Tree Classiﬁer 
 
6Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniEsempio di decision tree per il problema in esame:",decision tree classier sicuro durata reddito reputazione start sicuro rischioso rischioso rischioso sicuro durata scarsa eccellente sufciente alto modesto anni anni anni anni esempio decision tree problema esame
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#6,6,"Valutazione richiesta prestito 
 
7
Sicuro
DurataRedditoReputazioneStart
Sicuro
Rischioso
Rischioso
Rischioso
SicuroDurataScarsa
Eccellente
Sufﬁciente
Alto
Modesto
3 anni
5 anni
3 anni
5 annixi = (Reputazione = Scarsa , Reddito = Alto, Durata = 5 anni)  ",valutazione richiesta prestito sicuro durata reddito reputazione start sicuro rischioso rischioso rischioso sicuro durata scarsa eccellente sufciente alto modesto anni anni anni annixi reputazione scarsa reddito alto durata anni
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#7,7," 
8Richiesta 
PrestitoModello di 
Classiﬁcazione
Input: xiSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1)
Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniRichiesta 
PrestitoSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1) Input: xi
Decision Tree Model 
T(xi)",richiesta prestito modello classicazione input sicuro output sicuro durata reddito reputazione start sicuro rischioso rischioso rischioso sicuro durata scarsa eccellente sufciente alto modesto anni anni anni anni richiesta prestito sicuro output input decision tree model txi
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#8,8,"Apprendimento albero dai dati
 
9
Reputazione Durata Reddito yi
eccellente 3 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
sufﬁciente 3 anni alto Rischioso
scarso 5 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
scarso 3 anni alto Rischioso
scarso 5 anni modesto Rischioso
sufﬁciente 3 anni alto Rischioso
eccellente 3 anni modesto SicuroT(xi)
Vediamo come sia possibile costruire (ossia apprendere) un decision 
tree a partire da un certo numero di osservazioni:  
Minimizzazione  
funzione di costo",apprendimento albero dati reputazione durata reddito eccellente anni alto sicuro sufciente anni modesto sicuro sufciente anni alto rischioso scarso anni alto sicuro sufciente anni modesto sicuro scarso anni alto rischioso scarso anni modesto rischioso sufciente anni alto rischioso eccellente anni modesto sicuro txi vediamo possibile costruire ossia apprendere decision tree partire certo numero osservazioni minimizzazione funzione costo
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#9,9,"Metrica di Qualità 
[quality metric]
 
10Errore =#previsioni errate
#esempi
La metrica che si usa misura la frazione delle previsioni 
errate fornite dall’albero:
Ovviamente: 
• miglior valore possibile: 0.0 
• peggior valore possibile: ?",metrica qualit quality metric errore previsioni errate esempi metrica usa misura frazione previsioni errate fornite dallalbero ovviamente miglior valore possibile peggior valore possibile
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Algoritmo C4.5",machine learning universit roma tre dipartimento ingegneria anno accademico classicazione algoritmo
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#1,1,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error  
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5
2",algoritmi induzione algoritmo greedy decision tree learning scelta migliore feature utilizzando metrica classification error dati training problema hard servono euristiche algoritmo
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#10,10,"Guadagno
Introduciamo ora il Guadagno (Gain)  di un attributo A 
Calcolo di Gain(S,A) per ciascun attributo A 
•Riduzione di Entropia attesa a seguito dell’ordinamento del 
set di istanze S basato su A 
Scelta dell’attributo con il valore di Guadagno più elevato 
come nodo dell’albero 
Gain(S,A) = Entropy(S) – Expectation(A)  
 
 
 
dove {S1 ... Si ... Sn} sono le partizioni di S secondo i valori 
dell’attributo A, n il numero di valori distinti di A, |Si| il 
numero di istanze nella partizione Si e |S| il numero totale di 
istanze in S)( )( ),(
1in
iiS EntropySSS Entropy AS Gain ∗ − = ∑
=
11",guadagno introduciamo ora guadagno gain attributo calcolo gainsa ciascun attributo riduzione entropia attesa seguito set istanze basato scelta dellattributo valore guadagno elevato nodo dellalbero gainsa entropys expectationa partizioni secondo valori dellattributo numero valori distinti numero istanze partizione numero totale istanze entropy entropy gain
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#11,11,"Scelta Nodo Radice
Se Outlook è radice dell’albero ci 
sono 3 partizioni sulle istanze (S1 per 
Sunny , S2 per Cloudy, S3 per Rainy ) 
S1 (Sunny) = {istanze 1,2,8,9,11} 
|S1| = 5 (di queste 5 istanze, i 
valori per Play sono 3 No e 2 Yes) 
Entropy(S1) =  
= -2/5 (log2 2/5) – 3/5 (log2 3/5) =        
= -0.4 (-1.322) – 0.6 (-0.737) =  
= 0.53 +0.44 = 0.97 
Analogamente si ottiene  
 Entropy(S2) = 0  
 Entropy(S3) = 0.97 
 12",scelta nodo radice outlook radice dellalbero partizioni istanze sunny cloudy rainy sunny istanze istanze valori play yes entropys log log analogamente ottiene entropys entropys
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#12,12,"Scelta Nodo Radice
Gain(S,Outlook) = Entropy(S) – Expectation(Outlook) = 
= Entropy(S) – [|S1|/|S| * Entropy(S1) + |S2|/|S| * Entropy(S2) +  
+ |S3|/|S| * Entropy(S3)] = 0.94 – [5/14 * 0.97 + 4/14 * 0 + 5/14 * 0.97]  
da cui si ottiene 
Gain(S,Outlook) = 0.247 
Analogamente 
Gain(S,Temperature) = 0.029 
Gain(S,Humidity) = 0.152 
Gain(S,Windy) = 0.048  
In conclusione Gain(S,Outlook)  è il guadagno più elevato e quindi 
Outlook dovrebbe essere scelto come radice dell’Albero di Decisione  
13",scelta nodo radice gainsoutlook entropys entropys entropys entropys entropys ottiene gainsoutlook analogamente gainswindy conclusione gainsoutlook guadagno elevato quindi outlook dovrebbe essere scelto radice dellalbero decisione
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#13,13,"Scelta Nodi Successivi 
Ripetiamo il procedimento per il ramo 
 Sunny
  …
temperatureoutlook
rainy sunnycloudy
hot mild cold?
0    2 1    1 1    04    0
windyoutlook
rainy sunnycloudy
false?
true
1    2 1    14    0 humidityoutlook
rainy sunnycloudy
high?
normal
0    3 2    04    0
14
",scelta nodi successivi ripetiamo procedimento ramo sunny rainy sunnycloudy hot mild cold windyoutlook rainy sunnycloudy false true humidityoutlook rainy sunnycloudy high normal
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#14,14,"Scelta Nodi Successivi 
… e per il ramo Rainy
humidityoutlook
rainy sunnycloudy
high normalMild High False Yes
Cool Normal False Yes
Cool Normal True No
Mild Normal False Yes
Mild High True NoNo Yes Yes 
15
",scelta nodi successivi ramo rainy humidityoutlook rainy sunnycloudy high normal mild high false yes cool normal false yes cool normal true mild normal false yes mild high true yes yes
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#15,15,"humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normal
Decision Tree 
windy
high
No Yes falseIn conclusione, si ottiene il seguente Albero di Decisione
16
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza",humidityoutlook rainy sunnycloudy true yes yes normal decision tree windy high yes false conclusione ottiene seguente albero decisione nodi interni test attributi feature archi uscenti risultati test nodi foglia etichette classe appartenenza
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#16,16,"Scelta Nodo Radice 
La selezione dell’attributo come nodo radice è eseguita 
valutando il Guadagno di Informazione (Information Gain)  per 
ciascun attributo e scegliendo quello che dà il valore maggioreQual è l’attributo migliore per essere nodo radice dell’albero?
outlook
rainy sunnycloudyhumidity
low hightemperature
cold hotmildwindy
false true
2     
34     
04     
23     
13     
23     
46     
12     
26     
23     
3
17",scelta nodo radice selezione dellattributo nodo radice eseguita valutando guadagno informazione information gain ciascun attributo scegliendo valore maggiore qual lattributo migliore essere nodo radice dellalbero outlook rainy low hightemperature cold hotmildwindy false true
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#17,17,"Algoritmo C4.5
N.B. Pure: all instances in the subset fall in the same classSet di dati (tabella) attributo-valore
18",algoritmo pure instances subset fall class set dati tabella attributo valore
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#18,18,"Algoritmo C4.5
Salvatore Ruggieri. 2000. Efficient C4.5.  Technical Report. University of 
Pisa.  
Abstract: We present an analytic evaluation  of the run-time behavior  of the 
C4.5 algorithm which highlights some efficiency improvements. We have 
implemented a more efficient version of the algorithm, called EC4.5, that 
improves on C4.5 by adopting the best among three strategies at each node 
construction. The first strategy uses a binary search of thresholds instead of 
the linear search of C4.5. The second strategy adopts a counting sort method 
instead of the quicksort of C4.5. The third strategy uses a main-memory 
version of the RainForest algorithm for constructing decision trees. Our 
implementation computes the same decision trees as C4.5 with a 
performance gain of up to 5 times.
19",algoritmo salvatore ruggieri efficient technical report university pisa abstract present analytic evaluation run time behavior algorithm highlights efficiency improvements implemented efficient version algorithm called improves adopting best among three strategies node construction first strategy uses binary search thresholds instead linear search second strategy adopts counting sort method instead quicksort third strategy uses main memory version rain forest algorithm constructing decision trees implementation computes decision trees performance gain times
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#19,19,"Esercizio
Creare l’Albero di Decisione (Indice) per la  
Previsione di Rischio per Richieste di Prestito
20",esercizio creare lalbero decisione indice previsione rischio richieste prestito
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#2,2,"Algoritmo C4.5
 J. Ross Quinlan. 1993. C4.5: Programs for Machine Learning.   
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. 
 X. Wu, V. Kumar, J. R. Quinlan , J. Ghosh, Q. Yang, H. Motoda, G. J. 
McLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J. 
Hand, and D. Steinberg. 2007. Top 10 Algorithms in Data Mining.  
Knowledge and Information Systems , Volume 14, Issue 1, December 
2007, Pages 1-37, Springer-Verlag New York, Inc. New York, NY, USA.  
DOI=http://dx.doi.org/10.1007/s10115-007-0114-2  
3",algoritmo ross quinlan programs machine learning morgan kaufmann publishers inc san francisco kumar quinlan ghosh yang motoda lachlan liu zhou steinbach hand steinberg top algorithms data mining knowledge information systems volume issue december pages springer verlag new york inc new york
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#20,20,"Esercizio
21",esercizio
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#21,21,"Esercizio
( ) )( )( ,)( )(log )(
12
1
An Expectatio S Entropy AS GainS EntropySSAn Expectatiop p S Entropy
in
iiin
ii
− =∗ =∗− =
∑∑
==
22",esercizio log expectatio entropy gain entropy expectatiop entropy iiin
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#22,22,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer  
23",algoritmi induzione algoritmo greedy decision tree learning scelta migliore feature utilizzando metrica classification error dati training problema hard servono euristiche algoritmo scelta migliore feature utilizzando metrica information gain dati training problema risolvibile tramite strategia divideconquer
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#23,23,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
24",algoritmi induzione algoritmo greedy decision tree learning scelta migliore feature utilizzando metrica classification error dati training problema hard servono euristiche algoritmo scelta migliore feature utilizzando metrica information gain dati training problema risolvibile tramite strategia divideconquer algoritmo
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#24,24,"Algoritmo CART
Breiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984). 
Classification and Regression Trees.  Monterey, CA: Wadsworth & 
Brooks/Cole Advanced Books & Software. 
25",algoritmo breiman leo friedman olshen stone classification regression trees monterey wadsworth brookscole advanced books software
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#25,25,"Algoritmo CART
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Si basa sul Gini Index (o Indice di Gini) 
In corrispondenza di un certo nodo t dell’albero in costruzione, e rispetto alla 
corrispondente partizione del dataset di training, si definisce l’Indice di Gini 
come segue: 
 
      dove p(j/t) è la frequenza relativa (proporzione) della classe j  al nodo t  
L’Indice di Gini misura l’ impurezza ( o disordine)  del dataset corrispondente a t 
•Massimo valore ( 1-1/n c, con nc=numero di classi equiprobabili) quando i 
record sono equamente distribuiti fra tutte le classi 
•Minimo valore (0) quando tutti i record appartengono a una sola classeGini(t)=1−∑
j[p(j/t)]2
26",algoritmo obiettivo generare albero decisione tabella dati basa gini index indice gini corrispondenza certo nodo dellalbero costruzione rispetto corrispondente partizione dataset training definisce lindice gini segue pjt frequenza relativa proporzione classe nodo lindice gini misura impurezza disordine dataset corrispondente massimo valore ncnumero classi equiprobabili quando record equamente distribuiti fra tutte classi minimo valore quando record appartengono sola classe ginit jpjt
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#26,26,"Indice di Gini
           
Nel caso di una sola classe: 
                                                     
Nel caso di nc classi equiprobabili 
                                               
 
       dove n è il numero di record del dataset al nodo tGini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−12=0
Gini(t)=1−∑
j((n/nc)/n)2=1−∑
j(1/nc)2=1−nc(1/nc)2=1−1/nc
27",indice gini caso sola classe caso classi equiprobabili numero record dataset nodo ginit jpjt ginit ginit
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#27,27,"Indice di Gini
           
C1=0, C2=6 —> P(C1)=0/6=0 , P(C2)=6/6=1  
                             
C1=1, C2=5 —> P(C1)=1/6 , P(C2)=5/6  
                                    
C1=2, C2=4 —> P(C1)=2/6 , P(C2)=4/6  
                                    
C1=3, C2=3 —> P(C1)=3/6=0.5 , P(C2)=3/6=0.5  
                                   Gini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−P(C1)2−P(C2)2=1−0−1=0
Gini(t)=1−1/62−5/62=0.278
Gini(t)=1−2/62−4/62=0.444
Gini(t)=1−0.52−0.52=0.500
28",indice gini ginit jpjt
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#28,28,"Algoritmo CART
29
Criterio di Splitting: Minimizzare l’Indice di Gini della suddivisione  
Quando un nodo t è suddiviso in k partizioni (figli), la qualità della suddivisione è 
calcolata come:  
 
 
 
 
dove  
   ni = numero di record della partizione (figlio) i 
   n = numero di record del dataset al nodo t 
   n i/n = peso dei vari Gini(i) 
Dato il dataset associato al nodo t, si sceglie l’attributo che fornisce il più piccolo 
Gini split(t) per partizionare il dataset 
•E’ necessario enumerare tutti i possibili punti di splitting per ciascun attributo, 
ovverosia tutte le possibili partizioni   
 Ginisplit=k
∑
i=1ni/n*Gini(i)",algoritmo criterio splitting minimizzare lindice gini suddivisione quando nodo suddiviso partizioni figli qualit suddivisione calcolata come numero record partizione figlio numero record dataset nodo peso vari ginii dato dataset associato nodo sceglie lattributo fornisce piccolo gini splitt partizionare dataset e necessario enumerare possibili punti splitting ciascun attributo ovverosia tutte possibili partizioni ginisplitk ininginii
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#29,29,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
•Scelta della migliore feature utilizzando come metrica il Gini Index   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
30",algoritmi induzione algoritmo greedy decision tree learning scelta migliore feature utilizzando metrica classification error dati training problema hard servono euristiche algoritmo scelta migliore feature utilizzando metrica information gain dati training problema risolvibile tramite strategia divideconquer algoritmo scelta migliore feature utilizzando metrica gini index dati training problema risolvibile tramite strategia divideconquer
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#3,3,"Algoritmo C4.5
4",algoritmo
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#4,4,"Algoritmo C4.5
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Sviluppato da J. R. Quinlan nel 1993 come estensione dell’ Algoritmo ID3   
L’Albero ottenuto può essere usato per la classificazione, per cui 
l’Algoritmo C4.5  è spesso indicato come Statistical Classifier 
Basato sulla Teoria dell’Informazione (Claude E. Shannon, A Mathematical 
Theory of Communication , 1948) 
Strategia “divide and conquer” (suddivisione del problema in 
sottoproblemi più semplici e loro risoluzione ricorsiva):  
•Scelta di uno degli attributi come nodo radice 
•Creazione ramo per ciascun valore di quell’attributo 
•Suddivisione delle istanze lungo i rami 
•Ripetizione del processo per ciascun ramo finché tutti le istanze nel ramo hanno 
la stessa classe di appartenenza (si dice che tutti i sottoalberi sono “puri”)  
Assunzione di fondo: quanto più semplice  è l’albero che classifica le 
istanze, tanto meglio  è
 5",algoritmo obiettivo generare albero decisione tabella dati sviluppato quinlan estensione dell algoritmo lalbero ottenuto pu essere usato lalgoritmo spesso indicato statistical classifier basato teoria claude shannon mathematical theory communication strategia divide conquer suddivisione problema sottoproblemi semplici risoluzione ricorsiva scelta attributi nodo radice creazione ramo ciascun valore quellattributo suddivisione istanze lungo rami ripetizione processo ciascun ramo finch istanze ramo stessa classe appartenenza dice sottoalberi puri assunzione fondo semplice lalbero classifica istanze tanto meglio
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#5,5,"Entropia
Introduciamo il concetto di Entropia (Entropy) [(dal greco antico ἐν   
en, ""dentro"", e τροπή  tropé, “trasformazione"")] 
Entropia in Meccanica Statistica: grandezza interpretata come 
misura del disordine presente in un sistema fisico qualsiasi, 
incluso - come caso limite - l’universo 
Entropia in Teoria dell’Informazione: quantità di incertezza o 
informazione presente in un segnale aleatorio 
•Primo Teorema di Shannon (Codifica di Sorgente): “Una 
sorgente casuale d’informazione non può essere rappresentata 
con un numero di bit (da cui la base 2 del logaritmo) inferiore 
alla sua entropia, cioè alla sua autoinformazione media.”  
Tale teorema ha quindi un’implicazione in termini di 
rappresentazione dati, in quanto l’Entropia può essere 
interpretata anche come la minima complessità descrittiva di 
una variabile aleatoria, ovvero il limite inferiore della 
compressione dei dati 
 6",entropia introduciamo concetto entropia entropy dal greco antico dentro trop entropia meccanica statistica grandezza interpretata misura disordine presente sistema fisico qualsiasi incluso caso limite luniverso entropia teoria quantit incertezza informazione presente segnale aleatorio primo teorema shannon codifica sorgente una sorgente casuale dinformazione pu essere rappresentata numero bit base logaritmo inferiore entropia cio media tale teorema quindi unimplicazione termini dati lentropia pu essere interpretata minima complessit descrittiva variabile aleatoria ovvero limite inferiore compressione dati
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#6,6,"Tabella di Dati
7
",tabella dati
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#7,7,"Decision Tree
8humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normalwindy
high
No Yes false
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza",decision tree rainy sunnycloudy true yes yes normalwindy high yes false nodi interni test attributi feature archi uscenti risultati test nodi foglia etichette classe appartenenza
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#8,8,"Entropia
Intro duciamo il concetto di Entropia (Entropy) di un set di istanze  
S è un set di istanze (i.e., record della tabella) 
A è una feature (Play nell’esempio) 
{S1 ... Si ... Sn} sono le partizioni  di S secondo gli n valori che può 
assumere A (“Yes” e “No”  nell’esempio) 
{p1 ... pi ... pn} sono le proporzioni  di {S1 ... Si ... Sn} in S 
Si definisce Entropia di S la seguente grandezza
( ) ∑
=∗− =n
ii i p p S Entropy
12log )(
9",entropia intro duciamo concetto entropia entropy set istanze set istanze record tabella feature play nellesempio partizioni secondo valori pu assumere yes no nellesempio proporzioni definisce entropia seguente grandezza entropy log
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#9,9,"Entropia
Nel caso dell’esempio 
S è il set di 14 istanze 
L’obiettivo è classificare le istanze secondo i valori della 
feature Play, ossia “Yes” e “No”  
La proporzione delle istanze con valore “Yes” è 9 su 14 
(9/14=0.64) 
La proporzione delle istanze con valore “No” è 5 su 14 
(5/14=0.36) 
L’Entropia misura l’ impurezza di S e in questo caso vale  
Entropy(S)= - 0.64 (log2 0.64) – 0.36 (log2 0.36)=  
= - 0.64 (- 0.644) – 0.36 (- 1.474) = 0.41 + 0.53 = 0.94 
10",entropia caso dellesempio set istanze lobiettivo classificare istanze secondo valori feature play ossia yes no proporzione istanze valore yes proporzione istanze valore no lentropia misura impurezza caso vale entropys log log
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcation:  
Boosting",machine learning universit roma tre dipartimento ingegneria anno accademico classication boosting
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#1,1,"Sommario
Introduzione 
Ensemble Learning 
Boosting 
AdaBoost
 
2",sommario introduzione ensemble learning boosting ada boost
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#10,10,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
11
Ogni classiﬁcatore esprime un voto in base al valore della 
feature relativa. 1
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
f1(xi) = -1 f2(xi) = +1 f3(xi) = -12 3
",ensemble classier lidea considerare certo numero classicatori che fronte input forniscono previsione ogni classicatore esprime voto base valore feature relativa sicuro reputazione rischioso sicuro scarsa eccellente sufciente rischioso anni anni durata sicuro buone condizioni mercato sicuro input reputazione scarsa durata anni condizioni mercato cattive fxi fxi fxi
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#11,11,"Ensemble Model 
I vari voti espressi dai classiﬁcatori sono combinati insieme 
come segue per formulare la previsione ﬁnale: 
 
12
Se il segno è positivo la previsione vale +1, se è negativo vale -1. 
Questo è un semplice esempio di Ensemble Classiﬁer. 
Si segnala l’importanza dei pesi w
 i
, che devono essere 
individuati mediante un processo di training. F(xi) = sign[w 1 * f 1(xi) + w 2 * f 2(xi) + w 3 * f 3(xi)]",ensemble model vari voti espressi classicatori combinati insieme segue formulare previsione nale segno positivo previsione vale negativo vale semplice esempio ensemble classier segnala limportanza pesi devono essere individuati mediante processo training fxi signw
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#12,12,"Riepilogo sugli 
Ensemble Classiﬁer 
Obiettivo: 
•
 predire un output 
 ŷ
 (+1 o -1 nell’esempio) a partire da un 
input 
 x 
 
13
Apprendimento dell’Ensemble Model: 
• Classiﬁers: f 1(x), f2(x), …, f T(x) 
• Coefﬁcienti: ŵ1, ŵ2, …, ŵT 
Predizione: 
ˆy= sign[TX
t=1ˆwtft(x)]",riepilogo ensemble classier obiettivo predire output nellesempio partire input apprendimento dellensemble model classiers coefcienti predizione signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#13,13,"Boosting 
xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizionef1(xi)
ŷi = sign[f 1(xi)]
Consideriamo un problema di apprendimento automatico per  
la classiﬁcazione: 
 
14",boosting esempidati training signf consideriamo problema apprendimento automatico classicazione
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#14,14," 
15Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito",credito reddito sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro apprendimento decision stump kreddito
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#15,15," 
16Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1",credito reddito sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro apprendimento decision stump kreddito
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#16,16," 
17Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1
Sicuro",credito reddito sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro apprendimento decision stump kreddito sicuro
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#17,17," 
18Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
4     3 3     1
Sicuro",credito reddito sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro apprendimento decision stump kreddito sicuro
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#18,18," 
19Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
Sicuro4     3 3     1
Sicuro",credito reddito sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro apprendimento decision stump kreddito sicuro sicuro
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#19,19,"L’esempio precedente ci mostra che il decision stump non è 
riuscito a catturare adeguatamente le informazioni dal numero 
limitato di dati disponibili. 
 
20
Quello che fa il Boosting è considerare il decision stump, lo 
valuta, vede come classiﬁca i vari punti, e addestra un 
successivo decision stump (un successivo classiﬁcatore) con il 
quale si focalizza soprattutto sui punti dove il precedente 
classiﬁcatore era debole. Boosting: focus sugli “hard points” ",lesempio precedente mostra decision stump riuscito catturare adeguatamente informazioni numero limitato dati disponibili boosting considerare decision stump valuta vede classica vari punti addestra successivo decision stump successivo classicatore focalizza soprattutto punti precedente classicatore debole boosting focus hard points
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#2,2,"Boosting question 
 
3
Can a set of weak learners be combined to create a stronger learner? 
(Kearns e Valiant, 1988, 1989)
Sì!!  —>  Boosting  
(Schapire, 1990)
",boosting question set weak learners combined create stronger learner kearns valiant boosting schapire
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#20,20," 
21xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
Valutazione
Individuazione
punti critici
(2° classiﬁcatore)Apprendimentoyif1(xi)
… e così viaŷiBoosting:  focus sugli “hard points” 
l’algoritmo di apprendimento 
focalizza l’attenzione 
sui punti “critici”",esempidati training predizione valutazione individuazione punti critici cos viai boosting focus hard points lalgoritmo apprendimento focalizza lattenzione punti critici
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#21,21,"Apprendimento su Dati Pesati 
[weighted data]
L’idea è quella di dare maggiore attenzione ai data points 
ritenuti maggiormente importanti: 
•
 ogni data point (
 x
i
, y
i
) è pesato mediante un 
 α
i 
•
 più il punto è ritenuto importante, più è elevato il peso 
 α
i  
•
 l’algoritmo di apprendimento rimane lo stesso 
 
22",apprendimento dati pesati weighted data lidea dare maggiore attenzione data points ritenuti maggiormente importanti ogni data point pesato mediante punto ritenuto importante elevato peso lalgoritmo apprendimento rimane stesso
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#22,22," 
23Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Redditopeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]",credito reddito peso sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro kredditopeso incrementato punti erroneamente classicati apprendimento dati pesati weighted data
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#23,23," 
24Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Reddito
2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]",credito reddito peso sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro kreddito sicuropeso incrementato punti erroneamente classicati apprendimento dati pesati weighted data
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#24,24," 
25Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9Rischioso≤100K$ >100K$Reddito
3     6.5 2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]",credito reddito peso sicuro rischioso rischioso sicuro sicuro sicuro rischioso rischioso sicuro sicuro sicuro rischioso kreddito sicuropeso incrementato punti erroneamente classicati apprendimento dati pesati weighted data
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#25,25,"Apprendimento su Dati Pesati 
[weighted data]
Tale approccio comporta che: 
•
 Ogni punto i (
 x
i
, y
i
) conta come 
 α
i
 punti.  
•
 L’algoritmo di apprendimento rimane lo stesso. 
L’apprendimento su dati pesati non è solo relativo ai decision 
stumps. 
Esso si può applicare a molti algoritmi di Machine Learning  
•
 ad esempio, nel gradient ascent per la logistic regression: 
 
26w(t+1)
j w(t)
j+⌘·NX
i=1",apprendimento dati pesati weighted data tale approccio comporta che ogni punto conta punti lalgoritmo apprendimento rimane stesso lapprendimento dati pesati solo relativo decision stumps esso pu applicare molti algoritmi machine learning esempio gradient ascent logistic regression jn
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#26,26,"Boosting   
Algoritmo Greedy per l’apprendimento di “ensemble” dai 
dati. 
Si avvale di weak learners usati come black box.  
Weak Learning Assumption
 : ciascun weak learner deve 
avere prestazioni migliori di un classiﬁcatore “random”. 
Nel Boosting i base classiﬁers sono addestrati in sequenza.  
Per migliorare le prestazioni di un weak learner, l’algoritmo 
deve poter manipolare i dati in ingresso, altrimenti si 
ottengono sempre gli stessi risultati 
 
27",boosting algoritmo greedy lapprendimento ensemble dati avvale weak learners usati black box weak learning assumption ciascun weak learner deve avere prestazioni migliori classicatore random boosting base classiers addestrati sequenza migliorare prestazioni weak learner lalgoritmo deve poter manipolare dati ingresso altrimenti ottengono sempre risultati
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#27,27,"Boosting framework 
Step principali: 
 
28xi(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
(2° classiﬁcatore e ŵ)Apprendimentof1(xi)
… e così viaŷi = sign[f1(xi)]
ŷi = sign[ŵ1*f1(xi) + ŵ 2*f2(xi)]Individuazione
punti critici
e ricalcolo pesi
Predizioneŵ, f2(xi)weighted data
Idea del Boosting: aggiungere via via 
nuovi classiﬁcatori ottimizzando i pesi 
per focalizzarsi sui punti critici per poi 
apprendere i coefﬁcienti dei diversi 
classiﬁcatori. ",boosting framework step principali xin esempidati training predizione classicatore cos viai signfxi signfxi punti critici ricalcolo pesi predizione fxiweighted data idea boosting aggiungere via via nuovi classicatori ottimizzando pesi focalizzarsi punti critici poi apprendere coefcienti diversi classicatori
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#28,28,"AdaBoost 
[Adaptive Boosting]
Proposto da Yoav Freund e Robert E. Schapire nel 1996. 
I due autori hanno vinto il Gödel Prize nel 2003. 
Algoritmo estremamente utile e facile da implementare.  
 
29Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese Society 
for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. Riferimenti:
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in:  Thirteenth  
International Conference on Machine Learning , 1996, pp. 148-156. ",ada boost adaptive boosting proposto yoav freund robert schapire due autori vinto gdel prize algoritmo estremamente utile facile implementare freund schapire short introduction boosting ournal japanese society articial intelligence riferimenti schapire freund boosting foundations algorithms press freund schapire experiments new boosting algorithm thirteenth international conference machine learning
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#29,29,"AdaBoost 
[Adaptive Boosting]
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
(
minimizza funzione di costo
 ) 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
30ˆy= sign[TX
t=1ˆwtft(x)]",ada boost adaptive boosting apprendi pesi minimizza funzione costo calcola coefciente ricalcola pesi calcola predizione nale signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#3,3,"Introduzione al Boosting 
Il Boosting è una potente tecnica per combinare molti 
classiﬁcatori “di base” (detti anche “weak learners”) per produrre 
una forma di comitato le cui prestazioni sono di gran lunga 
migliori di ciascuno dei classiﬁcatori. 
Originariamente progettato per risolvere problemi di 
classiﬁcazione, può anche essere esteso alla regressione 
(Friedman, 2001).  
 
4",introduzione boosting boosting potente tecnica combinare molti classicatori di base detti weak learners produrre forma comitato prestazioni gran lunga migliori ciascuno classicatori originariamente progettato risolvere problemi classicazione pu essere esteso regressione friedman
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#30,30,"Evidenziamo qui il processo di training dei vari classiﬁcatori, basato su 
una forma pesata dei punti del training set (linee rosse). 
Ogni peso dipende dalle prestazioni del precedente classiﬁcatore (linee 
verdi)
 
31f1(x) fT(x){↵(1)
i} {↵(T)
i}
f2(x)······
······{↵(2)
i}
ˆy= sign[TX
t=1ˆwtft(x)]
Boosting framework ",evidenziamo qui processo training vari classicatori basato forma pesata punti training set linee rosse ogni peso dipende prestazioni precedente classicatore linee verdi tx fx signt twtftx boosting framework
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#31,31,"Dobbiamo risolvere i seguenti due problemi: 
1. come calcolare il coefﬁciente 
 ŵ
t  
(qual è la mia 
“ﬁducia” in f
 t
(
x
) ?) 
2. come ricalcolare i pesi 
 α
i 
(individuare i punti “critici”) 
 
32
AdaBoost 
[Adaptive Boosting]",dobbiamo risolvere seguenti due problemi calcolare coefciente qual ducia ricalcolare pesi individuare punti critici ada boost adaptive boosting
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#32,32,"Il peso 
 ŵ
t
 rappresenta un “grado di ﬁducia” nella 
 f
t
. Pertanto:
 
33
1° problema: 
Calcolo del coefﬁciente 
 ŵ
t 
ft(x) buona?
ŵt elevato ŵt bassosi no
Una funzione è considerata “buona” se ha un basso training error 
Vediamo come misurare l’errore nel caso di dati “pesati” (“weighted 
classiﬁcation error”) ",peso rappresenta grado ducia pertanto problema calcolo coefciente ftx buona elevato bassosi funzione considerata buona basso training error vediamo misurare lerrore caso dati pesati weighted classication error
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#33,33,"Weighted Classiﬁcation Error 
La misura di un errore pesato è simile a quella di un errore calcolato 
su dati non pesati. 
 
34
Vediamo un semplice esempio: 
Data point i yi αi ŷi risultato
1 +1 1.2 +1
 👍
2 -1 0.5 +1
 👎
3 -1 0.7 -1
 👍
… … … …
peso previsioni corrette 1.9
peso previsioni errate 0.5",weighted classication error misura errore pesato simile errore calcolato dati pesati vediamo semplice esempio data point risultato peso previsioni corrette peso previsioni errate
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#34,34,"Weighted Classiﬁcation Error 
Peso totale degli errori = 
 
35NX
i=1↵iI[ˆyi 6=yi]
NX
i=1↵i
 Peso totale di tutti i data points = 
L’errore “pesato” misura la frazione del peso degli errori: 
weighted error =peso totale degli errori
peso totale di tutti i data points=PN
i=1↵iI[ˆyi 6=yi]
PN
i=1↵i
Miglior valore: 0.0    Peggior valore: random classiﬁer ",weighted classication error peso totale errori ii iyi ii peso totale data points lerrore pesato misura frazione peso errori weighted error peso totale errori peso totale data pointsp ii iyi ii miglior valore peggior valore random classier
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#35,35,"Calcolo del coefﬁciente 
 ŵ
t 
[per il classiﬁcatore f
 t
(
x
)]
La formula usata in 
AdaBoost è la seguente:
 
36   
sui training dataŵt
0.01 (1 - 0.01)/0.01 = 99 +2.3
0.5 (1 - 0.5)/0.5 = 1 0
0.99 (1 - 0.99)/0.99 = 0.01 -2.31",calcolo coefciente per classicatore formula usata ada boost seguente training datat
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#36,36,"2° problema: Ricalcolo pesi alfa
Come sappiamo, dobbiamo focalizzarci soprattutto sui data point 
dove la funzione commette errori: 
 
37↵i ⇢↵i·e",problema ricalcolo pesi alfa sappiamo dobbiamo focalizzarci soprattutto data point funzione commette errori ie
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#37,37,"2° problema: Ricalcolo pesi alfa 
Vediamo un esempio:
 
38↵i ⇢↵i·e",problema ricalcolo pesi alfa vediamo esempio ie
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#38,38,"Normalizzazione pesi alfa 
La normalizzazione dei pesi 
 α
i
 è suggerita dal fatto che:  
•
 se la funzione sbaglia spesso la classiﬁcazione di 
 x
i
, il peso 
 α
i 
tende ad assumere valori molto alti 
•
 se la funzione prevede spesso correttamente la classiﬁcazione 
di 
x
i
, il peso 
 α
i 
tende ad assumere valori molto bassi 
Tutto ciò può causare instabilità numerica dopo varie iterazioni. 
Si normalizza come segue in modo tale che, dopo ogni iterazione, 
la somma dei pesi 
 α
i
 risulti sempre uguale ad 1:
 
39↵i ↵iPN
j=1↵j",normalizzazione pesi alfa normalizzazione pesi suggerita fatto che funzione sbaglia spesso classicazione peso tende assumere valori molto alti funzione prevede spesso correttamente classicazione peso tende assumere valori molto bassi ci pu causare instabilit numerica dopo varie iterazioni normalizza segue modo tale che dopo ogni iterazione somma pesi risulti sempre uguale jj
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#39,39,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
40ˆy= sign[TX
t=1ˆwtft(x)]",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#4,4,"Introduzione al Boosting 
Suo impatto per il Machine Learning: 
approccio di default per molti task di computer vision (e.g., 
face detection) 
numerose applicazioni nell’industria 
vince molte “ML competitions” (Kaggle, KDD Cup, ecc.): 
•   
malware classiﬁcation 
•
credit fraud detection 
•
sales forecasting 
•
Higgs boson detection, ecc., ecc.  
Si basa sul concetto di Ensamble Learning  
 
5",introduzione boosting impatto machine learning approccio default molti task computer vision face detection numerose applicazioni nellindustria vince molte competitions kaggle cup ecc malware classication credit fraud detection sales forecasting higgs boson detection ecc ecc basa concetto ensamble learning
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#40,40,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
41ˆy= sign[TX
t=1ˆwtft(x)]",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#41,41,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
42ˆy= sign[TX
t=1ˆwtft(x)]ˆwt=1
2ln⇣
1",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt ln
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#42,42,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
43ˆy= sign[TX
t=1ˆwtft(x)]",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#43,43,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
44ˆy= sign[TX
t=1ˆwtft(x)]↵i ⇢↵i·e",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftxi ie
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#44,44,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
45ˆy= sign[TX
t=1ˆwtft(x)]",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftx
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#45,45,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
46ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftxi jj
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#46,46,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
47ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j↵i ⇢↵i·e",ada boost apprendi pesi calcola coefciente ricalcola pesi normalizza pesi calcola predizione nale signt twtftxi jji ie
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#47,47,"Riferimenti 
 
48Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese 
Society for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. 
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in: 
Thirteenth  International Conference on Machine Learning , 1996, pp. 148-156. 
Friedman, J.H. “Greedy Function Approximation: A Gradient Boosting Machine”, in: 
Annals of Statistics , 29(5), 2001, pp. 1189-1232. Schapire, R.E.  “The Strength of Weak Learnability”, in: Machine Learning , 5(2), 1990, 
pp. 197–227.
Machine Learning: Classiﬁcation, University of Washington - Coursera, 2017.",riferimenti freund schapire short introduction boosting ournal japanese society articial intelligence schapire freund boosting foundations algorithms press freund schapire experiments new boosting algorithm thirteenth international conference machine learning friedman greedy function approximation gradient boosting machine annals statistics schapire the strength weak learnability machine learning machine learning classication university washington coursera
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#5,5,"Weak Classiﬁers
L’idea è quella di partire da Simple (o Base o Weak) 
Classiﬁers, come ad es.:  
 
6SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente+
++++-
--
-+
+
Logistic Regression 
con semplici featuresShallow 
Decision TreeDecision Stump
Essi in genere sono caratterizzati da bassa varianza (scarso 
overﬁtting) ma alto bias. ",weak classiers lidea partire simple base weak classiers sicuro reputazione rischioso sicuro scarsa eccellente sufciente logistic regression semplici features shallow decision tree decision stump essi genere caratterizzati bassa varianza scarso overtting alto bias
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#6,6,"Andamento Errori  
e Bias-Variance Trade-off
 
7
L’andamento del training error e del true error per la classiﬁcation è in 
genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e variance.True Error
Training Error
Model ComplexityClassiﬁcation
Error
(Weak Learner)",andamento errori bias variance trade landamento training error true error classication genere seguente dobbiamo solito considerare trade bias variancetrue error training error model complexity classication error weak learner
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#7,7," 
8
Un approccio per migliorare un classiﬁcatore può essere quello di 
aggiungere più features al classiﬁcatore, ad es.: 
•
 logistic regression: polinomio di grado più elevato, cercando di 
evitare l’overﬁtting 
•
 decision trees: aumentare la profondità dell’albero 
Nel Boosting si fa qualcosa di diverso: si parte da un insieme di weak 
classiﬁers i cui risultati sono opportunamente combinati per ottenere 
uno strong classiﬁer.
Introduzione al Boosting ",approccio migliorare classicatore pu essere aggiungere features classicatore logistic regression polinomio grado elevato cercando evitare lovertting decision trees aumentare profondit dellalbero boosting qualcosa diverso parte insieme weak classiers risultati opportunamente combinati ottenere strong classier introduzione boosting
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#8,8,"Ensemble Classiﬁer 
Alla base del Boosting c’è l’idea dell’Ensemble Classiﬁer, che 
ora vedremo. 
Consideriamo un weak classiﬁer, ad esempio un Decision 
Stump:  
 
9
Esso, a fronte del valore della feature d’interesse, restituisce 
un risultato (+1 o -1). SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Input: xi
Output: ŷ = f( xi)",ensemble classier base boosting c lidea dellensemble classier ora vedremo consideriamo weak classier esempio decision stump esso fronte valore feature dinteresse restituisce risultato sicuro reputazione rischioso sicuro scarsa eccellente sufciente input output
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#9,9,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
101
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
2 3",ensemble classier lidea considerare certo numero classicatori che fronte input forniscono previsione sicuro reputazione rischioso sicuro scarsa eccellente sufciente rischioso anni anni durata sicuro buone condizioni mercato sicuro input reputazione scarsa durata anni condizioni mercato cattive
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Overﬁtting e Regularization
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico classicazione overtting regularization machine learning
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#1,1,"Sommario
Introduzione 
Overﬁtting nella Classiﬁcazione 
Regolarizzazione 
L2 Penalty 
L1 Penalty (sparse solutions)
 
2",sommario introduzione overtting classicazione penalty penalty sparse solutions
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#10,10,"Funzione di Qualità 
nel caso L
 2
 Penalty
 
11
Questo è il caso in cui usiamo la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L2 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.    
                                           Qualit` a totaleL2=l n L(w)",funzione qualit caso penalty caso usiamo somma quadrati regularization funzione rappresenta qualit totale caso logistic regression regularized logistic regression seguente parametro tuning parameter serve bilanciare due termini qualit totale
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#11,11," 
12Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞: 
0<kˆwk2
2<kˆwMLEk2
2
<latexit sha1_base64=""GbN8PXIxssjt4tSdrVsj583mbQM="">AAACT3icdVBNSyNBFOyJ3/Erq0cvjUHwFGaioAcP4rLgQUHBRCEThzedpzbp+aD7ja408+P2J+zRg2ev7mlv4kycg0YtaCiq6vFeV5gqach1H5zaxOTU9MzsXH1+YXFpufFjpWuSTAvsiEQl+iIEg0rG2CFJCi9SjRCFCs/D4c/SP79FbWQSn9F9iv0IrmN5JQVQIQWNnsv3uK+6qIn7YaIG1r8Bsnd5/iYGtp1fFu+7VGB9wt9kj49+jY/Ug0bTbbkj8M/Eq0iTVTgJGo/+IBFZhDEJBcb0PDelvgVNUijM635mMAUxhGvsFTSGCE3fjkrI+UZmgBKeouZS8ZGI7ycsRMbcR2GRjIBuzLhXil95vYyudvtWxmlGGItyEUmFo0VGaFm0i3wgNRJBeTlyGXMBGohQSw5CFGJW1F324Y3//jPptlveVqt9ut3cP6iamWVrbJ1tMo/tsH12yE5Yhwn2hz2xZ/bP+ev8d15qVbTmVGSVfUBt7hUB/7VE</latexit>
Funzione di Qualità 
nel caso L
 2
 Penalty",vediamo cosa accade fronte diversi valori parametro riconduciamo vecchia soluzione ossia massimizzazione likelihood soluzioni costo totale lunica soluzione massimizzare qualit kwk kw latexit shabasegb ixssjtt sdr vsjmb qma cticd nsy foy jerqcvj uhw fgaio ethzedpzbpa djap rgevmlvkycg yta ciqv vgqach hzax mzs xhy xfpuf fjp avsi eqli iegr jci fcsdcs fiv irm wnnsvu igr bsndi ygtpf bwtkjj yugb tbbkj meqi jgoi jbcb pdelvg uij uxh gvs cefjkr zmg bkeou iycs rmbc grj ibuz xilv yyudvt wxml ity eum vga fmiwg jbe tly goh qsw pptlve vqtutc piam wvrb mots yhwnhzx pevdq svf ubth velatexit funzione qualit caso penalty
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#12,12," 
13Come già visto nel caso della Regressione, per la 
determinazione del parametro λ non usiamo mai il Test Set. Ci 
avvaliamo invece: 
del Validation Set , se abbiamo a disposizione un 
numero sufﬁcientemente elevato di osservazioni; 
della Cross-Validation , se abbiamo a disposizione un 
numero limitato di osservazioni. 
Scelta del Parametro di Tuning 
 λ",gi visto caso regressione determinazione parametro usiamo mai test set avvaliamo invece validation set disposizione numero sufcientemente elevato osservazioni cross validation disposizione numero limitato osservazioni scelta parametro tuning
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#13,13,"Bias-Variance Tradeoff
 
14
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., maximum likelihood (MLE) 
ﬁt per polinomi di grado elevato per λ = 0) Il parametro λ controlla la complessità del modello: ",bias variance tradeoff parametro elevato high bias low variance parametro piccolo low bias high variance maximum likelihood polinomi grado elevato parametro controlla complessit modello
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#14,14,"L
2
 Regularization 
Esempio
 
15
Vediamo l’effetto della L 2 regularization nel caso visto in 
precedenza (caso con 20 features):
Regularization:
Range coefﬁcienti: 
Decision boundary:",regularization esempio vediamo leffetto regularization caso visto precedenza caso features regularization range coefcienti decision boundary
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#15,15,"Gradient Ascent 
con la L
 2
 Regularization 
 
16
Come è noto, nell’algoritmo Gradient Ascent dobbiamo 
aggiornare il vettore dei pesi w come segue:
w(t+1) w(t)+↵·rQualit` a totaleL2(w(t))
<latexit sha1_base64=""TzTwdt9I3sAyHV9gN7z7vrC1WrU="">AAAC0nicfVFNb9NAEB2bj5bw0QBHLisipFaVIjtUKscKOHDg0EpNWykJ0XgzaZeuvdbuGChWDogrf5BDpf4Uxk4O0AJjaefNvDc7452stCZwkvyM4lu379xdW7/Xuf/g4aON7uMnR8FVXtNQO+v8SYaBrCloyIYtnZSeMM8sHWfnbxr++BP5YFxxyBclTXI8LczcaGRJua6DMWTgwMIMavgMC/ggfhMYtiGFLYmVKCwQzCWH4OVzolP/rFvWbLcKFL6EM/FNpEXrRNHgQnKZsEuG5f4vctZwAFVbZSS6EmYq3rWdmxkWEtfwXs6B4M3/zrAFHehMu72kn7SmboJ0BXqwsv1p93I8c7rKqWBtMYRRmpQ8qdGz0ZYWnXEVqER9jqc0ElhgTmFSt3tYqBdVQHaqJK+MVW2Sfq+oMQ/hIs9EmSOfhetck/wbN6p4/mpSm6KsmArdNGJjqW0UtDeyYFIz44kZm8lJmUJp9MhM3ijUWpKVbLx5j/T6398ER4N++rI/ONjp7b1evcw6PIPn8rYp7MIevIN9GIKO3kYfoxBxfBh/jb/F35fSOFrVPIU/LP7xC+iqucA=</latexit>
Dobbiamo dunque calcolare il gradiente della funzione di 
qualità totale ( L2 regularized log-likelihood ):
Qualit` a totaleL2=l n L(w)",gradient ascent regularization noto nellalgoritmo gradient ascent dobbiamo aggiornare vettore pesi segue wtr qualit totale lwt latexit shabasetz twdt hvg nzvr cnicf ebbjbw hlisip vijt uksc hdg nwyk xgza zeuvdbu gch wdogrf bdpf uxk ajjaef dcst czwkvy mluxd wxufga onu sya cloy iytn zse mms hwfnbxrb yfxxy bcl lczca jua wtgw mavg mcggfh myti lym ovzol emf exr kzs gfvct yqr wdmxk wetfw mzr heh mukn smbo bxqwsvp icr wbt rrmp qqd erjqc elhg fstt haq jkm sfqo mqh sofhetckwb npmp ksm ard jjq dey izk zml ujp mij uwp kvb lxjt njpbevcw pnr miev kok yfox bxf bhjbff iul ciquc alatexit dobbiamo dunque calcolare gradiente funzione qualit totale regularized log likelihood qualit totale
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#16,16,"Gradient Ascent 
con la L
 2
 Regularization 
 
17
Nell’algoritmo l’aggiornamento dei pesi possiamo farlo per 
ogni componente w j:
w(t+1)
0 w(t)
0+↵·@Qualit` a totaleL2(w(t))
@w0
w(t+1)
1 w(t)
1+↵·@Qualit` a totaleL2(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j+↵·@Qualit` a totaleL2(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D+↵·@Qualit` a totaleL2(w(t))
@wD
<latexit sha1_base64=""DNhBsTO/Fo42FgAscBocdQBJt+Y="">AAAHvXic3VVLb9NAEJ4GiEt4pXDksiKiKlRK7XCAGxXkwIFDK5G2Up1G680k3dQvvGtCZOWHckDiwA9hdm1BmxQkokpFbGTvvL7sN/NJ3iANpdKu+2WtduPmrbqzfrtx5+69+w+aGw8PVJJnAnsiCZPsKOAKQxljT0sd4lGaIY+CEA+Ds7cmf/gJMyWT+IOepdiP+DiWIym4plCyUfsODfAhAIQxSIihIOsj7Rwy+nGYwXOYU80UBpRzyT6hfQs0bIMHz8hnsEmPDyEhRxQvkQkhyswyskRtWxQnXAqntBtPwJCQmmxmeY0sB0E4n6rMP2tiaTAmounEz/QuYB9yG5XkfaPMgPbEcjGs5pbBe3p3yN6y/SaUGVJ0usDLPKbfy0781cncdsAsZ7+ySs5ljbfynLy/ntOfpsSucU7ezzmZGTXOsVYXelC2/82l2KJ/FV7JpOQ3WVmjyZVqdH0KTf5xhborK9T9TxTqVgoZbZC+ysPffp8bg2bLbbt2sWXDq4wWVGtv0PzqDxORRxhrEXKljj031f2CZ1qKEOcNP1eYcnHGx3hMZswjVP3CXjlz9jRXXCcsxYzJkNkgnkcUPFJqFgVUGXF9qhZzJnhZ7jjXo1f9QsZprjEW5iAtQ7QHKZFJusuQDWWGWnPDHJmMmeAZ1xozybgQFMzpcjPz8Ba7XzYOOm3vRbuz32ntvqkmsw6P4Qlp5MFL2IV3sAc9EPWdeq9+Uh84rx10QicuS2trFeYRXFjO9AeM558S</latexit>",gradient ascent regularization nellalgoritmo laggiornamento pesi possiamo farlo ogni componente qualit totale lwt qualit totale lwt jqualit totale lwt dqualit totale lwt latexit shabased tofo asc bocd jtya xic etp xdksi agx xkw gkd qvv hck diw ahdm bmx qkokp gtvv anpd wtdu jjn ansi qxlj tsdl iyc eadscmfg jmy wti oepdi pdi wiympl ufs odf siih iosj rwyn gyw ubp rzy thf qsb hzhns pdy qvk qkhyswysk xaqnt qmmxme enr mptia tamoun ezqu yby xkfa pmg ecj gspb bepy nysa vjus pkbfycncds ssljbfyn lynt ofps suc uezzm xel kjf wvmjy zvqd ktfxhbor vgo zcys pffpbgb lbbts dqw gtv pzq rxhr kljjf czq npe ycn hgxh mzswj cxjlzj xccsx nkgnkc fjq fqh jnh zjj xof zprj ewi fjusu gwn hjm mme azxozybg mzpcj omv rbuzntvqkmsw qlp ivs wdequhrx qicu str xfj slatexit
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#17,17,"Gradient Ascent 
con la L
 2
 Regularization 
 
18
La derivata parziale della funzione di qualità totale rispetto al 
termine generico w j è la seguente:
Componente MLE Componente L 2 Penalty@Qualit` a totaleL2(w(t))
@wj= derivata parziale[ j]",gradient ascent regularization derivata parziale funzione qualit totale rispetto termine generico seguente componente componente penaltyqualit totale lwt derivata parziale
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#18,18,"Gradient Ascent 
con la L
 2
 Regularization 
 
19
Questa è la versione dell’algoritmo:
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrQualit` a totaleL2(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1",gradient ascent regularization versione dellalgoritmo oppure inizializziamo modo casuale whilekr qualit totale lwtk derivata parziale
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#19,19,"Funzione di Qualità 
nel caso L
 1
 Penalty
 
20
Questo è il caso in cui usiamo la somma dei valori assoluti 
per la penalty ( L1 Regularization ). E’ in genere chiamata 
“sparse logistic regression ”. 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L1 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.                                              Qualit` a totaleL1=l n L(w)",funzione qualit caso penalty caso usiamo somma valori assoluti penalty regularization genere chiamata sparse logistic regression funzione rappresenta qualit totale caso logistic regression regularized logistic regression seguente parametro tuning parameter serve bilanciare due termini qualit totale
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#2,2,"Metriche di Qualità 
[quality metric]
 
3Errore =#previsioni errate
#esempi
Una metrica che si usa misura la frazione delle previsioni errate 
fornite:
miglior valore possibile: 0.0
Accuracy =#previsioni corrette
#esempi
<latexit sha1_base64=""NDG+msvJ/lTBIqDvf5G5eA2dVhE="">AAACPXicbVA9TxtBEN0jBIiTEBPKNCusSKmsO4JEGiRIGtIRCQOSz7LmhjEZsfeh3TmEdbrfxE/Ir0hBAanoEG1a9oyF+HrV03vzdnZeUhh2Eobnwcyr2ddz8wtvWm/fvV/80F76uOfy0iL1MDe5PUjAkeGMesJi6KCwBGliaD85/tH4+ydkHefZrowLGqRwlPGIEcRLw/bPWOhUqi3E0gKOa72h45FnVdy5c/xrJ9zEOR5ibi2JUF3f2+QoLbiuW61huxN2wwn0cxJNSUdNsTNsX8SHOZYpZYIGnOtHYSGDCqwwGqpbcemoADyGI+p7mkFKblBNTq7159KB5Logq9noiUgPExWkzo3TxE+mIL/dU68RX/L6pYy+DSrOilIow2aRsKHJIoeWfZekD7mpAZqfk+ZMI1jwtVjWgOjF0pfb9BE9vf452VvtRl+7q7/WOpvfp80sqE9qRX1RkVpXm2pb7aieQnWm/qpL9S/4E1wF18HN3ehMMM0sq0cI/t8C0Zew6Q==</latexit>
Un’altra metrica possibile misura la frazione delle previsioni 
corrette:
miglior valore possibile: 1.0",metriche qualit quality metric errore previsioni errate esempi metrica usa misura frazione previsioni errate fornite miglior valore possibile accuracy previsioni corrette esempi latexit shabasen dgmsv dvf xicb txt bii cus skms osz lmhj ezsfeh edbrfx eirh baano egaoy fhr vvzdn uhh wmfv ofyi mde puj ake gmes kcw bglia hydk hef zrow lgq rwl iec rlwb uqi koah vdycxr ribi ffqo lbiu whux nwwncx sud tns ign dcqww gqpbcemo ady gipmk fkbl logqnoi pex wkzo ild rxlp yyd oil iowa jioe zek dmp azqfkz mijwt fpfb bevf vvt rlqw opvfpsq xmpbaie wmqp hneh msqc zew qlatexit unaltra metrica possibile misura frazione previsioni corrette miglior valore possibile
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#20,20," 
21Anche in questo caso vediamo cosa accade a fronte di diversi valori 
del parametro λ: 
Se λ = 0: 
ci riconduciamo alla soluzione standard, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞:  
si va verso soluzioni “sparse”, in cui vari w j sono uguali a zero.
Funzione di Qualità 
nel caso L
 1
 Penalty",caso vediamo cosa accade fronte diversi valori parametro riconduciamo soluzione standard ossia massimizzazione likelihood soluzioni costo totale lunica soluzione massimizzare qualit verso soluzioni sparse vari uguali zero funzione qualit caso penalty
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#21,21,"Pesi nella regolarizzazione 
 
22
Nelle ﬁgure seguenti riportiamo un esempio di andamento 
dei pesi w j al variare di 𝜆 per i due tipi di penalty:
L2 Penalty
 L1 Penaltyλ λ ",pesi gure seguenti riportiamo esempio andamento pesi variare due tipi penalty penalty penalty
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#22,22,"Riferimenti
 
23
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning classication university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#3,3," 
4
Overﬁtting 
Apprendimento della Decision Boundary 
j 𝜱j wj
0 1 0.23
1 x{1} 1.12
2 x{2} -1.07
x[1] x[1]x[2] x[2]
Data Points dell’esempio Decision Boundary:
0.23 + 1.12 x[1] - 1.07 x[2] = 0Score( x) < 0 Score( x) > 0",overtting apprendimento decision boundary data points dellesempio decision boundary score score
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#4,4," 
5
j 𝜱j wj
0 1 1.68
1 x{1} 1.39
2 x{2} -0.59
3 x{1}^2 -0.17
4 x{2}^2 -0.96
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
1.68 + 1.39 x[1] - 0.59 x[2] - 0.17 x[1]^2  - 0.96 x[2]^2 = 0Score( x) < 0 Score( x) > 0
Decision Boundary:",data points dellesempio overtting apprendimento decision boundary score score decision boundary
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#5,5," 
6
j 𝜱j wj
0 1 21.6
1 x{1} 5.3
2 x{2} -42.7
3 x{1}^2 -15.9
4 x{2}^2 -48.6
5 x{1}^3 -11.0
6 x{2}^3 67.0
… … …
11 x[1]^6 0.8
12 x[2]^6 -8.6
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
I valori assoluti di vari coefﬁcienti 
wj sono aumentati(chiaro overﬁtting)Decision Boundary",data points dellesempio overtting apprendimento decision boundary score score valori assoluti vari coefcienti boundary
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#6,6," 
7
x[2]
x[1]x[2]
x[1]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
(overﬁtting ancora più evidente)j 𝜱j wj
0 1 8.7
1 x{1} 5.1
2 x{2} 78.7
… … …
11 x{1}^6 -7.5
12 x{2}^6 3803
13 x{1}^7 21.1
14 x{2}^7 -2406
… … …
39 x[1]^20 -2*10^-8
40 x[2]^20 0.03
I valori assoluti di vari coefﬁcienti 
wj sono aumentati ancora di piùDecision Boundary",data points dellesempio overtting apprendimento decision boundary score score overtting ancora evidentej valori assoluti vari coefcienti aumentati ancora decision boundary
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#7,7,"Andamento Errori  
e Bias-Variance Trade-off
 
8
L’andamento del training error e del true error per la 
classiﬁcation è in genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e varianza.True Error
Training Error
Model ComplexityClassiﬁcation
Error
Dato un modello con parametri ŵ, si ha overﬁtting 
se esiste un modello con i parametri stimati w’ tale 
che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
ŵ w’
",andamento errori bias variance trade landamento training error true error classication genere seguente dobbiamo solito considerare trade bias varianzatrue error training error model complexity classication error dato modello parametri overtting esiste modello parametri stimati tale che training error training errorw true error true errorw
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#8,8,"Regularization 
nella Classiﬁcazione
 
9
L’idea è quella di limitare il valore assoluto dei coefﬁcienti w i 
deﬁnendo come segue la funzione di qualità totale (da 
massimizzare nella fase di training): 
Qualità_totale  = misura del “ﬁt” - misura grandezza coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la MLE. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. ",regularization classicazione lidea limitare valore assoluto coefcienti denendo segue funzione qualit totale massimizzare fase training qualittotale misura t misura grandezza coefcienti misura t intendiamo funzione misura coefcienti possiamo denirla vari modi
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#9,9,"Misura dei Coefﬁcienti 
 
10
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2",misura coefcienti somma valori somma valori assoluti norm somma quadrati quadrato norm wwww jwjkwk w jkwk
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex04)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione regressione classicazione
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#1,1,"Sommario
Esercizi su Linear models per la classiﬁcazione",sommario esercizi linear models classicazione
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#10,10,"LinearLogistic: Breast cancer dataset
Esercizio
 : visualizza i parametri del modello. Cosa ti aspetti? 
plt
.
plot
(
logreg
.
coef_
.
T
, 
'o'
, 
label
=
""C=1""
)
plt
.
plot
(
logreg100
 .
coef_
.
T
, 
'^'
, 
label
=
""C=100""
)
plt
.
plot
(
logreg001
 .
coef_
.
T
, 
'v'
, 
label
=
""C=0.001""
 )
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
ylim
(
-
5
, 
5
)
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
legend
()
11",linear logistic breast cancer dataset esercizio visualizza parametri modello cosa aspetti plt plot logreg coef label plt plot logreg coef label plt plot logreg coef label plt xticks range cancer data shape cancer featurenames rotation plt hlines cancer data shape plt ylim plt xlabel coefficient index plt ylabel coefficient magnitude plt legend
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#11,11,"LinearLogistic: Breast cancer dataset
Regolarizzazioni alte spingono i parametri a 0.  
In alcuni casi (
 mean perimeter
 ), per C=100 e C=1 il coefﬁciente è negativo, 
positivo per C=0.001.  
12
Attenzione: 
 È sbagliato 
pensare che i parametri 
suggeriscano quali features 
determinino direttamente la 
classe (tumore maligno o 
meno). L'importanza della 
feature dipende strettamente 
dal modello preso in 
considerazione.",linear logistic breast cancer dataset alte spingono parametri alcuni casi mean perimeter coefciente negativo positivo attenzione sbagliato pensare parametri suggeriscano quali features determinino direttamente classe tumore maligno meno limportanza feature dipende strettamente modello preso considerazione
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#12,12,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature 
impiegando la L1 regularization. 
13",linear logistic breast cancer dataset esercizio cerca interpretare meglio limportanza feature impiegando regularization
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#13,13,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature impiegando la L1 
regularization. 
for 
C
, 
marker 
in 
zip
([
0.001
, 
1
, 
100
], [
'o'
, 
'^'
, 
'v'
]):
lr_l1 
= 
LogisticRegression
 (
C
=
C
, 
penalty
=
""l1""
)
.
fit
(
X_train
, 
y_train
)
print
(
""Training accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_train
, 
y_train
)))
print
(
""Test accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_test
, 
y_test
)))
plt
.
plot
(
lr_l1
.
coef_
.
T
, 
marker
, 
label
=
""C={:.3f}""
 .
format
(
C
))
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
ylim
(
-
5
, 
5
)
plt
.
legend
(
loc
=
3
)
> Training accuracy of l1 logreg with C=0.001: 0.91
> Test accuracy of l1 logreg with C=0.001: 0.92
> Training accuracy of l1 logreg with C=1.000: 0.96
> Test accuracy of l1 logreg with C=1.000: 0.96
> Training accuracy of l1 logreg with C=100.000: 0.99
> Test accuracy of l1 logreg with C=100.000: 0.98
14",linear logistic breast cancer dataset esercizio cerca interpretare meglio limportanza feature impiegando regularization marker zip lrl logistic regression penalty fit xtrain ytrain print training accuracy logreg format lrl score xtrain ytrain print test accuracy logreg format lrl score xtest ytest plt plot lrl coef marker label format plt xticks range cancer data shape cancer featurenames rotation plt hlines cancer data shape plt xlabel coefficient index plt ylabel coefficient magnitude plt ylim plt legend loc training accuracy logreg test accuracy logreg training accuracy logreg test accuracy logreg training accuracy logreg test accuracy logreg
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#14,14,"LinearLogistic: Breast cancer dataset
L'effetto della L1 regularization dipende dal valore del parametro, in modo 
simile al caso della regressione. 
15
",linear logistic breast cancer dataset leffetto regularization dipende valore parametro modo simile caso regressione
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#15,15,"Linear models per la classiﬁcazione multiclass
Alcuni modelli non si adattano facilmente al caso multiclass.  
Un approccio piuttosto semplice è il
  one-vs-rest:
  si creano vari modelli, 
dove ogni modello si addestra a riconoscere una speciﬁca classe. Durante 
la predizione vengono valutati tutti i modelli e quello con score più alto 
determina la classe in output. 
Chiaramente si avranno un insieme di parametri da addestrare per ogni 
classe. 
16",linear models classicazione multiclass alcuni modelli adattano facilmente caso multiclass approccio piuttosto semplice one rest creano vari modelli ogni modello addestra riconoscere specica classe durante predizione vengono valutati modelli score alto determina classe output chiaramente insieme parametri addestrare ogni classe
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#16,16,"Linear models per la classiﬁcazione multiclass
Esempio
 : creiamo un dataset con 2 features e 3 classi e impieghiamo il 
Linear SVM per la classiﬁcazione. Il dataset è creato seguendo una 
distribuzione gaussiana. 
from 
sklearn.datasets 
 import 
make_blobs
X
, 
y 
= 
make_blobs
 (
random_state
 =
42
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 , 
""Class 2""
 ])
17
",linear models classicazione multiclass esempio creiamo dataset features classi impieghiamo linear classicazione dataset creato seguendo distribuzione gaussiana import makeblobs makeblobs randomstate mglearn plt xlabel feature plt ylabel feature plt legend class class class
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#17,17,"Linear models per la classiﬁcazione multiclass
linear_svm 
 = 
LinearSVC
 ()
.
fit
(
X
, 
y
)
print
(
""Coefficient shape: ""
 , 
linear_svm
 .
coef_
.
shape
)
print
(
""Intercept shape: ""
 , 
linear_svm
 .
intercept_
 .
shape
)
> Coefficient shape: (3, 2)
>Intercept shape: (3,)
Ogni riga di 
 _coef
  rappresenta il vettore dei parametri per una delle 3 
classi, e le colonne sono le 2 features. 
 intercept_
  è un array 1d che 
memorizza l'intercetta per ogni classe. 
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
[
'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
ylim
(
-
10
, 
15
)
plt
.
xlim
(
-
10
, 
8
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
18",linear models classicazione multiclass linearsvm linear fit print coefficient shape linearsvm coef shape print intercept shape linearsvm intercept shape coefficient shape intercept shape ogni riga coef rappresenta vettore parametri classi colonne features intercept array memorizza lintercetta ogni classe mglearn line linspace coef intercept color zip linearsvm coef linearsvm intercept plt plot line line coef intercept coef color plt ylim plt xlim plt xlabel feature plt ylabel feature plt legend class class class line class line class line class loc
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#18,18,"Linear models per la classiﬁcazione multiclass
Ogni istanza etichettata con la classe 0 è al di sopra della 
 boundary  
deﬁnita dal classiﬁcatore per la class 0. Le istanze delle altre classi al di 
sotto. Stessa cosa per la classe 1 e 2, e i relativi classiﬁcatori. 
Cosa succede se una istanza si trova nel triangolo centrale? 
19
",linear models classicazione multiclass ogni istanza etichettata classe sopra boundary denita classicatore class istanze altre classi sotto stessa cosa classe relativi classicatori cosa succede istanza trova triangolo centrale
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#19,19,"Linear models per la classiﬁcazione multiclass
Cosa succede se una istanza si trova nel triangolo centrale? 
La classe associata corrisponde alla linea più vicina. 
20
",linear models classicazione multiclass cosa succede istanza trova triangolo centrale classe associata corrisponde linea vicina
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#2,2,"Richiami: Linear models per la classiﬁcazione
I modelli lineari possono essere impiegati per la classiﬁcazione con 
decision boundary
  che rappresento linee, piani o iperpiani.  
Nella logisitic regression si impiega un modello lineare tradizionale il cui 
output è valutato da una funzione 
 logistic
  (s
igmoid function
 ) che restituisce 
un valore in [0,1] ed indica la probabilità di appartenenza ad una certa 
classe (> 0.5) o meno (< 0.5). 
Il 
gradient descent
  è impiegato per minimizzare la funzione di costo. 
I due algoritmi di classiﬁcazione lineari più famosi sono la 
 logistic 
regression
 , e i 
linear support vector machine
  (o Linear SVM) che vedremo 
in seguito. 
Scikit-learn fornisce la classe 
 linear_model.LogisticRegression
  e 
svm.LinearSVC
  che implementa i due algoritmi.
3",richiami linear models classicazione modelli lineari possono essere impiegati classicazione decision boundary rappresento linee piani iperpiani logisitic regression impiega modello lineare tradizionale output valutato funzione logistic igmoid function restituisce valore indica probabilit appartenenza certa classe meno gradient descent impiegato minimizzare funzione costo due algoritmi classicazione lineari famosi logistic regression linear support vector machine linear vedremo seguito scikit learn fornisce classe regression svmlinear implementa due algoritmi
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#20,20,"Linear models per la classiﬁcazione multiclass
Il seguente codice mostra le regioni associate alle predizioni 
mglearn
.
plots
.
plot_2d_classification
 (
linear_svm
 , 
X
, 
fill
=
True
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
                            [
 'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
      
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21",linear models classicazione multiclass seguente codice mostra regioni associate predizioni mglearn plots linearsvm fill true alpha mglearn line linspace coef intercept color zip linearsvm coef linearsvm intercept plt plot line line coef intercept coef color plt legend class class class line class line class line class loc plt xlabel feature plt ylabel feature
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#21,21,"Linear models per la classiﬁcazione multiclass
22
",linear models classicazione multiclass
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#22,22,"Considerazioni sul tuning
Gli iperparametri C e 
 λ
 sono solitamente campionati su scala logaritmica. 
Se si assume che il dataset contenga solo alcune feature rilevanti si può 
testare la L1 regularization, altrimenti si tende a preferire la L2.  
La L1 regularization è utile anche per dare una interpretazione del modello.   
I modelli lineari sono veloci da addestrare, anche su dati sparsi. 
Per dataset con >100.000 istanze si può impiegare il parametro 
 solver='sag'  
nella LogisticRegression e Ridge, che rende l'apprendimento più veloce. 
Altre opzioni sono SGDClassiﬁer e SGDRegressor che implementano 
versioni più scalabili dei relativi algoritmi. 
I parametri possono indicare quali feature siano più rilevanti, nei casi in cui 
le feature sono indipendenti tra loro. 
I modelli lineari hanno buone performance quando il numero di features è 
grande rispetto al numero di istanze. Sono impiegati anche su grandi dataset 
perché spesso gli altri modelli non sono facilmente addestrabili.
23",considerazioni tuning iperparametri solitamente campionati scala logaritmica assume dataset contenga solo alcune feature rilevanti pu testare regularization altrimenti tende preferire regularization utile dare interpretazione modello modelli lineari veloci addestrare dati sparsi dataset istanze pu impiegare parametro solversag logistic regression ridge rende lapprendimento veloce altre opzioni classier regressor implementano versioni scalabili relativi algoritmi parametri possono indicare quali feature rilevanti casi feature indipendenti loro modelli lineari buone performance quando numero features grande rispetto numero istanze impiegati grandi dataset spesso altri modelli facilmente addestrabili
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#3,3,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
...
4",linear models classicazione forge dataset esercizio impiega forge dataset logistic regression classicazione valuta performance import logistic regression mglearn datasets makeforge
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#4,4,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
LinearSVC
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
2
, 
figsize
=
(
10
, 
3
))
for 
model, 
ax 
in 
zip
([
LinearSVC
 (), 
LogisticRegression
 ()], 
axes
):
clf 
= 
model
.
fit
(
X
, 
y
)
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
False
, 
eps
=
0.5
,
ax
=
ax
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
ax
.
set_title
 (
""{}""
.
format
(
clf
.
__class__
 .
__name__
 ))
ax
.
set_xlabel
 (
""Feature 0""
 )
ax
.
set_ylabel
 (
""Feature 1""
 )
axes
[
0
]
.
legend
()
Nota: 
 Impieghiamo entrambe le implementazioni, anche se l'algoritmo SVM 
lo vedremo in dettaglio in seguito. 
5",linear models classicazione forge dataset esercizio impiega forge dataset logistic regression classicazione valuta performance import logistic regression sklearnsvm import linear mglearn datasets makeforge fig axes plt subplots figsize model zip linear logistic regression axes clf model fit mglearn plots clf fill false eps alpha mglearn settitle format clf class name setxlabel feature setylabel feature axes legend nota impieghiamo entrambe lalgoritmo vedremo dettaglio seguito
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#5,5,"Linear models per la classiﬁcazione: forge dataset
In questo dataset la decision boundary è rappresentata da una retta. 
6
",linear models classicazione forge dataset dataset decision boundary rappresentata retta
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#6,6,"Scikit-learn: Logistic regression
In Scikit-learn, la Logistic regression impiega la 
 L2
 di default. 
Il parametro 
 penalty
  speciﬁca quale regolarizzazione impiegare {‘l1’, ‘l2’, 
‘elasticnet’, ‘none’}.  
Il parametro 
 C
 indica il peso della regolarizzazione (valori bassi 
rappresentano una regolarizzazione maggiore), il default è C=1.0  
7",scikit learn logistic regression scikit learn logistic regression impiega default parametro penalty specica impiegare l l elasticnet none parametro indica peso valori bassi rappresentano maggiore default
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#7,7,"Richiami: Linear models per la classiﬁcazione
Al variare di 
 C
 si può notare l'effetto sul dataset considerato. 
Con alta regolarizzazione (C basso) il modello sbaglia a classiﬁcare 2 
istanze cercando di considerare la ""maggioranza"" durante la scelta della 
decision boundary. 
Per valori più alti di C la retta si inclina dando più importanza ai 2 punti. 
Un punto rimane comunque non classiﬁcato, ed è impossibile considerarlo 
con una semplice linea retta. 
8
",richiami linear models classicazione variare pu notare leffetto dataset considerato alta basso modello sbaglia classicare istanze cercando considerare maggioranza durante scelta decision boundary valori alti retta inclina dando importanza punti punto rimane comunque classicato impossibile considerarlo semplice linea retta
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#8,8,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la 
 linera logistic 
 nel caso del Breast cancer dataset, 
considerando valori di C pari a 0.01, 1 e 100. Commenta i risultati ottenuti 
in termini di accuracy e potenziali fenomeni di over o underﬁtting.
9",linear logistic breast cancer dataset esercizio valuta linera logistic caso breast cancer dataset considerando valori pari commenta risultati ottenuti termini accuracy potenziali fenomeni undertting
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#9,9,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la linera logistic nel caso del Breast cancer dataset, 
considerando valori di C pari a 1, 100 e 0.01. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
logreg 
= 
LogisticRegression
 (C=1)
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_test
, 
y_test
)))
Training set score: 0.953
Test set score: 0.958
Training set score: 0.972
Test set score: 0.965
Training set score: 0.934
Test set score: 0.930
Per C=1 c'è un probabile underﬁtting. Per C=100 (modello più complesso) 
migliorano le performance. Per C=0.01 si incrementa l'underﬁtting iniziale.
10",linear logistic breast cancer dataset esercizio valuta linera logistic caso breast cancer dataset considerando valori pari import cancer xtrain xtest ytrain ytest cancer data cancer target stratify cancer target randomstate logreg logistic regression fit xtrain ytrain print training set score format logreg score xtrain ytrain print test set score format logreg score xtest ytest training set score test set score training set score test set score training set score test set score probabile undertting modello complesso migliorano performance incrementa lundertting iniziale
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Decision Trees (Ex05)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione decision trees
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#1,1,"Sommario
Richiami 
scikit-learn e decision trees 
Visualizzazione 
Feature importance 
Decision trees e regressione 
Pruning",sommario richiami scikit learn decision trees visualizzazione feature importance decision trees regressione pruning
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#10,10,"scikit-learn e decision trees
tree 
= 
DecisionTreeClassifier
 (
max_depth
 =
4
, 
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 0.988
> Accuracy on test set: 0.951
Più bassa sul training, ma migliora (meno overﬁtting) sul test.
11",scikit learn decision trees tree decision tree classifier maxdepth randomstate tree fit xtrain ytrain print accuracy training set format tree score xtrain ytrain print accuracy test set format tree score xtest ytest accuracy training set accuracy test set bassa training migliora meno overtting test
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#11,11,"scikit-learn: visualizzare i decision trees
La funzione 
 export_graphviz
  del modulo 
 tree
 permette di visualizzare 
l'albero. Salva un ﬁle .dot che può essere importato per la visualizzazione. 
from 
sklearn.tree 
 import 
export_graphviz
export_graphviz
 (
tree
, 
out_file
 =
""tree.dot""
 , 
class_names
 =
[
""malignant""
 , 
""benign""
 ], 
feature_names
 =
cancer
.
feature_names
 , 
impurity
 =
False
, 
filled
=
True
)
import 
graphviz
with 
open
(
""tree.dot""
 ) 
as 
f
:
dot_graph 
 = 
f
.
read
()
graphviz
 .
Source
(
dot_graph
 )
Visualizzare il ""comportamento"" di un algoritmo di ML è molto utile per 
spiegarne l'output (
 explaination
 ), in questo caso anche ai non-esperti.
12",scikit learn visualizzare decision trees funzione exportgraphviz modulo tree permette visualizzare lalbero salva le dot pu essere importato sklearntree import exportgraphviz exportgraphviz tree outfile treedot classnames malignant benign featurenames cancer featurenames impurity false filled true import graphviz open treedot dotgraph read graphviz source dotgraph visualizzare comportamento algoritmo molto utile spiegarne loutput explaination caso esperti
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#12,12,"scikit-learn: visualizzare i decision trees
L'albero generato:
13
samples  indica il numero di 
istanze, value  la rispettiva 
suddivisione in base alle label, 
class  la classe majoriy.",scikit learn visualizzare decision trees lalbero generato samples indica numero istanze value rispettiva suddivisione base label class classe majoriy
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#13,13,"scikit-learn: visualizzare i decision trees
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile feature_importances_ del modello è un array con valori in [0,1] 
dove 1 indica ""predice perfettamente in valore target"". 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
14",scikit learn visualizzare decision trees altro modo esplorare decision trees assegnare misura importanza feature base funzionamento dellalgoritmo variabile modello array valori indica predice perfettamente valore target print feature format tree out def model nfeatures cancer data shape plt barh range nfeatures model align center plt yticks arange nfeatures cancer featurenames plt xlabel feature importance plt ylabel feature tree
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#14,14,"Decision trees e feature importance
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile 
 feature_importances_
  del modello è un array con valori in 
[0,1] dove 1 indica ""predice perfettamente in valore target"". È valutata 
mediante la metrica GINI. 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
15",decision trees feature importance altro modo esplorare decision trees assegnare misura importanza feature base funzionamento dellalgoritmo variabile modello array valori indica predice perfettamente valore target valutata mediante metrica print feature format tree out def model nfeatures cancer data shape plt barh range nfeatures model align center plt yticks arange nfeatures cancer featurenames plt xlabel feature importance plt ylabel feature tree
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#15,15,"Decision trees e feature importance
Si può notare come worst radius è la feature più discriminante. Questo 
indica anche che l'albero è ben costruito avendo questa feature in cima. 
Puoi dire che una 
 feature
  con bassa importance è poco discriminante?
16
",decision trees feature importance pu notare worst radius feature discriminante indica lalbero ben costruito feature cima puoi dire feature bassa importance poco discriminante
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#16,16,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
Esercizio: 
 In questo esempio come costruiresti l'albero di decisione?
17
X[0]X[1]",esempio feature importance tree mglearn plots display tree esercizio esempio costruiresti lalbero decisione
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#17,17,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
In questo esempio, l'informazione rilevante è contenuta in X[1]. Infatti non 
possiamo dire che un valore alto per la feature X[0] identiﬁca la classe 0, e 
uno basso la classe 1. L'albero effettivamente impiega la feature corretta.
18
X[0]X[1]",esempio feature importance tree mglearn plots display tree esempio linformazione rilevante contenuta infatti possiamo dire valore alto feature identica classe basso classe lalbero effettivamente impiega feature corretta
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#18,18,"scikit-learn: decision tree per la regressione
La classe DecisionTreeRegressor impiega lo stesso algoritmo in ambito di 
regressione 
import 
pandas 
as 
pd
ram_prices 
 = 
pd
.
read_csv
 (
""data/ram_price.csv""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
ram_prices
 .
price
)
plt
.
xlabel
(
""Year""
)
plt
.
ylabel
(
""Price in $/Mbyte""
 )
19
https://github.com/amueller/introduction_to_ml_with_python/blob/master/data/ram_price.csvSu scala logaritmica per le y si può 
ipotizzare una relazione lineare",scikit learn decision tree regressione classe decision tree regressor impiega stesso algoritmo ambito regressione import pandas ramprices readcsv plt semilogy ramprices date ramprices price plt xlabel year plt ylabel price mbyte scala logaritmica pu ipotizzare relazione lineare
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#19,19,"scikit-learn: decision tree per la regressione
Confrontiamo i decision trees con un modelli lineare, con l'accortezza di 
convertire i dati in valori logaritmo altrimenti il modello lineare non può 
funzionare. 
from 
sklearn.tree 
 import 
DecisionTreeRegressor
# use historical data to forecast prices after the year 2000
data_train 
 = 
ram_prices
 [
ram_prices
 .
date 
< 
2000
]
data_test 
 = 
ram_prices
 [
ram_prices
 .
date 
>= 
2000
]
# predict prices based on date
X_train 
 = 
data_train
 .
date
[:, 
np
.
newaxis
]
# we use a log-transform to get a simpler relationship of data to target
y_train 
 = 
np
.
log
(
data_train
 .
price
)
tree 
= 
DecisionTreeRegressor
 ()
.
fit
(
X_train
, 
y_train
)
linear_reg 
 = 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
# predict on all data
X_all 
= 
ram_prices
 .
date
[:, 
np
.
newaxis
]
pred_tree 
 = 
tree
.
predict
(
X_all
)
pred_lr 
 = 
linear_reg
 .
predict
(
X_all
)
# undo log-transform
price_tree 
 = 
np
.
exp
(
pred_tree
 )
price_lr 
 = 
np
.
exp
(
pred_lr
)
Cosa ti aspetti?
20",scikit learn decision tree regressione confrontiamo decision trees modelli lineare laccortezza convertire dati valori logaritmo altrimenti modello lineare pu funzionare sklearntree import decision tree regressor use historical data forecast prices year datatrain ramprices ramprices date datatest ramprices ramprices date predict prices based date xtrain datatrain date newaxis use log transform get simpler relationship data target ytrain log datatrain price tree decision tree regressor fit xtrain ytrain linearreg linear regression fit xtrain ytrain predict data xall ramprices date newaxis predtree tree predict xall predlr linearreg predict xall undo log transform pricetree exp predtree pricelr exp predlr cosa aspetti
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#2,2,"Richiami: Decision Trees
Impiegati spesso per la classiﬁcazione e regressione.  
In sintesi creano una albero di nodi if/else che porta ad una certa 
decisione.  
Si può rappresentare come un albero dove le foglie contengono la risposta.
3
",richiami decision trees impiegati spesso classicazione regressione sintesi creano albero nodi ifelse porta certa decisione pu rappresentare albero foglie contengono risposta
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#20,20,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Ma che succede dopo l'ultima data presente nel dataset?
21
",scikit learn decision tree regressione plt semilogy datatrain date datatrain price label training data plt semilogy datatest date datatest price label test data plt semilogy ramprices date pricetree label tree prediction plt semilogy ramprices date pricelr label linear prediction plt legend modello lineare approssima retta decision tree molto accurato predizione succede dopo lultima data presente dataset
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#21,21,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Attenzione: 
 L'algoritmo decision tree non è in grado di fare predizioni su 
nuovi dati con la data oltre a quella contenuta nel dataset. 
22
",scikit learn decision tree regressione plt semilogy datatrain date datatrain price label training data plt semilogy datatest date datatest price label test data plt semilogy ramprices date pricetree label tree prediction plt semilogy ramprices date pricelr label linear prediction plt legend modello lineare approssima retta decision tree molto accurato predizione attenzione lalgoritmo decision tree grado fare predizioni nuovi dati data oltre contenuta dataset
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#22,22,"scikit-learn: decision tree e pruning
Per limitare l'overﬁtting e la complessità, solitamente è sufﬁciente 
impiegare una tecnica di pre-pruning con uno dei seguenti parametri: 
max_depth
 , 
max_leaf_nodes
 ,  o.  
min_samples_leaf
Nota: 
 min_samples_leaf indica il minimo numero di istanze per foglia. 
Esercizio
 : prova ad addestrare nuovamente il decision trees sul breast 
cancer dataset impostano a turno uno di questi valori e valutare le 
variazioni di accuracy.
23",scikit learn decision tree pruning limitare lovertting complessit solitamente sufciente impiegare tecnica pre pruning seguenti parametri maxdepth maxleafnodes nota indica minimo numero istanze foglia esercizio prova addestrare nuovamente decision trees breast cancer dataset impostano turno valori valutare variazioni accuracy
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#3,3,"Richiami: Decision Trees
In ML, ogni ""domanda"" in un nodo è chiamata comunemente 
 test
, ed è 
spesso codiﬁcata con feature su domini continui, ad esempio: 
la feature 
 i
 è maggiore del valore 
 a
? 
L'algoritmo si focalizza nello scegliere le sequenze if/else che portano ad 
una riposta più velocemente, ovvero sono più 
 informative
  per la variabile 
target.
4",richiami decision trees ogni domanda nodo chiamata comunemente test spesso codicata feature domini continui esempio feature maggiore valore lalgoritmo focalizza scegliere sequenze ifelse portano riposta velocemente ovvero informative variabile target
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#4,4,"Dataset two_moons
Toy dataset generato da scikit-learn 
sklearn.datasets.make_moons(
 n_samples=100
 , 
*
, 
shuﬄe=True
 , 
noise=None
 , 
random_state=None
 )
Ogni istanza ha 2 valori. 
Ad esempio, per 75 istanze otteniamo: 
Per la profondità 0 dell'albero, quale test immagineresti?
5
",dataset twomoons toy dataset generato scikit learn nsamples shuetrue noisenone ogni istanza valori esempio istanze otteniamo profondit dellalbero test immagineresti
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#5,5,"Decision Trees su two_moons dataset
Depth = 1 
Depth = 2 
...
6
dove [2,32] indica che 2 istanze appartengono 
alla classe 1 e 32 alla classe 2
Se in una foglia ci sono istanze appartenenti 
ad una sola classe allora la foglia si chiama 
pure.",decision trees twomoons dataset depth depth indica istanze appartengono classe classe foglia istanze appartenenti sola classe allora foglia chiama pure
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#6,6,"Richiami: Decision Trees
Ogni test considera una singola feature, perciò la relativa decisione è 
rappresentata come una asse parallelo ad uno degli assi. 
Nella predizione, una volta arrivati ad una foglia, si assegna la classe target 
che appare più spesso nella regione associata. In modo simile per la 
regressione si opera una media dei valori delle istanze nella regione. 
Per dataset grandi, creare foglie pure è molto dispendioso in termini di 
risorse computazione e può creare fenomeni di overﬁtting. 
Si possono implementare tecniche di early stopping limitando la 
profondità dell'albero (
 pre-pruning
 ), oppure rimuovere o fondere foglie 
che contengono poca informazione (
 post-pruning
  o 
pruning
 )
7",richiami decision trees ogni test considera singola feature perci relativa decisione rappresentata asse parallelo assi predizione volta arrivati foglia assegna classe target appare spesso regione associata modo simile regressione opera media valori istanze regione dataset grandi creare foglie pure molto dispendioso termini risorse computazione pu creare fenomeni overtting possono implementare tecniche early stopping limitando profondit dellalbero pre pruning oppure rimuovere fondere foglie contengono poca informazione post pruning pruning
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#7,7,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
...
8",scikit learn decision trees classe decision tree classier modulo decision tree regressor implementa lalgoritmo esercizio prova impiegarlo dataset breast cancer valuta laccuracy training test set sklearntree import decision tree classifier cancer xtrain xtest ytrain ytest cancer data cancer target stratify cancer target randomstate
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#8,8,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
tree 
= 
DecisionTreeClassifier
 (
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%?
9",scikit learn decision trees classe decision tree classier modulo decision tree regressor implementa lalgoritmo esercizio prova impiegarlo dataset breast cancer valuta laccuracy training test set sklearntree import decision tree classifier cancer xtrain xtest ytrain ytest cancer data cancer target stratify cancer target randomstate tree decision tree classifier randomstate tree fit xtrain ytrain print accuracy training set format tree score xtrain ytrain print accuracy test set format tree score xtest ytest accuracy training set accuracy test set aspettavi accuracy
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#9,9,"scikit-learn e decision trees
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%? Sì, per come funziona l'algoritmo 
l'albero cresce ﬁno a creare foglie pure che rappresentazione perfettamente 
l'appartenenza delle istanze alle relative label.  
L'accuracy sul test set è leggermente inferiore ai modelli lineari (95% ca). 
Esercizio
 : Prova a impostare una profondità col parametro 
 max_depth  
durante la costruzione dell'oggetto DecisionTreeClassiﬁer. Cosa ti aspetti 
sulle due accuracy?
10",scikit learn decision trees accuracy training set accuracy test set aspettavi accuracy funziona lalgoritmo lalbero cresce no creare foglie pure perfettamente lappartenenza istanze relative label laccuracy test set leggermente inferiore modelli lineari esercizio prova impostare profondit parametro maxdepth durante costruzione delloggetto decision tree classier cosa aspetti due accuracy
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#0,0,"Machine Learning 
Anno Accademico 2021 - 2022 
  
Richiami di Matematica",machine learning anno accademico richiami matematica
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#1,1,"Sommario
Richiami sulle Funzioni Convesse 
Funzioni di più Variabili (Derivate Parziali) 
Gradiente di una Funzione 
Algoritmo di Gradient Descent 
Cenni di Calcolo delle Probabilità
 
2",sommario richiami funzioni convesse funzioni variabili derivate parziali gradiente funzione algoritmo gradient descent cenni calcolo probabilit
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#10,10,"Funzioni Convesse 
 11
wg(w)
v wg(w)
g(v)
..g(v)+rg(v)T(w",funzioni convesse wgw wgw gvrgvtw
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#11,11,"Funzioni di più Variabili
 
12",funzioni variabili
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#12,12,"Derivate Parziali di 
Funzioni di più Variabili 
 13g(w0+",derivate parziali funzioni variabili
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#13,13," 14
Se esiste determinato e ﬁnito il seguente limite:
lim
",esiste determinato nito seguente limite lim
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#14,14," 15
Supponiamo ora che la funzione g sia parzialmente derivabile rispetto a w
 0 
in ogni punto del campo A.  
Per ogni punto di A resta ben determinato il corrispondente valore della 
derivata parziale rispetto a w
 0
. 
Nasce così in A una nuova funzione di due variabili w
 0
, w
 1
 che si chiama 
derivata parziale rispetto a 
 w
0
 della funzione g 
 e si denota ad esempio come 
segue:Derivate Parziali di 
Funzioni di più Variabili 
@g
@w0
<latexit sha1_base64=""VQx8u7rzFuG6k3KXt2wTraBjelE="">AAACI3icbZC5TsNAEIbX3IQrQEmzIkKiCjYgQRlBQxkkApFiyxpvJmHF+tDumEOWH4NH4ClooaJDNBR5F2wTiXOqX98/s7PzB4mShmz73ZqYnJqemZ2bry0sLi2v1FfXzk2caoEdEatYdwMwqGSEHZKksJtohDBQeBFcHZf+xTVqI+PojO4S9EIYRnIgBVCB/PqOO9AgMjcBTRJU5hLeUjbM87z2BW/8zC4I57zm1xt2066K/xXOWDTYuNp+feT2Y5GGGJFQYEzPsRPysvJloTCvuanBBMQVDLFXyAhCNF5WHZbzrdQAxTxBzaXiFcTvExmExtyFQdEZAl2a314J//N6KQ0OvUxGSUoYiXIRSYXVIiO0LBJD3pcaiaD8OXIZcQEaiFBLDkIUMC0iLPNwfl//V5zvNp295u7pfqN1NE5mjm2wTbbNHHbAWuyEtVmHCXbPHtkTe7YerBfr1Xr7bJ2wxjPr7EdZow9TRaVm</latexit>",supponiamo ora funzione parzialmente derivabile rispetto ogni punto campo ogni punto resta ben determinato corrispondente valore derivata parziale rispetto nasce cos nuova funzione due variabili chiama derivata parziale rispetto funzione denota esempio seguederivate parziali funzioni variabili latexit shabasev qxurz kxtw bjel ciicb eib iqr qemz qrl bqxkk fiyxpv hft dum clooa xoq shmz jqem zbrys liv xzkcao eat ydw mwq zkks jtoh bfc hzfx tvq ipoj yrn cbpq mjc ujb bwz izmxt tyu npfe yez rpysv jlo tcvuan zbzrd qax bza exm exty fqd ala vii jdpcaia izc qeai ldk mci nwflvzv npupfq nemjmw tbb awuy phtk yer bfr xrb jwxj zow vmlatexit
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#15,15," 16Derivate Parziali di 
Funzioni di più Variabili 
supposto determinato e ﬁnito.
Analogamente si deﬁnisce la derivata parziale rispetto a      , nel punto    ,  
come il limite
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
P
<latexit sha1_base64=""RzOqhOyvtYvEmUKPvym5XynVJro="">AAAB/nicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBIg8pjqLzZRNOOZ+tuzVSZEXiK2ihokO0/AoF/8LZuICEqUYzO9rdCWIpDLrup1NaWV1b3yhvVra2d3b3qvsHHRMlmkObRzLSvYAZkEJBGwVK6MUaWBhI6AbT68zvPoA2IlJ3OIthELKJEmPBGVrJ9yNrZtm0NR9Wa27dzUGXiVeQGinQGla//FHEkxAUcsmM6XtujIOUaRRcwrziJwZixqdsAn1LFQvBDNL85jk9SQzDiMagqZA0F+F3ImWhMbMwsJMhw3uz6GXif14/wfHlIBUqThAUzxahkJAvMlwL+y/QkdCAyLLLgQpFOdMMEbSgjHMrJradiu3DW/x+mXQade+s3rg9rzWvimbK5Igck1PikQvSJDekRdqEk5g8kWfy4jw6r86b8/4zWnKKzCH5A+fjG1b5loM=</latexit>
lim
",derivate parziali funzioni variabili supposto determinato nito analogamente denisce derivata parziale rispetto punto limite latexit shabases nesm yxjzvxl xicb efy hvwiv xni jkr rbk nhsgmnn bfio rmv ewmtn vzob kmn itjtwsrqvp gcb otbzufe cmy jqge spj zjks joq jfrs yjai mdm pvbl sap hti dcs wuhn ymn ecj uhqzc osh vipqk udgv tps qnuoen hwd cfq bpxb wnmnpt mepwez xiv eem sejt qda ugolmhy jngmh ohlow rukopc nzh vxauzv zopw bmdw cgc qbuo gji gftqv vpvvv kdwh latexit shabaserz oqh oyvt pvym xyn vjroa bnicb edy hvwiv xni jkr igpjq oztuz kihok oao lzu uyz ord dlrup wvbyhv vradbqvs rmlmk lsv bgw mua wbh tzv oith gvr ztm wadz qgin qglaf hekx aucsm xtuj rrcwrzi zixqds nljk sqz magq mws jmhwuz gxifwf auzxahk jav mlw lyqkd cay fod sgj hmr jradiu dwxm xqadesrgrz wvimb igck pik dek rdq ekgk wfyjwrbz kkz afj gblo mlatexit lim
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#16,16," 17
Osserviamo che, mentre per le funzioni di una variabile la derivabilità in un 
punto implica la continuità in tale punto, non sussiste il fatto analogo per le 
funzioni di due variabili.Derivate Parziali di 
Funzioni di più Variabili 
Possono cioè in un punto esistere le due derivate parziali senza che la 
funzione g sia continua in esso.
Tutte le considerazioni fatte ﬁno ad ora sulle funzioni di due variabili si 
estendono immediatamente al caso delle funzioni di più di due variabili:
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>",osserviamo che mentre funzioni variabile derivabilit punto implica continuit tale punto sussiste fatto analogo funzioni due parziali funzioni variabili possono cio punto esistere due derivate parziali senza funzione continua esso tutte considerazioni fatte no ora funzioni due variabili estendono immediatamente caso funzioni due variabili gwww latexit shabasei fyb paax ezqi xicb lss fjtri mfq gclq qkuh gkblx qlj xuvg jmbiw vglh vlfux iikdu hrb zcz dzpy jyanpmdmd lct lyiruj jrojke sqjf rew ioa rex etr umeba jsgb qyk bwdopb mqm vabf bugwh znjiwoi oqg xbp vlf lxt vrw swx gnwj sqg hwvxl aou ist mxds nlir ixu vehai mbdh yct dhlfmdy erw cvki coh efnc pciok mpf rzb ijqk qnxy qojkl ikn rbj inpxlc vsiecccq hnr pbq gwlatexit
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#17,17,"Gradiente
 
18",gradiente
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#18,18,"Gradiente di una Funzione 
 19
Il gradiente di una funzione è una diretta generalizzazione della nozione di 
derivata per una funzione a più variabili.
rg(w)=2
6666666664@g(w)
@w0
@g(w)
@w1
···
@g(w)
@wn3
7777777775
<latexit sha1_base64=""06VfDqyZDj5rj/n4a5yMYNZXbn4="">AAADBnicpVI9j9QwEHXCxx3L1y6UNBYrpKNZJQcSNCedoKE8JPbupPVqNXFmc9Y5TmRPuFtZ6fkVtFDRIVr+BgX/BWeJBOxSwcjF6L158zxjZ7VWjpLkWxRfuXrt+s7ujcHNW7fv3B2O7h27qrESp7LSlT3NwKFWBqekSONpbRHKTONJdv6y40/eonWqMm9oVeO8hMKopZJAAVqMopEwkGkQhJfki3ZPZJXO/UX7mB9woXFJM85FhoUyHqyFVetlywc8hFhakF7UYEmB9tsd2vYXe7HwSdu2XIhw/kmebshlXpH7j34m9BsINHk/FxdWFWc0HyyG42SSrINvJ2mfjFkfR4vhd5FXsinRkNTg3CxNapr7zkpqDCaNwxrkORQ4C6mBEt3cr9+u5Y8aB1TxGi1Xmq9B/F3hoXRuVWahsgQ6c5tcB/6NmzW0fD73ytQNoZGdESmNayMnrQqfAnmuLBJBd3PkynAJFojQKg5SBrAJv6TbR7o5/XZyvD9Jn0z2Xz8dH77oN7PLHrCHbI+l7Bk7ZK/YEZsyGV1G76MP0cf4Xfwp/hx/+VkaR73mPvsj4q8/AIJp+C8=</latexit>
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>
Data la seguente funzione:
deﬁniamo gradiente di g il vettore le cui componenti sono le derivate 
parziali della funzione:",gradiente funzione gradiente funzione diretta nozione derivata funzione variabili rgw latexit shabase dqy zdjrjnay xbna dbnicp vij xcxx byrp cedo jpbup pvq fmc rpu zfk vrbg swcj lzxj vwjp rfu xrtsujc wfv ohqr esp lsl wbqek npb jdvyeon mmo mkop mop ewk jfki xou bwo fho hqy fvetlywch fhak btsdv yxe sdu xihwkmebshl hjm hkfxd hyy ssr inv jmfj fkf rvhd fxsin ntg naprzkpq dca nwxrk betcru xmq bfho xru vwahsg qctc nmz dyt qno zgd esm nay mnr qqf anmu jbd pkyn foj qkg sbr ajv rox zyv jnz xzd chb zky ezsy mpcf xfwphxvka pvsjqa gwww latexit shabasei fyb paax ezqi xicb lss fjtri mfq gclq qkuh gkblx qlj xuvg jmbiw vglh vlfux iikdu hrb zcz dzpy jyanpmdmd lct lyiruj jrojke sqjf rew ioa rex etr umeba jsgb qyk bwdopb mqm vabf bugwh znjiwoi oqg xbp vlf lxt vrw swx gnwj sqg hwvxl aou ist mxds nlir ixu vehai mbdh yct dhlfmdy erw cvki coh efnc pciok mpf rzb ijqk qnxy qojkl ikn rbj inpxlc vsiecccq hnr pbq gwlatexit data seguente funzione deniamo gradiente vettore componenti derivate parziali funzione
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#19,19," 
20
w0w1ŵ
ŵ0ŵ1gradiente:
ijrg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
W(t)gGradiente di una Funzione ",ww gradiente ijrgwgw wigw latexit pqiq yyx emwd lta cknicl ntt ugig xla cqk kjce jcysbu gip wfvrgv qokfg tsz znk nwgz mxn yly zvb rkyc udki swqv gspwsvq wjnr cdk yaqqdkh evm nea smrgvm ibw jcg psvfd hnjzjdhep snnn hjea pfb exta awte ijab ejzvr sqiz kbtd kqjng ibh kohgxtz pla yfy gxi vzk bxdu gun fsah ici ulcud rcg aei vherx pdt gpy wbm vfj wwm tnb fms bxs blvhlag pnkr nkzxlh alatexit wtg gradiente funzione
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#2,2,"Richiami sulle 
Funzioni Convesse
 
3",richiami funzioni convesse
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#20,20," 
21
w0w1ŵ
ŵ0ŵ1
ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>W(t)gGradiente di una Funzione ",ww rgwgw wigw latexit pqiq yyx emwd lta cknicl ntt ugig xla cqk kjce jcysbu gip wfvrgv qokfg tsz znk nwgz mxn yly zvb rkyc udki swqv gspwsvq wjnr cdk yaqqdkh evm nea smrgvm ibw jcg psvfd hnjzjdhep snnn hjea pfb exta awte ijab ejzvr sqiz kbtd kqjng ibh kohgxtz pla yfy gxi vzk bxdu gun fsah ici ulcud rcg aei vherx pdt gpy wbm vfj wwm tnb fms bxs blvhlag pnkr nkzxlh gradiente funzione
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#21,21," 
22w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij",wwg derivata direzionale w gradiente rgwgw wigw latexit pqiq yyx emwd lta cknicl ntt ugig xla cqk kjce jcysbu gip wfvrgv qokfg tsz znk nwgz mxn yly zvb rkyc udki swqv gspwsvq wjnr cdk yaqqdkh evm nea smrgvm ibw jcg psvfd hnjzjdhep snnn hjea pfb exta awte ijab ejzvr sqiz kbtd kqjng ibh kohgxtz pla yfy gxi vzk bxdu gun fsah ici ulcud rcg aei vherx pdt gpy wbm vfj wwm tnb fms bxs blvhlag pnkr nkzxlh alatexitn
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#22,22,"Derivata Direzionale 
 23
Si può dimostrare che la derivata direzionale secondo n è:
@g
@n=↵·@g
@w0+",derivata direzionale pu dimostrare derivata direzionale secondo ng
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#23,23," 
24w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij",wwg derivata direzionale w gradiente rgwgw wigw latexit pqiq yyx emwd lta cknicl ntt ugig xla cqk kjce jcysbu gip wfvrgv qokfg tsz znk nwgz mxn yly zvb rkyc udki swqv gspwsvq wjnr cdk yaqqdkh evm nea smrgvm ibw jcg psvfd hnjzjdhep snnn hjea pfb exta awte ijab ejzvr sqiz kbtd kqjng ibh kohgxtz pla yfy gxi vzk bxdu gun fsah ici ulcud rcg aei vherx pdt gpy wbm vfj wwm tnb fms bxs blvhlag pnkr nkzxlh alatexitn
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#24,24," 25
La proprietà citata in precedenza del vettore gradiente, ossia il fatto che il 
gradiente fornisce direzione della pendenza più ripida, è alla base di 
algoritmi di Ricerca Locale che operano in spazi continui.
Tali algoritmi si dividono in due classi principali: 
•
Algoritmi a Salita più Ripida (Hill-Climbing) 
•
Algoritmi a Discesa del Gradiente (Gradient Descent)
Algoritmo Gradient Descent",propriet citata precedenza vettore gradiente ossia fatto gradiente fornisce direzione pendenza ripida base algoritmi ricerca locale operano spazi continui tali algoritmi dividono due classi principali algoritmi salita ripida hill climbing algoritmi discesa gradiente gradient descent algoritmo gradient descent
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#25,25," 
26
w0w1g
ŵ
ŵ0ŵ1
ij
W(t+1)W(t)
- 𝛼 * gradiente
Algoritmo Gradient Descent",wwg wtwt gradiente algoritmo gradient descent
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#26,26,"Algoritmo Gradient Descent
 
27w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrg(w(t))k2>✏
w(t+1) w(t)",algoritmo gradient descent oppure inizializziamo modo casuale
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#27,27,"Algoritmo Gradient Descent
 
28
Funzione non convessa di due variabili:",algoritmo gradient descent funzione convessa due variabili
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#28,28,"Richiami di Probabilità
 
29",richiami probabilit
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#29,29,"Variabili Aleatorie
Le quantità di interesse che sono determinate dal risultato di 
un esperimento casuale sono dette 
 variabili aleatorie
 . 
Poiché il valore di una variabile aleatoria è determinato 
dall’esito di un esperimento, possiamo assegnare delle 
probabilità ai suoi valori possibili. 
Esempi di v.a.: risultato del lancio di un dado, risultato del 
lancio di una moneta, ecc.
 
30",variabili aleatorie quantit interesse determinate risultato esperimento casuale dette variabili aleatorie poich valore variabile aleatoria determinato dallesito esperimento possiamo assegnare probabilit valori possibili esempi risultato lancio dado risultato lancio moneta ecc
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#3,3,"Insiemi Convessi 
 4Un insieme C in uno spazio vettoriale è convesso  se, comunque si scelgano 
due punti v e w appartenenti a C, il segmento che unisce i due punti 
appartiene a C.
Più formalmente:
Un insieme C in uno spazio vettoriale è convesso  se, ∀ v, w ∈ C, e ∀ λ ∈ [0, 1], si 
ha:
",insiemi convessi insieme spazio vettoriale convesso comunque scelgano due punti appartenenti segmento unisce due punti appartiene formalmente insieme spazio vettoriale convesso
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#30,30,"Valore Atteso
Il concetto di Valore Atteso è uno dei più importanti concetti 
in tutta la teoria della probabilità. 
Sia X una variabile aleatoria discreta che può assumere i 
valori x
 1
, x
2
, …, x
 N
. Il Valore Atteso di X è il numero: 
 
31E[X],NX
i=1[xi·P(X=xi)]",valore atteso concetto valore atteso importanti concetti tutta teoria probabilit variabile aleatoria discreta pu assumere valori valore atteso numero exn ixipxxi
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#31,31,"Valore Atteso
 
32
Si tratta della media pesata dei valori possibili di X, usando 
come pesi le probabilità che tali valori vengano assunti da X. 
Per questo E[X] è anche detto 
 media
  di X (termine che però è 
sconsigliabile), oppure 
 aspettazione
  (
expectation
 ). ",valore atteso tratta media pesata valori possibili usando pesi probabilit tali valori vengano assunti detto media termine per oppure aspettazione expectation
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#32,32,"Valore Atteso
Sia X il punteggio che si ottiene lanciando un dado non 
truccato. Quanto vale E[X]?
 
33E[X]=1 ·1
6+2 ·1
6+3 ·1
6+4 ·1
6+5 ·1
6+6 ·1
6=7
2=3.5
ESEMPIO: lancio di un dado",valore atteso punteggio ottiene lanciando dado truccato vale lancio dado
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#33,33,"Valore Atteso
Si noti che in questo esempio il valore atteso di X non è uno 
dei possibili valori che X può assumere.  
Perciò, anche se E[X] è chiamato 
 valore atteso
  di X, ciò non 
vuole affatto dire che noi ci attendiamo di vedere questo 
valore, ma piuttosto che ci aspettiamo che sia il limite a cui 
tende il punteggio medio del dado su un numero crescente di 
ripetizioni.
 
34
ESEMPIO: lancio di un dado",valore atteso noti esempio valore atteso possibili valori pu assumere perci chiamato valore atteso ci vuole affatto dire attendiamo vedere valore piuttosto aspettiamo limite tende punteggio medio dado numero crescente ripetizioni lancio dado
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#34,34,"Valore Atteso
ESEMPIO: Indicator Function
 
35E[I]=1 ·P(I= 1) + 0 ·P(I= 0) = P(I= 1) = P(A)
Se I[A] è la funzione indicatrice di un evento A, ossia se:
     allora:
Quindi il valore atteso della indicator function di un evento è 
la probabilità di quest’ultimo.I[A],8
<
:1 se A si veriﬁca
0 se A non si veriﬁca",valore atteso indicator function pi pi funzione indicatrice evento ossia allora quindi valore atteso indicator function evento probabilit verica verica
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#35,35,"Valore Atteso
Proprietà di E
 
36
Si riportano qui di seguito alcune proprietà della funzione E (a e 
b sono variabili aleatorie):
E[a+b]= E[a]+E[b]
E[k·a]= k·E[a] (k costante)
E[a·b]= E[a]·E[b]( aebi n d i p e n d e n t i )",valore atteso propriet riportano qui seguito alcune propriet funzione variabili aleatorie eab eaeb eka kea costante eab eaeb aebi
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#36,36,"Varianza
 
37
Sia X una variabile aleatoria con media 
 μ
. La varianza di X è la 
quantità:
Var(X),E[(X",varianza variabile aleatoria media varianza quantit varxex
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#37,37,"Varianza
 
38
Esiste una formula alternativa per la varianza, che si ricava in 
questo modo:
ossia:
Var(X)=E[X2]",varianza esiste formula alternativa varianza ricava modo ossia varxex
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#4,4,"Insiemi Convessi 
 5Vediamolo nel caso a due dimensioni:L’espressione: 
corrisponde dunque ai punti appartenenti al  segmento che unisce i due punti 
v e w, al variare di λ ∈ [0, 1].",insiemi convessi vediamolo caso due corrisponde dunque punti appartenenti segmento unisce due punti variare
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#5,5," 
6wv
λv + (1-λ)wλ(v - w)
λv + (1- λ)w = w + λ(v-w)
λ = 1
λ = 0Insiemi Convessi 
[caso a due dimensioni]
λ > 1
λ < 0λ = 0.6
C",wv insiemi convessi caso due dimensioni
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#6,6," 7Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si ?
si
 noInsiemi Convessi 
[caso a due dimensioni]",vediamo ora alcuni esempi insiemi convessi convessi caso spazio due dimensioni insiemi convessi caso due dimensioni
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#7,7," 8Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si no
si
 noInsiemi Convessi 
[caso a due dimensioni]
",vediamo ora alcuni esempi insiemi convessi convessi caso spazio due dimensioni insiemi convessi caso due dimensioni
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#8,8,"Funzioni Convesse 
 9con",funzioni convesse con
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#9,9,"Deﬁnizione di Funzione  
Strongly Convex
 
10
Una funzione 
 g
 è detta 
 λ
-strongly convex
  se, per ogni 
 w
, 
v
 e 
α 
∈
 (0, 1), si ha:
Ovviamente, ogni funzione convessa è 0
 -strongly convex.g(↵v+( 1",denizione funzione strongly convex funzione detta strongly convex ogni ovviamente ogni funzione convessa strongly convexgv
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Ensembles di Decision Trees (Ex 06)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione ensembles decision trees
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#1,1,"Sommario
Ensembles 
Random Forests 
Gradient boosted regression trees",sommario ensembles random forests gradient boosted regression trees
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#10,10,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT.
11",scikit learn random forests breast cancer dataset esercizio crea dataset breast cancer alberi valuta laccuracy training test set confrontandola ottenuta singolo
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#11,11,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT. 
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
100
, 
random_state
 =
0
)
forest
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
forest
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
forest
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.972
L'accuracy è più alta rispetto al modello lineare e al DT. 
È possibile fare un tuning con i parametri max_features e l'approccio 
pruning, ma su alcuni dataset i valori di default possono essere già 
sufﬁcienti.
12",scikit learn random forests breast cancer dataset esercizio crea dataset breast cancer alberi valuta laccuracy training test set confrontandola ottenuta singolo xtrain xtest ytrain ytest cancer data cancer target randomstate forest random forest classifier nestimators randomstate forest fit xtrain ytrain print accuracy training set format forest score xtrain ytrain print accuracy test set format forest score xtest ytest accuracy training set accuracy test set laccuracy alta rispetto modello lineare possibile fare tuning parametri maxfeatures lapproccio pruning alcuni dataset valori default possono essere gi sufcienti
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#12,12,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
13",scikit learn random forests breast cancer dataset cosa aspetti feature importance ottenuta mediando valori singoli trees forest
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#13,13,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
Il valore aggregato ha più variabilità e tendenzialmente è più accurato. Il 
modello considera più features dando meno importanza alle singole (es. 
worst radius
 )
14
",scikit learn random forests breast cancer dataset cosa aspetti feature importance ottenuta mediando valori singoli trees forest valore aggregato variabilit tendenzialmente accurato modello considera features dando meno importanza singole worst radius
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#14,14,"Considerazioni sui Random forests (1)
I RF sono modelli di ML molto utilizzati essendo versatili, non richiedono 
lunghe fasi di tuning degli iperparametri e il rescaling dei dati. 
D'altro canto se hai bisogno di una rappresentazione compatta, il singolo 
DT è la soluzione migliore. È impossibile interpretare il valore di centinaia 
o più DT, soprattutto se hanno profondità elevate. 
Le implementazione dei RF possono essere facilmente parallelizzate su più 
CPU. Il parametro 
 n_jobs
  imposta il numero di core da impiegare (un 
valore pari a -1 indica l'uso di tutti i core). 
L'approccio random nei RF rende i modelli generati sugli stessi dati anche 
molto diversi tra loro. Se vuoi ottenere risultati riproducibili, imposta il 
parametro 
 random_state
 . 
I RF non mostrano buone prestazioni su dati sparsi e/o con molte features, 
es. dati testuali. I modelli lineare sono da preferire.
15",considerazioni random forests modelli molto utilizzati versatili richiedono lunghe fasi tuning iperparametri rescaling dati daltro canto bisogno compatta singolo soluzione migliore impossibile interpretare valore centinaia soprattutto profondit elevate implementazione possono essere facilmente parallelizzate parametro njobs imposta numero core impiegare valore pari indica luso core lapproccio random rende modelli generati dati molto diversi loro vuoi ottenere risultati riproducibili imposta parametro randomstate mostrano buone prestazioni dati sparsi molte features dati testuali modelli lineare preferire
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#15,15,"Considerazioni sui Random forests (2)
Un parametro elevato di n_estimators solitamente migliora le performance, 
ma richiede più tempo e memoria per il training. 
Una indicazione per il parametro 
 max_features
  è impostarlo pari a 
sqrt(n_features)
  per la classiﬁcazione, e 
 log2(n_features)
  per la 
regressione.
16",considerazioni random forests parametro elevato nestimators solitamente migliora performance richiede tempo memoria training indicazione parametro maxfeatures impostarlo pari classicazione regressione
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#16,16,"Ensembles: Gradient boosted regression trees
I 
Gradient boosted regression trees
  (
gradient boosting machines
 ) 
GBRT  
sono un approccio di 
 ensembles
 , e possono essere impiegate sia per la 
classiﬁcazione sia per la regressione.  
A differenza dei RF, gli alberi sono costruiti in modo sequenziale, dove 
ogni albero tenta di risolvere i problemi mostrati in precedenza. 
L'algoritmo è basato sull'approccio 
 boosting
  visto in precedenza.  
Al posto dell'elemento casuale, è impiegato l'approccio pre-pruning. Gli 
alberi prodotti non sono profondi (tipicamenti depth da 1 a 5), e questo 
rende il modello più compatto e veloce nelle predizioni. 
I singoli alberi sono modelli 
 semplici
  (in ML sono spesso chiamati 
 weak 
learners
 ) che producono buone performance su alcune istanze dei dati. 
Rispetto ai RF sono più sensibili alla scelta degli iperparametri, ma possono 
produrre risultati migliori, per questo sono spesso impiegati in scenari reali.
17",ensembles gradient boosted regression trees gradient boosted regression trees gradient boosting machines approccio ensembles possono essere impiegate classicazione regressione differenza alberi costruiti modo sequenziale ogni albero tenta risolvere problemi mostrati precedenza lalgoritmo basato sullapproccio boosting visto precedenza posto dellelemento casuale impiegato lapproccio pre pruning alberi prodotti profondi tipicamenti depth rende modello compatto veloce predizioni singoli alberi modelli semplici spesso chiamati weak learners producono buone performance alcune istanze dati rispetto sensibili scelta iperparametri possono produrre risultati migliori spesso impiegati scenari reali
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#17,17,"Ensembles: Gradient boosted regression trees
Oltre al pre-pruning e al numero di alberi (
 n_estimators
 ), un altro 
iperparametro fondamentale è il 
 learning_rate,
  che controlla quanto un 
albero deve correggere gli errori prodotti dal precedente. Un valore elevato 
genera modelli più complessi. Allo stesso modo, un valore elevato di 
n_estimators
  incrementa la complessità e può ridurre gli errori commessi. 
In scikit-learn, la classe 
 GradientBoostingClassiﬁer
  implementa gli GBRT. 
Nel caso del Breast cancer dataset, con 100 alberi, con profondità max pari 
a 3 e un learning rate pari a 0.1: 
from 
sklearn.ensemble 
 import 
GradientBoostingClassifier
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.958
18",ensembles gradient boosted regression trees oltre pre pruning numero alberi nestimators altro iperparametro fondamentale learningrate controlla albero deve correggere errori prodotti precedente valore elevato genera modelli complessi stesso modo valore elevato nestimators incrementa complessit pu ridurre errori commessi scikit learn classe gradient boosting classier implementa caso breast cancer dataset alberi profondit max pari learning rate pari import gradient boosting classifier xtrain xtest ytrain ytest cancer data cancer target randomstate gbrt gradient boosting classifier randomstate gbrt fit xtrain ytrain print accuracy training set format gbrt score xtrain ytrain print accuracy test set format gbrt score xtest ytest accuracy training set accuracy test set
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#18,18,"Gradient boosted regression trees
Otteniamo una accuracy pari al 100%, potrebbe indicare un possibile 
overﬁtting.  
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate.
19",gradient boosted regression trees otteniamo accuracy pari potrebbe indicare possibile overtting esercizio prova incrementare pre pruning ridurre learning rate
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#19,19,"Gradient boosted regression trees
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.991
Accuracy on test set: 0.972
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
learning_rate
 =
0.01
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.988
Accuracy on test set: 0.965
Entrambi gli approcci riducono la complessità e l'accuracy sul training set. 
In questo scenario, ridurre la profondità migliora maggiormente le 
performance.
20",gradient boosted regression trees esercizio prova incrementare pre pruning ridurre learning rate gbrt gradient boosting classifier randomstate maxdepth gbrt fit xtrain ytrain print accuracy training set format gbrt score xtrain ytrain print accuracy test set format gbrt score xtest ytest accuracy training set accuracy test set gbrt gradient boosting classifier randomstate learningrate gbrt fit xtrain ytrain print accuracy training set format gbrt score xtrain ytrain print accuracy test set format gbrt score xtest ytest accuracy training set accuracy test set entrambi approcci riducono complessit laccuracy training set scenario ridurre profondit migliora maggiormente performance
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#2,2,"Ensembles
In ML, l'
 ensembles
  un approccio che combina più modelli di ML per 
creare un nuovo modello più soﬁsticato, che potenzialmente aggrega i 
beneﬁci dei singoli modelli.  
Esistono vari approcci di ensembles. Due approcci basati sui decision trees 
(
DT
) si sono dimostrati molto adatti in vari domini: 
Random forests 
Gradient boosted decision trees.
3",ensembles ensembles approccio combina modelli creare nuovo modello sosticato potenzialmente aggrega beneci singoli modelli esistono vari approcci ensembles due approcci basati decision trees dimostrati molto adatti vari domini random forests gradient boosted decision trees
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#20,20,"Gradient boosted regression trees
Avendo impiegato 100 alberi, è poco pratico visualizzare le decision 
boundaries di ognuno, ma possiamo analizzare le feature importance. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
plot_feature_importances_cancer
 (
gbrt
)
Noti differenze rispetto ai RF?
21
",gradient boosted regression trees impiegato alberi poco pratico visualizzare decision boundaries ognuno possiamo analizzare feature importance gbrt gradient boosting classifier randomstate maxdepth gbrt fit xtrain ytrain gbrt noti differenze rispetto
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#21,21,"Gradient boosted regression trees
I generale otteniamo 
 importance
  simili, ma in questo caso alcune features 
hanno peso pari a 0, cioè sono completamente ignorate dal modello.
22
",gradient boosted regression trees generale otteniamo importance simili caso alcune features peso pari cio completamente ignorate modello
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#22,22,"Gradient boosted regression trees: considerazioni (1)
Entrambi gli approcci ensembles mostrano buoni risultati su dati simili. Si 
può applicare prima l'approccio RF, piuttosto robusto.  
I GBRT richiedono un tuning degli iperparametri più lungo rispetto ai RF. 
Se il tempo impiegato per la predizione non è soddisfacente, o è 
fondamentale raggiungere una accuracy massima, si può considerare il 
GBRT. 
Come per i RF, i GBRT funzionano bene senza rescaling, e su combinazioni 
di feature binary o continous. Ma non sono efﬁcienti per dataset con molte 
features. 
I due iperparametri fondamentali sono 
 n_estimators
  e 
learning_rate
 . Sono 
dipendenti l'uno dall'altro. Un basso learning rate richiede più alberi per 
raggiungere la stessa complessità. Un valore elevato di 
 n_estimators  
migliora il modello, ma fa tendere il modello all'overﬁtting. 
Tipicamente si imposta 
 n_estimators
  in base alle risorse a disposizione, 
dopodiché si ottimizza il valore 
 learning_rates
 .
23",gradient boosted regression trees considerazioni entrambi approcci ensembles mostrano buoni risultati dati simili pu applicare prima lapproccio piuttosto robusto richiedono tuning iperparametri lungo rispetto tempo impiegato predizione soddisfacente fondamentale raggiungere accuracy massima pu considerare funzionano bene senza rescaling combinazioni feature binary continous efcienti dataset molte features due iperparametri fondamentali nestimators learningrate dipendenti luno dallaltro basso learning rate richiede alberi raggiungere stessa complessit valore elevato nestimators migliora modello tendere modello allovertting tipicamente imposta nestimators base risorse disposizione dopodich ottimizza valore learningrates
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#23,23,"Gradient boosted regression trees: considerazioni (2)
Altro iperparametro fondamentale è 
 max_depth
  (o alternativamente 
max_leaf_nodes
 ) per ridurre la complessità per ogni albero. Tipicamente si 
imposta a un valore molto basso, es. < 5.  
Con dataset di larghe dimensioni, si può considerare anche la libreria 
xgboost
 , che possiede una implementazione più ottimizzata.
24",gradient boosted regression trees considerazioni altro iperparametro fondamentale maxdepth maxleafnodes ridurre complessit ogni albero tipicamente imposta valore molto basso dataset larghe dimensioni pu considerare libreria xgboost possiede implementazione ottimizzata
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#24,24,"Esercizio su ensembles
Esercizio
 : impiegare i due approcci ensembles sui restanti dataset introdotti 
nelle precedenti esercitazioni: 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Boston housing dataset
  (regressione) 
Valutare la accuracy rispetto all'approccio basato sulla regressione lineare 
e al singolo decision tree.  
Operare un tuning degli iperparametri per incrementare le performance. 
25",esercizio ensembles esercizio impiegare due approcci ensembles restanti dataset introdotti precedenti esercitazioni forge dataset wave dataset regressione boston housing dataset regressione valutare accuracy rispetto allapproccio basato regressione lineare singolo decision tree operare tuning iperparametri incrementare performance
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#25,25,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
26",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#3,3,"Ensembles: Random forests
I 
random forests
  (
RF
) sono una collezione di DTs, ognuno costruito in 
modo leggermo diverso dall'altro durante il training. 
I DTs tendono a mostrare overﬁtting. I RF tendono ad affrontare questa 
problematica: ogni albero può mostrare overﬁtting su certi dati, ma se ne 
costruiamo diversi in modo indipendente e mediamo i risultati complessivi, 
l'effetto dell'overﬁtting si riduce.  
Per creare diversi DTs, introduciamo un elemento casuale durante il 
processo di training, ad esempio selezionando: 
diversi set di training 
diverse features in ogni split test
4",ensembles random forests random forests collezione ognuno costruito modo leggermo diverso dallaltro durante training tendono mostrare overtting tendono affrontare problematica ogni albero pu mostrare overtting certi dati costruiamo diversi modo indipendente mediamo risultati complessivi leffetto dellovertting riduce creare diversi introduciamo elemento casuale durante processo training esempio selezionando diversi set training diverse features ogni split test
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#4,4,"Scikit-learn: Random forests
In scikit-learn esiste una implementazione dei RF per la classiﬁcazione e 
per la regressione: 
 RandomForestClassiﬁer
  e 
RandomForestRegressor
 . 
Il numero di DTs è un iperparametro del modello RF e si imposta col 
parametro 
 n_estimators
  del costruttore (es. 10). 
Inizialmente si costruisce un 
 bootstrap sample
  dei dati.  
Dal training set estraiamo 
 n_samples
  istanze in modo casuale, con 
ripetizione, e ripetiamo n_samples volte. 
Il dataset che si ottiene è grande come quello originale, ma alcune 
istanze si possono ripetere, altre sono mancanti (approssimativamente 
1/3)  
Es.: se il dataset = ['a', 'b', 'c', 'd'], un possibile bootstrap è ['b', 'd', 'd', 
'c'], un altro ['d', 'a', 'd', 'a']. 
Dopodiché si addestra un DT per ogni boostrap sample.
5",scikit learn random forests scikit learn esiste implementazione classicazione regressione random forest classier random forest regressor numero iperparametro modello imposta parametro nestimators costruttore inizialmente costruisce bootstrap sample dati training set estraiamo nsamples istanze modo casuale ripetizione ripetiamo nsamples volte dataset ottiene grande originale alcune istanze possono ripetere altre mancanti dataset possibile bootstrap altro dopodich addestra ogni boostrap sample
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#5,5,"Scikit-learn: Random forests
Un ulteriore elemento casuale è introdotto in ogni nodo dell'albero. 
Durante la costruzione, invece di scegliere il test migliore, si selezionando 
un modo casuale un sottoinsieme di features e si seleziona la migliore 
considerando tale sottoinsieme.  
Il numero di features è impostato col parametro del costruttore 
max_features
  (ulteriore iperparametro del modello). 
Un valore alto di 
 max_features
  riduce la casualità nel modello RF, ma 
migliora il ﬁt sui dati. Un valore basso produce degli alberi molto 
complessi per raggiungere lo stesso livello di ﬁt. 
Per generare l'output, ogni DT è valutato sull'istanza in input e i risultati 
sono sottoposti a 
 soft voting, 
 cioè le probabilità per ogni 
 label
 ottenute dai 
singoli DT sono mediate e la classe con probabilità più alta è l'output del 
RF.
6",scikit learn random forests ulteriore elemento casuale introdotto ogni nodo dellalbero durante costruzione invece scegliere test migliore selezionando modo casuale sottoinsieme features seleziona migliore considerando tale sottoinsieme numero features impostato parametro costruttore maxfeatures ulteriore iperparametro modello valore alto maxfeatures riduce casualit modello migliora dati valore basso produce alberi molto complessi raggiungere stesso livello generare loutput ogni valutato sullistanza input risultati sottoposti soft voting cio probabilit ogni label ottenute singoli mediate classe probabilit alta loutput
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#6,6,"Scikit-learn: Random forests e two_moons
Esercizio
 : col dataset 
 two_moons
  crea un modello RF con 5 alberi. 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
...
7",scikit learn random forests twomoons esercizio dataset twomoons crea modello alberi import random forest classifier import makemoons makemoons nsamples noise randomstate
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#7,7,"Scikit-learn: Random forests e two_moons
Col dataset two_moons creiamo un modello RF con 5 alberi: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
stratify
 =
y
,
random_state
 =
42
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
5
, 
random_state
 =
2
)
forest
.
fit
(
X_train
, 
y_train
)
I parametri sono salvati nella variabile 
 estimator_
  del modello. 
Possiamo rappresentare i decision boundary per ogni modello: 
fig
, 
axes 
= 
plt
.
subplots
 (
2
, 
3
, 
figsize
=
(
20
, 
10
))
for 
i
, (
ax
, 
tree
) in 
enumerate
 (
zip
(
axes
.
ravel
(), 
forest
.
estimators_
 )):
ax
.
set_title
 (
""Tree {}""
 .
format
(
i
))
mglearn
.
plots
.
plot_tree_partition
 (
X_train
, 
y_train
, 
tree
, 
ax
=
ax
)
mglearn
.
plots
.
plot_2d_separator
 (
forest
, 
X_train
, 
fill
=
True
, 
ax
=
axes
[
-
1
, 
-
1
],
alpha
=.
4
)
axes
[
-
1
, 
-
1
]
.
set_title
 (
""Random Forest""
 )
mglearn
.
discrete_scatter
 (
X_train
[:, 
0
], 
X_train
[:, 
1
], 
y_train
)
8",scikit learn random forests twomoons dataset twomoons creiamo modello alberi import random forest classifier import makemoons makemoons nsamples noise randomstate xtrain xtest ytrain ytest stratify randomstate forest random forest classifier nestimators randomstate forest fit xtrain ytrain parametri salvati variabile estimator modello possiamo rappresentare decision boundary ogni modello fig axes plt subplots figsize tree enumerate zip axes ravel forest estimators settitle tree format mglearn plots xtrain ytrain tree mglearn plots forest xtrain fill true axes alpha axes settitle random forest mglearn xtrain xtrain ytrain
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#8,8,"Scikit-learn: Random forests e two_moons
Cosa puoi notare riguardo i modelli e i training set? 
9
",scikit learn random forests twomoons cosa puoi notare riguardo modelli training set
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#9,9,"Scikit-learn: Random forests e two_moons
Ogni modello ha decision boundaries distinti, dove alcune istanze non sono 
correttamente classiﬁcati.  
Ogni modello ha un training set leggermente distinto: alcune istanze del 
training set complessivo non sono presenti. 
Le boundaries del modello ﬁnale sono più ""smooth"". 
10
",scikit learn random forests twomoons ogni modello decision boundaries distinti alcune istanze correttamente classicati ogni modello training set leggermente distinto alcune istanze training set complessivo presenti boundaries modello nale smooth
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Voting e Stacking ensembles (Ex 07)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione voting stacking ensembles
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#1,1,"Sommario
Voting 
Stacking 
Mutilayer Stacking 
Datasets MNIST e notMNIST 
Altri dataset di immagini 
Esercitazioni",sommario voting stacking mutilayer stacking datasets altri dataset immagini esercitazioni
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#10,10,"Multilayer Stacking ensemble
È possibile considerare più blender, ognuno basato su un modello distinto 
(es. regressione lineare, random forest, etc), ottenendo un nuovo layer. 
In questo caso si suddivide il training set in 3 parti. La prima usata nel 
primo layer, come nel caso precedente. La seconda usata dai modelli che 
combinano le predizioni del primo layer. E la restate parte che combina le 
predizioni del secondo layer. 
Nota: scikit-learn non supporta lo stacking.  
Ma ci sono librerie open source, es.  
https://github.com/viisar/brew   
https://github.com/Menelau/DESlib  
11
",multilayer stacking ensemble possibile considerare blender ognuno basato modello distinto regressione lineare random forest etc ottenendo nuovo layer caso suddivide training set parti prima usata primo layer caso precedente seconda usata modelli combinano predizioni primo layer restate parte combina predizioni secondo layer nota scikit learn supporta stacking librerie open source eslib
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#11,11,"MNIST
E’ un dataset molto conosciuto (rielaborato da 
 NIST
 ) di cifre per addestrare sistemi 
di classiﬁcazione basati sulle immagini. 
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others."" 
Contiene 60K immagini di addestramento e 10K di training. 
1998: un linear classiﬁer ha ottenuto 7.6% di errore rate. 
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%. 
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono centrate 
in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare una cifra. 
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12",dataset molto conosciuto rielaborato cifre addestrare sistemi classicazione basati immagini work work all well work may still fail others contiene immagini addestramento training linear classier ottenuto errore rate mezzo architettura convolutional neural networks arrivati ogni immagine rappresentata scala grigi livelli cifre centrate box pixel valori rappresentare cifra recognizerdata implementazione online ott nethtml
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#12,12,"MNIST: train.csv e test.csv
Il ﬁle train.csv contiene una matrice con 785 colonne. La prima 
colonna è il 
 label
 della cifra (es. 3) e le restanti colonne sono la 
rappresentazione sequenziale dell’immagine: 
Il ﬁle test.csv ha la stessa rappresentazione senza la prima colonna. 
Esempio di immagini:
13
",traincsv testcsv le traincsv contiene matrice colonne prima colonna label cifra restanti colonne sequenziale dellimmagine le testcsv stessa senza prima colonna esempio immagini
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#13,13,"MNIST: Considerazioni
Non è impiegato per sistemi avanzati poiché è un task semplice. 
Algoritmi classici di ML raggiungono i 97% di precisione, 
approcci Deep Learning il 99.7% 
Troppo utilizzato: si rischia di ideare nuovi approcci adatti solo per 
questo dataset. 
Molto diverso dai task studiati oggi.
14",considerazioni impiegato sistemi avanzati poich task semplice algoritmi classici raggiungono precisione approcci deep learning troppo utilizzato rischia ideare nuovi approcci adatti solo dataset molto diverso task studiati oggi
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#14,14,"MNIST dataset
scikit-learn include il dataset che può essere facilmente usato: 
from
 sklearn.datasets 
 import
 fetch_openml
import
 numpy 
as
 np
mnist = fetch_openml(
 'mnist_784'
 , version=
 1
, as_frame=
 False
)
mnist.target = mnist.target.astype(np.uint8)
from
 sklearn.model_selection 
 import
 train_test_split
# 50K instanze per il training, 10K validation e 10K test
X_train_val, X_test, y_train_val, y_test = train_test_split(
    mnist.data, mnist.target, test_size=
 10000
, random_state=
 42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=
 10000
, random_state=
 42
)
15",dataset scikit learn include dataset pu essere facilmente usato import fetchopenml import numpy mnist fetchopenml mnist version asframe false mnisttarget import instanze training validation test xtrainval xtest ytrainval ytest mnistdata mnisttarget testsize randomstate xtrain xval ytrain yval xtrainval ytrainval testsize randomstate
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#15,15,"notMNIST
Simile a MNIST, contiene 10 labels (lettere da A a J), ma ogni lettera 
nel dataset occorre con font diversi, es: 
http://yaroslavvb.blogspot.ﬁ/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione 
notMNIST_small.tar.gz -> test 
16
",simile contiene labels lettere ogni lettera dataset occorre font diversi datasethtml download tlargetargz training validazione tsmalltargz test
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#16,16,"fashion-MNIST
Fornito da Zalando. 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc). 
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST: 
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
17
",fashion fornito zalando classi riferimento generi vestiario sandali shirt borse etc contiene immagini addestramento training ogni immagine rappresentata scala grigi pixel mnist side side accuracy fashion httpfashion mnists websiteeu central
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#17,17,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes. 
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su 
WordNet. In media 1K immagini per concetto. 
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi. 
Open Image
 : 9 milioni di URLs di immagini annotate con bounding 
boxes e migliaia di classi. 
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 
questions per immagini con 10 ground truth answers per question. 
The Street View House Numbers
 : 600K immagini di numeri civici. 
Risultati sperimentali ottenuti per varie architetture avanzate: 
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
18",altri dataset popolari immagini colour images classes image net milioni immagini organizzate etichettate word net media immagini concetto task milioni immagini classi open image milioni rls immagini annotate bounding boxes migliaia classi visual open ended questions immagini media questions immagini ground truth answers question street view house numbers immagini numeri civici risultati sperimentali ottenuti varie architetture avanzate
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#18,18,"Esercitazione: Voting Classiﬁer
Impiega il dataset MNIST con uno split 50K/10K/10K. Scegli almeno tre 
classiﬁcatori e addestrali singolarmente.  
Crea un ensemble Voting, e valutalo sia con approccio soft che hard voting, 
sia sul validation sia sul test set.  
Confronta i risultati con i classiﬁcatori singoli. 
Prova a rimuovere il classiﬁcatore che si comporta meglio e valuta 
nuovamente le prestazioni.
19",esercitazione voting classier impiega dataset split scegli almeno tre classicatori addestrali singolarmente crea ensemble voting valutalo approccio soft hard voting validation test set confronta risultati classicatori singoli prova rimuovere classicatore comporta meglio valuta nuovamente prestazioni
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#19,19,"Esercitazione: Stacking Ensemble
Esegui i singoli classiﬁcatori scelti in precedenza e colleziona gli output sul 
validation set. 
Crea un nuovo training set con tali predizioni. Ogni istanza del set è una 
vettore che contiene l'insieme di predizioni per una certa immagine, e il 
target e la classe associata all'immagine. Addestra un classiﬁcatore con tale 
training set. Valutalo sul test set. 
Hai appena realizzato un Stacking ensemble.
20",esercitazione stacking ensemble esegui singoli classicatori scelti precedenza colleziona output validation set crea nuovo training set tali predizioni ogni istanza set vettore contiene linsieme predizioni certa immagine target classe associata allimmagine addestra classicatore tale training set valutalo test set appena realizzato stacking ensemble
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#2,2,"Ensembles: Voting
L'approccio voting si ispira alla ﬁlosoﬁa 
 wisdom of the crowd.
  Supponiamo 
di avere più classiﬁcatori (es. Logistic regression, SVM, Random forest, k-
NN). Prendiamo la predizione di ognuno e scegliamo quella che riceve 
""più voti"". Questa forma di aggregazione prende il nome di 
 hard-voting
 . 
Se partiamo da weak classiﬁers con accuracy non soddisfacente, il 
classiﬁcatore risultante può raggiungere accuracy elevate.
3
",ensembles voting lapproccio voting ispira losoa wisdom crowd supponiamo avere classicatori logistic regression random forest prendiamo predizione ognuno scegliamo riceve pi voti forma aggregazione prende nome hard voting partiamo weak classiers accuracy soddisfacente classicatore risultante pu raggiungere accuracy elevate
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#20,20,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
21",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#3,3,"Scikit-learn: Voting
La classe 
 VotingClassiﬁer
  di scikit-learn implementa l'approccio.  
Esercizio
 : completa il seguente frammento di codice basandoti sulla 
documentazione online di VotingClassiﬁer. 
from 
sklearn.ensemble 
 import 
VotingClassifier
(... importa gli altri classificatori ...)
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
...
voting_clf 
 = 
VotingClassifier
 (
    
...
, 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
4",scikit learn voting classe voting classier scikit learn implementa lapproccio esercizio completa seguente frammento codice basandoti documentazione online voting classier import voting classifier importa altri classificatori import import makemoons noise randomstate xtrain xtest ytrain ytest randomstate votingclf voting classifier voting hard votingclf fit xtrain ytrain
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#4,4,"Scikit-learn: Voting
Impieghiamo SVM, RandomForest e LogisticRegression: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.ensemble 
 import 
VotingClassifier
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
SVC
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
log_clf 
 = 
LogisticRegression
 ()
rnd_clf 
 = 
RandomForestClassifier
 ()
svm_clf 
 = 
SVC
()
voting_clf 
 = 
VotingClassifier
 (
    
estimators
 =
[(
'lr'
, 
log_clf
), (
'rf'
, 
rnd_clf
), (
'svc'
, 
svm_clf
)], 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
5",scikit learn voting impieghiamo random forest logistic regression import random forest classifier import voting classifier import logistic regression sklearnsvm import import import makemoons noise randomstate xtrain xtest ytrain ytest randomstate logclf logistic regression rndclf random forest classifier svmclf votingclf voting classifier estimators logclf rndclf svc svmclf voting hard votingclf fit xtrain ytrain
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#5,5,"Scikit-learn: Voting
(segue)
from 
sklearn.metrics 
 import 
accuracy_score
for 
clf 
in (
log_clf
, 
rnd_clf
, 
svm_clf
, 
voting_clf
 ):
    
clf
.
fit
(
X_train
, 
y_train
)
    
y_pred 
= 
clf
.
predict
(
X_test
)
    
print
(
clf
.
__class__
 .
__name__
 , 
accuracy_score
 (
y_test
, 
y_pred
))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.888
VotingClassifier 0.904
6",scikit learn voting segue sklearnmetrics import accuracyscore clf logclf rndclf svmclf votingclf clf fit xtrain ytrain ypred clf predict xtest print clf class name accuracyscore ytest ypred logistic regression random forest classifier voting classifier
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#6,6,"Scikit-learn: Voting
Se i classiﬁcatori impiegati sono in grado di stimare probabilità di 
appartenenza alle singole label, cioè implementano la funzione 
predict_proba(), il voting può valutare le medie delle probabilità prodotte 
da ogni classiﬁcatore.  
L'approccio si chiama 
 soft voting,
  e si seleziona col parametro voting del 
costruttore: 
    
voting
=
'soft'
Esercizio
 : controlla che i classiﬁcatori impiegati in precedenza 
implementino predict_proba() e, in caso affermativo, lancia nuovamente il 
codice precedente e valuta la differenza di performance.
7",scikit learn voting classicatori impiegati grado stimare probabilit appartenenza singole label cio implementano funzione voting pu valutare medie probabilit prodotte ogni classicatore lapproccio chiama soft voting seleziona parametro voting costruttore voting soft esercizio controlla classicatori impiegati precedenza implementino predictproba caso affermativo lancia nuovamente codice precedente valuta differenza performance
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#7,7,"Scikit-learn: Voting
og_clf = LogisticRegression(solver=
 ""lbfgs""
, random_state=
 42
)
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
svm_clf = SVC(gamma=
 ""scale""
, probability=
 True
, random_state=
 42
)
voting_clf = VotingClassifier(
    estimators=[(
 'lr'
, log_clf), (
 'rf'
, rnd_clf), (
 'svc'
, svm_clf)],
    voting=
 'soft'
)
voting_clf.fit(X_train, y_train)
VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),
                             ('rf', RandomForestClassifier(random_state=42)),
                             ('svc', SVC(probability=True, random_state=42))],
                 
 voting='soft'
 )
from
·
sklearn.metrics
 ·
import
·
accuracy_score
for
·
clf
·
in
·
(log_clf,
 ·
rnd_clf,
 ·
svm_clf,
 ·
voting_clf):
    
clf.fit(X_train,
 ·
y_train)
    
y_pred
·
=
·
clf.predict(X_test)
    
print
(clf.__class__.__name__,
 ·
accuracy_score(y_test,
 ·
y_pred))
from sklearn.metrics import accuracy_score
for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.896
VotingClassifier 0.92
8",scikit learn voting ogclf logistic lbfgs randomstate rndclf random forest randomstate svmclf vcgamma scale probability true randomstate votingclf voting classifier estimators logclf rndclf svc svmclf voting soft ytrain voting logistic random forest svc votingsoft sklearnmetrics import accuracyscore clf logclf rndclf svmclf votingclf ytrain ypred print ypred sklearnmetrics import accuracyscore clf logclf rndclf svmclf votingclf ytrain ypred ypred logistic regression random forest classifier voting classifier
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#8,8,"Ensembles: Stacking
Un ulteriore approcio ensembles è lo 
 stacking
 , che sta per 
 stacked 
generalization
 . 
Invece di aggregare il risultato con una tecnica di voting, addestriamo un 
ulteriore modello per questo scopo, chiamato 
 blender
  o 
meta learner
 . 
9
",ensembles stacking ulteriore approcio ensembles stacking stacked generalization invece aggregare risultato tecnica voting addestriamo ulteriore modello scopo chiamato blender meta learner
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#9,9,"Stacking
Un approccio che spesso si impiega per addestrare il blender è il 
 hold-out 
set
. Inizialmente il training set è suddiviso in 2. Il primo è usato per 
addestrare i modelli nel primo layer, mentre il secondo (held-out) è usato 
per creare le predizioni. Per ogni istanza ci sono 3 predizioni. Tali 
predizioni costituiscono le features di una istanza in un 
 nuovo training set
 , 
il cui valore target è quello originale. Il blender è addestrato sul nuovo set.
10
",stacking approccio spesso impiega addestrare blender hold set inizialmente training set suddiviso primo usato addestrare modelli primo layer mentre secondo held out usato creare predizioni ogni istanza predizioni tali predizioni costituiscono features istanza nuovo training set valore target originale blender addestrato nuovo set
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al 
Clustering
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico introduzione clustering machine learning
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#1,1,"Sommario
Supervised e Unsupervised Learning 
Introduzione al Clustering 
Algoritmo k-means  
Algoritmo k-means++
 
2",sommario supervised unsupervised learning introduzione clustering algoritmo means algoritmo means
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#10,10,"k-means Clustering 
 
11
Vediamo un esempio di esecuzione dell’algoritmo nel caso in cui i 
data points siano quelli riportati in ﬁgura. 
Supponiamo di scegliere come numero di cluster: k=3 ",means clustering vediamo esempio esecuzione dellalgoritmo caso data points riportati gura supponiamo scegliere numero cluster
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#11,11,"k-means Clustering 
 
12
µ1,µ2,...,µ k
Scelta del numero di cluster k e inizializzazione dei k centroidi:
Esempio per k = 3
μ1
μ2
μ3",means clustering scelta numero cluster centroidi esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#12,12,"Voronoi Tesselation 
 
13
",voronoi tesselation
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#13,13,"k-means Clustering 
 
14
zi argmin
jkµj",means clustering argmin jkj
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#14,14,"k-Means Clustering 
 
15
Si ricalcolano i centroidi come media delle osservazioni assegnate 
ad ogni cluster:
µj=1
njX
i:zi=jxi
μ1
μ2μ3",means clustering ricalcolano centroidi media osservazioni assegnate ogni cluster izijxi
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#15,15,"k-Means Clustering 
 
16
zi argmin
jkµj",means clustering argmin jkj
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#16,16,"Algoritmo k-means 
 
17
L’algoritmo può essere pertanto sintetizzato come segue:
Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj",algoritmo means lalgoritmo pu essere pertanto sintetizzato segue scegliamo numero kdei cluster inizializziamo centroidi converged argmin jkj
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#17,17,"Algoritmo k-means 
come Coordinate Descent 
 
18µj argmin
µX
i:zi=jkµ",algoritmo means coordinate descent argmin izijk
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#18,18,"Algoritmo k-means 
come Coordinate Descent 
 
19
Abbiamo dunque la seguente versione equivalente dell’algoritmo:
dove si alternano le minimizzazioni (a): z dato 
 μ
 e (b): 
 μ
 dato z. Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj",algoritmo means coordinate descent dunque seguente versione equivalente dellalgoritmo alternano minimizzazioni dato dato scegliamo numero kdei cluster inizializziamo centroidi converged argmin jkj
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#19,19,"In genere k-means converge ad un ottimo locale. 
L’algoritmo è molto sensibile all’inizializzazione dei centroidi. 
Vediamo un esempio: 
 
20
Convergenza di k-means ",genere means converge ottimo locale lalgoritmo molto sensibile centroidi vediamo esempio convergenza means
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#2,2,"Supervised vs. Unsupervised 
Learning
Come sappiamo, molti problemi e metodi di Machine Learning 
rientrano in una delle due seguenti categorie: apprendimento 
supervisionato
  o 
non supervisionato
 . 
Gli esempi visti ﬁno ad ora rientrano nel dominio 
dell’apprendimento supervisionato: 
•
In quei casi (linear regression, logistic regression, ecc.) si 
hanno delle osservazioni che, a fronte di una certa 
conﬁgurazione delle features, ci dicono quale sia la 
soluzione corretta.
 
3",supervised unsupervised learning sappiamo molti problemi metodi machine learning rientrano due seguenti categorie apprendimento supervisionato supervisionato esempi visti no ora rientrano dominio supervisionato quei casi linear regression logistic regression ecc osservazioni che fronte certa congurazione features dicono soluzione corretta
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#20,20," 
21
Convergenza di k-means 
Data la scelta dei centroidi iniziali mostrata nella ﬁgura a sinistra, 
si ottiene il risultato mostrato a destra:",convergenza means data scelta centroidi iniziali mostrata gura sinistra ottiene risultato mostrato destra
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#21,21," 
22
Convergenza di k-means 
Altra scelta dei centroidi iniziali:",convergenza means altra scelta centroidi iniziali
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#22,22," 
23
Convergenza di k-means 
Altra scelta dei centroidi iniziali:",convergenza means altra scelta centroidi iniziali
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#23,23,"k-means++ 
 
24Arthur, D. e Vassilvitskii, S. “k-means++: the advantages of careful seeding”, in Proc. of the 
18th ACM-SIAM Symp. on Discrete Algorithms , 2007, pp. 1027-1035.
Bahmani, B., Moseley, B., Vattani, A., Kumar, R. e Vassilvitskii, S. “Scalable k-means++”, in 
Proc. of VLDB , 2012.
Come abbiamo visto, l’inizializzazione di k-means è critica ai ﬁni 
della qualità dell’ottimo locale trovato. 
Ora vediamo k-means++, un metodo che consiste in una 
particolare inizializzazione dei centroidi che in genere dà buoni 
risultati. 
Riferimenti:",means arthur vassilvitskii means advantages careful seeding proc symp discrete algorithms bahmani moseley vattani kumar vassilvitskii scalable means proc visto means critica ni qualit dellottimo locale trovato ora vediamo means metodo consiste particolare centroidi genere buoni risultati riferimenti
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#24,24,"k-means++ 
 
25
Smart initialization
 : 
1.
 Scegliere il primo centroide in modo casuale tra tutti i data 
points. 
2.
 Per ogni osservazione 
 x
i
, calcolare la distanza d(
 x
i
) tra 
x
i
 e il più 
vicino centroide. 
3.
 Scegliere il nuovo centroide tra i data point, con la probabilità 
di 
x
i
 di essere scelto proporzionale a d(
 x
i
) , ossia al quadrato 
della distanza tra 
 x
i
 e il centroide più vicino già scelto. 
4.
 Ripeti gli step 2 e 3 ﬁno ad arrivare a scegliere k centroidi.
2 ",means smart initialization scegliere primo centroide modo casuale data points ogni osservazione calcolare distanza vicino centroide scegliere nuovo centroide data point probabilit essere scelto proporzionale ossia quadrato distanza centroide vicino gi scelto ripeti step no arrivare scegliere centroidi
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#25,25,"k-means++: esempio 
 
26
Vediamo un esempio di inizializzazione con k=3, relativo alle 
osservazioni in ﬁgura:",means esempio vediamo esempio relativo osservazioni gura
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#26,26," 
27
Scelta random del primo cluster center:
k-means++: esempio ",scelta random primo cluster center means esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#27,27," 
28
Scelta del secondo cluster center. Si sceglie il punto con la 
probabilità maggiore, dove la probabilità è proporzionale a d(
 x
). 
In ﬁgura sono mostrate le varie distanze. 
2 
k-means++: esempio ",scelta secondo cluster center sceglie punto probabilit maggiore probabilit proporzionale gura mostrate varie distanze means esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#28,28," 
29
Supponiamo che venga scelto il secondo cluster center in verde: 
k-means++: esempio ",supponiamo venga scelto secondo cluster center verde means esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#29,29," 
30
Scelta dell’ultimo cluster center. Di nuovo, si sceglie il punto con 
la probabilità maggiore, dove la probabilità è proporzionale a 
d(
x
i
), quadrato della distanza tra il punto i e il più vicino 
centroide: 
2 
k-means++: esempio ",scelta dellultimo cluster center nuovo sceglie punto probabilit maggiore probabilit proporzionale quadrato distanza punto vicino centroide means esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#3,3,"Supervised vs. Unsupervised 
Learning
Nel caso non supervisionato ci troviamo in una situazione più 
impegnativa, nella quale abbiamo le varie osservazioni 
caratterizzate dai vari valori delle 
 features
 , ma per le quali non 
abbiamo disponibili le soluzioni. 
In questa situazione, in un certo senso dobbiamo lavorare alla 
cieca. 
La situazione è deﬁnita 
 unsupervised
  proprio perché nei 
 data 
points
  disponibili ci manca la risposta che può supervisionare la 
nostra analisi. 
 
4",supervised unsupervised learning caso supervisionato troviamo situazione impegnativa varie osservazioni caratterizzate vari valori features quali disponibili soluzioni situazione certo senso dobbiamo lavorare cieca situazione denita unsupervised proprio data points disponibili manca risposta pu supervisionare analisi
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#30,30," 
31
Supponiamo che il cluster center scelto sia quello in blu. I tre 
centroidi scelti sono quelli con cui inizializziamo l’algoritmo k-
means. 
k-means++: esempio ",supponiamo cluster center scelto blu tre centroidi scelti inizializziamo lalgoritmo means means esempio
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#31,31,"k-means++: pros & cons 
 
32
Eseguire k-means++ per individuare i centroidi iniziali è 
certamente più oneroso computazionalmente rispetto alla scelta 
random dei suddetti centroidi. 
Per contro, l’esecuzione di k-means con l’inizializzazione di k-
means++ è spesso più efﬁciente, nel senso che converge in genere 
più rapidamente. 
In generale possiamo dire che k-means++ tende a migliorare la 
qualità dell’ottimo locale trovato e diminuire il tempo di 
esecuzione. ",means pros cons eseguire means individuare centroidi iniziali certamente oneroso rispetto scelta random suddetti centroidi contro lesecuzione means means spesso efciente senso converge genere rapidamente generale possiamo dire means tende migliorare qualit dellottimo locale trovato diminuire tempo esecuzione
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#32,32,"Cluster Heterogeneity 
 
33
L’algoritmo k-means cerca di minimizzare la somma dei quadrati 
delle distanze (
 distortion
 ): 
Come abbiamo visto, in genere l’algoritmo trova un minimo 
locale. costo kmeans =kX
j=1X
i:zi=jkµj",cluster heterogeneity lalgoritmo means cerca minimizzare somma quadrati distanze distortion visto genere lalgoritmo trova minimo locale costo kmeans izijkj
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#33,33,"Cluster Heterogeneity 
 
34
Confrontiamo i seguenti due risultati: la ﬁgura a destra è 
sicuramente migliore. La ﬁgura a sinistra è più “eterogenea”. 
",cluster heterogeneity confrontiamo seguenti due risultati gura destra sicuramente migliore gura sinistra eterogenea
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#34,34,"Cosa accade al crescere di k 
 
35
Consideriamo il caso estremo k = N: 
•
 Signiﬁca che ogni cluster center è un data point. 
•
 Il costo (heterogeneity) è uguale a zero. 
Il costo (heterogeneity) decresce al crescere di k. ",cosa accade crescere consideriamo caso estremo signica ogni cluster center data point costo heterogeneity uguale zero costo heterogeneity decresce crescere
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#35,35,"Scelta del numero di cluster k 
 
36
“Elbow Method”: Un’euristica usata è quella di scegliere un punto 
che si trova nel “gomito” della curva: 
k (# di cluster)(minimo della 
cluster heterogeneity)costo_k_means 
minimo
123456",scelta numero cluster elbow method uneuristica usata scegliere punto trova gomito curva clusterminimo cluster minimo
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#36,36,"Riferimenti
 
37
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012.",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze apogeo edizione machine learning clustering retrieval university washington coursera flach machine learning art science algorithms make sense data cambridge university press murphy machine learning probabilistic approach press
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#4,4,"Clustering 
Dobbiamo chiederci quale tipo di analisi sia possibile in tale 
contesto. 
Possiamo ad esempio cercare di comprendere le relazioni tra le 
osservazioni. 
Un approccio che possiamo usare in tali situazioni è quello della 
cluster analysis
 , o 
clustering
 . 
L’obiettivo del 
 clustering
  è quello di veriﬁcare, date le features in 
input, se le osservazioni disponibili ricadono all’interno di gruppi 
relativamente distinti tra di loro. 
 
5",clustering dobbiamo chiederci tipo analisi possibile tale contesto possiamo esempio cercare comprendere relazioni osservazioni approccio possiamo usare tali situazioni cluster analysis clustering lobiettivo clustering vericare date features input osservazioni disponibili ricadono allinterno gruppi relativamente distinti loro
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#5,5,"Clustering 
Il 
clustering
  è in effetti una delle tecniche più utilizzate per la 
exploratory data analysis
 . 
In tante discipline, dalle scienze sociali alla biologia alla computer 
science, gli studiosi cercano di avere delle prime “intuizioni” sui 
dati di cui dispongono identiﬁcando gruppi signiﬁcativi dei data 
points: 
•
i venditori cercano di identiﬁcare cluster di clienti, in base ai loro proﬁli, 
per migliorare l’attività di marketing (
 market segmentation
 ); 
•
i medici cercano di raggruppare i pazienti in base alle loro condizioni 
cliniche; 
•
gli astronomi identiﬁcano cluster di stelle in base alla loro prossimità 
spaziale; 
•
ecc. ecc.
 
6",clustering clustering effetti tecniche utilizzate exploratory data analysis tante discipline scienze sociali biologia computer science studiosi cercano avere prime intuizioni dati dispongono identicando gruppi signicativi data points venditori cercano identicare cluster clienti base proli migliorare lattivit marketing market segmentation medici cercano raggruppare pazienti base condizioni cliniche astronomi identicano cluster stelle base prossimit spaziale ecc ecc
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#6,6,"Clustering 
Esempio in due dimensioni: individuare la 
 cluster structure
  solo 
dagli input: 
 
7
feature 1feature 2",clustering esempio due dimensioni individuare cluster structure solo input feature feature
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#7,7,"Clustering 
Ogni cluster è deﬁnito dal 
 centroide
  (
cluster center
 ) e dalla forma 
(shape/spread): 
 
8
feature 1feature 2
1 2
3",clustering ogni cluster denito centroide cluster center forma shapespread feature feature
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#8,8,"Ciascuna osservazione 
 x
i
 è assegnata al cluster 
 k
 se: 
•
 Il punteggio (
 score
 ) di 
x
i
 sotto il cluster 
 k
 è migliore rispetto agli 
altri cluster. 
Per semplicità, spesso si deﬁnisce lo 
 score
  come la distanza dal 
centroide
  del cluster (si ignora lo shape). 
 
9
Clustering ",ciascuna osservazione assegnata cluster punteggio score sotto cluster migliore rispetto altri cluster semplicit spesso denisce score distanza centroide cluster ignora shape clustering
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#9,9,"k-means Clustering 
L’algoritmo 
 k-means
  assume come 
 score
  proprio la distanza di una 
osservazione dal 
 centroide
 . Più bassa è la distanza, “migliore” è lo 
score
 . 
Deﬁnizione dei simboli utilizzati nell’esempio che segue: 
 
10nj: numero di  elementi nel cluster jµj: centroide  del cluster j
zi: label del cluster a cui appartiene xiN: numero delle osservazioni
j: indice dei cluster 
k: numero dei clusterxi: osservazione i-esima (              ) xi2Rd",means clustering lalgoritmo means assume score proprio distanza osservazione centroide bassa distanza migliore score denizione simboli utilizzati nellesempio segue numero elementi cluster jj centroide cluster label cluster appartiene numero osservazioni indice cluster numero clusterxi osservazione esima
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 08)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione clustering
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Preprocessing: Scaling 
Scaling in Scikit-learn 
Scaling e classiﬁcazione 
Scikit-learn e K-Means  
Esempi di limiti dell'algoritmo K-Means ",sommario preprocessing scaling scaling scikit learn scaling classicazione scikit learn means esempi limiti dellalgoritmo means
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#10,10,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set? 
Le istanze nel test set sono state scalate in modo improprio rispetto ai valori 
originali, e si trovano in posizioni relative diverse da quelle originali.
11
",scikit learn scaling cosa succede applicassimo due distinti rescaling training test set istanze test set state scalate modo improprio rispetto valori originali trovano posizioni relative diverse originali
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#11,11,"Scikit-learn: Scaling
Nota: In scikit-learn, gli scaler hanno spesso il metodo ﬁt_transform() che 
combina le 2 operazioni: 
from 
sklearn.preprocessing 
 import 
StandardScaler
scaler 
= 
StandardScaler
 ()
X_scaled 
 = 
scaler
.
fit
(
X
)
.
transform
 (
X
)
# stesso risultato ma più efficient
X_scaled_d 
 = 
scaler
.
fit_transform
 (
X
)
12",scikit learn scaling nota scikit learn scaler spesso metodo ttransform combina operazioni import standard scaler scaler standard scaler xscaled scaler fit transform stesso risultato efficient xscaledd scaler fittransform
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#12,12,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler sul dataset breast cancer e impiega 
l'algoritmo di classiﬁcazione SVC(C=100). Confronta la performance senza 
scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
...
13",scikit learn scaling classicazione esercizio impiega min max scaler dataset breast cancer impiega lalgoritmo classicazione vcc confronta performance senza scaling sklearnsvm import xtrain xtest ytrain ytest cancer data cancer target randomstate
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#13,13,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler e StandardScaler sul dataset breast cancer 
e impiega l'algoritmo SVC(C=100). Confronta la performance senza scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
svm 
= 
SVC
(
C
=
100
)
svm
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test
, 
y_test
)))
>> Test set accuracy: 0.63
# con scaling
scaler 
= 
MinMaxScaler
 ()
scaler
.
fit
(
X_train
)
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
svm
.
fit
(
X_train_scaled
 , 
y_train
)
print
(
""Scaled test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test_scaled
 , 
y_test
)))
>> Scaled test set accuracy: 0.97 (con StandardScaler si ottiene 0.96)
14",scikit learn scaling classicazione esercizio impiega min max scaler standard scaler dataset breast cancer impiega lalgoritmo vcc confronta performance senza scaling sklearnsvm import xtrain xtest ytrain ytest cancer data cancer target randomstate svm svm fit xtrain ytrain print test set accuracy format svm score xtest ytest test set accuracy scaling scaler min max scaler scaler fit xtrain xtrainscaled scaler transform xtrain xtestscaled scaler transform xtest svm fit xtrainscaled ytrain print scaled test set accuracy format svm score xtestscaled ytest scaled test set accuracy con standard scaler ottiene
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#14,14,"Scikit-learn: K-means
Scikit-learn implementa l'algoritmo con la classe 
 KMeans
 . Il parametro 
n_clusters
  è richiesto per speciﬁcare il numero di cluster.  
Supponiamo di avere il seguente  
dataset: 
L'output dell'algoritmo può essere  
rappresentato col diagramma  
Voronoi Tesselation. 
from 
sklearn.cluster 
 import 
KMeans
k 
= 
5
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
y_pred 
= 
kmeans
.
fit_predict
 (
X
)
print (
y_pred)
>> array([4, 0, 1, ..., 2, 1, 0],  
dtype=int32)
print (y_pred 
 is 
kmeans
.
labels_)
>> True
15
",scikit learn means scikit learn implementa lalgoritmo classe means parametro nclusters richiesto specicare numero cluster supponiamo avere seguente dataset loutput dellalgoritmo pu essere rappresentato diagramma voronoi tesselation sklearncluster import means kmeans means nclusters ypred kmeans fitpredict print ypred array dtypeint print ypred kmeans labels true
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#15,15,"Scikit-learn: Limiti K-means
Possiamo ottenere le coordinate dei 5 centroidi: 
kmeans
.
cluster_centers_
>> array([[-2.80389616, 1.80117999],
[ 0.20876306, 2.25551336],
[-2.79290307, 2.79641063],
[-1.46679593, 2.28585348],
[-2.80037642, 1.30082566]])
E predire la classe di nuove istanze: 
X_new 
= 
np
.
array
([[
0
, 
2
], [
3
, 
2
], [
-
3
, 
3
], [
-
3
, 
2.5
]])
kmeans
.
predict
(
X_new
)
>> array([1, 1, 2, 2], dtype=int32)
Nota
 : K-Means non si comporta molto bene con cluster che hanno 
diametri molto distinti tra loro, poiché l'algoritmo valuta solo la distanza 
col centroide.
16",scikit learn limiti means possiamo ottenere coordinate centroidi kmeans array predire classe nuove istanze xnew array kmeans predict xnew array dtypeint nota means comporta molto bene cluster diametri molto distinti loro poich lalgoritmo valuta solo distanza centroide
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#16,16,"Scikit-learn: K-means
Invece dell'
 hard clustering
  visto ﬁnora, dove l'output è un singolo cluster, 
possiamo ottenere uno score (anche chiamato 
 similarity score
  o 
afﬁnity
 ) per 
ogni cluster col 
 soft clustering
  mediante la funzione 
 transform
 (): 
kmeans
.
transform
 (
X_new
)
>> array([[2.81093633, 0.32995317, 2.9042344 , 1.49439034, 2.88633901],
[5.80730058, 2.80290755, 5.84739223, 4.4759332 , 5.84236351],
[1.21475352, 3.29399768, 0.29040966, 1.69136631, 1.71086031],
[0.72581411, 3.21806371, 0.36159148, 1.54808703, 1.21567622]])
È possibile impostare i centroidi iniziali in modo manuale col parametro 
init
: 
good_init 
 = 
np
.
array
([[
-
3
, 
3
], [
-
3
, 
2
], [
-
3
, 
1
], [
-
1
, 
2
], [
0
, 
2
]])
kmeans 
= 
KMeans
(
n_clusters
 =
5
, 
init
=
good_init
 , 
n_init
=
1
)
L'iperparametro 
 n_init
  speciﬁca quante volte l'algoritmo deve essere 
eseguito prima di selezionare la soluzione migliore ottenuta.
17",scikit learn means invece dell hard clustering visto nora loutput singolo cluster possiamo ottenere score anche chiamato similarity score afnity ogni cluster soft clustering mediante funzione transform kmeans transform xnew possibile impostare centroidi iniziali modo manuale parametro init goodinit array kmeans means nclusters init goodinit ninit liperparametro ninit specica volte lalgoritmo deve essere eseguito prima selezionare soluzione migliore ottenuta
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#17,17,"Scikit-learn: K-means
Per valutare la bontà della soluzione si misura il costo basato sulla cluster 
heterogeneity, chiamato anche 
 inertia
  del modello, cioè la distanza 
quadratica media con i centroidi. 
kmeans
.
inertia_
>> 211.59853725816856
kmeans
.
score
(
X
)
>> -211.59853725816856
Nota
 : di default KMeans() usa l'inizializzazione dei centroidi proposta in K-
Means++. Se vuoi impiegare quella dell'algoritmo originale, imposta il 
parametro 
 init='random'
 .
18",scikit learn means valutare bont soluzione misura costo basato cluster heterogeneity chiamato inertia modello cio distanza quadratica media centroidi kmeans inertia kmeans score nota default means usa centroidi proposta means vuoi impiegare dellalgoritmo originale imposta parametro initrandom
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: K-means
Esempio con un dataset toy: 
from 
sklearn.datasets 
 import 
make_blobs
from 
sklearn.cluster 
 import 
KMeans
# generate synthetic two-dimensional data
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
19
n_clusters=2 n_clusters=4 n_clusters=3",scikit learn means esempio dataset toy import makeblobs sklearncluster import means generate synthetic two dimensional data makeblobs randomstate kmeans means nclusters kmeans fit nclusters nclusters nclusters
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
20Secondo te è un output ideale?
",scikit learn limiti means xvaried yvaried makeblobs nsamples clusterstd randomstate ypred means nclusters randomstate fitpredict xvaried mglearn xvaried xvaried ypred plt legend cluster cluster cluster loc best plt xlabel feature plt ylabel feature secondo output ideale
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#2,2,"Clustering
Ci focalizziamo sugli algoritmi di 
 clustering
 . Esistono anche 
 trasformazioni 
unsupervised
 , utili per creare nuove rappresentazioni utili per analizzare 
dati o per darli in input a successivi algoritmi. Un approccio comune è la 
riduzione di dimensionalità
 , dove le N dimensioni corrispondenti alle 
features vengono ""compresse"" in poche dimensione (es. 2 o 3). 
La challenge del clustering è capire se l'algoritmo applicato su dati non 
etichettati (cioè senza output) riesce comunque a trovare qualcosa di utile. 
Esempio: Classiﬁcation (sx) e Clustering senza label (dx) 
3
",clustering focalizziamo algoritmi clustering esistono trasformazioni unsupervised utili creare nuove utili analizzare dati darli input successivi algoritmi approccio comune riduzione dimensionalit dimensioni corrispondenti features vengono compresse poche dimensione challenge clustering capire lalgoritmo applicato dati etichettati cio senza output riesce comunque trovare qualcosa utile esempio classication clustering senza label
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21K-means assume che ogni cluster abbia lo 
stesso diametro, e deﬁnisce la boundary tra i 
cluster esattamente a metà tra i due centroidi. 
Alcuni punti del graﬁco potevano essere 
classiﬁcati in modo diverso.
",scikit learn limiti means xvaried yvaried makeblobs nsamples clusterstd randomstate ypred means nclusters randomstate fitpredict xvaried mglearn xvaried xvaried ypred plt legend cluster cluster cluster loc best plt xlabel feature plt ylabel feature means assume ogni cluster stesso diametro denisce boundary cluster esattamente met due centroidi alcuni punti graco potevano essere classicati modo diverso
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
22
Secondo te è un output ideale?",scikit learn limiti means makeblobs randomstate nsamples rng random random state trasforma dati mezzo distribuzione gaussiana transformation rng normal size dot transformation kmeans means nclusters kmeans fit ypred kmeans predict plt scatter ypred cmap mglearn plt scatter kmeans kmeans marker linewidth cmap mglearn plt xlabel feature plt ylabel feature secondo output ideale
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
23
I dati sono distribuiti (""allungati"") sulla diagonale, 
non seguono una distribuzione sferica. 
L'algoritmo valuta solo la distanza dal centroide.",scikit learn limiti means makeblobs randomstate nsamples rng random random state trasforma dati mezzo distribuzione gaussiana transformation rng normal size dot transformation kmeans means nclusters kmeans fit ypred kmeans predict plt scatter ypred cmap mglearn plt scatter kmeans kmeans marker linewidth cmap mglearn plt xlabel feature plt ylabel feature dati distribuiti allungati diagonale seguono distribuzione sferica lalgoritmo valuta solo distanza centroide
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#23,23,"Scikit-learn: Limiti K-means
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
kmeans 
= 
KMeans
(
n_clusters
 =
2
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
))
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
mglearn
.
cm2
(
0
), 
mglearn
.
cm2
(
1
)], 
s
=
100
, 
linewidth
 =
2
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
24
Shape complesse non sono 
valutate correttamente.",scikit learn limiti means import makemoons makemoons nsamples noise randomstate kmeans means nclusters kmeans fit ypred kmeans predict plt scatter ypred cmap mglearn plt scatter kmeans kmeans marker mglearn mglearn linewidth plt xlabel feature plt ylabel feature shape complesse valutate correttamente
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#24,24,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
25",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#3,3,"Preprocessing: Scaling
Alcuni algoritmi di ML sono sensibili allo 
 scaling
  dei dati. Per tale motivo 
spesso si opera un rescaling e shifting. 
Vediamo qualche esempio dalla libreria mglearn: 
mglearn
.
plots
.
plot_scaling
 ()
4
",preprocessing scaling alcuni algoritmi sensibili scaling dati tale motivo spesso opera rescaling shifting vediamo qualche esempio libreria mglearn mglearn plots plotscaling
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#4,4,"Preprocessing: Scaling
Il diagramma mostra 4 scaler della libreria scikit-learn.  
StandardScaler
 : garantisce media 0 e varianza 1  
Non garantisce alcun intervallo max e min 
RobustScaler
 : approccio statistico simile,  
usa mediana e quartili, è meno sensibile  
agli 
outliers
 . 
MinMaxScaler
 : sposta i dati nell'intervallo [0,1] 
Normalizer
 : effettua un rescaling in modo che  
la distanza euclidea sia pari a 1, cioè proietta  
i punti su una circonferenza (o sfera) di raggio 1.  
Ogni punto è scalato per l'inverso della lunghezza.  
Utile quando si ha interesse soprattutto riguardo la direzione, piuttosto 
che della lunghezza del feature vector.
5
",preprocessing scaling diagramma mostra scaler libreria scikit learn standard scaler garantisce media varianza garantisce alcun intervallo max min robust scaler approccio statistico simile usa mediana quartili meno sensibile outliers min max scaler sposta dati nellintervallo normalizer effettua rescaling modo distanza euclidea pari cio proietta punti circonferenza sfera raggio ogni punto scalato linverso lunghezza utile quando interesse soprattutto riguardo direzione piuttosto lunghezza feature vector
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Scaling
Usiamo il breast cancer dataset per testare i vari scaling su un contesto 
supervised con algoritmo SVM/SVC: 
from 
sklearn.datasets 
 import 
load_breast_cancer
from 
sklearn.model_selection 
 import 
train_test_split
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
,
random_state
 =
1
)
print
(
X_train
.
shape
)
print
(
X_test
.
shape
)
>> (426, 30)
>> (143, 30)
from 
sklearn.preprocessing 
 import 
MinMaxScaler
scaler 
= 
MinMaxScaler
 ()
# consideriamo solo X_train, 
 non il y_train
scaler
.
fit
(
X_train
)
>> MinMaxScaler(copy=True, feature_range=(0, 1))
# trasformiamo i dati
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
6",scikit learn scaling usiamo breast cancer dataset testare vari scaling contesto supervised algoritmo vms import import cancer xtrain xtest ytrain ytest cancer data cancer target randomstate print xtrain shape print xtest shape import min max scaler scaler min max scaler consideriamo solo xtrain ytrain scaler fit xtrain min max trasformiamo dati xtrainscaled scaler transform xtrain
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#6,6,"Scikit-learn: Scaling
# stampa i valori delle features prima e dopo il rescaling
print
(
""transformed shape: {}""
 .
format
(
X_train_scaled
 .
shape
))
print
(
""per-feature minimum before scaling:\n {}""
 .
format
(
X_train
.
min
(
axis
=
0
)))
print
(
""per-feature maximum before scaling:\n {}""
 .
format
(
X_train
.
max
(
axis
=
0
)))
print
(
""per-feature minimum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
max
(
axis
=
0
)))
>> transformed shape: (426, 30)
per-feature minimum before scaling:
[ 6.98 9.71 43.79 143.50 0.05 0.02 0. 0. 0.11
0.05 0.12 0.36 0.76 6.80 0. 0. 0. 0.
0.01 0. 7.93 12.02 50.41 185.20 0.07 0.03 0.
0. 0.16 0.06]
per-feature maximum before scaling:
[ 28.11 39.28 188.5 2501.0 0.16 0.29 0.43 0.2
0.300 0.100 2.87 4.88 21.98 542.20 0.03 0.14
0.400 0.050 0.06 0.03 36.04 49.54 251.20 4254.00
0.220 0.940 1.17 0.29 0.58 0.15]
per-feature minimum after scaling:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
per-feature maximum after scaling:
[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
7",scikit learn scaling stampa valori features prima dopo rescaling print transformed shape format xtrainscaled shape print per feature minimum scalingn format xtrain min axis print per feature maximum scalingn format xtrain max axis print per feature minimum scalingn format xtrainscaled min axis print per feature maximum scalingn format xtrainscaled max axis transformed shape feature minimum scaling feature maximum scaling feature minimum scaling feature maximum scaling
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#7,7,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?
8",scikit learn scaling applichiamo scaling xtest transform test data xtestscaled scaler transform xtest print test data properties scaling print per feature minimum scaling format xtestscaled min axis print per feature maximum scaling format xtestscaled max axis feature minimum scaling feature maximum scaling range corretto
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#8,8,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?  
Sì, perché il max e min sono stati ricavati dal training set, e possono 
essere distinti da quelli nel X_test.
9",scikit learn scaling applichiamo scaling xtest transform test data xtestscaled scaler transform xtest print test data properties scaling print per feature minimum scaling format xtestscaled min axis print per feature maximum scaling format xtestscaled max axis feature minimum scaling feature maximum scaling range corretto max min stati ricavati training set possono essere distinti xtest
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#9,9,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set?
10
",scikit learn scaling cosa succede applicassimo due distinti rescaling training test set
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 09)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione clustering
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Agglomerative clustering 
Hierarchical clustering 
Dendograms 
DBSCAN 
Accelerated K-Means e Mini-batch K-Means 
Silhoutte score",sommario agglomerative clustering hierarchical clustering dendograms accelerated means mini batch means silhoutte score
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#10,10,"DBSCAN
DBSCAN (density-based spatial clustering of applications with noise) è un 
algoritmo che non richiede la scelta del numero di cluster a priori, inoltre può 
gestire conﬁgurazioni complesse dei dati (es. non sferiche). a differenza degli 
approcci visti ﬁnora. 
È generalmente più lento ma può scalare su dataset molto grandi. 
L'algoritmo identiﬁca i punti nel feature space che si trovano in regioni 
""popolate"" o 
 dense 
 e costruisce i cluster in base ad esse. I punti in queste 
regioni si chiamano 
 core samples
 .  
Ci sono 2 iperparametri: 
 min_samples
  e 
eps
. Se esistono almeno 
 min_samples  
punti con distanza inferiore a 
 eps
 rispetto a un punto X, allora  X è un 
 core 
sample
 . I core sample che sono vicini tra loro (distanza < eps) sono inseriti 
nello stesso cluster. Un cluster deve avere almeno min_samples punti. 
I punti che non sono assegnati a nessun cluster diventano i punti di partenza 
per una nuova iterazione. Quelli che non sono assegnati ad alcun cluster 
sono considerati rumore.
11",density based spatial clustering applications noise algoritmo richiede scelta numero cluster priori inoltre pu gestire congurazioni complesse dati sferiche differenza approcci visti nora generalmente lento pu scalare dataset molto grandi lalgoritmo identica punti feature space trovano regioni popolate dense costruisce cluster base esse punti regioni chiamano core samples iperparametri minsamples eps esistono almeno minsamples punti distanza inferiore eps rispetto punto allora core sample core sample vicini distanza eps inseriti stesso cluster cluster deve avere almeno minsamples punti punti assegnati nessun cluster diventano punti partenza nuova iterazione assegnati alcun cluster considerati rumore
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#11,11,"DBSCAN
Nota
 : anche in DBSCAN la funzione predict() non è implementata. 
Esempio: 
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
Perché l'output è sempre -1?
12",nota funzione predict implementata esempio sklearncluster import makeblobs randomstate nsamples dbscan clusters dbscan fitpredict print cluster format clusters cluster memberships loutput sempre
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#12,12,"DBSCAN
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
L'algoritmo usa il valore di default per eps che non è adatto per il piccolo dataset 
analizzato. 
mglearn
.
plots
.
plot_dbscan
 ()
min_samples: 2 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 2 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 2 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 2 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 3 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 3 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 3 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 3 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 5 eps: 1.000000 cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
min_samples: 5 eps: 1.500000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 2.000000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
13",sklearncluster import makeblobs randomstate nsamples dbscan clusters dbscan fitpredict print cluster format clusters cluster memberships lalgoritmo usa valore default eps adatto piccolo dataset analizzato mglearn plots plotdbscan minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster minsamples eps cluster
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#13,13,"DBSCAN
Diverse conﬁgurazioni variando gli iperparametri (i punti in bianco sono 
considerati rumore). Cosa noti? 
14
",diverse congurazioni variando iperparametri punti bianco considerati rumore cosa noti
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#14,14,"DBSCAN
Incrementando 
 eps
 ci sono più punti che appartengono a clusters, e si 
riducono anche il numero di clusters. 
Nota: è più facile impostare il valore di eps operando prima la normalizzazione delle features con 
StandardScaler
  o 
MinMaxScaler.  
Incrementando 
 min_samples
 , meno punti saranno core points, e più punti 
saranno etichettati come rumore. 
15
",incrementando eps punti appartengono clusters riducono numero clusters nota facile impostare valore eps operando prima normalizzazione features standard scaler min max scaler incrementando minsamples meno punti core points punti etichettati rumore
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#15,15,"DBSCAN - Esercizio
Esercizio
 : impiega l'algoritmo DBSCAN sul moon dataset, con o senza la 
normalizzazione. Valuta i cluster ottenuti.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
...
16",esercizio esercizio impiega lalgoritmo moon dataset senza valuta cluster ottenuti makemoons nsamples noise randomstate
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#16,16,"DBSCAN - Esercizio
Esercizio: impiega l'algoritmo DBSCAN sul moon dataset.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
# media 0 e varianza unitaria
scaler 
= 
StandardScaler
 ()
scaler
.
fit
(
X
)
X_scaled 
 = 
scaler
.
transform
 (
X
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X_scaled
 )
plt
.
scatter
(
X_scaled
 [:, 
0
], 
X_scaled
 [:, 
1
], 
c
=
clusters
 , 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
17",esercizio esercizio impiega lalgoritmo moon dataset makemoons nsamples noise randomstate media varianza unitaria scaler standard scaler scaler fit xscaled scaler transform dbscan clusters dbscan fitpredict xscaled plt scatter xscaled xscaled clusters cmap mglearn plt xlabel feature plt ylabel feature
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#17,17,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
Esercizio
 : Cosa succede se decrementiamo il valore di default di eps (0.5) a 
0.2, o lo incrementiamo a 0.7?
18
",esercizio volta clustering ottimale identicato esercizio cosa succede decrementiamo valore default eps incrementiamo
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#18,18,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
eps = 0.2 -> 8 clusters 
eps = 0.7 -> 1 cluster
19
",esercizio volta clustering ottimale identicato eps clusters eps cluster
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#19,19,"Accelerated K-Means e Mini-batch K-Means
L'algoritmo 
 accelerated
  K-Means evita di calcolare distanze non 
necessarie.  
Impiega la 
 triangle inequality 
  AC< AB+BC, dove A,B e C sono 3 punti, e 
tiene traccia del valore del upper e lower bounds delle distanze tra 
centroidi e istanze. È l'approccio normalmente impiegato 
nell'implementazione KMeans di scikit-learn. 
L'approccio 
 Mini-batch
  seleziona un piccolo insieme di istanze su cui 
valutare le distanze, creando una 
 inerzia
  nella modiﬁca dei clusters. 
Incrementa la velocità, ma se il numero di cluster è elevato si ottengono 
conﬁgurazioni meno ottimali. 
from 
sklearn.cluster 
 import 
MiniBatchKMeans
minibatch_kmeans 
 = 
MiniBatchKMeans
 (
n_clusters
 =
5
)
minibatch_kmeans
 .
fit
(
X
)
20",accelerated means mini batch means lalgoritmo accelerated means evita calcolare distanze necessarie impiega triangle inequality punti tiene traccia valore upper lower bounds distanze centroidi istanze lapproccio normalmente impiegato means scikit learn lapproccio mini batch seleziona piccolo insieme istanze valutare distanze creando inerzia modica clusters incrementa velocit numero cluster elevato ottengono congurazioni meno ottimali sklearncluster import mini batch kmeans mini batch kmeans nclusters fit
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#2,2,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
Quali criteri di unione (merge) puoi immaginare?
3",agglomerative clustering lalgoritmo segue seguenti passi deniamo serie cluster ognuno serie istanze interno ogni iterazione uniamo due cluster valutati maggiormente simili raggiungimento certo criterio stop fermiamo tipicamente criterio basato numero cluster desiderato quali criteri unione merge puoi immaginare
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#20,20,"Accelerated K-Means e Mini-batch K-Means
Mini-batch vs K-Means tradizionale impiegando diversi numeri di clusters 
k. Con un numero elevato di clusters l'inerzia si riduce notevolmente, e si 
limita il tempo di training. 
Ricordiamo che l'
 inertia
  del modello e' la distanza quadratica media con i 
centroidi, cioè la
  cluster heterogeneity 
 (vedi lezione sul clustering).
21
",accelerated means mini batch means mini batch means tradizionale impiegando diversi numeri clusters numero elevato clusters linerzia riduce notevolmente limita tempo training ricordiamo inertia modello distanza quadratica media centroidi cio cluster heterogeneity vedi lezione clustering
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#21,21,"Il numero ottimale di clusters
Alcuni algoritmi richiedono di speciﬁcare il numero di clusters, che 
possono produrre risultati molto diversi anche con valori simili: 
Potremmo scegliere il modello con minore inertia, ma nell'esempio con 
k=3 otteniamo 653.2, mentre con k=8 si ha inertia=119.1. Più cluster 
abbiamo, più si riduce la distanza col rispettivo centroide e la rispettiva 
inertia del modello. 
22
",numero ottimale clusters alcuni algoritmi richiedono specicare numero clusters possono produrre risultati molto diversi valori simili potremmo scegliere modello minore inertia nellesempio otteniamo mentre inertia cluster abbiamo riduce distanza rispettivo centroide rispettiva inertia modello
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#22,22,"Richiami: elbow method
Se graﬁchiamo il valore dell'inertia in funzione del numero di clusters 
 k
 si 
vede chiaramente con dopo un ""drop"" elevato, il decremento si riduce 
notevolmente. 
23
",richiami elbow method grachiamo valore dellinertia funzione numero clusters vede chiaramente dopo drop elevato decremento riduce notevolmente
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#23,23,"Silhoutte score
Un metodo più formale è il calcolo del valore della silhoutte su tutte le 
istanze. Si ricava con
  (b-a)/max(a,b)
  dove 
 a
 è la distanza media rispetto 
alle altre istanze nel cluster, 
 b
 è la 
 mean nearest-cluster distance
 , cioè la 
distanza media delle istanze rispetto al cluster più vicino. 
Il coefﬁciente varia in [-1,+1], dove un valore vicino:  
a +1 indica una istanza vicina al proprio cluster e lontana dagli altri,  
allo 0, istanza vicina al boundary del cluster 
a -1 l'istanza potrebbe essere stata assegnata al cluster sbagliato. 
from 
sklearn.metrics 
 import 
silhouette_score
silhouette_score
 (
X
, 
kmeans
.
labels_
)
0.655517642572828
24",silhoutte score metodo formale calcolo valore silhoutte tutte istanze ricava amaxab distanza media rispetto altre istanze cluster mean nearest cluster distance cio distanza media istanze rispetto cluster vicino coefciente varia valore vicino indica istanza vicina proprio cluster lontana altri istanza vicina boundary cluster listanza potrebbe essere stata assegnata cluster sbagliato sklearnmetrics import kmeans labels
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#24,24,"Silhoutte score
Un valore pari a 4 di cluster massimizza il valore della silhoutte
25
",silhoutte score valore pari cluster massimizza valore silhoutte
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#25,25,"Silhoutte diagram
Graﬁci del valore di silhoutte per ogni istanza, ordinati per il cluster di 
appartenenza. Per k=4 abbiamo che gran parte delle istanze sorpassano il 
valore di silhoutte associato a quella conﬁgurazione (linea rossa)
26
",silhoutte diagram graci valore silhoutte ogni istanza ordinati cluster appartenenza gran parte istanze sorpassano valore silhoutte associato congurazione linea rossa
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#26,26,"Silhoutte: Esercizio
Esercizio
 : riprendi il dataset blobs e l'approccio agglomerative e ricava il 
numero ottimale di cluster col approccio 
 Agglomerative
 . 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
...
27",silhoutte esercizio esercizio riprendi dataset blobs lapproccio agglomerative ricava numero ottimale cluster approccio agglomerative sklearncluster import agglomerative clustering makeblobs randomstate
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#27,27,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
28",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#3,3,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
In scikit-learn la fusione di cluster può seguire uno dei seguenti criteri: 
ward
  (default): si scelgono i cluster i cui merge riducono al massimo 
l'incremento di varianza tra tutti i cluster. Di solito porta ad avere 
cluster di dimensione confrontabile. 
average
 : i due cluster che hanno distanza media tra tutti punti minore 
complete
 : i due cluster che hanno distanza massima tra due punti 
minore.
4",agglomerative clustering lalgoritmo segue seguenti passi deniamo serie cluster ognuno serie istanze interno ogni iterazione uniamo due cluster valutati maggiormente simili raggiungimento certo criterio stop fermiamo tipicamente criterio basato numero cluster desiderato scikit learn fusione cluster pu seguire seguenti criteri ward default scelgono cluster merge riducono massimo lincremento varianza cluster solito porta avere cluster dimensione confrontabile average due cluster distanza media punti minore complete due cluster distanza massima due punti minore
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#4,4,"Agglomerative Clustering
Esempio libreria 
 mglearn
 : 
mglearn
.
plots
.
plot_agglomerative_algorithm
 ()
5
",agglomerative clustering esempio libreria mglearn mglearn plots
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Agglomerative Clustering
Esempio scikit-learn: 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
agg 
= 
AgglomerativeClustering
 (
n_clusters
 =
3
) # parametro obbligatorio
assignment 
 = 
agg
.
fit_predict
 (
X
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
assignment
 )
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
Nota
 : l'agglomerative clustering non può predire un cluster per nuovi dati, 
perciò non è possibile usare la funzione predict().
6
",scikit learn agglomerative clustering esempio scikit learn sklearncluster import agglomerative clustering makeblobs randomstate agg agglomerative clustering nclusters parametro obbligatorio assignment agg fitpredict mglearn assignment plt xlabel feature plt ylabel feature nota lagglomerative clustering pu predire cluster nuovi dati perci possibile usare funzione predict
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#6,6,"Hierarchical clustering
Ad ogni passo dell'algoritmo agglomerative si creano diverse 
conﬁgurazioni che possono essere rilevanti per analizzare i dati, soprattutto 
se si hanno poche features. 
mglearn
.
plots
.
plot_agglomerative
 ()
7
",hierarchical clustering ogni passo dellalgoritmo agglomerative creano diverse congurazioni possono essere rilevanti analizzare dati soprattutto poche features mglearn plots
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#7,7,"Dendrograms
Per dataset con molte features è comunque possibile rappresentare i dati 
sottoforma di dendogrammi. Scikit-learn non implementa tale funzionalità, 
usiamo la libreria 
 scipy
 : 
from 
scipy.cluster.hierarchy 
 import 
dendrogram
 , 
ward
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
# ward clustering sui dati
# la funzione restituisce un array che contiene le distanze ricavate
# durante il clustering agglomerative
linkage_array 
 = 
ward
(
X
)
# Visualizziamo il dendogramma con le distanze tra i cluster
dendrogram
 (
linkage_array
 )
# Nel plot aggiungiamo il numero di clsuter
ax 
= 
plt
.
gca
()
bounds 
= 
ax
.
get_xbound
 ()
ax
.
plot
(
bounds
, [
7.25
, 
7.25
], 
'--'
, 
c
=
'k'
)
ax
.
plot
(
bounds
, [
4
, 
4
], 
'--'
, 
c
=
'k'
)
ax
.
text
(
bounds
[
1
], 
7.25
, 
' two clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
ax
.
text
(
bounds
[
1
], 
4
, 
' three clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
plt
.
xlabel
(
""Sample index""
 )
plt
.
ylabel
(
""Cluster distance""
 )
8",dendrograms dataset molte features comunque possibile rappresentare dati sottoforma dendogrammi scikit learn implementa tale funzionalit usiamo libreria scipy import dendrogram ward makeblobs randomstate nsamples ward clustering dati funzione restituisce array contiene distanze ricavate durante clustering agglomerative linkagearray ward visualizziamo dendogramma distanze cluster dendrogram linkagearray plot aggiungiamo numero clsuter plt gca bounds getxbound plot bounds plot bounds text bounds two clusters center fontdict size text bounds three clusters center fontdict size plt xlabel sample index plt ylabel cluster distance
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#8,8,"Dendrograms
Dal seguente diagramma come immagini che si sia comportato l'algoritmo 
di clustering?
9
",dendrograms seguente diagramma immagini comportato lalgoritmo clustering
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#9,9,"Dendrograms
Sulle ascisse abbiamo le istanze numerate (da 0 a 11). Salendo si notano i 
nuovi cluster che uniscono le istanze, oppure cluster già presenti. 
Es. al principio si uniscono 1 e 4 in un cluster, poi 6 e 9 in un altro, etc. 
In cima abbiamo 2 cluster, uno con 11,0,5,10,7,6 e 9; l'altro coi 
restanti punti. 
La lunghezza in verticale delle linee rappresentano le distanze tra i due 
cluster o punti che si fondono. 
10
",dendrograms ascisse istanze numerate salendo notano nuovi cluster uniscono istanze oppure cluster gi presenti principio uniscono cluster poi altro etc cima cluster laltro restanti punti lunghezza verticale linee rappresentano distanze due cluster punti fondono
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 10)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione clustering
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Image segmentation 
Clustering per il preprocessing 
Grid search 
Active learning 
Gaussian Mixtures",sommario image segmentation clustering preprocessing grid search active learning gaussian mixtures
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#10,10,"Clustering per il semi-supervised learning
Soluzione: 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
X_digits_dist 
 = 
kmeans
.
fit_transform
 (
X_train
)
representative_digit_idx 
 = 
np
.
argmin
(
X_digits_dist
 , 
axis
=
0
)
X_representative_digits 
 = 
X_train
[
representative_digit_idx
 ]
# facciamo un labeling manuale delle 50 cifre
y_representative_digits 
 = 
np
.
array
([
4
, 
8
, 
0
, 
6
, 
8
, 
3
, 
...
, 
7
, 
6
, 
2
, 
3
, 
1
, 
1
])
l
og_reg 
= 
LogisticRegression
 ()
log_reg
.
fit
(
X_representative_digits
 , 
y_representative_digits
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9244444444444444
11
",clustering semi supervised learning soluzione kmeans means nclusters xdigitsdist kmeans fittransform xtrain argmin xdigitsdist axis xtrain labeling manuale cifre array ogreg logistic regression logreg fit logreg score xtest ytest
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#11,11,"Clustering per il preprocessing
Etichettiamo le restanti istanze nei cluster con le label che abbiamo creato 
in modo manuale (
 label propagation
 ), e proviamo nuovamente ad 
addestrare la logistic regression: 
y_train_propagated 
 = 
np
.
empty
(
len
(
X_train
), 
dtype
=
np
.
int32
)
for 
i 
in 
range
(
k
):
  
y_train_propagated
 [
kmeans
.
labels_
==
i
] 
= 
y_representative_digits
 [
i
]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
, 
y_train_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9288888888888889
Un leggero incremento. Non conviene propagare le label alle istanze 
lontano dal centroide e vicine al boundary.
12",clustering preprocessing etichettiamo restanti istanze cluster label creato modo manuale label propagation proviamo nuovamente addestrare logistic regression empty len xtrain dtype int range kmeans labels logreg logistic regression logreg fit xtrain logreg score xtest ytest leggero incremento conviene propagare label istanze lontano centroide vicine boundary
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#12,12,"Clustering per il preprocessing
Proviamo a fare propagation solo al 20% delle istanze più vicine al centroide 
percentile_closest 
 = 
20
X_cluster_dist 
 = 
X_digits_dist
 [
np
.
arange
(
len
(
X_train
)), 
kmeans
.
labels_
]
for 
i 
in 
range
(
k
):
in_cluster 
 = 
(
kmeans
.
labels_ 
 == 
i
)
cluster_dist 
 = 
X_cluster_dist
 [
in_cluster
 ]
cutoff_distance 
 = 
np
.
percentile
 (
cluster_dist
 , 
percentile_closest
 )
above_cutoff 
 = 
(
X_cluster_dist 
 > 
cutoff_distance
 )
X_cluster_dist
 [
in_cluster 
 & 
above_cutoff
 ] 
= -
1
partially_propagated 
 = 
(
X_cluster_dist 
 != -
1
)
X_train_partially_propagated 
 = 
X_train
[
partially_propagated
 ]
y_train_partially_propagated 
 = 
y_train_propagated
 [
partially_propagated
 ]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train_partially_propagated
 , 
y_train_partially_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9422222222222222
94.2% è molto vicino al risultato ottenuto con l'addestramento sull'interno 
dataset etichettato (96.7%). In effetti le istanze etichettate automatichemente 
con 
label propagation
  sono corrette al 99%.
13",clustering preprocessing proviamo fare propagation solo istanze vicine centroide xclusterdist xdigitsdist arange len xtrain kmeans labels range incluster kmeans labels clusterdist xclusterdist incluster cutoffdistance percentile clusterdist abovecutoff xclusterdist cutoffdistance xclusterdist incluster abovecutoff xclusterdist xtrain logreg logistic regression logreg fit logreg score xtest ytest molto vicino risultato ottenuto laddestramento sullinterno dataset etichettato effetti istanze etichettate label propagation corrette
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#13,13,"Active Learning
È un approccio iterativo dove l'algoritmo propone alcune istanze per essere 
etichettate manualmente. Ci sono diverse strategie per selezionare queste 
istanze: 
quelle su cui l'algoritmo mostra maggiore incertezza,  
quelle che potenzialmente riducono maggiormente il tasso di errore, 
quelle su cui diversi modelli (es. SVM, Random forest, etc) trovano 
maggiore disaccordo. 
Il procedimento continua ﬁnché non si hanno miglioramenti di 
performance tangibili. 
14",active learning approccio iterativo lalgoritmo propone alcune istanze essere etichettate manualmente diverse strategie selezionare istanze lalgoritmo mostra maggiore incertezza potenzialmente riducono maggiormente tasso errore diversi modelli random forest etc trovano maggiore disaccordo procedimento continua nch miglioramenti performance tangibili
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#14,14,"Gaussian Mixtures
Il 
Gaussian mixture model (GMM)
  suppone che le istanze siano generate 
da un mix di diverse distribuzioni gaussiano i cui parametri sono incogniti. 
Le istanze generate da una singola distribuzione formano un cluster a 
forma di ellissoide, con diverse forme, dimensioni, densità e orientamenti.  
Al principio non sappiamo quali distribuzioni generino una speciﬁca 
istanza. Occorre stimarle durante la fase di training. 
15
",gaussian mixtures gaussian mixture model suppone istanze generate mix diverse distribuzioni gaussiano parametri incogniti istanze generate singola distribuzione formano cluster forma ellissoide diverse forme dimensioni densit orientamenti principio sappiamo quali distribuzioni generino specica istanza occorre stimarle durante fase training
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#15,15,"Gaussian Mixtures
La classe 
 GaussianMixture
  suppone di conoscere in anticipo il numero 
 k
 di 
distribuzioni. 
Per ogni istanza, prendiamo casualmente un cluster dei 
 k
. La probabilità di 
scegliere il 
 j
-mo cluster e deﬁnita dal peso del cluster 
 ϕ
(j)
. L'indice del 
cluster selezionato per l'istanza 
 i
-ma è 
 z
(i)
. 
Se 
z
(i)
=
j
, la posizione della istanza 
 x
(i)
 è campionata in modo casuale da 
una distribuzione gaussiana con media 
 μ
(j)
 e matrice di covarianza 
 Σ
(j)
, e la 
indichiamo con:
16
",gaussian mixtures classe gaussian mixture suppone conoscere anticipo numero distribuzioni ogni istanza prendiamo casualmente cluster probabilit scegliere cluster denita peso cluster lindice cluster selezionato listanza posizione istanza campionata modo casuale distribuzione gaussiana media matrice covarianza indichiamo con
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#16,16,"Gaussian Mixtures
Rappresentiamo il modello graﬁcamente dove si notano le dipendenze tra le 
variabili casuali. Le circonferenze sono le variabili casuali, i quadrati i parametri. 
I rettangoli sono 
 plates
 , e indicano che i loro contenuti sono ripetuti diverse volte 
(es. 
m
 volte corrispondenti al numero di variabili casuali, o 
 k
 volte, cioè il 
numero di medie e covarianze, ed un solo array di parametri 
 ϕ
). 
Ogni variabile 
 z
(i) 
è ricavata da una distribuzione 
 categorical
  con pesi 
 ϕ
. 
Ogni 
variabile 
 x
(i)
 è ricavata da una distribuzione gaussiana con media e matrice di 
covarianza deﬁnita dal suo cluster 
 z
(i)
.
17
",gaussian mixtures rappresentiamo modello gracamente notano dipendenze variabili casuali circonferenze variabili casuali quadrati parametri rettangoli plates indicano contenuti ripetuti diverse volte volte corrispondenti numero variabili casuali volte cio numero medie covarianze solo array parametri ogni variabile ricavata distribuzione categorical pesi ogni variabile ricavata distribuzione gaussiana media matrice covarianza denita cluster
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#17,17,"Gaussian Mixtures
(cont...) Le frecce rappresentano dipendenze tra le variabili. Ad esempio, 
z
(i)
 dipende dal vettore dei pesi 
 ϕ
, per ogni 
 i
. 
A seconda del valore di 
 z
(i)
, l'istanza 
 x
(i)
 è campionata da una diversa 
distribuzione (freccia ondulata).  
I nodi colorati rappresentano dati noti, gli altri contengono parametri da 
stimare.
18
",gaussian mixtures cont frecce rappresentano dipendenze variabili esempio dipende vettore pesi ogni seconda valore listanza campionata diversa distribuzione freccia ondulata nodi colorati rappresentano dati noti altri contengono parametri stimare
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: Gaussian Mixtures
Una volta addestrato il modello impiegando la classe 
 GaussianMixture
 () 
possiamo ottenere facilmente i parametri 
 ϕ
, 
μ
 e 
Σ
: 
from 
sklearn.mixture 
 import 
GaussianMixture
gm 
= 
GaussianMixture
 (
n_components
 =
3
, 
n_init
=
10
)
gm
.
fit
(
X
)
# mostriamo i parametri stimati
gm
.
weights_
>>> array([0.20965228, 0.4000662 , 0.39028152])
gm
.
means_
>>> array([[ 3.39909717, 1.05933727],
[-1.40763984, 1.42710194],
[ 0.05135313, 0.07524095]])
gm
.
covariances_
>>> array([[[ 1.14807234, -0.03270354],
[-0.03270354, 0.95496237]],
[[ 0.63478101, 0.72969804],
[ 0.72969804, 1.1609872 ]],
[[ 0.68809572, 0.79608475],
[ 0.79608475, 1.21234145]]])
E ora?
19",scikit learn gaussian mixtures volta addestrato modello impiegando classe gaussian mixture possiamo ottenere facilmente parametri sklearnmixture import gaussian mixture gaussian mixture ncomponents ninit fit mostriamo parametri stimati weights means array covariances array ora
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Gaussian Mixtures
Impieghiamo l'algoritmo di Expectation Maximization (EM), simile come 
idea al K-Means. Inizializza i parametri dei cluster in modo casuale, e 
iterativamente raggiunge lo stato di convergenza. Assegna le istanze ai 
cluter (
 expectation step
 ) e poi aggiorna i cluster (
 maximization step
 ). Ricava 
i valori del centro dei cluster (medie), la loro dimensione, forma e 
orientazione (matrice di covarianze) e il relativo peso (
 Φ
). 
EM usa un soft clustering, stimando la probabilità di appartenenza. Durante 
il 
maximization step
  ogni cluster è aggiornato con tutte le istanze nel 
dataset, dove ogni istanza è pesata con la relativa probabilità di 
appartenenza (chiamata anche 
 responsability
  del cluster per l'istanza). 
Perciò ogni cluster viene aggiornato maggiormente dalle istanze che più 
verosimilmente appartengono ad esso. 
L'algoritmo richiede diversi run (es. n_init=10), poiché può facilmente 
produrre cattive conﬁgurazioni.
20",scikit learn gaussian mixtures impieghiamo lalgoritmo expectation maximization simile idea means inizializza parametri cluster modo casuale iterativamente raggiunge stato convergenza assegna istanze cluter expectation step poi aggiorna cluster maximization step ricava valori centro cluster medie dimensione forma orientazione matrice covarianze relativo peso usa soft clustering stimando probabilit appartenenza durante maximization step ogni cluster aggiornato tutte istanze dataset ogni istanza pesata relativa probabilit appartenenza chiamata responsability cluster listanza perci ogni cluster viene aggiornato maggiormente istanze verosimilmente appartengono esso lalgoritmo richiede diversi run ninit poich pu facilmente produrre cattive congurazioni
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#2,2,"Image segmentation e Instance segmentation
Nella 
 Image segmentation
  si suddivide una immagine in porzioni, dove 
ogni porzione contiene pixel che rappresentano un oggetto associato alla 
porzione (es. pedone, portiera di un auto, etc). Una porzione può 
contenere istanze multiple di un oggetto. 
Nella Instance segmentation ogni porzione contiene una singola istanza 
(es. ogni pedone ha una segmentation distinta). 
Affrontiamo il problema con un approccio basato sulla 
 color segmentation.  
Non è il più efﬁcace, ma per alcuni domini è sufﬁciente (es. analizzare la 
percentuale di zone verdi da immagini satellitari). 
Associamo un pixel ad un segmento se ha colore simile. 
3",image segmentation instance segmentation image segmentation suddivide immagine porzioni ogni porzione contiene pixel rappresentano oggetto associato porzione pedone portiera auto etc porzione pu contenere istanze multiple oggetto instance segmentation ogni porzione contiene singola istanza ogni pedone segmentation distinta affrontiamo problema approccio basato color segmentation efcace alcuni domini sufciente analizzare percentuale zone verdi immagini satellitari associamo pixel segmento colore simile
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Gaussian Mixtures
Possiamo valutare la convergenza e il numero di iterazioni: 
gm
.
converged_
>> True
gm
.
n_iter_
>> 3
Una volta ricavati i parametri possiamo predire il cluster (hard clustering) o 
i clusters (soft clustering) più adatti per una certa istanza: 
gm
.
predict
(
X
)
>> array([2, 2, 1, ..., 0, 0, 0])
gm
.
predict_proba
 (
X
)
>> array([[2.32389467e-02, 6.77397850e-07, 9.76760376e-01],
[1.64685609e-02, 6.75361303e-04, 9.82856078e-01],
[2.01535333e-06, 9.99923053e-01, 7.49319577e-05],
...,
[9.99999571e-01, 2.13946075e-26, 4.28788333e-07],
[1.00000000e+00, 1.46454409e-41, 5.12459171e-16],
[1.00000000e+00, 8.02006365e-41, 2.27626238e-15]])
21",scikit learn gaussian mixtures possiamo valutare convergenza numero iterazioni converged true niter volta ricavati parametri possiamo predire cluster hard clustering clusters soft clustering adatti certa istanza predict array predictproba
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Gaussian Mixtures
Essendo un modello generativo, puoi anche generare nuove istanze dal 
modello: 
X_new
, 
y_new 
= 
gm
.
sample
(
6
)
X_new
>> array([[ 2.95400315, 2.63680992],
[-1.16654575, 1.62792705],
[-1.39477712, -1.48511338],
[ 0.27221525, 0.690366 ],
[ 0.54095936, 0.48591934],
[ 0.38064009, -0.56240465]])
y_new
>>array([0, 1, 2, 2, 2, 2])
oppure stimare la densità del modello per un certo punto. Col metodo 
score_samples
 () si ricava la log della 
 probability density function 
 (PDF): 
gm
.
score_samples
 (
X
)
>> array([-2.60782346, -3.57106041, -3.33003479, ..., -3.51352783,
-4.39802535, -3.80743859])
Per stimare la prob che una istanza cada in una certa regione occorre 
integrare la funzione sull'intervallo.
22",scikit learn gaussian mixtures modello generativo puoi generare nuove istanze modello xnew ynew sample xnew array ynew array oppure stimare densit modello certo punto metodo scoresamples ricava log probability density function scoresamples array stimare prob istanza cada certa regione occorre integrare funzione
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Gaussian Mixtures
Il graﬁco precedente rappresenta la densità per mezzo dei colori: 
È stato facile rappresentare i dati perché abbiamo usato una gaussiana 2D. 
Per altri dataset occorrono più dimensioni (e molte più istanze). Se 
l'algoritmo non riesce a convergere si possono impostare vincoli sulla 
forma e orientazione delle distribuzioni (es. parametro 
 covariance_type
 )
23
",scikit learn gaussian mixtures graco precedente rappresenta densit mezzo colori stato facile rappresentare dati usato gaussiana altri dataset occorrono dimensioni molte istanze lalgoritmo riesce convergere possono impostare vincoli forma orientazione distribuzioni parametro covariancetype
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#3,3,"Scikit-learn: Image segmentation
Carichiamo una immagine, che sarà memorizzata in un array 3d, dove la 
profondità (numero di canali) rappresenta l'intensità RGB in [0,1], o 
[0,255] se si impiega imageio.imread() 
from 
matplotlib.image 
 import 
imread
import
 urllib2
f = 
urllib2.urlopen
 (
'
http://.../image.png
 '
)
f = 
os
.
path
.
join
(
""images""
 ,
""image.png""
 )       # in alternativa
image 
= 
imread
(f)
image
.
shape
>> (533, 800, 3)
Nota: alcune immagini hanno meno canali (es. scala di grigio), o più canali 
(es. alpha channel, segnale infrared).
4",scikit learn image segmentation carichiamo immagine memorizzata array profondit numero canali rappresenta lintensit impiega import imread import urllib urlliburlopen path join images imagepng alternativa image imread image shape nota alcune immagini meno canali scala grigio canali alpha channel segnale infrared
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#4,4,"Scikit-learn: Image segmentation
Il seguente codice ridimensiona l'array come un array 1D, dove ogni 
elemento è una tripla. Dopodiché fa clustering raggruppando pixel con 
colori simili. Inﬁne ricava il colore ""medio"" per mezzo del centroide e 
riordina il risultato come le dimensioni dell'immagine iniziale: 
X 
= 
image
.
reshape
(
-
1
, 
3
)
kmeans 
= 
KMeans
(
n_clusters
 =
8
)
.
fit
(
X
)
segmented_img 
 = 
kmeans
.
cluster_centers_
 [
kmeans
.
labels_
]
segmented_img 
 = 
segmented_img
 .
reshape
(
image
.
shape
)
5
",scikit learn image segmentation seguente codice ridimensiona larray array ogni elemento tripla dopodich clustering raggruppando pixel colori simili inne ricava colore medio mezzo centroide riordina risultato dimensioni dellimmagine iniziale image reshape kmeans means nclusters fit segmentedimg kmeans kmeans labels segmentedimg segmentedimg reshape image shape
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#5,5,"Clustering per il preprocessing
Il clustering può essere usato anche come tecnica di 
 dimensionality 
reduction
 , ad esempio per rendere più adatto un dataset per un approccio 
supervised, riducendo il numero di features e la dimensione totale.  
Es. prendiamo il MNIST dataset (1797 immagini 8x8 in scala di grigio) e 
impieghiamo la logistic regression per la classiﬁcazione: 
from 
sklearn.datasets 
 import 
load_digits
X_digits
 , 
y_digits 
 = 
load_digits
 (
return_X_y
 =
True
)
from 
sklearn.model_selection 
 import 
train_test_split
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X_digits
 , 
y_digits
 )
from 
sklearn.linear_model 
 import 
LogisticRegression
log_reg 
 = 
LogisticRegression
 (
random_state
 =
42
)
log_reg
.
fit
(
X_train
, 
y_train
)
log_reg
.
score
(
X_test
, 
y_test
)
0.9666666666666667
6",clustering preprocessing clustering pu essere usato tecnica dimensionality reduction esempio rendere adatto dataset approccio supervised riducendo numero features dimensione totale prendiamo dataset immagini scala grigio impieghiamo logistic regression classicazione import loaddigits xdigits ydigits loaddigits return true import xtrain xtest ytrain ytest xdigits ydigits import logistic regression logreg logistic regression randomstate logreg fit xtrain ytrain logreg score xtest ytest
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#6,6,"Clustering per il preprocessing
Usiamo inizialmente il cluster per raggruppare le immagini simili usando 
50 clusters (usarne solo 10 non è ottimale poiché esistono molti modi per 
rappresentare la stessa cifra), e usiamo la distanza da questi cluster come 
input al posto dell'immagine originale: 
from 
sklearn.pipeline 
 import 
Pipeline
pipeline 
 = 
Pipeline
 ([
    (
""kmeans""
 , 
KMeans
(
n_clusters
 =
50
)),
    (
""log_reg""
 , 
LogisticRegression
 ()),
])
pipeline
 .
fit
(
X_train
, 
y_train
)
pipeline
 .
score
(
X_test
, 
y_test
)
0.9822222222222222
Abbiamo dimezzato il tasso d'errore! 
Nota: Pipeline combina più operazioni di 
 trasformazione
  sui dati, cioè 
devono comparire classi che implementano 
 ﬁt
() e 
transform
 (). Per ultimo 
c'è l'estimator che deve includere l'implementazione di 
 ﬁt
().
7",clustering preprocessing usiamo inizialmente cluster raggruppare immagini simili usando clusters usarne solo ottimale poich esistono molti modi rappresentare stessa cifra usiamo distanza cluster input posto dellimmagine originale import pipeline pipeline pipeline kmeans means nclusters logreg logistic regression pipeline fit xtrain ytrain pipeline score xtest ytest dimezzato tasso derrore nota pipeline combina operazioni trasformazione dati cio devono comparire classi implementano transform ultimo lestimator deve includere
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#7,7,"Tuning degli iperparametri: grid search
Per il tuning degli iperparametri (numero di cluster) possiamo impiegare lo 
score della fase supervised, senza il bisogno di calcolare la silhoutte. 
La classe GridSearchCV ottimizza il valore degli iperparametri in modo 
esaustivo iterando su intervalli (approccio grid-search con cross-
validazione). 
from 
sklearn.model_selection 
 import 
GridSearchCV
# dizionario chiave->valore, dove la chiave è il nome del iperparametro,
# il valore è il range di valori da valutare
param_grid 
 = 
dict
(
kmeans__n_clusters
 =
range
(
2
, 
100
))
grid_clf 
 = 
GridSearchCV
 (
pipeline
 , 
param_grid
 , 
cv
=
3
, 
verbose
=
2
)
grid_clf
 .
fit
(
X_train
, 
y_train
)
grid_clf
 .
best_params_
>> {'kmeans__n_clusters': 90}
grid_clf
 .
score
(
X_test
, 
y_test
)
>> 0.9844444444444445
8",tuning iperparametri grid search tuning iperparametri numero cluster possiamo impiegare score fase supervised senza bisogno calcolare silhoutte classe grid search ottimizza valore iperparametri modo esaustivo iterando intervalli approccio grid search cross validazione import grid search dizionario chiave valore chiave nome iperparametro valore range valori valutare paramgrid dict range gridclf grid search pipeline paramgrid verbose gridclf fit xtrain ytrain gridclf bestparams gridclf score xtest ytest
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#8,8,"Clustering per il semi-supervised learning
Potremmo avere dataset poche istanze con label (etichettate), e molte 
istanze senza label. Non è sufﬁciente per l'addestramento supervised. 
Ad esempio, impiegando solo 50 istanze dal dataset delle cifre otteniamo 
una accuracy piuttosto bassa: 
n_labeled 
 = 
50
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
[:
n_labeled
 ], 
y_train
[:
n_labeled
 ])
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.826666666666666
9",clustering semi supervised learning potremmo avere dataset poche istanze label etichettate molte istanze senza label sufciente laddestramento supervised esempio impiegando solo istanze dataset cifre otteniamo accuracy piuttosto bassa nlabeled logreg logistic regression logreg fit xtrain nlabeled ytrain nlabeled logreg score xtest ytest
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#9,9,"Clustering per il semi-supervised learning
Esercizio: prova a fare il clustering del dataset delle cifre (split X_train) 
usando 50 clusters impiegando KMeans. Per ogni cluster trova la cifra con 
distanza minima dal centroide dal cluster. Usa queste cifre come il nuovo 
dataset di 50 immagini per addestrare la logistic regressione e valuta la 
differena nelle performance. 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
...
10",clustering semi supervised learning esercizio prova fare clustering dataset cifre split xtrain usando clusters impiegando means ogni cluster trova cifra distanza minima centroide cluster usa cifre nuovo dataset immagini addestrare logistic regressione valuta differena performance kmeans means nclusters
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alle  
Reti Neurali Artiﬁciali
1",machine learning universit roma tre dipartimento ingegneria anno accademico introduzione reti neurali articiali
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#1,1,"Sommario
Introduzione alle Reti Neurali Artiﬁciali 
Unità di Calcolo nelle Reti Neurali  
Reti Neurali a uno strato alimentate in avanti (percettroni) 
Reti Neurali multistrato alimentate in avanti 
Algoritmo di Back-propagation 
Esempio di esecuzione dell’algoritmo
2",sommario introduzione reti neurali articiali unit calcolo reti neurali reti neurali strato alimentate avanti percettroni reti neurali multistrato alimentate avanti algoritmo back propagation esempio esecuzione dellalgoritmo
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#10,10,"ReLU 
(Rectiﬁed Linear Unit)
gg(in i) = max(in i,0)
<latexit sha1_base64=""fdZuD83MuMKqvRY6gR2pKYYhfhM="">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>
ini 0
11",rectied linear unit ggin maxin latexit shabasefd mkqv ryg yhfh chicb ltg ejz ffi lehl gba mgumuj fiyby cqq hbib opz pqa eja swquev bmv hpw xlc hwnpo trky mrsb ktr extbesq dyomi asgh gsu tsxz ulg yln kqy tdjvq msj purs tfb ioz dlszxazet abzjtn mhkbalkz ixk vmm ezds unq faq uzk bfsx mak qpi scizm domnxp afa basfif voc uro sghgqn bwy qsu rtq ixj hlnu mrasl mvp yvpl uinknf nfi znk dllm xtgbecfqva prh dxb vyor mlatexit ini
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#11,11,"Funzione Gradino
La motivazione biologica è che un 1 rappresenta 
l’emissione di un impulso lungo l’assone, mentre uno 0 
rappresenta l’assenza di una tale emissione.
La soglia individua l’ingresso pesato minimo che fa in 
modo che il neurone invii l’impulso.
La funzione a gradino ha una soglia t tale che il 
risultato è 1 quando l’ingresso supera questa soglia.
12",funzione gradino motivazione biologica rappresenta lemissione impulso lungo lassone mentre rappresenta lassenza tale emissione soglia individua lingresso pesato minimo modo neurone invii limpulso funzione gradino soglia tale risultato quando lingresso supera soglia
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#12,12,"Funzione Gradino
In molti casi risulterà dal punto di vista matematico 
conveniente sostituire la soglia con un peso d’ingresso 
extra.
Questo consentirà di avere un elemento di 
apprendimento più semplice in quanto si dovrà 
preoccupare solo di modiﬁcare dei pesi anziché 
modiﬁcare sia dei pesi che delle soglie.
Quindi, invece di avere una soglia t, considereremo per 
ciascuna unità un ingresso aggiuntivo, la cui attivazione 
a
0
 è ﬁssata a -1.
13",funzione gradino molti casi risulter punto vista matematico conveniente sostituire soglia peso dingresso extra consentir avere elemento apprendimento semplice dovr preoccupare solo modicare pesi anzich modicare pesi soglie quindi invece avere soglia considereremo ciascuna unit ingresso aggiuntivo attivazione ssata
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#13,13,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
14",altri neuroni unit calcolo reti neurali
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#14,14,"Unità di Calcolo nelle Reti Neurali 
Il peso extra W
 0,i
 associato ad a
 0
 ricopre il ruolo della 
soglia t, dove W
 0,i
 = t e a
 0 
= -1. 
In questo modo tutte le unità possono avere una soglia 
ﬁssata a 0.ai=gradinot0
@nX
j=1Wj,iaj1
A=gradino00
@nX
j=0Wj,iaj1
A
<latexit sha1_base64=""bnb4YwLA9yDvbdcHkbSf+9auugw="">AAACfXicfVFNb9NAEF2brxI+moI4IcGIqFKRosgulcqlUgUXjkUiTaU4WOPNJJ12vbZ2x4jK8g/gJ3LgN/ATwA45QFrxTk9v5r3ZnclKw16i6HsQ3rp95+69rfu9Bw8fPd7u7zw59UXlNI11YQp3lqEnw5bGwmLorHSEeWZokl2+7+qTL+Q8F/aTXJU0y3FpecEapZXS/jdMGY4gEfrauuulwznbokkFEkML2YPEV3laXxzFzefaNjBp+ZAbSIaA6QUkjpfn8vqmhGgzIfpvQi/tD6JRtAJcJ/GaDNQaJ2n/RzIvdJWTFW3Q+2kclTKr0QlrQ00vqTyVqC9xSdOWWszJz+rVyhrYrTxKASU5YAMrkf521Jh7f5VnbWeOcu43a514U21ayeLtrGZbVkJWd4OEDa0Gee24vQXBnB2JYPdyArag0aEIOQbUuhWr9jjdPuLN318np/uj+M1o/+PB4PjdejNb6rl6pfZUrA7VsfqgTtRYafUzeBa8CF4Gv8LdcBiO/rSGwdrzVP2D8PA3NkzAIQ==</latexit>
15",unit calcolo reti neurali peso extra associato ricopre ruolo soglia modo tutte unit possono avere soglia ssata aigradinot wjiaj agradino wjiaj latexit lay dvbdc hkb sfauugwa xicf efbrx imo giq rosgulcql uxjk jjvb zxj kgg qfrx tkvr zncl kwi qrprfu bwf pduzw uxl yqplq enwb gwm lor wzoklq tlq juy fpec eap sjd efrauuulwznbokk fek evla xxz fzefa bpz qukjpfnvqmh ggz ifpv qit jrt ajc jga jnrz ivd qkcl tkr qlr qvq wsz jzr vyhr mrkf jhf vnb ocua uaye ltr gzb jwd geev pdy araga oqb uuh wrjjd pjdej nbrlpf zur vsfqg ryaf uze ldc sgwdrz nkz qlatexit
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#15,15,"Funzione Gradino 
(con soglia zero)
g
0g(in i)=⇢1i f i n i",funzione gradino con soglia zero gin ii
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#16,16," Vediamo adesso alcuni semplici esempi di 
reti neurali per la realizzazione di
Porte Logiche
17",vediamo adesso alcuni semplici esempi reti neurali realizzazione porte logiche
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#17,17,"Porte logiche
Lavorando in modo  adeguato sui pesi si possono realizzare 
porte logiche con una rete neurale formata da un solo 
neurone:
18",porte logiche lavorando modo adeguato pesi possono realizzare porte logiche rete neurale formata solo neurone
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#18,18,"Porta AND
•
(Soglia t =1.5) 
•
 W
0
=1.5 
•
W
1
=1 
•
W
2
=1 
•
a
0
= -1 
•
Per a
1
=1 e a
2
= 1si ha: in=0.5 => 
 g(in)=1
  (funzione g a gradino) 
•
Per a
1
=1 e a
2
= 0 si ha: in=-0,5 => 
 g(in)=0   
19",porta soglia gin funzione gradino gin
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#19,19,"Porta OR
•
(Soglia t = 0.5)
•
 W
0
=0.5
•
W
1
=1
•
W
2
=1
•
a
0
= -1
•
Per a
1
=1 e a
2
= 1si ha: in=1.5 => 
 g(in)=1
  (funzione g a gradino)
•
Per a
1
=1 e a
2
= 0 si ha: in=0.5 => 
 g(in)=1
•
 Per a
1
=0 e a
2
= 0 si ha: in=-0.5 => 
 g(in)=0
20",porta soglia gin funzione gradino gin gin
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#2,2,"Il cervello
•Costituito da circa 1011 neuroni
•1014 sinapsi
•Segnali basati su potenziale elettrochimico
 Quando il potenziale 
sinaptico supera una certa 
soglia la cellula emette un 
impulso
3",cervello costituito circa neuroni sinapsi segnali basati potenziale elettrochimico quando potenziale sinaptico supera certa soglia cellula emette impulso
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#20,20,"Porta NOT
•
(Soglia t = - 0.5)
•
 W
0
= - 0.5
•
W
1
= - 1
•
a
0
= -1
•
Per a
1
=1 => 
 g(in)=0
  (funzione g a gradino)
•
Per a
1
=0 si ha: in=0.5 => 
 g(in)=1
21",porta soglia gin funzione gradino gin
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#21,21,"Strutture di Rete
•
Ci sono due categorie principali di strutture di reti 
neurali:
•
Feed-forward 
 (o acicliche o alimentate in avanti)
•
Ricorrenti
  (o cicliche)
•
Noi ci occuperemo solo di reti feed-forward.
•
Esse sono una tipologia di reti neurali caratterizzate 
dall’avere un verso delle sinapsi, dallo strato di input allo 
strato di output.
22",strutture rete due categorie principali strutture reti neurali feed forward acicliche alimentate avanti ricorrenti cicliche occuperemo solo reti feed forward esse tipologia reti neurali caratterizzate dallavere verso sinapsi strato input strato output
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#22,22,"Esempio di Rete Feed-Forward
•
Una rete alimentata in avanti rappresenta una funzione dei 
suoi input:
a5
23",esempio rete feed forward rete alimentata avanti rappresenta funzione input
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#23,23,"•
L’output dell’intera rete 
 a
5
 è funzione dei suoi input 
 a 
•
I pesi 
 W
 agiscono da parametri della funzione. 
•
La rete calcola una funzione 
 f
W
(x) 
•
La funzione 
 f
W 
rappresenta una funzione dello 
 spazio 
delle ipotesi 
 H 
che può essere booleana o continua. 
•
Se i pesi vengono modificati, cambia la funzione 
rappresentata dalla rete. 
•
Le reti feed-forward sono in genere organizzate a strati, 
in modo tale che ogni unità riceva gli input solo dalle 
unità dello strato immediatamente precedente.
Esempio di Rete Feed-Forward
24",loutput dellintera rete funzione input pesi agiscono parametri funzione rete calcola funzione funzione rappresenta funzione spazio ipotesi pu essere booleana continua pesi vengono modificati cambia funzione rappresentata rete reti feed forward genere organizzate strati modo tale ogni unit riceva input solo unit strato immediatamente precedente esempio rete feed forward
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#24,24,"•
Si tratta di una rete feed-forward in cui 
 tutti
 gli input sono 
collegati direttamente a 
 tutti
 gli output.
•
Esempio:
• 3 unità di output
• 5 unità di input
• 1 unità di output
• 2 unità di input
Reti Feed-Forward a Strato Singolo 
(percettroni)
25",tratta rete feed forward input collegati direttamente output esempio unit output unit input unit output unit input reti feed forward strato singolo percettroni
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#25,25,"•
Esaminiamo lo spazio delle ipotesi che un percettrone 
può rappresentare.
•
Se ha una funzione di attivazione a soglia, si può 
pensare che il percettrone rappresenti una funzione 
booleana. 
•
Oltre alle funzioni elementari AND, OR e NOT viste 
prima, un percettrone può rappresentare funzioni 
booleane “complesse” in modo molto compatto. 
•
Vedi, ad esempio, la 
 funzione di maggioranza
 .
Reti Feed-Forward a Strato Singolo 
(percettroni)
26",esaminiamo spazio ipotesi percettrone pu rappresentare funzione attivazione soglia pu pensare percettrone rappresenti funzione booleana oltre funzioni elementari viste prima percettrone pu rappresentare funzioni booleane complesse modo molto compatto vedi esempio funzione maggioranza reti feed forward strato singolo percettroni
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#26,26,"La Funzione di Maggioranza
•
Percettrone a soglia 
•
Restituisce 1 se e solo se più della metà dei suoi 
 n
 input binari 
vale 1 
•
Basta porre: W
j
=1 per ogni input e W
0
=n/2 
•
Un albero di decisione necessiterebbe di 
 O(2
n
)
 nodi per 
rappresentare la stessa funzione. 
27",funzione maggioranza percettrone soglia restituisce solo met input binari vale basta porre ogni input albero decisione necessiterebbe nodi rappresentare stessa funzione
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#27,27,"•Un percettrone a soglia non può rappresentare tutte le 
funzioni booleane. 
•Infatti restituisce 1 se e solo se la somma pesata dei suoi 
input è positiva: 
•L’equazione                 deﬁnisce un iperpiano  nello spazio 
degli input. 
•Il percettrone restituisce 1 se e solo se l’input si trova da 
una parte speciﬁca rispetto a tale iperpiano. 
•Per questo il percettore a soglia è chiamato anche 
separatore lineare .nX
j=0Wjxj>0 oppure:
Separabilità Lineare di un Percettrone a Soglia
WT·x>0
<latexit sha1_base64=""d9P2mD7Jg+O+gyHjQQ5KI5NUFrA="">AAACFnicbVC7TsNAEDyHVwgvAyXNKRESVWQHJKhQBA1lkPKSkhCdL5twyvmhuzVKZKXnE/gKWqjoEC0tBf+CbYwECVONZna1O+MEUmi0rA8jt7S8srqWXy9sbG5t75i7e03th4pDg/vSV22HaZDCgwYKlNAOFDDXkdByxpeJ37oDpYXv1XEaQM9lI08MBWcYS32z2EWYoDOMWrObOu3ygY/0R5rM6Dm1Cn2zZJWtFHSR2BkpkQy1vvnZHfg8dMFDLpnWHdsKsBcxhYJLmBW6oYaA8TEbQSemHnNB96I0y4wehpqhTwNQVEiaivB7I2Ku1lPXiSddhrd63kvE/7xOiMOzXiS8IETweHIIhYT0kOZKxCUBHQgFiCz5HKjwKGeKIYISlHEei2HcWtKHPZ9+kTQrZfu4XLk+KVUvsmby5IAUyRGxySmpkitSIw3CyT15JE/k2XgwXoxX4+17NGdkO/vkD4z3LwRxnsk=</latexit>
WT·x=0
<latexit sha1_base64=""ChE2zA/JsnaGrMeC8O8z0h7ASAE="">AAACFnicbVC7SgNBFJ2Nrxhfq5Y2Q4JgFXajoI0QtLGMkBckMcxObuKQ2QczdyVhSe8n+BW2WtmJra2F/+LuuoImnupwzr3ce44TSKHRsj6M3NLyyupafr2wsbm1vWPu7jW1HyoODe5LX7UdpkEKDxooUEI7UMBcR0LLGV8mfusOlBa+V8dpAD2XjTwxFJxhLPXNYhdhgs4was1u6rTLBz7SH2kyo+fUKvTNklW2UtBFYmekRDLU+uZnd+Dz0AUPuWRad2wrwF7EFAouYVbohhoCxsdsBJ2YeswF3YvSLDN6GGqGPg1AUSFpKsLvjYi5Wk9dJ550Gd7qeS8R//M6IQ7PepHwghDB48khFBLSQ5orEZcEdCAUILLkc6DCo5wphghKUMZ5LIZxa0kf9nz6RdKslO3jcuX6pFS9yJrJkwNSJEfEJqekSq5IjTQIJ/fkkTyRZ+PBeDFejbfv0ZyR7eyTPzDevwAC357I</latexit>
28",un percettrone soglia pu rappresentare tutte funzioni booleane infatti restituisce solo somma pesata input positiva lequazione denisce iperpiano spazio input il percettrone restituisce solo linput trova parte specica rispetto tale iperpiano per percettore soglia chiamato separatore lineare wjxj oppure separabilit lineare percettrone soglia tx latexit shabased jgogy cfnicb edy hvwgv jkh alk skh ltwyvmhuz kwqjo ect bfcb nzna eumir ajt ssrq wxysb gtiethp dgv cgw ykl xkd byxpe yxv xea qml ysz mwr ouyg cnz bkpk qyvvn zhfgd dlpn whds bcxh bwo teb qsem iywehpqh veiaiv kul pxi sddhrdkv moz twe ytk hkjw kge heei pzk tqr zfu xlkk vuvsmby rgxy smpkit siw jek xgw xox ngdk ovk tx latexit shabasech ajsna ozh aea cfnicb nrxhfq fxajo bck mcx obu qczdy senb wtm jra fluuo imnupwzrce rsj wpuj hyo ode udpk dxoo gvmfus bavdp twx fjxh yhdhgswasur shkyof ukv tnkl ymek luu znddz wradwrw aou yvbohho cxsds yesw ggq gpg sfp lvj wkd gdqe pep hwgh dbkh qor ezc llkc dcowphgh zxakfnz ksl ojcu fsy jkw jef ejqek ijfkk rzp dfejbfv rey tpz devw ilatexit
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#28,28,"• Percettrone elementare (senza strati nascosti): non può classificare 
pattern che non siano linearmente separabili.
• Questi casi però sono frequenti: ad esempio problema dello XOR .
• Caso particolare della classificazione di punti nell’ipercubo unitario: 
ogni punto è in classe 0 o in classe 1.
• Per lo XOR si considerano gli angoli del quadrato unitario (i punti 
(0,0), (0,1), (1,0) e (1,1))
Separabilità Lineare di un Percettrone a Soglia
29",percettrone elementare senza strati nascosti pu classificare pattern linearmente separabili casi per frequenti esempio problema caso particolare classificazione punti nellipercubo unitario ogni punto classe classe considerano angoli quadrato unitario punti separabilit lineare percettrone soglia
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#29,29,"Marvin Minsky
Limiti del Percettrone 
30",marvin minsky limiti percettrone
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#3,3," Warren Sturgis McCulloch  (1899 – 1969) Neurofisiologo e cibernetico 
americano.  
 Walter Pitts  (1923 – 1969) fu un logico che lavorò nel campo della 
psicologia conoscitiva.  
Primo modello matematico di una cellula nervosa descritto in un famoso 
articolo: A Logical Calculus of the Ideas Immanent in Nervous Activity 
(1943).  
 Nello scritto del 1943 tentarono di dimostrare che il programma della 
macchina di Turing poteva essere effettuato anche in una rete finita di 
neuroni  e che il neurone fosse l’unità logica di base del cervello. I pionieri
4",warren sturgis culloch neurofisiologo cibernetico americano walter pitts logico lavor campo psicologia conoscitiva primo modello matematico cellula nervosa descritto famoso articolo logical calculus ideas immanent nervous activity scritto tentarono dimostrare programma macchina turing poteva essere effettuato rete finita neuroni neurone lunit logica base cervello pionieri
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#30,30,"Marvin Minsky
1969 : Minsky e Papert, Perceptrons
Limiti del Percettrone 
31",marvin minsky minsky papert perceptrons limiti percettrone
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#31,31,"Apprendimento nel Percettrone
•
Nonostante il loro potere espressivo limitato, esiste un semplice 
algoritmo di apprendimento capace di adattare un percettrone a 
soglia a qualsiasi insieme di addestramento linearmente 
separabile (noi vedremo una versione dell’algoritmo per 
l’apprendimento nei percettroni a sigmoide). 
•
L’idea base dell’algoritmo è quella di calcolare i pesi della rete in 
modo tale da minimizzare una determinata funzione di costo 
sull’insieme di training. 
•
In tal modo il processo di apprendimento è formulato come una 
ricerca di ottimizzazione nello spazio dei pesi.
32",apprendimento percettrone nonostante potere espressivo limitato esiste semplice algoritmo apprendimento capace adattare percettrone soglia qualsiasi insieme addestramento linearmente separabile noi vedremo versione dellalgoritmo lapprendimento percettroni sigmoide lidea base dellalgoritmo calcolare pesi rete modo tale minimizzare determinata funzione costo sullinsieme training tal modo processo apprendimento formulato ricerca ottimizzazione spazio pesi
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#32,32,"•
La funzione di costo sull’insieme di training che viene usata 
tradizionalmente è la 
 somma dei quadrati degli errori
 , dove 
il singolo errore è la differenza tra l’output desiderato y e 
l’output della rete f
W
(
x
)
. 
Il quadrato dell’errore per un singolo 
esempio di training è il seguente: 
essendo 
 x
 il vettore relativo ai dati di input dell’esempio,            
y il valore corretto della funzione di output e f
 w
(
x
) il valore di 
output ottenuto dalla rete avente in input 
 x
.
E=1
2Err2=1
2(y",funzione costo sullinsieme training viene usata somma quadrati errori singolo errore differenza loutput desiderato loutput rete quadrato dellerrore singolo esempio training seguente vettore relativo dati input dellesempio valore corretto funzione output valore output ottenuto rete avente input err
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#33,33,"Possiamo usare tale metodo per ridurre il quadrato dell’errore 
(ricerca del minimo globale) calcolando la derivata parziale di E 
rispetto ad ogni peso:
dove g’ è la derivata della funzione di attivazione.
Per la sigmoide:
Metodo della Discesa del Gradiente
34",possiamo usare tale metodo ridurre quadrato dellerrore ricerca minimo globale calcolando derivata parziale rispetto ogni peso derivata funzione attivazione sigmoide metodo discesa gradiente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#34,34," α = step size  o tasso di apprendimento .Il peso deve essere aggiornato in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E vista in precedenza:
L’aggiornamento del peso è pertanto il seguente:
Metodo della Discesa del Gradiente
35",step size tasso apprendimento peso deve essere aggiornato modo lidea modificare peso negativo derivata dellerrore vista precedenza laggiornamento peso pertanto seguente metodo discesa gradiente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#35,35,"Algoritmo completo di apprendimento 
a discesa di gradiente per percettroni
Metodo della discesa del gradiente
36",algoritmo completo apprendimento discesa gradiente percettroni metodo discesa gradiente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#36,36," Gli esempi di addestramento vengono fatti passare attraverso la 
rete uno per volta, modificando leggermente i pesi a ogni 
iterazione per ridurre l’errore.  
 Ogni ciclo attraverso tutti gli esempi prende il nome di epoca . 
 Le epoche sono ripetute secondo un ben preciso criterio di 
terminazione (e.g., quando le modifiche dei pesi sono piccole). 
Altri metodi calcolano il gradiente per l’intero training set, 
sommando tutti i contributi dati dall’equazione precedente prima 
di aggiornare i pesi. 
Metodo della Discesa del Gradiente
37",esempi addestramento vengono fatti passare attraverso rete volta modificando leggermente pesi ogni iterazione ridurre lerrore ogni ciclo attraverso esempi prende nome epoca epoche ripetute secondo ben preciso criterio terminazione quando modifiche pesi piccole altri metodi calcolano gradiente lintero training set sommando contributi dati dallequazione precedente prima aggiornare pesi metodo discesa gradiente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#37,37,"Percettrone a soglia
 Per percettroni a soglia  la g’(in)  è indefinita.
 In questo caso la regola di apprendimento del percettrone 
originale sviluppata da Rosenblatt (1957) è la seguente:
Essa è simile a quella vista, tranne per il fatto che la g’(in) è 
omessa. 
Poiché g’(in) è la stessa per tutti i pesi, la sua omissione 
cambia solo la dimensione e non la direzione 
dell’aggiornamento globale dei pesi.
38",percettrone soglia percettroni soglia gin indefinita caso regola apprendimento percettrone originale sviluppata rosenblatt seguente essa simile vista tranne fatto gin omessa poich gin stessa pesi omissione cambia solo dimensione direzione globale pesi
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#38,38,"Il Percettrone di Rosemblatt
39",percettrone rosemblatt
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#39,39,"Reti Feed-Forward Multistrato
 Si tratta di reti con unità nascoste, in cui esiste un 
verso di propagazione del segnale dall’input 
all’output. 
 Ciascun nodo dello strato i-mo è collegato con tutti 
i nodi dello strato i+1-mo. 
 Percettrone multistrato . 
40",reti feed forward multistrato tratta reti unit nascoste esiste verso propagazione segnale dallinput alloutput ciascun nodo strato collegato nodi strato percettrone multistrato
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#4,4,"John McCarthy ha indicato il lavoro di Nicolas Rashevsky  (1936, 
1938) come il primo modello matematico di apprendimento neurale. 
 Alan Turing  (1948) scrisse un rapporto di ricerca intitolato Intelligent 
Machinery  che inizia con la frase "" I propose to investigate the 
question as to whether it is possible for machinery to show intelligent 
behaviour "" e prosegue descrivendo un'architettura di rete neurale 
ricorrente che ha definito "" B-type unorganized machines  ""e un 
approccio per addestrarla. 
Sfortunatamente, tale rapporto non è stato pubblicato fino al 1969 ed 
è stato quasi ignorato fino a poco tempo fa.I pionieri
5",john carthy indicato lavoro nicolas rashevsky primo modello matematico apprendimento neurale alan turing scrisse rapporto ricerca intitolato intelligent machinery inizia frase propose investigate question whether possible machinery show intelligent behaviour prosegue descrivendo unarchitettura rete neurale ricorrente definito type unorganized machines approccio addestrarla tale rapporto stato pubblicato fino stato quasi ignorato fino poco tempo fai pionieri
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#40,40,"Esempio di Rete Neurale Feed-Forward Multistrato 
41",esempio rete neurale feed forward multistrato
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#41,41,"Spazio delle ipotesi H per il  
percettrone multistrato
•
Il vantaggio di aggiungere strati nascosti è quello di 
ampliare lo spazio delle ipotesi rappresentabili dalla rete. 
•
Possiamo infatti considerare ogni unità nascosta come un 
percettrone che rappresenta una funzione a soglia 
morbida nello spazio di input (vedi figura seguente). 
•
Ogni unità di output può dunque rappresentare una 
combinazione lineare (a soglia morbida) di molte 
funzioni simili.
42",spazio ipotesi percettrone multistrato vantaggio aggiungere strati nascosti ampliare spazio ipotesi rappresentabili rete possiamo infatti considerare ogni unit nascosta percettrone rappresenta funzione soglia morbida spazio input vedi figura seguente ogni unit output pu dunque rappresentare combinazione lineare soglia morbida molte funzioni simili
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#42,42,"Output di un Percettrone  
a due Input (con sigmoide)
43",output percettrone due input con sigmoide
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#43,43,"• Fig. (a): cresta  prodotta da due funzioni a 
soglia morbida rivolte in direzioni opposte 
e limitando il risultato con un’altra soglia.
• Fig. (b): protuberanza  prodotta dalla 
combinazione di due creste ad angolo retto 
(cioè, combinando le uscite di quattro unità 
nascoste).
(a) (b)⇓
Combinazione di Funzioni  
a Soglia Morbida
fw(x 1,x2) fw(x 1,x2)
44",fig cresta prodotta due funzioni soglia morbida rivolte direzioni opposte limitando risultato unaltra soglia fig protuberanza prodotta combinazione due creste angolo retto cio combinando uscite quattro unit nascoste combinazione funzioni soglia morbida fwx fwx
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#44,44,"Con un solo strato nascosto sufficientemente grande 
possiamo rappresentare qualsiasi funzione continua degli 
input con accuratezza arbitraria. 
Con due strati nascosti possono essere rappresentate anche 
funzioni discontinue (il numero delle unità nascoste cresce 
esponenzialmente con il numero degli input).
Purtroppo, data una qualsiasi struttura di rete prefissata , è 
difficile stabilire esattamente quali funzioni possano essere 
rappresentate e quali non possano esserlo.
Reti Feed-Forward Multistrato
45",solo strato nascosto grande possiamo rappresentare qualsiasi funzione continua input accuratezza arbitraria due strati nascosti possono essere rappresentate funzioni discontinue numero unit nascoste cresce numero input purtroppo data qualsiasi struttura rete prefissata difficile stabilire esattamente quali funzioni possano essere rappresentate quali possano esserlo reti feed forward multistrato
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#45,45,"Apprendimento nelle Reti  
Multistrato Feed-Forward 
Gli algoritmi per l’apprendimento per le reti multistrato sono 
simili all’algoritmo di apprendimento per i percettroni visto in 
precedenza.
Una differenza è costituita dal fatto che nelle reti multistrato 
avremo in generale più unità di output.
Ciò comporta che avremo un vettore di output fw(x) calcolato 
dalla rete anziché un valore singolo e, per ogni esempio, un 
vettore di output y.
46",apprendimento reti multistrato feed forward algoritmi lapprendimento reti multistrato simili allalgoritmo apprendimento percettroni visto precedenza differenza costituita fatto reti multistrato generale unit output ci comporta vettore output fwx calcolato rete anzich valore singolo ogni esempio vettore output
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#46,46,"•L’idea base rimane la stessa, che è quella di calcolare i pesi della 
rete in modo da minimizzare la somma dei quadrati degli errori che, 
per un singolo esempio, è definita come segue:
•Dato un certo esempio, il vettore di errore in output è il seguente:
•Indichiamo come segue l’i-esimo componente del suddetto vettore:
•E’ inoltre utile definire come segue un errore modificato:
 
Apprendimento nelle Reti  
Multistrato Feed-Forward 
y",lidea base rimane stessa calcolare pesi rete modo minimizzare somma quadrati errori che singolo esempio definita segue dato certo esempio vettore errore output seguente indichiamo segue li esimo componente suddetto vettore e inoltre utile definire segue errore modificato apprendimento reti multistrato feed forward
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#47,47,"Back-propagation
 : strato di output
Per lo strato di output, il peso deve essere aggiornato
 in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 52 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
48",back propagation strato output strato output peso deve essere aggiornato modo lidea modificare peso negativo derivata dellerrore vedi lucido dettagli derivazione laggiornamento peso pertanto seguente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#48,48,"Back-propagation
 : strato nascosto  
(versione intuitiva)
Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
Dobbiamo però definire una quantità analoga all’errore per i nodi di 
output.
E’ a questo punto che entra in gioco la retropropagazione :
L’idea  è  che  il  nodo  nascosto  j  sia  “responsabile”  per  una  parte  
dell’errore ∆i in ognuno dei nodi di output ai quali è collegato.
In tal modo i valori ∆ sono suddivisi in base alla forza delle connessioni 
tra nodo nascosto e nodo di output e passati all’indietro per fornire i 
valori ∆j allo strato nascosto.
49",back propagation strato nascosto versione intuitiva strato nascosto generico peso deve essere aggiornato modo dobbiamo per definire quantit analoga allerrore nodi output punto entra gioco lidea nodo nascosto responsabile parte dellerrore ognuno nodi output quali collegato tal modo valori suddivisi base forza connessioni nodo nascosto nodo output passati allindietro fornire valori strato nascosto
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#49,49,"La regola di propagazione per i valori       è dunque la seguente:
L’aggiornamento del peso è pertanto il seguente, identica a quella 
che riguarda lo strato di output:
Back-propagation
 : strato nascosto  
(versione intuitiva)
50",regola propagazione valori dunque seguente laggiornamento peso pertanto seguente identica riguarda strato output back propagation strato nascosto versione intuitiva
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#5,5,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
6",altri neuroni unit calcolo reti neurali
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#50,50,"Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
L’idea è, di nuovo, quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 53 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
Back-propagation
 : strato nascosto  
(versione formale)
51",strato nascosto generico peso deve essere aggiornato modo lidea nuovo modificare peso negativo derivata dellerrore vedi lucido dettagli derivazione laggiornamento peso pertanto seguente back propagation strato nascosto versione formale
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#51,51,"Calcolo del gradiente  
(strato di output)
52",calcolo gradiente strato output
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#52,52,"Calcolo del gradiente  
(strato nascosto)
53",calcolo gradiente strato nascosto
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#53,53,"Processo di Retropropagazione
In sintesi, il processo di retropropagazione può essere descritto 
come segue: 
•
Si calcolano i valori 
 ∆ 
per le unità di output usando l’errore 
osservato. 
•
Cominciando dallo strato di output, si ripete quanto segue per 
ogni strato della rete fino a raggiungere l’ultimo strato 
nascosto: 
o
si propagano all’indietro i valori ∆ verso lo strato 
precedente; 
o
si aggiornano i pesi tra i due strati.
54",processo sintesi processo pu essere descritto segue calcolano valori unit output usando lerrore osservato cominciando strato output ripete segue ogni strato rete fino raggiungere lultimo strato nascosto propagano allindietro valori verso strato precedente aggiornano pesi due strati
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#54,54,"Back-propagation
1. Presentazione pattern d’ingresso 
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
55",back propagation presentazione pattern dingresso unit input unit output unit nascoste wkj wji
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#55,55,"Unità di input akUnità di output ai
Unità nascoste aj2. Propagazione dell’input in avanti sullo strato nascosto 
Wk,jWj,i
Back-propagation
56",unit input unit output unit nascoste propagazione dellinput avanti strato nascosto wkj wji back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#56,56,"3. Propagazione dallo strato nascosto allo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
57",propagazione strato nascosto strato output unit input unit output unit nascoste wkj wji back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#57,57,"4. Calcolo dei valori DELTA per lo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
58",calcolo valori strato output unit input unit output unit nascoste wkj wji back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#58,58,"5. Retropropagazione dell’errore
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
L’errore si retropropaga  su 
ciascun nodo proporzionalmente  
alla forza  di connessione tra il 
nodo nascosto e il nodo di output
Back-propagation
59",dellerrore unit input unit output unit nascoste wkj wji lerrore retropropaga ciascun nodo forza connessione nodo nascosto nodo output back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#59,59,"6. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
60",aggiornamento pesi unit input unit output unit nascoste wkj wji back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#6,6," Ogni unità i calcola per prima cosa una somma pesata 
dei propri input:
 Successivamente si applica una funzione di attivazione  
g alla somma per derivare l’output:
Unità di Calcolo nelle Reti Neurali
ini=nX
j=1Wj,iaj
<latexit sha1_base64=""eWDCyQ6ONiLa3NNG6gCYSqPL4Ko="">AAACI3icbVC7TsNAEDzzDOEVoKQ5ESFRoGADEjRIETSUIBGCFAdrfSxwcD5bd2sEsvwZfAJfQQsVHaKh4F+4hBS8phrN7Gp3Js6UtOT7797Q8Mjo2Hhlojo5NT0zW5ubP7ZpbgS2RKpScxKDRSU1tkiSwpPMICSxwnZ8vdfz2zdorEz1Ed1l2E3gQstzKYCcFNXWQsJbt1dIXUaS73Ae2jyJiqudoDwtdMnbjq/KkoerHKIrHtXqfsPvg/8lwYDU2QAHUe0jPEtFnqAmocDaTuBn1C3AkBQKy2qYW8xAXMMFdhzVkKDtFv1gJV/OLVDKMzRcKt4X8ftGAYm1d0nsJhOgS/vb64n/eZ2czre7LnOWE2rRO0RSYf+QFUa6xpCfSYNE0PscudRcgAEiNJKDEE7MXYVV10fwO/1fcrzeCDYa64eb9ebuoJkKW2RLbIUFbIs12T47YC0m2D17ZE/s2XvwXrxX7+1rdMgb7CywH/A+PgGXqaO/</latexit>
ai=g(ini)=g0
@nX
j=1Wj,iaj1
A
<latexit sha1_base64=""L8MWGsH2A4rKpI1HGBXATIbImqQ="">AAACOnicbVDBShxBEO3RxOjG6MYcvTRZAivIMqOB5CKIguRoIOsKO+tQ09aOpT09Q3dNUIb5o3xCvsKbJF68idd8QHo3e0g07/R4rx5V9dJSk+MwvAnm5p89X3ixuNR6ufxqZbX9eu3IFZVV2FeFLuxxCg41Gewzscbj0iLkqcZBerE/8Qdf0ToqzBe+KnGUQ2ZoTArYS0n7ABKSOzLrxoyXPl+TaRLa8JLMYo1j7srYVXlSn+9EzUltGjnwfJMaGW9KSM5jS9kZbyTtTtgLp5BPSTQjHTHDYdK+jU8LVeVoWGlwbhiFJY9qsExKY9OKK4clqAvIcOipgRzdqJ7+28h3lQMuZIlWkpZTEf9O1JA7d5WnfjIHPnOPvYn4P29Y8fjjyFdQVoxGTRYxaZwucsqSLxLlKVlkhsnlKMlIBRaY0ZIEpbxY+WZbvo/o8fdPydFWL9rubX1+39ndmzWzKNbFW9EVkfggdsUncSj6Qolv4lr8ED+D78FdcB88/BmdC2aZN+IfBL9+A3R4rDw=</latexit>
7",ogni unit calcola prima cosa somma pesata propri input successivamente applica funzione attivazione somma derivare loutput unit calcolo reti neurali inin wjiaj latexit shabasee oni koa ciicb edzz evo fro dej fadrf sxwc dbds esvw ajf qqs vha bsphr mjo hhlojo ntz wub zpbg rkp scx utki swp sxwn zvdfzzdor edl qstz jbtd aejy jiqudo dwtd mnbjqkkoer xqfs pvglw huej pet fnq amoc kyq ywx fdhz kdt fvg jvo xft ymdns svbne zczre yfq fuaxp pscud rcg aei vfw ofcrze yaebebuo rlb ycm zes xvw xrx xrd mgb cyw hapg gxqa olatexit aiginig wjiaj latexit shabasel imq conicb bshx mycv zaiv imq igu ios kot ibox cvs jfidd qhoegrrx jskmwv anmp xixu nrufxq xeu fluxx gewzscbji lkqc zber qdf toqz bekn tar ysn lrxoy xplta rla myojsr ult gjnwf jma zby ttg lve wglwbhi yqs kclq oipg rzdq jhl qmu zil wkp jad wnfj opv yfjjy qvox ryxa zwucsq slx kvlkhsnl kml epbx zbvoofd pyd lrub xndmz knb evkfggds unc qolvlr edd fdc bbmd znif bla dwlatexit
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#60,60,"7. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
61",aggiornamento pesi unit input unit output unit nascoste wkj wji back propagation
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#61,61,"Esempio di Esecuzione
• Vediamo un esempio di esecuzione dell’algoritmo di Back-
propagation applicato sulla seguente rete:
a1 a2
0 1U1 U2
1 1U3 U4U5
1a5
W3,5=1.5 W4,5=-1.0
a3 a4
W1,3=1 W2,4=2W1,4=-1 W2,3=0.51 11Target = 1
Output Layer
Hidden Layer
Input Layer
62",esempio esecuzione vediamo esempio esecuzione dellalgoritmo back propagation applicato seguente rete target output layer hidden layer input layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#62,62,"Esempio di Esecuzione
•Eseguiamo l’algoritmo su un solo esempio di addestramento e, per il 
quale dunque conosciamo l’output corretto ( Target = 1 ) a fronte di un 
certo input  X.
• Supponiamo che i valori dell’input per l’esempio e in questione 
siano i seguenti:
•  Input U1: 
•  Input U2:  
63",esempio esecuzione eseguiamo lalgoritmo solo esempio addestramento dunque conosciamo loutput corretto target fronte certo input supponiamo valori dellinput lesempio questione seguenti input input
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#63,63,"Esempio di Esecuzione
1. Presentazione del pattern in ingresso :
64",esempio esecuzione presentazione pattern ingresso
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#64,64,"Esempio di Esecuzione
2. Passo Feed-Forward ( hidden layer ):
65",esempio esecuzione passo feed forward hidden layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#65,65,"Esempio di Esecuzione
3. Passo Feed-Forward ( output layer ):
66",esempio esecuzione passo feed forward output layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#66,66,"Esempio di Esecuzione
• A fronte di questo risultato in uscita possiamo calcolare il quadrato 
dell’errore:  
• L’errore non è molto alto, ma applicando l’algoritmo alla rete 
possiamo cercare di ridurlo.  
67",esempio esecuzione fronte risultato uscita possiamo calcolare quadrato dellerrore lerrore molto alto applicando lalgoritmo rete possiamo cercare ridurlo
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#67,67,"Esempio di Esecuzione
4. Calcolo del valore ∆ in uscita ( output layer ):
68",esempio esecuzione calcolo valore uscita output layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#68,68,"Esempio di Esecuzione
  5. Passo di Backward Propagation dell’errore ( hidden layer ):
69",esempio esecuzione passo backward propagation dellerrore hidden layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#69,69,"Esempio di Esecuzione
6. Passo di aggiornamento dei pesi ( link in ingresso all’output layer ):
70",esempio esecuzione passo aggiornamento pesi link ingresso alloutput layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#7,7,"Unità di Calcolo nelle Reti Neurali
Usando funzioni diverse come 
 g
 si possono ottenere 
modelli differenti. Ad esempio:
g(in i)=⇢1i f i n i",unit calcolo reti neurali usando funzioni diverse possono ottenere modelli differenti esempio gin ii
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#70,70,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
71",esempio esecuzione passo aggiornamento pesi link ingresso allhidden layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#71,71,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
72",esempio esecuzione passo aggiornamento pesi link ingresso allhidden layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#72,72,"Esempio di Esecuzione
• Ciò completa l’aggiornamento dei pesi per il training example 
corrente.
• Per verificare che l’algoritmo abbia effettivamente ridotto 
l’errore in output, eseguiamo la parte feed-forward ancora una 
volta per confrontare l’uscita attuale con la precedente.
73",esempio esecuzione ci completa laggiornamento pesi training example corrente verificare lalgoritmo effettivamente ridotto lerrore output eseguiamo parte feed forward ancora volta confrontare luscita attuale precedente
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#73,73,"Esempio di Esecuzione
• Nuovo  Passo Feed-Forward ( hidden layer ):
74",esempio esecuzione nuovo passo feed forward hidden layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#74,74,"Esempio di Esecuzione
• Nuovo Passo Feed-Forward ( output layer ):
75",esempio esecuzione nuovo passo feed forward output layer
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#75,75,"Esempio di Esecuzione
• Il nuovo quadrato dell’errore è il seguente:
• La differenza con il vecchio valore è:
76",esempio esecuzione nuovo quadrato dellerrore seguente differenza vecchio valore
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#76,76,"Esempio di Esecuzione
• L’esecuzione dell’algoritmo di Backpropagation che abbiamo 
visto è relativo ad un solo passaggio per un solo esempio di 
addestramento.  
• Si ricorda che l’algoritmo completo fa passare gli esempi di 
addestramento attraverso la rete uno per volta, modificando 
leggermente i pesi a ogni iterazione per ridurre l’errore.  
  
• Ogni ciclo attraverso tutti gli esempi prende il nome di epoca .  
• Le epoche sono ripetute fino a quando non viene soddisfatto un 
criterio di terminazione (in genere, quando le modifiche ai pesi 
sono diventate molto piccole).  
77",esempio esecuzione lesecuzione dellalgoritmo backpropagation visto relativo solo passaggio solo esempio addestramento ricorda lalgoritmo completo passare esempi addestramento attraverso rete volta modificando leggermente pesi ogni iterazione ridurre lerrore ogni ciclo attraverso esempi prende nome epoca epoche ripetute fino quando viene soddisfatto criterio terminazione genere quando modifiche pesi diventate molto piccole
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#77,77,"Sintesi degli Argomenti 
Trattati nella Lezione 
Una Rete Neurale è un modello computazionale che presenta alcune proprietà del cervello: consiste di molte 
unità semplici che lavorano in parallelo senza alcun controllo centralizzato.  Le connessioni tra le unità hanno 
pesi numerici che possono essere modiﬁcati dall’elemento di apprendimento.  
Il comportamento di una rete neurale è determinato dalla topologia delle connessioni e dalla natura delle 
singole unità. Le reti alimentate in avanti  in cui le connessioni formano un grafo diretto aciclico, sono le più 
semplici da analizzare. Le reti alimentate in avanti implementano funzioni senza stato. 
Un percettrone è una rete alimentata in avanti con un singolo strato di unità e può rappresentare solo funzioni 
linearmente separabili . Se i dati sono linearmente separabili si può utilizzare la regola di apprendimento del 
percettrone  per modiﬁcare i pesi della rete in modo da farli corrispondere esattamente ai dati. 
Le reti alimentate in avanti multistrato possono rappresentare qualsiasi funzione, dato un sufﬁciente numero di 
unità. 
L’algoritmo di apprendimento backpropagation (propagazione all’indietro ) funziona su reti multistrato 
alimentate in avanti effettuando una discesa del gradiente nello spazio dei pesi per minimizzare l’errore in 
uscita. Esso converge a una soluzione localmente ottima ed è stato usato con successo in un’ampia varietà di 
applicazioni. La sua convergenza è spesso molto lenta.
78",sintesi argomenti trattati lezione rete neurale modello computazionale presenta alcune propriet cervello consiste molte unit semplici lavorano parallelo senza alcun controllo centralizzato connessioni unit pesi numerici possono essere modicati dallelemento apprendimento comportamento rete neurale determinato topologia connessioni natura singole unit reti alimentate avanti connessioni formano grafo diretto aciclico semplici analizzare reti alimentate avanti implementano funzioni senza stato percettrone rete alimentata avanti singolo strato unit pu rappresentare solo funzioni linearmente separabili dati linearmente separabili pu utilizzare regola apprendimento percettrone modicare pesi rete modo farli corrispondere esattamente dati reti alimentate avanti multistrato possono rappresentare qualsiasi funzione dato sufciente numero unit lalgoritmo apprendimento backpropagation propagazione allindietro funziona reti multistrato alimentate avanti effettuando discesa gradiente spazio pesi minimizzare lerrore uscita esso converge soluzione localmente ottima stato usato successo unampia variet applicazioni convergenza spesso molto lenta
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#8,8,"Funzione Gradino
g
t0g(in i)=⇢1i f i n i",funzione gradino tgin ii
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#9,9,"Sigmoide
g
01g(in i)=1
1+e",sigmoide gin
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 11)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione reti neurali
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Richiami percettrone e MLP 
Sci-kit learn e percettrone 
MLP e regressione 
MLP e classiﬁcazione 
Keras 
Esempio fashion_mnist 
Keras: Sequential models, parametri, metriche, training, predizione",sommario richiami percettrone sci kit learn percettrone regressione classicazione keras esempio fashionmnist keras sequential models parametri metriche training predizione
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Richiami: Multi-Layer Perceptron (MLP)
Perché è fondamentale inserire una funzione di attivazione? 
Se combiniamo diversi layer e unità otteniamo semplicemente una 
sequenza di combinazioni lineari, perciò una trasformazione lineare 
input-output. È come ottenere un singolo layer. Non possiamo 
rappresentare funzioni complesse non lineari.
11",richiami multi layer perceptron fondamentale inserire funzione attivazione combiniamo diversi layer unit otteniamo semplicemente sequenza combinazioni lineari perci trasformazione lineare input output ottenere singolo layer possiamo rappresentare funzioni complesse lineari
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché nella MLP si preferisce la funzione logistica (o sigmoide) 
alla funzione gradino (o step function)?
12g(in i)=⇢1i f i n i",richiami multi layer perceptron domanda preferisce funzione logistica sigmoide funzione gradino step function gin ii
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Richiami: Multi-Layer Perceptron (MLP)
Perché nella MLP si preferisce la funzione logistica (o sigmoide) alla 
funzione gradino (o step function)? 
Con la funzione gradino i gradienti genererebbero una superﬁcie piatta, 
che non permetterebbe di adattare i parametri. 
La funzione logistica è deﬁnita ed ha derivata ovunque.  
La ReLU non è differenziabile per 
 in=0
, e ha derivata 0 per 
 in<0
. Ma 
empiricamente mostra buone performance ed è rapido il calcolo della 
derivata. Inoltre non avendo un valore max in output riduce alcune 
problematiche nelle architetture più complesse.
13
",richiami multi layer perceptron preferisce funzione logistica sigmoide funzione gradino step function funzione gradino gradienti genererebbero supercie piatta permetterebbe adattare parametri funzione logistica denita derivata ovunque differenziabile derivata empiricamente mostra buone performance rapido calcolo derivata inoltre valore max output riduce alcune problematiche architetture complesse
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"MLP e regressione
Una MLP può essere usata per produrre un singolo valore, es. creando un 
layer di output con una singola unità. Nel caso di 
 multivariate regression
 , il 
layer può contenere più unità. 
Solitamente non si inserisce la funzione di attivazione in output in modo da 
non imporre intervalli. Se c'è bisogno di valori positivi si può inserire una 
ReLU
  o una 
 softplus activation function
  (una versione smooth della ReLU). 
La loss function usata durante il training è la 
 mean squared error
 . Nel caso 
di molti outlier nel training set è possibile considerare anche la 
 mean 
absolute error
 . La Huber loss è una combinazione di entrambe.
14",regressione pu essere usata produrre singolo valore creando layer output singola unit caso multivariate regression layer pu contenere unit solitamente inserisce funzione attivazione output modo imporre intervalli bisogno valori positivi pu inserire softplus activation function una versione smooth loss function usata durante training mean squared error caso molti outlier training set possibile considerare mean absolute error huber loss combinazione entrambe
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"MLP e regressione: architettura tipica
Conﬁgurazione tipica degli iperparametri di una MLP usata per la 
regressione:
15
",regressione architettura tipica congurazione tipica iperparametri usata regressione
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"MLP e classiﬁcazione
Inserendo un layer con una singola unità e con funzione di attivazione 
logistica possiamo stimare la probabilità di appartenenza dell'input a una 
certa classe (binary classiﬁcation). Nel caso 
 multilabel binary classiﬁcation
 , 
(es. email spam/no_spam, urgent/no_urgent) si avranno più unità di output. 
Se una istanza può appartenere ad una di n possibili classi (es. una cifra da 
0 a 9), l'output layer conterrà n unità con una funzione 
 softmax
  che 
garantisce che ogni unità produca una probabilità la cui somma sia 1. In 
questo caso si impiega la 
 cross-entropy
  come funzione di loss. 
16
",classicazione inserendo layer singola unit funzione attivazione logistica possiamo stimare probabilit appartenenza dellinput certa classe binary classication caso multilabel binary classication email spamnospam unit output istanza pu appartenere possibili classi cifra loutput layer conterr unit funzione softmax garantisce ogni unit produca probabilit somma caso impiega cross entropy funzione loss
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"Keras
Keras (
 https://keras.io
 ) 
sono API per il Deep Learning ad alto livello per 
costruire ed addestrare architetture di reti neurali. 
Si basa a sua volta su librerie che permettono di eseguire le reti su varie 
piattaforme, es. TensorFlow, Microsoft Cognitive Toolkit (CNTK), Theano; 
Apache MXNet, Apple’s Core ML, Javascript o Typescript (Keras code in 
web browsers), or PlaidML (on GPUs). 
TensorFlow integra Keras e lo arricchisce di altre funzionalità (es. 
TensorFlow’s Data API) 
Installazione (via PIP):  
python3 -m pip install --upgrade tensorﬂow
17",keras keras deep learning alto livello costruire addestrare architetture reti neurali basa volta librerie permettono eseguire reti varie piattaforme tensor flow microsoft cognitive toolkit theano apache xnet apples core javascript typescript keras code web browsers plaid pus tensor flow integra keras arricchisce altre funzionalit tensor flows data installazione via python pip install upgrade tensorow
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Keras: esempio 
 fashion_mnist
Entrambe le versioni corrispondono alla 2.8.0 
import
 tensorflow 
 as
 tf
from
 tensorflow 
 import
 keras
print
(tf.__version__)
print
(keras.__version__)
Impieghiamo il dataset fashion_mnist: 
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
print
(X_train_full.shape)
print
(X_train_full.dtype)
>> (60000, 28, 28)
>> uint8
X_valid, X_train = X_train_full[:
 5000
] / 
255.0
, X_train_full[
 5000
:] / 
255.0
y_valid, y_train = y_train_full[:
 5000
], y_train_full[
 5000
:]
class_names = [
 ""T-shirt/top""
 , 
""Trouser""
 , 
""Pullover""
 , 
""Dress""
, 
""Coat""
,
""Sandal""
 , 
""Shirt""
, 
""Sneaker""
 , 
""Bag""
, 
""Ankle boot""
 ]
print
(class_names[y_train[
 0
]])
>> 
'Coat'
18",keras esempio fashionmnist entrambe versioni corrispondono import tensorflow tensorflow import keras print print impieghiamo dataset fashionmnist fashionmnist xtrainfull ytrainfull xtest ytest print print uint xvalid xtrain xtrainfull xtrainfull yvalid ytrain ytrainfull ytrainfull classnames shirttop trouser pullover dress coat sandal shirt sneaker bag ankle boot print coat
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Keras: sequential models
Il modello 
 Sequential
  è il più semplice e consiste in una singolo stack di 
layers connessi sequenzialmente: 
model = keras.models.Sequential()
# converto le istanze in input in array 1D
# equivale a una operazione: X.reshape(-1,1)
# è obbligatorio specificare il input_shape
model.add(keras.layers.Flatten(input_shape=[
 28
, 
28
]))
# layer denso con 300 unità e ReLU come activation function
# ogni layer contiene i propri parametri (pesi e bias) riferiti alle 
connessioni
# con il layer precedente
model.add(keras.layers.Dense(
 300
, activation=
 ""relu""
))
# layer denso di 100 unità
model.add(keras.layers.Dense(
 100
, activation=
 ""relu""
))
# layer di output con 10 unità (una per classe) e softmax activation function
model.add(keras.layers.Dense(
 10
, activation=
 ""softmax""
 ))
19",keras sequential models modello sequential semplice consiste singolo stack layers connessi model converto istanze input array equivale operazione xreshape obbligatorio specificare inputshape layer denso unit activation function ogni layer contiene propri parametri pesi bias riferiti connessioni layer precedente activation relu layer denso unit activation relu layer output unit una classe softmax activation function activation softmax
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Keras: sequential models
In alternativa, invece di creare un layer alla volta, possiamo passare una 
lista al costruttore:  
model = keras.models.Sequential([
keras.layers.Flatten(input_shape=[
 28
, 
28
]),
keras.layers.Dense(
 300
, activation=
 ""relu""
),
keras.layers.Dense(
 100
, activation=
 ""relu""
),
keras.layers.Dense(
 10
, activation=
 ""softmax""
 )
])
Sono possibile varie forme di import, tutte equivalenti: 
from 
keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow.keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow 
 import 
keras
output_layer 
 = 
keras
.
layers
.
Dense
(
10
)
20",keras sequential models alternativa invece creare layer volta possiamo passare lista costruttore model activation relu activation relu activation softmax possibile varie forme import tutte equivalenti keraslayers import dense outputlayer dense import dense outputlayer dense tensorflow import keras outputlayer keras layers dense
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Richiami: Percettrone
Una delle architetture più semplici, dove un singolo layer è connesso con 
tutti gli input dello strato precedente (
 fully connected 
 o
 dense layer
 ), cioè 
l'
input layer
 : 
Nota
 : nei precedenti lucidi si è usata la notazione dove gli input 
 x
 sono 
anche indicati con la lettera 
 a
. La step function 
 step()
  corrisponde alla 
funzione di attivazione 
 g(in).
3
",richiami percettrone architetture semplici singolo layer connesso input strato precedente fully connected dense layer cio input layer nota precedenti lucidi usata notazione input indicati lettera step function step corrisponde funzione attivazione gin
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Keras: parametri
Per monitorare l'architettura creata usiamo la funzione summary():  
model
.
summary()
Nota: i layer densi contengono molti parametri (es. 235.500!)
21
",keras parametri monitorare larchitettura creata usiamo funzione summary model summary nota layer densi contengono molti parametri
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Keras: parametri
Per accedere ai singoli layers usiamo il parametro 
 layers
 , e le funzioni 
get_weights
 () e 
set_weights
 (): 
>>> 
model
.
layers
[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,
<tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,
<tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,
<tensorflow.python.keras.layers.core.Dense at 0x13240d240>]
>>> 
model
.
layers
[
1
]
.
name
'dense_3'
>>> 
model
.
get_layer
 (
'dense_3'
 )
.
name
'dense_3'
>>> 
weights
, 
biases 
= 
hidden1
.
get_weights
 ()
>>> 
weights
array([[ 0.03854964, -0.04054524, 0.00599282, ..., 0.02566582,
0.01032123, 0.06914985],
...,
[ 0.02632413, -0.05105981, -0.00332005, ..., 0.04175945,
0.0443138 , -0.05558084]], dtype=float32)
>>> 
weights
.
shape
(784, 300)
>>> 
biases
array([0., 0., 0., 0., 0., 0., 0., 0., 0., ..., 0., 0., 0.], dtype=float32)
>>> 
biases
.
shape
(300,)
22",keras parametri accedere singoli layers usiamo parametro layers funzioni getweights setweights model layers xbad model layers name dense model getlayer dense name dense weights biases hidden getweights weights array dtypefloat weights shape biases array dtypefloat biases shape
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Keras: parametri
A cosa può servire una funzione set_weights()?
23",keras parametri cosa pu servire funzione setweights
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Keras: parametri
A cosa può servire una funzione set_weights()? 
Possiamo operare regolarizzazioni manuali, oppure sovrascrivere i 
valori iniziali random con valori ottenuti da precedenti fasi di training. 
Per impiegare altri criteri di inizializzazione dei kernel (cioè delle matrici 
dei parametri della rete) consultare 
 https://keras.io/initializers/
24",keras parametri cosa pu servire funzione setweights possiamo operare manuali oppure sovrascrivere valori iniziali random valori ottenuti precedenti fasi training impiegare altri criteri kernel cio matrici parametri rete consultare
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Keras: metriche
La funzione compile() prende in input la 
 loss 
function
  e il 
optimizer
 , cioè 
l'algoritmo per stimare i parametri, ed eventuali altri parametri, come la 
metrica per stimare l'errore:  
model
.
compile
(
loss
=
""sparse_categorical_crossentropy""
 ,
optimizer
 =
""sgd""
,
metrics
=
[
""accuracy""
 ])
Dove:  
loss=""sparse_categorical_crossentropy"" è equivalente a  
loss=keras.losses.sparse_categorical_crossentropy.  
optimizer=""sgd"" è equivalente a optimizer=keras.optimizers.SGD()  
metrics=[""accuracy""] è equivalente a 
metrics=[keras.metrics.sparse_categorical_accuracy]  
Per una lista completa consultare 
 https://keras.io/losses/  
https://keras.io/
optimizers/
   e  
https://keras.io/metrics/  
25",keras metriche funzione compile prende input loss function optimizer cio lalgoritmo stimare parametri eventuali altri parametri metrica stimare lerrore model compile loss optimizer sgd metrics accuracy dove equivalente optimizersgd equivalente equivalente lista completa consultare optimizers
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"Keras: metriche
Nell'esempio impieghiamo 
 sparse_categorical_crossentropy
  loss perché 
abbiamo label sparse, cioè per ogni istanza abbiamo solo una target class 
da 0 a 9, e ogni classe è esclusiva.  
Se avessimo avuto un target on vettore di 10 reali, es [0,0,...,1.0,...,0] 
avremmo dovuto impiegare la 
 categorical_crossentropy 
 loss. Per convertire 
label sparse in vettori impiegare 
 keras.utils.to_categorical()
 . 
Per la binary classiﬁcation avremmo usato la 
 sigmoid
  activation invece 
della softmax, e la 
 binary_crossentropy
  loss.
26",keras metriche nellesempio impieghiamo loss label sparse cio ogni istanza solo target class ogni classe esclusiva target vettore reali dovuto impiegare loss convertire label sparse vettori impiegare binary classication usato sigmoid activation invece softmax loss
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Keras: training
Inﬁne non ci resta che addestrare il modello: 
# il validation set è opzionale
>>> 
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
... 
validation_data
 =
(
X_valid
, 
y_valid
))
...
Train on 55000 samples, validate on 5000 samples
Epoch 1/30
55000/55000 [==========] - 3s 55us/sample - loss: 1.4948 - acc: 0.5757
- val_loss: 1.0042 - val_acc: 0.7166
Epoch 2/30
55000/55000 [==========] - 3s 55us/sample - loss: 0.8690 - acc: 0.7318
- val_loss: 0.7549 - val_acc: 0.7616
[...]
Epoch 50/50
55000/55000 [==========] - 4s 72us/sample - loss: 0.3607 - acc: 0.8752
- val_loss: 0.3706 - val_acc: 0.8728
Otteniamo una accuracy del 87% sul validation set dopo 50 epoche, simile 
all'accuracy del training set, perciò non dovrebbe esserci overﬁtting. 
27",keras training inne resta addestrare modello validation set opzionale history model fit xtrain ytrain epochs validationdata xvalid yvalid train samples validate samples epoch ussample loss acc valloss valacc epoch ussample loss acc valloss valacc epoch ussample loss acc valloss valacc otteniamo accuracy validation set dopo epoche simile allaccuracy training set perci dovrebbe esserci overtting
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Keras: training
Sel nel dataset ci sono classi meno frequenti di altre, si può impiegare il 
parametro 
 class_weight
  nella funzione 
 ﬁt
() in modo da diminuire l'effetto 
delle classi più rappresentate.  
Si può fare lo stesso ma per le singole istanze col parametro 
 sample_weight 
Il parametro 
 history
  è creato dopo il ﬁt, e contiene un oggetto 
 History
  con 
dati utili relativi all'addestramento: 
import 
pandas 
as 
pd
pd
.
DataFrame
 (
history
.
history
)
.
     
plot
(
figsize
=
(
8
, 
5
))
plt
.
grid
(
True
)
# set the vertical range to [0-1]
plt
.
gca
()
.
set_ylim
 (
0
, 
1
) 
plt
.
show
()
Cosa puoi dire dal graﬁco?
28
",keras training sel dataset classi meno frequenti altre pu impiegare parametro classweight funzione modo diminuire leffetto classi rappresentate pu fare stesso singole istanze parametro sampleweight parametro history creato dopo contiene oggetto history dati utili relativi import pandas data frame history history plot figsize plt grid true set vertical range plt gca setylim plt show cosa puoi dire graco
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Keras: training
Conferma il probabile scarso overﬁtting.  
Al principio il modello si comporta meglio col validation set, ma spesso è 
dovuto al caso. 
Il ﬁtting termina con l'accuracy sul training leggermente migliori rispetto al 
validation, fenomeno che capita spesso per training lunghi. 
Il validation error è ancora in discesa quando termina il training. Conviene 
aumentare le epoche.
29
",keras training conferma probabile scarso overtting principio modello comporta meglio validation set spesso dovuto caso tting termina laccuracy training leggermente migliori rispetto validation fenomeno capita spesso training lunghi validation error ancora discesa quando termina training conviene aumentare epoche
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#29,29,"Keras: training e test
Una volta terminato il training è possibile validare il modello sul test set: 
>>> 
model
.
evaluate
 (
X_test
, 
y_test
)
8832/10000 [==========================] - ETA: 0s - loss: 0.4074 - acc: 
0.8540
[0.40738476498126985, 0.854]
Le performance sono leggermente minori poiché gli iperparametri li 
abbiamo scelti in base al training e validation set. 
Ricordati di non modiﬁcarli in base al test set.
30",keras training test volta terminato training possibile validare modello test set model evaluate xtest ytest loss acc performance leggermente minori poich iperparametri scelti base training validation set ricordati modicarli base test set
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Richiami: Percettrone
Un singolo percettrone, indicato anche con Threshold logic unit (TLU) o 
Linear threshold unit (LTU), può essere usato come classiﬁcatore.  
Se la combinazione lineare degli input è oltre una certa soglia l'output 
assumerà la classe ""positiva"", altrimenti ""negativa"". 
Il training consiste nel trovare i pesi 
 w
 (parametri). 
Una rappresentazione alternativa indica esplicitamente un layer 
passthtough
  per i valori in input, e una unità 
 bias
 che restituisce sempre 1. 
Nell'esempio ci sono 3 outputs, perciò 3 distinte classi binarie in output: 
4
",richiami percettrone singolo percettrone indicato threshold logic unit linear threshold unit pu essere usato classicatore combinazione lineare input oltre certa soglia loutput assumer classe positiva altrimenti negativa training consiste trovare pesi parametri alternativa indica esplicitamente layer passthtough valori input unit bias restituisce sempre nellesempio outputs perci distinte classi binarie output
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#30,30,"Keras: predizione
Una volta addestrato possiamo fare predizione: 
>>> 
X_new 
= 
X_test
[:
3
]
>>> 
y_proba 
 = 
model
.
predict
(
X_new
)
>>> 
y_proba
.
round
(
2
)
array([[0. , 0. , 0. , 0. , 0. , 0.09, 0. , 0.12, 0. , 0.79],
[0. , 0. , 0.94, 0. , 0.02, 0. , 0.04, 0. , 0. , 0. ],
[0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]],
dtype=float32)
Dall'esempio: class 9 (ankle boot) prob=79%, class 7 (sneaker) prob=12%, 
class 5 (sandal) prob=9% 
Se ci interessa solo la classe con probabilità più alta: 
>>> 
y_pred 
= 
model
.
predict_classes
 (
X_new
)
>>> 
y_pred
array([9, 2, 1])
>>> 
np
.
array
(
class_names
 )[
y_pred
]
array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')
31",keras predizione volta addestrato possiamo fare predizione xnew xtest yproba model predict xnew yproba round array dtypefloat dallesempio class ankle boot prob class sneaker prob class sandal prob interessa solo classe probabilit alta ypred model predictclasses xnew ypred array array classnames ypred arrayankle boot pullover trouser dtypeu
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#31,31,"Esercizio
Impiegare il dataset MNIST (cifre numeriche) e una architettura simile 
all'esempio precedente.  
Valutare l'accuracy dopo 50 epoche. 
# import dataset
from
 keras.datasets 
 import
 mnist
# load dataset
(x_train, y_train),(x_test, y_test) 
 =
 mnist
.
load_data()
32
",esercizio impiegare dataset cifre numeriche architettura simile allesempio precedente valutare laccuracy dopo epoche import dataset kerasdatasets import mnist load dataset xtrain ytest mnist loaddata
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#32,32,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
33",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Sci-kit learn: Perceptron
La classe Perceptron implementa un singolo TLU: 
import 
numpy 
as 
np
from 
sklearn.datasets 
 import 
load_iris
from 
sklearn.linear_model 
 import 
Perceptron
iris 
= 
load_iris
 ()
X 
= 
iris
.
data
[:, (
2
, 
3
)] 
# petal length, petal width
y 
= 
(
iris
.
target 
== 
0
)
.
astype
(
np
.
int
) 
# Iris Setosa?
per_clf 
 = 
Perceptron
 ()
per_clf
.
fit
(
X
, 
y
)
y_pred 
= 
per_clf
.
predict
([[
2
, 
0.5
]])
La classe Perceptron implementa un singolo TLU.  
L'apprendimento è basato sull'algoritmo Stochastic Gradient Descent, cioè 
sulla classe SGDClassiﬁer con i seguenti parametri: 
 loss
=""perceptron"", 
learning_rate
 =""constant"", 
 eta0
=1 (
learning rate
 ), and 
 penalty
 =None 
(
nessuna regolarizzazione
 ). Per ogni istanza in input i pesi sono aggiornati 
in base all'errore prodotto.
5",sci kit learn perceptron classe perceptron implementa singolo import numpy import loadiris import perceptron iris loadiris iris data petal length petal width iris target astype int iris setosa perclf perceptron perclf fit ypred perclf predict classe perceptron implementa singolo lapprendimento basato sullalgoritmo stochastic gradient descent cio classe classier seguenti parametri loss perceptron learningrate constant eta learning rate penalty none nessuna ogni istanza input pesi aggiornati base allerrore prodotto
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Richiami: Multi-Layer Perceptron (MLP)
Al contrario della classiﬁcazione basata sulla logistic regression, il 
percettrone non produce probabilità, ma effettua predizioni in base ad una 
soglia preﬁssata. Per tale motivo si preferisce la logistic regression. 
Per stimare funzioni anche non lineare, si possono ""impilare"" più TLU 
raggruppati in singoli layer creando architetture 
 deep
 . Il ﬂusso dei segnali è 
monodirezionale (
 feedforward
 ).
6
",richiami multi layer perceptron contrario classicazione basata logistic regression percettrone produce probabilit effettua predizioni base soglia pressata tale motivo preferisce logistic regression stimare funzioni lineare possono impilare raggruppati singoli layer creando architetture deep usso segnali monodirezionale feedforward
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Richiami: Multi-Layer Perceptron (MLP)
L'algoritmo per stimare i pesi è 
 backpropagation
  training algorithm ed è 
basato sul calcolo dei gradienti degli errori rispetto ad ogni singolo 
parametro (
 automatic differentation
  o 
autodiff
 ).  
In particolare viene impiegato il 
 reverse-mode autodiff
 , adatto quando ci 
sono molte connessioni (pesi) e pochi output. 
In sintesi si analizzano 
 mini-batch
  di istanze estratte dal training set (es. 32). 
Alla ﬁne di una 
 epoca
  si è analizzato l'intero dataset. Il processo itera ﬁno 
alla convergenza. 
Il mini-batch viene dato in input alla rete e per ogni istanza viene ricavato 
l'output (
 forward pass
 ).  
Per mezzo della loss function è ricavato l'errore commesso dalla rete. 
La 
chain rule
  determina quanto ogni output contribuisce all'errore. Il 
processo è ripetuto anche per i layer precedenti, ﬁno all'input (
 reverse pass
 ). 
Inﬁne il 
 gradient descent
  impiega tali error gradients per aggiornare i pesi.
7",richiami multi layer perceptron lalgoritmo stimare pesi backpropagation training algorithm basato calcolo gradienti errori rispetto ogni singolo parametro automatic differentation autodiff particolare viene impiegato reverse mode autodiff adatto quando molte connessioni pesi pochi output sintesi analizzano mini batch istanze estratte training set ne epoca analizzato lintero dataset processo itera no convergenza mini batch viene dato input rete ogni istanza viene ricavato loutput forward pass mezzo loss function ricavato lerrore commesso rete chain rule determina ogni output contribuisce allerrore processo ripetuto layer precedenti no allinput reverse pass inne gradient descent impiega tali error gradients aggiornare pesi
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: L'inizializzazione dei pesi deve essere random. Se tutti i pesi e 
bias fossero impostati a 0 cosa accadrebbe?
8",richiami multi layer perceptron domanda pesi deve essere random pesi bias impostati cosa accadrebbe
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Richiami: Multi-Layer Perceptron (MLP)
L'inizializzazione dei pesi deve essere random. Se tutti i pesi e bias fossero 
impostati a 0 cosa accadrebbe? 
Tutte le unità di un layer si comporterebbero nello stesso modo.  
Il backpropagation inﬂuenzerebbe tutte le unità allo stesso modo. 
Potremmo avere 100ia di unità per layer, ma è come se ne avessimo 
una sola. 
L'assegnazione casuale dei pesi evita la simmetria e, il backpropagation 
""addestra"" gruppi di unità in modo diverso.
9",richiami multi layer perceptron pesi deve essere random pesi bias impostati cosa accadrebbe tutte unit layer comporterebbero stesso modo backpropagation inuenzerebbe tutte unit stesso modo potremmo avere unit layer sola lassegnazione casuale pesi evita simmetria backpropagation addestra gruppi unit modo diverso
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché è fondamentale inserire una funzione di attivazione?
10",richiami multi layer perceptron domanda fondamentale inserire funzione attivazione
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 12)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione reti neurali
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Architetture non sequenziali e Keras 
Output multipli 
Keras: Modelli statici e dinamici  
Save & Restore 
Callbacks 
Early stopping 
TensorBoard 
Fine tuning degli iperparametri 
Numero hidden layers, numero nodi per layers 
TensorFlow playground",sommario architetture sequenziali keras output multipli keras modelli statici dinamici save restore callbacks early stopping tensor board fine tuning iperparametri numero hidden layers numero nodi layers tensor flow playground
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Keras: Modelli dinamici
Si crea una subclass di 
 Model
 , nel costruttore si deﬁnisce il modello (cioè i 
layers) e nella funzione 
 call()
  si deﬁnisce come saranno elaborati i dati, e 
può comprendere loop, istruzioni if-else, etc. 
Per esempio, per il Wide & deep model: 
class 
WideAndDeepModel
 (
keras
.
models
.
Model
):
def 
__init__
 (
self
, 
units
=
30
, 
activation
 =
""relu""
, 
**
kwargs
):
super
()
.
__init__
 (
**
kwargs
) 
# standard args (e.g., name)
self
.
hidden1 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
hidden2 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
main_output 
 = 
keras
.
layers
.
Dense
(
1
)
self
.
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)
def 
call
(
self
, 
inputs
):
input_A
, 
input_B 
 = 
inputs
hidden1 
 = 
self
.
hidden1
(
input_B
)
hidden2 
 = 
self
.
hidden2
(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
main_output 
 = 
self
.
main_output
 (
concat
)
aux_output 
 = 
self
.
aux_output
 (
hidden2
)
return 
main_output
 , 
aux_output
model 
= 
WideAndDeepModel
 ()
11",keras modelli dinamici crea subclass model costruttore denisce modello cio layers funzione call denisce elaborati dati pu comprendere loop istruzioni else etc esempio wide deep model class wide deep model keras models model def init self units activation relu kwargs super init kwargs standard args name self hidden keras layers dense units activation activation self hidden keras layers dense units activation activation self mainoutput keras layers dense self auxoutput keras layers dense def call self inputs input input inputs hidden self hidden input hidden self hidden hidden concat keras layers concatenate input hidden mainoutput self mainoutput concat auxoutput self auxoutput hidden return mainoutput auxoutput model wide deep model
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Keras: Modelli dinamici
I modelli dinamici hanno lo svantaggio che 
 non
 possono essere facilmente 
ispezionati da Keras, tantomeno essere salvati o clonati. 
Il metodo summary() restituisce una lista di layer ma non come sono 
connessi. 
12",keras modelli dinamici modelli dinamici svantaggio possono essere facilmente ispezionati keras tantomeno essere salvati clonati metodo summary restituisce lista layer connessi
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Keras: Save & Restore
Addestrare i modelli può richiedere molto tempo. È fondamentale poter 
salvare i parametri durante (
 checkpoints
 ) o alla ﬁne dell'addestramento. 
model
.
save
(
""my_keras_model.h5""
 )
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
Il salvataggio interessa i parametri, l'architettura, e gli iperparametri. 
Per il Model subclassing si usano le funzioni save_weights() e 
load_weights(), che interessano però solo i pesi.
13",keras save restore addestrare modelli pu richiedere molto tempo fondamentale poter salvare parametri durante checkpoints ne model save model keras models loadmodel salvataggio interessa parametri larchitettura iperparametri model subclassing usano funzioni saveweights loadweights interessano per solo pesi
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"Keras: callbacks
È possibile deﬁnire una funzione 
 callback
  che verrà invocata al principio e 
alla ﬁne di ogni epoca, o batch. Nell'esempio la funzione 
ModelCheckpoint salva il modello a intervalli regolari (default: alla ﬁne di 
ogni epoca): 
[
...
] 
# dopo la compilazione del modello
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
 (
""my_keras_model.h5""
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
10
, 
callbacks
 =
[
checkpoint_cb
 ])
Se impiego un validation set, posso usare il parametro save_best_only=True 
in ModelCheckpoint per salvare il modello quando le prestazioni sono le 
migliori. Se interrompo e incomincio di nuovo l'addestramento, riparto 
dall'ultimo modello potenzialmente privo di overﬁtting. 
Si può deﬁnire la propria callback agganciandola agli eventi 
on_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_begin(), 
on_batch_end(), on_batch_end()
 , es.: 
class 
PrintValTrainRatioCallback
 (
keras
.
callbacks
 .
Callback
 ):
  
def 
on_epoch_end
 (
self
, 
epoch
, 
logs
):
      
print
(
""\nval/train: {:.2f}""
 .
format
(
logs
[
""val_loss""
 ] 
/ 
logs
[
""loss""
]))
14",keras callbacks possibile denire funzione callback verr invocata principio ne ogni epoca batch nellesempio funzione model checkpoint salva modello intervalli regolari default ne ogni epoca dopo compilazione modello checkpointcb keras callbacks model checkpoint history model fit xtrain ytrain epochs callbacks checkpointcb impiego validation set posso usare parametro model checkpoint salvare modello quando prestazioni migliori interrompo incomincio nuovo riparto dallultimo modello potenzialmente privo overtting pu denire propria callback agganciandola eventi ontrainend onbatchend onbatchend class print val train ratio callback keras callbacks callback def onepochend self epoch logs print nvaltrain format logs valloss logs loss
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"Keras: early stopping
Con la stessa tecnica possiamo interrompere il training se, dopo un certo 
numero di epoche (parametro 
 patience
 ), non ci sono incrementi di 
prestazioni tangibili: 
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
                                    
 (
""my_keras_model.h5""
 ,
save_best_only
 =
True
)
early_stopping_cb 
 = 
keras
.
callbacks
 .
EarlyStopping
                                    
 (
patience
 =
10
, 
restore_best_weights
 =
True
)
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
                    
 validation_data
 =
(
X_valid
, 
y_valid
),
                    
 callbacks
 =
[
checkpoint_cb
 , 
early_stopping_cb
 ]) 
# rollback al best model 
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
15",keras early stopping stessa tecnica possiamo interrompere training dopo certo numero epoche parametro patience incrementi prestazioni tangibili checkpointcb keras callbacks model checkpoint savebestonly true keras callbacks early stopping patience true history model fit xtrain ytrain epochs validationdata xvalid yvalid callbacks checkpointcb rollback best model model keras models loadmodel
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"TensorBoard
Un tool utile per visualizzare l'andamento dell'addestramento. Aggiorna la 
visualizzazione in base a un ﬁle binario chiamato event ﬁle.  
Si possono salvare i dati di ogni training in una directory distinta, così è 
possibile caricarli e confrontarli. Di seguito TensorBoard si occupa di 
creare la directory e salvarci i dati: 
root_logdir 
 = 
os
.
path
.
join
(
os
.
curdir
, 
""my_logs""
 )
def 
get_run_logdir
 ():
import 
time
run_id 
= 
time
.
strftime
 (
""run_
%Y
_
%m
_
%d
-
%H
_
%M
_
%S
""
)
return 
os
.
path
.
join
(
root_logdir
 , 
run_id
)
run_logdir 
 = 
get_run_logdir
 () 
# es. './my_logs/run_2019_01_16-11_28_43'
[
...
] 
# Build and compile your model
tensorboard_cb 
 = 
keras
.
callbacks
 .
TensorBoard
 (
run_logdir
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
                    
 validation_data
 =
(
X_valid
, 
y_valid
), 
                    
 callbacks
 =
[
tensorboard_cb
 ])
16",tensor board tool utile visualizzare landamento aggiorna visualizzazione base le binario chiamato event le possono salvare dati ogni training directory distinta cos possibile caricarli confrontarli seguito tensor board occupa creare directory salvarci dati rootlogdir path join curdir mylogs def getrunlogdir import time runid time strftime run return path join rootlogdir runid runlogdir getrunlogdir build compile model tensorboardcb keras callbacks tensor board runlogdir history model fit xtrain ytrain epochs validationdata xvalid yvalid callbacks tensorboardcb
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"TensorBoard
TensorBoard può funzionare come server in locale: 
$ 
tensorboard --logdir
 =
./my_logs --port
 =
6006
TensorBoard 2.0.0 at http://mycomputer.local:6006 
 (
Press CTRL+C to quit
 )
Per l'interfacciamento con Colab consultare: 
https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/
docs/get_started.ipynb
17
",tensor board tensor board pu funzionare server locale tensorboard logdir mylogs port tensor board press quit colab consultare
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Fine tuning degli iperparametri
Rispetto ad altri modelli le reti neurali hanno numerosi iperparametri da 
deﬁnire. Un approccio spesso usato è quello di esplorare lo spazio delle 
conﬁgurazioni con le classi 
 GridSearchCV
  o 
RandomizedSearchCV.  
Deﬁniamo una funzione che prende in input gli iperparametri da 
ottimizzare:  
def 
build_model
 (
n_hidden
 =
1
, 
n_neurons
 =
30
, 
learning_rate
 =
3e-3
, 
input_shape
 =
[
8
]):
model 
= 
keras
.
models
.
Sequential
 ()
# necessario per far si che il primo layer sia inizializzato correttamente
options 
 = 
{
""input_shape""
 : 
input_shape
 }
for 
layer 
in 
range
(
n_hidden
 ):
model
.
add
(
keras
.
layers
.
Dense
(
n_neurons
 , 
activation
 =
""relu""
, 
**
options
))
options 
 = 
{}
model
.
add
(
keras
.
layers
.
Dense
(
1
, 
**
options
))
optimizer 
 = 
keras
.
optimizers
 .
SGD
(
learning_rate
 )
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
optimizer
 )
return 
model
...
18",fine tuning iperparametri rispetto altri modelli reti neurali numerosi iperparametri denire approccio spesso usato esplorare spazio congurazioni classi grid search randomized search deniamo funzione prende input iperparametri ottimizzare def buildmodel nhidden nneurons learningrate inputshape model keras models sequential necessario far primo layer inizializzato correttamente options inputshape inputshape layer range nhidden model add keras layers dense nneurons activation relu options options model add keras layers dense options optimizer keras optimizers learningrate model compile loss mse optimizer optimizer return model
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Fine tuning degli iperparametri
Dopodiché istanziamo una regressione per Keras; 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default.  
Abbiamo appena creato un modello, e possiamo seguire i soliti step: 
keras_reg
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
              
 validation_data
 =
(
X_valid
, 
y_valid
),
              
 callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)])
mse_test 
 = 
keras_reg
 .
score
(
X_test
, 
y_test
)
y_pred 
= 
keras_reg
 .
predict
(
X_new
)
Qualsiasi parametro aggiuntivo passato a ﬁt() sarà inoltrato al modello 
Keras. 
19",fine tuning iperparametri dopodich istanziamo regressione keras kerasreg keras wrappers scikitlearn keras regressor buildmodel specicando altri parametri buildmodel user default appena creato modello possiamo seguire soliti step kerasreg fit xtrain ytrain epochs validationdata xvalid yvalid callbacks keras callbacks early stopping patience msetest kerasreg score xtest ytest ypred kerasreg predict xnew qualsiasi parametro aggiuntivo passato inoltrato modello keras
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Fine tuning degli iperparametri
Miglioriamo l'esplorazione con un comportamento random, e deﬁnendo 
degli intervallo per i parametri impiegati: 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default. 
Possiamo deﬁnire intervalli da cui campionare casualmente i valori degli 
iperparametri che abbiamo deﬁnito in build_model(): 
from 
scipy.stats 
 import 
reciprocal
from 
sklearn.model_selection 
 import 
RandomizedSearchCV
param_distribs 
 = 
{
""n_hidden""
 : [
0
, 
1
, 
2
, 
3
],
""n_neurons""
 : 
np
.
arange
(
1
, 
100
),
""learning_rate""
 : 
reciprocal
 (
3e-4
, 
3e-2
),
}
# RandomizedSearchCV usa la K-fold cross-validation, ignora X/y_valid
rnd_search_cv 
 = 
RandomizedSearchCV
 (
keras_reg
 , 
param_distribs
 , 
n_iter
=
10
, 
cv
=
3
)
rnd_search_cv
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
,
validation_data
 =
(
X_valid
, 
y_valid
),
callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)]) 
20",fine tuning iperparametri miglioriamo lesplorazione comportamento random denendo intervallo parametri impiegati kerasreg keras wrappers scikitlearn keras regressor buildmodel specicando altri parametri buildmodel user default possiamo denire intervalli campionare casualmente valori iperparametri denito buildmodel scipystats import reciprocal import randomized search paramdistribs nhidden nneurons arange learningrate reciprocal randomized search usa fold cross validation ignora xyvalid rndsearchcv randomized search kerasreg paramdistribs niter rndsearchcv fit xtrain ytrain epochs validationdata xvalid yvalid callbacks keras callbacks early stopping patience
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Architetture non sequenziali: wide & deep
Si possono impiegare architetture più complesse di quelle viste ﬁnora, ad 
esempio quelle non sequenziali. 
Nella 
 wide & deep 
 l'input è connesso direttamente con l'output. Questo 
permette di apprendere sia patterns 
 deep
  (con la pipeline MLP 
tradizionale), sia regole semplici, per mezzo del percorso breve.
3
",architetture sequenziali wide deep possono impiegare architetture complesse viste nora esempio sequenziali wide deep linput connesso direttamente loutput permette apprendere patterns deep con pipeline tradizionale regole semplici mezzo percorso breve
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Fine tuning degli iperparametri
I valori degli iperparametri si ottengono alle variabili: 
>>> 
rnd_search_cv
 .
best_params_
{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}
>>> 
rnd_search_cv
 .
best_score_
-0.3189529188278931
>>> 
model 
= 
rnd_search_cv
 .
best_estimator_
 .
model
Si possono impiegare per validare il modello sul test set. 
Se lo spazio degli iperparametri è molto grande, si parte con una 
esplorazione grossolana degli intervalli, e successivamente si rafﬁna lo 
spazio limitandolo agli intervalli potenzialmente più promettenti. 
21",fine tuning iperparametri valori iperparametri ottengono variabili rndsearchcv bestparams nhidden nneurons rndsearchcv bestscore model rndsearchcv bestestimator model possono impiegare validare modello test set spazio iperparametri molto grande parte esplorazione grossolana intervalli successivamente rafna spazio limitandolo intervalli potenzialmente promettenti
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Fine tuning degli iperparametri
Altre librerie per il tuning degli iperparametri: 
• 
Hyperopt
 : a popular Python library for optimizing over all sorts of complex 
search spaces (including real values such as the learning rate, or discrete values 
such as the number of layers).
• 
Hyperas
 , 
kopt 
 or 
Talos
 : optimizing hyperparameters for Keras model (the ﬁrst 
two are based on Hyperopt).
• 
Scikit-Optimize 
 (skopt): a general-purpose optimization library. The 
BayesSearchCV 
 class performs Bayesian optimization using an interface 
similar to 
Grid
 SearchCV .
• 
Spearmint
 : a Bayesian optimization library.
• 
Sklearn-Deap
 : a hyperparameter optimization library based on evolutionary 
algorithms, also with a 
 GridSearchCV
 -like interface.
22",fine tuning iperparametri altre librerie tuning iperparametri hyperopt popular python library optimizing sorts complex search spaces including real values learning rate discrete values number layers hyperas kopt talos optimizing hyperparameters keras model the rst two based hyperopt scikit optimize skopt general purpose optimization library bayes search class performs bayesian optimization using interface similar grid search spearmint bayesian optimization library sklearn deap hyperparameter optimization library based evolutionary algorithms also grid search like interface
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Numero di hidden layers
Una MLP con 1 hidden layer e un numero sufﬁciente di nodi può 
modellare qualsiasi funzione complessa. Ma le deep networks usano i nodi 
in modo più efﬁcienti, perciò richiedono meno potenza computazionale. 
Gli strati più vicini all'input possono rappresentare forme semplici e relative 
caratteristiche (es. segmenti, orientazioni), i layer intermedi combinano questi 
elementi per forme più complesse (es. quadrati, cerchi), mentre i layer ﬁnali si 
focalizzano sulle forme ad alto livello (es. viso delle persone). 
Inoltre le architetture deep riescono più facilmente a generalizzare a nuovi 
datasets.  
Una parte dei layers di una rete addestrata a riconoscere facce possono essere 
impiegati in una nuova rete per riconoscere tagli di capelli, evitando una scelta 
random dei parametri iniziali (
 transfer learning
 ). 
In generale si parte con pochi hidden layer (1 o 2) per task semplici, 
incrementandoli per task complessi, ﬁnché si raggiunge l'overﬁtting. Per i 
task molto complessi si cercano modelli pre-addestrati da cui partire con 
nuovi addestramenti. 
23",numero hidden layers hidden layer numero sufciente nodi pu modellare qualsiasi funzione complessa deep networks usano nodi modo efcienti perci richiedono meno potenza computazionale strati vicini allinput possono rappresentare forme semplici relative caratteristiche segmenti orientazioni layer intermedi combinano elementi forme complesse quadrati cerchi mentre layer nali focalizzano forme alto livello viso persone inoltre architetture deep riescono facilmente generalizzare nuovi datasets parte layers rete addestrata riconoscere facce possono essere impiegati nuova rete riconoscere tagli capelli evitando scelta random parametri iniziali transfer learning generale parte pochi hidden layer task semplici incrementandoli task complessi nch raggiunge lovertting task molto complessi cercano modelli pre addestrati partire nuovi addestramenti
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Numero di nodi per layers
Il numero di nodi per l'input layer è determinato dalle istanze in entrata. 
I restanti layer tipicamente formano una piramide, dove i nodi si riducono 
all'avvicinarsi del layer di output. L'idea è che gli ultimi layer 
rappresentano poche e salienti features ad alto livello. 
Ma sperimentazioni più recenti suggeriscono di mantenere costante il 
numero di nodi per layer, ottenendo un singolo iperparametro da 
ottimizzare. 
Anche per il numero di nodi si può partire da un numero basso e 
incrementarlo ﬁno a quando può comparire l'overﬁtting.
24",numero nodi layers numero nodi linput layer determinato istanze entrata restanti layer tipicamente formano piramide nodi riducono allavvicinarsi layer output lidea ultimi layer rappresentano poche salienti features alto livello sperimentazioni recenti suggeriscono mantenere costante numero nodi layer ottenendo singolo iperparametro ottimizzare numero nodi pu partire numero basso incrementarlo no quando pu comparire lovertting
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Altri iperparametri
Learning rate: il valore ottimale è solitamente la metà di quello massimo, 
cioè quello che genera divergenza nell'algoritmo di training.  
Si parte da un valore alto, dove si ha sicura divergenza, e poi si divide 
per 3 e si ripete ﬁno a quando la divergenza scompare. 
Batch size: inﬂuisce sia sulle performance che su tempo di addestramento. 
Solitamente inferiore a 32. Un valore basso garantisce una iterazione di 
training veloce. Un valore alto più precisione nella stima dei gradienti. 
Per altre raccomandazioni:  
Practical recommendations for gradient-based training of deep 
architectures   
 https://arxiv.org/abs/1206.5533  
25",altri iperparametri learning rate valore ottimale solitamente met massimo cio genera divergenza nellalgoritmo training parte valore alto sicura divergenza poi divide ripete no quando divergenza scompare batch size inuisce performance tempo addestramento solitamente inferiore valore basso garantisce iterazione training veloce valore alto precisione stima gradienti altre practical recommendations gradient based training deep architectures
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"TensorFlow Playground
Tool interattivo per sperimentare reti neurali 
https://playground.tensorﬂow.org/   
26
",tensor flow playground tool interattivo sperimentare reti neurali
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Esercitazione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, 
cosa puoi constatare?  
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. 
Addestrala varie volte, cosa noti? 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
Aumenta i nodi a 8. Riprova. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 
8 nodi. Cosa noti?
27",esercitazione addestra rete default analizza patterns riconosciuti vari layers cosa puoi constatare rimpiazza tanh cosa cambia modica larchitettura rendila solo hidden layer neuroni addestrala varie volte cosa noti rimuovi nodo rimagono riprova cosa noti aumenta nodi riprova usa dataset spirale architettura hidden layers ognuno nodi cosa noti
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Esercitazione - soluzione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, cosa puoi constatare?  
Gli strati più vicini all'output sono più complessi. 
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Si accelera il training, ma ora i boundaries sono lineari. 
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. Addestrala varie volte, cosa noti? 
I tempi di apprendimento variano molto e spesso ci si blocca in minimi locali. 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
La rete non trova soluzioni buone. Troppi pochi parametri generano underﬁtting. 
Aumenta i nodi a 8. Riprova. 
Più veloce, e non ferma più come nel caso precedente. Reti più complesse hanno più chance di 
trovare soluzioni ottime o tendenti all'ottimo, anche se possono comunque rimanere ""bloccate"" su 
plateaus. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 8 nodi. Cosa noti? 
Training time più lungo, spesso rallentanti da plateaus. I nodi nei layer verso l'output si aggiornano 
più velocemente degli altri. È il 
 vanishing gradinets
  problem. Si può risolvere con una 
inizializzazione più accurata dei pesi, altri ottimizzatori (es. AdaGrad e Adam) e con la Batch 
normalization.
28",esercitazione soluzione addestra rete default analizza patterns riconosciuti vari layers cosa puoi constatare strati vicini alloutput complessi rimpiazza tanh cosa cambia accelera training ora boundaries lineari modica larchitettura rendila solo hidden layer neuroni addestrala varie volte cosa noti tempi apprendimento variano molto spesso blocca minimi locali rimuovi nodo rimagono riprova cosa noti rete trova soluzioni buone troppi pochi parametri generano undertting aumenta nodi riprova veloce ferma caso precedente reti complesse chance trovare soluzioni ottime tendenti allottimo possono comunque rimanere bloccate plateaus usa dataset spirale architettura hidden layers ognuno nodi cosa noti training time lungo spesso rallentanti plateaus nodi layer verso loutput aggiornano velocemente altri vanishing gradinets problem pu risolvere accurata pesi altri ottimizzatori ada grad adam batch normalization
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
29",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Architetture non sequenziali e Keras
Impieghiamo le 
 functional API
  di Keras.  
Quando creiamo un layer possiamo passargli un parametro aggiuntivo che 
corrisponde all'input del layer, es: 
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
Il layer 
 Concatenate
  permette di concatenare e creare un input composito 
per un certo layer. 
input 
= 
keras
.
layers
.
Input
(
shape
=
X_train
.
shape
[
1
:])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
Concatenate
 ()[
input
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input
], 
outputs
=
[
output
])
4",architetture sequenziali keras impieghiamo functional keras quando creiamo layer possiamo passargli parametro aggiuntivo corrisponde allinput layer hidden keras layers dense activation relu input layer concatenate permette concatenare creare input composito certo layer input keras layers input shape xtrain shape hidden keras layers dense activation relu input hidden keras layers dense activation relu hidden concat keras layers concatenate input hidden output keras layers dense concat model keras models model inputs input outputs output
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Architetture non sequenziali e Keras
Se volessimo suddividere l'input in 2 parti, eventualmente in 
sovrapposizione, e mandare su 2 strati distinti, allora dobbiamo creare 2 
input layers: 
input_A 
 = 
keras
.
layers
.
Input
(
shape
=
[
5
])
input_B 
 = 
keras
.
layers
.
Input
(
shape
=
[
6
])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input_B
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
]
, 
outputs
=
[
output
])
5
",architetture sequenziali keras volessimo suddividere linput parti eventualmente mandare strati distinti allora dobbiamo creare input layers input keras layers input shape input keras layers input shape hidden keras layers dense activation relu input hidden keras layers dense activation relu hidden concat keras layers concatenate input hidden output keras layers dense concat model keras models model inputs input input outputs output
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Architetture non sequenziali e Keras
Avendo creato due input, dobbiamo speciﬁcarli esplicitamente nella 
funzione ﬁt(), dopo aver compilato il modello: 
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
""sgd""
)
X_train_A
 , 
X_train_B 
 = 
X_train
[:, :
5
], 
X_train
[:, 
2
:]
X_valid_A
 , 
X_valid_B 
 = 
X_valid
[:, :
5
], 
X_valid
[:, 
2
:]
X_test_A
 , 
X_test_B 
 = 
X_test
[:, :
5
], 
X_test
[:, 
2
:]
X_new_A
, 
X_new_B 
 = 
X_test_A
 [:
3
], 
X_test_B
 [:
3
]
history 
 = 
model
.
fit
(
(
X_train_A
 , 
X_train_B
 )
, 
y_train
, 
epochs
=
20
,
validation_data
 =
((
X_valid_A
 , 
X_valid_B
 ), 
y_valid
))
mse_test 
 = 
model
.
evaluate
 ((
X_test_A
 , 
X_test_B
 ), 
y_test
)
y_pred 
= 
model
.
predict
((
X_new_A
, 
X_new_B
))
6",architetture sequenziali keras creato due input dobbiamo specicarli esplicitamente funzione dopo aver compilato modello model compile loss mse optimizer sgd xtrain xtrain xtrain xtrain xvalid xvalid xvalid xvalid xtest xtest xtest xtest xnew xnew xtest xtest history model fit xtrain xtrain ytrain epochs validationdata xvalid xvalid yvalid msetest model evaluate xtest xtest ytest ypred model predict xnew xnew
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Output multipli
Perché costruire architetture con output multipli? 
Il task lo potrebbe richiedere, es. localizzare e classiﬁcare un oggetto in 
una foto, cioè un problema di regressione e classiﬁcazione.  
Lo stesso vale per task più distinti. Sebbene si possano addestrare reti 
distinte, conviene condividere i parametri che in qualche modo 
rappresentano potenziali features che sono di interesse per entrambi i 
task, in modo da dover addestrare una sola volta la rete. 
Implementare una forma di regolarizzazione dei parametri per ridurre 
l'overﬁtting. Se per esempio aggiungiamo un secondo output in una 
certa parte della rete, imponiamo che  
la sottorete si addestri in modo autonomo,  
senza dipendere dalla restante parte della rete.
7
",output multipli costruire architetture output multipli task potrebbe richiedere localizzare classicare oggetto foto cio problema regressione classicazione stesso vale task distinti sebbene possano addestrare reti distinte conviene condividere parametri qualche modo rappresentano potenziali features interesse entrambi task modo dover addestrare sola volta rete implementare forma parametri ridurre lovertting esempio aggiungiamo secondo output certa parte rete imponiamo sottorete addestri modo autonomo senza dipendere restante parte rete
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Output multipli e Keras
Per aggiungere un secondo output (aux) è sufﬁciente collegarlo al layer 
giusto e aggiungerlo alla lista degli output: 
[
...
] # Stesso codice visto fino al layer di output
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)(
hidden2
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
],
                             
 outputs
=
[
output
, 
aux_output
 ])
Ogni output deve possedere la propria 
 loss function
 , da indicare quando 
compiliamo. Solitamente si da più peso alla loss dell'output ﬁnale: 
model
.
compile
(
loss
=
[
""mse""
, 
""mse""
], 
loss_weights
 =
[
0.9
, 
0.1
], 
optimizer
 =
""sgd""
)
Nella architettura vogliamo che entrambi gli output producano lo stesso 
risultato (y_train): 
history 
 = 
model
.
fit
([
X_train_A
 , 
X_train_B
 ], [
y_train
, 
y_train
], 
epochs
=
20
,
                    
 validation_data
 =
([
X_valid_A
 , 
X_valid_B
 ], [
y_valid
, 
y_valid
])) 
8",output multipli keras aggiungere secondo output aux sufciente collegarlo layer giusto aggiungerlo lista output stesso codice visto fino layer output output keras layers dense concat auxoutput keras layers dense hidden model keras models model inputs input input outputs output auxoutput ogni output deve possedere propria loss function indicare quando compiliamo solitamente peso loss delloutput nale model compile loss mse mse lossweights optimizer sgd architettura vogliamo entrambi output producano stesso risultato ytrain history model fit xtrain xtrain ytrain ytrain epochs validationdata xvalid xvalid yvalid yvalid
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Output multipli e Keras
Durante l'addestramento, oltre alla loss totale, sarà prodotta anche la loss 
del layer di output principale e aux: 
total_loss
 , 
main_loss
 , 
aux_loss 
 = 
model
.
evaluate
 (
                             [
 X_test_A
 , 
X_test_B
 ], [
y_test
, 
y_test
])
Anche la funzione predict() produrrà un doppio output: 
y_pred_main
 , 
y_pred_aux 
 = 
model
.
predict
([
X_new_A
, 
X_new_B
])
9",output multipli keras durante oltre loss totale prodotta loss layer output principale aux totalloss mainloss auxloss model evaluate xtest xtest ytest ytest funzione predict produrr doppio output ypredmain ypredaux model predict xnew xnew
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Keras: Modelli statici e dinamici
Entrambe le API, sequential e functional, seguono un approccio 
dichiarativo
 , dove prima si deﬁniscono i layer, come sono connessi, e 
successivamente viene avviato il ﬂusso dei dati. Si hanno i seguenti 
vantaggi: 
il modello può facilmente essere salvato, clonato e condiviso 
la struttura può essere visualizzata 
il framework può inferire il tipo di dati e controllare i tipi (favorisce il 
debug) 
Ma non si possono prevedere loop, architetture dinamiche, conditional 
branching e altri comportamenti dinamici. 
Per tale motivo si impiega il Subclassing API.
10",keras modelli statici dinamici entrambe sequential functional seguono approccio dichiarativo prima deniscono layer connessi successivamente viene avviato usso dati seguenti vantaggi modello pu facilmente essere salvato clonato condiviso struttura pu essere visualizzata framework pu inferire tipo dati controllare tipi favorisce debug possono prevedere loop architetture dinamiche conditional branching altri comportamenti dinamici tale motivo impiega subclassing
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Classiﬁcatore di Bayes",machine learning universit roma tre dipartimento ingegneria anno accademico classicatore bayes
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#1,1,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) ",sommario approccio parametrico distribuzione multi normale approccio parametrico parzen window
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#10,10,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
",classicatore bayes prof davide maltoni universit bologna classificazione classificatore bayes dato cuisono note probabilit ledensit diprobabilit condizionali laregola bayes assegna massima laprobabilit aposteriori massimizzare laprobabilit aposteriori significa massimizzare densit diprobabilit condizionale tenendo comunque conto probabilit apriori classi regola sidimostra ottima inquanto minimizza lerrore classificazione adesempio nelcaso diclassi 
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#11,11,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
",classicatore bayes prof davide maltoni universit bologna classificazione classificatore bayes dato cuisono note probabilit ledensit diprobabilit condizionali laregola bayes assegna massima laprobabilit aposteriori massimizzare laprobabilit aposteriori significa massimizzare densit diprobabilit condizionale tenendo comunque conto probabilit apriori classi regola sidimostra ottima inquanto minimizza lerrore classificazione adesempio nelcaso diclassi 
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#12,12,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
ℜ1eℜ2rappresentano due regioni disgiunte
dell’insieme deinumeri reali .
Sipuò dimostrare che esiste unpunto x*per il
quale l’errore èminimo .
Infatti per x*=x B(dove Bstaper Bayes) l’area
indicata come reducible error èpari a0.
Ciascuno dei due integrali esprime laparte
della distribuzione diprobabilità diuna classe
che cade nell’area dell’altra classe (errata) .
Inquesto caso, lasuperficie decisionale (vedi
dopo) èunpunto sull’asse deinumeri reali .",classicatore bayes prof davide maltoni universit bologna classificazione classificatore bayes dato cuisono note probabilit ledensit diprobabilit condizionali laregola bayes assegna massima laprobabilit aposteriori massimizzare laprobabilit aposteriori significa massimizzare densit diprobabilit condizionale tenendo comunque conto probabilit apriori classi regola sidimostra ottima inquanto minimizza lerrore classificazione adesempio nelcaso diclassi prof davide maltoni universit bologna classificazione classificatore bayes dato cuisono note probabilit ledensit diprobabilit condizionali laregola bayes assegna massima laprobabilit aposteriori massimizzare laprobabilit aposteriori significa massimizzare densit diprobabilit condizionale tenendo comunque conto probabilit apriori classi regola sidimostra ottima inquanto minimizza lerrore classificazione adesempio nelcaso diclassi due regioni disgiunte dellinsieme deinumeri reali sipu dimostrare esiste unpunto xper lerrore minimo infatti bdove bstaper bayes larea indicata reducible error pari ciascuno due integrali esprime laparte distribuzione diprobabilit diuna classe cade nellarea dellaltra classe errata inquesto caso lasuperficie decisionale vedi dopo unpunto sullasse deinumeri reali
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#13,13,"Classificatore di Bayes30 CHAPTER 2. BAYESIAN DECISION THEORY
2.7 Error Probabilities and Integrals
We can obtain additional insight into the operation of a general classiﬁer — Bayes or
otherwise — if we consider the sources of its error. Consider ﬁrst the two-category
case, and suppose the dichotomizer has divided the space into two regions R1andR2
in a possibly non-optimal way. There are two ways in which a classiﬁcation error can
occur; either an observation xfalls in R2and the true state of nature is ω1, orxfalls
inR1and the true state of nature is ω2. Since these events are mutually exclusive
and exhaustive, the probability of error is
P(error )= P(x∈R2,ω1)+P(x∈R1,ω2)
=P(x∈R2|ω1)P(ω1)+P(x∈R1|ω2)P(ω2)
=/integraldisplay
R2p(x|ω1)P(ω1)dx+/integraldisplay
R1p(x|ω2)P(ω2)dx. (68)
This result is illustrated in the one-dimensional case in Fig. 2.17. The two in-
tegrals in Eq. 68 represent the pink and the gray areas in the tails of the functions
p(x|ωi)P(ωi). Because the decision point x∗(and hence the regions R1andR2) were
chosen arbitrarily for that ﬁgure, the probability of error is not as small as it might
be. In particular, the triangular area marked “reducible error” can be eliminated if
the decision boundary is moved to xB. This is the Bayes optimal decision boundary
and gives the lowest probability of error. In general, if p(x|ω1)P(ω1)>p(x|ω2)P(ω2),
it is advantageous to classify xas in R1so that the smaller quantity will contribute
to the error integral; this is exactly what the Bayes decision rule achieves.
ω2 ω1
x
x* R2 R1p(x|ωi)P(ωi)
reducible
error
∫p(x|ω1)P(ω1)dx
R2∫p(x|ω2)P(ω2)dx
R1xB
Figure 2.17: Components of the probability of error for equal priors and (non-optimal)
decision point x∗. The pink area corresponds to the probability of errors for deciding
ω1when the state of nature is in fact ω2; the gray area represents the converse, as
given in Eq. 68. If the decision boundary is instead at the point of equal posterior
probabilities, xB, then this reducible error is eliminated and the total shaded area is
the minimum possible — this is the Bayes decision and gives the Bayes error rate.
In the multicategory case, there are more ways to be wrong than to be right, and
it is simpler to compute the probability of being correct. Clearly
P(correct )=c/summationdisplay
i=1P(x∈Ri,ωi)",classificatore bayes error probabilities integrals obtain additional insight operation general classier bayes otherwise consider sources error consider rst two category case suppose dichotomizer divided space two regions rand possibly optimal way two ways classication error occur either observation xfalls rand true state nature orxfalls rand true state nature since events mutually exclusive exhaustive probability error perror result illustrated one dimensional case fig two tegrals represent pink gray areas tails functions pxipi decision point xand hence regions rand chosen arbitrarily gure probability error small might particular triangular area marked reducible error eliminated decision boundary moved bayes optimal decision boundary gives lowest probability error general advantageous classify xas rso smaller quantity contribute error integral exactly bayes decision rule achieves rpxipi reducible error pxpdx figure components probability error equal priors non optimal decision point pink area corresponds probability errors deciding when state nature fact gray area represents converse given decision boundary instead point equal posterior probabilities reducible error eliminated total shaded area minimum possible bayes decision gives bayes error rate multicategory case ways wrong right simpler compute probability correct clearly pcorrect pxrii
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#14,14,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )
!Vogliamo eseguire la stima (grossolana) delle probabilità a priori 
delle classi wie delle densità di probabilità condizionali per un nuovo 
pattern xdata la classe wi  a partire dal training set (per la seconda 
stima consideriamo l’intorno del pattern xcerchiato in figura)",esempio prof davide maltoni universit bologna classificazione esempio stima grossolana probabilit priori densit pu essere effettuata partire training set segue vedranno seguito tecniche rigorose effettuare tale stima probabilit priori considera semplicemente loccorrenza pattern training set densit probabilit condizionali nuovo pattern da classificare contano occorrenze pattern training set due classi intorno ottiene quindi lapproccio bayesiano assegna pattern alla classe femmine peso altezza classificare persone maschifemmine base peso allaltezza partire training set figura spazio dimensioni w maschi blu femmine rosso vogliamo eseguire stima grossolana probabilit priori classi wie densit probabilit condizionali nuovo pattern xdata classe partire training set per seconda stima consideriamo lintorno pattern xcerchiato figura
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#15,15,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )",esempio prof davide maltoni universit bologna classificazione esempio stima grossolana probabilit priori densit pu essere effettuata partire training set segue vedranno seguito tecniche rigorose effettuare tale stima probabilit priori considera semplicemente loccorrenza pattern training set densit probabilit condizionali nuovo pattern da classificare contano occorrenze pattern training set due classi intorno ottiene quindi lapproccio bayesiano assegna pattern alla classe femmine peso altezza classificare persone maschifemmine base peso allaltezza partire training set figura spazio dimensioni w maschi blu femmine rosso
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#16,16,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )",esempio prof davide maltoni universit bologna classificazione esempio stima grossolana probabilit priori densit pu essere effettuata partire training set segue vedranno seguito tecniche rigorose effettuare tale stima probabilit priori considera semplicemente loccorrenza pattern training set densit probabilit condizionali nuovo pattern da classificare contano occorrenze pattern training set due classi intorno ottiene quindi lapproccio bayesiano assegna pattern alla classe femmine peso altezza classificare persone maschifemmine base peso allaltezza partire training set figura spazio dimensioni w maschi blu femmine rosso
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#17,17,"Approccio Bayesiano
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes : approccio parametrico e
non-parametrico
Mentre
 lastima delle probabilità apriori èabbastanza semplice
(senon sihanno elementi sipossono ipotizzare leclassi
equiprobabili) ,laconoscenza delle densità condizionali è
possibile “solo inteoria”;nella pratica duesoluzioni :
Approccio
 parametrico :sifanno ipotesi sulla forma delle
distribuzioni (es.distribuzione multinormale )esiapprendono i
parametri fondamentali (vettore medio ,matrice dicovarianza )
daltraining set.
Approccio
 nonparametrico :siapprendono ledistribuzioni dal
training set(es.attraverso ilmetodo Parzen Window ).
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere unaragionevole certezza (osperanza )chelaforma della
distruzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
L’approccio
 parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore .",approccio bayesiano prof davide maltoni universit bologna classificazione bayes approccio parametrico parametrico mentre lastima probabilit apriori abbastanza semplice senon sihanno elementi sipossono ipotizzare leclassi equiprobabili laconoscenza densit condizionali possibile solo inteorianella pratica duesoluzioni approccio parametrico sifanno ipotesi forma distribuzioni multinormale esiapprendono parametri fondamentali vettore medio matrice dicovarianza daltraining set approccio nonparametrico siapprendono ledistribuzioni training ilmetodo parzen window generalmente lapproccio parametrico siutilizza quando oltre avere unaragionevole certezza osperanza chelaforma distruzione siaadeguata ladimensione deltraining setnon sufficiente perunabuona stima densit lapproccio parametrico infatti generalmente caratterizzato daunminor numero digradi dilibert eilrischio dioverfitting deidati quando iltraining setpiccolo minore
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#18,18,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) ",sommario approccio parametrico distribuzione multi normale approccio parametrico parzen window
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#19,19,"Approccio Bayesiano
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere una ragionevole certezza (osperanza )che laforma della
distribuzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
!L’approccio parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore .",approccio bayesiano generalmente lapproccio parametrico siutilizza quando oltre avere ragionevole certezza osperanza che laforma distribuzione siaadeguata ladimensione deltraining setnon sufficiente perunabuona stima densit lapproccio parametrico infatti generalmente caratterizzato daunminor numero digradi dilibert eilrischio dioverfitting deidati quando iltraining setpiccolo minore
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#2,2,"Probabilità
Quando un agente conosce l’ambiente circostante , l’approccio
logico gliconsente di derivare piani efficaci . Ma gliagenti non 
hanno quasi maiaccesso a tutta l’informazione necessaria : 
devono quindi agire in condizioni di incertezza .
La teoria della probabilità èilmodo migliore di ragionare in 
condizioni di incertezza .",probabilit quando agente conosce lambiente circostante lapproccio logico gliconsente derivare piani efficaci gliagenti quasi maiaccesso tutta linformazione necessaria devono quindi agire condizioni incertezza teoria probabilit ilmodo migliore ragionare condizioni incertezza
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#20,20,"Distribuzione Normale (d=1)
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
N.B. La funzione p(x) sopra nonvaconfusa con la densità di probabilità assoluta 
checompare a denominatore del Teorema di Bayes. Sono due grandezze diverse !",distribuzione normale prof davide maltoni universit bologna classificazione distribuzione normale densit diprobabilit distribuzione normale doveilvalor medio ladeviazione standard oscarto quadratico medio eilsuoquadrato lavarianza solo ilcirca delvolume solitamente siassume ladistribuzione valga adistanze maggiori didalvalore medio prof davide maltoni universit bologna classificazione distribuzione normale densit diprobabilit distribuzione normale doveilvalor medio ladeviazione standard oscarto quadratico medio eilsuoquadrato lavarianza solo ilcirca delvolume solitamente siassume ladistribuzione valga adistanze maggiori didalvalore medio prof davide maltoni universit bologna classificazione distribuzione normale densit diprobabilit distribuzione normale doveilvalor medio ladeviazione standard oscarto quadratico medio eilsuoquadrato lavarianza solo ilcirca delvolume solitamente siassume ladistribuzione valga adistanze maggiori didalvalore medio funzione sopra nonvaconfusa densit probabilit assoluta checompare denominatore teorema bayes due grandezze diverse
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#21,21,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza!Vogliamo eseguire la stima dei parametri tramite il Metodo 
della Massima Verosimiglianza ( Maximum Likelihood )
Il metodo consiste nel massimizzare la funzione di verosimiglianza, definita in 
base alla probabilità di osservare una data realizzazione campionaria , 
condizionatamente ai valori assunti dai parametri statistici oggetto di stima",esempio stima esd prof davide maltoni universit bologna classificazione esempio stima dato untraining setdipattern mono dimensionali composto elementi stima deiparametri permassima verosimiglianza maximum likelihood sidimostra essere stima permedia campionaria deivalori stima pervarianza campionaria deivalori iixn iixn eseguire stima parametri tramite metodo massima verosimiglianza maximum likelihood metodo consiste massimizzare funzione definita base probabilit osservare data realizzazione campionaria valori assunti parametri statistici oggetto stima
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#22,22,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza",esempio stima esd prof davide maltoni universit bologna classificazione esempio stima dato untraining setdipattern mono dimensionali composto elementi stima deiparametri permassima verosimiglianza maximum likelihood sidimostra essere stima permedia campionaria deivalori stima pervarianza campionaria deivalori iixn iixn
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#23,23,"Esempio Stima di µes(d=1)
8prof. Davide Maltoni –Università di Bologna
ML
Classificazione…in forma grafica

01495.07559.441
1416.32 855.171)25(4015.0 8.31829252
   
  e e p
ATTENZIONE SIAMO NEL 
CONTINUO :
𝑝è unadensità di 
probabilità : 𝑝(25) non è la 
probabilità del valore 25 
(questa vale 0!) ma la 
densità di probabilità nel
punto 25. Solo considerando
un intervallo di valori (anche
piccolo) sulla base possiamo
parlare di probabilità . 
In altre parole l’intervallo
𝑥,𝑥+𝑑𝑥ha probabilità
𝑝𝑥𝑑𝑥.N.B. Siamo nelcontinuo: p(25) è una densità di probabilità , non una probabilità !  ",esempio stima esd prof davide maltoni universit bologna forma grafica e unadensit probabilit probabilit valore questa vale densit probabilit punto solo considerando intervallo valori anche piccolo base possiamo parlare probabilit altre parole lintervallo ha probabilit nb nelcontinuo densit probabilit probabilit
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#24,24,"Esempio Stima di µes(d=1)
",esempio stima esd
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#3,3,"Spazio di Probabilità
Uno spazio di probabilità èuna terna (Ω, !, P) dove
!Ωèun insieme qualunque (in genere pensato come l’insieme
deirisultati possibili di un esperimento casuale );!!èdetta σ-algebra , ovvero un insieme di insiemi (glieventi ) 
per iquali sipuòcalcolare una probabilit à;
!P()èappunto una misura di probabilit àsuΩ(P:Ω → [0, 1]).
Per la precisione , una σ-algebra èuna famiglia di insiemi taliche
!∅∈!;!se A ∈!allora anche ilsuocomplementare Āèin!;
!unioni numerabili di elementi di !appartengono ancora ad !.",spazio probabilit spazio probabilit una terna un insieme qualunque genere pensato linsieme deirisultati possibili esperimento casuale detta algebra ovvero insieme insiemi glieventi iquali sipucalcolare probabilit pappunto misura probabilit sup precisione algebra una famiglia insiemi taliche se allora in unioni numerabili elementi appartengono ancora
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#4,4,"Spazio di Probabilità
Ad esempio : nell’esperimento “lancio di un dado”,
Ω= {1, 2, 3, 4, 5, 6}, !èla σ-algebra generata dagli
eventi elementari di Ω, cioè di fatto, quelli per iquali è
possibile calcolare una probabilit à.
Ad esempio E= “numero pari” = {2, 4, 6}, F= “numero
maggiore di 4” = {5, 6}. 
G = “ numero 7” appartiene a !?",spazio probabilit esempio lancio dado la algebra generata eventi elementari cio fatto iquali possibile calcolare probabilit esempio numero pari numero maggiore numero appartiene
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#5,5,"Esempio di Misura di Probabilità
Se ildado non ètruccato , cioèglieventi elementari sono
equiprobabili , allora
""#=#&'() *'+,-.+,/) '#
#&'() 0,(()1)/) 2)Ω
cioè, negli esempi precedenti
""#=#2,4,6
#1,2,3,4,5,6=3
6=1
2
"";=#5,6
#1,2,3,4,5,6=2
6=1
3",esempio misura probabilit ildado truccato cioglieventi elementari equiprobabili allora cio esempi precedenti
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#6,6,"Probabilità
Una probabilità (grado di credenza) èuna misura su un insieme di 
eventi che soddisfa tre assiomi (assiomi di Kolmogorov [1]):
!La misura di ogni evento è compresa fra 0 e 1;
!La misura dell’ intero insieme di eventi è 1;
!La probabilità dell’ unione di eventi disgiunti (o mutuamente
esclusivi )è pari alla somma delle probabilità dei singoli eventi .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
disgiunti quando la lorointersezione èvuota .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
indipendenti se P(A∩B) = P(A) ⋅P(B). 
[1] S. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , Pearson, 2020.",probabilit probabilit grado credenza una misura insieme eventi soddisfa tre assiomi assiomi kolmogorov misura ogni evento compresa fra misura dell intero insieme eventi probabilit dell unione eventi disgiunti mutuamente esclusivi pari somma probabilit singoli eventi dato unospazio probabilit due eventi bsidicono disgiunti quando vuota dato unospazio probabilit due eventi bsidicono indipendenti pab pb russell norvig artificial intelligence modern approach pearson
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#7,7,"Probabilità
Un modello probabilistico consiste in uno spazio di possibili esiti
(cioè descrizioni complete di stati) mutuamente esclusivi insieme 
alla misura di probabilità associata ad ogni esito. 
Probabilità condizionata P(A/B) , dove Ae Bsono proposizioni (cioè 
enunciati che affermano che qualcosa è verificato): “la probabilità 
di A, posto che tutto quello che sappiamo èB”.
In altritermini, la probabilità condizionata P(A/B) esprime una 
“correzione ” delle aspettative per A, dettata dall’osservazione di B.
Esempio: P(carie/maldidenti)=0.8 indica che se un paziente ha il mal di 
denti e non è disponibile nessun’altra informazione, la probabilità che 
abbia una carie sarà 0.8.
N.B. La probabilità condizionata P(A/B) ha senso solo se Bha 
probabilità non nulla di verificarsi .",probabilit modello probabilistico consiste spazio possibili esiti cio descrizioni complete stati mutuamente esclusivi insieme misura probabilit associata ogni esito probabilit condizionata pab bsono proposizioni cio enunciati affermano qualcosa verificato la probabilit posto sappiamo altritermini probabilit condizionata pab esprime correzione aspettative dettata esempio indica paziente mal denti disponibile nessunaltra informazione probabilit carie probabilit condizionata pab senso solo bha probabilit nulla verificarsi
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#8,8,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1",approccio bayesiano prof davide maltoni universit bologna classificazione approccio bayesiano ilproblema posto intermini probabilistici setutte ledistribuzioni ingioco notelapproccio bayesiano costituisce lamigliore regola possibile soluzione unospazio dipattern dimensionali w uninsieme diclassi disgiunte costituite daelementi di conla densit diprobabilit condizionale ocondizionata didata ovvero ladensit diprobabilit ilprossimo pattern sia sottolipotesi chelasuaclasse diappartenenza sia apriori ovvero laprobabilit cheilprossimo pattern daclassificare siadiclasse conladensit diprobabilit assoluta diovvero ladensit diprobabilit cheilprossimo pattern daclassificare sia conla probabilit aposteriori laprobabilit osservato diappartenenza sia perilteorema bayes 
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#9,9,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1",approccio bayesiano prof davide maltoni universit bologna classificazione approccio bayesiano ilproblema posto intermini probabilistici setutte ledistribuzioni ingioco notelapproccio bayesiano costituisce lamigliore regola possibile soluzione unospazio dipattern dimensionali w uninsieme diclassi disgiunte costituite daelementi di conla densit diprobabilit condizionale ocondizionata didata ovvero ladensit diprobabilit ilprossimo pattern sia sottolipotesi chelasuaclasse diappartenenza sia apriori ovvero laprobabilit cheilprossimo pattern daclassificare siadiclasse conladensit diprobabilit assoluta diovvero ladensit diprobabilit cheilprossimo pattern daclassificare sia conla probabilit aposteriori laprobabilit osservato diappartenenza sia perilteorema bayes 
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alla  
Regressione
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico introduzione regressione machine learning
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Regressione 
Simple Linear Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo) 
Multiple Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo)
 
2",sommario introduzione regressione simple linear regression fase training minimizzazione funzione costo multiple regression fase training minimizzazione funzione costo
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#10,10,"Il Processo di Training
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione
tra valori 
osservati e 
previsti ∀ iyi osservatoxi ŷi previsto
 11xi
Funzione  
di Costopesi ŵ 0 e ŵ 1  
calcolati(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ",processo training dati training estrazione features modello comparazione valori osservati previsti iyi osservatoxi previsto funzione costopesi calcolatin esempi algoritmo apprendimento calcolo vettore pesi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#11,11," 12Il Processo di Training
•Dati di training : insieme di esempi ( xi, yi) relativi a casi conosciuti 
(i punti nel piano x-y), da utilizzare per calcolare la funzione di 
costo RSS. 
•Estrazione di features : in questo caso tale funzione è inattiva, nel 
senso che riproduce in uscita il suo ingresso xi. 
•Modello di ML : ipotesi f scelta, istanziata con i valori dei pesi più 
opportuni. 
•Comparazione tra dati osservati e dati previsti : per ogni esempio 
abbiamo il valore vero yi e il valore previsto ŷi, da utilizzare per il 
calcolo della funzione RSS. 
•Algoritmo di Apprendimento : algoritmo che calcola i pesi che 
minimizzano la funzione di costo RSS, da utilizzare per deﬁnire il 
modello di ML.",processo training dati training insieme esempi relativi casi conosciuti punti piano utilizzare calcolare funzione costo estrazione features caso tale funzione inattiva senso riproduce uscita ingresso modello ipotesi scelta istanziata valori pesi opportuni comparazione dati osservati dati previsti ogni esempio valore vero valore previsto utilizzare calcolo funzione algoritmo apprendimento algoritmo calcola pesi minimizzano funzione costo utilizzare denire modello
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#12,12,"Minimizzazione  della funzione RSS
In sintesi, il processo di apprendimento è formulato come una 
ricerca di ottimizzazione (ricerca del minimo) nello 
 spazio dei 
pesi
. 
A tal ﬁne possiamo calcolare e avvalerci del 
 gradiente
  della 
“misura d’errore” 
 RSS
 deﬁnita in precedenza.  
Si può dimostrare che la 
 RSS
 è una funzione convessa.  
Ricordiamoci che, per funzioni convesse, quando il gradiente è 
uguale a zero si ha un minimo globale. 
 
13",minimizzazione funzione sintesi processo apprendimento formulato ricerca ottimizzazione ricerca minimo spazio pesi tal ne possiamo calcolare avvalerci gradiente misura derrore denita precedenza pu dimostrare funzione convessa ricordiamoci che funzioni convesse quando gradiente uguale zero minimo globale
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#13,13,"Minimo  di una funzione convessa
 
14
w0w1g
ŵ
w
ŵ0ŵ1
gradiente:ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
",minimo funzione convessa wwg gradienteij rgwgw wigw latexit pqiq yyx emwd lta cknicl ntt ugig xla cqk kjce jcysbu gip wfvrgv qokfg tsz znk nwgz mxn yly zvb rkyc udki swqv gspwsvq wjnr cdk yaqqdkh evm nea smrgvm ibw jcg psvfd hnjzjdhep snnn hjea pfb exta awte ijab ejzvr sqiz kbtd kqjng ibh kohgxtz pla yfy gxi vzk bxdu gun fsah ici ulcud rcg aei vherx pdt gpy wbm vfj wwm tnb fms bxs blvhlag pnkr nkzxlh alatexit
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#14,14,"Gradiente della funzione RSS
Il gradiente della funzione RSS: 
    
   è deﬁnito come segue:
 
15rRSS( w0,w1)=2
4@RSS
@w0
@RSS
@w13
5RSS( w0,w1)=NX
i=1[yi",gradiente funzione gradiente funzione denito segue wwn iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#15,15,"Calcolo del Gradiente  
della funzione RSS
 
16rRSS( w0,w1)=2
4",calcolo gradiente funzione
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#16,16,"Algoritmi per adattare il modello 
Una volta calcolato il gradiente della funzione 
 RSS
, ci sono 
due possibili approcci per minimizzare la funzione di 
costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero (ossia al vettore nullo) e si 
risolvono le equazioni (non sempre è possibile o conveniente dal punto di 
vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
17",algoritmi adattare modello volta calcolato gradiente funzione due possibili approcci minimizzare funzione costo forma chiusa uguaglia gradiente zero ossia vettore nullo risolvono equazioni non sempre possibile conveniente punto vista computazionale algoritmo discesa gradiente gradient descent richiede denizione criterio convergenza step size
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#17,17,"Forma Chiusa (1/4)
Poniamo il gradiente uguale al vettore nullo: 
ossia:
 
18",forma chiusa poniamo gradiente uguale vettore nullo ossia
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#18,18,"Forma Chiusa (2/4)
Dalla prima equazione otteniamo:
 
19PN
i=1yi",forma chiusa prima equazione otteniamo iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#19,19,"Forma Chiusa (3/4)
Dalla seconda equazione otteniamo: 
da cui si ha:
 
20PN
i=1xiyi",forma chiusa seconda equazione otteniamo ixiyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#2,2,"Introduzione alla Regressione
 
3I modelli a regressione vengono utilizzati per prevedere 
variabili target su scala continua , il che li rende 
interessanti per risolvere molte questioni in ambito 
scientiﬁco e anche industriale, come ad esempio:
• trovare relazioni fra variabili 
• valutare tendenze 
• effettuare previsioni ( e.g., vendite di una azienda nei prossimi mesi )",introduzione regressione modelli regressione vengono utilizzati prevedere variabili target scala continua rende interessanti risolvere molte questioni ambito scientico industriale esempio trovare relazioni fra variabili valutare tendenze effettuare previsioni vendite azienda prossimi mesi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#20,20,"Forma Chiusa (4/4)
e con facili passaggi otteniamo: 
che, insieme a: 
vista in precedenza, ci consente di calcolare i valori dei due 
pesi che minimizzano la funzione RSS.
 
21ˆw1=PN
i=1xiyi",forma chiusa facili passaggi otteniamo che insieme vista precedenza consente calcolare valori due pesi minimizzano funzione wp ixiyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#21,21,"Gradient Descent (1/3)
Come sappiamo, con questo approccio dobbiamo 
aggiornare i pesi in modo tale da spostarci nella direzione 
opposta al gradiente:
 
22w(t+1) w(t)",gradient descent sappiamo approccio dobbiamo aggiornare pesi modo tale spostarci direzione opposta gradiente
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#22,22,"Gradient Descent (2/3)
Rivediamo l’espressione del gradiente di RSS: 
L’aggiornamento dei due pesi può dunque essere effettuato 
come segue, scegliendo un opportuno 
 step size
 :
 
23rRSS( w0,w1)=2
4",gradient descent rivediamo lespressione gradiente laggiornamento due pesi pu dunque essere effettuato segue scegliendo opportuno step size
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#23,23,"Gradient Descent (3/3)
Dobbiamo inﬁne scegliere un 
 criterio di convergenza
 . 
Come già detto, per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
24krRSS(w(t))k2✏",gradient descent dobbiamo inne scegliere criterio convergenza gi detto funzioni convesse minimo globale quando gradiente uguale zero pratica possiamo terminare lelaborazione quando swtk
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#24,24,"Algoritmo di Gradient Descent 
 
25w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
w(t+1)
0 w(t)
0+2↵·NX
i=1[yi",algoritmo gradient descent oppure inizializziamo modo casuale whilekr wtk n iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#25,25,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Fino ad ora abbiamo ipotizzato, per la funzione 
 f(
x
)
, un andamento 
lineare per il nostro caso di studio relativo ai prezzi degli appartamenti. 
Tuttavia l’esperienza comune ci induce a pensare che la relazione tra 
le due variabili (area e prezzo di un appartamento) non sia proprio 
lineare. In genere, all’aumentare della metratura il prezzo aumenta ma 
non in modo esattamente proporzionale. Potremmo ipotizzare ad 
esempio una funzione quadratica o addirittura polinomiale di grado p: 
 
26f(x)=w0+w1x+w2x2
f(x)=w0+w1x+w2x2+···+wpxpy
Areax
y
Areax
",multiple regression caso linear regression multiple features fino ora ipotizzato funzione andamento lineare caso studio relativo prezzi appartamenti tuttavia lesperienza comune induce pensare relazione due variabili area prezzo appartamento proprio lineare genere allaumentare metratura prezzo aumenta modo esattamente proporzionale potremmo ipotizzare esempio funzione quadratica addirittura polinomiale grado areax areax
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#26,26,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
In quest’ultimo caso avremmo una 
 Polinomial Regression
 , 
il cui modello è il seguente: 
 
27yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
In genere, le potenze della x sono trattate come differenti 
features
 : 
feature 1 = 1
feature 2 = x
feature 3 = x2
······ ···
feature p+1 = xp",multiple regression caso linear regression multiple features questultimo caso polinomial regression modello seguente iwpxp ii genere potenze trattate differenti features feature feature feature feature
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#27,27,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, con un solo input x
 i
, è il seguente: 
 
28yi=w0",multiple regression caso linear regression multiple features caso generale solo input seguente yiw
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#28,28,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Inoltre, è importante considerare anche il caso in cui ci 
siano più input. 
Per l’esempio degli appartamenti potremmo voler 
considerare non solo l’area ma anche altre caratteristiche 
(#bagni, #camere da letto, anno di costruzione, ecc.). 
In tal caso avremmo in input un vettore 
 x
i
 per ogni 
esempio noto, le cui componenti sono appunto l’area, il 
#bagni, ecc. 
    
 
29",multiple regression caso linear regression multiple features inoltre importante considerare caso input lesempio appartamenti potremmo voler considerare solo larea altre caratteristiche bagni camere letto anno costruzione ecc tal caso input vettore ogni esempio noto componenti appunto larea bagni ecc
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#29,29,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, che ha in input un vettore 
 x
i
, è pertanto il 
seguente: 
 
30
dove le features che compaiono, ciascuna delle quali è 
funzione del vettore 
 x
i
, possono assumere forme diverse. yi=w0",multiple regression caso linear regression multiple features caso generale input vettore pertanto seguente features compaiono ciascuna quali funzione vettore possono assumere forme diverse yiw
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#3,3,"Modello a 
Regressione Lineare Semplice
 
4L’obiettivo di un modello a Regressione Lineare 
Semplice ( univariata ) consiste nell’individuare le 
relazioni esistenti tra un’unica caratteristica (la variabile 
descrittiva x) e una risposta continua (variabile target y).",modello regressione lineare semplice lobiettivo modello regressione lineare semplice univariata consiste relazioni esistenti ununica caratteristica variabile descrittiva risposta continua variabile target
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#30,30," 
31Anche in questo caso possiamo utilizzare, come funzione di 
costo da minimizzare, la RSS deﬁnita come segue, a partire 
da N osservazioni disponibili:
Il problema di addestrare il nostro modello è dunque quello 
di trovare i valori dei pesi ŵ0 ,ŵ1 ,…, ŵD che minimizzano la 
funzione RSS (convessa anche in questo caso).
Multiple Regression 
[caso di Linear Regression con Multiple Features]
RSS(w)=NX
i=1(yi",caso possiamo utilizzare funzione costo minimizzare denita segue partire osservazioni disponibili problema addestrare modello dunque trovare valori pesi minimizzano funzione convessa caso multiple regression caso linear regression multiple features sswn iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#31,31,"Il Processo di Training 
[caso di Linear Regression con Multiple Features]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione 
tra valori 
osservati e 
previsti ∀ iyi osservato(xi) ŷi previsto
 32xi
Funzione  
di Costovettore di pesi 
 ŵ calcolatoɸ
(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ",processo training caso linear regression multiple features dati training estrazione features modello comparazione valori osservati previsti iyi osservatoxi previsto funzione costovettore pesi calcolato esempi algoritmo apprendimento calcolo vettore pesi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#32,32,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In molti casi può essere conveniente usare una 
notazione matriciale. 
L’espressione: 
 
33
relativa all’i-esimo valore per y, può essere scritta 
come segue: yi=DX
j=0wj",regression model notazione matriciale caso linear regression multiple features molti casi pu essere conveniente usare notazione matriciale lespressione relativa alli esimo valore pu essere scritta segue yid jwj
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#33,33,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
 
34
oppure: yi=[w0w1···wD]·2
664",regression model notazione matriciale caso linear regression multiple features oppure yiwww
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#34,34,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In sintesi: 
 
35yi=DX
j=0wj",regression model notazione matriciale caso linear regression multiple features sintesi yid jwj
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#35,35,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Possiamo inﬁne rappresentare tutte le osservazioni y in 
modo compatto come segue: 
 
36
    ossia: 
y=",regression model notazione matriciale caso linear regression multiple features possiamo inne rappresentare tutte osservazioni modo compatto segue ossia
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#36,36,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
dove: 
    
 
37✏=2
664✏1
✏2
···
✏N3
775 y=2
664y1
y2
···
yN3
775
",regression model notazione matriciale caso linear regression multiple features dove 
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#37,37,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora la funzione RSS: 
 
38RSS(w)=NX
i=1(yi",regression model notazione matriciale caso linear regression multiple features calcoliamo ora funzione swn iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#38,38,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Da una precedente espressione per 
 y
 ricaviamo il vettore 
 ε
: 
 
39✏=y",regression model notazione matriciale caso linear regression multiple features precedente espressione ricaviamo vettore
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#39,39,"Gradiente della funzione RSS 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora il gradiente della funzione RSS, partendo dalla 
precedente espressione matriciale. 
Applicando una nota regola di calcolo differenziale matriciale 
si ottiene: 
 
40rRSS(w)=r[(y",gradiente funzione caso linear regression multiple features calcoliamo ora gradiente funzione partendo precedente espressione matriciale applicando nota regola calcolo differenziale matriciale ottiene swry
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#4,4,"Esempio 
 
5A titolo di esempio possiamo considerare il caso della 
previsione del prezzo di un appartamento (variabile target y) 
data la sua metratura (variabile descrittiva x).
Tipicamente, in casi come questo abbiamo a disposizione un 
certo numero di esempi (osservazioni), costituiti da 
appartamenti già venduti per ciascuno dei quali abbiamo a 
disposizione l’area in mq o in sq.ft. ( x) e il prezzo pagato per 
l’acquisto ( y).
Ciascuna delle suddette osservazioni può essere rappresentata 
da un punto in un piano cartesiano x-y, come illustrato nella 
ﬁgura che segue.",esempio titolo esempio possiamo considerare caso previsione prezzo appartamento variabile target data metratura variabile descrittiva tipicamente casi disposizione certo numero esempi osservazioni costituiti appartamenti gi venduti ciascuno quali disposizione larea sqft prezzo pagato lacquisto ciascuna suddette osservazioni pu essere rappresentata punto piano cartesiano illustrato gura segue
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#40,40,"Algoritmi per adattare il modello 
[caso di Linear Regression con Multiple Features]
Anche in questo caso, una volta calcolato il gradiente della 
funzione 
 RSS
, ci sono due possibili approcci per 
minimizzare la funzione di costo: 
“Forma chiusa”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
41",algoritmi adattare modello caso linear regression multiple features caso volta calcolato gradiente funzione due possibili approcci minimizzare funzione costo forma chiusa uguaglia gradiente zero risolvono equazioni non sempre possibile conveniente punto vista computazionale algoritmo discesa gradiente gradient descent richiede denizione criterio convergenza step size
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#41,41,"Forma Chiusa 
[caso di Linear Regression con Multiple Features]
Poniamo il gradiente uguale al vettore nullo: 
 
42ˆw=(",forma chiusa caso linear regression multiple features poniamo gradiente uguale vettore nullo
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#42,42,"Gradient Descent (1/4) 
[caso di Linear Regression con Multiple Features]
Dobbiamo aggiornare il vettore dei pesi in modo tale da 
spostarci nella direzione opposta al gradiente:
 
43w(t+1) w(t)",gradient descent caso linear regression multiple features dobbiamo aggiornare vettore pesi modo tale spostarci direzione opposta gradiente
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#43,43,"Gradient Descent (2/4) 
[caso di Linear Regression con Multiple Features]
I singoli pesi devono dunque essere aggiornati come segue:
 
44w(t+1)
0 w(t)
0",gradient descent caso linear regression multiple features singoli pesi devono dunque essere aggiornati segue
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#44,44,"Gradient Descent (3/4) 
[caso di Linear Regression con Multiple Features]
Per comprendere gli aggiornamenti da fare per i singoli pesi, 
calcoliamo la derivata parziale di RSS, espressa in questa 
forma:
 
45
rispetto al generico peso j-esimo:
@RSS(w(t))
@wj=NX
i=12[yi",gradient descent caso linear regression multiple features comprendere aggiornamenti fare singoli pesi calcoliamo derivata parziale espressa forma rispetto generico peso esimo sswt wjn iyi
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#45,45,"Gradient Descent (4/4) 
[caso di Linear Regression con Multiple Features]
Anche in questo caso dobbiamo inﬁne scegliere un 
 criterio 
di convergenza
 . 
Sappiamo che per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
46krRSS(w(t))k2✏",gradient descent caso linear regression multiple features caso dobbiamo inne scegliere criterio convergenza sappiamo funzioni convesse minimo globale quando gradiente uguale zero pratica possiamo terminare lelaborazione quando swtk
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#46,46,"Algoritmo di Gradient Descent 
[caso di Linear Regression con Multiple Features]
 
47w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=",algoritmo gradient descent caso linear regression multiple features oppure inizializziamo modo casuale whilekr wtk derivata parziale
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#47,47,"Riferimenti
 
48
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#5,5,"Esempio
 
6Il problema da risolvere è il seguente: scegliere lo spazio delle 
ipotesi  H (e.g., insieme di polinomi di grado massimo k) e la 
funzione f(x) (ipotesi) che approssima meglio le osservazioni 
disponibili di una funzione sconosciuta, da utilizzare per 
prevedere i prezzi di altri appartamenti (diversi dagli esempi).
y
Area xy
Area x
y
Area x
",esempio problema risolvere seguente scegliere spazio ipotesi insieme polinomi grado massimo funzione ipotesi approssima meglio osservazioni disponibili funzione sconosciuta utilizzare prevedere prezzi altri appartamenti diversi esempi area area area
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#6,6,"Apprendimento induttivo 
(Inductive Learning method)
La difﬁcoltà che si incontra in tale attività è dovuta al 
fatto che non è facile stabilire se una particolare f sia una 
buona approssimazione della funzione sconosciuta. 
Una buona ipotesi si potrà generalizzare  bene, ossia 
potrà predire correttamente esempi che non ha ancora 
incontrato.Il problema dell’induzione
 7",apprendimento induttivo inductive learning method difcolt incontra tale attivit dovuta fatto facile stabilire particolare buona approssimazione funzione sconosciuta buona ipotesi potr generalizzare bene ossia potr predire correttamente esempi ancora incontratoil problema dellinduzione
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#7,7,"Simple Linear Regression Model
 
8In ﬁgura è rappresentato un modello lineare per f(x), dove il 
peso wo rappresenta l’intercetta e il peso w1 rappresenta la 
pendenza della retta. Si noti l’offset verticale che costituisce 
l’errore che in genere esiste tra la previsione e il valore effettivo. 
Abbiamo dunque, per il valore vero e quello previsto per un 
certo valore dell’ascissa:
yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
Area x
Prezzo",simple linear regression model gura rappresentato modello lineare peso rappresenta lintercetta peso rappresenta pendenza retta noti loffset verticale costituisce lerrore genere esiste previsione valore effettivo dunque valore vero previsto certo valore dellascissa yiwwxii area prezzo
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#8,8,"Simple Linear Regression Model
 
9Supponiamo di scegliere il modello lineare. Una volta 
deﬁnito tale modello, ossia la forma della funzione f(x), 
occorre determinare i due pesi incogniti, ossia l’intercetta e la 
pendenza, che deﬁniscano la f(x) “migliore” secondo un certo 
criterio.
Un criterio possibile è quello di minimizzare gli errori che si 
hanno sulle osservazioni. ",simple linear regression model supponiamo scegliere modello lineare volta denito tale modello ossia forma funzione occorre determinare due pesi incogniti ossia lintercetta pendenza deniscano migliore secondo certo criterio criterio possibile minimizzare errori osservazioni
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#9,9,"Simple Linear Regression Model
 
10Una delle funzioni utilizzate a tal ﬁne, che deve essere per 
l’appunto minimizzata, è la Residual Sum of Squares (RSS) , 
deﬁnita come segue, a partire da N osservazioni disponibili:
RSS( w0,w1)=NX
i=1(yi",simple linear regression model funzioni utilizzate tal ne deve essere lappunto minimizzata residual sum squares denita segue partire osservazioni disponibili wwn iyi
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#0,0,"Distribuzione Normale Multivariata (Multinormale)
9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0",distribuzione normale multivariata multinormale prof davide maltoni universit bologna classificazione distribuzione normale multivariata multinormale notazione perevitare confusione utilizziamo apedicelindice pattern eove necessario adapice lacomponente scalare pattern esimo vettore componente esima delpattern esimo scalare densit diprobabilit distribuzione multinormale medio lamatrice covarianza assume ivettori ditipo colonna lapice trasposto litrasforma inrighe sono rispettivamente ildeterminante elinversa matrice dicovarianza sempre simmetrica edefinita positiva pertanto ammette inversa essendo simmetrica numero diparametri cheladefinisce elementi diagonali sono levarianze deirispettivi ovvero diagonali sono covarianze trae seesono statisticamente indipendenti seesono correlati positivamente seesono correlati negativamente 
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#1,1,"Richiami
!La Matrice di Covarianza si indica di solito con Σed è una generalizzazione del 
concetto di varianza al caso di dimensione maggiore di uno
!E’ una matrice che rappresenta la variazione di ogni variabile rispetto alle altre 
(inclusa se stessa)
!E’ sempre simmetrica e definita positiva (i.e., ha tutti gli autovalori strettamente 
positivi) ---> ammette sempre Matrice Inversa
!La Matrice Simmetrica è una matrice quadrata che ha la proprietà di essere la 
trasposta (vedi sotto) di se stessa 
!La Matrice Inversa di una matrice A è pari alla sua Matrice Aggiunta (i.e., Matrice 
Trasposta Coniugata) diviso il det(A)
!La Matrice Trasposta di una matrice è la matrice ottenuta scambiando le righe con 
le colonne
!La Matrice Trasposta Coniugata di una matrice a valori complessi è la matrice 
ottenuta effettuando la trasposta e scambiando ogni valore con il suo complesso 
coniugato",richiami matrice covarianza indica solito ed concetto varianza caso dimensione maggiore matrice rappresenta variazione ogni variabile rispetto altre inclusa stessa sempre simmetrica definita positiva autovalori strettamente positivi ammette sempre matrice inversa matrice simmetrica matrice quadrata propriet essere trasposta vedi sotto stessa matrice inversa matrice pari matrice aggiunta matrice trasposta coniugata diviso deta matrice trasposta matrice matrice ottenuta scambiando righe colonne matrice trasposta coniugata matrice valori complessi matrice ottenuta effettuando trasposta scambiando ogni valore complesso coniugato
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#10,10,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga.",esempio stima esd prof davide maltoni universit bologna kij oinnotazione vettoriale somma dimatrici ciascuna ottenuta vettore colonna pervettore riga
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#11,11,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga.",esempio stima esd prof davide maltoni universit bologna kij oinnotazione vettoriale somma dimatrici ciascuna ottenuta vettore colonna pervettore riga
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#12,12,"Esempio Stima di µes(d=2)
14prof. Davide Maltoni –Università di Bologna
ML
Classificazionein forma grafica
vista 
dall’alto
vista 
laterale",esempio stima esd prof davide maltoni universit bologna forma grafica vista dallalto vista laterale
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#13,13,"Classiﬁcatore di Bayes con Distribuzioni Multinormali
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
",classicatore bayes distribuzioni multinormali prof davide maltoni universit bologna classificazione classificatore bayes distribuzioni multinormali nellesempio visualizzate ledensit condizionali diclassi dipattern distribuiti normale dimensionale corrette base rispettive probabilit apriori classificazione eseguita utilizzando laregola bayesiana spazio suddiviso inregioni nonconnesse nelcaso specifico costituita daduecomponenti disgiunte decision boundary odecision surface superficie decisionale unazona diconfine traregioni associa classi diverse sulboundary ambigua superfici decisionali possono assumere forme diverse nel caso specifico sitratta didueiperboli ingenerale lematrici dicovarianza uguali decisionale uniper piano lematrici dicovarianza arbitrarie lasuperficie decisionale uniper quadratica
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#14,14,"15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
Classiﬁcatore di Bayes con Distribuzioni Multinormali",prof davide maltoni universit bologna classificazione classificatore bayes distribuzioni multinormali nellesempio visualizzate ledensit condizionali diclassi dipattern distribuiti normale dimensionale corrette base rispettive probabilit apriori classificazione eseguita utilizzando laregola bayesiana spazio suddiviso inregioni nonconnesse nelcaso specifico costituita daduecomponenti disgiunte decision boundary odecision surface superficie decisionale unazona diconfine traregioni associa classi diverse sulboundary ambigua superfici decisionali possono assumere forme diverse nel caso specifico sitratta didueiperboli ingenerale lematrici dicovarianza uguali decisionale uniper piano lematrici dicovarianza arbitrarie lasuperficie decisionale uniper quadratica classicatore bayes distribuzioni multinormali
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#15,15,"Altri Esempi di Superfici Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadraticheStessa Matrice di Covarianza: Iper-piani
Iper-piano: sottospazio di dimensione inferiore di uno rispetto allo spazio in cui è 
contenuto",altri esempi superfici decisionali prof davide maltoni universit bologna esempi superfici decisionali stessa matrice covarianza iper piani differenti matrici covarianza iper quadratiche stessa matrice covarianza iper piani iper piano sottospazio dimensione inferiore rispetto spazio contenuto
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#16,16,"Altri Esempi di Superﬁci Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadratiche
Differenti Matrici di Covarianza: Iper-quadratiche
Iper-quadratica: (iper -)superficie di uno spazio d -dimensionale sui complessi o sui 
reali rappresentata da un'equazione polinomiale del secondo ordine nelle variabili 
spaziali (coordinate)",altri esempi superci decisionali prof davide maltoni universit bologna esempi superfici decisionali stessa matrice covarianza iper piani differenti matrici covarianza iper quadratiche differenti matrici covarianza iper quadratiche iper quadratica iper superficie spazio dimensionale complessi reali rappresentata unequazione polinomiale secondo ordine variabili spaziali coordinate
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#17,17,"Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
Obiettivo: stimare la classe di appartenenza del pattern x (57,168)",esempio bayes parametrico multinormali prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training set prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training set obiettivo stimare classe appartenenza pattern
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#18,18,"17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:",prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training setesempio bayes parametrico multinormali prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training set prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training set
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#19,19,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:",prof davide maltoni universit bologna supponendo avere altre informazioni possono stimare probabilit priori come exp xx dwp exp xx peso altezza wis xxxp xxxp pesempio bayes parametrico multinormali prof davide maltoni universit bologna classificazione maschifemmine bayes parametrico multinormali exp xx exp xx peso altezza stima parametri training set
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#2,2,"Richiami
!Premessa :lanozione diautovalore siriferisce alle sole matrici
quadrate ,ossia alle matrici aventi lostesso numero dirighe edi
colonne .
!Chiarito ciò,siaAuna matrice quadrata diordine nacoefficienti in
uncampo !(dove !potrebbe essere ilcampo ℝdeinumeri reali oil
campo ℂdeinumeri complessi ).
!Sidice cheloscalare λ0∈!èunautovalore della matrice quadrata
Aseesiste unvettore colonna non nullo v∈!ntale che
Av=λ0v
!Ilvettore vèdetto autovettore relativo all’autovalore λ0",richiami premessa lanozione diautovalore siriferisce sole matrici quadrate ossia matrici aventi lostesso numero dirighe edi colonne chiarito cisia auna matrice quadrata diordine nacoefficienti uncampo dove potrebbe essere ilcampo deinumeri reali oil campo deinumeri complessi sidice cheloscalare matrice quadrata aseesiste unvettore colonna nullo vntale avv ilvettore vdetto autovettore relativo allautovalore
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#20,20,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)",prof davide maltoni universit bologna supponendo avere altre informazioni possono stimare probabilit priori come exp xx dwp exp xx peso altezza wis xxxp xxxp pesempio bayes parametrico multinormali
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#21,21,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi",bayes condenza classicazione prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente figura esempio classi
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#22,22,"Bayes e Confidenza di Classificazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
",bayes confidenza classificazione prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente 
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#23,23,"Bayes Parametrico In Pratica
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.",bayes parametrico pratica prof davide maltoni universit bologna classificazione bayes parametrico pratica molto spesso sifanno ipotesi azzardate normalit densit diprobabilit classi delproblema senza aver eseguito nessuna verifica ciporta ottenere cattivi risultati pertanto dato unproblema conclassi edato untraining set deve essere innanzitutto valutata larispondenza allanormalit questo puessere fatto modo formale malkovich afifi kolmogorov smirnov modo empirico visualizzando invarimodi lenuvole dati esistono deitool gipredisposti perquesto tipo analisi finoa diverse componenti econfrontandoli conlecurve teoriche volta provata seppur vaga normalit distribuzioni sistimano apartire daidati vettore medio matrice dicovarianza maximum likelihood riguarda leprobabilit apriori possono essere estratte percentuale dicampioni cheneltraining setappartengono allediverse classi oincaso diassenza informazioni possono essere poste tutte uguali traloro ogni nuovo pattern daclassificare assegnato auna possibili classi inaccordo conlaregola bayes media ecovarianza oranote fukunaga statistical pattern recognition academic press prof davide maltoni universit bologna classificazione bayes parametrico pratica molto spesso sifanno ipotesi azzardate normalit densit diprobabilit classi delproblema senza aver eseguito nessuna verifica ciporta ottenere cattivi risultati pertanto dato unproblema conclassi edato untraining set deve essere innanzitutto valutata larispondenza allanormalit questo puessere fatto modo formale malkovich afifi kolmogorov smirnov modo empirico visualizzando invarimodi lenuvole dati esistono deitool gipredisposti perquesto tipo analisi finoa diverse componenti econfrontandoli conlecurve teoriche volta provata seppur vaga normalit distribuzioni sistimano apartire daidati vettore medio matrice dicovarianza maximum likelihood riguarda leprobabilit apriori possono essere estratte percentuale dicampioni cheneltraining setappartengono allediverse classi oincaso diassenza informazioni possono essere poste tutte uguali traloro ogni nuovo pattern daclassificare assegnato auna possibili classi inaccordo conlaregola bayes media ecovarianza oranote fukunaga statistical pattern recognition academic press
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#24,24,"Bayes Parametrico In Pratica
",bayes parametrico pratica
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#25,25,"Problemi Closed e Open Set
",problemi closed open set
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#26,26,"Problemi Closed e Open Set
",problemi closed open set
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#3,3,"Richiami
!E’utile osservare chesevèunautovettore relativo all’autovalore λ0,
allora anche %v,con%∈!e%≠0,èunautovettore relativo aλ0.
!Infatti moltiplicando ambo imembri della relazione
Av=λ0v
perloscalare %≠0,siottiene
%(Av)=%(λ0v)⟺A(%v)=λ0(%v)
!Ciòdimostra cheanche %vèunautovettore associato aλ0.",richiami eutile osservare relativo allautovalore allora relativo infatti moltiplicando ambo imembri relazione avv perloscalare siottiene cidimostra cheanche associato
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#4,4,"9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0Distribuzione Normale Multivariata (Multinormale)",prof davide maltoni universit bologna classificazione distribuzione normale multivariata multinormale notazione perevitare confusione utilizziamo apedicelindice pattern eove necessario adapice lacomponente scalare pattern esimo vettore componente esima delpattern esimo scalare densit diprobabilit distribuzione multinormale medio lamatrice covarianza assume ivettori ditipo colonna lapice trasposto litrasforma inrighe sono rispettivamente ildeterminante elinversa matrice dicovarianza sempre simmetrica edefinita positiva pertanto ammette inversa essendo simmetrica numero diparametri cheladefinisce elementi diagonali sono levarianze deirispettivi ovvero diagonali sono covarianze trae seesono statisticamente indipendenti seesono correlati positivamente seesono correlati negativamente distribuzione normale multivariata multinormale
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#5,5,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)",prof davide maltoni universit bologna classificazione grafica normale multivariata laforma distribuzione quella diunellisse controlla laposizione delcentro lallungamento larotazione dellellisse rispetto assi cartesiani sematrice dicovarianza diagonale multinormale definita prodotto dinormali intalcaso paralleli esnaive bayes classifier se come caso figura esono positivamente correlate quando aumenta aumenta anche seesono negativamente correlate quando aumenta cala paralleli agliautovettori dile diverse ellissi individuano luoghi punti densit costante distribuzione normale multivariata multinormale
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#6,6,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti (!12=0) 
non siavera in generale , iClassificatori Naïve Bayes sidimostrano lavorare bene su
molti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari",prof davide maltoni universit bologna classificazione grafica normale multivariata laforma distribuzione quella diunellisse controlla laposizione delcentro lallungamento larotazione dellellisse rispetto assi cartesiani sematrice dicovarianza diagonale multinormale definita prodotto dinormali intalcaso paralleli esnaive bayes classifier se come caso figura esono positivamente correlate quando aumenta aumenta anche seesono negativamente correlate quando aumenta cala paralleli agliautovettori dile diverse ellissi individuano luoghi punti densit costante distribuzione normale multivariata multinormale lassunzione chele variabili statisticamente indipendenti siavera generale classificatori nave bayes sidimostrano lavorare bene molti dataset tale motivo fraipipopolari
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#7,7,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2",distanza mahalanobis prof davide maltoni universit bologna classificazione distanza mahalanobis distanza mahalanobis definisce ibordi adensit costante inuna distribuzione multinormale tale distanza viene spesso utilizzata sostituzione distanza euclidea essendo ingrado componenti tenendo conto deirelativi spazi divariazione edella prof davide maltoni universit bologna classificazione distanza mahalanobis distanza mahalanobis definisce ibordi adensit costante inuna distribuzione multinormale tale distanza viene spesso utilizzata sostituzione distanza euclidea essendo ingrado componenti tenendo conto deirelativi spazi divariazione edella
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#8,8,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ!Vogliano eseguire la stima dei parametri tramite il Metodo della 
Massima Verosimiglianza ( Maximum Likelihood )campioni in blu
vettore medio da 
stimare in rosso",esempio stima esd prof davide maltoni universit bologna classificazione esempio stima dato untraining setdipattern dimensionali composto da elementi stima deiparametri permassima verosimiglianza maximum likelihood oinnotazione vettoriale dxn vogliano eseguire stima parametri tramite metodo massima verosimiglianza maximum likelihood campioni blu vettore medio stimare rosso
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#9,9,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ",esempio stima esd prof davide maltoni universit bologna classificazione esempio stima dato untraining setdipattern dimensionali composto da elementi stima deiparametri permassima verosimiglianza maximum likelihood oinnotazione vettoriale dxn 
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#0,0,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) ",sommario approccio parametrico distribuzione multi normale approccio parametrico parzen window
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#1,1,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉",appr occi parametrici stima densit prof davide maltoni universit bologna classificazione approcci parametrici stima densit vengono fatte ipotesi distribuzioni deipattern eledensit diprobabilit stimate direttamente daltraining set ilproblema stima accurata densit ritenuto damolti problema picomplesso classificazione pertanto risolvere sotto problema unproblema picomplesso dellintero compito ingenerale lastima densit affrontabile inspazi dimensionalit ridotta critica alcrescere dimensionalit curse ilvolume spazio aumenta cos tanto cheipattern diventato troppo sparsi stima densit laprobabilit di datipattern indipendenti laprobabilit chediquesti cadano attraverso ladistribuzione binomiale ilcuivalor medio assumendo laregione eche allinterno diessa 
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#10,10,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
Ricordiamo che x è il pattern da classificare, xisono i pattern del 
Training Set",parzen window soft kernel prof davide maltoni universit bologna classificazione parzen window soft kernel pratica invece difunzioni finestra ipercubo siutilizzano kernel function pisoftgrazie allequali ogni stima didensit inunintorno diinaccordo conladistanza dain modo lesuperfici decisionali risultano molto piregolari smoothed lekernel function devono essere funzioni densit sempre conintegrale sututto lospazio uguale autilizzando lafunzione multinormale ricordiamo pattern classificare xisono pattern training set
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#11,11,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili hanno più
probabilità diesserlo inunospazio apiùdimensioni .
Qualsiasi modello lineare può essere trasformato inunmodello non
lineare applicando ilkernel trick (stratagemma del kernel) almodello :
sostituendo lesuefeature (predittori) conunafunzione kernel .",kernel trick classification ovviamente possono essere usate separare classi potrebbero essere separate classificatore lineare altrimenti applicazione casi reale interesse possibile casi coordinate oggetti mappate spazio detto feature space utilizzando funzioni lineare chiamate feature function ilfeature chiamate feature function ilfeature space spazio fortemente due classi possono essere separate classificatore lineare quindi spazio iniziale viene rimappato nuovo spazio punto viene identificato classificatore poi viene riportato spazio iniziale illustrato figurafonte stefano cavuoti classification funzione combina quindi spazio iniziale caratteristiche originali oggetti spaz features potrebbe linea principio avere dimensione infinita causa fatto spazio molte dimensioni pratico utilizzare funzione generica trovare liperpiano separazione quindi vengono usate funzioni dette kernel identifica funzione tramite combinazione funzioni kernel fonte funzioni kernel famosa lib usa quattro possibili kernel fonte jpg kernel trick possiamo trasformare dati nell input space nuovo spazio detto feature space alta dimensionalit vettori prima linearmente separabili probabilit esserlo spazio dimensioni idati nellinput space inunnuovo spazio detto feature space ipattern prima linearmente separabili probabilit diesserlo inunospazio apidimensioni qualsiasi modello lineare pu essere trasformato inunmodello lineare applicando ilkernel trick stratagemma kernel almodello sostituendo lesuefeature predittori conunafunzione kernel
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#12,12,"Kernel Trick
!Le funzioni kernel sono usate per operare nello spazio delle 
feature senza calcolare le coordinate dei dati nello spazio di 
input, ma piuttosto calcolando il prodotto scalare fra le immagini 
di tutte le copie di dati nello spazio funzione!Tale operazione è spesso computazionalmente più economica 
che l’esplicito calcolo delle coordinate, in quanto il prodotto 
scalare gode di alcune proprietà speciali!Infatti spesso si può calcolare φ(xi)""φ(xj) senza prima calcolare il 
valore di φ in ogni punto [dove x è il pattern nell’ input space (con 
ddimensioni) e φ(x) è il corrispondente pattern nel feature space 
(con m>d dimensioni)!Le funzioni kernel sono state introdotte per sequenze di dati, 
grafi, testi, immagini e vettori",kernel trick funzioni kernel usate operare spazio feature senza calcolare coordinate dati spazio input piuttosto calcolando prodotto scalare fra immagini tutte copie dati spazio funzionetale operazione spesso economica lesplicito calcolo coordinate prodotto scalare gode alcune propriet spesso pu calcolare xixj senza prima calcolare valore ogni punto dove pattern nell input space con ddimensioni corrispondente pattern feature space con dimensionile funzioni kernel state introdotte sequenze dati grafi testi immagini vettori
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#13,13,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
In questo caso il valore 
dell’iperparametro h
non è legato alla 
lunghezza di uno 
spigolo dell’ipercubo, 
ma all’ ampiezza della 
funzione multinormale ",parzen window soft kernel prof davide maltoni universit bologna classificazione parzen window soft kernel pratica invece difunzioni finestra ipercubo siutilizzano kernel function pisoftgrazie allequali ogni stima didensit inunintorno diinaccordo conladistanza dain modo lesuperfici decisionali risultano molto piregolari smoothed lekernel function devono essere funzioni densit sempre conintegrale sututto lospazio uguale autilizzando lafunzione multinormale caso valore legato lunghezza spigolo dellipercubo all ampiezza funzione multinormale
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#14,14,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(N.B. In questo caso il valore dell’iperparametro hè legato alla lunghezza 
dello spigolo dell’ ipercubo )
(N.B. In questo caso il valore dell’iperparametro hè legato all’ampiezza della 
funzione multinormale )",esempio parzen window prof davide maltoni universit bologna classificazione maschifemmine bayes parzen window stima parametrica densit attraverso parzen window nellipotesi peso altezza peso altezza funzione kernel ipercubo grafico sinistra funzione kernel normale grafico destra wpx wpx wis xxxp xxxp wpx wpx wis xxxp xxxp pnb caso valore legato lunghezza spigolo dell ipercubo caso valore legato allampiezza funzione multinormale
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#15,15,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(con hlegato alla lunghezza dello spigolo dell’ ipercubo )
(con hlegato all’ampiezza della funzione normale )
Sipuò notare come nelcaso della Funzione Kernel normale ,lesuperfici
decisionali risultino molto piùregolari (smoothed)",esempio parzen window prof davide maltoni universit bologna classificazione maschifemmine bayes parzen window stima parametrica densit attraverso parzen window nellipotesi peso altezza peso altezza funzione kernel ipercubo grafico sinistra funzione kernel normale grafico destra wpx wpx wis xxxp xxxp wpx wpx wis xxxp xxxp prof davide maltoni universit bologna classificazione maschifemmine bayes parzen window stima parametrica densit attraverso parzen window nellipotesi peso altezza peso altezza funzione kernel ipercubo grafico sinistra funzione kernel normale grafico destra wpx wpx wis xxxp xxxp wpx wpx wis xxxp xxxp prof davide maltoni universit bologna classificazione maschifemmine bayes parzen window stima parametrica densit attraverso parzen window nellipotesi peso altezza peso altezza funzione kernel ipercubo grafico sinistra funzione kernel normale grafico destra wpx wpx wis xxxp xxxp wpx wpx wis xxxp xxxp pcon hlegato lunghezza spigolo dell ipercubo con hlegato allampiezza funzione normale sipu notare nelcaso funzione kernel normale lesuperfici decisionali risultino molto piregolari smoothed
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#16,16,"Riferimenti
!S.J. Russell, and P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!R. O. Duda, P. Hart, and D. G. Stork Pattern Classification , 
Wiley -Interscience, 2000.
!D. Maltoni, Machine Learning , Università di Bologna, 2021.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.",riferimenti russell norvig artificial intelligence modern approach pearson fukunaga statistical pattern recognition academic press duda hart stork pattern classification wiley interscience maltoni machine learning universit bologna bishop pattern recognition machine learning springer murphy machine learning probabilistic perspective press
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#17,17,"Matlab
Questo esempio mostra come eseguire la classificazione in Matlab tramite 
NaÏve Bayes Classifier
MATLAB > Help > Examples > Statistics and Machine Learning Toolbox > 
Classification
Dataset: Fisher’s Iris Data
Fisher's iris data consists of measurements on the sepal length, sepal width, 
petal length, and petal width for 150 iris specimens. There are 50 specimens 
from each of three species. Load the data and see how the sepal 
measurements differ between species. You can use the two columns 
containing sepal measurements.
load fisheriris
gscatter(meas(:,1), meas(:,2), species,'rgb','osd');
xlabel('Sepal length');
ylabel('Sepal width');
N = size(meas,1);
",matlab esempio mostra eseguire classificazione matlab tramite nave bayes classifier help examples statistics machine learning toolbox classification dataset fishers iris data fishers iris data consists measurements sepal length sepal width petal length petal width iris specimens specimens three species load data see sepal measurements differ species use two columns containing sepal measurements load fisheriris meas xlabelsepal length ylabelsepal width sizemeas
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#18,18,"Matlab
",matlab
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#19,19,"Matlab
Approccio Parametrico: modelliamo ciascuna variabile in ciascuna classe tramite 
una distribuzione Gaussiana. Ci calcoliamo il resubstitution error (errore sul 
training set, di solito stima ottimistica dell’errore reale sul test set) e il cross -
validation error (in cui si suddivide il training set in gruppi di eguale numerosità, 
si esclude iterativamente un gruppo alla volta e lo si cerca di predire con i gruppi 
non esclusi)
nbGau = fitcnb(meas(:,1:2), species);
nbGauResubErr = resubLoss(nbGau)
[x,y] = meshgrid(4:.1:8,2:.1:4.5);
x = x(:);
y = y(:);
cp = cvpartition(species,'KFold',10)
nbGauCV = crossval(nbGau, 'CVPartition',cp);
nbGauCVErr = kfoldLoss(nbGauCV)
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbGauResubErr = 0.2200
nbGauCVErr = 0.2200
",matlab approccio parametrico modelliamo ciascuna variabile ciascuna classe tramite distribuzione gaussiana calcoliamo resubstitution error errore training set solito stima ottimistica dellerrore reale test set cross validation error suddivide training set gruppi eguale numerosit esclude iterativamente gruppo volta cerca predire gruppi esclusi gau species gau resub err resub lossnb gau fold gau crossvalnb gau gau err kfold lossnb gau labels predictnb gau gau resub err gau err
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#2,2,"Appr occi Non Parametrici e Stima della Densità
L'ipercubo (o n-cubo) è una forma geometrica regolare immersa in 
uno spazio di quattro o piùdimensioni
",appr occi parametrici stima densit lipercubo cubo forma geometrica regolare immersa spazio quattro pidimensioni
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#20,20,"Matlab
Approccio Non Parametrico: in questo caso modelliamo ciascuna variabile in 
ciascuna classe tramite una stima della densità di probabilità mediante funzione 
kernel (settata a ‘box’)
nbKD = fitcnb(meas(:,1:2), species, 'DistributionNames','kernel', 'Kernel','box');
nbKDResubErr = resubLoss(nbKD)
nbKDCV = crossval(nbKD, 'CVPartition',cp);
nbKDCVErr = kfoldLoss(nbKDCV)
labels = predict(nbKD, [x y]);
gscatter(x,y,labels,'rgb','osd')
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbKDResubErr = 0.2067
nbKDCVErr = 0.2133
",matlab approccio parametrico caso modelliamo ciascuna variabile ciascuna classe tramite stima densit probabilit mediante funzione kernel settata box species distribution resub err resub lossnb crossvalnb err kfold lossnb labels predictnb labels predictnb gau resub err err
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#21,21,"Esercizio 1
5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 ",esercizio date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#22,22,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 ",esercizio date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#23,23,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 ",esercizio date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#24,24,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 ",esercizio date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#25,25,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  ",esercizio data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#26,26,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  ",esercizio data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#27,27,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  ",esercizio data rete neurale livelli bias composta neuroni linput layer neuroni lhidden layer neuroni output somme moltiplicazioni necessarie passo forward generico pattern trascurando operazioni effettuate funzione attivazione motivare rispost riportando numero operazioni livello svolgimento ogni neurone livello corrente deve calcolare seguente formula comprende moltiplicazione somma ogni neurone livello precedente somma finale bias pertanto numero operazioni ivello hidden numero operazioni livello output totale dato insieme pattern dimensionali composto elementi calcolare vettore medio matrice covarianza ricorda ogni elemento matrice covarianza pu essere calcolato x lm esimo elemento esimo pattern numero pattern svolgimento machine learning matricola gen minuti cognome nome neuroni livello corrente somma bias somma ogni neurone livello precedente moltiplicazione ogni neurone livello precedente calcolo lato eseguito rascurando fatto ottimizzata sommatoria potrebbe evitare somma primo elemento sommatoria somma
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#28,28,"Esercizio 3
7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  ",esercizio date tre distribuzioni multinormali identificate seguenti parametri i matrice identit indicare classe assegnata seguenti pattern classificatore bayes multinormale motivandone risposta svolgimento regola classificazione bayes assegna pattern classe massima probabilit posteriori dato probabilit priori tre distribuzioni stessa determinare classe probabilit posteriori massima equivale individuare classe densit probabilit condizionale massima pertanto sapendo densit probabilit condizionale distribuzione multinormale tre matrici covarianza uguali matrice identit classe restituita classificatore bayes valore minimo che corrisponde distanza euclidea quadrato pattern vettore medio viene assegnato classe mentre viene assegnato classe date tre distribuzioni multinormali identificate seguenti parametri i matrice identit indicare classe assegnata seguenti pattern classificatore bayes multinormale motivandone risposta svolgimento regola classificazione bayes assegna pattern classe massima probabilit posteriori dato probabilit priori tre distribuzioni stessa determinare classe probabilit posteriori massima equivale individuare classe densit probabilit condizionale massima pertanto sapendo densit probabilit condizionale distribuzione multinormale tre matrici covarianza uguali matrice identit classe restituita classificatore bayes valore minimo che corrisponde distanza euclidea quadrato pattern vettore medio viene assegnato classe mentre viene assegnato classe
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#29,29,"Esercizio 37) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  ",esercizio date tre distribuzioni multinormali identificate seguenti parametri i matrice identit indicare classe assegnata seguenti pattern classificatore bayes multinormale motivandone risposta svolgimento regola classificazione bayes assegna pattern classe massima probabilit posteriori dato probabilit priori tre distribuzioni stessa determinare classe probabilit posteriori massima equivale individuare classe densit probabilit condizionale massima pertanto sapendo densit probabilit condizionale distribuzione multinormale tre matrici covarianza uguali matrice identit classe restituita classificatore bayes valore minimo che corrisponde distanza euclidea quadrato pattern vettore medio viene assegnato classe mentre viene assegnato classe
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#3,3,"Appr occi Non Parametrici e Stima della Densità
!In Teoria della Probabilità, la distribuzione binomiale è una 
distribuzione di probabilità discreta che descrive il numero di 
successi in un processo di Bernoulli!Tale processo vale nel caso di esperimenti di prove ripetute (i.e., 
esperimenti in cui si vuole misurare quante volte si verifichi un 
certo esito su tutte le prove effettuate)!E’ necessario che il risultato di una prova non influenzi le 
successive, ossia che le singole prove siano fra loro indipendenti!La formula da utilizzare in questi casi è la Formula di Bernoulli : 
se l’evento da noi indagato ha una probabilità p di verificarsi per 
ciascuna prova ed effettuiamo n prove indipendenti, la probabilità 
che l’evento si verifichi kvolte (con k ≤ n) è data da
P(k successi su n prove)=n
k⎛
⎝⎜⎜⎞
⎠⎟⎟pk⋅(1−p)n−k",appr occi parametrici stima densit teoria probabilit distribuzione binomiale distribuzione probabilit discreta descrive numero successi processo bernoullitale processo vale caso esperimenti prove ripetute esperimenti vuole misurare volte verifichi certo esito tutte prove effettuatee necessario risultato prova influenzi successive ossia singole prove fra indipendentila formula utilizzare casi formula bernoulli levento indagato probabilit verificarsi ciascuna prova effettuiamo prove indipendenti probabilit levento verifichi kvolte con data successi proven pkpnk
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#30,30,"Esercizio 4 
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
  
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 ",esercizio composto classificatori combinati livello decisione utilizzando borda count tecnica fusione viene utilizzato riconoscere pattern appartenenti classi tabella seguente riportati ranking restituit singoli classificatori dati input diversi pattern completare tabella nellipotesi prima classe assegnati punti seconda terza quarta punteggi classi classe scelta data rete neurale livelli bias composta neuroni input neuroni intermedi neuroni output calcolare motivandone risposta numero pesi totale svolgimento caso rete neurale numero pesi pari numero connessioni presenti numero connessioni quindi pesi presenti due livelli consecutivi pu calcolare prodotto numero neuroni livello numero neuroni livello caso dellutilizzo bias numero neuroni ogni livello dovr essere incrementato pertanto numero totale pesi pari date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale machine learning matricola lug minuti cognome nome composto classificatori combinati livello decisione utilizzando borda count tecnica fusione viene utilizzato riconoscere pattern appartenenti classi tabella seguente riportati ranking restituit singoli classificatori dati input diversi pattern completare tabella nellipotesi prima classe assegnati punti seconda terza quarta punteggi classi classe scelta data rete neurale livelli bias composta neuroni input neuroni intermedi neuroni output calcolare motivandone risposta numero pesi totale svolgimento caso rete neurale numero pesi pari numero connessioni presenti numero connessioni quindi pesi presenti due livelli consecutivi pu calcolare prodotto numero neuroni livello numero neuroni livello caso dellutilizzo bias numero neuroni ogni livello dovr essere incrementato pertanto numero totale pesi pari date due distribuzioni multinormali identificate seguenti parametri nellipotesi dellimpiego classificatore bayes multinormale calcolare punto densit probabilit condizionali probabilit posteriori lindice classe restituita output ricorda densit probabilit caso distribuzione multinormale machine learning matricola lug minuti cognome nome
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#31,31,"Esercizio 4
Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 ",esercizio svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#32,32,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 ",esercizio svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#33,33,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 ",esercizio svolgimento densit probabilit condizionale data densit probabilit condizionale data densit probabilit assoluta dato probabilit posteriori dato probabilit posteriori dato indice classe restituita
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#34,34,"Si supponga di partecipare a un gioco 
a premi, in cui si può scegliere fra tre 
porte: dietro una di esse c’è 
un’automobile, dietro le altre, due 
capre. 
Si sceglie una porta, diciamo la numero 
1. A quel punto, il conduttore del gioco 
a premi, che sa cosa si nasconde 
dietro ciascuna porta, ne apre un’altra, 
diciamo la 3, rivelando una capra. 
Quindi domanda: “vorresti scegliere la 
numero 2 o conservare la tua scelta 
iniziale?”
Ti conviene cambiare la tua scelta 
originale?
Problema",supponga partecipare gioco premi pu scegliere fra tre porte dietro esse c unautomobile dietro altre due capre sceglie porta diciamo numero quel punto conduttore gioco premi cosa nasconde dietro ciascuna porta apre unaltra diciamo rivelando capra quindi domanda vorresti scegliere numero conservare scelta iniziale conviene cambiare scelta originale problema
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#35,35,"Dal quiz televisivo americano Let’s Make a Deal , 
condotto dal presentatore Maurice Halprin , noto
con lo pseudonimo di Monty Hall. 
4500 puntate dal 1963 al 1991.
Il concorrente deve scegliere una delle tre
porte chiuse cheha davanti a sé: dietro a due 
di esse c’èuna capra , dietro l’altra c’èuna 
automobile . 
Ovviamente , né luiné ilpubblico sanno dietro
a quale porta sitrova l’auto .
Il concorrente fa la suascelta .
Problema di Monty Hall",quiz televisivo americano lets make deal condotto presentatore maurice halprin noto pseudonimo monty hall puntate concorrente deve scegliere tre porte chiuse cheha davanti dietro due esse cuna capra dietro laltra cuna automobile ovviamente luin ilpubblico sanno dietro porta sitrova lauto concorrente suascelta problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#36,36,"A questo punto, ilpresentatore apre
una delle altre due porte , rivelando
una capra .
Quindi chiede al concorrente se vuole
mantenere la porta scelta , o se vuole
cambiarla .
Domanda : al concorrente conviene
cambiare ? 
La risposta sembra ovvia : sono rimaste
due porte , e dietro una di esse c’è
l’auto . Cambiare porta non dovrebbe
influenzare le probabilità di vincita chea 
questo punto èlogico ritenere pari a 1/2, 
chesidecida di cambiare o meno .Problema di Monty Hall",punto ilpresentatore apre altre due porte rivelando capra quindi chiede concorrente vuole mantenere porta scelta vuole cambiarla domanda concorrente conviene cambiare risposta sembra ovvia rimaste due porte dietro esse c lauto cambiare porta dovrebbe influenzare probabilit vincita chea punto logico ritenere pari chesidecida cambiare meno problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#37,37,Problema di Monty Hall,problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#38,38,Problema di Monty Hall,problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#39,39,Problema di Monty Hall,problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#4,4,"Appr occi Non Parametrici e Stima della Densità
!Esempi di casi di distribuzione binomiale sono i risultati di una 
serie di lanci di una stessa moneta o di una serie di estrazioni 
da un'urna (con reintroduzione o reimbussolamento), ognuna 
delle quali può fornire due soli risultati : il successo con 
probabilità pe il fallimento con probabilità q=1−p!Reimbussolamento: dovendo estrarre un certo numero di 
carte/palline/numeri da un mazzo/urna/bussolo, ogni oggetto 
estratto è immesso nuovamente prima di estrarre 
carte/palline/numeri successivi",appr occi parametrici stima densit esempi casi distribuzione binomiale risultati serie lanci stessa moneta serie estrazioni unurna con reintroduzione ognuna quali pu fornire due soli risultati successo probabilit fallimento probabilit dovendo estrarre certo numero ogni oggetto estratto immesso nuovamente prima estrarre successivi
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#40,40,"h""ps ://www.youtube.com /watch?v =nYX8DMG8_ywProblema di Monty Hall",hps watchv gyw problema monty hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#5,5,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉",appr occi parametrici stima densit prof davide maltoni universit bologna classificazione approcci parametrici stima densit vengono fatte ipotesi distribuzioni deipattern eledensit diprobabilit stimate direttamente daltraining set ilproblema stima accurata densit ritenuto damolti problema picomplesso classificazione pertanto risolvere sotto problema unproblema picomplesso dellintero compito ingenerale lastima densit affrontabile inspazi dimensionalit ridotta critica alcrescere dimensionalit curse ilvolume spazio aumenta cos tanto cheipattern diventato troppo sparsi stima densit laprobabilit di datipattern indipendenti laprobabilit chediquesti cadano attraverso ladistribuzione binomiale ilcuivalor medio assumendo laregione eche allinterno diessa 
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#6,6,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro",parzen window prof davide maltoni universit bologna classificazione parzen window laregione denominata finestra window costituita daun ipercubo dimensionale definito funzione dato ungenerico ipercubo centrato ineavente latoequindi dipattern deltraining setchecadono allinterno delliper cubo dato sostituendo vedi lucido precedente siottiene dove ovviamente specie nelcaso incuiilnumero dipattern elevato ladimensione illatohaun forte impatto sulrisultato infatti lafinestra piccola lastima risulta piuttosto rumorosa molto attratta daicampioni instabile lafinestra grande lastima pistabile mapiuttosto vaga esfuocata sidimostra perottenere convergenza ladimensione finestra deve essere calcolata tenendo conto numero campioni deltraining set 
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#7,7,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro",parzen window prof davide maltoni universit bologna classificazione parzen window laregione denominata finestra window costituita daun ipercubo dimensionale definito funzione dato ungenerico ipercubo centrato ineavente latoequindi dipattern deltraining setchecadono allinterno delliper cubo dato sostituendo vedi lucido precedente siottiene dove ovviamente specie nelcaso incuiilnumero dipattern elevato ladimensione illatohaun forte impatto sulrisultato infatti lafinestra piccola lastima risulta piuttosto rumorosa molto attratta daicampioni instabile lafinestra grande lastima pistabile mapiuttosto vaga esfuocata sidimostra perottenere convergenza ladimensione finestra deve essere calcolata tenendo conto numero campioni deltraining set prof davide maltoni universit bologna classificazione parzen window laregione denominata finestra window costituita daun ipercubo dimensionale definito funzione dato ungenerico ipercubo centrato ineavente latoequindi dipattern deltraining setchecadono allinterno delliper cubo dato sostituendo vedi lucido precedente siottiene dove ovviamente specie nelcaso incuiilnumero dipattern elevato ladimensione illatohaun forte impatto sulrisultato infatti lafinestra piccola lastima risulta piuttosto rumorosa molto attratta daicampioni instabile lafinestra grande lastima pistabile mapiuttosto vaga esfuocata sidimostra perottenere convergenza ladimensione finestra deve essere calcolata tenendo conto numero campioni deltraining set prof davide maltoni universit bologna classificazione parzen window laregione denominata finestra window costituita daun ipercubo dimensionale definito funzione dato ungenerico ipercubo centrato ineavente latoequindi dipattern deltraining setchecadono allinterno delliper cubo dato sostituendo vedi lucido precedente siottiene dove ovviamente specie nelcaso incuiilnumero dipattern elevato ladimensione illatohaun forte impatto sulrisultato infatti lafinestra piccola lastima risulta piuttosto rumorosa molto attratta daicampioni instabile lafinestra grande lastima pistabile mapiuttosto vaga esfuocata sidimostra perottenere convergenza ladimensione finestra deve essere calcolata tenendo conto numero campioni deltraining set 
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#8,8,"Iperparametri
14prof. Davide Maltoni –Università di Bologna
ML
FondamentiIperparametri
Molto
 algoritmi richiedono didefinire, primadell’apprendimento
vero eproprio, ilvalore deicosiddetti iperparametri H.
Esempi
 diiperparametri :
Il
numero dineuroni inunareteneurale .
Il
numero divicini kinunclassificatore k-NN.
Il
grado diunpolinomio utilizzato inunaregressione .
Il
tipodilossfunction .
Si
procede con unapproccio adue livelli nelquale perogni
valore «ragionevole » degli iperparametri si esegue
l’apprendimento, ealtermine della procedura siscelgono gli
iperparametri chehanno fornito prestazioni migliori .
Ma
come sivalutano leprestazioni ,esuquali dati?",iperparametri prof davide maltoni universit bologna fondamenti iperparametri molto algoritmi richiedono didefinire vero eproprio ilvalore deicosiddetti iperparametri esempi diiperparametri numero dineuroni numero divicini grado diunpolinomio utilizzato procede unapproccio adue livelli nelquale perogni valore ragionevole iperparametri esegue ealtermine procedura siscelgono iperparametri chehanno fornito prestazioni migliori sivalutano leprestazioni esuquali dati
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#9,9,"Iperparametri
!Ricordiamo che
!Il Training Set è l’insieme di pattern su cui addestrare il 
sistema, trovando il valore ottimo per i parametri (e.g., i pesi 
delle connessioni in una rete neurale)!Il Validation Set è l’insieme di pattern su cui tarare gli 
iperparametri (ciclo esterno)!Il Test Set è l’insieme di pattern su cui valutare le prestazioni 
finali del sistema
!N.B. Sempre forte è la tentazione di tarare gli iperparametri 
direttamente sul Test Set, ma questo dovrebbe essere evitato, 
pena sovrastima delle prestazioni! ",iperparametri ricordiamo training set linsieme pattern addestrare sistema trovando valore ottimo parametri pesi connessioni rete neuraleil validation set linsieme pattern tarare iperparametri ciclo esternoil test set linsieme pattern valutare prestazioni finali sistema sempre forte tentazione tarare iperparametri direttamente test set dovrebbe essere evitato pena sovrastima prestazioni
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2019 -2020
Bayes & Nearest Neighbor",machine learning universit roma tre dipartimento ingegneria anno accademico bayes nearest neighbor
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#1,1,"Classiﬁcatore Nearest Neighbor (NN)
",classicatore nearest neighbor
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#10,10,"Da NN a k-NN
",
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#11,11,"Da NN a k-NN
28prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDa NN a k-NN
La
regola nearest neighbor produce unpartizionamento dello
dello spazio, noto come tassellazione diVoronoi :
Ogni elemento 𝐱𝑖∈TSdetermina untassello, all’interno delquale i
pattern saranno assegnati allastessa classe di𝐱𝑖.
La
regola diclassificazione nearest neighbor èpiuttosto radicale ;
infatti basta che unelemento deltraining setnon siamolto
“affidabile” (outlier )affinché tuttiipattern nelle suevicinanze siano
inseguito etichettati noncorrettamente .
Che
 errore commette ilclassificatore NNsultraining set?
Un
modo generalmente piùrobusto ,chepuòessere visto come
estensione della regola nearest -neighbor (inquesto caso detta
1-nearest neighbor )èilcosiddetto classificatore k-nearest
neighbor (k-NN).
",prof davide maltoni universit bologna classificazione regola nearest neighbor produce spazio noto tassellazione voronoi ogni elemento t sdetermina untassello allinterno delquale pattern assegnati allastessa classe di regola nearest neighbor piuttosto radicale infatti basta unelemento deltraining setnon siamolto affidabile outlier affinch tuttiipattern suevicinanze inseguito etichettati errore commette nsultraining set modo generalmente pirobusto chepuessere visto estensione regola nearest neighbor inquesto caso detta nearest neighbor ilcosiddetto classificatore nearest neighbor
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#12,12,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi.",nearest neighbor prof davide maltoni universit bologna nearest neighbor regola nearest neighbor ndetermina ikelementi vicini ogni pattern traikvicini vota perlaclasse cuiesso stesso appartiene ilpatternviene assegnato allaclasse chehaottenuto ilmaggior numero divoti sinfiniti laregola nsidimostra migliore eallaumentare diklerrore pconverge allerrore bayesiano pratica slimitati aumentare ksignifica estendere liper sfera diricerca andando asondare laprobabilit aposteriori lontano dalpunto diinteresse ilvalore ottimale diksolitamente deve essere determinato suunvalidation setseparato figura classificatore assegna alla classe nera questultima ricevuto voti caso classi bene scegliere dispari evitare pareggi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#13,13,"k-Nearest Neighbor ( k-NN)4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)",nearest neighbor examining labels knearest neighbors taking vote fig shall thorough analysis nearest neighbor rule however considering two class case kodd avoid ties gain additional insight procedures figure nearest neighbor query starts test point grows spher ical region encloses ktraining samples labels test point majority vote samples case test point xwould labelled category black points basic motivation considering nearest neighbor rule rests ear lier observation matching probabilities nature notice rst kis xed number nof samples allowed approach innity theknearest neighbors converge hence single nearest neighbor cases labels nearest neighbors random variables dependently assume values iwith probabilities pixi pmx larger posteriori probability bayes decision rule always selects single nearest neighbor rule selects mwith probability pmx nearest neighbor rule selects mif majority knearest neighbors labeled event probability general larger value greater probability mwill selected could analyze nearest neighbor rule much way analyzed single nearest neighbor rule however since arguments become involved supply little additional insight shall content stating results shown kis odd large sample two class error rate thek nearest neighbor rule bounded function ckp ckp dened smallest concave function pgreater
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#14,14,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi.",nearest neighbor prof davide maltoni universit bologna nearest neighbor regola nearest neighbor ndetermina ikelementi vicini ogni pattern traikvicini vota perlaclasse cuiesso stesso appartiene ilpatternviene assegnato allaclasse chehaottenuto ilmaggior numero divoti sinfiniti laregola nsidimostra migliore eallaumentare diklerrore pconverge allerrore bayesiano pratica slimitati aumentare ksignifica estendere liper sfera diricerca andando asondare laprobabilit aposteriori lontano dalpunto diinteresse ilvalore ottimale diksolitamente deve essere determinato suunvalidation setseparato figura classificatore assegna alla classe nera questultima ricevuto voti caso classi bene scegliere dispari evitare pareggi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#15,15,"k-Nearest Neighbor ( k-NN)28 CHAPTER 4. NONPARAMETRIC TECHNIQUES
Here the summation over the ﬁrst bracketed term represents the probability of error
due to ipoints coming from the category having the minimum probability and k−i>i
points from the other category. The summation over the second term in the brackets
is the probability that k−ipoints are from the minimum-probability category and
i+1<k−ifrom the higher probability category. Both of these cases constitute
errors under the k-nearest-neighbor decision rule, and thus we must add them to ﬁnd
the full probability of error (Problem 18).
Figure 4.16 shows the bounds on the k-nearest-neighbor error rates for several
values of k. As kincreases, the upper bounds get progressively closer to the lower
bound — the Bayes rate. In the limit as kgoes to inﬁnity, the two bounds meet and
thek-nearest-neighbor rule becomes optimal.
0 0.1 0.2 0.3 0.40.10.20.30.4
Bayes Rate
P*P
1
3
5
9
150.5
Figure 4.16: The error-rate for the k-nearest-neighbor rule for a two-category problem
is bounded by Ck(P∗) in Eq. 55. Each curve is labelled by k; when k=∞, the
estimated probabilities match the true probabilities and thus the error rate is equal
to the Bayes rate, i.e., P=P∗.
At the risk of sounding repetitive, we conclude by commenting once again on the
ﬁnite-sample situation encountered in practice. The k-nearest-neighbor rule can be
viewed as another attempt to estimate the a posteriori probabilities P(ωi|x) from
samples. We want to use a large value of kto obtain a reliable estimate. On the
other hand, we want all of the knearest neighbors x′to be very near xto be sure
thatP(ωi|x′) is approximately the same as P(ωi|x). This forces us to choose a
compromise kthat is a small fraction of the number of samples. It is only in the limit
asngoes to inﬁnity that we can be assured of the nearly optimal behavior of the
k-nearest-neighbor rule.
4.5.5 Computational Complexity of the k–Nearest-Neighbor
Rule
The computational complexity of the nearest-neighbor algorithm — both in space
(storage of prototypes) and time (search) — has received a great deal of analy-
sis. There are a number of elegant theorems from computational geometry on the
construction of Voronoi tesselations and nearest-neighbor searches in one- and two-
dimensional spaces. However, because the greatest use of nearest-neighbor techniques
is for problems with many features, we concentrate on the more general d-dimensional
case.
Suppose we have nlabelled training samples in ddimensions, and seek to ﬁnd
the closest to a test point x(k= 1). In the most naive approach we inspect each
stored point in turn, calculate its Euclidean distance to x, retaining the identity only
of the current closest one. Each distance calculation is O(d), and thus this search4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)Inparticolare ,sipuò dimostrare (vedi Duda etal.,2000 )che Ck(P*) èdefinita come
lapiùpiccola funzione concava diP*maggiore di",nearest neighbor summation rst bracketed term represents probability error due ipoints coming category minimum probability kii points category summation second term brackets probability kipoints minimum probability category ikifrom higher probability category cases constitute errors nearest neighbor decision rule thus must add nd full probability error problem figure shows bounds nearest neighbor error rates several values kincreases upper bounds get progressively closer lower bound bayes rate limit kgoes innity two bounds meet thek nearest neighbor rule becomes optimal bayes rate figure error rate nearest neighbor rule two category problem bounded ckp curve labelled estimated probabilities match true probabilities thus error rate equal bayes rate pp risk sounding repetitive conclude commenting nite sample situation encountered practice nearest neighbor rule viewed another attempt estimate posteriori probabilities pix samples want use large value kto obtain reliable estimate hand want knearest neighbors xto near xto sure pix approximately pix forces choose compromise kthat small fraction number samples limit asngoes innity assured nearly optimal behavior nearest neighbor rule computational complexity knearest neighbor rule computational complexity nearest neighbor algorithm space storage prototypes time search received great deal analy sis number elegant theorems computational geometry construction voronoi tesselations nearest neighbor searches one two dimensional spaces however greatest use nearest neighbor techniques problems many features concentrate general dimensional case suppose nlabelled training samples ddimensions seek nd closest test point naive approach inspect stored point turn calculate euclidean distance retaining identity current closest one distance calculation thus search examining labels knearest neighbors taking vote fig shall thorough analysis nearest neighbor rule however considering two class case kodd avoid ties gain additional insight procedures figure nearest neighbor query starts test point grows spher ical region encloses ktraining samples labels test point majority vote samples case test point xwould labelled category black points basic motivation considering nearest neighbor rule rests ear lier observation matching probabilities nature notice rst kis xed number nof samples allowed approach innity theknearest neighbors converge hence single nearest neighbor cases labels nearest neighbors random variables dependently assume values iwith probabilities pixi pmx larger posteriori probability bayes decision rule always selects single nearest neighbor rule selects mwith probability pmx nearest neighbor rule selects mif majority knearest neighbors labeled event probability general larger value greater probability mwill selected could analyze nearest neighbor rule much way analyzed single nearest neighbor rule however since arguments become involved supply little additional insight shall content stating results shown kis odd large sample two class error rate thek nearest neighbor rule bounded function ckp ckp dened smallest concave function pgreater sipu dimostrare vedi duda etal che ckp definita lapipiccola funzione concava pmaggiore
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#16,16,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
",esempi prof davide maltoni universit bologna classificazione esempi nellesempio visto precedenza regola assegna pattern alla classe femmine rossi lanimazione scomposta lucido successivo mostra partizionamento spazio operato regola training set classi visto precedenza variare peso altezza
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#17,17,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
",esempi prof davide maltoni universit bologna classificazione esempi nellesempio visto precedenza regola assegna pattern alla classe femmine rossi lanimazione scomposta lucido successivo mostra partizionamento spazio operato regola training set classi visto precedenza variare peso altezza
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#18,18,"Espansione Lucido Precedente (k=1,3)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11",espansione lucido precedente prof davide maltoni universit bologna classificazione espansione dellanimazione lucido precedente
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#19,19,"Espansione Lucido Precedente (k=5,7)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11",espansione lucido precedente prof davide maltoni universit bologna classificazione espansione dellanimazione lucido precedente
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#2,2,"Classiﬁcatore Nearest Neighbor (NN)
26prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore Nearest Neighbor (NN)
Data una metrica 𝑑𝑖𝑠𝑡(∙)nello spazio multidimensionale (es.
distanza euclidea )ilclassificarore nearest neighbor (letteralmente “il
piùvicino traivicini”),classifica unpattern𝐱conlastessa classe
dell’elemento 𝐱′adesso piùvicino neltraining setTS:
𝑑𝑖𝑠𝑡𝐱,𝐱′=𝑚𝑖𝑛
𝐱𝑖∈TS𝑑𝑖𝑠𝑡𝐱,𝐱𝑖
Invece
 diderivare daidatiledistribuzioni condizionali delle classi
perpoifaruso della regola diBayes perlaclassificazione,
questo classificatore cerca inmodo piuttosto pragmatico di
massimizzare direttamente laprobabilità aposteriori ;infatti se𝐱′
èmolto vicino a𝐱èlecito supporre che:
𝑃𝑤𝑖𝐱≈𝑃𝑤𝑖𝐱′
In
effetti, sipuòdimostrare (solo però nelcaso diTSpopolato da
infiniti campioni) chelaprobabilità dierrore P(nella figura sotto)
della regola nearest neighbor nonèmaipeggiore deldoppio del
minimo errore possibile P*(quello Bayesiano ).
Nella
 pratica ,questo non significa però chel’approccio
Bayesiano fornisca sempre risultati migliori dinearest neighbor ,
infatti selastima delle densità condizionali èpoco accurata i
risultati delclassificatore Bayesiano possono essere peggiori .
",classicatore nearest neighbor prof davide maltoni universit bologna classificazione classificatore nearest neighbor data metrica nello spazio distanza euclidea nearest neighbor letteralmente il pivicino classe dellelemento adesso pivicino neltraining set t s invece diderivare condizionali classi perpoifaruso regola bayes classificatore cerca inmodo piuttosto pragmatico massimizzare direttamente laprobabilit aposteriori infatti se molto vicino alecito supporre che effetti sipudimostrare solo per nelcaso tspopolato infiniti campioni dierrore pnella figura sotto regola nearest neighbor nonmaipeggiore deldoppio minimo errore possibile pquello bayesiano pratica questo significa per chelapproccio bayesiano fornisca sempre risultati migliori dinearest neighbor infatti selastima densit condizionali poco accurata risultati bayesiano possono essere peggiori
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#20,20,"Espansione Lucido Precedente (k=9,11)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11",espansione lucido precedente prof davide maltoni universit bologna classificazione espansione dellanimazione lucido precedente
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#21,21,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi",esempi bayes prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente figura esempio classi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#22,22,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi",bayes condenza classicazione prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente figura esempio classi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#23,23,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
",bayes condenza classicazione prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#24,24,"k-NN e Conﬁdenza di Classiﬁcazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
",condenza classicazione prof davide maltoni universit bologna confidenza classificazione nrisulta piuttosto semplice estrarre confidenza circa eseguita siano ivotiottenuti leconfidenze vedi sfumature figura sotto possono essere semplicemente ottenute dividendo 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#25,25,"k-NN e Confidenza di Classificazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
",confidenza classificazione prof davide maltoni universit bologna confidenza classificazione nrisulta piuttosto semplice estrarre confidenza circa eseguita siano ivotiottenuti leconfidenze vedi sfumature figura sotto possono essere semplicemente ottenute dividendo 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#26,26,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/",complessit computazionale prof davide maltoni universit bologna classificazione complessit computazionale lutilizzo nok nnelcaso ditraining setdi elevate dimensioni pudiventare problematico necessario memorizzare tuttiipattern training set ogni classificazione necessario calcolare ladistanza pattern daclassificare datutti ipattern deltraining sete ordinare parzialmente ledistanze perottenere lepipiccole tecniche diediting condensing lucido successivo possono alleviare problema maquando lefficienza importante consigliabile indicizzare idati attraverso strutture spaziali diindividuare ivicini senza effettuare scansione esaustiva lalibreria consente dieffettuare ricerche nearest neighbor approssimate molto efficientemente httpwww
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#27,27,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/
https ://github.com /mariusmuja /flann",complessit computazionale prof davide maltoni universit bologna classificazione complessit computazionale lutilizzo nok nnelcaso ditraining setdi elevate dimensioni pudiventare problematico necessario memorizzare tuttiipattern training set ogni classificazione necessario calcolare ladistanza pattern daclassificare datutti ipattern deltraining sete ordinare parzialmente ledistanze perottenere lepipiccole tecniche diediting condensing lucido successivo possono alleviare problema maquando lefficienza importante consigliabile indicizzare idati attraverso strutture spaziali diindividuare ivicini senza effettuare scansione esaustiva lalibreria consente dieffettuare ricerche nearest neighbor approssimate molto efficientemente httpwww https githubcom mariusmuja flann
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#28,28,"NN e Complessità ComputazionaleFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relative",complessit computazionale marius muja david lowe computer science department university british columbia vancouver canada lowecsubcca keywords nearest neighbors search randomized trees hierarchical means tree clustering abstract many computer vision problems time consuming component consists nearest neighbor match ing high dimensional spaces known exact algorithms solving high dimensional problems faster linear search approximate algorithms known provide large speedups minor loss accuracy many algorithms published minimal guidance selecting algorithm parameters given problem paper describe system answers question what fastest approximate nearest neighbor algorithm data system take given dataset desired degree precision use automatically determine best algorithm parameter values also describe new algorithm applies priority search hierarchical means trees found provide best known performance many datasets testing range alternatives found multiple randomized trees provide best performance datasets releasing public domain code implements approaches library provides one order magnitude improvement query time best previously available software provides fully automated parameter selection computationally expensive part many computer vision algorithms consists searching closest matches high dimensional vectors amples problems include nding best matches local image features large datasets lowe philbin clustering local features visual words using means sim ilar algorithms sivic zisserman forming normalized cross correlation compare age patches large datasets torralba nearest neighbor search problem also major importance many applications including chine learning document retrieval data compression bioinformatics data analysis dene nearest neighbor search prob lem follows given set points vector space points must preprocessed way given new query point qx nding points pthat nearest qcan formed efciently paper assume xis euclidean vector space appropriate problems computer vision scribe potential extensions approach general metric spaces although would cost efciency high dimensional spaces often known algorithms nearest neighbor search efcient simple linear search lin ear search costly many applications generated interest algorithms perform approximate nearest neighbor search optimal neighbors sometimes returned proximate algorithms orders magnitude faster exact search still providing near optimal accuracy hundreds papers published algorithms approximate nearest neighbor search little systematic comparison guide choice among algorithms set inter nal parameters one reason relative marius muja david lowe computer science department university british columbia vancouver canada lowecsubcca keywords nearest neighbors search randomized trees hierarchical means tree clustering abstract many computer vision problems time consuming component consists nearest neighbor match ing high dimensional spaces known exact algorithms solving high dimensional problems faster linear search approximate algorithms known provide large speedups minor loss accuracy many algorithms published minimal guidance selecting algorithm parameters given problem paper describe system answers question what fastest approximate nearest neighbor algorithm data system take given dataset desired degree precision use automatically determine best algorithm parameter values also describe new algorithm applies priority search hierarchical means trees found provide best known performance many datasets testing range alternatives found multiple randomized trees provide best performance datasets releasing public domain code implements approaches library provides one order magnitude improvement query time best previously available software provides fully automated parameter selection computationally expensive part many computer vision algorithms consists searching closest matches high dimensional vectors amples problems include nding best matches local image features large datasets lowe philbin clustering local features visual words using means sim ilar algorithms sivic zisserman forming normalized cross correlation compare age patches large datasets torralba nearest neighbor search problem also major importance many applications including chine learning document retrieval data compression bioinformatics data analysis dene nearest neighbor search prob lem follows given set points vector space points must preprocessed way given new query point qx nding points pthat nearest qcan formed efciently paper assume xis euclidean vector space appropriate problems computer vision scribe potential extensions approach general metric spaces although would cost efciency high dimensional spaces often known algorithms nearest neighbor search efcient simple linear search lin ear search costly many applications generated interest algorithms perform approximate nearest neighbor search optimal neighbors sometimes returned proximate algorithms orders magnitude faster exact search still providing near optimal accuracy hundreds papers published algorithms approximate nearest neighbor search little systematic comparison guide choice among algorithms set inter nal parameters one reason relative marius muja david lowe computer science department university british columbia vancouver canada lowecsubcca keywords nearest neighbors search randomized trees hierarchical means tree clustering abstract many computer vision problems time consuming component consists nearest neighbor match ing high dimensional spaces known exact algorithms solving high dimensional problems faster linear search approximate algorithms known provide large speedups minor loss accuracy many algorithms published minimal guidance selecting algorithm parameters given problem paper describe system answers question what fastest approximate nearest neighbor algorithm data system take given dataset desired degree precision use automatically determine best algorithm parameter values also describe new algorithm applies priority search hierarchical means trees found provide best known performance many datasets testing range alternatives found multiple randomized trees provide best performance datasets releasing public domain code implements approaches library provides one order magnitude improvement query time best previously available software provides fully automated parameter selection computationally expensive part many computer vision algorithms consists searching closest matches high dimensional vectors amples problems include nding best matches local image features large datasets lowe philbin clustering local features visual words using means sim ilar algorithms sivic zisserman forming normalized cross correlation compare age patches large datasets torralba nearest neighbor search problem also major importance many applications including chine learning document retrieval data compression bioinformatics data analysis dene nearest neighbor search prob lem follows given set points vector space points must preprocessed way given new query point qx nding points pthat nearest qcan formed efciently paper assume xis euclidean vector space appropriate problems computer vision scribe potential extensions approach general metric spaces although would cost efciency high dimensional spaces often known algorithms nearest neighbor search efcient simple linear search lin ear search costly many applications generated interest algorithms perform approximate nearest neighbor search optimal neighbors sometimes returned proximate algorithms orders magnitude faster exact search still providing near optimal accuracy hundreds papers published algorithms approximate nearest neighbor search little systematic comparison guide choice among algorithms set inter nal parameters one reason relative
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#29,29,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi non appartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x",prototipi classi prof davide maltoni universit bologna classificazione prototipi classi talvolta classificazione nearest neighbor invece dimantenere tuttiipattern tsecalcolare ladistanza daciascuno diessi preferisce daessi opi prototipi ciascuna classe eutilizzare ultimi sefossero isolielementi tsqueste tecniche prendono ilnome editing quando sicancellano solo pattern daltraining setsenza derivare nuovi pattern condensing seiprototipi appartenevano tsesono stati derivati cicomporta solitamente iseguenti vantaggi necessario calcolare unelevato numero didistanze iprototipi spesso piaffidabili erobusti disingoli pattern riduce ilrischio diaffidarsi adoutlier unsingolo prototipo diclasse pu essere derivato vettore medio deivettori diquella classe tsprocessi divector quantization oclustering consentono diottenere piprototipi perogni classe sebbene pattern vicino sia blu viene classificato rosso prototipo vicino rossox
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#3,3,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
",classicatore bayes prof davide maltoni universit bologna classificazione classificatore bayes dato cuisono note probabilit ledensit diprobabilit condizionali laregola bayes assegna massima laprobabilit aposteriori massimizzare laprobabilit aposteriori significa massimizzare densit diprobabilit condizionale tenendo comunque conto probabilit apriori classi regola sidimostra ottima inquanto minimizza lerrore classificazione adesempio nelcaso diclassi 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#30,30,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x",prototipi classi prof davide maltoni universit bologna classificazione prototipi classi talvolta classificazione nearest neighbor invece dimantenere tuttiipattern tsecalcolare ladistanza daciascuno diessi preferisce daessi opi prototipi ciascuna classe eutilizzare ultimi sefossero isolielementi tsqueste tecniche prendono ilnome editing quando sicancellano solo pattern daltraining setsenza derivare nuovi pattern condensing seiprototipi tsesono stati derivati cicomporta solitamente iseguenti vantaggi necessario calcolare unelevato numero didistanze iprototipi spesso piaffidabili erobusti disingoli pattern riduce ilrischio diaffidarsi adoutlier unsingolo prototipo diclasse pu essere derivato vettore medio deivettori diquella classe tsprocessi divector quantization oclustering consentono diottenere piprototipi perogni classe sebbene pattern vicino sia blu viene classificato rosso prototipo vicino rossox
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#31,31,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x",prototipi classi prof davide maltoni universit bologna classificazione prototipi classi talvolta classificazione nearest neighbor invece dimantenere tuttiipattern tsecalcolare ladistanza daciascuno diessi preferisce daessi opi prototipi ciascuna classe eutilizzare ultimi sefossero isolielementi tsqueste tecniche prendono ilnome editing quando sicancellano solo pattern daltraining setsenza derivare nuovi pattern condensing seiprototipi tsesono stati derivati cicomporta solitamente iseguenti vantaggi necessario calcolare unelevato numero didistanze iprototipi spesso piaffidabili erobusti disingoli pattern riduce ilrischio diaffidarsi adoutlier unsingolo prototipo diclasse pu essere derivato vettore medio deivettori diquella classe tsprocessi divector quantization oclustering consentono diottenere piprototipi perogni classe sebbene pattern vicino sia blu viene classificato rosso prototipo vicino rossox
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#32,32,"NN e Metriche
35prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Metriche
Il
comportamento della regola k-NNèstrettamente legato alla
metrica (funzione distanza )adottata .
La
distanza euclidea ,cherappresenta ilcaso L2nella definizione
dimetriche diMinkowski ,èsicuramente lametrica piùspesso
utilizzata .
𝐿𝑘𝐚,𝐛=෍
𝑖=1𝑑
𝑎𝑖−𝑏𝑖𝑘1/𝑘
Nella
 pratica ,prima diadottare semplicemente ladistanza
euclidea èbene valutare lospazio divariazione delle componenti
(ofeature )elapresenza dieventuali forti correlazioni trale
stesse .
Supponiamo
 adesempio divoler classificare lepersone sulla
basedell’altezza edella lunghezza delpiede .Ogni pattern𝐱
(bidimensionale) risulta costituito dadue feature (𝑥1=altezza,
𝑥2=lunghezza delpiede) .
Lospazio divariazione dell’altezza (210-140 =70cm) risulta
maggiore diquello della lunghezza delpiede (40-20=20cm).
Pertanto selasimilarità trapattern venisse misurata consemplice
distanza euclidea lacomponente altezza“peserebbe ”piùdella
componente lunghezza delpiede .𝑥2140 cm 210 cm𝑥1
20 cm40 cm",metriche prof davide maltoni universit bologna classificazione metriche comportamento regola nstrettamente legato metrica funzione distanza adottata distanza euclidea cherappresenta ilcaso lnella definizione dimetriche minkowski sicuramente lametrica pispesso utilizzata pratica prima diadottare semplicemente ladistanza euclidea bene valutare lospazio divariazione componenti ofeature elapresenza dieventuali forti correlazioni trale supponiamo adesempio divoler classificare lepersone edella lunghezza delpiede ogni pattern risulta costituito dadue feature altezza lunghezza delpiede lospazio divariazione dellaltezza risulta maggiore diquello lunghezza delpiede pertanto selasimilarit trapattern venisse misurata consemplice distanza euclidea lacomponente pidella componente lunghezza delpiede cm
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#33,33,"NN e Metriche
",metriche
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#34,34,"Normalizzazione
36prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNormalizzazione
Perevitare iproblemi legati adiversi spazi divariazioni delle feature ,
particolarmente fastidiosi peralcune tecniche (es.retineurali), si
consiglia dinormalizzare ipattern .
Lenormalizzazioni piùcomuni sono :
Min
-Max scaling :per ogni feature 𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcolano il
massimo 𝑚𝑎𝑥𝑖eilminimo𝑚𝑖𝑛𝑖esiapplica una trasformazione
lineare (scaling )che«tipicamente» mappa𝑚𝑖𝑛𝑖a0e𝑚𝑎𝑥𝑖a1.
𝑥′=𝑥−𝑚𝑖𝑛𝑖/𝑚𝑎𝑥𝑖−𝑚𝑖𝑛𝑖
Standardization
 :perogni feature𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcola lamedia
𝑚𝑒𝑎𝑛𝑖eladeviazione standard 𝑠𝑡𝑑𝑑𝑒𝑣 𝑖esitrasformano ivalori
come :
𝑥′=𝑥−𝑚𝑒𝑎𝑛𝑖/𝑠𝑡𝑑𝑑𝑒𝑣 𝑖
Dopo latrasformazione tutte lefeature hanno (sul training set)
media 0edeviazione standard 1.
Attenzione :iparametri della normalizzazione (es.minimi, massimi) si
calcolano sulsolo training setelatrasformazione siapplica siaatutti
idati(training, validation ,test).
Lesemplici tecniche sopra descritte operano sulle singole feature
indipendentemente .Una tecnica dinormalizzazione efficace (mapiù
costosa) che opera simultaneamente sututte lefeature tenendo
conto della lorocorrelazione èlaWhitening transform .",normalizzazione prof davide maltoni universit bologna classificazione normalizzazione perevitare iproblemi legati adiversi spazi divariazioni feature particolarmente fastidiosi peralcune tecniche consiglia dinormalizzare ipattern picomuni min max scaling per ogni feature sicalcolano massimo trasformazione lineare scaling standardization perogni feature sicalcola lamedia standard esitrasformano ivalori dopo tutte lefeature sul training set media edeviazione standard attenzione iparametri normalizzazione esminimi massimi calcolano sulsolo training siapplica siaatutti idatitraining validation test lesemplici tecniche sopra descritte operano singole feature una tecnica efficace mapi costosa opera simultaneamente sututte lefeature tenendo conto la whitening transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#35,35,"Normalizzazione
",normalizzazione
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#36,36,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, matraloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform",whitening transform prof davide maltoni universit bologna classificazione whitening transform unefficace normalizzazione rispetto spazi divariazione grado ditener conto correlazioni trafeature possibile pre normalizzando lospazio feature attraverso whitening transform che vedremo meglio inseguito utilizzando metrica ladistanza mahalanobis ledue alternative equivalenti nelprimo corrispondente allospazio feature apriori eviene inseguito usata ladistanza euclidea nelsecondo distanza mahalanobis normalizza ogni componente base matrice dicovarianza danon sottovalutare limportanza correlazione trafeatures aspetto negativo feature correlate riduce anche drasticamente ilpotere discriminante nelcaso ideale tutte lefeature staticamente indipendenti ellissoide assiparalleli aquelli cartesiani due feature altamente discriminanti seprese matraloro fortemente correlate nelcomplesso meno discriminanti diuna terza feature leggermente diognuna precedenti ladistanza mahalanobis spazio tiene conto correlazioni epesa maggiormente feature correlate distribuzione originaledopo whitening transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#37,37,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2",distanza mahalanobis prof davide maltoni universit bologna classificazione distanza mahalanobis distanza mahalanobis definisce ibordi adensit costante inuna distribuzione multinormale tale distanza viene spesso utilizzata sostituzione distanza euclidea essendo ingrado componenti tenendo conto deirelativi spazi divariazione edella prof davide maltoni universit bologna classificazione distanza mahalanobis distanza mahalanobis definisce ibordi adensit costante inuna distribuzione multinormale tale distanza viene spesso utilizzata sostituzione distanza euclidea essendo ingrado componenti tenendo conto deirelativi spazi divariazione edella
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#38,38,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, ma traloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform",whitening transform prof davide maltoni universit bologna classificazione whitening transform unefficace normalizzazione rispetto spazi divariazione grado ditener conto correlazioni trafeature possibile pre normalizzando lospazio feature attraverso whitening transform che vedremo meglio inseguito utilizzando metrica ladistanza mahalanobis ledue alternative equivalenti nelprimo corrispondente allospazio feature apriori eviene inseguito usata ladistanza euclidea nelsecondo distanza mahalanobis normalizza ogni componente base matrice dicovarianza danon sottovalutare limportanza correlazione trafeatures aspetto negativo feature correlate riduce anche drasticamente ilpotere discriminante nelcaso ideale tutte lefeature staticamente indipendenti ellissoide assiparalleli aquelli cartesiani due feature altamente discriminanti seprese traloro fortemente correlate nelcomplesso meno discriminanti diuna terza feature leggermente diognuna precedenti ladistanza mahalanobis spazio tiene conto correlazioni epesa maggiormente feature correlate distribuzione originaledopo whitening transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#39,39,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)",prof davide maltoni universit bologna classificazione grafica normale multivariata laforma distribuzione quella diunellisse controlla laposizione delcentro lallungamento larotazione dellellisse rispetto assi cartesiani sematrice dicovarianza diagonale multinormale definita prodotto dinormali intalcaso paralleli esnaive bayes classifier se come caso figura esono positivamente correlate quando aumenta aumenta anche seesono negativamente correlate quando aumenta cala paralleli agliautovettori dile diverse ellissi individuano luoghi punti densit costante distribuzione normale multivariata multinormale
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#4,4,"Classiﬁcatore Nearest Neighbor (NN)
Quando laprobabilità aposteriori diuna classe èvicina a1,la
probabilità dierrore Bayesiano P*èpiccola ,così come la
probabilità dierrore Pdella regola nearest neighbor .Quando
ciascuna classe èquasi ugualmente probabile ,siaBayes cheNN
hanno untasso dierrore ~(1-1/c),con cnumero diclassi .Nel
mezzo, iltasso dierrore NNèlimitato daltasso dierrore diBayes :
!∗≤!≤!∗2−%
%−1!∗(Eq.52)",classicatore nearest neighbor quando laprobabilit aposteriori diuna classe vicina ala probabilit dierrore bayesiano ppiccola cos probabilit dierrore pdella regola nearest neighbor quando ciascuna classe quasi ugualmente probabile sia bayes untasso dierrore ccon cnumero diclassi nel mezzo iltasso dierrore nlimitato daltasso dierrore bayes eq
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#40,40,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti
(!12=0) non siavera in generale , iClassificatori Naive Bayes sidimostrano lavorare
bene sumolti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari",prof davide maltoni universit bologna classificazione grafica normale multivariata laforma distribuzione quella diunellisse controlla laposizione delcentro lallungamento larotazione dellellisse rispetto assi cartesiani sematrice dicovarianza diagonale multinormale definita prodotto dinormali intalcaso paralleli esnaive bayes classifier se come caso figura esono positivamente correlate quando aumenta aumenta anche seesono negativamente correlate quando aumenta cala paralleli agliautovettori dile diverse ellissi individuano luoghi punti densit costante distribuzione normale multivariata multinormale lassunzione chele variabili statisticamente indipendenti siavera generale classificatori naive bayes sidimostrano lavorare bene sumolti dataset tale motivo fraipipopolari
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#41,41,Whitening Transform,whitening transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#42,42,"Metric Learning
38prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMetric Learning
Unapproccio piùgenerale allascelta della metrica dautilizzare in
unadeterminata applicazione, consiste nellearning supervisionato
della metrica stessa daidatideltraining set.
Obiettivo èdeterminare unatrasformazione degli input che:
«avvicini »pattern della stessa classe
«allontani »pattern diclassi diverse
Ladistanza euclidea nella spazio originale è:
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐚−𝐛𝑡𝐚−𝐛=𝐚−𝐛2
Untipico approccio dimetric learning lineare determina (con
training supervisionato) una matrice 𝐆che trasforma gliinput, e
continuare adapplicare ladistanza euclidea agliinput trasformati
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝐚−𝐆𝐛2
Vedremo una possibile soluzione diquesto problema nell’ambito
della riduzione didimensionalità con LDA (Linear Discriminant
Analysys ).
Sono anche possibili approcci nonlineari :
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝜙𝐚−𝐆𝜙𝐛2
dove𝜙èunafunzione nonlineare .",metric learning prof davide maltoni universit bologna classificazione metric learning unapproccio pigenerale allascelta metrica dautilizzare unadeterminata applicazione consiste nellearning supervisionato metrica stessa set obiettivo determinare input che avvicini pattern stessa classe allontani pattern diclassi diverse ladistanza euclidea spazio originale untipico approccio dimetric learning lineare determina con training supervisionato matrice che trasforma gliinput continuare adapplicare ladistanza euclidea agliinput trasformati vedremo possibile soluzione diquesto problema nellambito riduzione linear discriminant analysys possibili approcci nonlineari nonlineare
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#43,43,"Metric Learning
",metric learning
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#44,44,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋",similarit distanza coseno prof davide maltoni universit bologna classificazione similarit coseno distanza coseno piuttosto utilizzata inapplicazioni information retrieval data mining etext mining la coseno dati due coseno corrisponde tradiessi noto infatti cheilprodotto scalare traduevettori due vettori identici similarit eduevettori opposti ladistanza coseno semplicemente esempio confronto ditestiuntesto pu essere codificato daun vettore numerico ogni dimensione contiene ilnumero occorrenze diuna certa parola rispetto aundato dizionario similarit dicontenuto tradue testi dipende numero assoluto diparole madalla frequenza relativa diciascuna diesse ladistanza coseno sconta lalunghezza deivettori ladistanza coseno una metrica esnon rispetta diseguaglianza triangolare aunametrica sipu passare alladistanza angolare 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#45,45,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋",similarit distanza coseno prof davide maltoni universit bologna classificazione similarit coseno distanza coseno piuttosto utilizzata inapplicazioni information retrieval data mining etext mining la coseno dati due coseno corrisponde tradiessi noto infatti cheilprodotto scalare traduevettori due vettori identici similarit eduevettori opposti ladistanza coseno semplicemente esempio confronto ditestiuntesto pu essere codificato daun vettore numerico ogni dimensione contiene ilnumero occorrenze diuna certa parola rispetto aundato dizionario similarit dicontenuto tradue testi dipende numero assoluto diparole madalla frequenza relativa diciascuna diesse ladistanza coseno sconta lalunghezza deivettori ladistanza coseno una metrica esnon rispetta diseguaglianza triangolare aunametrica sipu passare alladistanza angolare 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#46,46,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (3 ed.) , Pearson, 2009.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. ",riferimenti russell norvig artificial intelligence modern approach pearson fukunaga statistical pattern recognition academic press maltoni machine learning universit bologna bishop pattern recognition machine learning springer murphy machine learning probabilistic perspective press duda hart stork pattern classification edition wiley interscience new york
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#5,5,"Esempi NN
",esempi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#6,6,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempi Bayes",prof davide maltoni universit bologna supponendo avere altre informazioni possono stimare probabilit priori come exp xx dwp exp xx peso altezza wis xxxp xxxp pesempi bayes
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#7,7,"Esempi NN
27prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi NN
Nell’esempio visto in precedenza, 
 la regola NN assegna il 
pattern 𝐱alla classe 𝑤1(maschi -blu)
La figura seguente mostra il partizionamento dello spazio 
operato dalla regola NN su un training set con 5 classi:
",esempi prof davide maltoni universit bologna classificazione esempi nellesempio visto precedenza regola assegna pattern alla classe maschi blu figura seguente mostra partizionamento spazio operato regola training set classi
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#8,8,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
",esempi bayes prof davide maltoni universit bologna classificazione bayes confidenza classificazione ungrande vantaggio bayes rispetto adaltri classificatori legato alfatto cheesso produce unvalore dioutput probabilistico unvero eproprio valore diprobabilit traecon somma sulle diverse classi che pu essere utilizzato confidenza visualizzata figura sfumatura colore infatti puassegnare condiversi livelli dicertezza oconfidenza chepossono essere impiegati per scartare pattern applicazioni open setcon soglia costruire multi classificatore interessati confidenza formula bayes necessario dividere il numeratore regola bayes semplicemente 
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#9,9,"Da NN a k-NN
",
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Classiﬁcatore Bayesiano (Ex 13)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione classicatore bayesiano
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#1,1,"Sommario
...",sommario
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#10,10,"Naive Bayes classiﬁer: step 2
Per ogni dataset ricaviamo 2 statistiche: media e deviazione standard. 
La media può essere ricavata così: 
 μ
 = sum(x)/n * count(x) 
    
dove x è la lista dei valori (o colonna) sui cui stiamo stimando la media.  
# Calculate the mean of a list of numbers
def mean
 (
numbers
)
:
return 
sum
(
numbers
)
/
float
(
len
(
numbers
))
Per la deviazione standard 
 σ
 si ha: 
 sqrt( 
Σ
i
(x
i
 – 
μ
(x))
2
 / N-1)  
from math import 
 sqrt
 
# Calculate the standard deviation of a list of numbers
def stdev
 (
numbers
)
:
avg
 = 
mean
(
numbers
)
variance
  = 
sum
([(
x
-
avg
)
**
2 
for 
x 
in 
numbers
])
 / 
float
(
len
(
numbers
)
-
1
)
return 
sqrt
(
variance
 )
Media e deviazione standard devono essere calcolate per ogni feature e 
considerando tutte le istanze.
11",naive bayes classier step ogni dataset ricaviamo statistiche media deviazione standard media pu essere ricavata cos sumxn countx lista valori colonna stimando media calculate mean list numbers def mean numbers return sum numbers float len numbers deviazione standard sqrt math import sqrt calculate standard deviation list numbers def stdev numbers avg mean numbers variance sum avg numbers float len numbers return sqrt variance media deviazione standard devono essere calcolate ogni feature considerando tutte istanze
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#11,11,"Naive Bayes classiﬁer: step 2
Media e deviazione standard devono essere calcolate per ogni feature e considerando 
tutte le istanze. 
La funzione 
 zip(*...)
  separa le colonne del dataset e restituisce una tupla per ogni 
colonna contenente i relativi valori delle features. 
 def summarize_dataset
 (
dataset
)
:
summaries
 =
[(
mean
(
column
),
stdev
(
column
),
len
(
column
)) 
for 
column 
in 
zip
(
*
dataset
)]
del
(
summaries
 [
-
1
])
return 
summaries
Ad esempio: 
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summary
 = 
summarize_dataset
 (
dataset
)
print
(
summary
)
> [(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]
12",naive bayes classier step media deviazione standard devono essere calcolate ogni feature considerando tutte istanze funzione zip separa colonne dataset restituisce tupla ogni colonna contenente relativi valori features def dataset summaries mean column stdev column len column column zip dataset summaries return summaries esempio dataset summary dataset print summary
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#12,12,"Naive Bayes classiﬁer: step 3
Vogliamo ricavare le statistiche per ogni classe (o label). Sfruttiamo la funzione 
separate_by_class()
  deﬁnita in precedenza:  
def summarize_by_class
 (
dataset
)
:
separated
  = 
separate_by_class
 (
dataset
)
summaries
  = 
dict
()
for 
class_value
 , 
rows 
in 
separated
 .
items
()
:
summaries
 [
class_value
 ]
 = 
summarize_dataset
 (
rows
)
return 
summaries
Ad esempio:  
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
13
>>>
0
(2.7420144012, 0.9265683289298018, 5)
(3.0054686692, 1.1073295894898725, 5)
1
(7.6146523718, 1.2344321550313704, 5)
(2.9914679790000003, 1.4541931384601618, 5)",naive bayes classier step vogliamo ricavare statistiche ogni classe label sfruttiamo funzione denita precedenza def dataset separated dataset summaries dict classvalue rows separated items summaries classvalue rows return summaries esempio dataset separated dataset label separated print label row separated label print row
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#13,13,"Naive Bayes classiﬁer: step 4
Assumiamo che la probabilità che un certo valore 
 x
 osservato sia funzione 
da una distribuzione gaussiana, descritta interamente dai due valori: media 
e deviazione standard.  
La funzione di densità di probabilità sarà così ricavata (vedi lezione; la y 
corrisponde alla media): 
f(x) = (1 / sqrt(2 * PI) * Σ) * exp(-((x-
 μ
)^2 / (2 * Σ^2)))
Dove 
 Σ
 è la matrice di covarianza (con d =1 coincide con la varianza). 
Esercizio
 : deﬁnire la funzione 
 calculate_probability(x, mean, stdev) 
 per il 
calcolo della densità di probabilità.
14
",naive bayes classier step assumiamo probabilit certo valore osservato funzione distribuzione gaussiana descritta interamente due valori media deviazione standard funzione densit probabilit cos ricavata vedi lezione corrisponde media sqrt exp matrice covarianza con coincide varianza esercizio denire funzione mean stdev calcolo densit probabilit
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#14,14,"Naive Bayes classiﬁer: step 4
Esercizio
 : deﬁnire la funzione calculate_probability(x, mean, stdev) per il 
calcolo della densità di probabilità. 
from math import sqrt
from math import pi
from math import 
 exp
def calculate_probability
 (
x
, 
mean
, 
stdev
)
:
exponent
  = 
exp
(
-
((
x
-
mean
)
**
2
 / 
(
2
 * 
stdev*
*
2 
)))
return 
(
1
 / 
(
sqrt
(
2
 * 
pi
)
 * 
stdev
))
 * 
exponent
print
(
calculate_probability
 (
1.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
2.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
0.0
, 
1.0
, 
1.0
))
> 
0.3989422804014327
> 
0.24197072451914337
> 
0.24197072451914337
Notare come per x=1, e media e varianza pari a 1, l'apice della campana 
assume valore 0.39. Per x=2 e x=0, e medesime statistiche, il valore è 0.24.
15",naive bayes classier step esercizio denire funzione mean stdev calcolo densit probabilit math import sqrt math import math import exp def mean stdev exponent exp mean stdev return sqrt stdev exponent print print print notare media varianza pari lapice campana assume valore medesime statistiche valore
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#15,15,"Naive Bayes classiﬁer: step 5
Ora impieghiamo le statistiche ricavate dal training data per nuovi dati. La 
stima delle probabilità viene stimata per ogni classe. 
P(class|data) = P(X|class) * P(class) 
Attenzione: Avendo eliminato la frazione, il risultato non è strettamente 
una probabilità.  
Vogliamo massimizzare tale valore, ovvero prendere la classe con valore di 
probabilità massimo. 
L'approccio naive implica l'indipendenza, es: 
P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)
16",naive bayes classier step ora impieghiamo statistiche ricavate training data nuovi dati stima probabilit viene stimata ogni classe pclassdata pxclass pclass attenzione eliminato frazione risultato strettamente probabilit vogliamo massimizzare tale valore ovvero prendere classe valore probabilit massimo lapproccio naive implica lindipendenza pxclass pxclass pclass
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#16,16,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Esempio: 
# Test calculating class probabilities
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summaries
  = 
summarize_by_class
 (
dataset
)
probabilities
  = 
calculate_class_probabilities
 (
summaries
 , 
dataset
[
0
])
print
(
probabilities
 )
> {0: 0.05032427673372075, 1: 0.00011557718379945765}
17",naive bayes classier step esercizio denire prende input statistiche restituite valuta probabilit certa istanza data sempre input esempio test calculating class probabilities dataset summaries dataset probabilities summaries dataset print probabilities
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#17,17,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Calcola il numero totale di istanze a partire dalle statistiche passate 
come parametro. 
Valuta il valore P(class) come frazione tra il numero di istanze per una 
classe e il numero di istanze nel dataset 
Stima la probabilità per ogni valore in input impiegando la funzione 
densità di probabilità, e le statistiche per ogni colonna associata ad una 
certa classe. Le probabilità saranno moltiplicate se associate alla stessa 
classe. 
Il processo sarà ripetuto per ogni classe nel dataset. 
Restituire un dizionario classe->probabilità
18",naive bayes classier step esercizio denire prende input statistiche restituite valuta probabilit certa istanza data sempre input calcola numero totale istanze partire statistiche passate parametro valuta valore pclass frazione numero istanze classe numero istanze dataset stima probabilit ogni valore input impiegando funzione densit probabilit statistiche ogni colonna associata certa classe probabilit moltiplicate associate stessa classe processo ripetuto ogni classe dataset restituire dizionario classe probabilit
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#18,18,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
def calculate_class_probabilities
 (
summaries
 , 
row
)
:
 
# numero totale di istanze di training
 
total_rows
  = 
sum
([
summaries
 [
label
][
0
][
2
] 
for 
label 
in 
summaries
 ])
 
# output
probabilities
  = 
dict
()
 
# per ogni chiave (classe) e valore (istanze di quella classe)
for 
class_value
 , 
class_summaries 
 in 
summaries
 .
items
()
:
   
# probabilità calcolata in base alle frequenze
probabilities
 [
class_value
 ]
 = 
summaries
 [
class_value
 ][
0
][
2
]
/
float
(
total_rows
 )
   
# per ogni istanza in summaries associata ad una classe
for 
i 
in 
range
(
len
(
class_summaries
 ))
:
      
# ricava le statistiche di quella classe
mean
, 
stdev
, 
count
 = 
class_summaries
 [
i
]
      
# aggiorna la probabilità per quella classe
probabilities
 [
class_value
 ]
 *= 
calculate_probability
 (
row
[
i
], 
mean
, 
stdev
)
return 
probabilities
19",naive bayes classier step esercizio denire prende input statistiche restituite valuta probabilit certa istanza data sempre input def summaries row numero totale istanze training totalrows sum summaries label label summaries output probabilities dict ogni chiave classe valore istanze classe classvalue classsummaries summaries items probabilit calcolata base frequenze probabilities classvalue summaries classvalue float totalrows ogni istanza summaries associata classe range len classsummaries ricava statistiche classe mean stdev count classsummaries aggiorna probabilit classe probabilities classvalue row mean stdev return probabilities
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#19,19,"Naive Bayes classiﬁer: esercitazione
Considerare il dataset Kaggle Adult income dataset:  
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html   
Contiene 16 colonne: 
Target ﬁled: Income  
-- The income is divide into two classes: <=50K and >50K   
Number of attributes: 14  
-- These are the demographics and other features to describe a person 
Analizza il dataset passo passo seguendo le considerazioni su: 
https://www.kaggle.com/code/prashant111/naive-bayes-classiﬁer-in-python/notebook  
Applica l'algoritmo Naive Bayes classiﬁer per i suddetto dataset.  
Nota
 : alcuni attributi potrebbero dover essere normalizzati oppure convertiti in valori 
numerici.
20",naive bayes classier esercitazione considerare dataset kaggle adult income dataset income dataset detailhtml contiene colonne target led income income divide two classes number attributes demographics features describe person analizza dataset passo passo seguendo considerazioni bayes classier pythonnotebook applica lalgoritmo naive bayes classier suddetto dataset nota alcuni attributi potrebbero dover essere normalizzati oppure convertiti valori numerici
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#2,2,"Scikit-learn: Classiﬁcatori Naive Bayes
Un approccio di classiﬁcazione molto veloce nell'addestramento, che non 
richiede che il training set sia caricato interamente in memoria, anche se a 
volte mostrano performance peggiori rispetto agli approcci lineare (es. 
LogisticRegression e LinearSVC). 
Naive
  perché basato sull'assunzione che le feature siano indipendenti dal 
punto di vista statistico, spesso inesatta. 
Es. un problema cardiovascolare può dipendere dal colesterolo, peso, livelli di 
diabete, etc; se presenti contemporaneamente possono aumentarne il rischio, ma 
l'approccio naive le valuta singolarmente. 
Si ricavano i parametri del modello analizzando le features singolarmente, e 
collezionando statistiche per ogni feature per ogni classe. 
Ricavare la classe più verosimile (con più alta probabilità 
 a posteriori
 ) si 
ottiene mediante il 
 Teorema di Bayes
 . 
L'approccio naive (indipendenza tra features) ci porta a non interpretare la probabilità 
in output poiché risulta essere una approssimazione troppo grossolana rispetto a 
quella reale. 
3",scikit learn classicatori naive bayes approccio classicazione molto veloce richiede training set caricato interamente memoria volte mostrano performance peggiori rispetto approcci lineare logistic regression linear naive basato sullassunzione feature indipendenti punto vista statistico spesso inesatta problema cardiovascolare pu dipendere colesterolo peso livelli diabete etc presenti possono aumentarne rischio lapproccio naive valuta singolarmente ricavano parametri modello analizzando features singolarmente collezionando statistiche ogni feature ogni classe ricavare classe verosimile con alta probabilit posteriori ottiene mediante teorema bayes lapproccio naive indipendenza features porta interpretare probabilit output poich risulta essere approssimazione troppo grossolana rispetto reale
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#20,20,"Naive Bayes classiﬁer: esercitazione
Alcune funzioni di supporto: 
# Load a CSV file
def 
load_csv
 (
filename
 ):
  dataset = 
 list
()
  
with 
open
(filename, 
 'r'
) 
as 
file
:
    csv_reader = reader(
 file
)
    
for
 row 
in
 csv_reader:
      
if 
not
 row:
        
 continue
      dataset.append(row)
  
return
 dataset
# Convert string column to float
def 
str_column_to_float
 (
dataset
, 
column
):
  
for
 row 
in
 dataset:
    row[column] = 
 float
(row[column].strip())
# Convert string column to integer
def 
str_column_to_int
 (
dataset
, 
column
):
  class_values = [row[column] 
 for
 row 
in
 dataset]
  unique = 
 set
(class_values)
  lookup = 
 dict
()
  
for
 i, value 
 in 
enumerate
 (unique):
    lookup[value] = i
  
for
 row 
in
 dataset:
    row[column] = lookup[row[column]]
  
return
 lookup
21",naive bayes classier esercitazione alcune funzioni supporto load file def loadcsv filename dataset list open filename file csvreader reader file row csvreader row continue return dataset convert string column float def dataset column row dataset rowcolumn float convert string column integer def dataset column classvalues rowcolumn row dataset unique set classvalues lookup dict value enumerate unique lookupvalue row dataset rowcolumn return lookup
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#21,21,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Tutorial 
 https://machinelearningmastery.com/naive-bayes-classiﬁer-scratch-
python/  
Dataset: 
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html  
Testi di Riferimento
22",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media tutorial bayes classier scratch python dataset income dataset detailhtml testi riferimento
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#3,3,"Classiﬁcatori Naive Bayes: pregi e difetti
Semplice implementazione (basata sulle occorrenze) 
Può funzionare anche su dataset piccoli 
È veloce e richiede poca memoria 
Gestiste il caso di valori mancanti nei dati  
Poco sensibile a dati rumorosi 
L'assunzione dell'indipendenza statistica è raramente soddisfatta; il modello non 
considera le dipendenze tra features 
I dati nel continuo devono essere spesso rielaborati (es. binning) 
Non raggiunge prestazioni ottimali rispetto ad altri approcci 
Non supporta l'
 online learning
 : occorre riaddestrare il modello in presenza di 
nuovi dati. 
Non funziona correttamente se i dati nel test set non sono presenti nel training.
4",classicatori naive bayes pregi difetti semplice implementazione basata occorrenze pu funzionare dataset piccoli veloce richiede poca memoria gestiste caso valori mancanti dati poco sensibile dati rumorosi lassunzione statistica raramente soddisfatta modello considera dipendenze features dati continuo devono essere spesso rielaborati binning raggiunge prestazioni ottimali rispetto altri approcci supporta online learning occorre riaddestrare modello presenza nuovi dati funziona correttamente dati test set presenti training
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#4,4,"Scikit-learn: Classiﬁcatori Naive Bayes
Ci sono vari classiﬁcatori implementati in Scikit-learn: 
GaussianNB: adatto a dati nel continuo 
CategoricalNB: features discrete distribuite su categorie predeﬁnite 
BernoulliNB: assume dati binari 
MultinomialNB: assume feature che accumulano valori (es. frequenza) 
ComplementNB: variazione del Multinomial per correggere alcune 
assunzioni sui dati. 
BernoulliNB e MultinomialNB sono spesso usati per dati testuali. 
Per dataset di training molto grandi e sparsi si può usare il parametro 
 partial_ﬁt
  che 
riduce la richiesta di memoria. 
È una valida alternativa a 
 logistic regression
  e 
decision trees
 .
5",scikit learn classicatori naive bayes vari classicatori implementati scikit learn gaussian adatto dati continuo categorical features discrete distribuite categorie predenite bernoulli assume dati binari multinomial assume feature accumulano valori frequenza complement variazione multinomial correggere alcune assunzioni dati bernoulli multinomial spesso usati dati testuali dataset training molto grandi sparsi pu usare parametro partialt riduce richiesta memoria valida alternativa logistic regression decision trees
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#5,5,"Scikit-learn: BernoulliNB
Conteggia quante volte una feature non è pari 0 per ogni classe. 
Ad esempi, 4 istanze con 4 feature binarie ciascuna. La 1a e 3a istanza 
hanno classe '0', mentre la 2a e 4a hanno classe '1'. 
X 
= 
np
.
array
([[
0
, 
1
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
1
],
[
0
, 
0
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
0
]])
y 
= 
np
.
array
([
0
, 
1
, 
0
, 
1
])
Effettuando il conteggio per entrambe le classi si ha: 
counts 
= 
{}
for 
label 
in 
np
.
unique
(
y
):
# iterate over each class
# count (sum) entries of 1 per feature
counts
[
label
] 
= 
X
[
y 
== 
label
]
.
sum
(
axis
=
0
)
print
(
""Feature counts:\n{}""
 .
format
(
counts
))
Feature counts:
{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}
6",scikit learn bernoulli conteggia volte feature pari ogni classe esempi istanze feature binarie ciascuna istanza classe mentre classe array array effettuando conteggio entrambe classi counts label unique iterate class count sum entries feature counts label label sum axis print feature countsn format counts feature counts array array
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#6,6,"Scikit-learn: MultinomialNB e GaussianNB
 ,
MultinomialNB
  tiene conto del valor medio per ogni feature per ogni 
classe. 
 GaussianNB
  ricava valor medio e varianza. 
La predizione su una istanza è ricavata valutando tutte le classi e 
scegliendo quella ottimale. 
MultinomialNB e BernoulliNB hanno un singolo parametro 
 alpha
 , che 
determina la complessità del modello. Ai dati sono aggiunti 
 alpha
  istanze 
virtuali che hanno valori positivi per tutte le features. Questo genera uno 
""smoothing"" sulle statistiche calcolate.  
Valori elevati di 
 alpha
  creano smoothing elevati e modelli meno 
complessi.  
GaussianNB
  è più adatto a dataset con molte features. 
 MultinomialNB
  è 
migliore rispetto a 
 BernoulliNB
  con dataset con un numero elevato di 
features diverse da 0 (es. grandi documenti testuali).
7",scikit learn multinomial gaussian multinomial tiene conto valor medio ogni feature ogni classe gaussian ricava valor medio varianza predizione istanza ricavata valutando tutte classi scegliendo ottimale multinomial bernoulli singolo parametro alpha determina complessit modello dati aggiunti alpha istanze virtuali valori positivi tutte features genera smoothing statistiche calcolate valori elevati alpha creano smoothing elevati modelli meno complessi gaussian adatto dataset molte features multinomial migliore rispetto bernoulli dataset numero elevato features diverse grandi documenti testuali
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#7,7,"Naive Bayes classiﬁer da zero
Proviamo a fare l'implementazione del classiﬁcatore 
Step 1: Separate By Class.  
Step 2: Summarize Dataset.  
Step 3: Summarize Data By Class.  
Step 4: Gaussian Probability Density Function.  
Step 5: Class Probabilities 
Immaginiamo di impiegare il dataset 
 Iris
: 
lunghezza e larghezza sepalo (reali) 
lunghezza e larghezza petalo (reali) 
classe di appartenenza = {Iris-setosa, Iris-versicolor, Iris-virginica}
8",naive bayes classier zero proviamo fare classicatore step separate class step summarize dataset step summarize data class step gaussian probability density function step class probabilities immaginiamo impiegare dataset iris lunghezza larghezza sepalo reali lunghezza larghezza petalo reali classe appartenenza iris setosa iris versicolor iris virginica
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#8,8,"Naive Bayes classiﬁer: step 1
Calcoliamo la probabilità di appartenenza di una istanza ad una certa 
classe. 
Separiamo i dati in ingresso in base alla classe di appartenenza.  
# Split the dataset by class values
# Restituisce un dizionario classe -> lista di istanze
# Funziona per ogni dataset il cui ultimo valore è la classe di appartenenza
def separate_by_class
 (
dataset
)
:
separated
  = 
dict
()
for 
i 
in 
range
(
len
(
dataset
))
:
vector
 = 
dataset
[
i
]
class_value
  = 
vector
[
-
1
]   # ultimo valore
if 
(
class_value 
 not 
in 
separated
 )
:
separated
 [
class_value
 ]
 = 
list
()
separated
 [
class_value
 ].
append
(
vector
) 
return 
separated
9",naive bayes classier step calcoliamo probabilit appartenenza istanza certa classe separiamo dati ingresso base classe appartenenza split dataset class values restituisce dizionario classe lista istanze funziona ogni dataset ultimo valore classe appartenenza def dataset separated dict range len dataset vector dataset classvalue vector ultimo valore classvalue separated separated classvalue list separated classvalue append vector return separated
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#9,9,"Naive Bayes classiﬁer: step 1
# Iris dataset
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
0
[3.393533211, 2.331273381, 0]
[3.110073483, 1.781539638, 0]
[1.343808831, 3.368360954, 0]
[3.582294042, 4.67917911, 0]
[2.280362439, 2.866990263, 0]
1
[7.423436942, 4.696522875, 1]
[5.745051997, 3.533989803, 1]
[9.172168622, 2.511101045, 1]
[7.792783481, 3.424088941, 1]
[7.939820817, 0.791637231, 1]
10",naive bayes classier step iris dataset dataset separated dataset label separated print label row separated label print row
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Support Vector Machine (SVM)",machine learning universit roma tre dipartimento ingegneria anno accademico support vector machine
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#1,1,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse",sommario lineari pattern linearmente separabili lineari multiclasse
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#10,10,"SVM50 CHAPTER 5. LINEAR DISCRIMINANT FUNCTIONS
transformation ϕ() that well separates the data — so the expected number of support
vectors is small — then Eq. 107 shows that the expected error rate will be lower.
y1y2
R1
R2
optimal hyperplanemaximummargin b
maximummargin b
Figure 5.19: Training a Support Vector Machine consists of ﬁnding the optimal hy-
perplane, i.e., the one with the maximum distance from the nearest training patterns.
The support vectors are those (nearest) patterns, a distance bfrom the hyperplane.
The three support vectors are shown in solid dots.
5.11.1 SVM training
We now turn to the problem of training an SVM. The ﬁrst step is, of course, to choose
the nonlinear ϕ-functions that map the input to a higher dimensional space. Often
this choice will be informed by the designer’s knowledge of the problem domain. In
the absense of such information, one might choose to use polynomials, Gaussians or
yet other basis functions. The dimensionality of the mapped space can be arbitrarily
high (though in practice it may be limited by computational resources).
We begin by recasting the problem of minimizing the magnitude of the weight
vector constrained by the separation into an unconstrained problem by the method
of Lagrange undetermined multipliers. Thus from Eq. 106 and our goal of minimizing
||a||, we construct the functional
L(a,α)=1
2||a||2−n/summationdisplay
k=1αk[zkatyk−1]. (108)
and seek to minimize L() with respect to the weight vector a, and maximize it with
respect to the undetermined multipliers αk≥0. The last term in Eq. 108 expresses
the goal of classifying the points correctly. It can be shown using the so-called Kuhn-
Tucker construction (Problem 30) (also associated with Karush whose 1939 thesis
addressed the same problem) that this optimization can be reformulated as maximiz-
ing
L(α)=n/summationdisplay
k=1αi−1
2n/summationdisplay
k,jαkαjzkzjyt
jyk, (109)
subject to the constraintsVedi Duda et al., Pattern Classification , 2000, pg. 262",transformation well separates data expected number support vectors small shows expected error rate lower optimal maximummargin figure training support vector machine consists nding optimal perplane one maximum distance nearest training patterns support vectors nearest patterns distance bfrom hyperplane three support vectors shown solid dots training turn problem training rst step course choose nonlinear functions map input higher dimensional space often choice informed designers knowledge problem domain absense information one might choose use polynomials gaussians yet basis functions dimensionality mapped space arbitrarily high though practice may limited computational resources begin recasting problem minimizing magnitude weight vector constrained separation unconstrained problem method lagrange undetermined multipliers thus goal minimizing construct functional la seek minimize respect weight vector maximize respect undetermined multipliers k last term expresses goal classifying points correctly shown using called kuhn tucker construction problem also associated karush whose thesis addressed problem optimization reformulated maximiz ing ki kjkjzkzjyt jyk subject constraints vedi duda pattern classification
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#11,11,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse",sommario lineari pattern linearmente separabili lineari multiclasse
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#12,12,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  ℜd: spazio vettoriale di d
dimensioni ( d=3 in figura)
xi: vettore di d componenti 
relativo al pattern i-esimo 
del TS
yi: etichetta relativa al 
pattern i-esimo del TS
w: vettore che indica la 
direzione ortogonale a tutti 
i vettori dell’iperpiano H
b : coefficiente del termine 
noto che compare nell’eq. 
del iperpiano H",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare spazio vettoriale dimensioni figura vettore componenti relativo pattern esimo etichetta relativa pattern esimo vettore indica direzione ortogonale vettori delliperpiano coefficiente termine noto compare nelleq iperpiano
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#13,13,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Iperpiano : sottospazio inferiore di una dimensione allo spazio in cui è 
definito (e.g., nello spazio 3D gli iperpiani sono i piani)
!Equazione cartesiana di un piano:
Il luogo delle soluzioni (x,y,z) che verificano l’equazione è il luogo dei 
punti P = (x,y,z) che appartengono al piano
!L’equazione del piano specifica due elementi
!la terna (w1,w2,w3) dei coefficienti detti parametri direttori del piano
che individua la direzione ortogonale a tutti i vettori del piano
!il coefficiente del termine noto b
!In sintesi, per individuare univocamente un piano nello spazio è 
sufficiente disporre della direzione ortogonale al piano we del 
coefficiente bw1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ",qualche richiamo prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare iperpiano sottospazio inferiore dimensione spazio definito spazio iperpiani piani equazione cartesiana piano luogo soluzioni xyz verificano lequazione luogo punti xyz appartengono piano lequazione piano specifica due elementi terna www coefficienti detti parametri direttori piano individua direzione ortogonale vettori piano coefficiente termine noto sintesi individuare univocamente piano spazio sufficiente disporre direzione ortogonale piano coefficiente www
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#14,14,"Qualche Richiamo
!Sia      uno spazio vettoriale di dimensione n sul campo    . 
Il prodotto scalare fra due vettori di      è un’operazione che 
generalmente si indica con il simbolo “ •” ed è definita come segue:
ovvero associa ad una coppia di vettori x=(x 1,x2,...,x n)e y=(y 1,y2,...,y n) 
un numero reale così definito 
x∙y = <x,y> = x1y1+x 2y2,..., +x nyn
!Alle volte il prodotto scalare è definito anche come
x∙y = = < x,y> = xty
dove xtyè il prodotto riga per colonna tra il vettore trasposto xte il 
vettore y
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
ℜn
ℜn
•: ℜn×ℜn→ℜℜ",qualche richiamo sia spazio vettoriale dimensione campo prodotto scalare fra due vettori unoperazione generalmente indica simbolo definita segue ovvero associa coppia vettori numero reale cos definito xy xyx nyn alle volte prodotto scalare definito xy xty xty prodotto riga colonna vettore trasposto xte vettore prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare nn
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#15,15,"Qualche Richiamo
!La norma di un vettore                                    è un’applicazione che 
ad un vettore associa un numero reale
Essa è pari alla radice quadrata della somma del quadrato delle 
componenti del vettore o, equivalentemente, alla radice quadrata del 
prodotto scalare del vettore con se stesso
!Fra le proprietà di cui gode la norma vi è quella di omogeneità : x=x1,x2,...,xn ( )∈ ℜn
•: ℜn→ℜ
x=x12+x22+...+xn2=x•x
per ogni x∈ ℜn e per ogni λ∈ ℜ si ha
λx=λx
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  ",qualche richiamo norma vettore unapplicazione vettore associa numero reale essa pari radice quadrata somma quadrato componenti vettore radice quadrata prodotto scalare vettore stesso fra propriet gode norma omogeneit xxxxn n ogni ogni xx prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#16,16,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Dato un piano P di equazione
la sua distanza dall’origine degli assi è pari a
!
""!""+""""""+""#""=!
%
!Si può dimostrare che la distanza !di un punto ""da un piano P è pari a
&=%'(+!
""!""+""""""+""#""=%'(+!
%=)(+)
%
mentre se il punto ""appartiene al piano, cioè se ""∈P, allora la 
distanza !é per definizione zero w1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ",qualche richiamo prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare dato piano equazione distanza dallorigine assi pari pu dimostrare distanza punto piano pari mentre punto appartiene piano cio allora distanza definizione zero www
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#17,17,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
In altri termini, D(x) è la funzione distanza dall’iperpiano, cioè indica 
quanto il pattern xè distante dalla superficie decisionale ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare altri termini funzione distanza dalliperpiano cio indica pattern distante superficie decisionale
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#18,18,"SVM Lineari: Pattern Separabili
182 4. LINEAR MODELS FOR CLASSIFICATION
Figure 4.1 Illustration of the geometry of a
linear discriminant function in two dimensions.
The decision surface, shown in red, is perpen-
dicular to w, and its displacement from the
origin is controlled by the bias parameter w0.
Also, the signed orthogonal distance of a gen-
eral point xfrom the decision surface is given
byy(x)/∥w∥.x2
x1wx
y(x)
∥w∥
x⊥
−w0
∥w∥y=0
y<0y>0
R2R1
an arbitrary point xand let x⊥be its orthogonal projection onto the decision surface,
so that
x=x⊥+rw
∥w∥. (4.6)
Multiplying both sides of this result by wTand adding w0, and making use of y(x)=
wTx+w0andy(x⊥)=wTx⊥+w0=0, we have
r=y(x)
∥w∥. (4.7)
This result is illustrated in Figure 4.1.
As with the linear regression models in Chapter 3, it is sometimes convenient
to use a more compact notation in which we introduce an additional dummy ‘input’
value x0=1and then deﬁne /tildewidew=(w0,w)and/tildewidex=(x0,x)so that
y(x)=/tildewidewT/tildewidex. (4.8)
In this case, the decision surfaces are D-dimensional hyperplanes passing through
the origin of the D+1-dimensional expanded input space.
4.1.2 Multiple classes
Now consider the extension of linear discriminants to K> 2classes. We might
be tempted be to build a K-class discriminant by combining a number of two-class
discriminant functions. However, this leads to some serious difﬁculties (Duda and
Hart, 1973) as we now show.
Consider the use of K−1classiﬁers each of which solves a two-class problem of
separating points in a particular class Ckfrom points not in that class. This is known
as a one-versus-the-rest classiﬁer. The left-hand example in Figure 4.2 shows an4.1. Discriminant Functions 181
(McCullagh and Nelder, 1989). Note, however, that in contrast to the models used
for regression, they are no longer linear in the parameters due to the presence of the
nonlinear function f(·). This will lead to more complex analytical and computa-
tional properties than for linear regression models. Nevertheless, these models are
still relatively simple compared to the more general nonlinear models that will be
studied in subsequent chapters.
The algorithms discussed in this chapter will be equally applicable if we ﬁrst
make a ﬁxed nonlinear transformation of the input variables using a vector of basis
functions φ(x)as we did for regression models in Chapter 3. We begin by consider-
ing classiﬁcation directly in the original input space x, while in Section 4.3 we shall
ﬁnd it convenient to switch to a notation involving basis functions for consistency
with later chapters.
4.1. Discriminant Functions
A discriminant is a function that takes an input vector xand assigns it to one of K
classes, denoted Ck. In this chapter, we shall restrict attention to linear discriminants ,
namely those for which the decision surfaces are hyperplanes. To simplify the dis-
cussion, we consider ﬁrst the case of two classes and then investigate the extension
toK>2classes.
4.1.1 Two classes
The simplest representation of a linear discriminant function is obtained by tak-
ing a linear function of the input vector so that
y(x)=wTx+w0 (4.4)
where wis called a weight vector , andw0is abias (not to be confused with bias in
the statistical sense). The negative of the bias is sometimes called a threshold .A n
input vector xis assigned to class C1ify(x)/greaterorequalslant0and to class C2otherwise. The cor-
responding decision boundary is therefore deﬁned by the relation y(x)=0 , which
corresponds to a (D−1)-dimensional hyperplane within the D-dimensional input
space. Consider two points xAandxBboth of which lie on the decision surface.
Because y(xA)=y(xB)=0 ,w eh a v e wT(xA−xB)=0 and hence the vector wis
orthogonal to every vector lying within the decision surface, and so wdetermines the
orientation of the decision surface. Similarly, if xis a point on the decision surface,
theny(x)=0 , and so the normal distance from the origin to the decision surface is
given by
wTx
∥w∥=−w0
∥w∥. (4.5)
We therefore see that the bias parameter w0determines the location of the decision
surface. These properties are illustrated for the case of D=2in Figure 4.1.
Furthermore, we note that the value of y(x)gives a signed measure of the per-
pendicular distance rof the point xfrom the decision surface. To see this, consider
Vedi Bishop, Pattern Recognition and Machine Learning , 2006, pg. 182In questo caso la notazione è 
y(x) = wTx + w0  = D(x) = w · x + b
cioè
wTx =w · x = <w,x>
w0 = b",lineari pattern separabili figure illustration geometry linear discriminant function two dimensions decision surface shown red perpen dicular displacement origin controlled bias parameter also signed orthogonal distance gen eral point xfrom decision surface given byyxwx xwx w wy arbitrary point xand let xbe orthogonal projection onto decision surface xxrw w multiplying sides result tand adding making use txwandyxw txw ryx w result illustrated figure linear regression models chapter sometimes convenient use compact notation introduce additional dummy input value xand dene ttildewidex case decision surfaces dimensional hyperplanes passing origin dimensional expanded input space multiple classes consider extension linear discriminants classes might tempted build class discriminant combining number two class discriminant functions however leads serious difculties duda hart show consider use kclassiers solves two class problem separating points particular class ckfrom points class known one versus rest classier left hand example figure shows discriminant functions cullagh nelder note however contrast models used regression longer linear parameters due presence nonlinear function lead complex analytical computa tional properties linear regression models nevertheless models still relatively simple compared general nonlinear models studied subsequent chapters algorithms discussed chapter equally applicable rst make xed nonlinear transformation input variables using vector basis functions xas regression models chapter begin consider ing classication directly original input space section shall nd convenient switch notation involving basis functions consistency later chapters discriminant functions discriminant function takes input vector xand assigns one classes denoted chapter shall restrict attention linear discriminants namely decision surfaces hyperplanes simplify dis cussion consider rst case two classes investigate extension kclasses two classes simplest representation linear discriminant function obtained tak ing linear function input vector yxw txw wis called weight vector andwis abias not confused bias statistical sense negative bias sometimes called threshold input vector xis assigned class class cotherwise cor responding decision boundary therefore dened relation corresponds dimensional hyperplane within dimensional input space consider two points aandx bboth lie decision surface ayx ax hence vector wis orthogonal every vector lying within decision surface wdetermines orientation decision surface similarly xis point decision surface thenyx normal distance origin decision surface given ww w therefore see bias parameter wdetermines location decision surface properties illustrated case din figure furthermore note value yxgives signed measure pendicular distance rof point xfrom decision surface see this consider vedi bishop pattern recognition machine learning caso notazione cio
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#19,19,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Vincoli da soddisfare",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili date due classi pattern linearmente separabili training set contenente campioni pattern etichette due classi esistono diversi iperpiani grado eseguire separazione voluta generico iperpiano definito parametri distanza vettore dalliperpiano vale pertanto iperpiani separano pattern distanza minima ogni lato soddisfano equazioni modo compatto iperpiano vettore normale alliperpiano distanza dallorigine luogo vettori piano semplicit omettiamo trasposto prodotto scalare prof davide maltoni universit bologna classificazione lineari pattern separabili minima distanza liperpiano separazione pattern training set detta margine distanza punti giacciono sulliperpiano dalliperpiano separazione stesso vale punti sulliperpiano pertanto margine liperpiano ottimo secondo soddisfa vincoli separazione pattern massimizza margine minimizza inverso minimizza vincoli pattern training set giacciono margine cerchi pieni figura detti support vector tali pattern costituiscono casi complessi definiscono completamente soluzione problema pu essere espressa funzione solo tali pattern dimensionalit spazio numero elementi vincoli soddisfare
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#2,2,"Dilemma
Reti Neurali a un solo strato :
Pro: algoritmo di apprendimento semplice ed efficiente
Cons : potere espressivo limitato (i.e., possono apprendere solo 
“confini” decisionali lineari nello spazio di input)
Reti Neurali multistrato :
Pro: potere espressivo elevato (i.e., possono rappresentare funzioni        
generiche non lineari)
Cons : algoritmo di apprendimento complicato (a causa della 
abbondanza di minimi locali e dell’alto numero di dimensioni  
dello spazio dei pesi)
?:
Pro: potere espressivo elevato
Pro: algoritmo di apprendimento efficiente",dilemma reti neurali solo strato pro algoritmo apprendimento semplice efficiente cons potere espressivo limitato possono apprendere solo confini decisionali lineari spazio input reti neurali multistrato pro potere espressivo elevato possono rappresentare funzioni generiche lineari cons algoritmo apprendimento complicato causa abbondanza minimi locali dellalto numero dimensioni spazio pesi pro potere espressivo elevato pro algoritmo apprendimento efficiente
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#20,20,"SVM Lineari: Pattern Separabili
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM lineari: Pattern Separabili (2)
Laminima distanza tral’iperpiano diseparazione eunpattern del
training setèdetta margine (W).
Ladistanza dei punti che giacciono sull’iperpiano 𝐷𝐱=+1
dall’iperpiano diseparazione (𝐷𝐱=0)è1/𝐰;lostesso vale peri
puntisull’iperpiano 𝐷𝐱=−1.
Pertanto ilmargine èW=2/𝐰.
L’iperpiano ottimo secondo SVM èquello soddisfa ivincoli di
separazione dei pattern emassimizza ilmargine W(o
alternativamente minimizza ilsuoinverso) :
Minimizza :𝐰2/2
Vincoli :𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0𝑝𝑒𝑟𝑖=1…𝑛
Ipattern deltraining setchegiacciono sulmargine (cerchi pieni in
figura) sono detti support vector .Talipattern, checostituiscono icasi
più complessi, definiscono completamente lasoluzione del
problema, che può essere espressa come funzione disolo tali
pattern ,indipendentemente dalla dimensionalità dello spazio𝑑edal
numero𝑛dielementi inTS.𝐷𝐱=+11/𝐰
𝐷𝐱=0
𝐷𝐱=−1𝐷𝐱>+1
𝐷𝐱<−11/𝐰Laminima distanza trapattern del training set didue classi
differenti piùvicini all’iperpiano diseparazione èdetta margine (-).",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili laminima distanza traliperpiano diseparazione eunpattern training setdetta margine ladistanza punti giacciono sulliperpiano dalliperpiano diseparazione vale peri pertanto ilmargine liperpiano ottimo secondo quello soddisfa ivincoli separazione pattern emassimizza ilmargine minimizza ilsuoinverso minimizza vincoli ipattern deltraining setchegiacciono sulmargine cerchi pieni figura detti support vector talipattern icasi complessi definiscono completamente lasoluzione problema pu essere espressa funzione disolo tali pattern dimensionalit spazioedal ts laminima distanza trapattern training set didue classi differenti pivicini alliperpiano diseparazione detta margine
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#21,21,"SVM Lineari: Pattern Separabili
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 
",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili minima distanza liperpiano separazione pattern training set detta margine distanza punti giacciono sulliperpiano dalliperpiano separazione stesso vale punti sulliperpiano pertanto margine liperpiano ottimo secondo soddisfa vincoli separazione pattern massimizza margine minimizza inverso minimizza vincoli pattern training set giacciono margine cerchi pieni figura detti support vector tali pattern costituiscono casi complessi definiscono completamente soluzione problema pu essere espressa funzione solo tali pattern dimensionalit spazio numero elementi 
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#22,22,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Funzione 
Obiettivo",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili problema ottimizzazione precedente pu essere risolto passando innanzitutto formulazione lagrangiana successivamente formulazione duale formulazione lagrangiana prevede introdurre moltiplicatore ogni vincolo forma sottrarre vincolo moltiplicato funzione obiettivo minimizzare rispetto massimizzare rispetto utilizzando condizioni karush kuhn tucker problema pu essere posto forma duale esprimendo parametri funzione moltiplicatori risolto massimizzando nuova funzione obiettivo rispetto soli vincoli approfondimenti derivazione equazioni gunn support vector machines classification regression burges tutorial support vector machines pattern recognition prof davide maltoni universit bologna classificazione lineari pattern separabili minima distanza liperpiano separazione pattern training set detta margine distanza punti giacciono sulliperpiano dalliperpiano separazione stesso vale punti sulliperpiano pertanto margine liperpiano ottimo secondo soddisfa vincoli separazione pattern massimizza margine minimizza inverso minimizza vincoli pattern training set giacciono margine cerchi pieni figura detti support vector tali pattern costituiscono casi complessi definiscono completamente soluzione problema pu essere espressa funzione solo tali pattern dimensionalit spazio numero elementi funzione obiettivo
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#23,23,"6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 SVM Lineari: Pattern Separabili
VincoliFunzione 
Obiettivo",prof davide maltoni universit bologna classificazione lineari pattern separabili problema ottimizzazione precedente pu essere risolto passando innanzitutto formulazione lagrangiana successivamente formulazione duale formulazione lagrangiana prevede introdurre moltiplicatore ogni vincolo forma sottrarre vincolo moltiplicato funzione obiettivo minimizzare rispetto massimizzare rispetto utilizzando condizioni karush kuhn tucker problema pu essere posto forma duale esprimendo parametri funzione moltiplicatori risolto massimizzando nuova funzione obiettivo rispetto soli vincoli approfondimenti derivazione equazioni gunn support vector machines classification regression burges tutorial support vector machines pattern recognition lineari pattern separabili vincoli funzione obiettivo
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#24,24,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
prodotto scalare fra 
coppie di vettori del TS 
VincoliFunzione 
Obiettivo",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili problema ottimizzazione precedente pu essere risolto passando innanzitutto formulazione lagrangiana successivamente formulazione duale formulazione lagrangiana prevede introdurre moltiplicatore ogni vincolo forma sottrarre vincolo moltiplicato funzione obiettivo minimizzare rispetto massimizzare rispetto utilizzando condizioni karush kuhn tucker problema pu essere posto forma duale esprimendo parametri funzione moltiplicatori risolto massimizzando nuova funzione obiettivo rispetto soli vincoli approfondimenti derivazione equazioni gunn support vector machines classification regression burges tutorial support vector machines pattern recognition prodotto scalare fra coppie vettori vincoli funzione obiettivo
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#25,25,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili problema ottimizzazione precedente pu essere risolto attraverso algoritmo programmazione quadratica disponibile librerie numeriche soluzione consiste derivare valori ottimi condizioni assicurano vettori support vector liperpiano ottimo dunque parametrizzato support vector funzione distanza dalliperpiano noti che segno funzione consente classificare generico pattern sommatorie riducibili soli support vector caso lineare necessario dopo aver calcolato support vectors
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#26,26,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili problema ottimizzazione precedente pu essere risolto attraverso algoritmo programmazione quadratica disponibile librerie numeriche soluzione consiste derivare valori ottimi condizioni assicurano vettori support vector liperpiano ottimo dunque parametrizzato support vector funzione distanza dalliperpiano noti che segno funzione consente classificare generico pattern sommatorie riducibili soli support vector caso lineare necessario dopo aver calcolato support vectors
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#27,27,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili vantaggi dellapproccio definizione soluzione base numero ridotto support vector solitamente pochi numero support vector indica complessit problema pu essere dimostrato lerrore medio sui possibili training set limitato scala molto bene rispetto dimensionalit spazio feature grazie prodotti scalari complessit computazionale training quadratica rispetto numero pattern pratica problema pu essere risolto fino esempio support vectors cerchiati definiscono soluzione
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#28,28,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili vantaggi dellapproccio definizione soluzione base numero ridotto support vector solitamente pochi numero support vector indica complessit problema pu essere dimostrato lerrore medio sui possibili training set limitato scala molto bene rispetto dimensionalit spazio feature grazie prodotti scalari complessit computazionale training quadratica rispetto numero pattern pratica problema pu essere risolto fino esempio support vectors cerchiati definiscono soluzione
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#29,29,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
Vi saranno quindi tante
variabili di slack (scarto)
quanti sono ipattern del
Traning Set(TS) .
Tali variabili saranno, però,
diverse dazero (>0)solo per
ipattern non separabili, cioè
classificati erroneamente",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili caso pattern possono essere separati iperpiano necessario rilassare vincoli separazione far alcuni pattern minor numero possibile possano valicare confine classe tal fine introducono variabili slack positive modificano vincoli separazione ogni pattern variabile codifica deviazione margine pattern separabili corrispondenti variabili slack assumeranno valore liperpiano ottimo deve caso ancora massimizzare margine stesso tempo minimizzare numero elementi correttamente classificati funzione obiettivo conseguenza problema ottimizzazione vengono cos modificati minimizza vincoli pattern erroneamente classificati prof davide maltoni universit bologna classificazione lineari pattern separabili caso pattern possono essere separati iperpiano necessario rilassare vincoli separazione far alcuni pattern minor numero possibile possano valicare confine classe tal fine introducono variabili slack positive modificano vincoli separazione ogni pattern variabile codifica deviazione margine pattern separabili corrispondenti variabili slack assumeranno valore liperpiano ottimo deve caso ancora massimizzare margine stesso tempo minimizzare numero elementi correttamente classificati funzione obiettivo conseguenza problema ottimizzazione vengono cos modificati minimizza vincoli pattern erroneamente classificati quindi tante variabili slack scarto ipattern traning sett tali variabili saranno per diverse dazero solo ipattern separabili cio classificati erroneamente
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#3,3,"Support Vector Machine (SVM)
LeMacchine aVettori diSupporto oMacchine Kernel (Support Vector Machine,
SVM) costituiscono uninsieme dimetodi diapprendimento supervisionato .
Possono essere utilizzate siaperfare Classificazione ,siaperfare Regressione .
Inunbreve lasso temporale dalla loro prima implementazione hanno trovato
applicazione inunnutrito numero dibranche scientifiche come Fisica, Biologia,
Chimica :
!Preparazione difarmaci
!Ricerca direlazioni quantitative sulle proprietà distrutture
!Chemiometria
!Sensoristica
!Ingegneria chimica
!Computer vision (e.g.,face detection erecognition inimmagini evideo)
!...",support vector machine macchine vettori supporto macchine kernel support vector machine costituiscono uninsieme dimetodi diapprendimento supervisionato possono essere utilizzate siaperfare classificazione siaperfare regressione inunbreve lasso temporale prima implementazione trovato applicazione inunnutrito numero dibranche scientifiche fisica biologia chimica preparazione difarmaci ricerca direlazioni quantitative propriet distrutture chemiometria sensoristica ingegneria chimica computer vision egface detection erecognition inimmagini evideo
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#30,30,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 ",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili caso pattern possono essere separati iperpiano necessario rilassare vincoli separazione far alcuni pattern minor numero possibile possano valicare confine classe tal fine introducono variabili slack positive modificano vincoli separazione ogni pattern variabile codifica deviazione margine pattern separabili corrispondenti variabili slack assumeranno valore liperpiano ottimo deve caso ancora massimizzare margine stesso tempo minimizzare numero elementi correttamente classificati funzione obiettivo conseguenza problema ottimizzazione vengono cos modificati minimizza vincoli pattern erroneamente classificati prof davide maltoni universit bologna classificazione lineari pattern separabili caso pattern possono essere separati iperpiano necessario rilassare vincoli separazione far alcuni pattern minor numero possibile possano valicare confine classe tal fine introducono variabili slack positive modificano vincoli separazione ogni pattern variabile codifica deviazione margine pattern separabili corrispondenti variabili slack assumeranno valore liperpiano ottimo deve caso ancora massimizzare margine stesso tempo minimizzare numero elementi correttamente classificati funzione obiettivo conseguenza problema ottimizzazione vengono cos modificati minimizza vincoli pattern erroneamente classificati
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#31,31,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  -Se C ---> ∞  : non ammettiamo violazioni del margine (hard -margin SVM)
-Se C è finito : ammettiamo violazioni del margine e pattern misclassificati 
(soft-margin SVM)VincoliFunzione 
Obiettivo",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili coefficiente problema ottimizzazione precedente indica limportanza relativa errori classificazione rispetto allampiezza margine tratta pochi iperparametri lutente deve scegliere tuning passando attraverso forma otteniamo risultato uguale caso linearmente separabile tranne lintroduzione limite superiore valori moltiplicatori vincoli metodo soluzione progr quadratica modo derivare liperpiano caso linearmente separabile esempi solo errore margine minore errori margine maggiore ammettiamo violazioni margine hard margin finito ammettiamo violazioni margine pattern misclassificati soft margin vmvincoli funzione obiettivo
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#32,32,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  
All’aumentare del valore di C
!diminuisce il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",lineari pattern separabili prof davide maltoni universit bologna classificazione lineari pattern separabili coefficiente problema ottimizzazione precedente indica limportanza relativa errori classificazione rispetto allampiezza margine tratta pochi iperparametri lutente deve scegliere tuning passando attraverso forma otteniamo risultato uguale caso linearmente separabile tranne lintroduzione limite superiore valori moltiplicatori vincoli metodo soluzione progr quadratica modo derivare liperpiano caso linearmente separabile esempi solo errore margine minore errori margine maggiore allaumentare valore diminuisce numero support vector complessit problema diminuisce numero errori traning set diminuisce margine separazione capacit
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#4,4,"SVM
!In1936 ,R.A.Fisher suggested the first algorithm forPattern Recognition
(Fisher 1936 ).
!Aronszajn (1950 )introduced the“Theory ofReproducing Kernels” .
!In1957 Frank Rosenblatt invented alinear classifier called the perceptron (the
simplest kind offeedforward neural network) .
!Vapnik and Lerner (1963 )introduced the Generalized Portrait algorithm (the
algorithm implemented by support vector machines isanonlinear
generalization oftheGeneralized Portrait algorithm) .
!Aizerman, Braverman and Rozonoer (1964 )introduced the geometrical
interpretation ofthekernels asinner products inafeature space .
!Vapnik and Chervonenkis (1964 )further developed the Generalized
Portrait algorithm .
!...
!SVMs close totheir current form were first introduced with apaper attheCOLT
1992 conference (Boser, Guyon and Vapnik 1992 ).
!In1995 thesoft margin classifier was introduced byCortes and Vapnik (1995 );
inthe same year the algorithm was extended tothe case ofregression by
Vapnik (1995 )inThe Nature ofStatistical Learning Theory .
fonte: https://www.svms.org/history.html",rafisher suggested first algorithm pattern recognition fisher aronszajn introduced thetheory reproducing kernels frank rosenblatt invented alinear classifier called perceptron the simplest kind offeedforward neural network vapnik lerner introduced generalized portrait algorithm the algorithm implemented support vector machines isanonlinear generalization ofthe generalized portrait algorithm aizerman braverman rozonoer introduced geometrical interpretation ofthekernels asinner products inafeature space vapnik chervonenkis further developed generalized portrait algorithm vms close totheir current form first introduced apaper atthe conference boser guyon vapnik thesoft margin classifier introduced cortes vapnik inthe year algorithm extended tothe case ofregression vapnik nature statistical learning theory fonte
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#5,5,"SVM! SVMs (Vapnik, 1990’s) choose the linear separator with the 
largest margin  
• Good according to intuition, theory, practice  
• SVM became famous when, using images as input, it gave 
accuracy comparable to neural-network with hand-designed 
features in a handwriting recognition task Support Vector Machine (SVM) 
V. Vapnik Robust to 
outliers! 
A. Chervonenkis    XXV «                         »   * 1 
1964 
    5 1 9 . 9 5 
                             
 .  .       ,  .  .             
(      ) 
                                  ,                          -
                    .                -                              
                          .                                         -
                                                                
                           . 
1.          
  1 9 5 7  .                                                     -
                                   ,                            -
      . 
                                              ,                
                                                                     
               ,        ,   -       ,                                -
  ,     -       ,                                                    -
     . 
  
      
   . 1 
  1 9 5 7  .                                                  .   -
                                  ,                                  
                   .     -                                    . 1. 
                        ,                                        , 
                                  -        . 
   ,                                                ,        -
        ,                                                        . 
               ,                                      ,             -
    ,          % ,...,  ,                             ,              , 
                   .                                                
        .                                                        
[1].          [ 1]                                           ,           
                                                     .               , 
                                                                     
                                 ,                                  
         .              ,                    U                      
                   
£*= ejx     §2   . . .   cnfn, 
112 
                        
1.              .  . ,              .  .                                     -
             .                          ,  . X X I V ,   6, 1 9 6 3 . 
2. X        .  ,              .  ,              .  .                - 1 ,     
                            .                        ,   4.    -          . 
     . , 1 9 6 2 . 
3.            .  .                                                      . 
 .         ,        .            .    . ,  . 2,   2, 1 9 6 2 . 
4.                .    .                                                    -
            .                        ,   4.    -          .      . , 1 9 6 2 . 
5.            .                                               .          -
              ,   4.    -          .      . , 1 9 6 2 . 
ON A P E R C E P T R O N C L A S S 
V. N . V A P N I K , A . Y A . C H E R V O N E N K I S 
A c l a s s of p e r c e p t r o n s d i f f e r i n g f r o m p e r c e p t r o n s in e x i s t e n c e w i t h t h e l e a r n i n g m e t -
hod is c o n s i d e r e d . S u c h a p e r c e p t r o n is d e s c r i b e d , i t s b l o c k - s c h e m e a n d t h e l e a r n i n g m e t -
hod s a r e p r o p o s e d . T h e a l g o r i t h m s f o r v a r i o u s c l a s s e s of p e r c e p t r o n s a r e c o m p a r e d w i t h 
the t h e o r y of p a t t e r n r e c o g n i t i o n w i t h t h e h e l p of a g e n e r a l i z e d p o r t r a i t . Journal of Machine Learning Research 16 (2015) 2067-2080 Published 9/15
Alexey Chervonenkis’s Bibliography
Alex Gammerman alex@cs.rhul.ac.uk
Vladimir Vovk v.vovk@rhul.ac.uk
Computer Learning Research Centre, Department of Computer Science
Royal Holloway, University of London
This bibliography does not contain Alexey’s patents (he has at least two), technical reports,
unpublished manuscripts, and collections edited by him. ""NA"" indicates that a journal paper
was not assigned to a volume; e.g., it is common for Russian journals (such as Проблемы
управления and, in some years, Автоматика и телемеханика ) not to have volumes, and
also to have pages numbered separately inside each issue. All papers published by Alexey
before 2001 (and afterwards in the case of papers whose original language was Russian) have
author lists ordered according to the Cyrillic alphabetic order; for other papers the order
may reﬂect the authors’ contributions (people who contributed most tend to be listed ﬁrst)
and administrative positions (bosses tend to be listed last).
The bibliography is given by the year of the original publication (which may be di ﬀerent
from the year of the English translation, always given ﬁrst when available).
1964
[1] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of perceptrons. Au-
tomation and Remote Control ,2 5 ( 1 ) : 1 0 3 – 1 0 9 ,1 9 6 4 . R u s s i a no r i g i n a l : В.Н.Вапник ,
А.Я.Червоненкис .Об одном классе персептронов .Автоматика и телемеханика ,
25(1):112–120, 1964; with English summary entitled “On a perceptron class”. The orig-
inal article submitted on 21 February 1963.
[2] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of pattern-recognition
learning algorithms. Automation and Remote Control ,2 5 ( 6 ) : 8 3 8 – 8 4 5 ,1 9 6 4 . R u s s i a n
original: В.Н.Вапник ,А.Я.Червоненкис .Об одном классе алгоритмов обучения
распознаванию образов .Автоматика и телемеханика , 25(6):937–945, 1964; with
English summary entitled “A class of algorithms for pattern recognition learning”. The
submission date is not given.
[3] Vladimir N. Vapnik, Lyudmila M. Dronfort, and Alexey Ya. Chervonenkis. Some ques-
tions of the self-organization of recognizing systems (in Russian). In Theory and Appli-
cation of Automatic Systems (Russian), pages 172–177. Nauka, Moscow, 1964. In the
original language: В.Н.Вапник ,Л.М.(Людмила Михайловна )Дронфорт ,А.Я.
Червоненкис .Некоторые вопросы самоорганизации распознающих устройств .
Теория и применение автоматических систем ,сс.1 7 2 – 1 7 7 . Наука ,Москва ,1 9 6 4 .
c",vms vapnik choose linear separator largest margin good according intuition theory practice became famous when using images input gave accuracy comparable neural network hand designed features handwriting recognition task support vector machine vapnik robust outliers chervonenkis ejx cnfn hod hod journal machine learning research published alexey chervonenkiss bibliography alex gammerman vladimir vovk computer learning research centre department computer science royal holloway university london bibliography contain alexeys patents least two technical reports unpublished manuscripts collections edited him indicates journal paper assigned volume common russian journals such and years volumes also pages numbered separately inside issue papers published alexey and afterwards case papers whose original language russian author lists ordered according cyrillic alphabetic order papers order may reect authors contributions people contributed tend listed rst administrative positions bosses tend listed last bibliography given year original publication which may erent year english translation always given rst available vladimir vapnik alexey chervonenkis class perceptrons tomation remote control english summary entitled on perceptron class orig inal article submitted february vladimir vapnik alexey chervonenkis class pattern recognition learning algorithms automation remote control original english summary entitled class algorithms pattern recognition learning submission date given vladimir vapnik lyudmila dronfort alexey chervonenkis ques tions self organization recognizing systems russian theory appli cation automatic systems russian pages nauka moscow original language 
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#6,6,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas ",prof davide maltoni universit bologna classificazione support vector machines teoria governa meccanismi funzionamento stata introdotta vapnik partire statistical learning theory perfezionata recentemente stesso vapnik altri strumenti utilizzati classificazione pattern invece stimare densit probabilit classi vapnik suggerisce risolvere direttamente problema interesse che considera semplice ovvero determinare superfici decisionali classi classification boundaries andiamo gradi nasce classificatore binario classi estendibile classi affrontiamo trattazione gradi lineare superficie separazione iperpiano pattern training set linearmente separabili esiste ipotesi almeno iperpiano grado separarli lineare pattern linearmente separabili inevitabilmente errori classificazione training set esistendo alcun iperpiano grado separare pattern lineare superficie separazione complessa senza ipotesi separabilit pattern estensione multiclasse use optimization find solution hyperplane errors seek large margin separator improve generalization use kernel trick make large feature spaces computationally efficient support vector machines key ideas
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#7,7,"SVM
Le SVM si fondano su tre idee chiave
!L’adozione di tecniche di ottimizzazione matematica per 
individuare soluzioni (i.e., iperpiani) con un basso tasso di errori
!La ricerca di un separatore con margine largo per migliorare la 
generalizzazione 
!L’impiego dello stratagemma del kernel (kernel trick) per rendere 
computazionalemente efficienti ampi spazi di feature1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas ",fondano tre idee chiave ladozione tecniche ottimizzazione matematica individuare soluzioni iperpiani basso tasso errori ricerca separatore margine largo migliorare limpiego stratagemma kernel kernel trick rendere efficienti ampi spazi feature use optimization find solution hyperplane errors seek large margin separator improve generalization use kernel trick make large feature spaces computationally efficient support vector machines key ideas
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#8,8,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 Iperpiano: sottospazio di dimensione inferiore di uno (n-1) rispetto allo spazio in 
cui è contenuto (n) (e.g., se lo spazio ha dimensione 3, i suoi iperpiani sono i piani)",prof davide maltoni universit bologna classificazione support vector machines teoria governa meccanismi funzionamento stata introdotta vapnik partire statistical learning theory perfezionata recentemente stesso vapnik altri strumenti utilizzati classificazione pattern invece stimare densit probabilit classi vapnik suggerisce risolvere direttamente problema interesse che considera semplice ovvero determinare superfici decisionali classi classification boundaries andiamo gradi nasce classificatore binario classi estendibile classi affrontiamo trattazione gradi lineare superficie separazione iperpiano pattern training set linearmente separabili esiste ipotesi almeno iperpiano grado separarli lineare pattern linearmente separabili inevitabilmente errori classificazione training set esistendo alcun iperpiano grado separare pattern lineare superficie separazione complessa senza ipotesi separabilit pattern estensione multiclasse iperpiano sottospazio dimensione inferiore rispetto spazio contenuto spazio dimensione iperpiani piani
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#9,9,"3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
SVM",prof davide maltoni universit bologna classificazione lidea date due classi pattern linearmente separabili possibili iperpiani separazione determina grado separare classi maggior margine possibile margine distanza minima punti due classi training set dalliperpiano individuato definizione formale seguito massimizzazione margine legata pattern training set classificati ampio margine pu sperare pattern test set vicini confine classi gestiti correttamente prof davide maltoni universit bologna classificazione lidea date due classi pattern linearmente separabili possibili iperpiani separazione determina grado separare classi maggior margine possibile margine distanza minima punti due classi training set dalliperpiano individuato definizione formale seguito massimizzazione margine legata pattern training set classificati ampio margine pu sperare pattern test set vicini confine classi gestiti correttamente prof davide maltoni universit bologna classificazione lidea date due classi pattern linearmente separabili possibili iperpiani separazione determina grado separare classi maggior margine possibile margine distanza minima punti due classi training set dalliperpiano individuato definizione formale seguito massimizzazione margine legata pattern training set classificati ampio margine pu sperare pattern test set vicini confine classi gestiti correttamente
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#0,0,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse",sommario lineari pattern linearmente separabili lineari multiclasse
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#1,1,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 ",lineari prof davide maltoni universit bologna classificazione lineari prevede unimportante estensione teoria inizialmente sviluppata iperpiani caso non lineare separazione pattern superfici molto complesse ci avviene modo molto semplice viene definito mapping lineare pattern spazio partenza verso spazio alta dimensionalit spazio maggiori gradi libert pattern possono essere facilmente separati iperpiano utilizzando teoria nota ci equivale separare pattern superfici arbitrariamente complesse analizzando formulazione problema lagrangiano duale nota vettori training set appaiono solo forma prodotti scalari coppie vettori propriet fondamentale permette evitare manipolazione vettori spazio pu facilmente raggiungere dimensione assumere valore infinito infatti opportuni mapping possibile ricondurre prodotto scalare due pattern mappati spazio funzione detta kernel due pattern originali spazio ci consente risolvere problema ottimizzazione senza particolari complicazioni rispetto caso lineare volta determinati gli superficie separazione regola esprimibile 
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#10,10,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Si può vedere che il kernel RBF (o gaussiano) equivale a eseguire 
il prodotto interno dei dati di input mappati in un feature space a 
dimensione infinita ",lineari kernel function prof davide maltoni universit bologna classificazione lineari kernel functions polinomio grado iperparametro componenti ottenute tutte possibili combinazioni elevamento potenze componenti esempio quindi dimostra che radial basis function ampiezza iperparametro layer neural network meno utilizzato iperparametri devono essere scelti opportunamente possibile scelta numero hidden units pesi determinati automaticamente pu vedere kernel gaussiano equivale eseguire prodotto interno dati input mappati feature space dimensione infinita
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#11,11,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Il kernel 2-layer Neural Network è anche detto kernel Sigmoid",lineari kernel function prof davide maltoni universit bologna classificazione lineari kernel functions polinomio grado iperparametro componenti ottenute tutte possibili combinazioni elevamento potenze componenti esempio quindi dimostra che radial basis function ampiezza iperparametro layer neural network meno utilizzato iperparametri devono essere scelti opportunamente possibile scelta numero hidden units pesi determinati automaticamente kernel layer neural network detto kernel sigmoid
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#12,12,"SVM Non Lineari: Kernel Function
!Inoltre spesso viene chiamato kernel lineare il kernel
che equivale a utilizzare una funzione di mapping φtale 
che φ(x)=x, cioè a nonutilizzare un kernelK(x,x')=(x⋅x')",lineari kernel function inoltre spesso viene chiamato kernel lineare kernel equivale utilizzare funzione mapping tale xx cio nonutilizzare kernel kxxxx
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#13,13,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  All’aumentare del valore dell’iperparametro q (grado del polinomio)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",lineari esempi prof davide maltoni universit bologna classificazione lineari esempi polinomio polinomio allaumentare valore grado polinomio aumenta numero support vector complessit problema diminuisce numero errori traning set diminuisce margine separazione capacit
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#14,14,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  
Al diminuire del valore dell’iperparametro !(deviazione standard)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",lineari esempi prof davide maltoni universit bologna classificazione lineari esempi polinomio polinomio diminuire valore deviazione standard aumenta numero support vector complessit problema diminuisce numero errori traning set diminuisce margine separazione capacit
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#15,15,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse",sommario lineari pattern linearmente separabili lineari multiclasse
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#16,16,"SVM: Multiclasse
14 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: estensione multiclasse  
SVM  è in grado  di determinare  la superficie  di separazione  tra 2 
classi  di pattern ; come  gestire  allora  i problemi  con più di 2 classi  ? 
Si tratta  di un problema  ancora  aperto  anche  se esistono  diverse  
soluzioni ; le più utilizzate  sono : 
 
One-Against -One: che studieremo  in seguito  nell’ambito  dei multi -
classificatori . 
 
One-Against -All: 
Date  𝑠 classi , 𝑤1,𝑤2…𝑤𝑠 
Per ogni classe  𝑤𝑘, si determina  con SVM  la superficie  di 
separazione  tra i pattern  di 𝑤𝑘 (etichettati  +1) da una parte,  e i 
pattern  di tutte le rimanenti  classi  𝑤ℎ,ℎ≠𝑘 (etichettati  -1) 
dall’altra,  ottenendo  la funzione  𝐷𝑘𝐱 che indica  quanto  𝐱 è 
distante  dalla  superficie  decisionale  in direzione  di 𝑤𝑘. 
Maggiore  è 𝐷𝑘𝐱 più confidenti  siamo  dell’appartenenza  di 𝐱 a 
𝑤𝑘.  
Al termine  del training,  si assegna  il pattern  𝐱 alla classe  𝑘∗ per 
cui è massima  la distanza  dalla  superficie  decisionale :  
𝑘∗=𝑎𝑟𝑔 𝑚𝑎𝑥
𝑘𝐷𝑘𝐱 
Nota : È necessario  eseguire  𝑠 training  SVM   
 
 
 !One-Against -One
!One-Against -All",multiclasse prof davide maltoni universit bologna classificazione estensione multiclasse grado determinare superficie separazione classi pattern gestire allora problemi classi tratta problema ancora aperto esistono diverse soluzioni utilizzate one one studieremo seguito nellambito multi classificatori one all date classi ogni classe determina superficie separazione pattern etichettati parte pattern tutte rimanenti classi etichettati dallaltra ottenendo funzione indica distante superficie decisionale direzione maggiore confidenti termine training assegna pattern classe massima distanza superficie decisionale nota necessario eseguire training one one one
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#17,17,"One-Against -One
E’ingenere piùaccurato diOne-Against -All(vedi dopo), anche se
meno efficiente inquanto richiede l’addestramento diunnumero
maggiore diclassificatori
24 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  One-Against -One 
L’approccio  One-Against -One, consente  di risolvere  un problema  di 
classificazione  multi -classe , attraverso  classificatori  binari . 
È l’approccio  adottato  dalla  libreria  LIBSVM  (usata  in BioLab ). 
Se 𝑠 sono  le classi  del problema,  si addestrano  
𝑠×𝑠−1/2 classificatori  binari : tutte le possibili  coppie , 
indipendentemente  dall’ordine . 
Durante  la classificazione,  il pattern  𝐱 viene  classificato  da ogni 
classificatore  binario,  che assegna  un voto alla classe  (tra le due) 
più probabile .  
Al termine  il pattern  𝐱 è assegnato  alla classe  che ha ricevuto  più 
voti (majority  vote rule).  
 
È in genere  più accurato  di One-Against -All (discusso  in precedenza  
per SVM),  anche  se meno  efficiente  in quanto  richiede  
l’addestramento  di un numero  maggiore  di classificatori . 
 
 (Numero di combinazioni di classe k=2)",one one eingenere piaccurato one allvedi dopo meno efficiente inquanto richiede laddestramento diunnumero maggiore prof davide maltoni universit bologna classificazione one one lapproccio one one consente risolvere problema classificazione multi classe attraverso classificatori binari lapproccio adottato libreria usata bio lab classi problema addestrano classificatori binari tutte possibili coppie dallordine durante pattern viene classificato ogni classificatore binario assegna voto classe tra due probabile termine pattern assegnato classe ricevuto voti majority vote rule genere accurato one discusso precedenza meno efficiente richiede laddestramento numero maggiore classificatori numero combinazioni classe
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#18,18,"14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
 ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVMSVM: Multiclasse
(con x pattern da classificare 
e k=1, 2 ... s)  
14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVM",prof davide maltoni universit bologna classificazione estensione multiclasse ingrado dideterminare lasuperficie diseparazione tra classi dipattern come gestire allora iproblemi conpidiclassi sitratta diunproblema ancora aperto seesistono diverse soluzioni one deimulti classificatori one all date classi ogni lasuperficie separazione traipattern daunaparte pattern ditutte lerimanenti dallaltra ottenendo lafunzione cheindica quanto distante superficie decisionale indirezione di maggiore dia termine deltraining siassegna cuimassima ladistanza superficie decisionale nota necessario eseguire training multiclasse con pattern classificare prof davide maltoni universit bologna classificazione estensione multiclasse ingrado dideterminare lasuperficie diseparazione tra classi dipattern come gestire allora iproblemi conpidiclassi sitratta diunproblema ancora aperto seesistono diverse soluzioni one deimulti classificatori one all date classi ogni lasuperficie separazione traipattern daunaparte pattern ditutte lerimanenti dallaltra ottenendo lafunzione cheindica quanto distante superficie decisionale indirezione di maggiore dia termine deltraining siassegna cuimassima ladistanza superficie decisionale nota necessario eseguire training
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#19,19,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 ",implementazione prof davide maltoni universit bologna classificazione implementazione training richiede algoritmi numerici banali grado risolvere problema programmazione quadratica alcune implementazioni disponibili line esempio wrapped bio lab httpwww attenzione kernel ecc parametrizzati modo diverso comune vedi file readme txt lib svm particolare uso generico parametro gamma regolare complessit superficie decisionale aumentando superficie pu assumere forme complesse kernel opera modo inverso rispetto inserito kernel polinomiale oltre grado polinomio coef classificazione multiclasse utilizza internamente one one accurato inefficiente molte classi hsu chang lin practical guide support vector classification disponibile sito web chang lin library support vector machines transactions intelligent systems technology disponibile sito web https www autori consigliata caso lineare elevata dimensionalit elevato numero pattern light httpsvmlight joachims org
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#2,2,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili nello spazio di
partenza hanno piùprobabilità diesserlo inuno spazio apiùdimensioni,
essendo ilnumero digradi dilibertà piùelevato .",kernel trick classification ovviamente possono essere usate separare classi potrebbero essere separate classificatore lineare altrimenti applicazione casi reale interesse possibile casi coordinate oggetti mappate spazio detto feature space utilizzando funzioni lineare chiamate feature function ilfeature chiamate feature function ilfeature space spazio fortemente due classi possono essere separate classificatore lineare quindi spazio iniziale viene rimappato nuovo spazio punto viene identificato classificatore poi viene riportato spazio iniziale illustrato figurafonte stefano cavuoti classification funzione combina quindi spazio iniziale caratteristiche originali oggetti spaz features potrebbe linea principio avere dimensione infinita causa fatto spazio molte dimensioni pratico utilizzare funzione generica trovare liperpiano separazione quindi vengono usate funzioni dette kernel identifica funzione tramite combinazione funzioni kernel fonte funzioni kernel famosa lib usa quattro possibili kernel fonte jpg kernel trick possiamo trasformare dati nell input space nuovo spazio detto feature space alta dimensionalit vettori prima linearmente separabili probabilit esserlo spazio dimensioni idati nellinput space inunnuovo spazio detto feature space ipattern prima linearmente separabili spazio partenza piprobabilit diesserlo inuno spazio apidimensioni ilnumero digradi dilibert pielevato
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#20,20,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
 15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM   
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 ",implementazione prof davide maltoni universit bologna classificazione implementazione training richiede algoritmi numerici banali grado risolvere problema programmazione quadratica alcune implementazioni disponibili line esempio wrapped bio lab httpwww attenzione kernel ecc parametrizzati modo diverso comune vedi file readme txt lib svm particolare uso generico parametro gamma regolare complessit superficie decisionale aumentando superficie pu assumere forme complesse kernel opera modo inverso rispetto inserito kernel polinomiale oltre grado polinomio coef classificazione multiclasse utilizza internamente one one accurato inefficiente molte classi hsu chang lin practical guide support vector classification disponibile sito web chang lin library support vector machines transactions intelligent systems technology disponibile sito web https www autori consigliata caso lineare elevata dimensionalit elevato numero pattern light httpsvmlight joachims org prof davide maltoni universit bologna classificazione implementazione training richiede algoritmi numerici banali grado risolvere problema programmazione quadratica alcune implementazioni disponibili line esempio wrapped bio lab httpwww attenzione kernel ecc parametrizzati modo diverso comune vedi file readme txt lib svm particolare uso generico parametro gamma regolare complessit superficie decisionale aumentando superficie pu assumere forme complesse kernel opera modo inverso rispetto inserito kernel polinomiale oltre grado polinomio coef classificazione multiclasse utilizza internamente one one accurato inefficiente molte classi hsu chang lin practical guide support vector classification disponibile sito web chang lin library support vector machines transactions intelligent systems technology disponibile sito web https www autori consigliata caso lineare elevata dimensionalit elevato numero pattern light httpsvmlight joachims org prof davide maltoni universit bologna classificazione implementazione training richiede algoritmi numerici banali grado risolvere problema programmazione quadratica alcune implementazioni disponibili line esempio httpwww attenzione kernel ecc parametrizzati modo diverso comune vedi file readme txt lib svm particolare uso generico parametro gamma regolare complessit superficie decisionale aumentando superficie pu assumere forme complesse kernel opera modo inverso rispetto inserito kernel polinomiale oltre grado polinomio coef classificazione multiclasse utilizza internamente one one accurato inefficiente molte classi hsu chang lin practical guide support vector classification disponibile sito web chang lin library support vector machines transactions intelligent systems technology disponibile sito web https www autori consigliata caso lineare elevata dimensionalit elevato numero pattern light httpsvmlight joachims org
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#21,21,"SVM: Implementazione
27LIBSVM :AL i b r a r yf o rS u p p o r tV e c t o rM a c h i n e s
CHIH-CHUNG CHANG and CHIH-JEN LIN ,N a t i o n a lT a i w a nU n i v e r s i t y
LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package
since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained
wide popularity in machine learning and many other areas. In this article, we present all implementation
details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass
classiﬁcation probability estimates and parameter selection are discussed in detail.
Categories and Subject Descriptors: I.5.2 [ Pattern Recognition ]: Design Methodology— Classiﬁer design
and evaluation ;G . 1 . 6[ Numerical Analysis ]: Optimization— Quadratic programming methods
General Terms: Algorithms, Performance, Experimentation
Additional Key Words and Phrases: Classiﬁcation LIBSVM optimization regression support vector machines
SVM
ACM Reference Format:
Chang, C.-C. and Lin, C.-J. 2011. LIBSVM : A library for support vector machines. ACM Trans. Intell. Syst.
Technol. 2, 3, Article 27 (April 2011), 27 pages.
DOI=10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
1. INTRODUCTION
Support Vector Machines (SVMs) are a popular machine learning method for clas-
siﬁcation, regression, and other learning tasks. Since the year 2000, we have been
developing the package LIBSVM as a library for support vector machines.1LIBSVM is
currently one of the most widely used SVM software. In this article,2we present all
implementation details of LIBSVM .H o w e v e r ,t h i sa r t i c l ed o e sn o ti n t e n dt ot e a c ht h e
practical use of LIBSVM . For instructions of using LIBSVM ,s e et h e README ﬁle included
in the package, the LIBSVM FAQ ,3and the practical guide by Hsu et al. [2003].
LIBSVM supports the following learning tasks.
(1) SVC: support vector classiﬁcation (twoclass and multiclass);
(2) SVR: support vector regression.
(3) One-class SVM.
1The Web address of the package is at http://www.csie.ntu.edu.tw/ ∼cjlin/libsvm.
2This LIBSVM implementation document was created in 2001 and has been maintained at
http://www.csie.ntu.edu.tw/ ∼cjlin/papers/libsvm.pdf.
3LIBSVM FAQ :h t t p : / / w w w . c s i e . n t u . e d u . t w / ∼cjlin/libsvm/faq.html.
This work was supported in part by the National Science Council of Taiwan via the grants NSC 89-2213-E-
002-013 and NSC 89-2213-E-002-106.
Authors’ addresses: C.-C. Chang and C.-J. Lin (corresponding author), Department of Computer Science,
National Taiwan University, Taipei 106, Taiwan; email: cjlin@csie.ntu.edu.tw.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that
copies show this notice on the ﬁrst page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior speciﬁc permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1( 2 1 2 )
869-0481, or permissions@acm.org.
c⃝2011 ACM 2157-6904/2011/04-ART27 $10.00
DOI 10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
ACM Transactions on Intelligent Systems and Technology, Vol. 2, No. 3, Article 27, Publication date: April 2011.
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: implementazione
Iltraining diSVM, richiede algoritmi numerici nonbanali ingrado di
risolvere unproblema diprogrammazione quadratica .Alcune
implementazioni sono disponibili on-line:
LIBSVM
 -http://www .csie.ntu.edu.tw/~cjlin/libsvm
Attenzione
 iKernel (RBF, ecc.)sono parametrizzati inmodo
diverso daquello comune (vedi Readme .txtdiLibSvm e[1]).In
particolare sifausodelparametro gamma (𝛾)perregolare la
complessità della superficie decisionale .Aumentando γla
superficie puòassumere forme piùcomplesse .
N.B.Con kernel RBFγopera inmodo inverso rispetto a𝜎.
Inserito
γanche nelkernel polinomiale (oltre algrado polinomio e
Coef 0)
Per
 laclassificazione multiclasse utilizza internamente One-
Against -One [2](accurato mainefficiente permolte classi ).
Wrapped
 daScikit -Learn→sklearn .svm.SVC
[1]C.W.Hsu, C.C.Chang, andC.J.Lin,APractical Guide toSupport Vector
Classification, disponibile sulsitoweb diLIBSVM
[2]C.C.Chang andC.J.Lin.LIBSVM :alibrary forsupport vector machines .
ACM Transactions onIntelligent Systems andTechnology, 2:27:1--27:27,
2011 ,disponibile sulsitoweb diLIBSVM
LIBLINEAR
 -https ://www .csie.ntu.edu.tw/~cjlin/liblinear /
Stessi
 autori diLIBSVM, consigliata nelcaso lineare perelevata
dimensionalità edelevato numero dipattern .
Wrapped
 daScikit -Learn→sklearn .svm.LinearSVC
SVM
 -light -http://svmlight .joachims .org",implementazione library support vector machines vms actively developing package since year goal help users easily apply applications gained wide popularity machine learning many areas article present implementation details issues solving optimization problems theoretical convergence multiclass classication probability estimates parameter selection discussed detail categories subject descriptors pattern recognition design methodology classier design evaluation numerical analysis optimization quadratic programming methods general terms algorithms performance experimentation additional key words phrases classication optimization regression support vector machines reference format chang lin library support vector machines trans intell syst technol article april pages support vector machines vms popular machine learning method clas sication regression learning tasks since year developing package library support vector machines currently one widely used software articlewe present implementation details practical use instructions using le included package and practical guide hsu supports following learning tasks support vector classication twoclass multiclass support vector regression one class web address package cjlinlibsvm implementation document created maintained work supported part national science council taiwan via grants authors addresses chang lin corresponding author department computer science national taiwan university taipei taiwan email permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed prot commercial advantage copies show notice rst page initial screen display along full citation copyrights components work owned others must honored abstracting credit permitted copy otherwise republish post servers redistribute lists use component work works requires prior specic permission andor fee permissions may requested publications dept inc penn plaza suite new york fax transactions intelligent systems technology vol article publication date april prof davide maltoni universit bologna classificazione implementazione iltraining richiede algoritmi numerici nonbanali ingrado risolvere unproblema quadratica alcune implementazioni disponibili line httpwww attenzione kernel eccsono parametrizzati inmodo diverso daquello comune vedi readme txtdi lib svm ein particolare gamma perregolare complessit superficie decisionale aumentando la superficie puassumere forme picomplesse nbcon kernel bfopera inmodo inverso rispetto inserito anche nelkernel polinomiale oltre algrado polinomio coef multiclasse utilizza internamente one one accurato mainefficiente permolte classi wrapped scikit learnsklearn svms cwhsu ccchang cjlina practical guide support vector classification disponibile sulsitoweb ccchang cjlinl alibrary forsupport vector machines transactions intelligent systems technology disponibile sulsitoweb https www autori consigliata nelcaso lineare perelevata dimensionalit edelevato numero dipattern wrapped scikit learnsklearn svmlinear light httpsvmlight joachims org
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#22,22,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaSVM Lineare",esempi prof davide maltoni universit bologna classificazione esempi lib svm maschi femmine lineare lineare polinomio polinomio peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza lineare
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#23,23,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
SVM Non Lineare (Kernel Polinomiale)",esempi prof davide maltoni universit bologna classificazione esempi lib svm maschi femmine lineare lineare polinomio polinomio peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza lineare kernel polinomiale
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#24,24,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)",esempi prof davide maltoni universit bologna classificazione bf bf bf peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza esempi lib svm maschi femmine lineare kernel
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#25,25,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)",esempi prof davide maltoni universit bologna classificazione bf bf bf peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza peso altezza esempi lib svm maschi femmine lineare kernel
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#26,26,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Lineare e Non Lineare (Kernel Polinomiale)
Caso Multiclasse",esempi prof davide maltoni universit bologna classificazione lineare polinomio bf polinomio esempi lib svm multiclasse lineare lineare kernel polinomiale caso multiclasse
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#27,27,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Non Lineare (Kernel Polinomiale e Kernel RBF)
Caso Multiclasse",esempi prof davide maltoni universit bologna classificazione lineare polinomio bf polinomio esempi lib svm multiclasse lineare kernel polinomiale kernel caso multiclasse
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#28,28,"Esempi LIBSVM
Una semplicissima applicazione sviluppata
daicreatori della libreria LIBSVM che ne
illustra ilfunzionamento èdisponibile allink
seguente :
https://www.csie.ntu.edu.tw/~cjlin/libsvm/
Inparticolare, cliccando col mouse si
tracciano dei punti sullo schermo,
premendo suChange sicambia laclasse (il
colore deipunti relativi) ;infine, premendo
suRun, una semplice SVM attribuisce al
piano l’appartenenza alle varie classi
mostrandole colorate inmaniera diversa .
LIBSVM is an integrated software for support vector classification, (C -SVC, nu -SVC), 
regression (epsilon -SVR, nu -SVR) and distribution estimation (one -class SVM). 
It supports multi -class classification. ",esempi semplicissima applicazione sviluppata daicreatori libreria illustra ilfunzionamento disponibile allink seguente inparticolare cliccando mouse tracciano punti schermo premendo change sicambia laclasse colore deipunti relativi infine premendo run semplice attribuisce piano lappartenenza varie classi mostrandole colorate inmaniera diversa integrated software support vector classification regression epsilon distribution estimation one class supports multi class classification
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#29,29,"Esempi LIBSVM
This isasimple graphical interface which
shows how SVM separate data inaplane .
You canclick inthewindow todraw data
points .Use ""change"" button tochoose
class 1,2or3(i.e.,uptothree classes are
supported), ""load"" button toload data from
afile,""save"" button tosave data toafile,
""run"" button toobtain anSVM model, and
""clear"" button toclear thewindow .Youcan
enter options inthebottom ofthewindow,
thesyntax ofoptions isthesame as`svm -
train' .Note that""load"" and""save"" consider
data inthe classification but not the
regression case .Each data point hasone
label (the color) which must be1,2,or3
and two attributes (x-axis and y-axis
values) in[0,1].Type `make' inrespective
directories tobuild them ...",esempi isasimple graphical interface shows separate data inaplane canclick inthewindow todraw data points use change button tochoose class classes supported load button toload data afilesave button tosave data toafile run button toobtain model clear button toclear thewindow youcan enter options inthebottom ofthewindow thesyntax ofoptions isthesame assvm train note thatload andsave consider data inthe classification regression case each data point hasone label the color must beor two attributes axis axis values intype make inrespective directories tobuild
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#3,3,"!Dato un insieme              , una funzione                           è un kernel se 
risulta che  
dove                     e   è uno spazio di Hilbert
!Lo Spazio di Hilbert è uno spazio vettoriale che generalizza la nozione 
di Spazio Euclideo
!φ è la funzione di mapping dall’Input Space al Feature Space
!Si può dimostrare che una funzione                           è un kernel se, e 
solo se, comunque si scelgano r elementi x1, x 2, ..., x r∈X, la matrice 
K=[k(x i,xj)]i,j=1,...,r è simmetrica e semidefinita positiva
!Ogni matrice simmetrica semidefinita positiva ha tutti gli autovalori non 
negativik(x,y)=φ(x),φ(y)   ∀x,y∈XX⊂ ℜ k:X×X→ℜ
ϕ:X→ΗΗ
k:X×X→ℜKernel",dato insieme funzione kernel risulta spazio hilbert spazio hilbert spazio vettoriale generalizza nozione spazio euclideo funzione mapping dallinput space feature space pu dimostrare funzione kernel solo comunque scelgano elementi rx matrice kkx simmetrica semidefinita positiva ogni matrice simmetrica semidefinita positiva autovalori xyx kxx x kxx kernel
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#30,30,Esempi LIBSVM,esempi
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#31,31,"Esempi LIBSVM
Q:What isthedifference between
nu-SVC and C-SVC? Basically they
arethesame thing butwith different
parameters .The range ofCisfrom
zero toinfinity but nu isalways
between [0,1].Anice property ofnuis
thatitisrelated totheratio ofsupport
vectors and theratio ofthetraining
error.
Additionally one-class SVM type is
supported fordistribution estimation .
The one-class SVM type gives the
possibility tolearn from justone class
ofexamples and later ontest ifnew
examples match theknown ones .",esempi qwhat isthedifference basically arethesame thing butwith different parameters the range cisfrom zero toinfinity isalways anice property ofnuis thatitisrelated totheratio ofsupport vectors theratio ofthetraining error additionally one class type supported fordistribution estimation one class type gives possibility tolearn justone class ofexamples later ontest ifnew examples match theknown ones
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#32,32,"SVM in pratica
19 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM in pratica  
Lineare  o Non-lineare?   
se la dimensionalità  𝑑 dello  spazio  è molto  elevata  (es. 5000  
feature ) si utilizza  generalmente  SVM  lineare . Infatti  in uno 
spazio  così grande  i pattern  sono  tipicamente  molto  sparsi  e 
anche  «semplici»  iperpiani  sono  in grado  di separare  le 
classi  efficacemente . Il solo iperparametro  da tarare  è 𝐶.  
per bassa  dimensionalità  (es. 20 feature ) la scelta  primaria  è 
SVM  non lineare  con kernel  RBF. Gli iperparametri  da tarare  
sono  𝐶 e V (o γ se si utilizza  LIBSVM ). 
Per media  dimensionalità  (es. 200 features ) in genere  si 
provano  entrambe  le tipologie  (i.e., anche  questa  scelta  
diventa  un iperparametro ). 
Come  sempre  gli iperparametri  si tarano  su un validation  set 
separato,  oppure  attraverso  cross -validation  sul training  set. 
 
Come  gestire  il caso  multi -classe?   
Tipicamente  ci si affida  alla soluzione  disponibile  nella  libreria  
utilizzata  (One-Agaist -One per LIBSVM ). 
Se però il numero  di classi  è molto  elevato,  il costo  può 
diventare  inaccettabile  per certe  applicazioni . In questo  caso  
One-Against -All diventa  la scelta  obbligata .  
 ",pratica prof davide maltoni universit bologna classificazione pratica lineare lineare dimensionalit spazio molto elevata feature utilizza generalmente lineare infatti spazio cos grande pattern tipicamente molto sparsi semplici iperpiani grado separare classi efficacemente solo iperparametro tarare bassa dimensionalit feature scelta primaria lineare kernel iperparametri tarare utilizza media dimensionalit features genere provano entrambe tipologie scelta diventa iperparametro sempre iperparametri tarano validation set separato oppure attraverso cross validation training set gestire caso multi classe tipicamente affida soluzione disponibile libreria utilizzata one agaist one per numero classi molto elevato costo pu diventare inaccettabile certe applicazioni caso one diventa scelta obbligata
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#33,33,"SVM in pratica
",pratica
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#34,34,"SVM in sintesi
!Vantaggi
!Si basa su una teoria ben fondata
!Presenta eccellenti proprietà di generalizzazione
!La funzione obiettivo non presenta minimi locali
!Può essere impiegata per individuare funzioni discriminanti non lineari
!La complessità del classificatore è caratterizzata dal numero di su pport 
vector piuttosto che dalla dimensionalità dello spazio trasformato
!Svantaggi
!Tende ad essere più lenta rispetto ad altri metodi
!La programmazione quadratica è computazionalmente onerosa ",sintesi vantaggi basa teoria ben fondata presenta eccellenti propriet funzione obiettivo presenta minimi locali pu essere impiegata individuare funzioni discriminanti lineari complessit classificatore caratterizzata numero pport vector piuttosto dimensionalit spazio trasformato svantaggi tende essere lenta rispetto altri metodi programmazione quadratica onerosa
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#35,35,"!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , 
Pearson, 2020.
!C. Burges, A Tutorial on Support Vector Machines for Pattern Recognition , 
1998.
!S. Gunn, Support Vector Machines for Classification and Regression , 1998.
!D. Maltoni, Machine Learning , Università di Bologna, 2017.
!C.W. Hsu, C.C. Chang, and C.J. Lin, A Practical Guide to Support Vector 
Classification , Last updated: May 19, 2016.
!C.C. Chang and C.J. Lin, LIBSVM: A Library for Support Vector Machines , ACM 
Transactions on Intelligent Systems and Technology, 2:27:1 —27:27, 2011.
!G. Raiconi, Support Vector Machines: Concetti ed Esempi , Università di 
Salerno 2016.
!R.O. Duda, P.E. Hart, and D.G. Stork. 2000. Pattern Classification (2nd 
Edition). Wiley -Interscience, New York, NY, USA. 
!C.M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.Riferimenti",russell norvig artificial intelligence modern approach pearson burges tutorial support vector machines pattern recognition gunn support vector machines classification regression maltoni machine learning universit bologna hsu chang lin practical guide support vector classification last updated may chang lin library support vector machines transactions intelligent systems technology raiconi support vector machines concetti esempi universit salerno duda hart stork pattern classification edition wiley interscience new york bishop pattern recognition machine learning springer
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#4,4,"Kernel
!Uno spazio di Hilbert     è uno spazio vettoriale Hreale o 
complesso sul quale è definito un prodotto interno tale che, detta d 
la distanza indotta da       su H, lo spazio metrico ( H, d) sia completo
!Uno spazio metrico è un insieme di elementi, detti punti , nel quale è 
definita una distanza , detta anche metrica (lo spazio metrico più 
comune è lo spazio euclideo di dimensione 1, 2 o 3)
!Uno spazio metrico completo è uno spazio metrico in cui tutte le 
successioni di Cauchy sono convergenti ad un elemento dello spazio
!Una successione di Cauchy è una successione tale che, comunque si 
fissi una distanza arbitrariamente piccola ε> 0, da un certo punto in poi 
tutti gli elementi della successione hanno distanza reciproca inferiore 
ad ε=(H,⋅,⋅) Η
⋅,⋅
⋅,⋅",kernel uno spazio hilbert spazio vettoriale hreale complesso definito prodotto interno tale che detta distanza indotta spazio metrico completo uno spazio metrico insieme elementi detti punti definita distanza detta metrica spazio metrico comune spazio euclideo dimensione uno spazio metrico completo spazio metrico tutte successioni cauchy convergenti elemento spazio una successione cauchy successione tale che comunque fissi distanza arbitrariamente piccola certo punto poi elementi successione distanza reciproca inferiore h
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#5,5,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 ",lineari prof davide maltoni universit bologna classificazione lineari prevede unimportante estensione teoria inizialmente sviluppata iperpiani caso non lineare separazione pattern superfici molto complesse ci avviene modo molto semplice viene definito mapping lineare pattern spazio partenza verso spazio alta dimensionalit spazio maggiori gradi libert pattern possono essere facilmente separati iperpiano utilizzando teoria nota ci equivale separare pattern superfici arbitrariamente complesse analizzando formulazione problema lagrangiano duale nota vettori training set appaiono solo forma prodotti scalari coppie vettori propriet fondamentale permette evitare manipolazione vettori spazio pu facilmente raggiungere dimensione assumere valore infinito infatti opportuni mapping possibile ricondurre prodotto scalare due pattern mappati spazio funzione detta kernel due pattern originali spazio ci consente risolvere problema ottimizzazione senza particolari complicazioni rispetto caso lineare volta determinati gli superficie separazione regola esprimibile 
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#6,6,"SVM Non Lineari
!In altri termini, possiamo calcolare w*, b*e funzione di 
decisione in maniera analoga a quanto visto in precedenza
!Utilizzando il kernel evitiamo l’operazione costosa di 
trasformazione e prodotto interno nello spazio trasformato, 
essendo il kernel una funzione dei pattern originali definiti 
nell’Input Space ℜd
!Possiamo inoltre effettuare trasformazioni in spazi a 
dimensione infinita
!In sintesi, le proprietà del prodotto scalare consentono di 
esprimere il prodotto scalare dei pattern immagine (""(x) ∈ℜm) 
corrispondenti ai pattern in input (x ∈ℜd) semplicemente come 
funzioni kernel dei pattern in input (x ∈ℜd)",lineari altri termini possiamo calcolare funzione decisione maniera analoga visto precedenza utilizzando kernel evitiamo loperazione costosa trasformazione prodotto interno spazio trasformato kernel funzione pattern originali definiti nellinput space possiamo inoltre effettuare trasformazioni spazi dimensione infinita sintesi propriet prodotto scalare consentono esprimere prodotto scalare pattern immagine m corrispondenti pattern input d semplicemente funzioni kernel pattern input d
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#7,7,"Kernel Trick
!Pattern linearmente non separabili possono diventare 
linearmente separabili se trasformati, o mappati, in uno spazio 
dimensionale superiore
!Il calcolo della matematica vettoriale (cioè i prodotti scalari) in 
uno spazio dimensionale assai elevato è costoso dal punto di 
vista computazionale
!Il trucco del kernel consente di calcolare in modo efficiente 
prodotti scalari di dimensioni molto elevate
!Esso consente di mappare in pattern in input in modo implicito 
in uno spazio dimensionale più elevato (possibilmente infinito) 
con un overhead computazionale ridotto
!“In modo implicito”, in quanto i vettori a dimensionalità 
superiore non sono mai effettivamente costruiti",kernel trick pattern linearmente separabili possono diventare linearmente separabili trasformati mappati spazio dimensionale superiore calcolo matematica vettoriale cio prodotti scalari spazio dimensionale assai elevato costoso punto vista computazionale trucco kernel consente calcolare modo efficiente prodotti scalari dimensioni molto elevate esso consente mappare pattern input modo implicito spazio dimensionale elevato possibilmente infinito overhead computazionale ridotto in modo implicito vettori dimensionalit superiore mai effettivamente costruiti
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#8,8,"Kernel Function: Esempio
!Supponiamo di avere i seguenti due vettori bidimensionali 
""=$!,$""e &='!,'""
!La funzione seguente ((*)mappa vettori bidimensionali in vettori 
tridimensionali
!Il modo standard per calcolare
è prima mappare i pattern in input nello spazio delle feature e poi 
eseguire il prodotto scalare nello spazio a dimensione più elevata
!Tuttavia, il prodotto scalare può essere effettuato interamente nello 
spazio originale a due dimensioni(,=-!""
2-!-""
-""""
(""*(&
(""*(&=$!""'!""+2$!$""'!'""+$""""'""""=""*&""",kernel function esempio supponiamo avere seguenti due vettori bidimensionali funzione seguente mappa vettori bidimensionali vettori tridimensionali modo standard calcolare prima mappare pattern input spazio feature poi eseguire prodotto scalare spazio dimensione elevata tuttavia prodotto scalare pu essere effettuato interamente spazio originale due dimensioni
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#9,9,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 ",lineari kernel function prof davide maltoni universit bologna classificazione lineari kernel functions polinomio grado iperparametro componenti ottenute tutte possibili combinazioni elevamento potenze componenti esempio quindi dimostra che radial basis function ampiezza iperparametro layer neural network meno utilizzato iperparametri devono essere scelti opportunamente possibile scelta numero hidden units pesi determinati automaticamente
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#0,0,"MATLAB (MATrix LABoratory)
!Per installare il sofftware, accedere all’Area Sistemi Informativi di Roma Tre 
disponibile al seguente indirizzo: http://asi.uniroma3.it/ ---> cliccare su ‘servizi 
agli studenti’ ---> scorrere fino in fondo e cliccare su ‘MathWorks’
",atrix aboratory per installare sofftware accedere allarea sistemi informativi roma tre disponibile seguente indirizzo cliccare servizi studenti scorrere fino fondo cliccare math works
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#1,1,"MATLAB
Manualetto di Matlabr
L. Scuderi
1 Comandi d’avvio
Per avviare Matlab in ambiente Windows ` e su éciente selezionare con il mouse l’icona corrispon-
dente. In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il tasto di invio (o
enter, return, ...). Il simbolo >>che compare, ` e il prompt di Matlab . Per eseguire un comando
digitato occorre premere il tasto di invio. Per terminare la sessione di lavoro occorre digitare il
comando exit oppure quit .
Tabella 1. Alcuni comandi per gestire una sessione di lavoro.
Comando Signiﬁcato
help per visualizzare tutti gli argomenti presenti
help arg per visualizzare informazioni su arg
doc arg per visualizzare dettagliate informazioni su arg
clc per cancellare il contenuto della ﬁnestra di lavoro
; per non visualizzare il risultato di un’istruzione
... per continuare a scrivere un’istruzione nella riga successiva
who per visualizzare le variabili poste in memoria
whos per visualizzare informazioni sulle variabili poste in memoria
clear per cancellare tutte le variabili dalla memoria
clear var1 var2 per cancellare le variabili var1 evar2 dalla memoria
2 Le variabili in Matlab
I nomi delle variabili possono essere lunghi al massimo 32 caratteri. I caratteri utilizzabili sono
le lettere (maiuscole e minuscole), i numeri e il carattere “ _” (underscore). Un nome di variabile
deve cominciare con un carattere alfabetico (a-z, A-Z). Matlab distingue tra lettere maiuscole
e minuscole (ad esempio i nomi a1edA1rappresentano variabili diverse). La variabile si crea
automaticamente nel momento in cui si assegna ad essa un valore o il risultato di un’espressione.
L’assegnazione avviene mediante il simbolo =secondo la seguente sintassi
>> nome_variabile=espressione
Se la variabile che si vuole creare ` e di tipo stringa occorre racchiudere espressione tra una
coppia di apici. Nella tabella 2 abbiamo riportato alcune variabili scalari predeﬁnite.
Matlab lavora con sedici cifre signiﬁcative. Tuttavia, in output una variabile intera viene
visualizzata generalmente in un formato privo di punto decimale, mentre una variabile reale (non
intera) viene visualizzata solo con quattro cifre decimali. Se si vuole modiﬁcare il formato di output
si pu` o utilizzare uno dei comandi della tabella 3. Per visualizzare tutte le sedici cifre impiegate da
Matlab ` e necessario attivare il comando format long e .
Nella tabella 4 abbiamo riportato le principali operazioni eseguibili sulle variabili scalari. Oltre
alle operazioni di base, in Matlab sono presenti anche le funzioni predeﬁnite riportate nella tabella
5.
Gli elementi di un vettore vanno digitati tra parentesi quadre; gli elementi di un vettore riga
vanno separati con uno spazio oppure una virgola, quelli di un vettore colonna con un punto e virgola
1!Per avviare Matlab in ambiente Windows o Mac è sufficiente selezionare con 
il mouse l’icona corrispondente!In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il 
tasto Invio (o Enter, Return, ... )!Il simbolo >> che compare nella Command Window è il prompt di Matlab!Per eseguire un comando digitato occorre premere il tasto Invio!Per terminare la sessione di lavoro occorre digitare il comando exit o quit!Seguono alcuni comandi per gestire una sessione di lavoro",manualetto matlabr scuderi comandi davvio avviare matlab ambiente windows ciente selezionare mouse licona corrispon dente ambiente dos ambiente unix basta digitare matlab premere tasto invio enter return simbolo che compare prompt matlab eseguire comando digitato occorre premere tasto invio terminare sessione lavoro occorre digitare comando exit oppure quit tabella alcuni comandi gestire sessione lavoro comando signicato help visualizzare argomenti presenti help arg visualizzare informazioni arg doc arg visualizzare dettagliate informazioni arg clc cancellare contenuto nestra lavoro visualizzare risultato unistruzione continuare scrivere unistruzione riga successiva visualizzare variabili poste memoria whos visualizzare informazioni variabili poste memoria clear cancellare tutte variabili memoria clear var var cancellare variabili var evar memoria variabili matlab nomi variabili possono essere lunghi massimo caratteri caratteri utilizzabili lettere maiuscole minuscole numeri carattere underscore nome variabile deve cominciare carattere alfabetico matlab distingue lettere maiuscole minuscole esempio nomi aed arappresentano variabili diverse variabile crea automaticamente momento assegna essa valore risultato unespressione lassegnazione avviene mediante simbolo secondo seguente sintassi variabile vuole creare tipo stringa occorre racchiudere espressione coppia apici tabella riportato alcune variabili scalari predenite matlab lavora sedici cifre signicative tuttavia output variabile intera viene visualizzata generalmente formato privo punto decimale mentre variabile reale non intera viene visualizzata solo quattro cifre decimali vuole modicare formato output utilizzare comandi tabella visualizzare tutte sedici cifre impiegate matlab necessario attivare comando format long tabella riportato principali operazioni eseguibili variabili scalari oltre operazioni base matlab presenti funzioni predenite riportate tabella elementi vettore vanno digitati parentesi quadre elementi vettore riga vanno separati spazio oppure virgola vettore colonna punto virgola per avviare matlab ambiente windows mac sufficiente selezionare mouse licona ambiente dos ambiente unix basta digitare matlab premere tasto invio enter return simbolo compare command window prompt matlabper eseguire comando digitato occorre premere tasto invioper terminare sessione lavoro occorre digitare comando exit quitseguono alcuni comandi gestire sessione lavoro
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#10,10,"Esempi in MATLAB
!Overfitting con SVM Non Lineare (Kernel Gaussiano)
σ=1/15, C=106Esempi in MATLAB –(7)
49
•Vediamo invece un esempio di overfitting utilizzando il kernel
gaussiano con 𝜎=1/15e 𝐶=106:
",esempi overfitting lineare kernel gaussiano esempi vediamo invece esempio overfitting utilizzando kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#11,11,"Esempi in MATLAB
% … caricamento dei dati come nel caso precedente …%
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei petali
y = ~strcmp(species,'virginica'); % label 0 se Iris viginica, 1 se altre specie
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6,'KernelFunction' ,'gaussian' ,'KernelScale' ,
1/15);
% … disegno dello scatter plot come nel caso precedente …%
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2),'ko','MarkerSize',10) % cerchia i vettori di supporto
legend('Iris virginica','Altre specie','Support vectors','Location','southeast')
axis manual
% … disegno dello scatter plot come nel caso precedente …%
d=0.02; % intervallo utilizzato per generare la griglia di punti
[x1Grid,x2Grid]=meshgrid(min(X(:,1)):d:max(X(:,1)),min(X(:,2)):d:max(X(:,2))); % 
generazione della griglia
xGrid=[x1Grid(:),x2Grid(:)];
[~,scores1]=predict(SVMModel,xGrid); % valutiamo l’output del modello nei punti 
della griglia
contour(x1Grid,x2Grid,reshape(scores1(:,2),size(x1Grid)),[0 0],'k'); % plot del 
confine di decisione",esempi caricamento dati caso precedente load fisheriris carica osservazioni meas label species xmeas estrae lunghezza larghezza petali label iris viginica altre specie caricamento dati caso precedente box constraint ekernel function gaussian kernel scale disegno scatter plot caso precedente figure scatter plot vettori training hold modelsupport vectors size cerchia vettori supporto legendiris axis manual disegno scatter plot caso precedente intervallo utilizzato generare griglia punti gridx generazione griglia gridx gridx grid modelx grid valutiamo loutput modello punti griglia contourx gridx grid plot confine decisione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#12,12,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%!Overfitting con SVM Non Lineare (Kernel Gaussiano)",esempi caricamento dati caso precedente box constraint kernel function gaussian kernel scale disegno scatter plot caso precedente overfitting lineare kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#13,13,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Overfitting con SVM Non Lineare (Kernel Gaussiano)",esempi caricamento dati caso precedente box constraint kernel function gaussian kernel scale disegno scatter plot caso precedente overfitting lineare kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#14,14,"Esempi in MATLAB
σ=1/15, C=106Esempi in MATLAB –(8)
50
𝐶=106,𝜎=1/15
!Overfitting con SVM Non Lineare (Kernel Gaussiano)",esempi esempi overfitting lineare kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#15,15,"Esempi in MATLAB
!Esempio di SVM Non Lineare (Kernel Gaussiano)
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%",esempi esempio lineare kernel gaussiano caricamento dati caso precedente box constraint kernel function gaussian kernel scale disegno scatter plot caso precedente
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#16,16,"Esempi in MATLAB
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Esempio di SVM Non Lineare (Kernel Gaussiano)",esempi caricamento dati caso precedente box constraint kernel function gaussian kernel scale disegno scatter plot caso precedente esempio lineare kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#17,17,"Esempi in MATLAB
σ=5, C=100
Esempi in MATLAB –(8)
51
𝐶=100,𝜎=5!Esempio di SVM Non Lineare (Kernel Gaussiano)",esempi esempi lineare kernel gaussiano
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#18,18,"Classification Learner
The Classification Learner app lets you train models toclassify data using supervised
machine learning .
Using Classification Learner, you can perform common machine learning tasks such
asinteractively exploring your data, selecting features, specifying validation schemes,
training models, and assessing results .Choose from several classification types
including decision trees ,support vector machines (SVM) ,and k-nearest neighbors ,
and select from ensemble methods such asbagging, boosting, and random subspace .
Classification Learner helps you choose thebest model foryour data byletting you
perform model assessment and model comparisons using confusion matrices and
ROC curves .Export classification models tothe MATLAB workspace togenerate
predictions onnew data, orgenerate MATLAB code tointegrate models into
applications such ascomputer vision, signal processing, and data analytics .",classification learner classification learner app lets train models toclassify data using supervised machine learning using classification learner perform common machine learning tasks asinteractively exploring data selecting features specifying validation schemes training models assessing results choose several classification types including decision trees support vector machines and nearest neighbors select ensemble methods asbagging boosting random subspace classification learner helps choose thebest model foryour data byletting perform model assessment model comparisons using confusion matrices curves export classification models tothe workspace togenerate predictions onnew data orgenerate code tointegrate models applications ascomputer vision signal processing data analytics
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#19,19,"Classification Learner
Matrice diConfusione (oTabella diErrata Classificazione) :rappresentazione
dell'accuratezza diclassificazione statistica .
Ogni colonna della matrice rappresenta ivalori predetti, mentre ogni riga
rappresenta ivalori reali (i.e.,l'elemento sulla riga iesulla colonna jèilnumero di
casi incui ilclassificatore haclassificato laclasse ""vera"" icome classe j).
Attraverso questa matrice èosservabile seviè""confusione"" nella classificazione di
diverse classi .
Curve ROC (Receiver Operating Characteristic) :schemi grafici perunclassificatore
binario .
Lungo idue assi sipossono rappresentare lasensibilità e(1-specificità), come True
Positive Rate (vero positivo) eFalse Positive Rate (falso positivo) .Inaltri termini, si
studiano irapporti fraveri allarmi (hitrate) efalsi allarmi alvariare diuna soglia .",classification learner matrice confusione tabella errata statistica ogni colonna matrice rappresenta ivalori predetti mentre ogni riga rappresenta ivalori reali riga iesulla colonna jilnumero casi incui haclassificato laclasse vera icome classe attraverso matrice osservabile classificazione diverse classi curve receiver operating characteristic schemi grafici binario lungo idue assi sipossono rappresentare lasensibilit specificit true positive rate vero positivo false positive rate falso positivo inaltri termini studiano irapporti fraveri allarmi hitrate efalsi allarmi alvariare diuna soglia
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#2,2,"Esempi in MATLAB
!Dataset multivariato Iris (Fisher's 1936 iris data)
!50 esemplari di Iris Setosa , 50 di Iris Versicolor , 50 di Iris Virginica
!4 feature: lunghezza e larghezza del sepalo, lunghezza e larghezza 
del petalo
!Sepalo: in botanica, ciascuno degli elementi, simili a foglioline verdi, 
che formano il calice del fiore
!Utilizzeremo solo lunghezza e larghezza del sepalo (per poter 
visualizzare i dati)
!Funzione fitcsvm di MATLAB (metodo di ottimizzazione adottato: 
Sequential Minimal Optimization (SMO))
",esempi dataset multivariato iris fishers iris data esemplari iris setosa iris versicolor iris virginica feature lunghezza larghezza sepalo lunghezza larghezza petalo sepalo botanica ciascuno elementi simili foglioline verdi formano calice fiore utilizzeremo solo lunghezza larghezza sepalo per poter visualizzare dati funzione fitcsvm metodo ottimizzazione adottato sequential minimal optimization
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#20,20,"Classification Learner
-Avviare Matlab
-Scaricare il file ClassificationLearner_Example_Datasets.mat
-Doppio clic sul file ClassificationLearner_Example_Datasets.mat
-Selezionare i dati che si desidera importare 
[e.g., FisherIris (Numero di feature (predittori): 4, Numero di pattern (osservazioni): 150, Numero di 
classi: 3); tabella di 150 righe (osservazioni) e 5 colonne (4 valori delle feature + classe)]
-Digitare Finish per importarli nel Workspace di Matlab
-Avviare l’app Classification Learner (vedi scheda APPS o digitare al prompt il 
comando classificationLearner )",classification learner avviare matlab scaricare file classification learner example datasetsmat doppio clic file classification learner example datasetsmat selezionare dati desidera importare fisher iris numero feature predittori numero pattern osservazioni numero classi tabella righe osservazioni colonne valori feature classe digitare finish importarli workspace matlab avviare lapp classification learner vedi scheda digitare prompt comando classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#21,21,"Classification Learner
-New Session —> From Workspace
-Selezionare le feature e l’eventuale metodo di validazione
-Start Session
-Selezionare uno o più algoritmi di classificazione dalla barra superiore (per 
selezionare i parametri vedi Advanced)
-Train e buon divertimento!
-per ulteriori dettagli: https://it.mathworks.com/help/stats/classificationlearner -app.html",classification learner new session workspace selezionare feature leventuale metodo validazione start session selezionare algoritmi classificazione barra superiore per selezionare parametri vedi advanced train buon divertimento ulteriori dettagli apphtml
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#22,22,"CL Features
",features
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#23,23,"CL Features
",features
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#24,24,"CL Features
",features
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#25,25,"CL Features
-Linear SVM
-Fine Gaussian SVM (Kernel Scale=0.35)
-Medium Gaussian SVM (Kernel Scale=1.4)
-Coarse Gaussian SVM (Kernel Scale=5.7)
-Quadratic SVM (Kernel Polinomiale con grado=2)
-Cubic SVM (Kernel Polinomiale con grado=3)
-Kernel scale parameter, specified as the comma -separated pair consisting of 'KernelScale' and 'auto' or a positive 
scalar. The software divides all elements of the predictor matrix X by the value of KernelScale. Then, the software 
applies the appropriate kernel norm to compute the Gram matrix.
-per ulteriori dettagli digitare al prompt il comando doc fitcsvm",features linear fine gaussian kernel scale medium gaussian kernel scale coarse gaussian kernel scale quadratic kernel polinomiale grado cubic kernel polinomiale grado kernel scale parameter specified comma separated pair consisting kernel scale auto positive scalar software divides elements predictor matrix value kernel scale then software applies appropriate kernel norm compute gram matrix ulteriori dettagli digitare prompt comando doc fitcsvm
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#26,26,"CL Features
",features
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#27,27,"CL Features
",features
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#28,28,"Altri Dataset
",altri dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#29,29,Altri Dataset,altri dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#3,3,"Dataset Fisher Iris
",dataset fisher iris
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#30,30,Altri Dataset,altri dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#31,31,Altri Dataset,altri dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#32,32,Altri Dataset,altri dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#33,33,"Classification Learner
",classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#34,34,"Classification Learner
“Plotting the fisheriris data, you can see that sepal length
and sepal width separate one ofthe classes well
(setosa) .You need toplot other predictors (features) to
see ifyou can separate theother two classes .”",classification learner plotting fisheriris data see sepal length sepal width separate one ofthe classes well setosa you need toplot predictors features see ifyou separate theother two classes
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#35,35,"Classification Learner
",classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#36,36,"Classification Learner
",classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#37,37,"Classification Learner
",classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#38,38,"Classification Learner
",classification learner
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#39,39,"Classification Learner
“Plotting thefisheriris data, you can seethat petal length and petal
width arethefeatures that separate theclasses best.”",classification learner plotting thefisheriris data seethat petal length petal width arethefeatures separate theclasses best
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#4,4,"Esempi in MATLAB
fitcsvm trains or cross -validates a support vector machine (SVM) model for 
two-class (binary) classification on a low -dimensional or moderate -
dimensional predictor data set. fitcsvm supports mapping the predictor data 
using kernel functions, and supports sequential minimal optimization (SMO), 
iterative single data algorithm (ISDA), or L1 soft -margin minimization via 
quadratic programming for objective -function minimization. Matlab Help
The support vectors are observations that occur on or beyond their estimated 
class boundaries. 
You can adjust the boundaries (and, therefore, the number of support 
vectors) by setting a box constraint during training using the 'BoxConstraint'
name -value ( C) pair argument.",esempi fitcsvm trains cross validates support vector machine model two class binary classification low dimensional moderate dimensional predictor data set fitcsvm supports mapping predictor data using kernel functions supports sequential minimal optimization iterative single data algorithm soft margin minimization via quadratic programming objective function minimization matlab help support vectors observations occur beyond estimated class boundaries adjust boundaries and therefore number support vectors setting box constraint training using box constraint name value pair argument
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#40,40,"L'errore di classificazione è uguale, ma i classificatori sono molto diversi fra loro!Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Classificatore 1  
(assegn aun 
oggetto sempre 
alla prima classe )
Errore: 3/10 = 0.3 
(30%)Classificatore 2Valutazione Prestazioni
Errore: 3/10 = 0.3
(30%)Il sempice errore di classificazione (i.e., numero di errori / numero totale di classificazioni) 
non sempre ci permette di capire o confrontare completamente due classificatori.
Esempio:",lerrore classificazione uguale classificatori molto diversi fra lorovera assegnata vera assegna classificatore assegn aun oggetto sempre prima classe errore valutazione prestazioni errore sempice errore classificazione numero errori numero totale sempre permette capire confrontare completamente due classificatori esempio
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#41,41,"Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Elementi della classe 1 classificati  
come appartenenti alla classe 1
Elementi della classe 1classificati 
come appartenenti alla classe 2
Elementi della classe 2 classificati  
come appartenenti alla classe 2Matrice di Confusione
Elementi della classe 2classificati  
come appartenenti alla classe 15 2
1 2EsempioMatrice Mche ci dice come un classificatore opera rispetto alle diverse classi 
m(i,j) = numero di elementi della classe iclassificati come elementi della classe j
In altri termini, indice di riga i:valore reale , indice di colonna j:valore predetto",vera assegna elementi classe classificati appartenenti classe elementi classe classificati appartenenti classe elementi classe classificati appartenenti classe matrice confusione elementi classe classificati appartenenti classe esempio matrice mche dice classificatore opera rispetto diverse classi mij numero elementi classe iclassificati elementi classe altri termini indice riga ivalore reale indice colonna jvalore predetto
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#42,42,"Matrice di Confusione
L'errore di classificazione può essere calcolato facilmente dalla matrice di 
confusione
La somma di tutti gli elementi non appartenenti alla diagonale principale
O, meglio, può essere calcolato come “1 -Accuracy”
Accuracy: somma elementi diagonale principale / numero elementi totali",matrice confusione lerrore classificazione pu essere calcolato facilmente matrice confusione somma elementi appartenenti diagonale principale meglio pu essere calcolato accuracy accuracy somma elementi diagonale principale numero elementi totali
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#43,43,"Nel caso di problema a due classi la matrice di 
confusione  assume una forma particolare (2 classi, 
positivi vs negativi)
True  
Positive  
(TP)False  
Negative  
(FN)
False  
Positive  
(FP)True  
Negative  
(TN)ESEMPIO: classificazione tra malati (positivi) e sani(negativi)
CLASSIFICAZIONE CORRETTA:
Veri positivi: pazienti malati classificati come malati
Veri negativi: pazienti sani classificati come sani
CLASSIFICAZIONE ERRATA:
Falsi positivi: pazienti sani classificati come malati
Falsi negativi: pazienti malati classificati come saniMatrice di Confusione",caso problema due classi matrice confusione assume forma particolare classi positivi negativi true positive pfalse negative false positive ptrue negative classificazione malati positivi saninegativi veri positivi pazienti malati classificati malati veri negativi pazienti sani classificati sani falsi positivi pazienti sani classificati malati falsi negativi pazienti malati classificati sani matrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#44,44,"Dalla matrice di confusione possono essere calcolati diversi indici
Indice Formula Intuizione
Accuracy Percentuale di classificazioni corrette
Precision Percentuale di classificazioni positive che  
sono corrette
Recall (Sensitivity) Percentuale di elementi positivi del tes tset 
che sono stati classificati come positivi
Specificity Percentuale di elementi negativi del test set 
che sono stati classificati come negativi
Precision: se dico “positivo”, è corretto ?
Recall: riesco a trovare tuttii positivi del testing set?Matrice di Confusione
TN
TN+FPTP
TP+FNTP+TN
TP+FP+TN+FN
TP
TP+FP",matrice confusione possono essere calcolati diversi indici indice formula intuizione accuracy percentuale classificazioni corrette precision percentuale classificazioni positive corrette recall sensitivity percentuale elementi positivi tes tset stati classificati positivi specificity percentuale elementi negativi test set stati classificati negativi precision dico positivo corretto recall riesco trovare tuttii positivi testing setmatrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#45,45,"Matrice di Confusione
Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegnata
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 7/10 (0.7)
Recall: 7/7 (1)
Specificity: 0/3 (0)TP:7 FN:0
FP:3 TN:0Indice Formula
Accuracy
Precision
Recall (Sensitivity)
Specificity
Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 5/6 (0.83)
Recall: 5/7 (0.71)
Specificity: 2/3 (0.66)TP:5 FN:2
FP:1 TN:2TP+TN
TP+FP+TN+FN
TP
TP+FP
TP
TP+FN
TN
TN+FP",matrice confusione vera assegnata vera assegnata matrice diconfusione accuracy precision recall specificity indice formula accuracy precision recall sensitivity specificity matrice diconfusione accuracy precision recall specificity tpt
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#46,46,"blu50 10
20 20Supponiamo diaver addestrato unmodello utilizzando 100
esempi ditraining .Diquesti 100,60sono diclasse “rosso” e
40sono diclasse “blu”.
Ilmodello haeffettuato leseguenti classificazioni :
Etichette predette
rosso blu
rosso
Etichette
realiMatrice di Confusione",blu supponiamo diaver addestrato unmodello utilizzando esempi ditraining diquesti sono diclasse rosso sono diclasse blu ilmodello haeffettuato leseguenti classificazioni etichette predette rosso blu rosso etichette reali matrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#47,47,"rosso
blu50 10
20 20Etichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione",rosso blu etichette predette rosso blu somma sempre pari numero pattern reale etichetta predetta tipo predizione rosso rosso true positive rosso blu false negative blu blu true negative blu rosso false positive matrice confusione etichette reali matrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#48,48,"rosso
bluTP FN
FP TNEtichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione",rosso blu netichette predette rosso blu somma sempre pari numero pattern reale etichetta predetta tipo predizione rosso rosso true positive rosso blu false negative blu blu true negative blu rosso false positive matrice confusione etichette reali matrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#49,49,"Precision: =50 / (50+20) =0.7142
TP +FPEtichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Precision: ""Quanti dei pattern che ho predetto di tipo rosso sono
davvero pattern di classe rosso ?""
TPMatrice di Confusione",precision petichetta reale etichetta predetta tipo predizione rosso rosso true positive rosso blu false negative blu blu true negative blu rosso false positive misure performance precision quanti pattern predetto tipo rosso davvero pattern classe rosso pmatrice confusione
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#5,5,"Esempi in MATLAB
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei sepali
y = ~strcmp(species, 'setosa' ); % label 0 se Iris setosa, 1 se altre specie
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,+Inf); % C=+Inf —> hard-margin linear SVM
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2), 'ko','MarkerSize' ,10) % cerchia i vettori di supporto
legend('Iris setosa' ,'Altre specie' ,'Support vectors' ,'Location' ,'southeast' )
axis manual
x1 = linspace( -5,5);
f=@(x)(-SVMModel.Bias -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % iperpiano di 
separazione
plot(x1,f(x1))
f1=@(x)( -SVMModel.Bias+1 -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
positivo
plot(x1,f1(x1))
f2=@(x)( -SVMModel.Bias -1-SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
negativo
plot(x1,f2(x1))",esempi load fisheriris carica osservazioni meas label species xmeas estrae lunghezza larghezza sepali setosa label iris setosa altre specie box constraint inf cinf hard margin linear figure scatter plot vettori training hold modelsupport vectors komarker size cerchia vettori supporto legendiris setosa altre specie support vectors location southeast axis manual linspace modelbias modelbeta iperpiano separazione plotxfx modelbias modelbeta margine positivo plotxfx modelbias modelbeta margine negativo plotxfx
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#50,50,"Recall 
(Sensi tivity) :
TP
Sensitivity: =50 / (50+10) =0.8333Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
TP + FN
somma dei positivi nel training setMatrice di Confusione
“Dei pattern che dovrei predire come rosso (positivo) 
quanti ne ho predetti di classe rosso (positivo)?”",recall sensi tivity sensitivity etichetta reale etichetta predetta tipo predizione rosso rosso true positive rosso blu false negative blu blu true negative blu rosso false positive misure performance somma positivi training set matrice confusione dei pattern dovrei predire rosso positivo predetti classe rosso positivo
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#51,51,"Specificity: = 20 / (20+20) =0.5Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Specifici ty:Matrice di Confusione
TN“Dei pattern che dovrei predire come blu(negativo) 
quanti ne ho predetti di classe blu(negativo)?”
TN+FP
somma dei negativi nel training set",specificity etichetta reale etichetta predetta tipo predizione rosso rosso true positive rosso blu false negative blu blu true negative blu rosso false positive misure performance specifici tymatrice confusione ndei pattern dovrei predire blunegativo predetti classe blunegativo somma negativi training set
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#52,52,"Lacurva ROC (Receiver Operating Characteristic) èuna
tecnica statistica attualmente utilizzata inuna grande varietà di
campi scientifici .
Questa tecnica trae origine nell'ambito della teoria della
rilevazione delsegnale .Sitratta diunametodologia cheèstata
adottata per laprima volta daalcuni ingegneri, durante la
seconda guerra mondiale, perl'analisi delle immagini radar elo
studio delrapporto segnale/disturbo .
E'possibile usare lacurva ROC anche pervalutare leprestazioni
diunmodello diclassificazione .Curva ROC",lacurva receiver operating characteristic una tecnica statistica attualmente utilizzata inuna grande variet campi scientifici tecnica trae origine nellambito teoria rilevazione delsegnale sitratta chestata adottata laprima volta daalcuni ingegneri durante seconda guerra mondiale perlanalisi immagini radar elo studio delrapporto epossibile usare lacurva pervalutare leprestazioni diunmodello curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#53,53,"Sistema molto utilizzato per valutare un classificatore binario
basato susoglia
Legenda: 
Positivo = Disease (Malati) 
Negativo = Normal (Sani)
Classificazione:
Negativo < !
Positivo > !
Variando il valore di soglia 
!(cut-off)si ottengono 
diversi valori di TP, TN, FP,
FN
Esempio: con ilvalore  di !
in figura i Falsi Positivi 
sono azeroCurva ROC
!",sistema molto utilizzato valutare classificatore binario basato susoglia legenda positivo disease malati negativo normal sani negativo positivo variando valore soglia cut offsi ottengono diversi valori esempio ilvalore figura falsi positivi azero curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#54,54,"La curva ROC mette in relazione la specificity (recall) 
conla sensitivity al variare della soglia
Fissata una soglia, quanti sono i veri positivi rispetto ai falsipositivi? 
Come si calcola:
Si fa variare la soglia calcolando i  
corrispondenti veri positivi e falsi  
positivi, che rappresentano un  
punto della curva
Il valore minimo/massimo della  
soglia è quello per cui sono tutti  
falsi positivi o tutti veri positiviCurva ROC",curva mette relazione specificity recall conla sensitivity variare soglia fissata soglia veri positivi rispetto falsipositivi calcola variare soglia calcolando corrispondenti veri positivi falsi positivi rappresentano punto curva valore minimomassimo soglia falsi positivi veri positivi curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#55,55,"Fissatauna sogliat,
peri tutti gliesempi  
quali il
(classificatore)modello
genera
unoscore >tvengono  
predetti positivi.
Questo cipermette di
quantificare, per ogni
scelta del valore di
soglia ,TP,TN, FPe
FN.
TP
FPCurva ROC
TN
FN",fissatauna sogliat peri gliesempi quali genera unoscore tvengono predetti positivi cipermette quantificare ogni scelta valore soglia pcurva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#56,56,"Fissato unvalore dit
possiamo calcolare, ad
esempio :
TP=0.5  
FN=0.5  
FP=0.12  
FN=0.88
Possiamo  
identificare un  
punto sulla curva  
(associato al  
valore di tscelto)Curva ROC",fissato unvalore dit possiamo calcolare esempio possiamo identificare punto curva associato valore tsceltocurva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#57,57,"Possiamo calcolare TP  
e FP per una serie di  
valori  di t (es. 0.1,0.2,
0.3, 0.4, 0.5, 0.6, …,
1.0). In questo modo  
otteniamo diversi punti  
che compongono la  
curva ROC.
Curva ROC
Il valore degli score 
generati dal 
classificatore può 
variare tra 0 e 1.",possiamo calcolare serie valori modo otteniamo diversi punti compongono curva curva valore score generati classificatore pu variare
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#58,58,"A seconda di come si vuole operare si sceglie lasoglia
Esempio 1 (curva) : Sensitivity al 95%, si 
ottiene un corrispondente valore di Specificity
(70%)
Esempio 2 (segmento tratteggiato) : 
Sensitivity = 100-Specificity, si chiama 
Equal Error Rate
Curva ROC",seconda vuole operare sceglie lasoglia esempio curva sensitivity ottiene corrispondente valore specificity esempio segmento tratteggiato sensitivity specificity chiama equal error rate curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#59,59,"Ciò che èimportante
però non èlacurva di
persé,mal’area sotto
la curva . Questa
quantità èindicata con
iltermine Area Under
theROC Curve (AUC )
Curva ROC",ci importante per lacurva persmalarea sotto curva quantit indicata iltermine area curve curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#6,6,"Esempi in MATLAB Esempi in MATLAB –(3)
45
𝐶=+∞C=+∞
",esempi esempi c
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#60,60,"AUC = 1:
Il classificatore è  
perfetto
AUC = 0.5 :
Il classificatore è
totalmente casuale
(lancio diunamoneta)
Curva ROC",classificatore perfetto classificatore totalmente casuale lancio diunamoneta curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#61,61,"Rispetto a TP e FP :
TP:0, FP:0
Predice sempre «negativo»
TP:1, FP:1
Predice sempre «positivo»
TP:1, FP:0
Classificatore ideale
Curva ROC",rispetto predice sempre negativo predice sempre positivo classificatore ideale curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#62,62,"Si possono confrontare curve ROC calcolando l'area
sotto la curva (AUC –Area Under theCurve)
Un AUC più grande 
implica unclassificatore
migliore
Curva ROC",possono confrontare curve calcolando larea sotto curva area curve grande implica migliore curva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#63,63,A B CA migliore di B migliore di C (C=lancio moneta)Curva ROC,migliore migliore clancio monetacurva
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#64,64,"Join the protest!!!
",join protest
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#7,7,"Esempi in MATLAB
C=+∞Esempi in MATLAB –(4)
46
𝐶=+∞
",esempi cesempi
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#8,8,"Esempi in MATLAB
C=1Esempi in MATLAB –(5)
47
𝐶=1
",esempi esempi
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#9,9,"Esempi in MATLAB
C=10−6Esempi in MATLAB –(6)
48
𝐶=10−6
",esempi esempi
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: SVM (Ex 14)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#1,1,"Sommario
Scikit-learn e SVM 
SVM e Iris dataset 
Use case: Stock forecasting 
Use case: Sentiment Analysis",sommario scikit learn iris dataset use case stock forecasting use case sentiment analysis
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#10,10,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
... (completa)
11",esercitazione stock forecasting sklearnsvm import sklearnmetrics import accuracyscore import pandas import numpy import plt pltstyleuse seaborn darkgrid import warnings ignore pdreadcsv ecsv findex date dfdrop date axis columns completa
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#11,11,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
df[
'Open-Close'
 ] = df.Open - df.Close
df[
'High-Low'
 ] = df.High - df.Low
  
# per ora uso solo 2 valori
X = df[[
 'Open-Close'
 , 
'High-Low'
 ]]
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
>> [1 1 1 ... 1 0 0]
... (segue)
12",esercitazione stock forecasting sklearnsvm import sklearnmetrics import accuracyscore import pandas import numpy import plt pltstyleuse seaborn darkgrid import warnings ignore pdreadcsv ecsv findex date dfdrop date axis columns open close dfopen dfclose high low dfhigh dflow ora uso solo valori open close high low npwheredf close shift close segue
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#12,12,"Esercitazione: stock forecasting
split_percentage = 
 0.8
split = 
 int
(split_percentage*
 len
(df))
  
# Train data set
X_train = X[:split]
y_train = y[:split]
  
# Test data set
X_test = X[split:]
y_test = y[split:]
cls = SVC().fit(X_train, y_train)
df[
'Predicted_Signal'
 ] = cls.predict(X)
df[
'Return'
 ] = df.Close.pct_change()
df[
'Strategy_Return'
 ] = df.Return *df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
import
 matplotlib.pyplot 
 as
 plt
%matplotlib 
 inline
  
plt.plot(df[
 'Cum_Ret'
 ],color=
 'red'
)
plt.plot(df[
 'Cum_Strategy'
 ],color=
 'blue'
)
13",esercitazione stock forecasting split int len train data set xtrain xsplit ytrain ysplit test data set xtest xsplit ytest ysplit cls ytrain predicted signal clspredictx return strategy return dfreturn dfpredicted signalshift cum ret return cumsum cum strategy strategy return cumsum import plt matplotlib inline pltplotdf cum ret color red pltplotdf cum strategy color blue
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#13,13,"Esercitazione: stock forecasting
14
",esercitazione stock forecasting
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#14,14,"Esercitazione: stock forecasting
L'algoritmo genera un ritorno del 18.87% in un 1 anno, rispetto al 5.97% 
del titolo azionario. 
La funzione accuracy_score() restituisce una accuracy del 62.07% sul train 
set e 50.67 sul test set. 
Esercizi: (1) crea il target value a distanza di più giorni dall'istanza 
corrente; (2) usa gli ultimi 15 valori Close come istanza di input per predire 
il successivo; (3) impiega altri kernel (es. rbf).
15
",esercitazione stock forecasting lalgoritmo genera ritorno anno rispetto titolo azionario funzione restituisce accuracy train set test set esercizi crea target value distanza giorni dallistanza corrente usa ultimi valori close istanza input predire successivo impiega altri kernel rbf
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#15,15,"Esercitazione: Sentiment Analysis
Tecnica molto popolare per classiﬁcare brani di testo, micropost o frasi in 
linguaggio naturale in base al sentimento (es. positivo, negativo, neutro). 
Supponiamo di impiegare le review di ﬁlm, es: 
http://www.cs.cornell.edu/people/pabo/movie-review-data/  
Movie-review data for use in sentiment-analysis experiments. Available are collections of 
movie-review documents labeled with respect to their overall 
 sentiment polarity
  (positive 
or negative) or 
 subjective rating
  (e.g., ""two and a half stars"") and sentences labeled with 
respect to their 
 subjectivity status
  (subjective or objective) or 
 polarity 
import pandas as pd  
trainData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/train.csv
 "") 
testData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/test.csv
 "") 
trainData.sample(frac=1).head(5) # shuffle the df and pick first 5  
      
Content                                             
 Label 
56
    jarvis cocker of pulp once said that he wrote ...   pos  
1467
  david spade has a snide , sarcastic sense of h...   neg  
392
   upon arriving at the theater during the openin...   pos  
104
   every once in a while , a film sneaks up on me...   pos  
1035
  susan granger's review of "" american outlaws ""...   neg
16",esercitazione sentiment analysis tecnica molto popolare classicare brani testo micropost frasi linguaggio naturale base sentimento positivo negativo neutro supponiamo impiegare review lm review data movie review data use sentiment analysis experiments available collections movie review documents labeled respect overall sentiment polarity positive negative subjective rating two half stars sentences labeled respect subjectivity status subjective objective polarity import pandas train data pdreadcsv test data pdreadcsv train shuffle pick first content label jarvis cocker pulp said wrote pos david spade snide sarcastic sense neg upon arriving theater openin pos every film sneaks pos susan grangers review american outlaws neg
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#16,16,"Esercitazione: Sentiment Analysis
Per impiegare il testo come input agli algoritmi di ML spesso si effettua una 
pipeline di processamento per trasformare parole o frasi in vettori numerici. 
Per dettagli: 
 https://medium.com/@vasista/preparing-the-text-data-with-
scikit-learn-b31a3df567e
   e  
https://scikit-learn.org/stable/modules/
generated/sklearn.feature_extraction.text.TﬁdfVectorizer.html   
from sklearn.feature_extraction.text import TfidfVectorizer  
# ignora i termini che compaiono in meno di 5 documenti 
# e i termini che compaiono in > 80% dei documenti; 
# abilita l'inverse document frequency per pesare i termini 
vectorizer = TfidfVectorizer(min_df = 5,  
                             max_df = 0.8,  
                             sublinear_tf = True,  
                             use_idf = True)  
train_vectors = vectorizer.fit_transform(trainData['Content'])  
test_vectors = vectorizer.transform(testData['Content']) 
Esercizio
 : completa il codice impiegando SVM lineare e valutane 
l'accuratezza. Testa la predizione su review di Amazon.
17",esercitazione sentiment analysis impiegare testo input algoritmi spesso effettua pipeline processamento trasformare parole frasi vettori numerici dettagli text data scikit learn badfe httpsscikit vectorizerhtml import tfidf vectorizer ignora termini compaiono meno documenti termini compaiono documenti abilita linverse document frequency pesare termini vectorizer tfidf maxdf sublineartf true useidf true trainvectors testvectors esercizio completa codice impiegando lineare valutane laccuratezza testa predizione review amazon
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#17,17,"Esercitazione: Sentiment Analysis
from sklearn import svm 
from sklearn.metrics import classification_report 
classifier_linear = svm.SVC(kernel='linear') 
classifier_linear.fit(train_vectors, trainData['Label']) 
prediction_linear = classifier_linear.predict(test_vectors) 
time_linear_train = t1-t0 
time_linear_predict = t2-t1 
report = classification_report(testData['Label'], prediction_linear, 
output_dict=True) 
print('positive: ', report['pos']) 
print('negative: ', report['neg']) 
positive:  {'precision': 0.9191919191919192, 'recall': 0.91, 'f1-score': 
0.9145728643216081, 'support': 100} 
negative:  {'precision': 0.9108910891089109, 'recall': 0.92, 'f1-score': 
0.9154228855721394, 'support': 100} 
review = """"""Very good picture and sound, very glad I chose this unit"""""" 
review_vector = vectorizer.transform([review]) # vectorizing 
print(classifier_linear.predict(review_vector))  
18",esercitazione sentiment analysis sklearn import svm sklearnmetrics import svms train datalabel report datalabel reportpos reportneg positive precision recall score support negative precision recall score support review very good picture sound glad chose unit reviewvector vectorizing
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#18,18,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and TensorFlow: 
Concepts, Tools, and Techniques to Build Intelligent Systems
 . O'Reilly Media 
2017 
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-
using-pandas/notebook   
https://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-
b31a3df567e    
https://scikit-learn.org/stable/modules/generated/
sklearn.feature_extraction.text.TﬁdfVectorizer.html  
Tutorial: 
 https://www.geeksforgeeks.org/predicting-stock-price-direction-using-
support-vector-machines/?ref=rp  
Tutorial: 
 https://medium.com/@vasista/sentiment-analysis-using-
svm-338d418e3ff1
Testi di Riferimento
19",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media started time series using pandasnotebook text data scikit learn badfe httpsscikit vectorizerhtml tutorial stock price direction using support vector tutorial analysis using svm deff testi riferimento
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#2,2,"Support Vector Machines
L'algoritmo SVM è impiegato in ambito di classiﬁcazione e regressione. 
Ha molti vantaggi tra cui: 
Efﬁcace in spazi con molte dimensioni (cioè features) 
Può trattare casi in cui le dimensioni sono maggiori delle istanze 
È efﬁciente in termini di spazio di memoria richiesto 
Attenzione: 
Se le dimensioni sono molto maggiori delle istanze, la scelta della 
funzione kernel e la regolarizzazione sono fondamentali. 
SVM non restituisce direttamente probabilità.
3",support vector machines lalgoritmo impiegato ambito classicazione regressione molti vantaggi cui efcace spazi molte dimensioni cio features pu trattare casi dimensioni maggiori istanze efciente termini spazio memoria richiesto attenzione dimensioni molto maggiori istanze scelta funzione kernel fondamentali restituisce direttamente probabilit
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#3,3,"Scikit-learn: Support Vector Machines
I dati in input supportati in scikit-learn sono sia 
 dense
  (es. 
numpy.ndarray
 , 
numpy.asarray
 ) sia sparsi (qualsiasi 
 scipy.sparse
 ) 
>>> 
from 
sklearn 
import
 svm 
>>> 
X 
=
 [[
0
, 
0
], [
1
, 
1
]] 
>>> 
y 
=
 [
0
, 
1
] 
>>> 
clf 
=
 svm
.
SVC() 
>>> 
clf
.
fit(X, y) 
SVC() 
>>> 
clf
.
predict([[
 2.
, 
2.
]]) 
array([1]) 
>>> 
# support vectors  
>>> 
clf
.
support_vectors_ 
array([[0., 0.],  
       [1., 1.]])  
>>> 
# indici dei support vectors  
>>> 
clf
.
support_ 
array([0, 1]...)  
>>> 
# numero dei support vectors per ogni classe  
>>> 
clf
.
n_support_ 
array([1, 1]...)
4",scikit learn support vector machines dati input supportati scikit learn dense numpyndarray numpyasarray sparsi qualsiasi scipysparse sklearn import svm clf svm clf fitx clf predict array support vectors clf array indici support vectors clf support array numero support vectors ogni classe clf nsupport array
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#4,4,"Scikit-learn: Support Vector Machines
Esempio IRIS dataset: 
# carico il dataset IRIS
iris 
=
 load_iris()
# uso solo le prime due features
X 
=
 iris.data[:, :
 2
]
Y 
=
 iris.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)
# equivale a SVC(kernel
 =
""linear""
 )
svm 
=
 LinearSVC()
svm.fit(X_train_std, Y_train)
 
print
(
""Accuracy Train Set:""
 , svm.score(X_train_std, Y_train))
print
(
""Accuracy Test Set:""
 , svm.score(X_test_std, Y_test))
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire?
5",scikit learn support vector machines esempio dataset carico dataset iris loadiris uso solo prime due features irisdata iristarget xtrain xtest ytrain ytest testsize randomstate scaler standard scaler xtrainstd xteststd equivale vckernel linear svm linear ytrain print accuracy train set ytrain print accuracy test set ytest accuracy train set accuracy test set cosa possiamo dire
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#5,5,"Scikit-learn: Support Vector Machines
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire? 
Il modello soffre di overﬁtting. 
Esercizio: prova ad impiegare tutte le features del dataset.
6
",scikit learn support vector machines accuracy train set accuracy test set cosa possiamo dire modello soffre overtting esercizio prova impiegare tutte features dataset
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#6,6,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features.
7",scikit learn support vector machines esercizio prova impiegare tutte features dataset accuracy train set accuracy test set esercizio cambia parametro kernel testa altre funzioni oltre linear cio rbf sigmoid poly impiegando sempre features
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#7,7,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features. 
8
Accuracy Train Set: 0.81
Accuracy Test Set: 0.78Accuracy Train Set: 0.72
Accuracy Test Set: 0.8Accuracy Train Set: 0.76
Accuracy Test Set: 0.67",scikit learn support vector machines esercizio prova impiegare tutte features dataset accuracy train set accuracy test set esercizio cambia parametro kernel testa altre funzioni oltre linear cio rbf sigmoid poly impiegando sempre features accuracy train set accuracy test set accuracy train set accuracy test set accuracy train set accuracy test set
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#8,8,"Stock forecasting
Alcuni servizi web rendono disponibili gli andamenti di titoli azionari via 
APIs, es: 
Open: Starting price at which a stock is traded in a day. 
Close: Closing price. 
High: The highest price of equity symbol in a day. 
Low: The lowest price of the share in a day 
VWAP: Volume weighted average price 
Volume: Total volume of stocks traded on a particular day.  
I dati possono essere interpretati come 
 time series
 , cioè sequenze di valori 
ordinati temporalmente. 
Per approfondimenti:  
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-using-pandas/notebook  
Il task della stock price forecasting è predire il valore futuro (es. intraday, 
giornalieri, mensile, etc). di un titolo in base ai valori passati.
9",stock forecasting alcuni servizi web rendono disponibili andamenti titoli azionari via pis open starting price stock traded day close closing price high highest price equity symbol day low lowest price share day volume weighted average price volume total volume stocks traded particular day dati possono essere interpretati time series cio sequenze valori ordinati temporalmente started time series using pandasnotebook task stock price forecasting predire valore futuro intraday giornalieri mensile etc titolo base valori passati
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#9,9,"Esercitazione: stock forecasting
Al seguente indirizzo trovi i dati storici del titolo RELIANCE: 
https://storage.googleapis.com/kaggle-forum-message-attachments/894813/16059/RELIANCE.csv 
Possiamo impiegare l'istanza attuale come input e tentare di fare predizione 
sul comprare (+1) oppure no (0). 
In ambito azionario è utile deﬁnire nuove features che combinano quelle 
attuali, es. Open-Close o High-Low: 
df[
'Open-Close'
 ] = df.Open - df.Close
La variabile target puoi essere approssimare nel seguente modo: 
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
Il ritorno cumulato può essere ottenuto nel seguente modo: 
df[
'Return'
 ] = df.Close.pct_change() 
 # variazione percentuale rispetto al prec
df[
'Strategy_Return'
 ] = df.Return * df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
Esercizio
 : impiega l'algoritmo SVM per la predizione e valuta l'accuratezza.
10",esercitazione stock forecasting seguente indirizzo trovi dati storici titolo forum message ecsv possiamo impiegare listanza attuale input tentare fare predizione comprare oppure ambito azionario utile denire nuove features combinano attuali open close high low open close dfopen dfclose variabile target puoi essere approssimare seguente modo npwheredf close shift close ritorno cumulato pu essere ottenuto seguente modo return variazione percentuale rispetto prec strategy return dfreturn dfpredicted signalshift cum ret return cumsum cum strategy strategy return cumsum esercizio impiega lalgoritmo predizione valuta laccuratezza
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Riduzione di Dimensionalità",machine learning universit roma tre dipartimento ingegneria anno accademico riduzione dimensionalit
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#1,1,"Sommario
!Introduzione
!Definizioni
!Le Principali Tecniche
!PCA vs LDA
!Principal Component Analysis (PCA)
!Linear Discriminant Analysis (LDA)
!t-SNE",sommario introduzione definizioni principali tecniche principal component analysis linear discriminant analysis
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#10,10,"PCA: Retro -Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘",retro proiezione prof davide maltoni universit bologna riduzione dimensionalit proiezione retroproiezione proiezione ouna volta determinato lospazio proiezione diunpattern sutale spazio semplicemente proiezione geometrica chedefinisce lospazio inrealt lavera proiezione geometrica unvettore chehalastessa dimensionalit delvettore originale mentre contesto indichiamo proiezione ilvettore ridotto spazio operazione eseguita prodotto matrice diproiezione trasposta perilpattern alquale sottratta lamedia retro proiezione mdato unvettore spazio lasua retro proiezione verso lospazio originale siottiene moltiplicando ilvettore perlamatrice diproiezione esommando ilvettore medio questa trasformazione sposta spazialmente vettore giace ancora spazio camaopera cambiamento dicoordinate nepermette lacodifica termini spazio originale prof davide maltoni universit bologna riduzione dimensionalit proiezione retroproiezione proiezione ouna volta determinato lospazio proiezione diunpattern sutale spazio semplicemente proiezione geometrica chedefinisce lospazio inrealt lavera proiezione geometrica unvettore chehalastessa dimensionalit delvettore originale mentre contesto indichiamo proiezione ilvettore ridotto spazio operazione eseguita prodotto matrice diproiezione trasposta perilpattern alquale sottratta lamedia retro proiezione mdato unvettore spazio lasua retro proiezione verso lospazio originale siottiene moltiplicando ilvettore perlamatrice diproiezione esommando ilvettore medio questa trasformazione sposta spazialmente vettore giace ancora spazio camaopera cambiamento dicoordinate nepermette lacodifica termini spazio originale 
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#11,11,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2",esempio riduzione prof davide maltoni universit bologna riduzione dimensionalit esempio riduzione ellisse rappresenta distribuzione pattern training set sono autovettori matrice covarianza autovalori sono varianze distribuzione lungo assi sono proiezioni sugli assi piccolo pu essere approssimato senza perdite significative informazione pu dimostrare tutte riduzioni dimensionalit lineari preserva massimo linformazione vettori originali spazio iniziale spazio prof davide maltoni universit bologna riduzione dimensionalit esempio riduzione ellisse rappresenta distribuzione pattern training set sono autovettori matrice covarianza autovalori sono varianze distribuzione lungo assi sono proiezioni sugli assi piccolo pu essere approssimato senza perdite significative informazione pu dimostrare tutte riduzioni dimensionalit lineari preserva massimo linformazione vettori originali spazio iniziale spazio 
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#12,12,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2",esempio riduzione prof davide maltoni universit bologna riduzione dimensionalit esempio riduzione ellisse rappresenta distribuzione pattern training set sono autovettori matrice covarianza autovalori sono varianze distribuzione lungo assi sono proiezioni sugli assi piccolo pu essere approssimato senza perdite significative informazione pu dimostrare tutte riduzioni dimensionalit lineari preserva massimo linformazione vettori originali spazio iniziale spazio 
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#13,13,"PCA: Scelta di k
8prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: scelta di 𝑘
Talvolta
 lascelta di𝑘èobbligata :adesempio per la
visualizzazione 2Do3Ddeidati.
Quando
 invecel’obiettivo èquello discartare informazione
inutile edati correlati mantenendo gran parte delcontenuto
informativo sipuòscegliere 𝑘nelmodo seguente :
Fissata
 una percentuale 𝑡delcontenuto informativo chesi
vuole preservare (es.𝑡=95%)sisceglie ilminimo valore di
𝑘percuilasomma deipiùgrandi𝑘autovalori ,rispetto alla
somma dituttigliautovalori ,èmaggiore ouguale a𝑡.
Considerando
 gliautovalori ordinati inordine decrescente :
𝑘=𝑎𝑟𝑔𝑚𝑖𝑛
𝑧σ𝑖=1…𝑧𝜆𝑖
σ𝑖=1…𝑑𝜆𝑖≥𝑡
Infatti, ricordando che gliautovalori denotano lavarianza
lungo idiversi assi, ilrapporto nella formula indica lavarianza
«conservata» rispetto allavarianza totale .",scelta prof davide maltoni universit bologna riduzione dimensionalit scelta talvolta lascelta diobbligata adesempio visualizzazione ddeidati quando quello discartare informazione inutile edati correlati mantenendo gran parte delcontenuto informativo sipuscegliere nelmodo seguente fissata percentuale delcontenuto informativo chesi vuole preservare ilminimo valore percuilasomma rispetto somma maggiore ouguale considerando gliautovalori ordinati inordine decrescente infatti ricordando gliautovalori denotano lavarianza lungo idiversi assi ilrapporto formula indica lavarianza conservata rispetto allavarianza totale
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#14,14,"PCA: Codifica di Immagini
9prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: codifica di un’immagine
𝐱∈16500
𝐲∈15
𝐱′∈16500Immagine
originaleRicostruzione
(retroproiezione)
proiezione retro-proiezioneiprimi 8 autovettori o componenti principali
(denominati eigenfaces nell’applicazione al riconoscimento volto )
𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ15𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ15
-2532 2193 -2179 2099 491
427 -324 961 35 -40
-149 -624 317 -158 -142",codifica immagini prof davide maltoni universit bologna riduzione dimensionalit codifica unimmagine immagine originale ricostruzione proiezione retro autovettori componenti principali denominati eigenfaces riconoscimento volto
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#15,15,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺",calcolo pratica prof davide maltoni universit bologna riduzione dimensionalit calcolo pratica perelevato tipico nelcaso diimmagini audio ecclamatrice covarianza puessere molto grande milioni divalori calcolare lamatrice diproiezione primi autovettori attraverso decomposizione matrice rettangolare deipattern centralizzati senza passare perlamatrice dicovarianza vedi decomposizone ortonormale diagonale autovettori eautovalori dipossono dunque essere ottenuti colonne divettori singolari sinistri elementi diagonali dialquadrato valori singolari alquadrato di madsen hansen winther singular value decomposition principal component analysis attenzione formato trasposto rispetto usata regressione ogni pattern colonna decomposizione spettrale matrice quadrata prof davide maltoni universit bologna riduzione dimensionalit calcolo pratica perelevato tipico nelcaso diimmagini audio ecclamatrice covarianza puessere molto grande milioni divalori calcolare lamatrice diproiezione primi autovettori attraverso decomposizione matrice rettangolare deipattern centralizzati senza passare perlamatrice dicovarianza vedi decomposizone ortonormale diagonale autovettori eautovalori dipossono dunque essere ottenuti colonne divettori singolari sinistri elementi diagonali dialquadrato valori singolari alquadrato di madsen hansen winther singular value decomposition principal component analysis attenzione formato trasposto rispetto usata regressione ogni pattern colonna decomposizione spettrale matrice quadrata
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#16,16,"Singular Value Decomposition (SVD)
!LaDecomposizione aiValori Singolari (Singular Value
Decomposition, SVD) èuna importante fattorizzazione per
matrici avalori reali ocomplessi chesiavvale diautovalori
eautovettori
!Ogni matrice M∈!m×npuò essere fattorizzata in 
M=U""V*
dove
!Uèuna matrice m×munitaria (cioè UUt=Im)
!#èuna matrice m×ndiagonale rettangolare con soli elementi
reali non negativi
!V*èlatrasposta coniugata diuna matrice n×nunitaria V",singular value decomposition decomposizione valori singolari singular value decomposition una importante fattorizzazione matrici avalori reali ocomplessi chesiavvale diautovalori eautovettori ogni matrice mmnpu essere fattorizzata muv uuna matrice mmunitaria cio utim una matrice mndiagonale rettangolare soli elementi reali negativi vlatrasposta coniugata diuna matrice nnunitaria
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#17,17,"Singular Value Decomposition (SVD)
!Glielementi della diagonale di""sono detti valori singolari diM
!Lemcolonne diUsono dette vettori singolari sinistri diM
!Lencolonne diVsono dette vettori singolari destri diM
!Vale quanto segue
!Ivettori singolari sinistri diMsono gliautovettori diM∙M*
!Ivettori singolari destri diMsono gliautovettori diM*∙M
!Ivalori singolari diMsono leradici quadrate degli autovalori non
nulli diM∙M* eM*∙M",singular value decomposition glielementi diagonale disono detti valori singolari lemcolonne usono dette vettori singolari sinistri lencolonne vsono dette vettori singolari destri vale segue ivettori singolari sinistri msono gliautovettori mm ivettori singolari destri msono gliautovettori mm ivalori singolari msono leradici quadrate autovalori nulli mm mm
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#18,18,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
",calcolo pratica prof davide maltoni universit bologna riduzione dimensionalit calcolo pratica perelevato tipico nelcaso diimmagini audio ecclamatrice covarianza puessere molto grande milioni divalori calcolare lamatrice diproiezione primi autovettori attraverso decomposizione matrice rettangolare deipattern centralizzati senza passare perlamatrice dicovarianza vedi decomposizone ortonormale diagonale autovettori eautovalori dipossono dunque essere ottenuti colonne divettori singolari sinistri elementi diagonali dialquadrato valori singolari alquadrato di madsen hansen winther singular value decomposition principal component analysis attenzione formato trasposto rispetto usata regressione ogni pattern colonna decomposizione spettrale matrice quadrata prof davide maltoni universit bologna riduzione dimensionalit calcolo pratica perelevato tipico nelcaso diimmagini audio ecclamatrice covarianza puessere molto grande milioni divalori calcolare lamatrice diproiezione primi autovettori attraverso decomposizione matrice rettangolare deipattern centralizzati senza passare perlamatrice dicovarianza vedi decomposizone ortonormale diagonale autovettori eautovalori dipossono dunque essere ottenuti colonne divettori singolari sinistri elementi diagonali dialquadrato valori singolari alquadrato di madsen hansen winther singular value decomposition principal component analysis attenzione formato trasposto rispetto usata regressione ogni pattern colonna decomposizione spettrale matrice quadrata
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#19,19,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2Ricordiamo, infatti, che gliautovettori della matrice dicovarianza !
sono paralleli agli assi dell’ellisse che rappresenta ladistribuzione dei
pattern delTraning Set(TS)",whitening prof davide maltoni universit bologna riduzione dimensionalit whitening unatecnica dipre normalizzazione deidati che rimuove lecorrelazioni ruotando lanuvola punti allineare gliassi divariazione principale deidati autovettori sfericizza lellissoide uniformando levarianze denotate autovalori alungo tuttigliassi dopo aver proiettato ipattern spazio definito daiprimi autovettori sufficiente dividere ogni dimensione perlaradice quadrata dellautovalore corrispondente deviazione standard lamatrice dicovarianza deidati normalizzati lidentit ricordiamo infatti gliautovettori matrice dicovarianza paralleli assi dellellisse rappresenta ladistribuzione pattern traning sett
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#2,2,"Definizioni
2prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàDefinizioni
Obiettivo dei metodi per lariduzione didimensionalità
(dimensionality reduction )èquello dieseguire unmapping dallo
spazio iniziale𝑑aunospazio didimensione inferiore 𝑘,𝑘<𝑑.
Può essere vista come unaforma dicompressione (con perdita di
informazione) .Obiettivo èscartare leinformazioni non rilevanti o
meno rilevanti perilproblema diinteresse :
allevia
 iproblemi collegati allacurse ofdimensionality :operare
inspazi adelevata dimensionalità ,acausa delfatto che i
pattern sono molto sparsi, richiede ingenti moli didati per
l’addestramento .
operare
 inspazi adimensionalità inferiore rende piùsemplice
addestrare algoritmi dimachine learning .Scartando dati
ridondanti (informazioni correlate) erumorosi talvolta si
migliorano anche leprestazioni .
Attenzione :riduzione didimensionalità non significa mantenere
alcune «dimensioni» ecancellarne altre, ma «combinare »le
dimensioni inmodo opportuno .",definizioni prof davide maltoni universit bologna riduzione dimensionalit definizioni obiettivo metodi lariduzione dimensionality reduction quello dieseguire unmapping spazio didimensione inferiore pu essere vista unaforma dicompressione con perdita informazione obiettivo scartare leinformazioni rilevanti meno rilevanti perilproblema diinteresse allevia iproblemi collegati allacurse operare inspazi adelevata dimensionalit acausa delfatto pattern molto sparsi richiede ingenti moli didati laddestramento operare inspazi adimensionalit inferiore rende pisemplice addestrare algoritmi dimachine learning scartando dati ridondanti informazioni correlate erumorosi talvolta migliorano leprestazioni attenzione riduzione significa mantenere alcune dimensioni ecancellarne altre combinare le dimensioni inmodo opportuno
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#20,20,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2",whitening prof davide maltoni universit bologna riduzione dimensionalit whitening unatecnica dipre normalizzazione deidati che rimuove lecorrelazioni ruotando lanuvola punti allineare gliassi divariazione principale deidati autovettori sfericizza lellissoide uniformando levarianze denotate autovalori alungo tuttigliassi dopo aver proiettato ipattern spazio definito daiprimi autovettori sufficiente dividere ogni dimensione perlaradice quadrata dellautovalore corrispondente deviazione standard lamatrice dicovarianza deidati normalizzati lidentit
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#21,21,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne",linear discriminant analysis prof davide maltoni universit bologna riduzione dimensionalit linear discriminant analysis riduzione lineare esupervisionata ilcui obiettivo massimizzare laseparazione traleclassi che etichettate lesempio seguente mostra chealfinedella discriminazione lasoluzione ottimale pu essere molto diversa soluzione formulare ilcriterio dimassima separazione traleclassi definite leseguenti matrici scattering within classindica ivettori scattered rispetto alcentro classi ciascuno rispetto allapropria classe classindica icentri classi scattered rispetto alcentro generale distribuzione ovvero leclassi scattered matrice discatter sicalcola unamatrice dicovarianza senza normalizzare perilnumero dauomini donne
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#22,22,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne",linear discriminant analysis prof davide maltoni universit bologna riduzione dimensionalit linear discriminant analysis riduzione lineare esupervisionata ilcui obiettivo massimizzare laseparazione traleclassi che etichettate lesempio seguente mostra chealfinedella discriminazione lasoluzione ottimale pu essere molto diversa soluzione formulare ilcriterio dimassima separazione traleclassi definite leseguenti matrici scattering within classindica ivettori scattered rispetto alcentro classi ciascuno rispetto allapropria classe classindica icentri classi scattered rispetto alcentro generale distribuzione ovvero leclassi scattered matrice discatter sicalcola unamatrice dicovarianza senza normalizzare perilnumero dauomini donne
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#23,23,"Calcolo LDA
",calcolo
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#24,24,"Richiami
!Latraccia diuna matrice èdefinita solo per lematrici
quadrate edèlasomma degli elementi presenti sulla
diagonale principale .
!Traccia eautovalori diuna matrice :latraccia diuna
matrice èuguale allasomma deisuoi autovalori moltiplicati
perlerispettive molteplicità algebriche ,cioè seλ1,λ2,...,λp
sono gliautovalori distinti diuna matrice Adiordine n,
dette m1,m2,...,mplerispettive molteplicità algebriche, se
m1+m2+...+mp=n,allora
tr(A) =m1λ1+m2λ2+...+mpλp",richiami latraccia diuna matrice definita solo lematrici quadrate edlasomma elementi presenti diagonale principale traccia eautovalori diuna matrice latraccia diuna matrice uguale allasomma deisuoi autovalori moltiplicati perlerispettive molteplicit algebriche cio sep gliautovalori distinti diuna matrice adiordine dette molteplicit algebriche tra
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#25,25,"Richiami
!SiaAuna matrice quadrata diordine nesiaλ0unsuo
autovalore .Sidice molteplicità algebrica dell’autovalore λ0,
esiindica conma(λ0),ilnumero cheesprime quante volte
l’autovalore λ0annulla ilpolinomio caratteristico .
!Ricordiamo che ilpolinomio caratteristico associato auna
matrice quadrata Aèildeterminante della matrice A-λIn,
dove Aèlamatrice inesame, λèun’incognita eInèla
matrice identità dello stesso ordine di A.
Informule :
pA(λ):=det(A-λIn)",richiami sia auna matrice quadrata diordine nesiaunsuo autovalore sidice molteplicit algebrica dellautovalore esiindica cheesprime volte lautovalore annulla ilpolinomio caratteristico ricordiamo ilpolinomio caratteristico associato auna matrice quadrata matrice alamatrice inesame unincognita inla matrice identit stesso ordine informule adeta
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#26,26,"Calcolo LDA
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa 𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1",calcolo prof davide maltoni universit bologna riduzione dimensionalit calcolo dato untraining set tscontenente pattern dovesono ipattern ele etichette delleclassi dipattern eilvettore medio classe esima allora lematrici discattering definite within class class idiversi criteri possibili frequentemente utilizzato quantit somma autovalori della matrice criterio intuitivo inquanto cerca dimassimizzare loscattering leclassi alcontempo matrice inversa diogni classe sidimostra dilospazio definito analogia cadagli autovettori relativi aiprimi valoremassimo di prof davide maltoni universit bologna riduzione dimensionalit calcolo dato untraining set tscontenente pattern dovesono ipattern ele etichette delleclassi dipattern eilvettore medio classe esima allora lematrici discattering definite within class class idiversi criteri possibili frequentemente utilizzato quantit somma autovalori della matrice criterio intuitivo inquanto cerca dimassimizzare loscattering leclassi alcontempo matrice inversa diogni classe sidimostra dilospazio definito analogia cadagli autovettori relativi aiprimi valoremassimo di
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#27,27,"t-distributed Stochastic Neighbor Embedding (t -SNE)
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten andG.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
",distributed stochastic neighbor embedding prof davide maltoni universit bologna riduzione dimensionalitt distributed stochastic neighbor embedding unatecnica nonlineare perlariduzione introdotta nel van der maaten hinton rappresenta ddi dati disponibile inmolti linguaggi conopu essere utilizzata atale scopo spiccatamente nonmultinormali possono essere efficacemente ridotti attraverso mapping lineare esempio ddi digit scritti amano ljpvander maaten gehinton visualizing high dimensional data using nejournal machine learning research https lvdmaaten github iotsne prof davide maltoni universit bologna riduzione dimensionalitt distributed stochastic neighbor embedding unatecnica nonlineare perlariduzione introdotta nel van der maaten hinton rappresenta ddi dati disponibile inmolti linguaggi conopu essere utilizzata atale scopo spiccatamente nonmultinormali possono essere efficacemente ridotti attraverso mapping lineare esempio ddi digit scritti amano ljpvander maaten gehinton visualizing high dimensional data using nejournal machine learning research https lvdmaaten github iotsne prof davide maltoni universit bologna riduzione dimensionalitt distributed stochastic neighbor embedding unatecnica nonlineare perlariduzione introdotta nel van der maaten hinton rappresenta ddi dati disponibile inmolti linguaggi conopu essere utilizzata atale scopo spiccatamente nonmultinormali possono essere efficacemente ridotti attraverso mapping lineare esempio ddi digit scritti amano ljpvander maaten gehinton visualizing high dimensional data using nejournal machine learning research https lvdmaaten github iotsne
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#28,28,"14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
t-SNE: Esempio",prof davide maltoni universit bologna riduzione dimensionalitt distributed stochastic neighbor embedding unatecnica nonlineare perlariduzione introdotta nel van der maaten hinton rappresenta ddi dati disponibile inmolti linguaggi conopu essere utilizzata atale scopo spiccatamente nonmultinormali possono essere efficacemente ridotti attraverso mapping lineare esempio ddi digit scritti amano ljpvander maaten gehinton visualizing high dimensional data using nejournal machine learning research https lvdmaaten github iotsne esempio
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#29,29,"t-SNE in Scikit -Learn
Per maggiori dettagli vedi documentazione online della libreria
open source scikit -learn :sklearn .manifold .TSNE!Esempio :visualizzazione 2Ddiundataset contenente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients)
invece deipixel .
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.",scikit learn maggiori dettagli vedi documentazione online libreria open source scikit learn sklearn manifold eesempio ddiundataset contenente immagini non controllate cani gatti utilizzando feature diinput histogram oriented gradients invece deipixel prof davide maltoni universit bologna riduzione dimensionalitt sklearn esempio ddiundataset contente immagini non controllate cani gatti utilizzando feature diinput histogram oriented gradients invece deipixel vedi https distill pub misread sucome tarare iparametri esperplexity ditsne due cluster molto sovrapposti classificatori tradizionali raggiungono circa sfruttando maggiore densit patter verdi gatti certa regione
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#3,3,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini .",principali tecniche prof davide maltoni universit bologna riduzione dimensionalit principali tecniche lepinote tecniche diriduzione che vedremo principal component analysis supervisionata nota karhunen loeve transform esegue unmapping lineare conlobiettivo preservare almassimo linformazione deipattern linear discriminant analysis dailmapping ancora lineare mainquesto caso supervisionato mentre privilegia dimensioni almeglio ipattern privilegia ledimensioni chediscriminano almeglio ipattern distributed stochastic neighbor embedding trasformazione lineare supervisionata ideata ridurre dimensionalit dimensioni onde poter visualizzare altre tecniche diinteresse independent component analysis lineare orientata aproiettare ipattern suuna base dicomponenti indipendenti kernel casimile mapipotente ilmapping lineare utilizza untrucco simile aquello chepermette passare lineare nonlineare local linear embedding lineare invece dicalcolare unmapping globale considera relazioni tragruppi dipattern vicini
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#30,30,"15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.I due cluster appaiono molto 
sovrapposti. 
I classificatori tradizionali 
(e.g., SVM) raggiungono una 
accuratezza di circa il 70%, 
sfruttando la maggiore 
densità dei pattern verdi 
(gatti) in una certa regione.t-SNE in Scikit -Learn",prof davide maltoni universit bologna riduzione dimensionalitt sklearn esempio ddiundataset contente immagini non controllate cani gatti utilizzando feature diinput histogram oriented gradients invece deipixel vedi https distill pub misread sucome tarare iparametri esperplexity ditsne due cluster molto sovrapposti classificatori tradizionali raggiungono circa sfruttando maggiore densit patter verdi gatti certa regione prof davide maltoni universit bologna riduzione dimensionalitt sklearn esempio ddiundataset contente immagini non controllate cani gatti utilizzando feature diinput histogram oriented gradients invece deipixel vedi https distill pub misread sucome tarare iparametri esperplexity ditsne due cluster molto sovrapposti classificatori tradizionali raggiungono circa sfruttando maggiore densit patter verdi gatti certa regionei due cluster appaiono molto sovrapposti classificatori tradizionali raggiungono accuratezza circa sfruttando maggiore densit pattern verdi gatti certa regionet scikit learn
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#31,31,"!Matlab Toolbox for Dimensionality Reduction:
https://lvdmaaten.github.io/drtoolbox/
t-SNE in Matlab",matlab toolbox dimensionality reduction matlab
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#32,32,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. ",riferimenti russell norvig artificial intelligence modern approach pearson fukunaga statistical pattern recognition academic press maltoni machine learning universit bologna bishop pattern recognition machine learning springer murphy machine learning probabilistic perspective press duda hart stork pattern classification edition wiley interscience new york
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#4,4,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini .",principali tecniche prof davide maltoni universit bologna riduzione dimensionalit principali tecniche lepinote tecniche diriduzione che vedremo principal component analysis supervisionata nota karhunen loeve transform esegue unmapping lineare conlobiettivo preservare almassimo linformazione deipattern linear discriminant analysis dailmapping ancora lineare mainquesto caso supervisionato mentre privilegia dimensioni almeglio ipattern privilegia ledimensioni chediscriminano almeglio ipattern distributed stochastic neighbor embedding trasformazione lineare supervisionata ideata ridurre dimensionalit dimensioni onde poter visualizzare altre tecniche diinteresse independent component analysis lineare orientata aproiettare ipattern suuna base dicomponenti indipendenti kernel casimile mapipotente ilmapping lineare utilizza untrucco simile aquello chepermette passare lineare nonlineare local linear embedding lineare invece dicalcolare unmapping globale considera relazioni tragruppi dipattern vicini
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#5,5,"Esempio PCA vs LDA
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
",esempio prof davide maltoni universit bologna riduzione dimensionalit esempio infigura dueesempi diriduzione daa dimensione segmento nero cheidentifica lasoluzione liperpiano sulquale proiettando ipattern classe conserviamo almassimo linformazione segmento verde cheidentifica lasoluzione liperpiano sulquale proiettando ipattern ingrado didistinguere meglio ledueclassi pattern rossi blu entrambi mapping retta profondamente diversa prof davide maltoni universit bologna riduzione dimensionalit esempio infigura dueesempi diriduzione daa dimensione segmento nero cheidentifica lasoluzione liperpiano sulquale proiettando ipattern classe conserviamo almassimo linformazione segmento verde cheidentifica lasoluzione liperpiano sulquale proiettando ipattern ingrado didistinguere meglio ledueclassi pattern rossi blu entrambi mapping retta profondamente diversa
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#6,6,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali",principal component analysis prof davide maltoni universit bologna riduzione dimensionalit principal component analysis dato untraining ilvettore dicovarianza definizioni simili aquelle usate bayes parametrico multinormali ladivisione perinvece dovuta acorrezione bessel percaso unbiased allora definito dalvettore medio edalla matrice proiezione lecui colonne costituite autovettori aipigrandi autovalori autovettore corrispondente all autovalore indica direzione maggior varianza training set s primi autovettori detti componenti principali
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#7,7,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali",principal component analysis prof davide maltoni universit bologna riduzione dimensionalit principal component analysis dato untraining ilvettore dicovarianza definizioni simili aquelle usate bayes parametrico multinormali ladivisione perinvece dovuta acorrezione bessel percaso unbiased allora definito dalvettore medio edalla matrice proiezione lecui colonne costituite autovettori aipigrandi autovalori autovettore corrispondente all autovalore indica direzione maggior varianza training set s primi autovettori detti componenti principali
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#8,8,"Principal Component Analysis (PCA)
!Riassumendo
!Dagli npattern delTraining Set (TS) sicalcolano vettore medio e
matrice dicovarianza !
!Dalla matrice dicovarianza sicalcolano idautovalori eautovettori
!Dei dautovalori siconsiderano solo ikautovalori con valore
maggiore (inordine decrescente)
!Lamatrice diproiezione ""ksarà unmatrice (d×k)lecuikcolonne
sono costituite dagli autovettori relativi aikautovalori calcolati
come sopra
!Gli autovettori !idella matrice di 
covarianza ""sono paralleli agli 
assi dell’ ellisse che rappresenta 
ladistribuzione dei pattern nel TS
!Gli autovalori #isono le varianze 
lungo gli assi !i
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali",principal component analysis riassumendo dagli npattern training set sicalcolano vettore medio matrice dicovarianza dalla matrice dicovarianza sicalcolano idautovalori eautovettori dei dautovalori siconsiderano solo ikautovalori valore maggiore inordine decrescente lamatrice diproiezione ksar unmatrice costituite autovettori relativi aikautovalori calcolati sopra gli autovettori idella matrice covarianza sono paralleli assi dell ellisse rappresenta ladistribuzione pattern gli autovalori isono varianze lungo assi prof davide maltoni universit bologna riduzione dimensionalit principal component analysis dato untraining ilvettore dicovarianza definizioni simili aquelle usate bayes parametrico multinormali ladivisione perinvece dovuta acorrezione bessel percaso unbiased allora definito dalvettore medio edalla matrice proiezione lecui colonne costituite autovettori aipigrandi autovalori autovettore corrispondente all autovalore indica direzione maggior varianza training set s primi autovettori detti componenti principali
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#9,9,"PCA: Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘",proiezione prof davide maltoni universit bologna riduzione dimensionalit proiezione retroproiezione proiezione ouna volta determinato lospazio proiezione diunpattern sutale spazio semplicemente proiezione geometrica chedefinisce lospazio inrealt lavera proiezione geometrica unvettore chehalastessa dimensionalit delvettore originale mentre contesto indichiamo proiezione ilvettore ridotto spazio operazione eseguita prodotto matrice diproiezione trasposta perilpattern alquale sottratta lamedia retro proiezione mdato unvettore spazio lasua retro proiezione verso lospazio originale siottiene moltiplicando ilvettore perlamatrice diproiezione esommando ilvettore medio questa trasformazione sposta spazialmente vettore giace ancora spazio camaopera cambiamento dicoordinate nepermette lacodifica termini spazio originale 
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Riduzione dimensionalità (Ex 15)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione riduzione dimensionalit
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#1,1,"Sommario
Richiami riduzione dimensionalità, projection, mainfold learning 
PCA in Python 
Scikit-learn e PCA 
PCA e compressione 
Randomized PCA 
Kernel PCA 
Locally Linear Embedding LLE 
Esercitazione",sommario richiami riduzione dimensionalit projection mainfold learning python scikit learn compressione randomized kernel locally linear embedding esercitazione
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#10,10,"PCA: Step by step in Python
Una volta ottenute le componenti, deﬁniamo il nuovo iperspazio con 
 d 
dimensioni. Prendiamo le prime d colonne di 
 V
 e proiettiamo le istanze nel 
nuovo spazio: 
X
d-proj
 = X W
 d 
In Python: 
W2 
= 
Vt
.
T
[:, :
2
]
X2D 
= 
X_centered
 .
dot
(
W2
)
11",step step python volta ottenute componenti deniamo nuovo iperspazio dimensioni prendiamo prime colonne proiettiamo istanze nuovo spazio proj python xcentered dot
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#11,11,"Scikit-learn e PCA
Scikit-learn implementa la PCA nel seguente modo: 
from 
sklearn.decomposition 
 import 
PCA
pca 
= 
PCA
(
n_components 
 = 
2
)
X2D 
= 
pca
.
fit_transform
 (
X
)
La variabile components_ contiene i vettori. Per accedere al primo vettore:  
pca.components_.T[:,0] 
Ogni componente è associata alla relativa varianza che si può analizzare 
con la variabile 
 explained_variance_ratio_
 . Considerando l'esempio 
precedente si ottiene: 
>>> 
pca
.
explained_variance_ratio_
array([0.84248607, 0.14631839])
12",scikit learn scikit learn implementa seguente modo import pca ncomponents pca fittransform variabile components contiene vettori accedere primo vettore ogni componente associata relativa varianza pu analizzare variabile considerando lesempio precedente ottiene pca
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#12,12,"Scikit-learn e PCA
La scelta del numero di dimensioni dipende dalla varianza: si tende a 
scegliere il numero che garantisce sempre elevata varianza (es. 95%). 
Eccezione se vogliamo fare un diagramma dei campioni, in tal caso ci 
occorrono 2 o 3 dimensioni. 
Il seguente codice ricava il numero di dimensioni che preservano il 95% 
della varianza sul training set: 
pca 
= 
PCA
()
pca
.
fit
(
X_train
)
cumsum 
= 
np
.
cumsum
(
pca
.
explained_variance_ratio_
 )
d 
= 
np
.
argmax
(
cumsum 
>= 
0.95
) 
+ 
1
Un modo alternativo per speciﬁcare la varianza: 
pca 
= 
PCA
(
n_components
 =
0.95
)
X_reduced 
 = 
pca
.
fit_transform
 (
X_train
)
(continua)
13",scikit learn scelta numero dimensioni dipende varianza tende scegliere numero garantisce sempre elevata varianza eccezione vogliamo fare diagramma campioni tal caso occorrono dimensioni seguente codice ricava numero dimensioni preservano varianza training set pca pca fit xtrain cumsum cumsum pca argmax cumsum modo alternativo specicare varianza pca ncomponents xreduced pca fittransform xtrain continua
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#13,13,"Scikit-learn e PCA
Ulteriore metodo per ﬁssare d è fare un graﬁco del cumsum della varianza. 
Il 
gomito
  della curva è dove la varianza interrompe la crescita veloce.  
Nell'esempio una dimensionalità inferiore a 100 è un valore ideale:
14
",scikit learn ulteriore metodo ssare fare graco cumsum varianza gomito curva varianza interrompe crescita veloce nellesempio dimensionalit inferiore valore ideale
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#14,14,"PCA e compressione
Una volta ottenuto il dataset proiettato sulle componenti, la dimensione del 
dataset si riduce sensibilmente. 
La funzione 
 inverse_transform
 () di PCA permette di ricostruire una 
approsimazione del dataset con le dimensioni originali a partire dalle 
istanze nello spazio ridotto. 
X
recovered
  = X
 d-proj
 W
d
T 
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset. (2) visualizza le cifre ricostruite con 
 inverse_transform(). 
Suggerimento per visualizzare le cifre
 : 
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
15",compressione volta ottenuto dataset proiettato componenti dimensione dataset riduce sensibilmente funzione permette ricostruire approsimazione dataset dimensioni originali partire istanze spazio ridotto recovered proj esercizio impiega dataset cifre dimensioni applica riducendo dimensioni valuta dimensioni nuovo dataset visualizza cifre ricostruite suggerimento visualizzare cifre import plt reshape cmap gray pltshow
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#15,15,"PCA e compressione
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset 
from
 sklearn.decomposition 
 import
 PCA
from
 sklearn 
 import
 datasets
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 fetch_openml
from
 sklearn.preprocessing 
 import
 StandardScaler
mnist = fetch_openml(
 'mnist_784'
 )
X_train, X_test, y_train, y_test  = train_test_split
        (mnist.data, mnist.target, test_size=
 1
/
7.0
, random_state=
 0
)
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
pca = PCA(n_components = 
 154
)
X_reduced = pca.fit_transform(X_train)
X_recovered = pca.inverse_transform(X_reduced)
(continua)
16",compressione esercizio impiega dataset cifre dimensioni applica riducendo dimensioni valuta dimensioni nuovo dataset import sklearn import datasets import import fetchopenml import standard scaler mnist fetchopenml mnist xtrain xtest ytrain ytest mnistdata mnisttarget testsize randomstate scaler standard scaler xtrain xtest pca cancomponents xreduced xrecovered continua
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#16,16,"PCA e compressione
original_len = X_train.flatten().size
print
(original_len)
red_len = X_reduced.flatten().size
print
(red_len)
rec_len = X_recovered.flatten().size
print
(rec_len)
pct = (red_len - original_len) * 
 100
 / original_len
print
 (pct)
47040000
9240000
47040000
-80.35714285714286 
Dataset ridotto al 20% della dimensione originale! 
17",compressione originallen print originallen redlen print redlen reclen print reclen pct redlen originallen originallen print pct dataset ridotto dimensione originale
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#17,17,"PCA e compressione
Esercizio
 : ... (2) visualizza le cifre ricostruite con 
 inverse_transform().  
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
plt.imshow(X_recovered[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
18
",compressione esercizio visualizza cifre ricostruite import plt reshape cmap gray pltshow reshape cmap gray pltshow
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#18,18,"Scikit-learn: Randomized PCA
Impiegando il parametro 
 svd_solver
 =
""randomized"", impieghiamo 
l'algoritmo Randomized PCA che riduce notevolmente il tempo di 
esecuzione essendo d << n: 
O(
m × n
2
) + O(
 n
3
)  --->   O(
 m × d
2
) + O(
 d
3
) 
Per default sciki-learn usa il solver 
 auto
, che impiega la versione 
randomized se 
 m
 o 
n
 sono maggiori di 500 e d è minore del 80% rispetto a 
m
 o 
n
.  
Per forzare l'impiego della versione esatta, impiegare l'opzione 
 full
. 
19",scikit learn randomized impiegando parametro svdsolver randomized impieghiamo lalgoritmo randomized riduce notevolmente tempo esecuzione default sciki learn usa solver auto impiega versione randomized maggiori minore rispetto forzare limpiego versione esatta impiegare lopzione full
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#19,19,"Scikit-learn: Incremental PCA
L'algoritmo PCA richieda che l'intero dataset sia presente in memoria. 
L'algoritmo Incremental PCA accetta il dataset suddiviso in mini-batch, e 
può essere impiegato 
 online
 . 
from 
sklearn.decomposition 
 import 
IncrementalPCA
n_batches 
 = 
100
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
)
for 
X_batch 
 in 
np
.
array_split
 (
X_train
, 
n_batches
 ):
    
inc_pca
.
partial_fit
 (
X_batch
)
X_reduced 
 = 
inc_pca
.
transform
 (
X_train
)
Con la classe memmap di NumPy possiamo leggere gli array 
incrementalmente da ﬁle binary: 
X_mm 
= 
np
.
memmap
(
filename
 , 
dtype
=
""float32""
 , 
mode
=
""readonly""
 , 
shape
=
(
m
, 
n
))
batch_size 
 = 
m 
// 
n_batches
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
, 
batch_size
 =
batch_size
 )
inc_pca
.
fit
(
X_mm
)
20",scikit learn incremental lalgoritmo richieda lintero dataset presente memoria lalgoritmo incremental accetta dataset suddiviso mini batch pu essere impiegato online import incremental nbatches incpca incremental ncomponents xbatch arraysplit xtrain nbatches incpca partialfit xbatch xreduced incpca transform xtrain classe memmap num possiamo leggere array le binary xmm memmap filename dtype float mode readonly shape batchsize nbatches incpca incremental ncomponents batchsize batchsize incpca fit xmm
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#2,2,"Richiami: riduzione di dimensionalità
In casi reali i dati da analizzare possono essere sempliﬁcati riducendo il 
numero di features. L'obiettivo è velocizzare il processo di training senza 
inﬂuire troppo sulle performance, e ridurre l'eventuale rumore, es: 
Nel MNIST dataset i pixel nei bordi sono sempre bianchi, possiamo 
pensare di rimuoverli 
Spesso i pixel neri sono correlati, cioè appaiono vicini. È possibile 
fonderli facendone una media.  
Se creassimo a caso immagini, in rarissimi casi potrebbero assomigliare 
alle cifre nel dataset. Perciò i gradi di libertà disponibili nella creazione 
di istanze sono notevolmente ridotti rispetto a quelli potenziali in uno 
spazio con le medesime dimensioni. 
Inoltre la riduzione di dimensionalità permette di creare graﬁci nel caso in 
cui le dimensioni siano 2 o 3.
3",richiami riduzione dimensionalit casi reali dati analizzare possono essere semplicati riducendo numero features lobiettivo velocizzare processo training senza inuire troppo performance ridurre leventuale rumore dataset pixel bordi sempre bianchi possiamo pensare rimuoverli spesso pixel neri correlati cio appaiono vicini possibile fonderli facendone media creassimo caso immagini rarissimi casi potrebbero assomigliare cifre dataset perci gradi libert disponibili creazione istanze notevolmente ridotti rispetto potenziali spazio medesime dimensioni inoltre riduzione dimensionalit permette creare graci caso dimensioni
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#20,20,"Scikit-learn: Kernel PCA (kPCA)
In modo simile ai kernel del SVM è possibile fare proiezioni non lineari 
complesse per la riduzione di dimensionalità. 
Similmente al SVM, ha il vantaggio di mantenere cluster di istanze dopo la 
proiezione, oppure operare 
 unrolling
  di forme complesse. 
In scikit-learn impiegando il kernel rbf si ha: 
from 
sklearn.decomposition 
 import 
KernelPCA
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.04
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
Di seguito alcuni esempi di proiezioni a 2 dimensioni con vari kernel:
21
",scikit learn kernel modo simile kernel possibile fare proiezioni lineari complesse riduzione dimensionalit similmente vantaggio mantenere cluster istanze dopo proiezione oppure operare unrolling forme complesse scikit learn impiegando kernel rbf import kernel rbfpca kernel ncomponents kernel rbf gamma xreduced rbfpca fittransform seguito alcuni esempi proiezioni dimensioni vari kernel
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#21,21,"Scikit-learn: Kernel PCA (kPCA)
La scelta del kernel dipende dal task. Se il task è supervisionato, si può fare 
una semplice grid search sui kernel e i relativi iperparametri per ottenere 
performance migliori. 
Nel seguente codice si impiega una pipeline per il task di regressione: 
from 
sklearn.model_selection 
 import 
GridSearchCV
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.pipeline 
 import 
Pipeline
clf 
= 
Pipeline
 ([
(
""kpca""
, 
KernelPCA
 (
n_components
 =
2
)),
(
""log_reg""
 , 
LogisticRegression
 ())
])
param_grid 
 = 
[{
""kpca__gamma""
 : 
np
.
linspace
 (
0.03
, 
0.05
, 
10
),
""kpca__kernel""
 : [
""rbf""
, 
""sigmoid""
 ]
}]
grid_search 
 = 
GridSearchCV
 (
clf
, 
param_grid
 , 
cv
=
3
)
grid_search
 .
fit
(
X
, 
y
)
>>> 
print
(
grid_search
 .
best_params_
 )
{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}
22",scikit learn kernel scelta kernel dipende task task supervisionato pu fare semplice grid search kernel relativi iperparametri ottenere performance migliori seguente codice impiega pipeline task regressione import grid search import logistic regression import pipeline clf pipeline kpca kernel ncomponents logreg logistic regression paramgrid kpcagamma linspace kpcakernel rbf sigmoid gridsearch grid search clf paramgrid gridsearch fit print gridsearch bestparams kpcagamma kpcakernel rbf
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#22,22,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri?
23",scikit learn kernel task unsupervised possibile comunque fare tuning parametri
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#23,23,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri? 
Se ricostruiamo i dati originali con le componenti PCA possiamo valutare 
le performance con una misura di discostamento (es. distanza quadratica). 
Attenzione
 : l'impiego dei kernel implica che la ricostruzione generi un 
feature space inﬁnito-dimensionale. Perciò non è possibile confrontare 
direttamente le istanze con lo spazio originale. Con la tecnica 
recontruction pre-image è possibile trovare il punto nello spazio originale 
che è vicino alla istanza 
 ricostruita
 .
24
",scikit learn kernel task unsupervised possibile comunque fare tuning parametri ricostruiamo dati originali componenti possiamo valutare performance misura discostamento distanza quadratica attenzione limpiego kernel implica ricostruzione generi feature space innito dimensionale perci possibile confrontare direttamente istanze spazio originale tecnica recontruction pre image possibile trovare punto spazio originale vicino istanza ricostruita
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#24,24,"Scikit-learn: Kernel PCA (kPCA)
Il parametro ﬁt_inverse_transform=True adotta questa strategia: 
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.0433
,
              
 fit_inverse_transform
 =
True
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
X_preimage 
 = 
rbf_pca
.
inverse_transform
 (
X_reduced
 )
>>> 
from 
sklearn.metrics 
 import 
mean_squared_error
>>> 
mean_squared_error
 (
X
, 
X_preimage
 )
32.786308795766132
25",scikit learn kernel parametro adotta strategia rbfpca kernel ncomponents kernel rbf gamma true xreduced rbfpca fittransform xpreimage rbfpca xreduced sklearnmetrics import xpreimage
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#25,25,"Scikit-learn: Locally Linear Embedding (LLE)
È una ulteriore tecnica non lineare, ma non si basa sulle proiezioni. 
In sintesi, nella prima fase analizza le similarità tra una istanza e le istanze 
vicine (neighbors), e successivamente crea un iperspazio con meno 
dimensioni che mantiene queste tali relazioni.  
È un approccio ideale per fare unrolling e in presenza di poco rumore. 
from 
sklearn.manifold 
 import 
LocallyLinearEmbedding
lle 
= 
LocallyLinearEmbedding
 (
n_components
 =
2
, 
n_neighbors
 =
10
)
X_reduced 
 = 
lle
.
fit_transform
 (
X
)
Lo spazio risultate è correttamente dispiegato, anche se le distanze relative 
non sono mantenute coerenti.
26
",scikit learn locally linear embedding ulteriore tecnica lineare basa proiezioni sintesi prima fase analizza similarit istanza istanze vicine neighbors successivamente crea iperspazio meno dimensioni mantiene tali relazioni approccio ideale fare unrolling presenza poco rumore import locally linear embedding lle locally linear embedding ncomponents nneighbors xreduced lle fittransform spazio risultate correttamente dispiegato distanze relative mantenute coerenti
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#26,26,"Esercitazione
Carica il dataset MNIST e suddividilo in 60K training e 10K test set. 
Addestra un classiﬁcatore Random Forest, calcola il tempo di training e le 
performance. 
Applica PCA con una 
 explained variance ratio
  del 95%. 
Addestra un nuovo classiﬁcatore Random Forest, calcola il tempo di 
training e le performance, e confronta i valori con i valori precedenti.
27",esercitazione carica dataset suddividilo training test set addestra classicatore random forest calcola tempo training performance applica explained variance ratio addestra nuovo classicatore random forest calcola tempo training performance confronta valori valori precedenti
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#27,27,"Esercitazione
from
 sklearn.datasets 
 import
 fetch_openml
mnist = fetch_openml(
 'mnist_784'
 )
X_train = mnist[
 'data'
][:
60000
]
y_train = mnist[
 'target'
 ][:
60000
]
X_test = mnist[
 'data'
][
60000
:]
y_test = mnist[
 'target'
 ][
60000
:]
from
 sklearn.ensemble 
 import
 RandomForestClassifier
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
import
 time
t0 = time.time()
rnd_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
28",esercitazione import fetchopenml mnist fetchopenml mnist xtrain mnist data ytrain mnist target xtest mnist data ytest mnist target import random forest classifier rndclf random forest randomstate import time timetime ytrain timetime print training took format
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#28,28,"Esercitazione
from
 sklearn.metrics 
 import
 accuracy_score
y_pred = rnd_clf.predict(X_test)
accuracy_score(y_test, y_pred)
from
 sklearn.decomposition 
 import
 PCA
pca = PCA(n_components=
 0.95
)
X_train_reduced = pca.fit_transform(X_train)
rnd_clf2 = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
t0 = time.time()
rnd_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
X_test_reduced = pca.transform(X_test)
y_pred = rnd_clf2.predict(X_test_reduced)
accuracy_score(y_test, y_pred)
29",esercitazione sklearnmetrics import accuracyscore ypred ypred import pca xtrainreduced rndclf random forest randomstate timetime ytrain timetime print training took format xtestreduced ypred ypred
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#29,29,"Esercitazione
from
 sklearn.linear_model 
 import
 LogisticRegression
log_clf = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf.predict(X_test)
print(
accuracy_score(y_test, y_pred))
log_clf2 = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf2.predict(X_test_reduced)
print(
accuracy_score(y_test, y_pred))
30",esercitazione import logistic regression logclf logistic multinomial solver lbfgs randomstate timetime ytrain timetime print training took format ypred print ypred logclf logistic multinomial solver lbfgs randomstate timetime ytrain timetime print training took format ypred print ypred
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#3,3,"Osservazione
Presi 2 punti a caso in un quadrato di dimensioni 1x1, la distanza media è 
0.52. In un cubo 3d è 0.66. In un ipercubo di 1M dimensioni è 408,25. 
In dataset con alta dimensionalità il rischio di data sparity è elevato. 
Una nuova istanza è molto probabile che sia lontana dalle altre già 
incontrate in precedenza; probabile overﬁtting durante il test. 
Se incrementiamo le istanze nel training set riduciamo il problema, ma il 
tempo di addestramento si allungano, e a volte non è possibile 
collezionare nuove istanze. 
Il numero di istanze da includere cresce esponenzialmente col numero 
di dimensioni del dataset.
4",osservazione presi punti caso quadrato dimensioni distanza media cubo ipercubo dimensioni dataset alta dimensionalit rischio data sparity elevato nuova istanza molto probabile lontana altre gi incontrate precedenza probabile overtting durante test incrementiamo istanze training set riduciamo problema tempo addestramento allungano volte possibile collezionare nuove istanze numero istanze includere cresce numero dimensioni dataset
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#30,30,"Esercitazione
>>>
Training took 57.60s
Training took 124.90s
0.9255
Training took 55.04s
Training took 15.68s
0.9201
31",esercitazione training took training took training took training took
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#31,31,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
32",andreas mller sarah guido introduction machine learning python guide data scientists oreilly media aurlien gron hands machine learning scikit learn tensor flow concepts tools techniques build intelligent systems oreilly media testi riferimento
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#4,4,"Projection
Spesso le features sono correlate tra loro, oppure assumono spesso valori in 
piccoli intervalli. 
Nell'esempio seguente si può notare come molti punti sono vicini ad un 
piano (2d). Se proiettiamo questi punti sul piano (sottospazio) otteniamo un 
dataset di dimensioni ridotte, con 2 nuove features, cioè le coordinate nel 
piano.
5
",projection spesso features correlate loro oppure assumono spesso valori piccoli intervalli nellesempio seguente pu notare molti punti vicini piano proiettiamo punti piano sottospazio otteniamo dataset dimensioni ridotte nuove features cio coordinate piano
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#5,5,"Projection
In altri casi la proiezione è difﬁcile o impossibile. 
Nel dataset toy Swiss roll, semplici piani non permettono di mantenere la 
coerenza spaziale originale delle istanze. Solo ""dispiegando il rotolo"" di 
punti è possibile avere un piano coerente.
6
",projection altri casi proiezione difcile impossibile dataset toy swiss roll semplici piani permettono mantenere coerenza spaziale originale istanze solo dispiegando rotolo punti possibile avere piano coerente
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#6,6,"Manifold learning
Nell'esempio precedente, il 
 roll
 è una struttura che assomiglia a un piano 
2d (d=2) che è disposta (rotolata) in uno spazio 3d (n=3 con n>d). 
Manifold assumption
 : l'ipotesi che molti dataset reali possono essere 
rappresentati in spazi con dimensioni ridotte. Inoltre suppone che nello 
spazio ridotto sia più facile risolvere problemi di classiﬁcazione, 
regressione, etc.  
Quest'ultima assunzione non è sempre vera, es:
7
",manifold learning nellesempio precedente roll struttura assomiglia piano disposta rotolata spazio manifold assumption lipotesi molti dataset reali possono essere rappresentati spazi dimensioni ridotte inoltre suppone spazio ridotto facile risolvere problemi classicazione regressione etc questultima assunzione sempre vera
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#7,7,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Quale piano sceglieresti?
8
",richiami proiettare dati iperspazio meno dimensioni occorre prima denirlo nellesempio piano linea continua mantiene varianza massima mentre piani tratteggiati varianze basse piano sceglieresti
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#8,8,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Il piano con massima varianza potenzialmente riduce la perdita di 
informazione durante la proiezione. 
PCA mira a identiﬁcare tali assi.
9
",richiami proiettare dati iperspazio meno dimensioni occorre prima denirlo nellesempio piano linea continua mantiene varianza massima mentre piani tratteggiati varianze basse piano massima varianza potenzialmente riduce perdita informazione durante proiezione mira identicare tali assi
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#9,9,"PCA: Step by step in Python
Attenzione
 : se perturbiamo leggermente il training set, i 
 principal 
component 
 (gli assi) possono cambiare, ad esempio invertendo la 
direzione, anche se il piano deﬁnito da essi rimane generalmente lo stesso. 
Per trovare le compomenti si impiega la Singular Value Decomposition 
(SVD) che permette di ottenere la seguente decomposizione: 
X = U 
 Σ
 V
T 
dove le colonne di V rappresentano le componenti che stiamo cercando. 
In Python possiamo ottenerle nel seguente modo: 
X_centered 
 = 
X 
- 
X
.
mean
(
axis
=
0
)
U
, 
s
, 
Vt 
= 
np
.
linalg
.
svd
(
X_centered
 )
c1 
= 
Vt
.
T
[:, 
0
]
c2 
= 
Vt
.
T
[:, 
1
]
Attenzione
 : è sempre consigliabile centrare i dati nell'origine impiegando 
lo 
StandardScaler
 ().
10",step step python attenzione perturbiamo leggermente training set principal component gli assi possono cambiare esempio invertendo direzione piano denito essi rimane generalmente stesso trovare compomenti impiega singular value decomposition permette ottenere seguente decomposizione colonne rappresentano componenti cercando python possiamo ottenerle seguente modo xcentered mean axis linalg svd xcentered attenzione sempre consigliabile centrare dati nellorigine impiegando standard scaler
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Valutazione delle prestazioni
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico regressione valutazione prestazioni machine learning
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Valutazione delle Prestazioni nella 
Regression 
Loss Function e le tre misure di Loss: 
•
 Training Error, Generalization Error, Test Error 
Overﬁtting 
Le tre fonti di errore: Noise, Bias, Variance
 
2",sommario introduzione valutazione prestazioni regression loss function tre misure loss training error generalization error test error overtting tre fonti errore noise bias variance
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#10,10,"Training Error vs.  
Complessità del Modello
 
11E’ interessante vedere come può variare tale errore in base 
alla complessità del modello.  
caso di modello costante:  
y
Area xPrezzo
Complessità del modelloErrore ",training error complessit modello interessante vedere pu variare tale errore base complessit modello caso modello costante area prezzo complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#11,11,"Training Error vs.  
Complessità del Modello
 
12caso di modello lineare:  
y
Area xPrezzo
Complessità del modelloErrore ",training error complessit modello caso modello lineare area prezzo complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#12,12,"Training Error vs.  
Complessità del Modello
 
13
caso di modello quadratico:  
Complessità del modelloErrore 
y
Area xPrezzo
",training error complessit modello caso modello quadratico complessit modello errore area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#13,13,"Training Error vs.  
Complessità del Modello
 
14
caso di modello polinomiale:  
Complessità del modelloErrore 
y
Area xPrezzo
",training error complessit modello caso modello polinomiale complessit modello errore area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#14,14,"Training Error vs.  
Complessità del Modello
 
15L’andamento dell’errore ha dunque in genere la seguente 
forma: 
Complessità del modelloErrore ",training error complessit modello landamento dellerrore dunque genere seguente forma complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#15,15,"Training Error vs.  
Complessità del Modello
 
16Il training error non è una buona misura della predictive 
performance: 
Esso è eccessivamente ottimistico, proprio perché il vettore 
ŵ è calcolato afﬁnché il modello si adatti ai dati di training. y
Area xPrezzo
xt
",training error complessit modello training error buona misura predictive performance esso eccessivamente ottimistico proprio vettore calcolato afnch modello adatti dati training area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#16,16,"Generalization Error
 
17Sarebbe interessante conoscere il “loss” prendendo in 
considerazione tutte le possibili coppie ( x, y), ossia, per il 
nostro esempio degli appartamenti, tutte le possibili case della 
zona presa in considerazione, calcolando la media della 
funzione loss su tali appartamenti. 
In genere però nel nostro data set abbiamo soltanto un 
numero limitato di osservazioni ( x, y). ",generalization error interessante conoscere loss prendendo considerazione tutte possibili coppie ossia esempio appartamenti tutte possibili case zona presa considerazione calcolando media funzione loss tali appartamenti genere per data set soltanto numero limitato osservazioni
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#17,17,"Generalization Error
 
18Per effettuare una stima di tale costo dovremmo cercare di 
pesare le varie coppie ( x, y) in base alla probabilità che hanno 
di essere presenti nella zona d’interesse.  
E’ dunque utile prendere in considerazione la distribuzione 
degli appartamenti in base al valore della loro area:
Area",generalization error effettuare stima tale costo dovremmo cercare pesare varie coppie base probabilit essere presenti zona dinteresse dunque utile prendere considerazione distribuzione appartamenti base valore area area
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#18,18,"Generalization Error
 
19Potremmo inoltre considerare la distribuzione delle case in 
base al loro prezzo, a parità di area:
Prezzo",generalization error potremmo inoltre considerare distribuzione case base prezzo parit area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#19,19,"Generalization Error
 
20Formalmente, possiamo deﬁnire il Generalization (o True) 
Error come segue:
Generalization Error = Ex,y[L(y,f ˆw(x))]
ossia come l’average value della funzione Loss, calcolato su 
tutte le possibili coppie ( x, y) pesate in base alla loro 
probabilità di comparire nella zona.",generalization error formalmente possiamo denire generalization true error segue generalization error exylyf wx ossia laverage value funzione loss calcolato tutte possibili coppie pesate base probabilit comparire zona
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#2,2,"La valutazione delle prestazioni è di importanza cruciale 
per poter apprezzare il metodo che stiamo utilizzando per 
le nostre previsioni. 
Essa ci aiuta nella scelta tra modelli di diversa complessità 
a nostra disposizione. 
A tal ﬁne occorre deﬁnire una metrica che ci consenta di 
valutare quanto perdiamo (loss) quando facciamo una 
certa previsione. 
 
3
Introduzione alla  
Valutazione delle Prestazioni",valutazione prestazioni importanza cruciale poter apprezzare metodo utilizzando previsioni essa aiuta scelta modelli diversa complessit disposizione tal ne occorre denire metrica consenta valutare perdiamo loss quando certa previsione introduzione valutazione prestazioni
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#20,20,"Generalization Error
 
21Vediamo ora di intuire come tale errore possa variare in base 
alla complessità del modello. 
Per far questo ci avvarremo della rappresentazione che segue, 
dove la regione in blu rappresenta, con le diverse gradazioni 
nei vari punti, la distribuzione di probabilità di avere una casa 
nel nostro data set (la parte bianca rappresenta le più alte 
probabilità):
y
Area xPrezzo",generalization error vediamo ora intuire tale errore possa variare base complessit modello far avvarremo segue regione blu rappresenta diverse gradazioni vari punti distribuzione probabilit avere casa data set parte bianca rappresenta alte probabilit area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#21,21,"Generalization Error
 
22Per valutare l’errore consideriamo come la “ﬁtted function” f 
(in verde nella ﬁgura precedente e in quelle successive), che 
si adatta alle osservazioni del training set, possa predire i 
valori delle case non presenti nel training set, pesate dalle 
loro probabilità. 
Ossia dobbiamo vedere quanto la f sia “vicina” all’area in 
bianco della distribuzione rappresentata in ﬁgura. 
Nei lucidi che seguono cercheremo di intuire l’andamento del 
Generalization Error a fronte di diverse complessità del 
modello (costante, lineare, quadratico, ecc.).",generalization error valutare lerrore consideriamo tted function verde gura precedente successive adatta osservazioni training set possa predire valori case presenti training set pesate probabilit ossia dobbiamo vedere vicina allarea bianco distribuzione rappresentata gura lucidi seguono cercheremo intuire landamento generalization error fronte diverse complessit modello costante lineare quadratico ecc
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#22,22,"Generalization Error vs.  
Complessità del Modello
 
23caso di modello costante: 
Prezzo
AreaErrore 
Complessità del modello",generalization error complessit modello caso modello costante prezzo area errore complessit modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#23,23,"Generalization Error vs.  
Complessità del Modello
 
24caso di modello lineare: 
AreaPrezzoErrore 
Complessità del modello",generalization error complessit modello caso modello lineare area prezzo errore complessit modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#24,24,"Generalization Error vs.  
Complessità del Modello
 
25caso di modello quadratico: 
AreaPrezzoErrore 
Complessità del modello",generalization error complessit modello caso modello quadratico area prezzo errore complessit modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#25,25,"Generalization Error vs.  
Complessità del Modello
 
26caso di modello polinomiale: 
AreaPrezzoErrore 
Complessità del modello",generalization error complessit modello caso modello polinomiale area prezzo errore complessit modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#26,26,"Generalization Error vs.  
Complessità del Modello
 
27caso di modello “High level”: 
AreaPrezzoErrore 
Complessità del modello",generalization error complessit modello caso modello high level area prezzo errore complessit modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#27,27,"Generalization Error vs.  
Complessità del Modello
 
28L’andamento dell’errore è dunque in genere il seguente: 
Complessità del ModelloErrore",generalization error complessit modello landamento dellerrore dunque genere seguente complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#28,28,"Generalization Error
 
29Ricordiamoci però che, a differenza di ciò che accade per 
il training error, NON è possibile calcolare il 
Generalization Error. 
Per calcolarlo, dovremmo conoscere la “true distribution” 
delle probabilità vista prima, cosa che non sappiamo fare. ",generalization error ricordiamoci per che differenza ci accade training error possibile calcolare generalization error calcolarlo dovremmo conoscere true distribution probabilit vista prima cosa sappiamo fare
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#29,29,"Test Error
Deﬁnito come average loss sui punti dell’insieme di test:
 
30
Test Error =1
Ntest·X
i2testL[yi,fˆw(xi)]
AreaPrezzo",test error denito average loss punti dellinsieme test test error ntestx itest lyifwxi area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#3,3,"Loss Function
 
4Possiamo indicare una funzione di Loss come segue:
dove y è l’actual value, mentre la funzione f ci fornisce il 
valore previsto ŷ.  
Tale funzione L rappresenta il costo che abbiamo se usiamo 
la f con il vettore dei pesi ŵ a fronte dell’input x.L[y, f ˆw(x)]",loss function possiamo indicare funzione loss segue lactual value mentre funzione fornisce valore previsto tale funzione rappresenta costo usiamo vettore pesi fronte dellinput xly wx
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#30,30,"Andamento degli errori  vs.  
Complessità del Modello
 
31Training Error: 
Training Error
Complessità del modelloErrore ",andamento errori complessit modello training error training error complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#31,31,"Andamento degli errori vs.  
Complessità del Modello
 
32Generalization Error: 
Generalization Error
Training Error
Complessità del modelloErrore ",andamento errori complessit modello generalization error generalization error training error complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#32,32,"Andamento degli errori vs.  
Complessità del Modello
 
33Test Error: approssima il Generalization Error 
Generalization Error
Training ErrorTest Error
Complessità del modelloErrore ",andamento errori complessit modello test error approssima generalization error generalization error training error test error complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#33,33,"Overﬁtting
 
34Dato un modello con parametri ŵ, si ha overﬁtting se esiste un 
modello con i parametri stimati w’ tale che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
Generalization (true) Error
Training ErrorTest Error
ŵw’
Complessità del modelloErrore ",overtting dato modello parametri overtting esiste modello parametri stimati tale che training error training errorw true error true errorw generalization true error training error test error w complessit modello errore
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#34,34,"Training/Test Split
Un importante problema da considerare ai ﬁni 
dell’addestramento e della valutazione di un modello è la 
suddivisione delle osservazioni disponibili tra training set 
e test set:
 
35
Training Set Test Set",trainingtest split importante problema considerare ni valutazione modello suddivisione osservazioni disponibili training set test set training set test set
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#35,35,"Training/Test Split
Se per il training set abbiamo poche osservazioni 
rischiamo di non stimare in modo adeguato il modello, 
cosa che potrebbe comportare previsioni imprecise da 
parte dello stesso.
 
36
Training Set Test Set
Troppo pochi ➝ ŵ non stimato adeguatamente  ",trainingtest split training set poche osservazioni rischiamo stimare modo adeguato modello cosa potrebbe comportare previsioni imprecise parte stesso training set test set troppo pochi stimato adeguatamente
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#36,36,"Training/Test Split
D’altro canto, se abbiamo poche osservazioni per il test 
set rischiamo di non avere una rappresentazione adeguata 
dei dati che stiamo analizzando (e.g., tutte le case in 
vendita) 
 
37
Training Set Test Set
Troppo pochi ➝ true error non stimato  
                       adeguatamente dal test error",trainingtest split daltro canto poche osservazioni test set rischiamo avere adeguata dati analizzando tutte case vendita training set test set troppo pochi true error stimato adeguatamente test error
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#37,37,"Training/Test Split
Purtroppo non esiste una formula che ci dica come 
suddividere esattamente i dati in training set e test set. 
Una regola pratica da poter seguire consiste nell’usare un 
numero sufﬁciente di punti per il test set per consentire 
una ragionevole approssimazione del true error: 
 
38
Training Set Test Set
Se ciò lascia troppi pochi punti per il training set,  ci 
possiamo avvalere di altri metodi che vedremo 
successivamente (
 cross validation
 ).",trainingtest split purtroppo esiste formula dica suddividere esattamente dati training set test set regola pratica poter seguire consiste nellusare numero sufciente punti test set consentire ragionevole approssimazione true error training set test set ci lascia troppi pochi punti training set possiamo avvalere altri metodi vedremo successivamente cross validation
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#38,38,"Le tre sorgenti di errore
Noise 
Bias  
Variance
 
39Test SetE’ estremamente utile analizzare le diverse cause che possono 
portare ad un errore nelle previsioni. Esse sono le seguenti:
Cominciamo a vedere in modo intuitivo di cosa si tratta.",tre sorgenti errore noise bias variance test set estremamente utile analizzare diverse cause possono portare errore previsioni esse seguenti cominciamo vedere modo intuitivo cosa tratta
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#39,39,"Noise
Come sappiamo, in genere i dati sono intrinsecamente 
“rumorosi”. 
Nel nostro caso, possiamo ipotizzare che esista una “true 
function” che lega 
 x
 a y. Essa però non è una descrizione 
perfetta di tale legame. Ci sono infatti altri fattori che 
magari non abbiamo tenuto in conto (altri attributi, ecc.)
 
40
Tutto ciò comporta un “rumore” intrinseco, che possiamo 
rappresentare con il termine 
 ε
, che ha media uguale a zero.y
Area xPrezzo
",noise sappiamo genere dati intrinsecamente rumorosi caso possiamo ipotizzare esista true function lega essa per descrizione perfetta tale legame infatti altri fattori magari tenuto conto altri attributi ecc ci comporta rumore intrinseco possiamo rappresentare termine media uguale zeroy area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#4,4,"Esempi di Loss Function
 
5La funzione di Loss può essere ad esempio deﬁnita come 
Errore Assoluto (Absolute Error):
oppure come Errore Quadratico (Squared Error):L[y, f ˆw(x)] = |y",esempi loss function funzione loss pu essere esempio denita errore assoluto absolute error oppure errore quadratico squared errorly wx
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#40,40,"Noise
Tale rumore comporta in genere uno scostamento (spread) 
rispetto alla funzione vera. 
Possiamo dunque prendere in considerazione la varianza 
di tale variabile:
 
41varianza di ε
Il rumore in questione è chiamato “
 irreducible error
 ”.y
Area xPrezzo
",noise tale rumore comporta genere scostamento spread rispetto funzione vera possiamo dunque prendere considerazione varianza tale variabile varianza rumore questione chiamato irreducible error area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#41,41,"Bias
Il rumore prima descritto non lo possiamo controllare. 
Possiamo però controllare il bias e la variance. 
Per deﬁnire il bias, consideriamo ad es. un modello 
costante addestrato con diversi training set:
 
42y
Area xPrezzo
y
Area xPrezzo
",bias rumore prima descritto possiamo controllare possiamo per controllare bias variance denire bias consideriamo modello costante addestrato diversi training set area prezzo area prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#42,42,"Bias
Consideriamo adesso la funzione media (quella tratteggiata) 
delle varie funzioni f stimate:
 
43y
Area xPrezzo
y
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]",bias consideriamo adesso funzione media quella tratteggiata varie funzioni stimate area prezzo area prezzo fwxtetrain fwxt
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#43,43,"Bias
Il bias è deﬁnito come la differenza tra la funzione media 
e la true function:
 
44
E’ in sostanza una valutazione di quanto il mio modello si 
adatti alla true function.
low complexity → high biasy
Area xPrezzo
bias( fˆw(xt)) = fw(true) (xt)",bias bias denito differenza funzione media true function sostanza valutazione modello adatti true function low complexity high biasy area prezzo bias fwxt fwtrue
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#44,44,"Variance
Per introdurre il concetto di varianza nella regression, 
dobbiamo considerare quanto le varie funzioni f stimate 
differiscono dalla funzione media. Vediamo ad esempio il 
caso di modello costante: 
 
45Non abbiamo una variazione elevata  
per le diverse funzioni stimate.
low complexity → low variancey
Area xPrezzo
y
Area xPrezzo
y
Area xPrezzo
var(fˆw(xt)) =Etrain [(fˆw(xt)",variance introdurre concetto varianza regression dobbiamo considerare varie funzioni stimate differiscono funzione media vediamo esempio caso modello costante variazione elevata diverse funzioni stimate low complexity low variancey area prezzo area prezzo area prezzo varfwxt etrain fwxt
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#45,45,"Variance
Per un modello polinomiale di grado elevato le cose 
vanno in modo diverso:
 
46
Prezzo
Prezzo
Area Area",variance modello polinomiale grado elevato cose vanno modo diverso prezzo prezzo area area
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#46,46,"Variance
Se consideriamo le funzioni f stimate per i possibili 
training set:
 
47
Questa volta la variazione è elevata.
high complexity → high varianceArea AreaPrezzo
Prezzo
var(fˆw(xt)) =Etrain [(fˆw(xt)",variance consideriamo funzioni stimate possibili training set volta variazione elevata high complexity high variance area area prezzo prezzo varfwxt etrain fwxt
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#47,47,"Bias per  
high-complexity models
Il bias per modelli “high order” è invece in genere basso:
 
48high complexity → low biasy
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]
bias( fˆw(xt)) = fw(true) (xt)",bias high complexity models bias modelli high order invece genere basso high complexity low biasy area prezzo fwxtetrain fwxt bias fwxt fwtrue
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#48,48," 
49
Bias-Variance Tradeoff
bias variance
Complessità del Modello
sweet spotMSE = bias + variance2",bias variance tradeoff bias variance complessit modello sweet spot bias variance
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#49,49," 
50
Bias-Variance Tradeoff
goal in ML →  trovare il cosiddetto “sweet spot”
purtroppo non possiamo calcolare bias e variance!
Per calcolarle dovremmo avere a disposizione la true 
function e tutti i possibili training set. 
Vedremo in seguito come poter operare in pratica per 
ottimizzare il tradeoff.",bias variance tradeoff goal trovare cosiddetto sweet spot purtroppo possiamo calcolare bias variance calcolarle dovremmo avere disposizione true function possibili training set vedremo seguito poter operare pratica ottimizzare tradeoff
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#5,5,"Valutare la funzione Loss 
 
6Ai ﬁni della valutazione del “loss” occorre deﬁnire i 
seguenti tipi di errore: 
• Training Error 
• Generalization Error (True Error) 
• Test Error",valutare funzione loss ni valutazione loss occorre denire seguenti tipi errore training error generalization error true error test error
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#50,50," 
51
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)
bias + noise
#data points nel training settrue errorErrore
training error",errori numerosit dati con modello ssata complessit bias noise data points training settrue error errore training error
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#51,51," 
52Andamento del True Error:
Se abbiamo pochi punti nel training set l’errore è alto, perché la 
funzione f (ﬁtted function) non stima bene la “true relationship” 
tra 
x
 e y. 
Aumentando i punti l’errore diminuisce. 
Al limite, esso tende ad un valore uguale a: bias + noise. Questo 
perché, anche se avessimo tutte le osservazioni possibili, il 
modello potrebbe non essere sufﬁcientemente ﬂessibile per 
catturare perfettamente la “true relationship” (questa è la nostra 
deﬁnizione di bias). 
A ciò si aggiunge il noise che, come sappiamo, non possiamo 
controllare. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)",andamento true error pochi punti training set lerrore alto funzione tted function stima bene true relationship aumentando punti lerrore diminuisce limite esso tende valore uguale bias noise perch tutte osservazioni possibili modello potrebbe essere sufcientemente essibile catturare perfettamente true relationship questa denizione bias ci aggiunge noise che sappiamo possiamo controllare errori numerosit dati con modello ssata complessit
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#52,52," 
53Andamento del Training Error:
Se abbiamo pochi punti nel training set l’errore è basso, 
perché la funzione f (ﬁtted function) può approssimare più 
facilmente la “true relationship” tra 
 x
 e y. 
Aumentando i punti l’errore aumenta. 
Al limite, anch’esso tende ad un valore uguale a: bias + noise. 
Questo perché, se avessimo tutte le osservazioni possibili, 
l’errore calcolato sarebbe proprio il true error che, come 
abbiamo visto, tende al valore bias + noise. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)",andamento training error pochi punti training set lerrore basso funzione tted function pu approssimare facilmente true relationship aumentando punti lerrore aumenta limite anchesso tende valore uguale bias noise perch tutte osservazioni possibili lerrore calcolato proprio true error che visto tende valore bias noise errori numerosit dati con modello ssata complessit
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#53,53,"Workﬂow per Regression  
(e per il ML in generale)
I due task importanti che dobbiamo attuare nella 
regression sono: 
1.
 Scelta del modello di regressione (
 model selection
 ) 
2.
 Valutazione del modello (
 model assessment
 )
 
54",workow regression generale due task importanti dobbiamo attuare regression sono scelta modello regressione model selection valutazione modello model assessment
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#54,54,"Workﬂow per Regression (e ML)
1.
 Model selection 
Spesso dobbiamo scegliere dei parametri di tuning 
 λ 
che controllano la complessità del modello (e.g., grado 
del polinomio) 
2.
 Model assessment 
Una volta scelto il modello, dobbiamo effettuare la 
valutazione del Generalization Error.
 
55",workow regression model selection spesso dobbiamo scegliere parametri tuning controllano complessit modello grado polinomio model assessment volta scelto modello dobbiamo effettuare valutazione generalization error
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#55,55,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
• 
stima dei parametri 
 ŵ
λ
 sui training data 
•
 valutazione delle prestazioni sui test data 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso test error  
2.
 Model assessment 
Considerare il test error calcolato su 
 ŵ
λ
*
 (ﬁtted model per la 
complessità scelta 
 λ
*) per approssimare il Generalization 
Error.
 
56Un approccio ingenuo  al problema potrebbe essere il seguente:",workow regression model selection ogni modello complessit stima parametri training data valutazione prestazioni test data scelta parametro comporta basso test error model assessment considerare test error calcolato tted model complessit scelta approssimare generalization error approccio ingenuo problema potrebbe essere seguente
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#56,56,"Workﬂow per Regression (e ML)
 
57Attenzione! 
Si è veriﬁcato un Peaking!!!
•E’ accaduto che l’ipotesi (i.e., la funzione stimata) è stata 
selezionata  in base alle sue prestazioni sull’insieme di test . 
•L’informazione che avrebbe dovuto rimanere conﬁnata in 
tale insieme si è, per così dire, “inﬁltrata” nell’algoritmo di 
apprendimento.",workow regression attenzione vericato peaking e accaduto lipotesi funzione stimata stata selezionata base prestazioni sullinsieme test linformazione dovuto rimanere connata tale insieme cos dire inltrata nellalgoritmo apprendimento
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#57,57,"Una soluzione è quella di considerare non solo due data 
set, ossia il training set e il test set: 
 
58
Training 
SetTest 
Set
ma considerarne tre (a patto di avere dati sufﬁcienti): 
Training 
SetTest 
Set
Validation
 Set
Workﬂow per Regression (e ML)",soluzione considerare solo due data set ossia training set test set training set test set considerarne tre patto avere dati sufcienti training set test set validation set workow regression
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#58,58,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
•
 stima dei parametri 
 ŵ
λ 
sul training set 
•
 valutazione delle prestazioni sul validation set 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso errore sul 
validation set 
2.
 Model assessment 
Calcolo del test error (usando dunque il test set) con 
 ŵ
λ
*
 per 
approssimare il Generalization Error.
 
59L’approccio in questo caso è il seguente:",workow regression model selection ogni modello complessit stima parametri training set valutazione prestazioni validation set scelta parametro comporta basso errore validation set model assessment calcolo test error usando dunque test set approssimare generalization error lapproccio caso seguente
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#59,59,"Tipici split 
 
60Non c’è una regola generale per suddividere le 
osservazioni disponibili tra i tre data set. 
Tipici split sono i seguenti:
Training 
SetTest 
Set
Validation
 Set
80%      10 %   10%
50%      25%   25%",tipici split c regola generale suddividere osservazioni disponibili tre data set tipici split seguenti training set test set validation set
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#6,6,"Training Error
 
7Consideriamo ancora l’esempio relativo ai prezzi degli 
appartamenti. Supponiamo di avere a disposizione le 
osservazioni come rappresentate in ﬁgura:
y
AreaxPrezzo
",training error consideriamo ancora lesempio relativo prezzi appartamenti supponiamo avere disposizione osservazioni rappresentate gura areax prezzo
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#60,60,"Riferimenti
 
61
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2008. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012.",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press murphy machine learning probabilistic approach press
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#7,7,"Training Error
 
8y
AreaxPrezzo
Come sappiamo, dobbiamo decidere il modello da 
utilizzare (lineare, quadratico, ecc.) e scegliere un 
sottoinsieme delle osservazioni per effettuare la fase di 
training del modello:",training error areax prezzo sappiamo dobbiamo decidere modello utilizzare lineare quadratico ecc scegliere sottoinsieme osservazioni effettuare fase training modello
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#8,8,"Training Error
 
9y
AreaxPrezzo
Possiamo ad esempio scegliere un modello quadratico e 
calcolare i pesi w tali da minimizzare la funzione RSS:",training error areax prezzo possiamo esempio scegliere modello quadratico calcolare pesi tali minimizzare funzione
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#9,9,"Calcolo del Training Error
 
10Una volta stimati i parametri del modello, possiamo 
valutare il training error di tale modello stimato come 
segue: 
1. Deﬁnizione di una Loss Function (absolute error, squared 
error, ecc.) 
2. Calcolo del Training Error come “average loss”, deﬁnito 
sugli N punti di training: 
Training Error =1
N·NX
i=1L[yi,fˆw(xi)]",calcolo training error volta stimati parametri modello possiamo valutare training error tale modello stimato segue denizione loss function absolute error squared error ecc calcolo training error average loss denito punti training training error nn lyifwxi
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Reinforcement Learning",machine learning universit roma tre dipartimento ingegneria anno accademico reinforcement learning
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#1,1,"Acknowledgements, sources and links
Organization, content and images of the slides are extracted from  the 
following sources:
•Reinforcement Learning: An Introduction . Richard S. Sutton  
and Andrew G. Barto, second edition, 2018.
•Implementation of Reinforcement Learning algorithms, from 
Sutton -Barto’s book . Denny Britz, GitHub project, 2016.
•Tutorial: Introduction to Reinforcement Learning with 
Function Approximation . Richard S. Sutton, 2016.
•UCL Course, Reinforcement Learning, videos and slides .  
David Silver, 2015.
•UCL course, Advanced Deep Learning & Reinforcement 
Learning, videos and slides . DeepMind, 2018.",sources links organization content images slides extracted following sources reinforcement learning introduction richard sutton andrew barto second edition implementation reinforcement learning algorithms sutton bartos book denny britz git hub project tutorial introduction reinforcement learning function approximation richard sutton course reinforcement learning videos slides david silver course advanced deep learning reinforcement learning videos slides deep mind
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#10,10,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(Ot,Rt,At−1,Ot−1,Rt−1,...))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. ..",first actor agent never ending loop wethe agent receive rtand observe wechoose action and ofour action environment send usareward rt new state observe
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#11,11,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(history ))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. ..",first actor agent never ending loop wethe agent receive rtand observe wechoose action and ofour action environment send usareward rt new state observe
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#12,12,"Not alone! Second actor: the environment
Agent, step t
•Receives observation Ot
•Receives scalar reward Rt 
•Computes his own state !!""
•Executes action At.
Environment, step t
•Receives action At 
•Computes his own state !!#$%
•Emits observation Ot+1
•Emits scalar reward Rt+1",alone second actor environment agent step receives observation receives scalar reward computes state executes action environment step receives action computes state emits observation emits scalar reward
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#13,13,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement",reinforcement learning setup problem actors know state observability policy value andmodel never ending control loop prediction improvement
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#14,14,"History , agent state , environment state
Notation
•History : the sequence of observations, actions, rewards up 
to  time step t:
Ht:=O1,R1,A1,...,At−1,Ot,Rt
•The agent selects actions, and the environment answers with
observations andrewards
•State : the information used (by the agent and the  
environment) to determine what happens next
•State is naturally a sequence St
•Agent state is a function of history: St := f (Ht)
•Environment state ""!""is different from agent state ""!#",history agent state environment state notation history sequence observations actions rewards time step the agent selects actions environment answers observations andrewards state information used agent environment determine happens next state naturally sequence agent state function history environment state different agent state
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#15,15,"Markov state
Uncertainty
Since we have no control of environment, everything is a random  
variable
Definition
A sequence of states (random variables) is Markov if and only if
Pr(St+1|St)=Pr(St+1|S1,...,St)
•The future is independent of the past given the present:
St  →Ht+1:+ ∞
•Once the state is known, the history may be thrown away: the  
state is a sufficient statistic of the future
Exercise
Is the environment state ""!""Markov? Is the history HtMarkov?",markov state uncertainty since control environment everything random variable definition sequence states random variables markov the future independent past given present ht once state known history may thrown away state sufficient statistic future exercise environment state markov history markov
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#16,16,"Fully observable environments
•Agent observes environment
state: Ot = !!""=!!%
•Agent state andenvironment  
state coincides!
Anever -ending loop
•...we(the agent) receive Rt
and observe St...
•...and thus wedecide todo  
action At∼π(·,St)...
•...andenvironment answers  
At with a new reward, state  
pair Rt+1,St+1...",fully observable environments agent observes environment state agent state andenvironment state coincides anever ending loop wethe agent receive observe and thus wedecide todo action atst answers new reward state pair rtst
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#17,17,"Example: themaze
Exercise
Discuss this example in terms of the language you have  
learned up tonow.",example themaze exercise discuss example terms language learned tonow
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#18,18,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4 What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement",reinforcement learning setup problem actors know state observability policy value model never ending control loop prediction improvement
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#19,19,"Strategy Policy
Arrows represent the policy π: which action to take from  
every state.Example: a policy for themaze
",strategy policy arrows represent policy action take every stateexample policy themaze
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#2,2,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement",reinforcement learning setup problem actors know state observability policy value andmodel never ending control loop prediction improvement
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#20,20,"Example: values for the policy of the maze
•Let πbe the optimal policy
•Value vπ (s) for every state s
Exercise
Choose a state s and compute vπ (s) by yourself. If sj denote s
the successor state of s, can the value vπ (sj) help with this  
computation?",example values policy maze let be optimal policy value every state exercise choose state compute yourself denote successor state value help computation
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#21,21,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement",reinforcement learning setup problem actors know state observability policy value model never ending control loop prediction improvement
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#22,22,"Prediction , improvement and control
The prediction problem inRL
Forecast the future: can you say from each state how much will be  
your return? It depends on the policy!
The improvement problem inRL
Change the future: can you find a different policy that will give  
you a better return?
The control problem inRL
Change the future: can you find the best policy atall?
Exercise
State formally the prediction, the improvement and the control  
problem.",prediction improvement control prediction problem forecast future say state much return depends policy improvement problem change future find different policy give better return control problem change future find best policy atall exercise state formally prediction improvement control problem
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#23,23,"Gridworld example: prediction
Exercise
Compute the value function for the uniform random policy.",gridworld example prediction exercise compute value function uniform random policy
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#24,24,"Gridworld example: improvement
Exercise
Find an improvement of the uniform policy.",gridworld example improvement exercise find improvement uniform policy
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#25,25,"Gridworld example: optimal control
Exercise
Compute the optimal value function over all possible policies.  
Given the optimal value v∗as above, find the optimal policy.  Is 
the optimal policy unique?",gridworld example optimal control exercise compute optimal value function possible policies given optimal value vas above find optimal policy optimal policy unique
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#26,26,"Wrapping up
Learning goals
•Understand the RL problem, and how RL differs from  
supervised learning
•Understand reward, return and how they are used to 
make  decisions
•Understand actions, states and rewards in term 
of  agent/environment interactions
•Understand the optimal control problem",wrapping learning goals understand problem differs supervised learning understand reward return used make decisions understand actions states rewards term interactions understand optimal control problem
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#27,27,"Wrapping up
What we (hopefully) have learnt
•Reinforcement Learning (RL) is concerned with goal -directed  
learning and decision -making. In RL an agent learns from  
experiences it gains by interacting with the environment. In  
supervised learning we cannot affect theenvironment
•In RL rewards are often delayed in time and the agent tries to  
maximize the cumulative sum of rewards, called return .Return 
is a long -term goal. For example, one may need to  make 
seemingly suboptimal moves to reach a winning position in a 
game
•An agent interacts with the environment via actions. The  
environment answers with states and rewards ... and so on in 
a  loop, that can finish after a certain number of steps or go 
on  forever
•Optimal control can be achieved by a prediction -improvement  
loop",wrapping hopefully learnt reinforcement learning concerned goal directed learning decision making agent learns experiences gains interacting environment supervised learning cannot affect theenvironment in rewards often delayed time agent tries maximize cumulative sum rewards called return return long term goal example one may need make seemingly suboptimal moves reach winning position game an agent interacts environment via actions environment answers states rewards loop finish certain number steps forever optimal control achieved prediction improvement loop
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#28,28,"Exercises
•Can every decision task be represented as an optimization  
problem with respect to a suitable reward?
•Is the reward an intrinsic datum of the decision task?
•Make an example where the greedy policy isoptimal.
•Make an example of a decision task with non-Markov  
environment state.
•Make an example of a decision task with non-Markov agent  
state.",exercises can every decision task represented optimization problem respect suitable reward is reward intrinsic datum decision task make example greedy policy isoptimal make example decision task markov environment state make example decision task markov agent state
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#29,29,"Exercises
The generic definition of policy is a time -dependant stochastic  
function of the history: πt (At|Ht ) = Pr(At |Ht ). Give a definition  of the 
policy in the following cases, and find a corresponding task.
•Fully observable environment, stochastic and non-stationary  
policy.
•Partially observable environment, stochastic and stationary  
policy.
•Fully observable environment, deterministic and stationary  
policy.",exercises generic definition policy time dependant stochastic function history atht prat give definition policy following cases find corresponding task fully observable environment stochastic stationary policy partially observable environment stochastic stationary policy fully observable environment deterministic stationary policy
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#3,3,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement",reinforcement learning setup problem actors know state observability policy value andmodel never ending control loop prediction improvement
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#4,4,"The RLproblem
Important points
•Trying to reach a goal
•Interactions: active decision -making agent vs environment
•Uncertainty about theenvironment
•Effects of actions cannot be fully predicted: 
adaptation required ( learning )
The RL reward hypothesis
All goals can be described by the maximization of some expected  
cumulative reward
•Is it true? Interesting analysis at  
http://incompleteideas.net/rlai.cs.ualberta.ca/ 
RLAI/rewardhypothesis.html
•Related with the expected utility hypothesis from von  
Neumann -Morgenstern utility theory",lproblem important points trying reach goal interactions active decision making agent environment uncertainty theenvironment effects actions cannot fully predicted adaptation required learning reward hypothesis goals described maximization expected cumulative reward is true interesting analysis related expected utility hypothesis von neumann morgenstern utility theory
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#5,5,"The RLproblem
RL main task
Decision problem: we would like to choose actions that maximize  
the return , i.e. the total future reward
Sequential decision making
Actions may have long term consequences
Uncertainty
The best we can aim for is maximizing the value , i.e.the
expected total future reward
Exercise
Find an example of a deterministic task, that is, a task where  your 
actions gives a fixed outcome (that you may or may not know  in 
advance)",lproblem main task decision problem would like choose actions maximize return total future reward sequential decision making actions may long term consequences uncertainty best aim maximizing value iethe expected total future reward exercise find example deterministic task task actions gives fixed outcome that may may know advance
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#6,6,"The RLproblem
To be greedy can bewrong
•A financial investment (may take months to mature)
•Refuelling a helicopter (might prevent a crash in 
several  hours)
•Blocking opponent moves (might help winning chances 
many moves from now)
Exercise
Discuss the difference between return and value",lproblem greedy bewrong financial investment may take months mature refuelling helicopter might prevent crash several hours blocking opponent moves might help winning chances many moves now exercise discuss difference return value
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#7,7,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?",lproblem examples reward games win draw lose generally final score games win lose case value probability winning why atari games immediate score increment step walking robot every step doesnt fall financial investment money increment last time step portfolio maze gridworld reaching exit otherwise wrong why
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#8,8,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?
•Maze and Gridworld: −1 for every move. Correct. Why?",lproblem examples reward games win draw lose generally final score games win lose case value probability winning why atari games immediate score increment step walking robot every step doesnt fall financial investment money increment last time step portfolio maze gridworld reaching exit otherwise wrong why maze gridworld every move correct why
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#9,9,"Examples
Games
TD-Gammon, 1995, ACM Communications .  
Atari’s family (video ).
•49 out of 57: DQN, 25 Feb 2015, Nature .
•52 out of 57: R2D2, Sep 2018, ICLR 2019 .
•51 out of 57: MuZero, Nov 2019, arXiv .
•57 out of 57: Agent57, Mar 2020, arXiv .
AlphaGo’s family (video ).
•AlphaGo, 27 Jan 2016, Nature .
•AlphaGo Zero, Oct 2017, Nature . 
•AlphaZero, Dec 2018, Science .
•MuZero, Nov 2019, arXiv .
StarCraft II (video ).AlphaStar, Nov 2019, Nature .
Protein folding
How a protein’s amino acid sequence dictates its three -dimensional  
structure? AlphaFold :Oct 2019, PROTEINS ;Jan 2020, Nature .",examples games gammon communications ataris family video feb nature sep zero nov xiv agent mar xiv alpha gos family video alpha jan nature alpha zero oct nature alpha zero dec science mu zero nov xiv star craft video alpha star nov nature protein folding proteins amino acid sequence dictates three dimensional structure alpha fold oct jan nature
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#0,0,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equationsMDP: Markov Decision Processes
",distribution model decisions andreturn value functions bellman equations markov decision processes
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#1,1,"Basic block: state , action , model ,reward
uintermediate
or initial state
 vintermediate
or final state
w
r =+3
p(v,+3|u,a)=0.7
r =−1
p(w,−1|u,a)=0.3intermediate
or final stateaction a",basic block state action model reward uintermediate initial state vintermediate final state pvua final stateaction
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#10,10,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations",distribution model decisions andreturn value functions bellman equations
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#11,11,"The D in MDP: decisions
Where are thedecisions?
•In any state s, the agent must choose between available  
actions a
•When choosing a from s, the environment answers s’ 
with probability #!!!"". Environment decision.
•The agent behaviour is given by probabilities π(a|s): ”how  
likely I’m going to choose a from s?”.  Agent decision.
Definition
A policy π is a probability distribution over actions given states:
π(a|s) := Pr(At = a|St =s)",decisions thedecisions in state agent must choose available actions when choosing environment answers probability environment decision the agent behaviour given probabilities as how likely im going choose agent decision definition policy probability distribution actions given states as prat ast
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#12,12,"Example: uniform stochastic policy
A
1
B
1
0.5
0.5
0.8,+10
 0.2,+3
0.1,+2
 0.9,−30.5
0.5
0.1,+39
0.9,+42
0.1,−2
0.9,+3
2 2
What can wedo?
At every step, we choose the action according to the probability.",example uniform stochastic policy wedo every step choose action according probability
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#13,13,"Example: deterministic policy
A
1
2B
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2
What can wedo?
At every step, we choose the given action.",example deterministic policy wedo every step choose given action
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#14,14,"Tabular representation
S and Aarefinite
A policy can be represented by a table: every line in the table  
corresponds to a state.
Stochastic policy
A[0.5,0.5]
B[0.5,0.5]
Deterministic policy
A2
B1",tabular representation aarefinite policy represented table every line table corresponds state stochastic policy deterministic policy
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#15,15,"The return : towards the goal
Definition
•Total return ofanepisode ending attime T:thevalue ofthe  
random variable Gt:=Rt+1+Rt+2+···+RTfortheepisode
•If the MDP is continuing, we need a discount factor :
Why?
•Transforming theterminal state inabsorbing with reward 0,we  
can use a unified notation for episodic and continuing MDP:
•In episodic tasks we can use γ = 1, in continuing tasks we  
must use γ <1!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#
!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#",return towards goal definition total return ofanepisode ending attime tthevalue ofthe random variable tfortheepisode if continuing need discount factor why transforming theterminal state inabsorbing reward use unified notation episodic continuing in episodic tasks use continuing tasks must use
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#16,16,"The return : towards the goal
Why the discount
•The discount factor measures how much do we care about 
rewards far in thefuture
•A reward r after k + 1 time -steps is worth “only” γkr : wesay
myopic evaluation if γ ∼0, far-sighted evaluation if γ ∼1
•Convenience: avoids infinite returns in cyclic MDP
•We shouldn’t trust our model too much: uncertainty about  
the future may not be fully represented
•If the reward is financial, immediate rewards may earn more  
interest than delayed rewards
•Animal and human behaviour shows preference for immediate  
reward",return towards goal discount the discount factor measures much care rewards far thefuture reward time steps worth only kr wesay myopic evaluation far sighted evaluation convenience avoids infinite returns cyclic we shouldnt trust model much uncertainty future may fully represented if reward financial immediate rewards may earn interest delayed rewards animal human behaviour shows preference immediate reward
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#17,17,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations",distribution model decisions andreturn value functions bellman equations
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#18,18,"How much are states and actions worth?
Remark
The total return Gt at time t is a random variable:
Thus, it makes sense to compute its expected value.
Definition :state -value function
The state -value function vπ(s)foraMDP isthe return wecan
expect toaccumulate starting from state s,following thepolicy π:
vπ(s):=""π[Gt|St=s]
Exercise
Is the above definition/notation correct?!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#",much states actions worth remark total return time random variable thus makes sense compute expected value definition state value function state value function vsfora isthe return wecan expect toaccumulate starting state sfollowing thepolicy exercise
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#19,19,"How much are states and actions worth?
Total return
State -value function
vπ(s)=""π[Gt|St=s]
Definition: action -value function
The action -value function qπ (s,a) for a MDP is the return we can 
expect to accumulate starting from a state s, choosing action a, 
and then following the policy π:
qπ(s,a):=Eπ[Gt|St=s,At=a]!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#",much states actions worth total return state value function definition action value function action value function return expect accumulate starting state choosing action following policy
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#2,2,"Basic block: state , action , model ,reward
u
v
wa
r = +3, p =0.7
r=−1,p=0.3",basic block state action model reward rp
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#20,20,"Example
Exercise
Compute qπ(A,1),qπ(A,2),qπ(B,1) and qπ(B,2) forthe uniform policy π.",example exercise compute qb forthe uniform policy
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#3,3,"Markov Decision Process: MDP
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
Distribution model
The probability distribution p is called distribution model , or  
simply model, of the MDP
Focus on finite MDP
From now on, assume that S, Aand Rarefinite",markov decision process markov decision process data asetofstates sasetofactions for state action aa probability distribution psaover sr discount factor distribution model probability distribution called distribution model simply model focus finite assume aand rarefinite
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#4,4,"MDP: meaning of the model
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
From distribution model to random variables St andRt
The probability distribution p of the MDP gives the next state and  
reward:
Pr(St=s',Rt=r|St−1=s,At−1=a):=p(s',r|s,a)",meaning model markov decision process data asetofstates sasetofactions for state action aa probability distribution psaover sr discount factor distribution model random variables probability distribution gives next state reward
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#5,5,"MDP: meaning of the model
Exercises
•Explain what St,At and Rtare
•Given p, give a formula for Pr(St = s'|St−1 = s, At−1 = a)
•Given p, give a formula for ""[Rt|St−1 = s, At−1 =a]
•Given p, give a formula for ""[Rt|St−1 = s, At−1 = a,St = s']",meaning model exercises explain stat rtare given give formula prst sst at given give formula rtst at given give formula rtst at ast
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#6,6,"The M in MDP: Markov property
Tabular representation: transitions
An action a ∈Agives a transition probability from a state s toa
state s' :
Thus, we have a transition matrix Pa for each action a, and a  
corresponding underlying Markov stochastic process.
Tabular representation: rewards
An action a ∈A gives an average reward for any state s:
Thus, we have an average reward vector Ra for any action a.!!!!""≔#$#|$,'==!)*$=$#|*$%&=$,+$%&='
,!""=-,$|*$%&=$,+$%&='",markov property tabular representation transitions action agives transition probability state toa state thus transition matrix action corresponding underlying markov stochastic process tabular representation rewards action gives average reward state thus average reward vector action
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#7,7,"Example
u
1
2v
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2",example
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#8,8,"Example
u1
2v1
0.8,+10 0.2,+3
0.1,+2 0.9,−30.1,+39
0.9,+42
0.9,+30.1,−2
2
= distribution model",example distribution model
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#9,9,"Episodic MDP
•If there is a special terminal  
state reachable from every  
state, the MDP is episodic
•Otherwise, the MDP is
continuing
•Episode : any sample
S0,A0,R1,S1,...terminating  
in the final state
Exercise
•Write an episode, and compute its probability 
of  happening. Hint: tricky question.",episodic if special terminal state reachable every state episodic otherwise continuing episode sample final state exercise write episode compute probability happening hint tricky question
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 16)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione reinforcement learning
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#1,1,"Sommario
Richiami RL e Q-learning 
Esempio taxi  
Ambiente OpenAI Gym 
Approccio non RL 
Approccio Q-Learning 
Approccio Epsilon-Greedy Q-Learning 
Valutazione e iperparametri",sommario richiami learning esempio taxi ambiente open gym approccio approccio learning approccio epsilon greedy learning valutazione iperparametri
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#10,10,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
https://www.gymlibrary.ml  
La libreria include già l'ambiente Taxi già costruito. 
!
pip install cmake 
 'gym[atari]'
  scipy
import
 gym
# carichiamo l'environment taxi
env = gym.make(
 ""Taxi-v3""
 ).env
env.render()
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | 
: |
|
Y
| : |B: |
+---------+
11",open gym python permettono sperimentare approcci libreria include gi lambiente taxi gi costruito pip install cmake gymatari scipy import gym carichiamo lenvironment taxi env gymmake taxi env envrender
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#11,11,"OpenAI Gym
...
env.reset() 
 # reset environment to a new, random state
env.render()
print
(
""Action Space {}""
 .
format
(env.action_space))
print
(
""State Space {}""
 .
format
(env.observation_space))
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : 
: : |
| | : | : |
|Y| : |
 B
: |
+---------+
>> Action Space Discrete(6)
>> State Space Discrete(500)
...
12",open gym envreset reset environment new random state envrender print action space format print state space format action space discrete state space discrete
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#12,12,"OpenAI Gym
Le azioni sono codiﬁcate con interi:  
0 = south, 1 = north, 2 = east, 3 = west, 4 = pickup, 5 = dropoff 
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : 
| : |
|Y| : |
 B
: |
+---------+
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | : |
|Y| : 
|
B
: |
+---------+
13",open gym azioni codicate interi south north east west pickup dropoff state reward done info envstep azione verso south envrender state reward done info envstep azione verso south envrender
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#13,13,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
# parametri (taxi row, taxi column, passenger index, destination index) 
state = env.encode(
 3
, 
1
, 
2
, 
0
)
print
(
""State:""
 , state)
env.s = state
env.render()
>> State: 328
+---------+
|
R
: | : :G|
| : | : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
14",open gym python permettono sperimentare approcci parametri taxi row taxi column passenger index destination index state envencode print state state envs state envrender state
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#14,14,"OpenAI Gym
Possiamo rappresentare un certo stato dell'environment esplicitamente. 
Allo stato sarà associato un id numerico (328). 
state 
=
 env.
encode
(
3
, 
1
, 
2
, 
0
)  
# (taxi row, taxi column, passenger index, destination index)
print
(
""State:""
 , state)
env.
s 
=
 state
env.
render
()
State: 328
+---------+
|
R
: | : :G|
| : : : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
15",open gym possiamo rappresentare certo stato esplicitamente stato associato numerico state env encode taxi row taxi column passenger index destination index print state state env state env render state
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#15,15,"OpenAI Gym
La reward table rappresenta coppie stati x azioni. 
Ad esempio, per lo stato 328 otteniamo il seguente dizionario: 
env.P[
328
]
>>
{0: [(1.0, 428, -1, False)],
 1: [(1.0, 228, -1, False)],
 2: [(1.0, 348, -1, False)],
 3: [(1.0, 328, -1, False)],
 4: [(1.0, 328, -10, False)],
 5: [(1.0, 328, -10, False)]}
Dove il dizionario ha la struttura:  
{action: [(probability 
 sempre_1
 , next-state, reward, done)]}.
16",open gym reward table rappresenta coppie stati azioni esempio stato otteniamo seguente dizionario envp false false false false false false dizionario struttura action probability sempre next state reward done
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#16,16,"Esercizio Taxi: senza RL
Supponi che l'agente abbia accesso unicamente la 
 reward table
  P per 
decidere quale azioni compiere. Perciò non apprende dall'esperienza 
acquista nel passato. 
Crea un loop che prosegua ﬁnché il cliente non sia arrivato a destinazione. 
Suggerimento: la funzione 
 env.action_space
 .
sample
 ()
 restituisce una 
azione in modo casuale.
17",esercizio taxi senza supponi lagente accesso unicamente reward table decidere azioni compiere perci apprende dallesperienza acquista passato crea loop prosegua nch cliente arrivato destinazione suggerimento funzione sample restituisce azione modo casuale
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#17,17,"Esercizio Taxi: senza RL
env.
s 
= 
328  
# stato iniziale
epochs 
= 
0
penalties, reward 
 = 
0
, 
0
frames 
=
 [] 
# per animazione
done 
= 
False
while 
not
 done:
    action 
 =
 env.
action_space
 .
sample
()
    state, reward, done, info 
 =
 env.
step
(action)
    
if
 reward 
 == 
-
10
:
        penalties 
 += 
1
    
    frames.
 append
({
        
 'frame'
: env.
render
(mode
=
'ansi'
),
        
 'state'
: state,
        
 'action'
 : action,
        
 'reward'
 : reward
        }
    )
    epochs 
 += 
1
    
print
(
""Timesteps taken: {}""
 .
format
(epochs))
print
(
""Penalties incurred: {}""
 .
format
(penalties))
18",esercizio taxi senza env stato iniziale epochs penalties reward frames animazione done false done action env actionspace sample state reward done info env step action reward penalties frames append frame env render mode ansi state state action action reward reward epochs print timesteps taken format epochs print penalties incurred format penalties
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#18,18,"Esercizio Taxi: senza RL
Per l'animazione: 
from
 IPython.
 display 
import
 clear_output
from
 time 
import
 sleep
def
 print_frames(frames):
    
for
 i, frame 
 in 
enumerate
 (frames):
        clear_output(wait
 =
True
)
        
 print
(frame[
'frame'
].
getvalue
 ())
        
 print
(
f""Timestep: 
 {i 
+ 
1
}
""
)
        
 print
(
f""State: 
 {frame[
'state'
]}
""
)
        
 print
(
f""Action: 
 {frame[
'action'
 ]}
""
)
        
 print
(
f""Reward: 
 {frame[
'reward'
 ]}
""
)
        sleep(
 .1
)
        
print_frames(frames)
L'algoritmo può impiegare molti step (oltre 1000) incorrendo in molte 
penalty (oltre 300).
19",esercizio taxi senza lanimazione python display import clearoutput time import sleep def frame enumerate frames true print frame frame getvalue print ftimestep print fstate frame state print faction frame action print freward frame reward sleep lalgoritmo pu impiegare molti step oltre incorrendo molte penalty oltre
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#19,19,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
20",esercizio learning python esercizio modica codice precedente implementando lalgoritmo learning
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#2,2,"Richiami: Reinforcement Learning
Nell'ambito del Reinforcement Learning (RL), la 
 policy
  è la strategia per 
scegliere una azione nello stato corrente che determini la massima 
ricompensa (
 reward)
 . 
Il 
Q-learning
  è un algoritmo che mira a determinare col tempo la migliore 
azione (
 best action
 ), dato lo stato corrente (
 current state), 
 in base alla stima 
di 
reward
  attesa. 
Misura la bontà di una combinazione stato-azione in termini di 
 reward
 . 
Impiega una 
 Q-table
  aggiornata dopo ogni episodio, dove la riga 
corrisponde allo stato e la colonna all'azione. Il Q-value dentro la tabella 
indicano quanto una azione è stata buona (alto reward) in passato. 
È un algoritmo model-free, poiché l'agente non conosce il valore di una 
azione prima di effettuarla.  
Non segue un approccio greedy poiché scegliere sempre l'azione con 
reward immediato massimo potrebbe determinare sequenze di azioni non 
ottime.
3",richiami reinforcement learning nellambito reinforcement learning policy strategia scegliere azione stato corrente determini massima ricompensa reward learning algoritmo mira determinare tempo migliore azione best action dato stato corrente current state base stima reward attesa misura bont combinazione stato azione termini reward impiega table aggiornata dopo ogni episodio riga corrisponde stato colonna allazione value dentro tabella indicano azione stata buona alto reward passato algoritmo model free poich lagente conosce valore azione prima effettuarla segue approccio greedy poich scegliere sempre lazione reward immediato massimo potrebbe determinare sequenze azioni ottime
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#20,20,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
%%time   # stampa il tempo trascorso al termine dell'esecuzione
import
 numpy 
as
 np
import
 random
from
 IPython.display 
 import
 clear_output
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
# per il report
all_epochs = []
all_penalties = []
q_table = np.zeros([env.observation_space.n, env.action_space.n])
...
21",esercizio learning python esercizio modica codice precedente implementando lalgoritmo learning time stampa tempo trascorso termine dellesecuzione import numpy import random pythondisplay import clearoutput iperparametri alpha gamma report allepochs allpenalties qtable
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#21,21,"Esercizio: Q-learning in Python
...
for
 i 
in 
range
(
1
, 
100001
):
    state = env.reset()
    epochs, penalties, reward, = 
 0
, 
0
, 
0
    done = 
 False
    
    
while 
not
 done:
        action = np.argmax(q_table[state])
        next_state, reward, done, info = env.step(action) 
        
        old_value = q_table[state, action]
        next_max = np.
 max
(q_table[next_state])
        
 # eq Bellman 
        new_value = (
 1
 - alpha) * old_value + alpha * 
                    (reward + gamma * next_max)
        q_table[state, action] = new_value
...
22",esercizio learning python range state envreset epochs penalties reward done false done action nextstate reward done info oldvalue qtablestate action nextmax max bellman newvalue alpha oldvalue alpha reward gamma nextmax qtablestate action newvalue
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#22,22,"Esercizio: Q-learning in Python
...
        
 if
 reward == 
 -10
:
            penalties += 
 1
        state = next_state
        epochs += 
 1
        
    
if
 i % 
100
 == 
0
:
        clear_output(wait=
 True
)
        
 print
(
f
""Episode: 
 {i}
""
)
print
(
""Training finished.\n""
 )
>> Episode: 100000
>> Training finished.
>> CPU times: user 1min 25s, sys: 15 s, total: 1min 40s
>> Wall time: 1min 29s
q_table[
 328
] # l'azione migliore è north -2.27
>> array([-2.31436727, -2.27325184, -2.31164458, -2.3090025 , 
          -2.8816    , -2.8816    ])
23",esercizio learning python reward penalties state nextstate epochs true print episode print training finishedn episode training finished times user min sys total min wall time min qtable lazione migliore north array
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#23,23,"Esercizio: Q-learning in Python
Esercizio
 : valuta nuovamente l'algoritmo con le best action ricavate dalla 
Q-table. 
24",esercizio learning python esercizio valuta nuovamente lalgoritmo best action ricavate table
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#24,24,"Esercizio: Q-learning in Python
Valutazione dell'algoritmo con le best action ricavate dalla Q-table: 
total_epochs, total_penalties 
 = 
0
, 
0
episodes 
 = 
100
for
 _ 
in 
range
(episodes):
    state 
 =
 env.
reset
()
    epochs, penalties, reward 
 = 
0
, 
0
, 
0
    
    done 
 = 
False
    
while 
not
 done:
        
 action 
=
 np.
argmax
(q_table[state])
        state, reward, done, info 
 =
 env.
step
(action)
        
 if
 reward 
 == 
-
10
:
            penalties 
 += 
1
        epochs 
 += 
1
    total_penalties 
 +=
 penalties
    total_epochs 
 +=
 epochs
print
(
f""Results after 
 {episodes}
  episodes:""
 )
print
(
f""Average timesteps per episode: 
 {total_epochs  
/ 
episodes}
 ""
)
print
(
f""Average penalties per episode: 
 {total_penalties  
/ 
episodes}
 ""
)
>> Results after 100 episodes:
>> Average timesteps per episode: 13.01     
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
25",esercizio learning python valutazione dellalgoritmo best action ricavate table totalepochs totalpenalties episodes range episodes state env reset epochs penalties reward done false done action argmax state reward done info env step action reward penalties epochs totalpenalties penalties totalepochs epochs print fresults episodes episodes print faverage timesteps episode totalepochs episodes print faverage penalties episode episodes results episodes average timesteps episode average penalties episode nessuna penalty clienti
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#25,25,"Epsilon-Greedy Q-learning
Con l'approccio Epsilon-greedy Q-learning introduciamo il bilanciamento 
tra 
exploration
  e 
exploitation
 .  
Nei modelli model-free è fondamentale esplorare l'ambiente per ottenere 
informazioni su cui basare le successive decisioni informate. 
Nella versione Espilon-greedy, con probabilità epsilon l'agente sceglie una 
azione in modo casuale (esplorazione) e segue l'azioni valutata migliore 
nell'altro caso (1-epsilon).  
Esercizio
 : modiﬁca il codice introducendo questa versione.
26
",epsilon greedy learning lapproccio epsilon greedy learning introduciamo bilanciamento exploration exploitation modelli model free fondamentale esplorare lambiente ottenere informazioni basare successive decisioni informate versione espilon greedy probabilit epsilon lagente sceglie azione modo casuale esplorazione segue lazioni valutata migliore nellaltro caso epsilon esercizio modica codice introducendo versione
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#26,26,"Epsilon-Greedy Q-learning
Esercizio
 : modiﬁca il codice introducendo questa versione. 
... 
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
epsilon = 
 0.1
...
while 
not
 done:
        
 if
 random.uniform(
 0
, 
1
) < epsilon:
            action = env.action_space.sample() 
 # Explore action space
        
 else
:
            action = np.argmax(q_table[state]) 
 # Exploit learned values
...
>> Results after 100 episodes:
>> Average timesteps per episode: 12.81     <-- invece di 13.01 
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
27",epsilon greedy learning esercizio modica codice introducendo versione iperparametri alpha gamma epsilon done randomuniform epsilon action explore action space else action exploit learned values results episodes average timesteps episode invece average penalties episode nessuna penalty clienti
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#27,27,"Valutazione approccio RL
Alcune metriche da considerare nella valutazione sono: 
Numero medio di 
 penalità
  per episodio (ideale --> 0) 
Numero medio di 
 timesteps
  per percorso  
Valore medio di 
 reward
  per mossa
28
",valutazione approccio alcune metriche considerare valutazione sono numero medio penalit episodio ideale numero medio timesteps percorso valore medio reward mossa
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#28,28,"Iperparametri
Alpha
 : da decrementare con l'incremento dell'esperienza acquisita 
Gamma
 : se ci avviciniamo all'obiettivo dobbiamo ridurre l'importanza 
della reward a lungo termine 
Epsilon
 : con l'accumularsi dei tentativi, epsilon deve ridursi. 
Esercizio: applica un approccio 
 grid search
  per ricavare una 
approssimazione degli iperparametri nello scenario del taxi che guida da 
solo.
29",iperparametri alpha decrementare lincremento dellesperienza acquisita gamma avviciniamo allobiettivo dobbiamo ridurre limportanza reward lungo termine epsilon laccumularsi tentativi epsilon deve ridursi esercizio applica approccio grid search ricavare approssimazione iperparametri scenario taxi guida solo
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#29,29,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
30",open gym testi riferimento
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#3,3,"Richiami: Reinforcement Learning
Step #1: inizializzo la Q-table con valori pari a 0, ogni azioni e 
equiprobabile. 
Step #2: scegli l'azione in modo random, o sfrutta l'eventuale informazione 
che hai al principio 
Step #3: esegui l'azioni e colleziona il reward 
Step #4: aggiorna la Q-table di conseguenza 
4
",richiami reinforcement learning step inizializzo table valori pari ogni azioni equiprobabile step scegli lazione modo random sfrutta leventuale informazione principio step esegui lazioni colleziona reward step aggiorna table conseguenza
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#4,4,"Richiami: Reinforcement Learning
L'equazione di 
 Bellman
  aggiorna i Q-values determinando il valore 
massimo di 
 reward
  atteso per ogni stato nella Q-table.  
Il primo termine 
 Q()
 indica il valore dell'azione corrente nello stato 
corrente. Il secondo combina il reward corrente e il valore discount dello 
stato futuro caratterizzato da reward massima.  
Il 
discount factor lambda
  [0,1] permette di ridurre il reward col tempo e 
indica quanta importanza assegnamo ai futuri reward: valori vicini allo 0 
indicano che l'agente si limita a valutare i reward immediati, vicini al 1 
permettono di valutare l'effetto a lungo termine dei reward. 
Il valore 
 alpha
  (learning rate (0,1]) determina l'importanza che assegniamo 
ai valori futuri rispetto a quelli attuali.
5
",richiami reinforcement learning lequazione bellman aggiorna values determinando valore massimo reward atteso ogni stato table primo termine indica valore dellazione corrente stato corrente secondo combina reward corrente valore discount stato futuro caratterizzato reward massima discount factor lambda permette ridurre reward tempo indica importanza assegnamo futuri reward valori vicini indicano lagente limita valutare reward immediati vicini permettono valutare leffetto lungo termine reward valore alpha learning rate determina limportanza assegniamo valori futuri rispetto attuali
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#5,5,"Esempio: taxi che guida da solo
Deﬁniamo un ambiente (environment) sempliﬁcato dove un taxi deve 
prendere un cliente in una certa locazione e lasciarlo in un'altra. 
Vogliamo altresì: 
Lasciare il cliente nel luogo giusto 
Minimizzare il tempo per il trasporto 
Seguire le regole della strada 
Dobbiamo deﬁnire: rewards, states, actions. 
Quali puoi ipotizzare?
6",esempio taxi guida solo deniamo ambiente environment semplicato taxi deve prendere cliente certa locazione lasciarlo unaltra vogliamo altres lasciare cliente luogo giusto minimizzare tempo trasporto seguire regole strada dobbiamo denire rewards states actions quali puoi ipotizzare
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#6,6,"Taxi che guida da solo: reward
Per i reward possiamo ipotizzare: 
Alto reward se il cliente viene lasciato correttamente. 
Penalizzazione se il cliente viene lasciato nella location sbagliata. 
Per ogni istante di tempo trascorso, una piccola penalità.
7",taxi guida solo reward reward possiamo ipotizzare alto reward cliente viene lasciato correttamente penalizzazione cliente viene lasciato location sbagliata ogni istante tempo trascorso piccola penalit
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#7,7,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Quanti sono il numero dei possibili stati?
8
",taxi guida solo state space state space corrisponde tutte possibili situazioni taxi pu trovare ogni stato deve contenere abbastanza informazioni permettere allagente decidere azione supponiamo taxi lunico veicolo suddividiamo lambiente griglia posizione corrente location pick drop off rgyb cio cliente vuole andare stato aggiuntivo rappresenta cliente allinterno taxi numero possibili stati
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#8,8,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Possibili stati: 5 x 5 x 5 x 4 = 500
9
",taxi guida solo state space state space corrisponde tutte possibili situazioni taxi pu trovare ogni stato deve contenere abbastanza informazioni permettere allagente decidere azione supponiamo taxi lunico veicolo suddividiamo lambiente griglia posizione corrente location pick drop off rgyb cio cliente vuole andare stato aggiuntivo rappresenta cliente allinterno taxi possibili stati
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#9,9,"Taxi che guida da solo: action space
L'agente può in ogni stato fare una delle seguenti azioni: 
muoversi a nord 
muoversi a su 
muoversi a est 
muoversi a ovest 
prendere il cliente 
lasciare il cliente 
Se l'agente non può fare una certa azione in uno stato (es. presenza di un 
muro) possiamo assegnare una penalità di -1.
10",taxi guida solo action space lagente pu ogni stato fare seguenti azioni muoversi nord muoversi muoversi est muoversi ovest prendere cliente lasciare cliente lagente pu fare certa azione stato presenza muro possiamo assegnare penalit
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 17)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione reinforcement learning
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#1,1,"Sommario
OpenAI GYM: Ambienti  
Deep Q-learning 
Libreria Baseline3",sommario open ambienti deep learning libreria baseline
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#10,10,"OpenAI GYM: Environments
..
env = gym.make(
 ""Qbert-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
11
",open environments env gymmake qbert directory video env recorderenv directory
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#11,11,"OpenAI GYM: Environments
12
",open environments
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#12,12,"Deep Q-learning
Per ambienti complessi (es. 10K stati e 1K azioni), la Q-table associata ad 
ogni observation può risultare complessa (10M di celle). La stima di un 
certo valore a partire da quelli esplorati in passato richiede: 
molta memoria per la Q-table 
tempo necessario per esplorare tutti gli stati e ricavare i valori 
Nel Deep Q-learning usiamo una rete neurale per stimare i Q-value, dove 
in output abbiamo il valore stimato per ogni azione.
13
Q learning Deep Q learning",deep learning ambienti complessi stati azioni table associata ogni observation pu risultare complessa celle stima certo valore partire esplorati passato richiede molta memoria table tempo necessario esplorare stati ricavare valori deep learning usiamo rete neurale stimare value output valore stimato ogni azione learning deep learning
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#13,13,"Deep Q-learning: Temporal Difference
La rete neurale ha bisogno di un valore di loss. 
Deﬁniamo la 
 Temporal Difference:   
Q(s,a)
  è il Q-value per una certa azione a. Dopo aver eseguito l'azione avremo 
un reward R(s,a). 
 Q
t-1
(s,a)
 è il Q-value precedente . 
Idealmente le due parti devono coincidere, essendo la prima impiegata per 
ricavare la seconda, ma la casualità dell'ambiente e il tempo di apprendimento 
creano discostamenti. 
Il valore del loss è determinato dal discostamento (
 Temporal Difference target)  
dal target: Q-value - Q* 
Impiegando il learning rate alpha, usiamo la TD per ricavare il nuovo Q-value.
14
",deep learning temporal difference rete neurale bisogno valore loss deniamo temporal difference qsa value certa azione dopo aver eseguito lazione reward rsa value precedente idealmente due parti devono coincidere prima impiegata ricavare seconda casualit dellambiente tempo apprendimento creano discostamenti valore loss determinato discostamento temporal difference target target value impiegando learning rate alpha usiamo ricavare nuovo value
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#14,14,"Deep Q-learning
Nel Deep Q-learning l'azione da eseguire è determinata dal valore 
massimo in output dalla rete (non esiste la Q-table tradizionale). Ogni 
nodo di output è una azione possibile. 
Otteniamo un problema di regressione, senza però conoscere il valore del 
target
  (nell'equazione in verde) non essendoci Q-table. 
La nuova eq per il Q-learning diverrà: 
il brackpropagation tenderà a convergere i Q-value e i reward. 
15
",deep learning deep learning lazione eseguire determinata valore massimo output rete non esiste table tradizionale ogni nodo output azione possibile otteniamo problema regressione senza per conoscere valore target nellequazione verde essendoci table nuova learning diverr tender convergere value reward
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#15,15,"Deep Q-learning: Neural Fitted Q Iteration 
La rete ci restituisce i Q-value target per ogni azione.  
La loss sarà così deﬁnita: 
Nota: nel Q-learning tradizionale, il Q-value viene aggiornato ad ogni 
transizione di stato. Nel Deep Q-learning il processo è più complesso...
16
",deep learning neural fitted iteration rete restituisce value target ogni azione loss cos denita nota learning tradizionale value viene aggiornato ogni transizione stato deep learning processo complesso
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#16,16,"Deep Q-learning: Neural Fitted Q Iteration 
La rete deve valutare sia il valore 
 predetto
  sia il 
 target
 . Per tale motivo se ne 
usano 2 con stessa architettura ma pesi distinti. 
Una rete per i valori 
 target
  con i parametri ""ﬁssi"". Ad ogni C iterazioni (es. 
100) i parametri della 
 prediction
  network (aggiornata spesso, es. ogni 4 
steps) saranno copiati nella 
 target
  network. Questo rende il training più 
stabile poiché mantiene la funzione target stabile. Approccio ""
 Neural Fitted 
Q Iteration (NFQ)
 "" 
17
La target nework stima il Temporal difference target",deep learning neural fitted iteration rete deve valutare valore predetto target tale motivo usano stessa architettura pesi distinti rete valori target parametri ssi ogni iterazioni parametri prediction network aggiornata spesso ogni steps copiati target network rende training stabile poich mantiene funzione target stabile approccio neural fitted iteration target nework stima temporal difference target
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#17,17,"Experience replay
Data la numerosità degli stati possibili, conviene salvarli per poi ""rigiocarci"" 
in seguito. È una 
 off-line policy
 , cioè si sfrutta l'esperienza acquisita nelle 
azioni fatte nel passato per aggiornare i parametri attuali. 
Dare in input lunghe sequenze di stati correlati (es. foto di percorsi 
autostradali rettilinei) può creare bias nella rete e non permettere di 
adattarsi in altre situazione. 
A differenza del Q-learning, durante l'esecuzione i dati [state, action, 
reward, next_state] sono salvati in un buffer chiamato 
 experience replay
 . 
Supponendo che l'ambiente sia un gioco, durante il training possiamo 
campionare periodicamente (es. ogni 4 step) in modo casuale 64 frames 
(batch) dei 100K possibili in modo che abbiano scarsa correlazione tra 
loro. Questo permette di non introdurre bias dovuti alla particolare subset 
di istanze considerate.
18",experience replay data numerosit stati possibili conviene salvarli poi rigiocarci seguito line policy cio sfrutta lesperienza acquisita azioni fatte passato aggiornare parametri attuali dare input lunghe sequenze stati correlati foto percorsi autostradali rettilinei pu creare bias rete permettere adattarsi altre situazione differenza learning durante lesecuzione dati state action reward nextstate salvati buffer chiamato experience replay supponendo lambiente gioco durante training possiamo campionare periodicamente ogni step modo casuale frames batch possibili modo scarsa correlazione loro permette introdurre bias dovuti particolare subset istanze considerate
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#18,18,"Deep Q-learning: step principali
Ricava i Q-values dalla rete per ogni azione dando in input lo stato 
corrente (es. screenshot). 
Seleziona una azione con 
 epsilon-greedy policy
 , cioè random con 
probabilità 
 epsilon
 , altrimenti l'azione con Q-value massimo. 
Valuta l'azione che genera il nuovo stato 
 s'
, e ricava il reward 
corrispondente. Lo stato 
 s'
 corrisponde allo screen successivo. La 
transizione 
 <s,a,r,s’>
  è salvata nel replay buffer. 
Campiona casualmente batch di transizioni dal replay buffer e ricava la loss 
corrispondente. 
Esegui il 
 gradient descent
  con la differenza tra 
 target Q
  e 
predicted Q 
impiegando la rete e i parametri attuali minimizzando la loss. 
Ogni C iterazioni trasferisci i parametri della rete alla rete target. 
Ripeti il procedimento M episodi.
19",deep learning step principali ricava values rete ogni azione dando input stato corrente screenshot seleziona azione epsilon greedy policy cio random probabilit epsilon altrimenti lazione value massimo valuta lazione genera nuovo stato ricava reward corrispondente stato corrisponde screen successivo transizione sars salvata replay buffer campiona casualmente batch transizioni replay buffer ricava loss corrispondente esegui gradient descent differenza target predicted impiegando rete parametri attuali minimizzando loss ogni iterazioni trasferisci parametri rete rete target ripeti procedimento episodi
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#19,19,"Deep Q-learning in Python: CartPole
# codice tratto da 
 https://github.com/mswang12/minDQN/blob/main/minDQN.py
import
 gym
import
 tensorflow 
 as
 tf
import
 numpy 
as
 np
from
 tensorflow 
 import
 keras
from
 collections 
 import
 deque
import
 time
import
 random
RANDOM_SEED = 
 5
tf.random.set_seed(RANDOM_SEED)
env = gym.make(
 'CartPole-v1'
 )
env.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
print
(
""Action Space: {}""
 .
format
(env.action_space))
print
(
""State space: {}""
 .
format
(env.observation_space))
# An episode a full game
train_episodes = 
 300
test_episodes = 
 100
...
20",deep learning python cart pole codice tratto nblobmainmin npy import gym import tensorflow import numpy tensorflow import keras collections import deque import time import random env gymmake cart pole envseedr print action space format print state space format episode full game trainepisodes testepisodes
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#2,2,"OpenAI GYM: Environments
La classe Env implementa il simulatore dell'ambiente in cui l'agente si 
muove.  
Alcuni esempi di environment disponibili in Gym: 
import
 gym
env = gym.make(
 'MountainCar-v0'
 )
Esempio
 : nel MointainCar, un carrello deve incrementare l'inerzia per 
riuscire a passare la collina.
3
",open environments classe env implementa simulatore dellambiente lagente muove alcuni esempi environment disponibili gym import gym env gymmake mountain car esempio mointain car carrello deve incrementare linerzia riuscire passare collina
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#20,20,"Deep Q-learning in Python: CartPole
...
def 
agent
(
state_shape
 , 
action_shape
 ):
    # l'output è il Q-value stimato per ogni azione
    learning_rate = 
 0.001
    init = tf.keras.initializers.HeUniform()
    model = keras.Sequential()
    model.add(keras.layers.Dense(
 24
, input_shape=state_shape, activation=
 'relu'
, 
kernel_initializer=init))
    model.add(keras.layers.Dense(
 12
, activation=
 'relu'
, kernel_initializer=init))
    model.add(keras.layers.Dense(action_shape, activation=
 'linear'
 , 
kernel_initializer=init))
    model.
 compile
(loss=tf.keras.losses.Huber(), 
optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=[
 'accuracy'
 ])
    
return
 model
def 
get_qs
(
model
, 
state
, 
step
):
    
return
 model.predict(state.reshape([
 1
, state.shape[
 0
]]))[
0
]
...
21",deep learning python cart pole def agent stateshape actionshape loutput value stimato ogni azione learningrate init uniform model activation relu activation relu activation linear model compile metrics accuracy return model def getqs model state step return stateshape
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#21,21,"Deep Q-learning in Python: CartPole
...
def 
train
(
env
, 
replay_memory
 , 
model
, 
target_model
 , 
done
):
    learning_rate = 
 0.7 
# Learning rate
    discount_factor = 
 0.618
    MIN_REPLAY_SIZE = 
 1000
    
if 
len
(replay_memory) < MIN_REPLAY_SIZE:
        
 return
    batch_size = 
 64
 * 
2
    mini_batch = random.sample(replay_memory, batch_size)
    current_states = np.array([transition[
 0
] 
for
 transition 
 in
 mini_batch])
    current_qs_list = model.predict(current_states)
    new_current_states = np.array([transition[
 3
] 
for
 transition 
 in
 mini_batch])
    future_qs_list = target_model.predict(new_current_states)
    X = []
    Y = []
...
22",deep learning python cart pole def train env replaymemory model targetmodel done learningrate learning rate discountfactor len replaymemory return batchsize minibatch batchsize currentstates transition minibatch currentqslist transition minibatch futureqslist
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#22,22,"Deep Q-learning in Python: CartPole
...
    
for
 index, (observation, action, reward, new_observation, done) 
 in 
                                       
 enumerate
 (mini_batch):
        
 if 
not
 done:
            max_future_q = reward + discount_factor * 
        np.
 max
(future_qs_list[index])
        
 else
:
            max_future_q = reward
        current_qs = current_qs_list[index]
        current_qs[action] = (
 1
 - learning_rate) * current_qs[action] + 
                 learning_rate * max_future_q
        X.append(observation)
        Y.append(current_qs)
    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=
 0
, 
        shuffle=
 True
)
 ...
23",deep learning python cart pole index observation action reward done enumerate minibatch done maxfutureq reward discountfactor max else maxfutureq reward currentqs learningrate learningrate maxfutureq nparrayy verbose shuffle true
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#23,23,"Deep Q-learning in Python: CartPole
...
def 
main
():
    epsilon = 
 1 
# inizializzato ad 1, cioè ogni azione è random
    max_epsilon = 
 1
    min_epsilon = 
 0.01 
# al valore minimo, 1% sarà ancora esplorazione
    decay = 
 0.01
    
# 1. Initializzazione Target e Main models
    
# Main Model (updated every 4 steps)
    model = agent(env.observation_space.shape, env.action_space.n)
    
# Target Model (updated every 100 steps)
    target_model = agent(env.observation_space.shape, env.action_space.n)
    target_model.set_weights(model.get_weights())
    replay_memory = deque(maxlen=
 50
_
000
)
    target_update_counter = 
 0
    
# X = states, y = actions
    X = []
    y = []
...
24",deep learning python cart pole def main epsilon inizializzato cio ogni azione random maxepsilon minepsilon valore minimo ancora esplorazione decay target main models main model updated every steps model target model updated every steps targetmodel replaymemory dequemaxlen states actions
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#24,24,"Deep Q-learning in Python: CartPole
...
    steps_to_update_target_model = 
 0
    
for
 episode 
 in 
range
(train_episodes):
        total_training_rewards = 
 0
        observation = env.reset()
        done = 
 False
        
 while 
not
 done:
            steps_to_update_target_model += 
 1
            
 if True:            # Su Colab può dare problemi
            
    env.render()
            random_number = np.random.rand()
            
 # 2. Esplora con Epsilon Greedy Exploration Strategy
            
 if
 random_number <= epsilon:
                
 # Explore
                action = env.action_space.sample()
            
 else
:
                
 # Exploit best known action
                
 # model dims are (batch, env.observation_space.n)
                encoded = observation
                encoded_reshaped = encoded.reshape([
 1
, encoded.shape[
 0
]])
                predicted = model.predict(encoded_reshaped).flatten()
                action = np.argmax(predicted)
            new_observation, reward, done, info = env.step(action)
            replay_memory.append([observation, action, reward, new_observation, done])
...
25",deep learning python cart pole episode range observation envreset done false done true colab pu dare problemi envrender randomnumber esplora epsilon greedy exploration strategy randomnumber epsilon explore action else exploit best known action model dims batch encoded observation encodedshape predicted action reward done info action reward done
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#25,25,"Deep Q-learning in Python: CartPole
...
           
 # 3. Aggiorna la rete con la Bellman Equation
            
 if
 steps_to_update_target_model % 
 4
 == 
0 
or
 done:
                train(env, replay_memory, model, target_model, done)
            observation = new_observation
            total_training_rewards += reward
            
 if
 done:
                
 print
(
'Total training rewards: {} after n steps = {} with final 
                      reward = {}'
 .
format
(total_training_rewards, episode, reward))
                total_training_rewards += 
 1
                
 if
 steps_to_update_target_model >= 
 100
:
                    
 print
(
'Copying main network weights to the target network 
                           weights'
 )
                    target_model.set_weights(model.get_weights())
                    steps_to_update_target_model = 
 0
                
 break
        epsilon = min_epsilon+(max_epsilon - min_epsilon)*np.exp(-decay * episode)
    env.close()
if
 __name__ == 
 '__main__'
 :
    main()
26",deep learning python cart pole aggiorna rete bellman equation done trainenv replaymemory model targetmodel done observation newobservation reward done print total training rewards steps final reward format episode reward print copying main network weights target network weights break epsilon decay episode envclose name main main
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#26,26,"Action Space: Discrete(2)
State space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)
Total training rewards: 19.0 after n steps = 0 with final reward = 1.0
...
Copying main network weights to the target network weights
Total training rewards: 184.0 after n steps = 291 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 152.0 after n steps = 292 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 47.0 after n steps = 293 with final reward = 1.0
Total training rewards: 20.0 after n steps = 294 with final reward = 1.0
Total training rewards: 121.0 after n steps = 295 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 10.0 after n steps = 296 with final reward = 1.0
Total training rewards: 124.0 after n steps = 297 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 272.0 after n steps = 298 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 41.0 after n steps = 299 with final reward = 1.0
Deep Q-learning in Python: CartPole
27",action space discrete state space box float total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward total training rewards steps final reward total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward copying main network weights target network weights total training rewards steps final reward deep learning python cart pole
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#27,27,"Deep Q-learning: Stable Baseline3
Stable Baselines3 (SB3) implementa algoritmi di RL in PyTorch.  
Possono essere impiegati in OpenAI GYM. 
Github repository: 
 https://github.com/DLR-RM/stable-baselines3  
La classe DQN implementa l'approccio descritto in precedenza 
https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html   
https://stable-baselines3.readthedocs.io/en/master/guide/examples.html  
28",deep learning stable baseline stable baselines implementa algoritmi torch possono essere impiegati open github repository mstable baselines classe implementa lapproccio descritto precedenza httpsstable httpsstable
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#28,28,"Deep Q-learning: Stable Baseline3
Algoritmi implementati:
29
",deep learning stable baseline algoritmi implementati
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#29,29,"Deep Q-learning: CartPole in GYM
# Anaconda: conda install -c conda-forge stable-baselines3 
!
pip install stable-baselines3[extra]
import
 gym
from
 stable_baselines3 
 import
 DQN
env = gym.make(
 ""CartPole-v0""
 )
model = DQN(
 ""MlpPolicy""
 , env, verbose=
 1
)
model.learn(total_timesteps=
 10000
, log_interval=
 4
)
model.save(
 ""dqn_cartpole""
 )
del
 model 
# remove to demonstrate saving and loading
model = DQN.load(
 ""dqn_cartpole""
 )
obs = env.reset()
while 
True
:
    action, _states = model.predict(obs, deterministic=
 True
)
    obs, reward, done, info = env.step(action)
    env.render()                 
 # Su colab può dare problemi
    
if
 done:
      obs = env.reset()
30",deep learning cart pole anaconda conda install conda forge stable baselines pip install stable import gym import env gymmake cart pole model mlp policy env verbose loginterval modelsave dqncartpole model remove demonstrate saving loading model qnload dqncartpole obs envreset true action states deterministic true obs reward done info envrender colab pu dare problemi done obs envreset
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#3,3,"OpenAI GYM: Environments
La variabile 
 observation_space
  deﬁnisce la struttura e gli stati permessi 
dell'ambiente.  
Per esempio, posizione  rispetto all'orgine e velocità del carrello 
CartPole, rappresentati come vettore numerico. 
Ma in casi più complessi è possibile fare un rendering dello stato (es. 
uno screenshot di un arcade) è impiegare una matrice di pixel come 
stato. 
La variabile 
 action_space
  consiste nelle azioni permesse nell'ambiente. 
Gym fornisce diverse strutture per rappresentare osservazioni e stati (es. 
discrete action space, continuous action space, ecc). 
4",open environments variabile denisce struttura stati permessi dellambiente esempio posizione rispetto allorgine velocit carrello cart pole rappresentati vettore numerico casi complessi possibile fare rendering stato screenshot arcade impiegare matrice pixel stato variabile actionspace consiste azioni permesse nellambiente gym fornisce diverse strutture rappresentare osservazioni stati discrete action space continuous action space ecc
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#30,30,"Deep Q-learning: CartPole in GYM
L'output dipende dall'approccio RL scelto, es. per agenti PPO - Proximal 
Policy Optimization algorithm che combina il A2C multiple workers, e 
TRPO:
31
",deep learning cart pole loutput dipende dallapproccio scelto agenti proximal policy optimization algorithm combina multiple workers
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#31,31,"Deep Q-learning: CartPole in GYM
32
",deep learning cart pole
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#32,32,"Deep Q-learning: CartPole in GYM
33
",deep learning cart pole
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#33,33,"Deep Q-learning: CartPole in GYM
34
",deep learning cart pole
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#34,34,"Esercitazione
Deﬁnisci una misura di prestazioni per confrontare diverse approcci RL 
Impiega la classe Deep Q Network (DQN) 
Sperimenta diversi iperparametri e valuta le differenze: 
learning_rate 
exploration_initial_eps  e  exploration_ﬁnal_eps 
buffer_size 
batch_size 
gamma 
train_freq 
Usa altri ambienti, es: Atlantis-v0, MountainCar-v0, o ambienti Atari.
35",esercitazione denisci misura prestazioni confrontare diverse approcci impiega classe deep network sperimenta diversi iperparametri valuta differenze learningrate buffersize batchsize gamma trainfreq usa altri ambienti atlantis mountain car ambienti atari
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#35,35,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
36",open gym testi riferimento
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#4,4,"OpenAI GYM
Come ispezionare l'ambiente. 
import
 gym
def 
query_environment
 (
name
):
    env = gym.make(name)
    spec = gym.spec(name)
    
print
(
f
""Action Space: 
 {env.action_space}
 ""
)
    
print
(
f
""Observation Space: 
 {env.observation_space}
 ""
)
    
print
(
f
""Max Episode Steps: 
 {spec.max_episode_steps}
 ""
)
    
print
(
f
""Nondeterministic: 
 {spec.nondeterministic}
 ""
)
    
print
(
f
""Reward Range: 
 {env.reward_range}
 ""
)
    
print
(
f
""Reward Threshold: 
 {spec.reward_threshold}
 ""
)
query_environment(
 ""MountainCar-v0""
 )
3 azioni: Accelerate forward, decelerate, backward
>> Action Space: Discrete(3)
2 ﬂoat: velocità e posizione; (2,) indica la struttura del dato
>> Observation Space: 
                 Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)
200 step disponibili
>> Max Episode Steps: 200
>> Nondeterministic: False
Per il reward occorre ispezionare il codice (i.e., nessun reward tranne quando il carrello riesce ad uscire)
>> Reward Range: (-inf, inf)
>> Reward Threshold: -110.0
5",open ispezionare lambiente import gym def name env gymmakename spec gymspecname print action space print observation space print max episode steps print print reward range print reward threshold mountain car azioni accelerate forward decelerate backward action space discrete oat velocit posizione indica struttura dato observation space box float step disponibili max episode steps false reward occorre ispezionare codice nessun reward tranne quando carrello riesce uscire reward range inf inf reward threshold
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#5,5,"OpenAI GYM
query_environment(
 ""CartPole-v1""
 )
2 valori: spingi a sinistra, spingi a destra
>> Action Space: Discrete(2)
4 valori: Cart Position, Cart Velocity, Pole Angle, Pole Velocity At Tip
>> Observation Space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), 
float32)
>> Max Episode Steps: 500
>> Nondeterministic: False
reward +1 per ogni step, e termino quando il palo cade, o se mi sposto di >2.4 unità dal centro
>> Reward Range: (-inf, inf)
>> Reward Threshold: 475.0
query_environment(
 ""MountainCarContinuous-v0""
 )
1 valore: quanta forza imprimere (a sinistra o destra)
>> Action Space: Box(-1.0, 1.0, (1,), float32)
>> Observation Space: Box(-1.2000000476837158, 0.6000000238418579, (2,), 
float32)
>> Max Episode Steps: 999
>> Nondeterministic: False
>> Reward Range: (-inf, inf)
>> Reward Threshold: 90.0
6",open cart pole valori spingi sinistra spingi destra action space discrete valori cart position cart velocity pole angle pole velocity tip observation space box float max episode steps false reward ogni step termino quando palo cade sposto unit centro reward range inf inf reward threshold mountain car continuous valore forza imprimere sinistra destra action space box float observation space box float max episode steps false reward range inf inf reward threshold
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#6,6,"OpenAI GYM
Nell'ambiente Atari breakout, l'observation space può corrispondere alle 
dimensioni dell screen (210x160) o alla RAM dell'elaboratore (128 bytes). 
query_environment(
 ""Breakout-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (210, 160, 3), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
query_environment(
 ""Breakout-ram-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (128,), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
7
",open nellambiente atari breakout lobservation space pu corrispondere dimensioni screen bytes breakout action space discrete observation space box uint max episode steps false reward range inf inf reward threshold none breakout ram action space discrete observation space box uint max episode steps false reward range inf inf reward threshold none
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#7,7,"OpenAI GYM: Environments
Come applicare un'azione sull'ambiente. 
# reset 
obs = env.reset()
print
(
""The initial observation is {}""
 .
format
(obs))
random_action = env.action_space.sample()
# Applichiamo l'azione all'ambiente
new_obs, reward, done, info = env.step(random_action)
print
(
""The new observation is {}""
 .
format
(new_obs))
>> OUTPUT:
>> 
The initial observation 
 is
 [
-0.48235664   
0
.]
>> 
The new observation 
 is
 [
-0.48366517  
-0.00130853
 ]
8",open environments applicare unazione sullambiente reset obs envreset print the initial observation format obs randomaction applichiamo lazione allambiente newobs reward done info print the new observation format newobs initial observation new observation
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#8,8,"OpenAI GYM: Environments
Per visualizzare lo stato a video su Colab inserire il seguente codice: 
# vedi 
https://github.com/ryanrudes/colabgymrender  
!
pip install gym pyvirtualdisplay > /dev/null 
 2
>&
1
!
apt-get install -y xvfb python-opengl ffmpeg > /dev/null 
 2
>&
1
!
pip install colabgymrender==
 1.0.2
import
 gym
from
 colabgymrender.recorder 
 import
 Recorder
env = gym.make(
 ""MountainCar-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
observation = env.reset()
terminal = 
 False
while 
not
 terminal:
# Azione random
  action = env.action_space.sample()
  observation, reward, terminal, info = env.step(action)
env.play()
9
",open environments visualizzare stato video colab inserire seguente codice vedi pip install gym devnull apt get install xvfb python opengl ffmpeg devnull pip install import gym import recorder env gymmake mountain car directory video env recorderenv directory observation envreset terminal false terminal azione random action observation reward terminal info envplay
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#9,9,"OpenAI GYM: Environments
...
env = gym.make(
 ""Atlantis-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
10
",open environments env gymmake atlantis directory video env recorderenv directory
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Introduzione al Deep Learning  
(Ex 18/19)
1",machine learning universit roma tre dipartimento ingegneria anno accademico esercitazione introduzione deep learning
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#1,1,"Sommario
Introduzione 
Il concetto di Deep Learning 
Esempi di applicazioni 
Translational simmetry 
Convolutional Neural network 
•
Convolutional layer 
•
Local receptive ﬁeld 
•
Stride e Padding 
•
Filters e Feature Maps 
•
Pooling Layer 
Architettura LeNet-5 
Architettura AlexNet 
Architettura GoogleNet e Inception Module 
Architettura Residual Network (ResNet)",sommario introduzione concetto deep learning esempi applicazioni translational simmetry convolutional neural network convolutional layer local receptive eld stride padding filters feature maps pooling layer architettura net architettura alex net architettura google net inception module architettura residual network res net
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#10,10,"Esercizio
Realizzo un classiﬁcatore binario che mi identiﬁca se in una 
porzione di immagine c’è un pedone. 
Scorro l’immagine per trovare una porzione con un pedone  
 
        
11
",esercizio realizzo classicatore binario identica porzione immagine c pedone scorro limmagine trovare porzione pedone
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#11,11,"Object recognition
Yolo https://pjreddie.com/darknet/yolov2/ 
https://www.youtube.com/watch?v=VOC3huqHrss 
",object recognition yolo ochuq hrss
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#12,12,"Pose estimation
Zhe Cao , Tomas Simon, Shih-En Wei, Yaser Sheikh   
https://www.youtube.com/watch?v=pW6nZXeWlGM 
",pose estimation zhe cao tomas simon shih wei yaser sheikh zxe
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#13,13,"Object Tracking
 Beijing DeepGlint  https://www.youtube.com/watch?v=xhp47v5OBXQ  
",object tracking beijing deep glint
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#14,14,"Activity Recognition
 MIT CS & AI Lab http://relation.csail.mit.edu
https://www.youtube.com/watch?v=JBwSk6nJOyM 
",activity recognition lab skn joy
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#15,15,"Tesla Self Driving Demo 2016
Tesla   https://www.youtube.com/watch?v=VG68SKoG7vE 
",tesla self driving demo tesla sko
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#16,16,"Introduzione
Alcune soﬁsticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come: 
•
Riconoscere un giocattolo in una immagine 
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speciﬁche.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture. 
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identiﬁcarlo. 
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
17",introduzione alcune sosticate architetture riuscite ottenere performance superiori umane gioco scacchi deep blue solo intorno ottenute buone performance task apparentemente semplici come riconoscere giocattolo immagine speech recognition riconoscimento vocale task semplici levoluzione portato cervello costruire strutture funzioni speciche quando informazioni arrivano parti deputate ragionamento alto livello gi arricchite features alto livello elaborate strutture sebbene coscienti esiste giocattolo sappiamo spiegare processo seguito identicarlo architetture convolutional neural networks state sviluppate anni base studi zona corteccia deputata riconoscimento visivo ultime decadi diffuse grazie presenza
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#17,17,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive ﬁeld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale. 
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
conﬁgurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"". 
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi
 . 
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
18",larchitettura visual cortex anni hubel wiesel dimostrato molti neuroni parte corteccia deputata riconoscimento immagini possiedono piccolo local receptive eld cio possono reagire stimoli situati regioni limitate campo visuale sebbene condividano alcuni neuroni attivano solo presenza linee orizzontali altri solo verticali alcuni neuroni estesi attivano presenza certe congurazioni caratteristiche basso livello pu desumere lattivazione neuroni alto livello basata sulloutput neuroni basso livello ritenuti vicini aumentando complessit ripetendo volte cascata passi riportati possiamo riconoscere patterns visuali molto complessi nota resto lezione suppone considerare immagini istanze input tecnologie introdotte possono essere usate altri input
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#18,18,"L'architettura della Visual cortex
19
Secondo te è una MLP?Ad ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds",larchitettura visual cortex secondo lpad ogni livello saliamo astrazione pattern individuati local receptive elds
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#19,19,"L'architettura della Visual cortex
20
È simile a una MLP , 
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds",larchitettura visual cortex simile ogni nodo connesso solo piccolo insieme neuroni vicini ogni livello saliamo astrazione pattern individuati local receptive elds
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#2,2,"Deep Learning - Cos’è?
Invece di una singola rete con molti parametri da individuare 
tutti insieme, si suddividono le elaborazione in più moduli 
distinti a cascata. 
Sviluppato negli anni ’80 (Geoff Hinton, Yann Lecun, Yoshua 
Bengio, Jürgen Schmidhuber) ispirandosi ai risultati sulla 
cognizione umana. 
Ma al tempo non c’erano le infrastrutture hardware e software 
adatte (GPU-enabled). 
Utile in scenari con grosse moli di dati complessi. 
Uno degli obiettivi è ignorare la (noiosa) fase di deﬁnizione di 
feature ad-hoc per lo speciﬁco problema da esaminare e lasciare 
alle reti neurali identiﬁcare le features più adatte.
3",deep learning cos invece singola rete molti parametri individuare insieme suddividono elaborazione moduli distinti cascata sviluppato anni geoff hinton yann lecun yoshua bengio jrgen schmidhuber ispirandosi risultati cognizione umana tempo cerano infrastrutture hardware software adatte enabled utile scenari grosse moli dati complessi obiettivi ignorare noiosa fase denizione feature hoc specico problema esaminare lasciare reti neurali identicare features adatte
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#20,20,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
21",fully connected usiamo riconoscere oggetti
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#21,21,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra 
notevolmente le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
22",fully connected usiamo riconoscere oggetti causa dell elevato numero parametri stimare supponiamo avere input piccola immagine pixel creiamo primo layer appena nodi perci ltra notevolmente informazioni passata successivi layer primo strato gi milioni parametri stimare
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#22,22,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra notevolmente 
le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare. 
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo task
 , es. 
riconoscere linee orizzontali. 
•
I neuroni specializzati sono attivati se il pattern da identiﬁcare è localizzato in 
una certa zona.  
•
Ma vorremmo poter identiﬁcare lo stesso pattern indipendentemente da dove 
compare. 
Con 
translational symmetry
  intendiamo che lo stesso output deve essere 
prodotto anche a seguito di operazioni di traslazione sulla istanza in input. 
23",fully connected usiamo riconoscere oggetti causa dell elevato numero parametri stimare supponiamo avere input piccola immagine pixel creiamo primo layer appena nodi perci ltra notevolmente informazioni passata successivi layer primo strato gi milioni parametri stimare supponiamo certi nodi primo strato specializzino certo task riconoscere linee orizzontali neuroni specializzati attivati pattern identicare localizzato certa zona vorremmo poter identicare stesso pattern compare translational symmetry intendiamo stesso output deve essere prodotto seguito operazioni traslazione istanza input
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#23,23,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
3. Le reti 
 MLP 
non riescono a codiﬁcare esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identiﬁcano 
features analizzando piccole aree dell'immagine. 
•
I neuroni ""ad alto livello"" combinano tali features per identiﬁcare features 
spazialmente più estese.
24",fully connected usiamo riconoscere oggetti reti riescono codicare esplicitamente spaziale features visual cortex neuroni strati vicini allinput identicano features analizzando piccole aree dellimmagine neuroni alto livello combinano tali features identicare features spazialmente estese
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#24,24,"Esempi di 
 translational simmetry
25
Nel task a lato, per addestrare una MLP dovremmo avere 
un training set con: 
•stessa specie animale che compare in varie 
posizioni, angolazioni e dimensioni. 
•specie visualizzate parzialmente (es. sul bordo). 
•casi di overlap tra specie diverse di animali",esempi translational simmetry task lato addestrare dovremmo avere training set con stessa specie animale compare varie posizioni angolazioni dimensioni specie visualizzate parzialmente bordo casi overlap specie diverse animali
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#25,25,"Ulteriore considerazione: 
 sparsity
26Per riconoscere certe caratteristiche speciﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata. Non c'è bisogno di considerare l'intera immagine iniziale. 
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  ",ulteriore considerazione sparsity riconoscere certe caratteristiche speciche analizziamo informazioni locali ravvicinate cio distanza relativa limitata bisogno considerare lintera immagine iniziale output associato certa feature occhio naso associato solo certo numero pixel input
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#26,26,"Convolutional NN
Le architetture 
 Convolutional NN (CNN)
  consistono in varie tecniche 
ispirate al funzionalmente del cervello.  
Il blocco più importante è il 
 convolutional layer
  così costituito: 
•
I nodi nel primo layer 
 non sono connessi con tutti i pixel
  dell'immagine in 
input, ma 
 solo in una regione
  (es. un rettangolo). Tale regione è chiamata 
Local receptive ﬁeld (LRF)
 . 
•
Questo permette alla rete di 
 specializzarsi
  su caratteristiche a basso 
livello che saranno poi elaborate in caratteristiche a più alto livello nei 
successivi hidden layer. 
•
Una rete CNN è 
 gerarchica
 , con più convolutional layer nascosti che 
individuano via via caratteristiche più astratte.
27",convolutional architetture convolutional consistono varie tecniche ispirate funzionalmente cervello blocco importante convolutional layer cos costituito nodi primo layer connessi pixel dellimmagine input solo regione rettangolo tale regione chiamata local receptive eld permette rete specializzarsi caratteristiche basso livello poi elaborate caratteristiche alto livello successivi hidden layer rete gerarchica convolutional layer nascosti individuano via via caratteristiche astratte
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#27,27,"CNN - Convolutional layer e LRF
28
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input: 
immagine 25x25 pixel
in bianco e neroOutput dopo il primo  
layer convolutivo.local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato 
da una certa posizione del 
LRF che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione",convolutional layer nodo input successivo hidden layer esempio input immagine pixel bianco nero output dopo primo layer receptive eld ogni nodo attivato base allinput determinato certa posizione scorre lungo linputinput convolutional layer notiamo riduzione dimensione rispetto attivazioni elaborazione
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#28,28,"CNN - Struttura gerarchica
29Input layer: 
È un layer costituito da unità 
a cui viene associato il valore 
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerDato una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota: Nelle tradizionali MLP, input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori, ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN tale ridimensionamento è controproducente poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell'input layer le features 
corrispondono ai singoli pixel",struttura gerarchica input layer layer costituito unit viene associato valore singoli pixel dellimmagine reale convolutional layer secondo convolutional layer dato instanza input nodi vicini convolutional layer layer attivati base features estratte certa zona dellinput astrazione features nota tradizionali input bidimensionali immagini bianco nero comunemente ridimensionati vettori ovvero matrici dimensioni tale poich perderebbe linformazione relativa vicinanza features input struttura gerarchica nellinput layer features corrispondono singoli pixel
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#29,29,"CNN - LRF
30Output layer precedente•In un certo layer convoluzionale, un nodo con indice (i, j) prende in input gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF va dalla riga i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e f w corrispondono all'altezza e larghezza del LRF. 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni.forward propagation
Esempio con LRF 3x3 
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding 
(discusso più avanti)",output layer precedentein certo layer convoluzionale nodo indice prende input output nodi layer precedente posizionati allinterno la regione riga riga colonna colonna fh corrispondono allaltezza larghezza indici scorrono dim dim convolutional layer rappresentato griglia bidimensionale contiene risultato propagation esempio stride pari padding padding dim dimy padding discusso avanti
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#3,3,"Deep Learning - Cos’è? (2)
In estrema sintesi: 
Si compongono più strutture di reti neurali in cascata il cui 
scopo è analizzare l’input ed estrarre ad ogni passo un 
insieme di features (in automatico). 
L’output di una rete neurale è l’input della successiva. 
Tipicamente l’input iniziale è low-level (es. gruppi di pixel di 
una immagine) e ogni rete genera rappresentazioni più ad 
alto livello (es. contorno viso, bocca, bocca sorridente etc.). 
Le elaborazioni degli strati intermedi sono tipicamente 
unsupervised.
4",deep learning cos estrema sintesi compongono strutture reti neurali cascata scopo analizzare linput estrarre ogni passo insieme features automatico loutput rete neurale linput successiva tipicamente linput iniziale low level gruppi pixel immagine ogni rete genera alto livello contorno viso bocca bocca sorridente etc elaborazioni strati intermedi tipicamente unsupervised
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#30,30,"CNN - Stride
31•La distanza s tra due LRF adiacenti è chiamata stride. 
•Finora abbiamo visto stride di 1 pixel, ma la LRF può scorrere di più pixel. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3 
Stride = 2",stride la distanza due adiacenti chiamata stride finora visto stride pixel pu scorrere pixel output layer precedente layer convoluzionale padding padding stride
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#31,31,"CNN: Padding
32•Supponendo stride > 1, può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input. 
•Il padding aggiunge dimensioni ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding). Si hanno i seguenti vantaggi:
•Permettere alla LRF di scorrere per intero l'immagine in input senza ignorarne delle parti.
•Un LRF potrebbe ""imparare"" a riconosce una certa feature quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo, senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding",padding supponendo stride pu accadere convolutional layer comunque ridotto causa dimensioni layer precedente poich pu scorrere lintera instanza input il padding aggiunge dimensioni dati input normalmente dati inseriti valori nulli padding seguenti vantaggi permettere scorrere intero limmagine input senza ignorarne parti un potrebbe imparare riconosce certa feature quando centrata nellimmagine feature posizionata molto vicino bordo senza padding potrebbe essere ignorata padding output layer precedente senza padding output layer precedente padding
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#32,32,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la ﬁnestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della ﬁnestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF",esempio attivazione nodo lattivazione nodo layer convoluzionale ottiene analizzando loutput layer precedente mezzo esempio funzione dattivazione nodo valuta considerando bias matrice dimensione associati caso pari parametri determinare offset riferiti nestra scorre passo volta allora riferimento allorigine nestra ijlk
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#33,33,"CNN: Riduzione dimensionalità e Stride
34Output layer precedente•La presenza di stride > 1 altera gli indici iniziali e ﬁnali che identiﬁcato il LRF associato ad 
un certo nodo. 
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista.
•Stride > 1 riducono la dimensione del layer convoluzionale a scapito della precisione.
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3 
Stride = 2",riduzione dimensionalit stride output layer precedentela presenza stride altera indici iniziali nali identicato associato certo nodo lattivazione nodo posizione certo layer determinato output nodi layer precedente posizionati righe colonne per pari torna formulazione gi vista stride riducono dimensione layer convoluzionale scapito precisione layer convoluzionale padding padding stride verticale stride orizzontale stride
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#34,34,"CNN: Filters
35Filters•Supponiamo di poter rappresentare graﬁcamente i pesi associati a un certo nodo, usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters o convolution kernels  
(o kernels )
•Ad esempio, una LRF 7 7 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input",filters poter rappresentare gracamente pesi associati certo nodo usati calcolo attivazione tali pesi prendono nome lters convolution kernels kernels ad esempio corrisponder ltro medesime dimensioni nellesempio due ltri vertical lter horizontal lter entrambi matrice tutta tranne colonna riga input
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#35,35,"Esempi di ﬁltri e attivazioni (1)
36Esempio di input 
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo.
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni",esempi ltri attivazioni esempio input immagine pixel output dopo primo layer convolutivo immagine input immagine input output output filtro filtro attivazioni attivazioni
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#36,36,"Esempi di ﬁltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro",esempi ltri attivazioni ltro ltro
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#37,37,"CNN: Feature Maps
38Filters•Le LRF scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione. Tale approccio prende il nome di shared weights. 
•L'insieme delle attivazioni ottenute con lo stesso ﬁltro viene chiamato feature map. Esse 
possono essere visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map dove le zone dell'input simili a una 
linea verticale sono più evidenziate (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate. Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input",feature maps filtersle scorrono immagine input supponiamo mantenere costante valori ltro usato calcolo tale approccio prende nome shared weights linsieme attivazioni ottenute stesso ltro viene chiamato feature map esse possono essere visualizzate immagine nellesempio nota vertical lter crea feature map zone dellinput simili linea verticale evidenziate cio attivazione mentre zone meno simili scure sfocate discorso duale ltro horizontal lterfeature maps input
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#38,38,"CNN: Stacking feature maps
In 
ogni layer
  possiamo contemplare 
 più ﬁltri con le medesime dimensioni
 . 
Ogni ﬁltro produrrà una diversa feature map. Ogni layer sarà così costituito 
da una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i ﬁltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di: 
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP. 
•
Durante la backpropagation, adattare ogni ﬁltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso ﬁltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
39",stacking feature maps ogni layer possiamo contemplare ltri medesime dimensioni ogni ltro produrr diversa feature map ogni layer cos costituito sequenza matrici attivazioni perci struttura durante forward propagation fondamentale ltri cio parametri pesi bias costituiscono layer convoluzionale rimangano costanti sebbene valore attivazioni ovvero feature map cambiano base posizione permette avere numero molto minore parametri stimare rispetto layer durante adattare ogni ltro particolare caratteristica saliente possibilit usare stesso ltro diverse zone dellimmagine garantisce translational simmetry cio possiamo riconoscere caratteristica diverse posizioni rete fully connected potrebbe riconoscere caratteristica posizione stimando certi parametri grado riutilizzarli altre posizioni
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#39,39,"CNN: Feature Maps
40...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB.Possiamo deﬁnire un certo numero di ﬁltri (es. 12) per riconoscere diverse caratteristiche salienti dell'immagine iniziale. I ﬁltri analizzano contemporaneamente 3 canali RGB, perciò i ﬁltri saranno deﬁniti con matrici a 3 dimensioni. Un ﬁltro applicato all'immagine in input produce un singolo convolutional layer.I successivi layer convoluzionali analizzato le attivazioni di più ﬁltri contemporaneamente. I ﬁltri di questo layer riconosceranno caratteristiche più astratte.depth = 3 depth = 12 depth = 7",feature maps input convolutional layer convolutional layer immagine colori matrici associate canali gbpossiamo denire certo numero ltri riconoscere diverse caratteristiche salienti dellimmagine iniziale ltri analizzano canali perci ltri deniti matrici dimensioni ltro applicato allimmagine input produce singolo convolutional layeri successivi layer convoluzionali analizzato attivazioni ltri ltri layer riconosceranno caratteristiche astrattedepth depth depth
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#4,4,"Deep Learning - Principali vantaggi
Rispetto ad altri approcci: 
Si può sviluppare un unico framework computazionale che 
può essere implementato ed eseguito su varie piattaforme 
hardware e cloud. 
Il framework offre funzionalità valide per molte architetture di 
reti e tasks (es. natural language processing, computer vision, 
speech recognition, etc.) 
Si possono condividere e riutilizzare i parametri ottenuti 
durante l’apprendimento per uno speciﬁco task in altri 
contesti.
5",deep learning principali vantaggi rispetto altri approcci pu sviluppare unico framework computazionale pu essere implementato eseguito varie piattaforme hardware cloud framework offre funzionalit valide molte architetture reti tasks natural language processing computer vision speech recognition etc possono condividere riutilizzare parametri ottenuti durante lapprendimento specico task altri contesti
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#40,40,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori: 
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
4101234567891011121300 12345678910111213
senza padding ('VALID') con padding ('SAME')ignorati
stride=5padding P=+3",tensor flow padding tensor flow fornisce parametro padding pu assumere due valori caso voglia ignorare padding aggiungere automaticamente righe colonne composte valori modo bilanciato garantire scorra lintera matrice input senza padding padding eignorati stridepadding
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#41,41,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di ﬁltri per layer (o 
 depth
 ) 
Dimensione del LRF 
Stride e padding 
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una conﬁgurazione 
verosimilmente già ottimizzata.
42",tuning rispetto molti iperparametri stimare numero ltri layer depth dimensione stride padding invece usare tecniche automatiche tuning ispira architetture gi studiate letteratura avere congurazione verosimilmente gi ottimizzata
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#42,42,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con ﬁltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200 
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile. 
•
Con ﬂoat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
43",risorse memoria considerazioni backpropagation richiede memorizzare valor intermedi calcolati durante forward propagation esempio convolutional layer ltri feature maps dimensione stride padding input immagini numero parametri layer completamente connesso layer input richiederebbe parametri ognuna mappe contiene nodi ogni nodo ricava lattivazione valutando input corrispondono milioni moltiplicazioni virgola mobile oat bit layer output impiega circa ogni istanza istanze layer occuperebbe produzione attivazioni layer possono essere dimenticate appena calcoli layer successivo terminati richiedendo molta meno memoria cio massimo layer
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#43,43,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti: 
•
Meno complessità computazione 
•
Meno risorse di memoria 
•
Meno parametri (e ridurre l'overﬁtting come effetto collaterale) 
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF. 
•
Occorre deﬁnire dimensione, stride e padding 
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
44",pooling layer layer pooling scopo ridurre numero parametri operando campionamento sampling dati vantaggi seguenti meno complessit computazione meno risorse memoria meno parametri ridurre lovertting effetto collaterale convolutional layer ogni nodo connesso numero limitato nodi layer precedente posizionati certo occorre denire dimensione stride padding pooling layer parametri opera semplicemente aggregazione valori associati nodi esempio calcolando media valore massimo spesso calcolo fatto ogni canale input cio singolo strato volta rispetto allintera profondit layer precedente canale separatamente profondit numero layer uscita corrisponder ingresso
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#44,44,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁeld (
 pooling size
 ), il 
pooling stride
 , e tipo di aggregazione. 
•
Spesso pooling size e stride corrispondono. 
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identiﬁcata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche. 
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta. 
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel ﬁeld considerato. 
•
average pooling:
  considero il valor medio nel ﬁeld.
45",pooling layer parametri inferire solo iperparametri cio dimensione eld pooling size pooling stride tipo aggregazione spesso pooling size stride corrispondono molti scenari fondamentale posizione esatta certa caratteristica fatto esista certa zona identicata certa sequenza pattern features senza considerare esattamente rispettive distanze reciproche esempio face detection interesse riconoscere due occhi vicini interessa distanza esatta esistono due tipi principali aggregazione max pooling nodo assume lattivazione massima valori presenti eld considerato average pooling considero valor medio eld
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#45,45,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max. 
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
46
A causa del padding VALID 
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  f po è il pooling size, s po il pooling stride,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1",esempio pooling layer nellesempio pooling kernel stride pari padding aggregazione max layer output contiene meno valori layer precedente causa padding valore alcuni nodi ignorato input canale layer pooling size pooling stride dimensione layer output nfpo spo
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#46,46,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri. 
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente: 
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×",convolutional layer dimensione output dimensione delloutput convolutional layer ricava partire dimensione dellinput valore iperparametri semplicit assumiamo input dimensione stride righe colonne aggiunte padding allora due dimensione layer output seguente dimensione output perci corrisponde
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#47,47,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classiﬁcazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden: 
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID 
•Numero ﬁltri (o depth) = 96 
•L’output per ogni ﬁltro avrà dimensione di lato (227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 =290.400 nodi. 
•L'attivazione di un nodo si ricava considerando 11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri. 
•Per la proprietà degli shared weights, nella CNN il numero di parametri sarà 11x11x3x96 + 96 = 34.944. × ×
×
×
feature mapscomputazione",alex net prime architetture reti neurali combina nellambito classicazione oggetti esempio calcolo parametri alex netoutput depth input depth ricordiamoci local receptive eld profondit pari dellinput esempi calcolo parametri primo layer hidden dim immagine input dim stride padding numero ltri depth loutput ogni ltro dimensione lato cio ltro considerando profondit nodi lattivazione nodo ricava considerando nodi layer precedente in parametri per propriet shared weights numero parametri xxx feature
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#48,48,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST. 
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identiﬁcate dalle CNN 
per fare classiﬁcazione per mezzo della MLP. 
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni.",architettura net net prime architetture stata ideata fare garantendo errore combina layers rete tradizionale valle scopo impiegare caratteristiche salienti identicate fare classicazione mezzo rete interamente fully connected richiesto molti parametri ottenere prestazioni
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#49,49,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/ ",demo net
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#5,5,"DeepMind e Atari Breakout
Google Deepminds https://deepmind.com 
https://www.youtube.com/watch?v=eG1Ed8PTJ18 ",deep mind atari breakout google deepminds
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#50,50,"Architettura LeNet-5
convolutional layer#1 conv. layer
feature maps:  
28x28, depth 6#3 conv. layer 
feature maps: 
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling layer
feature maps: 
14x14, depth 6#4 pooling layer
feature maps: 
5x5, depth 16
conv. layer#6 fully connected layer 
nodi 84#5 conv. layer 
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer 
nodi 10
La conﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding.",architettura net convolutional layer conv layer feature maps depth conv layer feature maps depth avg poolingconv layeravg pooling pooling layer feature maps depth pooling layer feature maps depth conv layer fully connected layer nodi conv layer feature maps depth immagini gray scalel loutput dellultimo convolution layer convertito vettore adatto input fully connected layer ancora stata approfondita tempi net impiegata tradizionale tanh fully connected layer nodi congurazione iperparametri dimensione dellinput necessita impiegare padding
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#51,51,"LeNet-5 in Keras
Con Keras l'implementazione di LeNet-5 per il dataset MNIST è rapida poiché i 
layer di pooling e di convoluzione sono già fatti:  
model = keras.Sequential()
model.add(layers.Conv2D(filters=
 6
, kernel_size=(
 3
, 
3
), activation=
 'relu'
, 
                     input_shape=(
 32
,
32
,
1
)))
model.add(layers.AveragePooling2D())
model.add(layers.Conv2D(filters=
 16
, kernel_size=(
 3
, 
3
), activation=
 'relu'
))
model.add(layers.AveragePooling2D())
# cambio il formato da matrice a vettore
model.add(layers.Flatten())
# layer fully connected o denso
model.add(layers.Dense(units=
 120
, activation=
 'relu'
))
model.add(layers.Dense(units=
 84
, activation=
 'relu'
))
model.add(layers.Dense(units=
 10
, activation = 
 'softmax'
 ))",net keras keras net dataset rapida poich layer pooling convoluzione gi fatti model dfilters kernelsize activation relu inputshape pooling dfilters kernelsize activation relu pooling cambio formato matrice vettore layer fully connected denso activation relu activation relu activation softmax
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#52,52,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
53",esercizio memoria sufciente rete quali cose puoi fare risolvere problema
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#53,53,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 .
54",esercizio memoria sufciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#54,54,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
55",esercizio memoria sufciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#55,55,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
56",esercizio memoria sufciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#56,56,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32.
57",esercizio memoria sufciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer usare oat bit invece
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#57,57,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32. 
5.
Distribuire la computazione
  su più elaboratori.
58",esercizio memoria sufciente rete quali cose puoi fare risolvere problema ridurre dimensione mini batch ridurre dimensionalit rete esempio stride layers pooling layers convolutional layer riduce dimensione layer precedente differena pooling layer introduce ulteriori parametri apprendere cambiare larchitettura rimuovendo layer usare oat bit invece distribuire computazione elaboratori
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#58,58,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%).  
E' molto simile a 
 LeNet-5
  ma con più profondità, con stacking dei pooling layer 
uno dopo l'altro (senza strato di pooling). 
•
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer. 
Impiega ReLI, SGD e 
momentum. 
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 gpu)",architettura alex net architettura vincitrice challenge object detection top error secondo ottenuto molto simile net profondit stacking pooling layer dopo laltro senza strato pooling primo tentativo sfruttare piattaforme hardware enabled addestrare reti complesse dopo convolutional layers max pooling rete layer impiega momentum doppia pipeline dovuta allhardware impiegato laddestramento gpu
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#59,59,"Architettura AlexNet (2)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signiﬁcativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
",architettura alex net impiega dropout strati data augumentation layer impiega local response normalization nodo riceve attivazione signicativa inibiscono nodi stessa posizione altre feature maps lipotesi favorire competitivit specializzando ogni feature map caratteristiche distinte
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#6,6,"Robot Learns to Flip Pancakes
Petar Kormushev (IIT): https://www.youtube.com/watch?v=W_gxLKSsSIE 
",robot learns flip pancakes petar kormushev
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#60,60,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁltri negli strati iniziali. 
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
",alcune problematiche seguenti esempi riconosciamo cane posizione dimensione dellanimale molto diverse loro facile determinare giusta dimensione numero ltri strati iniziali nonostante tecnologie apprendimento introdotte architetture molto deep con molti strati pu sempre riproporsi vanishing gradient problem
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#61,61,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identiﬁcate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei ﬁltri
 . Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo. 
•
Si impiegano ﬁltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function. 
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 .",inception module google net inception module basa ipotesi combinare informazioni provenienti diverse pipeline processamento basate convolutional layer permetta estendere caratteristiche salienti identicate convolution layer parallelo ognuno diversa dimensione ltri output convolution layers combinati singola struttura consister nellinput layer successivo impiegano ltri dimensioni pari stride padding activation function pratica processa stesso input considerando dimensioni linception module stato impiegato prima volta google net
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#62,62,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempliﬁcare i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali. 
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5. 
•
Sperimentalmente si nota come gli inception module sono più 
efﬁcienti se usati negli higher layers. 
Inception module
",inception module linput dato convolution layers max pooling convolution comprimono profondit dellinput utili soprattutto semplicare dati input convoluzioni richiedono risorse computazionali combinazione possibilit rappresentare feature complesse rispetto singoli nota inception module efcienti usati higher layers inception module
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#63,63,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri. 
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module",architettura goog net larchitettura vincitrice object detection challenge raggiungendo top error principale caratteristica profondit layer considerando pooling layers inception module cascata dopo ogni inception module opera average pooling ridurre numero parametri sebbene profonda possiede parametri alex net milioni circa altre tecniche impiegate batch normalization image distortions msprop inception module
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#64,64,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classiﬁcazione 
 per mezzo di una softmax. 
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer. 
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati. 
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più efﬁciente il training e migliorare l’accuracy.
auxiliary classiﬁerauxiliary classiﬁer",architettura goog net output due inception module intermedi inception module valutato preliminarmente task classicazione mezzo softmax affrontare problema vanishing gradient problem dato generano gradienti addizionali hidden layer lontani dallultimo layer valore loss intermedia chiamato auxiliary loss durante training viene combinato linearmente scalato loss dellintera rete produzione test set vengono impiegati nota versioni google net introducono molti espedienti rendere efciente training migliorare laccuracy auxiliary classier
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#65,65,"GoogLeNet: esempio di ﬁltri
",goog net esempio ltri
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#66,66,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers. 
Una rete con tale profondità non potrebbe essere addestrata a causa del 
vanishing gradient problem. 
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice propagare segnali 
 su varie parti della rete. 
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
",architettura residual network res net res net stata presentata top consiste layers rete tale profondit potrebbe essere addestrata causa vanishing gradient problem introducono skip connections propagano loutput certo layer nellinput layer posizionato valle lipotesi rendere semplice propagare segnali varie parti rete fasi iniziali comportamento random obbliga parti rete comportarsi modo riproporre valori input rendendo veloce lapprendimento
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#67,67,"ResNet: Residual learning
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning
 . 
Dal punto di vista operativo, è sufﬁciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
",res net residual learning addestrare rete neurale pu essere interpretato approssimare funzione aggiungi valore alloutput rete allora rete obbligata modellare funzione tale approccio chiamato residual learning punto vista operativo sufciente combinare loutput layer loutput layer posizionato monte prima valutare funzione attivazione
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#68,68,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza. 
69
",architetture principali architetture immagini complessit numero operazioni richieste laddestramento accuratezza
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#7,7,"Chess Game
Stati possibili: ~1047
",chess game stati possibili
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#8,8,"Driverless cars
Stati possibili: ?Microsoft AirSim simulator 
https://www.youtube.com/watch?v=fv-oFP AqSZ4 
",driverless cars stati possibili microsoft air sim simulator
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#9,9,"Esercizio
Voglio sapere se c’è un pedone di fronte a me analizzando 
l’immagine di una camera dalla mia auto, come procedo? 
10
",esercizio voglio sapere c pedone fronte analizzando limmagine camera auto procedo
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Ridge Regression 
Cross Validation
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico ridge regression cross validation machine learning
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#1,1,"Sommario
Overﬁtting nella polynomial  regression 
Sintomi dell’Overﬁtting 
Funzione di Costo nella Ridge Regression 
Minimizzazione della Funzione di Costo 
Forma Chiusa 
Gradient Descent 
K-fold Cross Validation
 
2",sommario overtting polynomial regression sintomi dellovertting funzione costo ridge regression minimizzazione funzione costo forma chiusa gradient descent fold cross validation
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#10,10,"Overﬁtting e #input
 
11
Anche il numero di input inﬂuenza l’overﬁtting: 
1 input (e.g., sq.ft)  → per evitare l’overﬁtting servono 
osservazioni che sono molto “dense” sull’asse delle ascisse. 
Servono in sostanza osservazioni rappresentative di tutte le 
coppie (x, y), cosa  difﬁcile da ottenere.  
d input (e.g., sq.ft, #bagni, #camere-letto, anno di costruzione, 
ecc.) → è ancora  più difﬁcile avere molte osservazioni 
rappresentative delle coppie (x, y) .
AreaPrezzoy
x",overtting input numero input inuenza lovertting input sqft evitare lovertting servono osservazioni molto dense sullasse ascisse servono sostanza osservazioni rappresentative tutte coppie cosa difcile ottenere input sqft bagni camere letto anno costruzione ecc ancora difcile avere molte osservazioni rappresentative coppie area prezzoy
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#11,11,"Funzione di Costo 
nella Ridge Regression
 
12
L’idea alla base della Ridge Regression è quella di limitare 
il valore assoluto dei coefﬁcienti wi deﬁnendo come 
segue la funzione di costo totale (da minimizzare nella 
fase di training): 
costo_ridge  = misura del “ﬁt” + misura della grandezza dei coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la RSS. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. ",funzione costo ridge regression lidea base ridge regression limitare valore assoluto coefcienti denendo segue funzione costo totale minimizzare fase training costoridge misura t misura grandezza coefcienti misura t intendiamo funzione misura coefcienti possiamo denirla vari modi
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#12,12,"Misura dei Coefﬁcienti  
di Regressione
 
13
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2",misura coefcienti regressione somma valori somma valori assoluti norm somma quadrati quadrato norm wwww jwjkwk w jkwk
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#13,13,"Funzione di Costo 
nella Ridge Regression
 
14
La Ridge Regression usa la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta il costo totale nella Ridge è 
dunque la seguente:    
dove il parametro λ (tuning parameter ) serve per 
bilanciare i due termini.                                              costo ridge(w)=R S S ( w)+",funzione costo ridge regression ridge regression usa somma quadrati regularization funzione rappresenta costo totale ridge dunque seguente parametro tuning parameter serve bilanciare due termini costo ridgewr
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#14,14," 
15Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵ = 0 
Se 0 < λ < ∞: 
Funzione di Costo 
nella Ridge Regression
0kˆwk2
2kˆwLSk2
2",vediamo cosa accade fronte diversi valori parametro riconduciamo vecchia soluzione ossia minimizzazione dell soluzioni costo totale lunica soluzione minimizzare costo funzione costo ridge regression kwk kw lsk
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#15,15,"Bias-Variance tradeoff
 
16
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., standard least squares ﬁt 
per polinomi di grado elevato) ",bias variance tradeoff parametro elevato high bias low variance parametro piccolo low bias high variance standard least squares polinomi grado elevato
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#16,16,"Esempio di polynomial ﬁt 
rivisitato
 
17
Rivediamo ora la demo relativa al polinomio di grado 16, 
applicando però l’approccio della Ridge Regression con 
diversi valori del parametro λ. ",esempio polynomial rivisitato rivediamo ora demo relativa polinomio grado applicando per lapproccio ridge regression diversi valori parametro
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#17,17,"Polinomio di grado 16 
lambda = 1.00e-25
 
18
",polinomio grado lambda
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#18,18,"Polinomio di grado 16 
lambda = 1.00e-10
 
19
",polinomio grado lambda
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#19,19,"Polinomio di grado 16 
lambda = 1.00e-06
 
20
",polinomio grado lambda
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#2,2,"Il problema dell’Overﬁtting 
nella polynomial regression
 
3
Ricordiamo il nostro modello nella polynomial  
regression:
A seconda del grado del polinomio possiamo avere 
diverse situazioni:
overﬁt
yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
y
Area xPrezzo
AreaPrezzoy
x",problema dellovertting polynomial regression ricordiamo modello polynomial regression seconda grado polinomio possiamo avere diverse situazioni overt yiwwxiwx iwpxp ii area prezzo area prezzoy
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#20,20,"Polinomio di grado 16 
lambda = 1.00e-03 
 
21
",polinomio grado lambda
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#21,21,"Polinomio di grado 16 
lambda = 1.00e+02
 
22
",polinomio grado lambda
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#22,22," 
23costo ridge(w)=R S S ( w)+",costo ridgewr
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#23,23,"Gradiente della Funzione di Costo 
 
24rcosto ridge(w)= r[(y",gradiente funzione costo rcosto ridgew
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#24,24,"Algoritmi per adattare il modello 
[caso della Ridge Regression]
Anche nel caso della Ridge Regression, una volta calcolato 
il gradiente della funzione 
 costo_ridge
  ci sono due possibili 
approcci per minimizzare la funzione di costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
25",algoritmi adattare modello caso ridge regression caso ridge regression volta calcolato gradiente funzione costoridge due possibili approcci minimizzare funzione costo forma chiusa uguaglia gradiente zero risolvono equazioni non sempre possibile conveniente punto vista computazionale algoritmo discesa gradiente gradient descent richiede denizione criterio convergenza step size
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#25,25,"Forma Chiusa 
[caso della Ridge Regression] 
 
26Poniamo il gradiente uguale a zero:
rcosto ridge( w)=",forma chiusa caso ridge regression poniamo gradiente uguale zero rcosto ridge
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#26,26,"Gradient Descent (1/4) 
[caso della Ridge Regression] 
 
27w(t+1) w(t)",gradient descent caso ridge regression
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#27,27,"Gradient Descent (2/4) 
[caso della Ridge Regression] 
 
28@costo ridge(w(t))
@wj=@RSS(w(t))
@wj+",gradient descent caso ridge regression costo ridgewt wjr sswt
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#28,28,"Gradient Descent (3/4) 
[caso della Ridge Regression] 
 
29@RSS(w(t))
@wj=",gradient descent caso ridge regression sswt
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#29,29,"Gradient Descent (4/4) 
[caso della Ridge Regression] 
 
30
L’aggiornamento del generico peso w j:
diventa:
ossia:",gradient descent caso ridge regression laggiornamento generico peso diventa ossia
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#3,3,"Sintomi dell’Overﬁtting
 
4
Spesso, quando il fenomeno dell’overﬁtting si manifesta, 
accade che i valori assoluti dei parametri stimati ŵ 
assumono valori molto alti. 
Vediamo ora una semplice demo in cui si mostra questo 
fenomeno.",sintomi dellovertting spesso quando fenomeno dellovertting manifesta accade valori assoluti parametri stimati assumono valori molto alti vediamo ora semplice demo mostra fenomeno
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#30,30,"Algoritmo di Gradient Descent 
[caso della Ridge Regression] 
 
31w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]=",algoritmo gradient descent caso ridge regression oppure inizializziamo modo casuale whilekrcosto ridge wtk derivata parziale
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#31,31,"Andamento Coefﬁcienti 
Ridge
 
32
λ ",andamento coefcienti ridge
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#32,32," 
33
Selezione dei parametri  
via Cross Validation 
Un problema importante è quello relativo alla scelta del 
parametro λ. Lo affrontiamo per la Ridge, ma le 
considerazioni sono più generali. 
Come è stato detto in precedenza, per ogni valore di λ che 
vogliamo considerare possiamo addestrare il nostro modello 
sui dati di training, valutarlo sul validation set e scegliere il 
valore di λ che ottiene i migliori risultati (validation error più 
basso). 
Possiamo poi valutare le prestazioni del modello selezionato 
sul test set.",selezione parametri via cross validation problema importante relativo scelta parametro affrontiamo ridge considerazioni generali stato detto precedenza ogni valore vogliamo considerare possiamo addestrare modello dati training valutarlo validation set scegliere valore ottiene migliori risultati validation error basso possiamo poi valutare prestazioni modello selezionato test set
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#33,33,"Tutto ciò è certamente possibile, a patto di avere un numero 
sufﬁciente di dati:
 
34
Training 
SetTest 
Set
Validation
 Set
ﬁt ŵλ 
test prestazioni di ŵλ  
per selezionare λ* 
valutare il  
true error di ŵλ*  
Selezione dei parametri  
via Cross Validation ",ci certamente possibile patto avere numero sufciente dati training set test set validation set test prestazioni selezionare valutare true error selezione parametri via cross validation
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#34,34,"La domanda che dobbiamo porci è però la seguente: cosa 
accade se non abbiamo dati sufﬁcienti per dividerli nei tre 
sottoinsiemi necessari? 
 
35
Dati disponibili
Resto dei dati Test 
Set
Selezione dei parametri  
via Cross Validation 
Supponiamo dunque di trovarci in questa situazione, in cui i 
dati disponibili sono pochi:
",domanda dobbiamo porci per seguente cosa accade dati sufcienti dividerli tre sottoinsiemi necessari dati disponibili resto dati test set selezione parametri via cross validation supponiamo dunque trovarci situazione dati disponibili pochi
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#35,35," 
36
Dopo aver scorporato il test set di dimensione adeguata, 
vediamo come poter gestire il resto dei dati da utilizzare  per 
il training e la validation.
Un uso ingenuo potrebbe essere il seguente:
Selezione dei parametri  
via Cross Validation 
Resto dei dati 
Training 
Set
Validation
 Set
",dopo aver scorporato test set dimensione adeguata vediamo poter gestire resto dati utilizzare training validation uso ingenuo potrebbe essere seguente selezione parametri via cross validation resto dati training set validation set
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#36,36," 
37
Il metodo però non funzionerebbe perché, con pochi dati a 
disposizione, il validation set non sarebbe sufﬁcientemente 
ampio per consentire una valutazione adeguata.
Questo varrebbe per la suddivisione mostrata nella ﬁgura 
precedente, ma anche per altre suddivisioni, come ad es.:
Selezione dei parametri  
via Cross Validation 
Validation
 Set
Validation
 Set",metodo per funzionerebbe perch pochi dati disposizione validation set sufcientemente ampio consentire valutazione adeguata varrebbe suddivisione mostrata gura precedente altre suddivisioni selezione parametri via cross validation validation set validation set
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#37,37," 
38
Ossia vale per qualsiasi scelta di un sottoinsieme dei dati 
disponibili, da utilizzare come validation set.
Quale di tali sottoinsiemi possiamo utilizzare? Sappiamo che 
ciascuno di essi è troppo piccolo per le valutazioni di nostro 
interesse.
Selezione dei parametri  
via Cross Validation 
La risposta è la seguente: li utilizziamo tutti, effettuando una 
“averge performance” su tutte le scelte. 
In tal modo (cross validation) si evita la “sensitivity” dei 
risultati in base al particolare sottoinsieme scelto, causata 
delle poche osservazioni che contiene.",ossia vale qualsiasi scelta sottoinsieme dati disponibili utilizzare validation set tali sottoinsiemi possiamo utilizzare sappiamo ciascuno essi troppo piccolo valutazioni interesse selezione parametri via cross validation risposta seguente utilizziamo tutti effettuando averge performance tutte scelte tal modo cross validation evita sensitivity risultati base particolare sottoinsieme scelto causata poche osservazioni contiene
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#38,38," 
39
k-fold Cross Validation 
Consideriamo dunque il resto dei dati (N dati), ottenuto 
scorporando un training set di dimensione adeguata dai dati 
disponibili.
Suddividiamo tali N dati in K blocchi, assegnando casualmente  
i dati a ciascuno dei blocchi:
Resto dei dati 
N/K N/K N/K ………….1 2 K ……….",fold cross validation consideriamo dunque resto dati dati ottenuto scorporando training set dimensione adeguata dati disponibili suddividiamo tali dati blocchi assegnando casualmente dati ciascuno blocchi resto dati 
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#39,39," 
40
k-fold Cross Validation 
Per ciascuno dei K blocchi, operiamo considerandolo il 
Validation Set, utilizzando quindi i dati rimanenti come 
Training Set.
In sostanza, dopo aver ﬁssato un valore per λ, operiamo 
come segue per il primo blocco (ricordiamoci che in verde 
abbiamo il Training Set):
Validation
 Set
ˆw(1)
",fold cross validation ciascuno blocchi operiamo considerandolo validation set utilizzando quindi dati rimanenti training set sostanza dopo aver ssato valore operiamo segue primo blocco ricordiamoci verde training set validation set
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#4,4,"Esempio di funzione
 
5
Applichiamo rumore gaussiano, campioniamo 30 
osservazioni e addestriamo vari modelli:y=s i n ( 4 x)",esempio funzione applichiamo rumore gaussiano campioniamo osservazioni addestriamo vari modelliys
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#40,40," 
41
k-fold Cross Validation 
Per il secondo blocco abbiamo:
Validation
 Set
ˆw(2)
",fold cross validation secondo blocco abbiamo validation set
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#41,41," 
42
k-fold Cross Validation 
… e così via ﬁno al blocco K:
Validation
 Set
ˆw(K)
",fold cross validation cos via no blocco validation set wk
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#42,42," 
43
k-fold Cross Validation 
L’algoritmo è il seguente:
Per ogni scelta del valore di λ:
 for k = 1, 2, …., K 
   1. stima di ŵλ sui blocchi di training 
   2. calcolo dell’errore sul “validation block”:
Calcolo dell’Average Error: CV(",fold cross validation lalgoritmo seguente ogni scelta valore stima blocchi training calcolo dellerrore validation block calcolo dellaverage error
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#43,43," 
44
leave-one-out Cross Validation 
Formalmente, la migliore approssimazione si ha per validation 
set di dimensione 1 (K = N).
In tal caso si parla di leave-one-out cross validation :
123 n
1 2 3 N
2 3 N
1 2 3 N
1 2 3 N
……………1…
…
…
…
…1 2 3 N",leave one cross validation formalmente migliore approssimazione validation set dimensione tal caso parla leave one cross validation 
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#44,44,"Scelta del valore K 
 
45
Il Leave-one-out è molto pesante dal punto di vista 
computazionale: 
richiede il calcolo di N “ﬁt” del modello per ogni λ. 
In genere, tipici valori utilizzati per K sono: 
K = 5 (5-fold CV) 
K = 10 (10-fold CV)",scelta valore leave one molto pesante punto vista computazionale richiede calcolo t modello ogni genere tipici valori utilizzati sono fold fold
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#45,45," 
46
La gestione dell’intercetta 
Nella discussione su Ridge e Cross Validation non abbiamo 
considerato il come gestire l’intercetta, che compare in tanti  
modelli.
yi=w0",gestione dellintercetta discussione ridge cross validation considerato gestire lintercetta compare tanti modelli yiw
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#46,46," 
47
La gestione dell’intercetta 
Conosciamo bene la funzione di costo per la Ridge:
Minimizzando tale funzione, anche l’intercetta w 0 (così 
come gli altri coefﬁcienti) tende ad assumere piccoli valori.RSS(w)+",gestione dellintercetta conosciamo bene funzione costo ridge minimizzando tale funzione lintercetta cos altri coefcienti tende assumere piccoli valorir ssw
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#47,47," 
48
La gestione dell’intercetta 
Possiamo dunque considerare una versione modiﬁcata della 
funzione di costo per la Ridge:
In tal modo, la parte relativa alla L 2-norm (penalty) non 
considera w 0.
Vediamo come possiamo implementare ciò nel caso in cui si 
usi l’algoritmo di Gradient Descent.RSS(w0,wresto)+",gestione dellintercetta possiamo dunque considerare versione modicata funzione costo ridge tal modo parte relativa norm penalty considera vediamo possiamo implementare ci caso usi lalgoritmo gradient descentr sswwresto
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#48,48," 
49
L’algoritmo viene modiﬁcato come segue:
Algoritmo di Gradient Descent 
[caso della Ridge Regression senza penalizzazione dell’intercetta] 
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]=",lalgoritmo viene modicato segue algoritmo gradient descent caso ridge regression senza penalizzazione oppure inizializziamo modo casuale whilekrcosto ridge wtk derivata parziale
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#49,49,"Riferimenti
 
50
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#5,5,"Polinomio di grado 2
 
6
",polinomio grado
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#6,6,"Polinomio di grado 4
 
7
",polinomio grado
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#7,7,"Polinomio di grado 16
 
8
",polinomio grado
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#8,8,"Overﬁtting con molte feature
 
9
Questo fenomeno accade non solo nella polynomial 
regression, ma anche: 
 quando è elevato il numero degli input d (e.g., per il 
caso degli appartamenti, oltre alla metratura abbiamo 
il #bagni, ecc.); 
e, più in generale, quando è elevato il numero delle 
feature ( D elevato):
yi=DX
j=0wj",overtting molte feature fenomeno accade solo polynomial regression anche quando elevato numero input caso appartamenti oltre metratura bagni ecc generale quando elevato numero feature elevato yid jwj
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#9,9,"Overﬁtting e #osservazioni
 
10
Il problema dell’overﬁtting, che in genere aumenta 
all’aumentare della complessità del modello, dipende 
anche dal numero delle osservazioni di cui disponiamo: 
Poche osservazioni (N piccolo) → è facile avere overﬁt al crescere 
della complessità del modello. 
Tante osservazioni (N molto grande)  → è più  difﬁcile avere overﬁt.Prezzo
Prezzo
Area Area",overtting osservazioni problema genere aumenta allaumentare complessit modello dipende numero osservazioni disponiamo poche osservazioni piccolo facile avere overt crescere complessit modello tante osservazioni molto grande difcile avere overtprezzo prezzo area area
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Feature Selection e LASSO
Machine Learning 
 
1",universit roma tre dipartimento ingegneria anno accademico feature selection machine learning
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#1,1,"Sommario
La Selezione delle Feature nella Regression 
Algoritmo All Subsets 
Approccio Greedy per Feature Selection (Forward Stepsize 
Algorithm) 
Algoritmo Coordinate Descent 
LASSO 
Confronto tra Ridge e LASSO
 
2",sommario selezione feature regression algoritmo subsets approccio greedy feature selection forward stepsize algorithm algoritmo coordinate descent confronto ridge
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#10,10," 
11
La scelta del Modello 
Ci sono varie possibilità: 
Valutazione delle prestazioni sul validation set (se abbiamo dati sufﬁcienti) 
Cross Validation 
Altre metriche proposte in letteratura che penalizzano la “model 
complexity”
La domanda ora è la seguente: quale conﬁgurazione di 
feature scegliamo? 
Come sappiamo, non conviene scegliere il modello con RSS 
più basso, che diminuisce all’aumentare della complessità del 
modello.",scelta modello varie possibilit valutazione prestazioni validation set dati sufcienti cross validation altre metriche proposte letteratura penalizzano model complexity domanda ora seguente congurazione feature scegliamo sappiamo conviene scegliere modello basso diminuisce allaumentare complessit modello
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#11,11,"Complessità di “All Subsets”
 
12
La complessità computazionale dell’algoritmo è elevata: basti 
considerare il numero di modelli da valutare! E’ esponenziale 
rispetto al numero delle feature:
[000 ···0]
[100 ···0]
[010 ···0]
···
[110 ···0]
···
[111 ···1]yi= ✏i
yi=w0",complessit all subsets complessit computazionale dellalgoritmo elevata basti considerare numero modelli valutare esponenziale rispetto numero feature yi yiw
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#12,12,"Algoritmi Greedy
 
13
Un approccio alternativo è quello di utilizzare algoritmi 
greedy che ci consentono di ottenere soluzioni sub-ottime, 
ma con complessità computazionale molto più bassa.
L’algoritmo che ora vedremo si chiama Forward Stepsize 
Algorithm. Esso si distingue dal precedente perché, 
all’aumentare del numero di feature, sceglie solo una nuova 
feature conservando quelle scelte nei passi precedenti.",algoritmi greedy approccio alternativo utilizzare algoritmi greedy consentono ottenere soluzioni sub ottime complessit computazionale molto bassa lalgoritmo ora vedremo chiama forward stepsize algorithm esso distingue precedente perch allaumentare numero feature sceglie solo nuova feature conservando scelte passi precedenti
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#13,13,"Forward Stepsize Algorithm
 
14
Partiamo dalla ﬁgura che rappresenta la fase ﬁnale di All Subsets:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront",forward stepsize algorithm partiamo gura rappresenta fase nale subsets features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#14,14," 
15
Vediamo come il Forward Stepsize si differenzia:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm",vediamo forward stepsize differenzia features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#15,15," 
16
Per #features = 1 sceglie la migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm",features sceglie migliore features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#16,16," 
17
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
deriva dal passo  
precedente
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:",features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm deriva passo precedente features aggiunge gi scelta migliore
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#17,17," 
18
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
seconda feature 
selezionata",features aggiunge gi scelta migliore features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm seconda feature selezionata
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#18,18," 
19
E’ evidente la differenza rispetto all’algoritmo All Subset:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
feature selezionate da 
“all subset algorithm”",evidente differenza rispetto allalgoritmo subset features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm feature selezionate all subset algorithm
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#19,19," 
20
… e così via …
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm",cos via features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#2,2,"Selezione delle Feature
 
3
La selezione delle feature nella regression è una fase molto 
importante per due motivi: 
1. Efﬁcienza di elaborazione : 
•Se la dimensione di w è elevata (e.g., 100B) la predizione è 
molto pesante computazionalmente. 
•Del resto, se ŵ è sparso, il calcolo dipende solo dai valori 
non nulli. 
2. Interpretabilità : 
• Quali feature sono rilevanti per la nostra  predizione? ",selezione feature selezione feature regression fase molto importante due motivi efcienza elaborazione se dimensione elevata predizione molto pesante del resto sparso calcolo dipende solo valori nulli quali feature rilevanti predizione
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#20,20," 
21
… ﬁno al caso che considera tutte le feature:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm",no caso considera tutte feature features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront forward stepsize algorithm
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#21,21," 
22
Consideriamo il dizionario delle feature {
 ɸ
0
, 
ɸ
1
, … , 
ɸ
D
} 
Impostiamo l’insieme delle feature F come segue: F
 0
 = 
∅
   (
o impostiamo 
 ɸ
0
 a 1
); 
addestriamo e calcoliamo l’errore. 
t = 0 
•
Per ogni j (≠ dalle feature correnti), addestriamo il modello usando le 
feature correnti F
 t
 + {
ɸ
j
(x)} per ottenere il vettore dei pesi 
 ŵ
 per j. 
•
Selezioniamo la best feature 
 ɸ
j*
(x) (e.g., quella che dà luogo al training 
error più basso quando addestriamo con F
 t
 + {
ɸ
j*
(x)}) 
•
Set  F
 t+1
 <— F
 t 
+ {
ɸ
j*
(x)};  
•
t = t + 1 
•
Ripetere il ciclo 
Forward Stepsize Algorithm
L’algoritmo in sintesi è il seguente:",consideriamo dizionario feature impostiamo linsieme feature segue impostiamo addestriamo calcoliamo lerrore ogni feature correnti addestriamo modello usando feature correnti ottenere vettore pesi selezioniamo best feature luogo training error basso quando addestriamo set ripetere ciclo forward stepsize algorithm lalgoritmo sintesi seguente
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#22,22," 
23
La complessità computazionale di questo algoritmo è 
sensibilmente minore di quella dell’All Stepsize Algorithm. 
Infatti, il numero di modelli valutati (con D feature) è il 
seguente: 
1° step: D modelli 
2° step: D-1 modelli (si aggiunge 1 feature tra le D-1 possibili) 
3° step: D-2 modelli (si aggiunge 1 feature tra le D-2 possibili) 
ecc.
Forward Stepsize Algorithm
Il numero massimo di step è uguale a D. Abbiamo dunque: 
O(D2)",complessit computazionale algoritmo sensibilmente minore dellall stepsize algorithm infatti numero modelli valutati con feature seguente step modelli step modelli aggiunge feature possibili step modelli aggiunge feature possibili ecc forward stepsize algorithm numero massimo step uguale dunque
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#23,23," 
24
Questo metodo, proposto da Robert Tibshirani nel 1996, consente 
di effettuare una feature selection, oltre a limitare i valori assoluti 
dei coefﬁcienti w. 
Lasso Regression usa la somma dei valori assoluti dei pesi ( L1 
Regularization ). 
La funzione che rappresenta il costo totale nel Lasso è dunque la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i due 
termini.                                              costo lasso(w)=R S S ( w)+",metodo proposto robert tibshirani consente effettuare feature selection oltre limitare valori assoluti coefcienti lasso regression usa somma valori assoluti pesi regularization funzione rappresenta costo totale lasso dunque seguente parametro tuning parameter serve bilanciare due termini costo lassowr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#24,24," 
25Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵlasso = 0 
Se 0 < λ < ∞: 
Soluzioni Lasso 
per diversi valori 
 λ
0kˆwlassok1kˆwLSk1",vediamo cosa accade fronte diversi valori parametro riconduciamo vecchia soluzione ossia minimizzazione dell soluzioni costo totale lunica soluzione minimizzare costo lasso soluzioni lasso diversi valori lsk
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#25,25,"Andamento Coefﬁcienti 
Ridge e Lasso
 
26
Ridge Lasso
λ λ ",andamento coefcienti ridge lasso ridge lasso
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#26,26,"Visualizzazione costo Ridge
 
27
ellissicosto ridge(w)=R S S ( w)+",visualizzazione costo ridge ellissicosto ridgewr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#27,27," 
28
circonferenzecosto ridge(w)=R S S ( w)+",ridgewr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#28,28,"Simulazione Ridge
 
29
λ = 0
λ→∞ˆwridge
ˆwridgeˆwridge
ˆwridge ˆwridge ˆwridge",simulazione ridge wridge wridgewridge wridge wridge wridge
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#29,29," 
30
costo lasso(w)=R S S ( w)+",costo lassowr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#3,3,"Selezione delle Feature
 
4
Un approccio che possiamo adottare per selezionare le 
migliori feature consiste nel considerare ogni possibile 
combinazione delle feature che abbiamo disponibili, 
veriﬁcando le prestazioni di ciascuna scelta. 
Questo è esattamente ciò che fa l’ All Subset Algorithm  che 
ora vediamo. 
Esso comincia considerando 0 feature, poi tutte le 
possibilità per 1 feature, poi tutte le possibilità per 2 
feature, ecc., scegliendo ogni volta la migliore 
combinazione.",selezione feature approccio possiamo adottare selezionare migliori feature consiste considerare ogni possibile combinazione feature disponibili vericando prestazioni ciascuna scelta esattamente ci subset algorithm ora vediamo esso comincia considerando feature poi tutte possibilit feature poi tutte possibilit feature ecc scegliendo ogni volta migliore combinazione
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#30,30," 
31
kwk1= |w0|+|w1|costo lasso(w)=R S S ( w)+",kwk wwcosto lassowr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#31,31,"Simulazione Lasso
 
32
λ→∞λ = 0
ˆwlasso
ˆwlassoˆwlasso
ˆwlasso ˆwlasso ˆwlasso",simulazione lasso wlasso wlassowlasso wlasso wlasso wlasso
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#32,32,"Confronto tra Ridge e Lasso
 
33
Per ogni valore di 
 λ
, per la Ridge esiste un certo valore 
 s
 tale 
che le seguenti due equazioni forniscono le stesse stime dei 
coefﬁcienti w
 ridge
:
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
jsargmin
w[RSS(w)+",confronto ridge lasso ogni valore ridge esiste certo valore tale seguenti due equazioni forniscono stime coefcienti ridge argmin sotto condizioned jsargmin ssw
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#33,33,"Confronto tra Ridge e Lasso
 
34w1
w0
w2
0+w2
1s
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
js
Consideriamo per semplicità il caso a 2 dimensioni. L’equazione: 
indica che i coefﬁcienti ŵridge stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al cerchio deﬁnito da: w2
0+w2
1s",confronto ridge lasso argmin sotto condizioned js consideriamo semplicit caso dimensioni lequazione indica coefcienti ridge stimati piccolo punti appartenenti cerchio denito
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#34,34,"Confronto tra Ridge e Lasso
 
35
Analogamente, per ogni valore di 
 λ
, per il Lasso esiste un 
certo valore 
 s
 tale che le seguenti due equazioni forniscono 
le stesse stime dei coefﬁcienti w
 lasso
:
argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|sargmin
w[RSS(w)+",confronto ridge lasso analogamente ogni valore lasso esiste certo valore tale seguenti due equazioni forniscono stime coefcienti lasso argmin sotto condizioned jwjsargmin ssw
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#35,35,"Confronto tra Ridge e Lasso
 
36|w0|+|w1|sw0w1
|w0|+|w1|s
Analogamente, la seguente equazione:  
indica che i coefﬁcienti ŵlasso stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al “diamante”: argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|s",confronto ridge lasso wws analogamente seguente equazione indica coefcienti lasso stimati piccolo punti appartenenti diamante argmin sotto condizioned jwjs
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#36,36,"Confronto tra Ridge e Lasso
 
37
La ﬁgura seguente ci mostra i punti di minimo per i due casi, e il 
perché Lasso spesso consente di eliminare alcune feature. In rosso 
sono indicate le curve di livello per RSS.
|w0|+|w1|s w2
0+w2
1s
w0w1
w0w1
ˆwLSˆwLS
ˆwlasso ˆwridge",confronto ridge lasso gura seguente mostra punti minimo due casi lasso spesso consente eliminare alcune feature rosso indicate curve livello wws lsw wlasso wridge
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#37,37,"Confronto tra Ridge e Lasso
 
38
Se 
s
 è sufﬁcientemente grande, le regioni in verde conterranno la 
soluzione Least Squares. Pertanto le stime della Ridge regression e 
del Lasso saranno le stesse della Least Squares (tale grande valore per 
s
 corrisponde a 
 λ
 = 0) 
Se invece la soluzione Least Squares sta al di fuori delle regioni in 
verde, essa non può essere la soluzione perché non rispetta i vincoli 
citati in precedenza. 
I punti di minimo sono dunque quelli che corrispondono alla curva 
di livello più “stretta” che passa per l’area in verde (ricordiamoci che 
le curve di livello per RSS corrispondono a valori sempre più alti 
mano a mano che si “allargano” rispetto alla soluzione LS)",confronto ridge lasso sufcientemente grande regioni verde conterranno soluzione least squares pertanto stime ridge regression lasso least squares tale grande valore corrisponde invece soluzione least squares fuori regioni verde essa pu essere soluzione rispetta vincoli citati precedenza punti minimo dunque corrispondono curva livello stretta passa larea verde ricordiamoci curve livello corrispondono valori sempre alti mano mano allargano rispetto soluzione
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#38,38,"Confronto tra Ridge e Lasso
 
39
Nella ﬁgura abbiamo considerato il caso di 2 dimensioni per il 
vettore 
 w
. 
Nel caso di 3 dimensioni la “constraint region” in verde diventa una 
sfera per la Ridge e un poliedro per il Lasso. 
Nel caso di dimensione > 3, essa diventa una ipersfera per la Ridge e 
un politopo per il Lasso (politopo è un termine coniato da Alicia 
Boole, ﬁglia di George Boole)",confronto ridge lasso gura considerato caso dimensioni vettore caso dimensioni constraint region verde diventa sfera ridge poliedro lasso caso dimensione essa diventa ipersfera ridge politopo lasso politopo termine coniato alicia boole glia george boole
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#39,39,"Minimizzazione della  
funzione di costo Lasso
In precedenza abbiamo visto come poter minimizzare la 
funzione di costo (per LS e per Ridge) mediante: 
La forma chiusa (uguagliando a zero il gradiente della 
funzione) 
Gradient Descent 
Per il Lasso ci sono delle difﬁcoltà per il calcolo del gradiente.
 
40",minimizzazione funzione costo lasso precedenza visto poter minimizzare funzione costo per ridge mediante forma chiusa uguagliando zero gradiente funzione gradient descent lasso difcolt calcolo gradiente
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#4,4,"Ricerca delle migliori feature 
Size: 0
 
5# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
",ricerca migliori feature size features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#40,40,"Minimizzazione della  
funzione di costo Lasso
La funzione da minimizzare è la seguente: 
 
41
wj
|wj|
derivata = +1 derivata = -1
non derivabile
costo lasso(w)=R S S ( w)+",minimizzazione funzione costo lasso funzione minimizzare seguente derivata derivata derivabile costo lassowr
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#41,41,"Minimizzazione della  
funzione di costo
Non possiamo quindi calcolare il gradiente della funzione. 
Successivamente vedremo come utilizzare il concetto di 
subgradient
  per superare la difﬁcoltà appena vista. 
Ora cogliamo l’occasione per vedere un nuovo algoritmo per 
minimizzare una funzione di costo, chiamato 
 Coordinate 
Descent
 . 
Presenteremo l’algoritmo in generale, per poi vedere come esso 
possa essere usato convenientemente per minimizzare la 
funzione di costo per il Lasso.
 
42",minimizzazione funzione costo possiamo quindi calcolare gradiente funzione successivamente vedremo utilizzare concetto subgradient superare difcolt appena vista ora cogliamo loccasione vedere nuovo algoritmo minimizzare funzione costo chiamato coordinate descent presenteremo lalgoritmo generale poi vedere esso possa essere usato minimizzare funzione costo lasso
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#42,42,"Il nostro scopo è quello di minimizzare una certa funzione:
Algoritmo Coordinate Descent
g(w)=g(w0,w1,···,wD)
La caratteristica distintiva del Coordinate Descent è che la 
minimizzazione avviene lungo una singola dimensione per 
volta, come illustrato qui di seguito nel semplice caso di 
funzione di due variabili w
 0
 e w
 1
. 
 
43",scopo minimizzare certa funzione algoritmo coordinate descent caratteristica distintiva coordinate descent minimizzazione avviene lungo singola dimensione volta illustrato qui seguito semplice caso funzione due variabili
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#43,43,"Algoritmo Coordinate Descent
Curve di livello di una funzione g(
 w
) da minimizzare:
 
44
w0w1
scegliamo il 
punto inizialevalori di g( w) maggiori per  
curve di livello più esterne ",algoritmo coordinate descent curve livello funzione minimizzare scegliamo punto inizialevalori maggiori curve livello esterne
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#44,44,"Facciamo variare una sola coordinata:
 
45
w0w1
w0
0
Algoritmo Coordinate Descent",variare sola coordinata algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#45,45,"Troviamo il minimo e spostiamoci su tale punto (axis-alined move):
 
46
w0w1
w0
0
Algoritmo Coordinate Descent",troviamo minimo spostiamoci tale punto axis alined move algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#46,46,"Facciamo variare una sola altra coordinata:
 
47
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent",variare sola altra coordinata algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#47,47,"Troviamo il minimo e passiamo su tale punto:
 
48
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent",troviamo minimo passiamo tale punto algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#48,48,"……. e così via …….
 
49
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent",cos via algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#49,49,"………
 
50
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent", algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#5,5," 
6# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature 
Size: 1",features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront ricerca migliori feature size
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#50,50,"………
 
51
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent", algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#51,51,"………
 
52
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent", algoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#52,52,"…. ﬁno ad arrivare al minimo globale:
 
53
w0w1
w0
1w00
1
w00
0w0
0
……
Algoritmo Coordinate Descent
per problemi convessi, 
step sempre più piccoli 
man mano che ci  
avviciniamo alla soluzione",no arrivare minimo globale algoritmo coordinate descent problemi convessi step sempre piccoli man mano avviciniamo soluzione
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#53,53,"Algoritmo Coordinate Descent
 
54
Inizializza ŵ = 0 (o in modo “smart”) 
while  not converged: 
   scegli una coordinata j
si minimizza solo sulla j-esima coordinataˆwj argmin
!g(ˆw0,ˆw1,···,ˆwj",algoritmo coordinate descent inizializza modo smart converged scegli coordinata minimizza solo esima coordinatawj argmin
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#54,54,"Algoritmo Coordinate Descent
 
55
Come scegliere nell’algoritmo la coordinata successiva? 
In modo casuale (“random” o “stochastic"" coordinate descent) 
In modo “round robin” 
ecc. 
Si noti che in questo algoritmo non è necessario scegliere lo step size! 
Tale approccio è utilissimo per numerosi problemi 
Converge ad un ottimo in vari altri casi (e.g., funzione “strongly 
convex”) 
Converge per la funzione obiettivo Lasso ",algoritmo coordinate descent scegliere nellalgoritmo coordinata successiva modo casuale random stochastic coordinate descent modo round robin ecc noti algoritmo necessario scegliere step size tale approccio utilissimo numerosi problemi converge ottimo vari altri casi funzione strongly convex converge funzione obiettivo lasso
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#55,55,"Normalizzazione delle Feature
 
56
L’applicazione dell’algoritmo Coordinate Descent per il Lasso è 
sempliﬁcata se operiamo una normalizzazione delle feature. 
Per far questo dobbiamo prendere in considerazione la matrice 
delle feature   usata in precedenza, nella quale ogni colonna 
corrisponde ad una feature (0, 1, … D) applicata ai vari ingressi xi 
dei training data. ",normalizzazione feature lapplicazione dellalgoritmo coordinate descent lasso semplicata operiamo normalizzazione feature far dobbiamo prendere considerazione matrice feature usata precedenza ogni colonna corrisponde feature applicata vari ingressi training data
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#56,56,"Normalizzazione Feature
 
57",normalizzazione feature
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#57,57,"Normalizzazione delle Feature
 
58Zj=vuutNX
i=1",normalizzazione feature zjvuut
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#58,58,"Coordinate Descent per 
Unregularized Regression
 
59
Vediamo ora come sia possibile applicare l’algoritmo Coordinate 
Descent nel caso di regressione senza regularization, ossia nel 
caso Least Squares. 
Il passo successivo sarà la sua applicazione al Lasso. 
Per l’applicazione al caso Least Squares (con feature 
normalizzate) dobbiamo calcolare le derivare parziali della 
funzione di costo RSS (necessarie per minimizzare sulla singola 
coordinata): 
RSS(w)=NX
i=1[yi",coordinate descent unregularized regression vediamo ora possibile applicare lalgoritmo coordinate descent caso regressione senza regularization ossia caso least squares passo successivo applicazione lasso lapplicazione caso least squares con feature normalizzate dobbiamo calcolare derivare parziali funzione costo necessarie minimizzare singola coordinata sswn iyi
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#59,59,"Derivate di RSS 
con feature normalizzate
 
60@RSS(w)
@wj=",derivate feature normalizzate ssw
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#6,6," 
7# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliore feature
Ricerca delle migliori feature 
Size: 1",features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront migliore feature ricerca migliori feature size
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#60,60,"Ricerca del minimo per una 
coordinata
 
61⇢j=NX
i=1",ricerca minimo coordinata jn
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#61,61,"Algoritmo Coordinate Descent 
per Least Squares
 
62set:calcola:
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
⇢j=NX
i=1",algoritmo coordinate descent least squares setcalcola inizializza altro modo converged jn
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#62,62," 
63ˆwj=8
<
:⇢j+",wj
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#63,63,"Coefﬁcienti per LS, Ridge e Lasso
 
64ˆwj=8
<
:⇢j+",coefcienti ridge lasso wj
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#64,64,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature normalizzate]
 
65ˆwj=8
<
:⇢j+",algoritmo coordinate descent lasso versione feature normalizzate wj
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#65,65,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
66
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+",algoritmo coordinate descent lasso versione feature normalizzate calcola inizializza altro modo converged setcalcola wj
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#66,66," 
67
Un aspetto importante è il criterio di convergenza. 
Per problemi convessi (in particolare strongly convex) gli step 
sono sempre più piccoli mano a mano che ci si avvicina al 
punto di ottimo:
Algoritmo Coordinate Descent 
per Lasso
Un criterio che possiamo utilizzare per la convergenza è quello 
di considerare una misura degli step fatti in un ciclo completo su 
tutte le feature e fermarsi quando: 
 max step < 
 ε",aspetto importante criterio convergenza problemi convessi particolare strongly convex step sempre piccoli mano mano avvicina punto ottimo algoritmo coordinate descent lasso criterio possiamo utilizzare convergenza considerare misura step fatti ciclo completo tutte feature fermarsi quando max step
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#67,67,"Scelta del parametro 
 λ
per approfondimenti: 
Murphy, K. “
 Machine Learning: A Probabilistic Perspective
 ”. The MIT Press, 
2012.
 
68
Il parametro 
 λ
 può essere scelto avvalendosi dell’approccio che 
usa il validation set, a patto di avere un numero sufﬁciente di 
osservazioni. 
Altrimenti possiamo usare la k-fold cross validation. 
Quest’ultima tende a scegliere il parametro che ottiene la 
migliore “predictive accuracy”. Essa tende a favorire soluzioni 
meno “sparse”, ossia con piccoli valori di 
 λ
, anziché soluzioni 
con maggiore feature selection.",scelta parametro murphy machine learning probabilistic perspective press parametro pu essere scelto avvalendosi dellapproccio usa validation set patto avere numero sufciente osservazioni altrimenti possiamo usare fold cross validation questultima tende scegliere parametro ottiene migliore predictive accuracy essa tende favorire soluzioni meno sparse ossia piccoli valori anzich soluzioni maggiore feature selection
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#68,68,"Riferimenti
 
69
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012.",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press murphy machine learning probabilistic approach press
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#7,7," 
8# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliori 2 feature
Ricerca delle migliori feature 
Size: 2",features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront migliori feature ricerca migliori feature size
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#8,8," 
9
Ricerca delle migliori feature 
Size: 8
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront",ricerca migliori feature size features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#9,9," 
10# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature  
andamento in base al numero di feature",features bedrooms bathrooms sqft living sqft lot oors year built year renovated waterfront ricerca migliori feature andamento base numero feature
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Dimostrazioni Formali Lasso
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico dimostrazioni formali lasso machine learning
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#1,1,"Sommario
 
2Dimostrazione della formula di aggiornamento dei 
coefﬁcienti nell’algoritmo coordinate descent per 
LASSO
",sommario dimostrazione formula aggiornamento coefcienti nellalgoritmo coordinate descent
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#10,10,"Differential set della  
funzione di costo Lasso
 
11
Il differential set rispetto al generico peso w
 j
 è pertanto il seguente:
@wj[costo lasso] = 2 zjwj",differential set funzione costo lasso differential set rispetto generico peso pertanto seguente wjcosto lasso zjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#11,11,"Differential Set della  
funzione di costo Lasso  
 
12
Abbiamo pertanto la seguente espressione ﬁnale:
@wj[costo lasso] =8
<
:2zjwj",differential set funzione costo lasso pertanto seguente espressione nale wjcosto lasso zjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#12,12,"Soluzione ottima 
 
13
Se uguagliamo a zero la precedente espressione, abbiamo tre casi:
caso 1 (
 w
j  
< 0
):2zjˆwj",soluzione ottima uguagliamo zero precedente espressione tre casi caso zjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#13,13,"Soluzione ottima 
 
14
Abbiamo dunque:
In deﬁnitiva:
caso 2 ( wj  = 0): l’intervallo                                            deve contenere 0 [",soluzione ottima dunque denitiva caso lintervallo deve contenere
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#14,14,"Soluzione ottima 
 
15
caso 3 (
 w
j  
> 0
):
da cui otteniamo:
Poiché 
 ŵ
j  
> 0, abbiamo:2zjˆwj",soluzione ottima caso otteniamo poich abbiamozjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#15,15," 
16
In conclusione:
ˆwj=8
><
>:⇢j+",conclusione wj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#16,16,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
17
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+",algoritmo coordinate descent lasso versione feature normalizzate calcola inizializza altro modo converged setcalcola wj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#17,17,"Coefﬁcienti per LS, Ridge e Lasso
 
18
soft thresholding
+",coefcienti ridge lasso soft thresholding
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#18,18,"Riferimenti
 
19
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012.",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press murphy machine learning probabilistic approach press
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#2,2,"Ottimizzazione Lasso
 
3
Come sappiamo, la Funzione Obiettivo per il Lasso da ottimizzare 
mediante Coordinate Descent è la seguente:
RSS(w)+",ottimizzazione lasso sappiamo funzione obiettivo lasso ottimizzare mediante coordinate descent seguente ssw
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#3,3,"Derivazione del termine RSS
 
4RSS(w)+",derivazione termine
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#4,4," 
5
In questo caso c’è il problema del calcolo della derivata parziale:
RSS(w)+",caso c problema calcolo derivata parziale ssw
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#5,5,"Subgradiente di Funzioni Convesse 
 6
I metodi che conosciamo (e.g., Gradient Descent, Coordinate 
Descent) richiedono che la funzione da ottimizzare sia 
differenziabile. 
E’ possibile però generalizzare la discussione andando al di là 
delle funzioni differenziabili. 
E’ possibile ad esempio mostrare come i precedenti algoritmi 
possano essere applicati anche per funzioni non differenziabili, 
utilizzando il subgradiente anziché il gradiente.",subgradiente funzioni convesse metodi conosciamo gradient descent coordinate descent richiedono funzione ottimizzare possibile per generalizzare discussione andando funzioni possibile esempio mostrare precedenti algoritmi possano essere applicati funzioni utilizzando subgradiente anzich gradiente
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#6,6,"Subgradiente di Funzioni Convesse
 
7Un vettore S che soddisfa la: 
è detto subgradiente di g in v.g(w)",subgradiente funzioni convesse vettore soddisfa detto subgradiente vgw
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#7,7,"Subgradiente della funzione  
Valore Assoluto
 
8
Nel punto non derivabile della funzione “valore assoluto” i 
subgradienti variano da -1 a +1:
derivata = +1 derivata = -1
wj|wj|",subgradiente funzione valore assoluto punto derivabile funzione valore assoluto subgradienti variano derivata derivata wjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#8,8,"Subgradiente della funzione  
Valore Assoluto
 
9
Il “differential set” è dunque il seguente per i vari punti:
@wj|wj|=8
<
:{",subgradiente funzione valore assoluto differential set dunque seguente vari punti wjwj
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#9,9,"Subgradiente di L
 1
 term
 
10
Nel caso del Lasso abbiamo:
",subgradiente term caso lasso abbiamo
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Fonti di Errore 
Expected Prediction Error
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico regressione fonti errore expected prediction error machine learning
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#1,1,"Sommario
Le tre fonti di errore: Noise, Bias, Variance 
Deﬁnizione e derivazione formale delle tre fonti di 
errore 
Expected Prediction Error 
 
2",sommario tre fonti errore noise bias variance denizione derivazione formale tre fonti errore expected prediction error
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#10,10,"Noise: 
Varianza dell’Errore del modello
 
11
EPE( xt)=",noise varianza dellerrore modello
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#11,11,"Bias della funzione stimata 
 
12bias( fˆw(xt)) = fw(true) (xt)",bias funzione stimata bias fwxt fwtrue
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#12,12,"Varianza della funzione stimata 
 
13EPE( xt)=",varianza funzione stimata
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#13,13,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Vediamo ora come dimostrare la formula dell’EPE, in cui 
entrano in gioco i tre termini che abbiamo deﬁniti 
formalmente in precedenza:
 
14EPE( xt)=",dimostrazione lexpected prediction error vediamo ora dimostrare formula delle entrano gioco tre termini deniti formalmente precedenza
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#14,14,"Dimostrazione per  
l’Expected Prediction Error (EPE)
A tal ﬁne, ricordiamo innanzi tutto la deﬁnizione di tale 
errore:
 
15EPE = Etrain[Generalization Error per ˆw(train)] =
=Etrain[Ex,y[L(y,f ˆw(train) (x))]]
1.
 Consideriamo: 
2.
 Riferiamoci ad uno speciﬁco 
 x
tL[y, f ˆw(x)] = ( y",dimostrazione lexpected prediction error tal ne ricordiamo innanzi denizione tale errore error wtrain wtrain consideriamo riferiamoci specico wx
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#15,15,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Con le due assunzioni precedenti l’espressione per l’EPE 
si sempliﬁca come segue:
 
16EPE( xt)=Etrain ,yt[(yt",dimostrazione lexpected prediction error due assunzioni precedenti lespressione le semplica segue xtetrain ytyt
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#16,16,"Expected Prediction Error
Partendo da tale espressione, vediamo come dimostrare la 
formula dell’EPE:
 
17EPE( xt)= Etrain ,yt[(yt",expected prediction error partendo tale espressione vediamo dimostrare formula delle etrain ytyt
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#17,17,"Expected Prediction Error
1° termine: Si sempliﬁca come segue, poiché  y
 t
 e f non 
dipendono dal training set:
 
18
Si noti che l’Expectation del quadrato dell’errore 
 ε
 è la 
varianza di 
 ε
, avendo esso media nulla.Etrain ,yt[(yt",expected prediction error termine semplica segue poich dipendono training set noti lexpectation quadrato dellerrore varianza esso media nullaetrain ytyt
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#18,18,"Expected Prediction Error
2° termine:
 
192·Etrain ,yt[(yt",expected prediction error termine etrain ytyt
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#19,19,"Expected Prediction Error
3° termine:
 
20
L’espressione per l’errore EPE può essere dunque scritta 
così:
Abbiamo: Etrain ,yt[(f",expected prediction error termine lespressione lerrore pu essere dunque scritta cos abbiamo etrain ytf
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#2,2,"Deﬁnizione e derivazione 
formale
Occupiamoci della deﬁnizione e derivazione formale delle 
tre sorgenti di errore: 
noise 
bias 
variance 
A tal ﬁne introduciamo innanzi tutto l’Expected Prediction 
Error, le cui componenti sono le suddette sorgenti di errore.
 
3",denizione derivazione formale occupiamoci denizione derivazione formale tre sorgenti errore noise bias variance tal ne introduciamo innanzi lexpected prediction error componenti suddette sorgenti errore
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#20,20,"Means Squared Error
Dobbiamo ora dimostrare che:
 
21MSE[ fˆw(train) (xt)] = Etrain[(fw(true) (xt)",means squared error dobbiamo ora dimostrare che fwtrain
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#21,21,"1° termine: ricordiamo che
 
22
Ne consegue che:
poiché   e    non dipendono dal training set. f¯f
Means Squared Error
¯f,Etrain [ˆf]
Etrain [(f",termine ricordiamo consegue che poich dipendono training set ff means squared error fetrain etrain
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#22,22,"2° termine:
 
232·Etrain [(f",termine etrain
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#23,23,"Means Squared Error
3° termine:
 
24Etrain [(¯f",means squared error termine etrain
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#24,24,"E’ in tal modo dimostrato che:
 
25MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)
Means Squared Error",tal modo dimostrato che bias var means squared error
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#25,25,"In conclusione:
 
26EPE( xt)=",conclusione
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#26,26,"Riferimenti
 
27
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning regression university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#3,3,"Training Set Randomness
Un Training Set è un campione di N osservazioni (e.g., N 
appartamenti venduti di cui conosciamo le features e il 
prezzo).  
Cosa accade se il Training Set è costituito da altre N 
osservazioni diverse dalle precedenti?  
Come cambiano le prestazioni del sistema?
 
4",training set randomness training set campione osservazioni appartamenti venduti conosciamo features prezzo cosa accade training set costituito altre osservazioni diverse precedenti cambiano prestazioni sistema
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#4,4,"Training Set Randomness
Ad esempio, nella ﬁgura sono mostrate due situazioni 
relative a due diverse scelte del training set:
 
5Test Set
Per valutare la prestazione dei due “ﬁt” dobbiamo 
prendere in considerazione il Generalization Error.",training set randomness esempio gura mostrate due situazioni relative due diverse scelte training set test set valutare prestazione due t dobbiamo prendere considerazione generalization error
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#5,5,"Training Set Randomness
Nei due casi otterremo due diversi valori del 
Generalization Error:
 
6Test Set
",training set randomness due casi otterremo due diversi valori generalization error test set
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#6,6,"Expected Prediction Error
Idealmente, vorremmo poter ottenere una misura delle 
prestazioni del sistema, mediata su tutti i possibili training 
set. 
Possiamo deﬁnire formalmente tale quantità, che 
chiamiamo Expected Prediction Error (EPE), come segue: 
 
7EPE = Etrain[Generalization Error per ˆw(train)]
“averaging” su tutti i possibili Training Set 
(pesati in base alle loro probabilità)parametri calcolati su 
uno speciﬁco Training Set",expected prediction error idealmente vorremmo poter ottenere misura prestazioni sistema mediata possibili training set possiamo denire formalmente tale quantit chiamiamo expected prediction error segue error wtrain averaging possibili training set pesati base calcolati specico training set
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#7,7,"Expected Prediction Error 
su un target input
Per analizzare questo tipo di errore, cominciamo a 
prendere in considerazione uno speciﬁco punto 
 x
t
: 
 
8Test 
x
t
Supponiamo  inoltre che la Loss function sia la seguente: 
L[y, f ˆw(x)] = ( y",expected prediction error target input analizzare tipo errore cominciamo prendere considerazione specico punto test supponiamo inoltre loss function seguente wx
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#8,8,"Expected Prediction Error 
su un target input
E’ possibile dimostrare che l’errore EPE in 
 x
t
 è uguale alla 
somma di tre termini:
 
9
Vediamo ora di illustrare adeguatamente tali tre termini.EPE( xt)=",expected prediction error target input possibile dimostrare lerrore uguale somma tre termini vediamo ora illustrare adeguatamente tali tre terminie
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#9,9,"Noise: 
Varianza dell’Errore del modello
 
10EPE( xt)=",noise varianza dellerrore modello
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione  
alla  
Classiﬁcazione
Machine Learning ",universit roma tre dipartimento ingegneria anno accademico introduzione classicazione machine learning
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#1,1,"Sommario
Introduzione alla Classiﬁcazione 
Esempi di applicazione della Classiﬁcazione 
Decision Boundary 
Logistic Regression 
Maximum Likelihood Estimation 
Training mediante Gradient Ascent
 
2",sommario introduzione classicazione esempi applicazione classicazione decision boundary logistic regression maximum likelihood estimation training mediante gradient ascent
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#10,10,"Introduzione alla Classiﬁcazione
 
11
•Come si vede in ﬁgura, tutte le immagini del test set, tranne una, 
sono classiﬁcate correttamente. 
•L’errore per il Boston terrier  è dovuto completamente alla nostra 
scelta delle features, scelta fatta basandoci sul training set 
disponibile (un po’ troppo piccolo). 
•Per migliorare dobbiamo perciò ricominciare, collezionando più 
dati e individuare più features.",introduzione classicazione come vede gura tutte immagini test set tranne una classicate correttamente lerrore boston terrier dovuto completamente scelta features scelta fatta basandoci training set disponibile po troppo piccolo per migliorare dobbiamo perci ricominciare collezionando dati individuare features
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#11,11,"Learning Pipeline
 
12
•In ﬁgura è rappresentata la learning pipeline del problema di 
classiﬁcazione che stiamo considerando. 
•Lo stesso processo è usato essenzialmente per tutti i task di 
Machine Learning, non solo per la classiﬁcazione. ",learning pipeline in gura rappresentata learning pipeline problema classicazione considerando lo stesso processo usato essenzialmente task machine learning solo classicazione
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#12,12,"Learning Pipeline
 
13•Deﬁnire il problema . Qual è il task che vogliamo sia appreso dal 
computer? 
•Collezionare i dati . Raccogliere i dati per il training set e il test set. Più 
i dati sono numerosi e diversiﬁcati, meglio è per il successo del 
sistema da realizzare. 
•Individuare le features . Quali sono le features migliori per descrivere i 
dati? 
•Addestrare il modello . Scegliere il modello e calibrare i suoi parametri 
sul training set mediante metodi di ottimizzazione. 
•Testare il modello . Valutare sul test set le prestazioni del modello 
addestrato. Se i risultati non sono soddisfacenti, ripensare la scelta 
delle features utilizzate e collezionare, se possibile, più dati. ",learning pipeline denire problema qual task vogliamo appreso computer collezionare dati raccogliere dati training set test set dati numerosi diversicati meglio successo sistema realizzare individuare features quali features migliori descrivere dati addestrare modello scegliere modello calibrare parametri training set mediante metodi ottimizzazione testare modello valutare test set prestazioni modello addestrato risultati soddisfacenti ripensare scelta features utilizzate collezionare possibile dati
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#13,13,"Minimizzazione di una funzione di costo
 
14
Caso della regressione:",minimizzazione funzione costo caso regressione
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#14,14,"Minimizzazione di una funzione di costo
 
15
Caso della classiﬁcazione:",minimizzazione funzione costo caso classicazione
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#15,15,"Esempi di applicazione 
Object Detection
 
16
",esempi applicazione object detection
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#16,16,"Esempi di applicazione 
Spam Filtering
 
17(Testo della email, 
mittente, IP, ecc.)
Input: x Output: ŷ",esempi applicazione spam filtering testo email mittente ecc input output
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#17,17,"Esempi di applicazione 
Image Classiﬁcation
 
18
Input: x Output: ŷ
(pixel dell’immagine) (categoria predetta)",esempi applicazione image classication input output pixel dellimmagine categoria predetta
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#18,18,"Esempi di applicazione 
Diagnosi Mediche Personalizzate 
 
19Input: x Output: ŷ
",esempi applicazione diagnosi mediche personalizzate input output
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#19,19,"Esempi di applicazione 
Reading Your Mind
 
20
Output: ŷ",esempi applicazione reading mind output
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#2,2,"Introduzione alla Classiﬁcazione
Il task della 
 Classiﬁcazione
  è simile in linea di principio a 
quello della 
 Regressione  
La vera differenza tra i due è che, anziché predire un valore di 
output continuo, nella classiﬁcazione cerchiamo di prevedere 
valori discreti o 
 classi 
 
3",introduzione classicazione task classicazione simile linea principio regressione vera differenza due che anzich predire valore output continuo classicazione cerchiamo prevedere valori discreti classi
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#20,20,"Esempi di applicazione 
 
21Sentiment Analysis
Esempio: classiﬁcatore di reviews di ristorantiInput: xOutput: ŷ",esempi applicazione sentiment analysis esempio classicatore reviews ristoranti input output
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#21,21,"Esempi di applicazione 
Sentiment Analysis
 
22
Input x:  In questo ristorante preparano i migliori  
“spaghetti alla carbonara” di Roma
ŷ = +1",esempi applicazione sentiment analysis input ristorante preparano migliori spaghetti carbonara roma
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#22,22,"Punteggio di una frase 
(
Score
 ) 
 
23Termine Peso w
migliore 1.5
buono 1.0
cattivo -1.0
magniﬁco 2.0
terribile -2.1
eccezionale 2.7
il, noi, dove, ecc. 0.0Un modo che possiamo adottare per classiﬁcare una review come 
positiva o negativa consiste nel considerare alcuni “termini” che 
riteniamo rilevanti ai ﬁni della classiﬁcazione, calcolando per ciascuno 
di essi il numero di occorrenze con cui compare nella review e un 
“valore di rilevanza” (peso) da utilizzare per calcolare un “punteggio”. 
Ad esempio:",punteggio frase score termine peso migliore buono cattivo magnico terribile eccezionale noi dove ecc modo possiamo adottare classicare review positiva negativa consiste considerare alcuni termini riteniamo rilevanti ni classicazione calcolando ciascuno essi numero occorrenze compare review valore rilevanza peso utilizzare calcolare punteggio esempio
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#23,23," 
24x1 = #eccezionalex2 = #terribile
+
++ ++-
--
-
+Score( x) = 2.7 x1 - 2.1 x2Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
-Score( x) < 0
Score( x) > 0r:  2.7 x1 - 2.1 x2 = 0  
      (decision boundary)",eccezionalex terribile score termine peso eccezionale terribile punteggio frase score score score decision boundary
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#24,24," 
25+
++ ++-
--
-
+Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
+Score( x) < 0
Score( x) > 0
x1 = #eccezionalex2 = #terribiler:  1.0 + 2.7 x1 - 2.1 x2 = 0 
    (decision boundary)Score( x) = 1.0 + 2.7 x1 - 2.1 x2",termine peso eccezionale terribile punteggio frase score score score eccezionalex terribiler decision boundaryscore
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#25,25," 26
ˆyi= sign[Score( xi)]Nel caso in cui i termini siano d possiamo calcolare il punteggio 
come segue:
e classiﬁcare la review in questo modo:
Punteggio di una frase 
(
Score
 ) 
dove:
sign(Score) =⇢+1 se Score >0
",yi signscore xinel caso termini possiamo calcolare punteggio segue classicare review modo punteggio frase score dove signscore score
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#26,26, 27ˆyi= sign[Score( xi)]Score( xi)= w0,yi signscore xiscore
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#27,27,"Afﬁdabilità della Previsione 
 28•La funzione sign vista in precedenza ci fornisce una 
classiﬁcazione binaria del sentiment della revisione. 
•Potremmo però essere interessati anche ad avere un grado di 
conﬁdenza della previsione. 
•Ad esempio, potremmo voler distinguere il caso di uno 
Score di poco superiore allo zero (e.g., 0.1) dal caso di uno 
Score ben più elevato (e.g., 4.0), punteggi che in entrambi i 
casi danno luogo a review positive. ",afdabilit previsione la funzione sign vista precedenza fornisce classicazione binaria sentiment revisione potremmo per essere interessati avere grado condenza previsione ad esempio potremmo voler distinguere caso score poco superiore zero caso score ben elevato punteggi entrambi casi danno luogo review positive
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#28,28,"Probabilità come “degree of belief” 
 290 1P(yi = +1)
Assolutamente certo 
review negative0.5
Assolutamente certo 
review positive
Non so se le review  
sono positive o negative•A tale scopo possiamo avvalerci del calcolo delle probabilità. 
•Se diciamo che la probabilità di avere y i = +1 è di 0.7, vogliamo 
dire che ci aspettiamo di avere nell’insieme delle review 
disponibili il 70% di review positive. ",probabilit degree belief pyi assolutamente certo review negative assolutamente certo review positive review positive negativea tale scopo possiamo avvalerci calcolo probabilit se diciamo probabilit avere vogliamo dire aspettiamo avere nellinsieme review disponibili review positive
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#29,29,"Probabilità come “degree of belief” 
Probabilità Condizionate 
 30•E’ molto utile in tale contesto considerare le probabilità 
condizionate. 
•Se diciamo ad esempio che la probabilità di avere una review 
positiva, condizionata al fatto di avere nella review 3 occorrenze 
di “eccezionale” ed 1 di “terribile”, è di 0.9, vogliamo dire che ci 
aspettiamo il 90% delle review positive nella lista delle review 
disponibili, considerando però solo quelle che hanno 3 
“eccezionale” e 1 “terribile” (in verde nella ﬁgura che segue). ",probabilit degree belief probabilit condizionate e molto utile tale contesto considerare probabilit condizionate se diciamo esempio probabilit avere review positiva condizionata fatto avere review occorrenze eccezionale terribile vogliamo dire aspettiamo review positive lista review disponibili considerando per solo eccezionale terribile verde gura segue
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#3,3,"Introduzione alla Classiﬁcazione
In buona sostanza, un classiﬁcatore realizza un mapping: 
dove  
    è l’
 instance space
 , ossia l’insieme di tutte le possibili 
istanze del problema. Se esse sono descritte da un numero 
precisato di features, abbiamo: 
 
    è un ﬁnito e in genere piccolo insieme di 
 class labels
 : 
 
4C
C=[C1,C2,...,C k]X!C
X=[F1⇥F2⇥···⇥FD]X",introduzione classicazione buona sostanza classicatore realizza mapping instance space ossia linsieme tutte possibili istanze problema esse descritte numero precisato features abbiamo nito genere piccolo insieme class labels cccc kxc xfff
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#30,30," 
31 xi : testo della review yi: sentiment
Il cacio e pepe era delizioso. +1
La carbonara era eccezionale. L’ambiente terribile. Il servizio eccezionale. 
Complessivamente un ristorante eccezionale.+1
Mia moglie ha preso i carcioﬁ alla romana, che erano pessimi. -1
………… -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale +1P(y i = +1| 3 eccezionale & 1 terribile) = 0.9Probabilità come “degree of belief” 
Probabilità Condizionate ",testo review sentiment cacio pepe delizioso carbonara eccezionale lambiente terribile servizio eccezionale ristorante eccezionale moglie preso carcio romana pessimi eccezionale terribile eccezionale eccezionale eccezionale terribile eccezionale eccezionale eccezionale terribile probabilit degree belief probabilit condizionate
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#31,31," 320 1P(yi = +1| xi)
Assolutamente certo 
che xi è negativa0.5
Assolutamente certo 
che xi è positiva
Non sono sicuro se la xi  
è positiva o negativaIn generale, dato un input xi, (e.g., una review) abbiamo la 
seguente situazione: Probabilità come “degree of belief” 
Probabilità Condizionate ",pyi assolutamente certo negativa assolutamente certo positiva sicuro positiva negativa generale dato input review seguente situazione probabilit degree belief probabilit condizionate
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#32,32,"Link Function 
 33Score( xi, w)- ∞ + ∞ •Il problema che dobbiamo risolvere, se vogliamo avvalerci delle 
probabilità condizionate, è capire come passare dai valori dello 
Score a quelli delle probabilità. 
•La funzione Score ha un range che va da -∞ a +∞: 
•La probabilità, come sappiamo, può variare da 0 a 1:  
0 1P(yi = +1| xi)",link function score il problema dobbiamo risolvere vogliamo avvalerci probabilit condizionate capire passare valori score probabilit la funzione score range la probabilit sappiamo pu variare pyi
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#33,33," 34Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = g[Score( xi, w)]Link Function 
•Dobbiamo pertanto deﬁnire una “link function” g (generalized 
linear model ) che realizzi un mapping tra i due intervalli: ",score pyi gscore wlink function dobbiamo pertanto denire link function generalized linear model realizzi mapping due intervalli
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#34,34," 
35
•Una funzione tipicamente usata in questi casi è la funzione 
logistica , o sigmoide , così deﬁnita:Link Function 
•Essa, come si vede, ha l’insieme di deﬁnizione costituito 
dall’intervallo (-∞, +∞) e come codominio l’intervallo [0, 1].  ",una funzione tipicamente usata casi funzione logistica sigmoide cos denitalink function essa vede linsieme denizione costituito dallintervallo codominio lintervallo
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#35,35," 36Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = sigmoid [Score( xi, w)]Logistic Regression Model 
•Il nostro modello diventa dunque il seguente: ",score pyi sigmoid score wlogistic regression model il modello diventa dunque seguente
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#36,36," 37Logistic Regression Model 
•L’espressione per la probabilità, dato un ingresso xi ed un vettore 
dei pesi calcolato ŵ, è dunque la seguente: 
ˆP(yi=+ 1 |xi,ˆw)=1
1+e",logistic regression model lespressione probabilit dato ingresso vettore pesi calcolato dunque seguente pyi xiw
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#37,37," 38Il Processo di Training 
•Il processo di training consiste nel deﬁnire una funzione di costo, 
o una funzione che misura la “qualità” della previsione, e nel 
determinare la conﬁgurazione dei pesi (vettore w) che ottimizza 
la funzione per gli esempi di training. 
•Nella ﬁgura che segue sono mostrati i passi relativi a tale 
processo. ",processo training il processo training consiste denire funzione costo funzione misura qualit previsione determinare congurazione pesi vettore ottimizza funzione esempi training nella gura segue mostrati passi relativi tale processo
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#38,38,"Il Processo di Training 
[caso della Classiﬁcazione]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
metrica 
valutazione 
qualità
Calcolo vettore 
dei pesi ŵyi osservato(xi)
 39xi
Funzione  
valutazione 
qualitàŵɸ
(N esempi)
Algoritmo di 
ApprendimentoˆP(yi=+ 1 |xi,ˆw)",processo training caso classicazione dati training estrazione features modello metrica valutazione qualit calcolo vettore pesi yi osservatoxi funzione valutazione qualit esempi algoritmo apprendimento pyi xiw
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#39,39,"Funzione per Valutazione Qualità 
 
40•Dobbiamo ora deﬁnire una funzione che possiamo usare per la 
valutazione della qualità delle prestazioni del sistema. 
•A tal ﬁne possiamo prendere in considerazione le probabilità 
condizionate deﬁnite in precedenza. 
•in particolare, per ciascuno degli esempi di training ( xi, yi) che 
abbiamo disponibili, possiamo calcolare la probabilità di avere in 
uscita un valore y i dato un vettore di pesi w (vedi ﬁgura seguente). ",funzione valutazione qualit dobbiamo ora denire funzione possiamo usare valutazione qualit prestazioni sistema tal ne possiamo prendere considerazione probabilit condizionate denite precedenza in particolare ciascuno esempi training disponibili possiamo calcolare probabilit avere uscita valore dato vettore pesi vedi gura seguente
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#4,4,"Introduzione alla Classiﬁcazione
 
5
Vediamo un semplice esempio di classiﬁcazione: 
Supponiamo di voler addestrare un computer a distinguere 
immagini di gatti da immagini di cani (
 task
). 
•
Dobbiamo innanzi tutto procurarci un certo numero di 
immagini (
 training set
 ) in modo da poter addestrare il 
computer: 
",introduzione classicazione vediamo semplice esempio classicazione supponiamo voler addestrare computer distinguere immagini gatti immagini cani task dobbiamo innanzi procurarci certo numero immagini training set modo poter addestrare computer
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#40,40,"Maximum Likelihood Estimation 
(
MLE
)
 
41Data Point xi,1 xi,2 yi Scegliere w che massimizza:
x1, y1 2 1 +1 P(y 1=+1| x1, w)
x2, y2 0 2 -1 P(y 2=-1| x2, w)
x3, y3 3 3 -1 P(y 3=-1| x3, w)
x4, y4 4 1 +1 P(y 4=+1| x4, w)
L(w)=P(y1|x1,w)·P(y2|x2,w)·P(y3|x3,w)·P(y4|x4,w)La funzione che possiamo usare per la valutazione della qualità è: ",maximum likelihood estimation data point scegliere massimizza funzione possiamo usare valutazione qualit
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#41,41," 
42L(w)=NY
i=1P(yi|xi,w)La forma generale della funzione Likelihood  è:
L’obiettivo è dunque quello di massimizzare tale funzione, ad 
esempio mediante Hill Climbing (o Gradient Ascent ), visto che 
non si ha una forma chiusa:
max
wL(w) = max
wNY
i=1P(yi|xi,w)
Maximum Likelihood Estimation 
(
MLE
)",lwn pyixiwla forma generale funzione likelihood lobiettivo dunque massimizzare tale funzione esempio mediante hill climbing gradient ascent visto forma chiusa max max pyixiw maximum likelihood estimation
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#42,42," 
43•Per il calcolo del gradiente dobbiamo calcolare le varie derivate parziali 
della funzione. 
•Possiamo sempliﬁcare tale calcolo trasformando la funzione,  
considerando il logaritmo naturale del Likelihood: 
•In tal modo trasformiamo i prodotti in somme, pur non cambiando il 
punto di massimo assoluto. Infatti si ha:lnL(w)=l nNY
i=1P(yi|xi,w)=NX
i=1lnP(yi|xi,w)
ˆw= argmax
wL(w) ˆwln= argmax
wlnL(w) ˆw=ˆwln
Log-Likelihood 
[facilita l'operazione di derivazione]",per calcolo gradiente dobbiamo calcolare varie derivate parziali funzione possiamo semplicare tale calcolo trasformando funzione considerando logaritmo naturale likelihood in tal modo trasformiamo prodotti somme pur cambiando punto massimo assoluto infatti haln lwl pyixiwn iln pyixiw argmax wln argmax wln wwln log likelihood facilita loperazione derivazione
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#43,43,"Log-Likelihood 
[facilita l'operazione di derivazione]
 
44
dove è stata utilizzata la Indicator Function :Per facilitare i calcoli possiamo riscrivere la funzione come segue:
lnL(w)=NX
i=1lnP(yi|xi,w)=
=NX
i=1{I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi=",log likelihood facilita loperazione derivazione stata utilizzata indicator function per facilitare calcoli possiamo riscrivere funzione segue lwn iln pyixiw iiyi ln pyi xiwiyi
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#44,44," 
45
Log-Likelihood 
[facilita l'operazione di derivazione]
Sostituendo alle probabilità P le seguenti espressioni:
otteniamo, per un solo punto  i, la forma che segue:P(yi=+ 1 |xi,w)=1
1+e",log likelihood facilita loperazione derivazione sostituendo probabilit seguenti espressioni otteniamo solo punto forma seguepyi xiw
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#45,45,"Forma della Funzione da Derivare 
[per un punto 
 i
] 
 
46lnL(w)= I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi=",forma funzione derivare per punto iyi ln pyi xiwiyi
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#46,46," 
47
Regole applicate:
lne",regole applicate lne
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#47,47," 
48lnL(w)=",
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#48,48,"Derivata Parziale per un punto
 
49dove:
e:Per uno solo punto i abbiamo:
@(wT·",derivata parziale punto dove eper solo punto abbiamo
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#49,49,"Derivata parziale su tutti i punti
 
50Sommando su tutti i punti i otteniamo:
Questa è la forma della derivata parziale che possiamo usare 
nell’algoritmo di Gradient Ascent  per trovare il vettore ŵ che 
ottimizza la funzione:@lnL(w)
@wj=NX
i=1",derivata parziale punti sommando punti otteniamo forma derivata parziale possiamo usare nellalgoritmo gradient ascent trovare vettore ottimizza funzioneln wjn
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#5,5,"Introduzione alla Classiﬁcazione
 
6
•
Dobbiamo poi identiﬁcare le caratteristiche distintive 
(
features
 ) che ci possano consentire di distinguere le due 
tipologie di immagini. Nel nostro caso potremmo ad esempio 
scegliere le due seguenti: 
•
Dimensione del naso (da piccolo a grande) 
•
Forma delle orecchie (da arrotondate ad appuntite) 
supponendo di essere in grado di estrarle dalle immagini. ",introduzione classicazione dobbiamo poi identicare caratteristiche distintive features possano consentire distinguere due tipologie immagini caso potremmo esempio scegliere due seguenti dimensione naso piccolo grande forma orecchie arrotondate appuntite supponendo essere grado estrarle immagini
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#50,50,"Algoritmo di Gradient Ascent
 
51w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrlnL(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1",algoritmo gradient ascent oppure inizializziamo modo casuale whilekrln lwtk derivata parziale
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#51,51,"Riferimenti
 
52
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. ",riferimenti watt borhani katsaggelos machine learning rened edition cambridge university press james witten hastie tibishirani introduction statistical learning springer ross probabilit statistica lingegneria scienze edizione apogeo machine learning classication university washington coursera flach machine learning art science algorithms make sense data cambridge university press
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#6,6,"Introduzione alla Classiﬁcazione
 
7
•Se rappresentiamo le immagini del training set nello spazio 
delle features , abbiamo le seguente situazione, in cui le varie 
immagini appaiono ben aggregate:",introduzione classicazione se rappresentiamo immagini training set spazio features seguente situazione varie immagini appaiono ben aggregate
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#7,7,"Introduzione alla Classiﬁcazione
 
8•Ora che abbiamo una buona rappresentazione dei dati di 
training nello spazio delle features, l’ultimo passo per 
addestrare il computer a distinguere le immagini dei gatti da 
quelle dei cani è un problema geometrico: 
•identiﬁcare un modello (ad esempio un linear model ) che 
separi chiaramente i gatti dai cani nello spazio delle 
features.",introduzione classicazione ora buona dati training spazio features lultimo passo addestrare computer distinguere immagini gatti cani problema geometrico identicare modello esempio linear model separi chiaramente gatti cani spazio features
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#8,8,"Introduzione alla Classiﬁcazione
 
9
•La ﬁgura che segue mostra un modello lineare (la retta in nero) 
“addestrato” ( trained linear model ), che divide lo spazio delle 
features in due regioni. 
•Una volta determinata questa linea, una nuova immagine la cui 
rappresentazione sta al di sopra della linea (regione blu) sarà 
considerata dal computer relativa ad un gatto. Se invece sta 
sotto la linea sarà considerata relativa ad un cane. ",introduzione classicazione la gura segue mostra modello lineare retta nero addestrato trained linear model divide spazio features due regioni una volta determinata linea nuova immagine sopra linea regione blu considerata computer relativa gatto invece sotto linea considerata relativa cane
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#9,9,"Introduzione alla Classiﬁcazione
 
10
•Per veriﬁcare l’efﬁcacia del sistema dobbiamo valutare le sue 
prestazioni su un insieme di immagini ( test set ) distinte da 
quelle usate per l’addestramento: ",introduzione classicazione per vericare lefcacia sistema dobbiamo valutare prestazioni insieme immagini test set distinte usate
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#0,0,Diagrammi a Blocchi,diagrammi blocchi
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#1,1,"Cos’è un diagramma a blocchi?Il diagramma a blocchi (diagramma di flusso o flow chart) è uno schema a blocchi utilizzato per rappresentare gli algoritmi.
Si tratta di una rappresentazione grafica che utilizza delle forme geometriche per descrivere gli algoritmi.",cos diagramma blocchiil diagramma blocchi diagramma flusso flow chart schema blocchi utilizzato rappresentare algoritmi tratta grafica utilizza forme geometriche descrivere algoritmi
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#10,10,"Cos’è una variabile?Le variabili sono aree di memoria RAM dove vengono memorizzati i dati e che possono essere cambiati durante l’esecuzione di un’applicazione.
Le costanti invece contengono un valore non modificabile.
Per entrambe è opportuno dare dei nomi sensati, non troppo lunghi e non separati da spazi.",cos variabilele variabili aree memoria vengono memorizzati dati possono essere cambiati durante lesecuzione costanti invece contengono valore modificabile entrambe opportuno dare nomi sensati troppo lunghi separati spazi
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#11,11,"Esercizi struttura sequenziale (1)Eseguire il prodotto tra due numeri;
Calcolare l'ipotenusa date le misure dei cateti di un triangolo rettangolo
Date 2 variabili, scambiarne il contenuto;
Calcolare il numero minimo di banconote per un importo in euro, tenendo conto dei diversi tagli da 500, 200, 100, 50, 20, 10, 5 euro.

",esercizi struttura sequenziale eseguire prodotto due numeri calcolare lipotenusa date misure cateti triangolo rettangolo date variabili scambiarne contenuto calcolare numero minimo banconote importo euro tenendo conto diversi tagli euro
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#12,12,Esercizi struttura condizionale (1),esercizi struttura condizionale
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#13,13,Esercizi struttura iterativa (1),esercizi struttura iterativa
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#14,14,"Esercizi vettori (1)Caricamento di 10 numeri in un vettore;
Somma degli elementi di un vettore;
Ricerca di un valore all’interno di un vettore.",esercizi vettori caricamento numeri vettore somma elementi vettore ricerca valore allinterno vettore
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#2,2,"Cos’è un algoritmo? A cosa serve?Per algoritmo si intende una successione di passi (o istruzioni) che definiscono le operazioni da eseguire sui dati per ottenere i risultati.
Esempi di algoritmi ne troviamo tantissimi, anche nella vita di tutti i giorni. Tipicamente è necessario un algoritmo a fronte di un problema, come ad esempio: andare a scuola; per risolvere questo problema dobbiamo seguire una sequenza ordinata e finita di passi (algoritmo), come ad esempio:
Svegliarsi  Fare colazione  Vestirsi  Uscire di casa  Prendere l’autobus  Entrare in classe
Quindi, l’insieme dei passi che consentono di risolvere un problema prende nome di algoritmo.",cos algoritmo cosa serveper algoritmo intende successione passi istruzioni definiscono operazioni eseguire dati ottenere risultati esempi algoritmi troviamo tantissimi vita giorni tipicamente necessario algoritmo fronte problema esempio andare scuola risolvere problema dobbiamo seguire sequenza ordinata finita passi algoritmo esempio svegliarsi fare colazione vestirsi uscire casa prendere lautobus entrare classe quindi linsieme passi consentono risolvere problema prende nome algoritmo
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#3,3,"Come si descrive un algoritmo?Ci sono tanti modi per rappresentare un algoritmo, un metodo molto utilizzato è quello basato sui diagrammi a blocchi, conosciuti anche con il nome di flow chart (letteralmente diagrammi di flusso).
Sono dunque utilizzati dei blocchi, cioè delle forme geometriche e ciascuna di essa ha un significato ben preciso.",descrive algoritmoci tanti modi rappresentare algoritmo metodo molto utilizzato basato diagrammi blocchi conosciuti nome flow chart letteralmente diagrammi flusso dunque utilizzati blocchi cio forme geometriche ciascuna essa significato ben preciso
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#4,4,"Quanti e quali blocchi abbiamo in un diagramma?I blocchi convenzionalmente utilizzati in un flow chart sono:
Ellisse
Parallelogramma
Rettangolo
Rombo",quali blocchi diagrammai blocchi utilizzati flow chart sono ellisse parallelogramma rettangolo rombo
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#5,5,"EllisseL’ellisse è utilizzata semplicemente solo per indicare l’inizio e la fine di un diagramma a blocchi.
Quindi ciascun diagramma inizierà con il blocco inizio e terminerà, dopo aver risolto il compito assegnato, con il blocco fine.",ellisse lellisse utilizzata semplicemente solo indicare linizio fine diagramma blocchi quindi ciascun diagramma inizier blocco inizio terminer dopo aver risolto compito assegnato blocco fine
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#6,6,"ParallelogrammaIl parallelogramma è utilizzato per prendere dei dati in INPUT o per visualizzare dei dati in OUTPUT. 
Nel caso in cui deve prendere dei dati in input è consigliabile inserire una I in alto a sinistra, seguita dai due punti. Similmente per l’output, che si è soliti indicare con una O in alto a sinistra, sempre seguita dai due punti (ma va bene una qualunque altra convenzione).",parallelogramma parallelogramma utilizzato prendere dati visualizzare dati caso deve prendere dati input consigliabile inserire alto sinistra seguita due punti similmente loutput soliti indicare alto sinistra sempre seguita due punti bene qualunque altra convenzione
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#7,7,"RettangoloIl rettangolo è utilizzato per eseguire dei calcoli, ovvero per elaborare dei dati. 
Ad esempio: per calcolare la somma tra due numeri, l’area di un rettangolo, la media fra tre numeri, …",rettangolo rettangolo utilizzato eseguire calcoli ovvero elaborare dati esempio calcolare somma due numeri larea rettangolo media fra tre numeri
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#8,8,"RomboIl rombo è utilizzato per le istruzioni condizionali, ovvero per porre una domanda. All’interno dunque viene fatto un test, per cui si valuta una condizione che può essere o vera o falsa, quindi si sceglie tra due strade diverse. 
Un esempio di semplice test potrebbe essere quello di vedere se un numero è positivo o negativo.",rombo rombo utilizzato istruzioni condizionali ovvero porre domanda allinterno dunque viene fatto test valuta condizione pu essere vera falsa quindi sceglie due strade diverse esempio semplice test potrebbe essere vedere numero positivo negativo
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#9,9,RomboIl rombo viene spesso utilizzato anche per i cicli while e do-while.,rombo rombo viene spesso utilizzato cicli while
data_test\rootfolder\varie\HTML&CSS.pptx#0,0,HTML e CSS,
data_test\rootfolder\varie\HTML&CSS.pptx#1,1,"Tag base dell’HTML: <p>, <div> e <span><p>, <div> e <span> sono tre diversi tipi di contenitori (di testo o altro), e si comportano in modo diverso:
<p> è un elemento di blocco e lascia spazio prima e dopo la propria chiusura;
<div> è un elemento di blocco, non lascia spazio prima e dopo la propria chiusura, ma va a capo;
<span> è un elemento inline e quindi non va a capo.",tag base dellh div spanp div span tre diversi tipi contenitori testo altro comportano modo diverso elemento blocco lascia spazio prima dopo propria chiusura div elemento blocco lascia spazio prima dopo propria chiusura capo span elemento inline quindi capo
data_test\rootfolder\varie\HTML&CSS.pptx#2,2,"Tag base dell’HTML: <ul>, <ol> e <li><ul> e <ol> sono tag che descrivono l’inizio di una lista, in particolare:
<ul> per le liste non ordinate;
<ol> per le liste ordinate.
<li> serve a descrivere l’inizio di un elemento della lista.
Esempio di utilizzo:
",tag base dellh liul tag descrivono linizio lista particolare liste ordinate liste ordinate serve descrivere linizio elemento lista esempio utilizzo
data_test\rootfolder\varie\HTML&CSS.pptx#3,3,"Tag base dell’HTML: <table>, <tr>, <th> e <td><table> descrive l’inizio di una tabella, e contiene al suo interno i tag <tr>, che descrivono l’inizio di una riga; i tag <tr> a loro volta possono contenere due tag:
<th> per descrivere una cella di «testata»;
<td> per descrivere una generica cella di contenuto.",tag base dellh table tdtable descrive linizio tabella contiene interno tag descrivono linizio riga tag volta possono contenere due tag descrivere cella testata descrivere generica cella contenuto
data_test\rootfolder\varie\HTML&CSS.pptx#4,4,"Tag base dell’HTML: <img><img> serve per inserire un’immagine all’interno della pagina, l’attributo «src» dei questo tag serve a specificare quale immagine caricare.",tag base dellh imgimg serve inserire unimmagine allinterno pagina lattributo src tag serve specificare immagine caricare
data_test\rootfolder\varie\HTML&CSS.pptx#5,5,"Tag base dell’HTML: <form>Un form (modulo) è una sezione di documento HTML che contiene elementi di controllo che l’utente può utilizzare per inserire dati o in generale per interagire. I dati inseriti possono essere poi inoltrati al server dove un agente può processarli. Gli elementi di controllo sono caratterizzati da un valore iniziale e da un valore corrente. Gli elementi di controllo possono essere: 
Bottoni di azione
Checkbox (caselle di spunta)
Radio Button (bottoni mutuamente esclusivi)
Liste di selezione (lista di opzioni)
Caselle di inserimento di testo",tag base dellh formun form modulo sezione documento contiene elementi controllo lutente pu utilizzare inserire dati generale interagire dati inseriti possono essere poi inoltrati server agente pu processarli elementi controllo caratterizzati valore iniziale valore corrente elementi controllo possono essere bottoni azione checkbox caselle spunta radio button bottoni mutuamente esclusivi liste selezione lista opzioni caselle inserimento testo
data_test\rootfolder\varie\HTML&CSS.pptx#6,6,Esercizi,esercizi
data_test\rootfolder\varie\homework\id-homework-1.pptx#0,0,Ingegneria dei dati 2022/2023Homework 1Paolo Merialdo,ingegneria dati homework paolo merialdo
data_test\rootfolder\varie\homework\id-homework-1.pptx#1,1,"Homework 1Leggere l'articolo (divulgativo) di Andrew Ng ""Data-centric AI"" (https://spectrum.ieee.org/andrew-ng-data-centric-ai)
In una relazione di circa 300 parole: 1) descrivi quella consideri la tesi più importante dell'autore e 2) esprimi la tua posizione rispetto ad essa. 

Termini di consegna: inviare la relazione entro le ore 12:00 del14 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc ",homework leggere larticolo divulgativo andrew data centric data centric relazione circa parole descrivi consideri tesi importante dellautore esprimi posizione rispetto essa termini consegna inviare relazione entro ore del ottobre attraverso seguente modulo online ypnc xyqc
data_test\rootfolder\varie\homework\id-homework-2.pptx#0,0,Ingegneria dei dati 2022/2023Homework 2(da svolgere individualmente)Paolo Merialdo,ingegneria dati homework svolgere merialdo
data_test\rootfolder\varie\homework\id-homework-2.pptx#1,1,"Homework 2A partire dal codice github dell'ing. Tommaso Teofili (https://github.com/tteofili/lucenex):
scrivere un programma Java che indicizza i file .txt contenuti in una directory del proprio laptop. In particolare, si devono considerare due campi (e quindi creare due indici): il nome del file, il contenuto del file. Per ciascun campo utilizzare un analyzer appropriato
scrivere un programma Java che legge una query da console, interroga l'indice e stampa il risultato. Usare una semplice sintassi per la query (ad esempio, una query inizia con la parola chiave nome o contentuto seguita da una sequenza di termini (eventualmente racchiusi tra virgolette per esprimere una phrase query)
testare il sistema con una decina di query diverse

Scrivere una relazione che, oltre a riportare l'url del proprio progetto su Github (o analogo) descriva:
gli analyzer che si è scelto di utilizzare (motivando le scelte)
il numero di file indicizzati e i tempi di indicizzazione
le query usate per testare il sistema",homework partire codice github delling tommaso teofili scrivere programma java indicizza file txt contenuti directory proprio laptop particolare devono considerare due campi quindi creare due indici nome file contenuto file ciascun campo utilizzare analyzer appropriato scrivere programma java legge query console interroga lindice stampa risultato usare semplice sintassi query esempio query inizia parola chiave nome contentuto seguita sequenza termini eventualmente racchiusi virgolette esprimere phrase query testare sistema decina query diverse scrivere relazione che oltre riportare lurl proprio progetto github analogo descriva analyzer scelto utilizzare motivando scelte numero file indicizzati tempi indicizzazione query usate testare sistema
data_test\rootfolder\varie\homework\id-homework-2.pptx#2,2,"Homework 2
Termini di consegna: inviare la relazione entro le ore 21:00 del 22 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc ",homework termini consegna inviare relazione entro ore ottobre attraverso seguente modulo online ypnc xyqc
data_test\rootfolder\varie\homework\id-homework-3.pptx#0,0,Ingegneria dei datiHomework 3(da svolgere in gruppo)Paolo Merialdo,ingegneria dati homework svolgere gruppopaolo merialdo
data_test\rootfolder\varie\homework\id-homework-3.pptx#1,1,"Homework 3Implementare l'algoritmo ""MergeList"" per la soluzione al problema ""Joinable Table Search""
Utilizzare la libreria Apache Lucene
Testare la correttezza dell'algoritmo su un piccolo insieme di tabelle, appositamente costruito
Testare l'efficacia e l'efficienza dell'algoritmo sulle tabelle contenute nel dataset ""tables"" del progetto Mentor: https://gitlab.com/Rm3UofA/Mentor/Datasets",homework implementare lalgoritmo merge list soluzione problema joinable table search utilizzare libreria apache lucene testare correttezza dellalgoritmo piccolo insieme tabelle appositamente costruito testare lefficacia lefficienza dellalgoritmo tabelle contenute dataset tables progetto mentor uof
data_test\rootfolder\varie\homework\id-homework-3.pptx#2,2,"Homework 3Ogni team deve preparare 
una presentazione di 5' per illustrare le caratteristiche del dataset 
una presentazione di 10' minuti per illustrare la valutazione sperimentale della propria implementazione dell'algoritmo ""MergeList""
Termini di consegna: entro le ore 19:00 del 2 novembre 2022 ogni membro del team deve inviare le due presentazioni al docente compilando il seguente modulo (compilare il modulo due volte, una per ciascuna presentazione):
             https://forms.office.com/r/PYP0ncXYqc 

Quattro team (scelti dal docente) presenteranno il proprio lavoro nella lezione del 3 novembre 2022


",homework ogni team deve preparare presentazione illustrare caratteristiche dataset presentazione minuti illustrare valutazione sperimentale propria implementazione dellalgoritmo merge list termini consegna entro ore novembre ogni membro team deve inviare due presentazioni docente compilando seguente modulo compilare modulo due volte ciascuna presentazione ypnc xyqc quattro team scelti docente presenteranno proprio lavoro lezione novembre
data_test\rootfolder\varie\homework\id-homework-3.pptx#3,3,"Presentazione Caratteristiche del DatasetDurata 5'
Deve riportare statistiche sul dataset ""tables"" che possano essere utili all'analisi del problema, all'implementazione dell'algoritmo di soluzione e alla sua valutazione. 
Ad esempio:
Numero di tabelle
Numero medio di righe
Numero medio di colonne
Numero medio di valori nulli per tabella
Distribuzione numero di righe (quante tabelle hanno 1, 2, 3, 4, etc. righe)
Distribuzione numero di colonne (quante tabelle hanno 1, 2, 3, 4, etc. colonne)
Distribuzione valori distinti (quante colonne hanno 1, 2, 3, 4, etc valori distinti)
Altro a vostra scelta
Presentare le statiche in maniera opportuna, anche attraverso l'uso di rappresentazioni grafiche
",presentazione caratteristiche dataset durata deve riportare statistiche dataset tables possano essere utili allanalisi problema dellalgoritmo soluzione valutazione esempio numero tabelle numero medio righe numero medio colonne numero medio valori nulli tabella distribuzione numero righe quante tabelle etc righe distribuzione numero colonne quante tabelle etc colonne distribuzione valori distinti quante colonne etc valori distinti altro scelta presentare statiche maniera opportuna attraverso luso grafiche
data_test\rootfolder\varie\homework\id-homework-3.pptx#4,4,"Presentazione Valutazione SperimentaleDurata 10'
Deve includere
Descrizione ad alto livello dell'implementazione (classi e metodi principali)
Principali problemi riscontrati nell'implementazione
Valutazione sperimentale:
Con una descrizione chiara e precisa di obiettivi e metriche di ciascun esperimento",presentazione valutazione sperimentale durata deve includere descrizione alto livello classi metodi principali principali problemi riscontrati valutazione sperimentale descrizione chiara precisa obiettivi metriche ciascun esperimento
data_test\rootfolder\varie\homework\id-homework-4.pptx#0,0,Ingegneria dei datiHomework 4(da svolgere individualmente)Paolo Merialdo,ingegneria dati homework svolgere merialdo
data_test\rootfolder\varie\homework\id-homework-4.pptx#1,1,"Homework 4 - Esercizio 1Scegliere una tipologia di prodotti su amazon.it (ad esempio fotocamere, oppure prodotti senza glutine)
Scegliere un pagina con un prodotto della tipologia scelta
Individuare nella pagina almeno 5 caratteristiche del prodotto
Scrivere un'espressione XPath per estrarre il nome, il prezzo e il valore di ciascuna delle caratteristiche individuate al punto precedente
Verificare che le espressioni XPath funzionino correttamente su almeno altre 10 pagine di prodotti della stessa categoria
Se una regola XPath non funziona, correggerla affinchè funzioni correttamente su tutte e 10 le pagine

",homework esercizio scegliere tipologia prodotti amazonit esempio fotocamere oppure prodotti senza glutine scegliere pagina prodotto tipologia scelta individuare pagina almeno caratteristiche prodotto scrivere unespressione path estrarre nome prezzo valore ciascuna caratteristiche individuate punto precedente verificare espressioni path funzionino correttamente almeno altre pagine prodotti stessa categoria regola path funziona correggerla affinch funzioni correttamente tutte pagine
data_test\rootfolder\varie\homework\id-homework-4.pptx#2,2,"Homework 4 - Esercizio 2Scegliere un tipo di entità di interesse (ad esempio, giocatori di basketball, aziende, università, etc.)
Cercare 5 sorgenti Web che pubblicano pagine di dettaglio di istanze dell'entità scelta (ad esempio siti web che pubblicano pagine di giocatori di basketball)
Su ogni sorgente scegliere 5 pagine di dettaglio
Scrivere espressioni XPath per estrarre I valori di (almeno) 5 attributi rilevanti su tutte le pagine scelte
",homework esercizio scegliere tipo entit interesse esempio giocatori basketball aziende universit etc cercare sorgenti web pubblicano pagine dettaglio istanze dellentit scelta esempio siti web pubblicano pagine giocatori basketball ogni sorgente scegliere pagine dettaglio scrivere espressioni path estrarre valori almeno attributi rilevanti tutte pagine scelte
data_test\rootfolder\varie\homework\id-homework-4.pptx#3,3,"Termini di consegnaOgni studente deve preparare individualmente una relazione in cui descrive l'attività svolta per portare a termine l'homework
Termini di consegna: entro le ore 19:00 del 19 novembre 2022 inviare la relazione al docente compilando il seguente modulo:
             https://forms.office.com/r/PYP0ncXYqc 


",termini consegna ogni studente deve preparare individualmente relazione descrive lattivit svolta portare termine lhomework termini consegna entro ore novembre inviare relazione docente compilando seguente modulo ypnc xyqc
data_test\rootfolder\varie\homework\id-homework-5.pptx#0,0,Ingegneria dei datiHomework 5(da svolgere in gruppo)Paolo Merialdo,ingegneria dati homework svolgere gruppopaolo merialdo
data_test\rootfolder\varie\homework\id-homework-5.pptx#1,1,"Homework 5Obiettivo: creare un dataset strutturato con dati estratti da sorgenti Web
Ci interessano dati su una tipologia di entità: aziende
Per semplicità, ci concentriamo su sorgenti in lingua inglese
Scrivere un programma di estrazione dati per almeno 1000 istanze da almeno 4 sorgenti web",homework obiettivo creare dataset strutturato dati estratti sorgenti web interessano dati tipologia entit aziende semplicit concentriamo sorgenti lingua inglese scrivere programma estrazione dati almeno istanze almeno sorgenti web
data_test\rootfolder\varie\homework\id-homework-5.pptx#2,2,"TecnologieE' possibile usare una delle seguenti tecnologie (ma è possibile usarne altre)

In Python: 
https://scrapy.org/ 
https://www.crummy.com/software/BeautifulSoup/
In Java: 
https://www.selenium.dev/ 
https://jsoup.org/ 

",tecnologie possibile usare seguenti tecnologie possibile usarne altre python soup java
data_test\rootfolder\varie\homework\id-homework-5.pptx#3,3,"Termini di consegnaOgni team deve preparare una presentazione così strutturata
1 minuto per illustrare come è stata scelta la tecnologia per implementare il sistema di estrazione
2 minuti per illustrare l'architettura del sistema di estrazione dati realizzato
3 minuti per illustrare le prestazioni del sistema di estrazione
4 minuti per illustrare le caratteristiche delle sorgenti e le caratteristiche del dataset ottenuto
Termini di consegna: 
entro le ore 19:00 del 9 dicembre 2022 inviare la presentazione al docente compilando il seguente modulo: https://forms.office.com/r/PYP0ncXYqc 
Il 13 dicembre, ogni team dovrà consegnare il dataset con i dati estratti al docente (in un file compresso). Ogni team può liberamente scegliere in che modo strutturare il dataset
Quattro team (scelti dal docente) presenteranno il proprio lavoro nelle lezioni del 13 e del 15 dicembre 2022
",termini consegna ogni team deve preparare presentazione cos strutturata minuto illustrare stata scelta tecnologia implementare sistema estrazione minuti illustrare larchitettura sistema estrazione dati realizzato minuti illustrare prestazioni sistema estrazione minuti illustrare caratteristiche sorgenti caratteristiche dataset ottenuto termini consegna entro ore dicembre inviare presentazione docente compilando seguente modulo ypnc xyqc dicembre ogni team dovr consegnare dataset dati estratti docente file compresso ogni team pu liberamente scegliere modo strutturare dataset quattro team scelti docente presenteranno proprio lavoro lezioni dicembre
data_test\rootfolder\varie\homework\id-homework-6.pptx#0,0,Ingegneria dei datiHomework 6(da svolgere individualmente)Paolo Merialdo,ingegneria dati homework svolgere merialdo
data_test\rootfolder\varie\homework\id-homework-6.pptx#1,1,"Homework 6Leggere uno tra questi due articoli: 
Y. Suhara et at ""Annotating Columns with Pre-trained Language Models"" (https://arxiv.org/pdf/2104.01785.pdf) 
K. Koutras et at ""Valentine: Evaluating Matching Techniques for Dataset Discovery""(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458921) 
In una relazione di circa 900 parole, descrivere: 1) descrivere  il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 
Leggere l'articolo (scientifico):
P. Konda et al. ""Magellan: Toward Building Entity Matching Management Systems"" (http://www.vldb.org/pvldb/vol9/p1197-pkonda.pdf)
In una relazione di circa 900 parole, descrivere: 1) il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 

Termini di consegna: inviare le due relazioni entro le ore 18:00 del 5 gennaio 2023 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc ",homework leggere due articoli suhara annotating columns pre trained language models koutras valentine evaluating matching techniques dataset discovery relazione circa parole descrivere descrivere problema affronta larticolo soluzioni propone limpostazione sperimentale valutazione risultati leggere larticolo scientifico konda magellan toward building entity matching management systems pkondapdf relazione circa parole descrivere problema affronta larticolo soluzioni propone limpostazione sperimentale valutazione risultati termini consegna inviare due relazioni entro ore gennaio attraverso seguente modulo online ypnc xyqc
data_test\rootfolder\varie\homework\id-homework-7.pptx#0,0,Ingegneria dei datiHomework 7(da svolgere individualmente)Paolo Merialdo,ingegneria dati homework svolgere merialdo
data_test\rootfolder\varie\homework\id-homework-7.pptx#1,1,"Homework 7L'obiettivo dell'homework è quello di valutare il sistema CERTA per la generazione di spiegazioni di diversi sistemi di Record Linkage basati su tecniche di deep learning

Seguire le istruzioni riportate a questo indirizzo:
	 https://gist.github.com/tteofili/eaaeaaa8af2d22005fe199f1dc8874ad 

Termini di consegna: entro le ore 18.00 del 21 gennaio 2023 caricare il file cvv nel seguente modulo:
	https://forms.office.com/r/PYP0ncXYqc ",homework lobiettivo dellhomework valutare sistema generazione spiegazioni diversi sistemi record linkage basati tecniche deep learning seguire istruzioni riportate indirizzo termini consegna entro ore gennaio caricare file cvv seguente modulo ypnc xyqc
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#0,0,Ingegneria dei datiHomework 8(da svolgere in gruppo)Paolo Merialdo,ingegneria dati homework svolgere gruppopaolo merialdo
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#1,1,"Homework 8L'obiettivo dell'homework è quello di integrare le sorgenti dati collezionate da tutti i team nell'homework 5 e di arricchirle con le tecniche sviluppate nell'homework 3 
Analizzare le sorgenti dati e individuare le principali eterogeneità
Definire uno schema mediato opportuno ed allineare gli schemi delle sorgenti allo schema mediato. È possibile usare:
Una soluzione custom (anche manuale)
FlexMatcher https://flexmatcher.readthedocs.io/en/latest/ 
Coma https://sourceforge.net/projects/coma-ce/  
Uno dei tool del progetto Valentine https://github.com/delftdata/valentine
Calcolare il Record linkage. E' possibile usare:
Una soluzione custom
Python Record Linkage Toolkit https://recordlinkage.readthedocs.io/en/latest/ 
Magellan https://github.com/anhaidgroup/deepmatcher
DeepMatcher (soluzione neural network) https://github.com/anhaidgroup/deepmatcher 
Ditto (soluzione neural network) https://github.com/megagonlabs/ditto 
EMT (soluzione neural network molto simile a Ditto) https://github.com/brunnurs/entity-matching-transformer 
Un sistema non supervisionato  https://github.com/uestc-db/Unsupervised-Entity-Resolution oppure https://github.com/chu-data-lab/zeroer
Arricchire i dati integrati usando le tecniche (e il dataset di tabelle) sviluppate nell'homework 3
",homework lobiettivo dellhomework integrare sorgenti dati collezionate team nellhomework arricchirle tecniche sviluppate nellhomework analizzare sorgenti dati individuare principali eterogeneit definire schema mediato opportuno allineare schemi sorgenti schema mediato possibile usare soluzione custom anche manuale flex matcher coma tool progetto valentine calcolare record linkage possibile usare soluzione custom python record linkage toolkit magellan deep matcher soluzione neural network ditto soluzione neural network soluzione neural network molto simile ditto matching transformer sistema supervisionato dbunsupervised entity resolution oppure data labzeroer arricchire dati integrati usando tecniche dataset tabelle sviluppate nellhomework
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#2,2,"Termini di consegnaPreparare un documento scritto di 4 pagine e una presentazione di 15' che descrivano:
Le caratteristiche salienti delle sorgenti
I benefici potenziali di integrare i loro dati
Lo schema mediato
Le soluzioni che avete scelto per integrare i dati
Le prestazioni (in termini id precision, recall, F-measure, tempi di calcolo, sforzo umano)
I dati tabulari che avete trovato per arricchire le informazioni integrate dalle sorgenti
Il documento e la presentazione vanno consegnati caricandoli attraverso il modulo all'indirizzo:
	https://forms.office.com/r/PYP0ncXYqc
",termini consegna preparare documento scritto pagine presentazione descrivano caratteristiche salienti sorgenti benefici potenziali integrare dati schema mediato soluzioni scelto integrare dati prestazioni termini precision recall measure tempi calcolo sforzo umano dati tabulari trovato arricchire informazioni integrate sorgenti documento presentazione vanno consegnati caricandoli attraverso modulo allindirizzo ypnc xyqc
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#0,0,"Caratteristiche del dataset tables - Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638",caratteristiche dataset tables homework federico bianchi matr andrea donato matr paolo simone matr
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#1,1,Formato del dataset,formato dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#10,10,Distribuzione numero di colonne,distribuzione numero colonne
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#11,11,Distribuzione numero di valori distinti per colonna,distribuzione numero valori distinti colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#12,12,Distribuzione percentuale di valori distinti per colonna,distribuzione percentuale valori distinti colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#2,2,Formato del dataset,formato dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#3,3,"Formato delle celle
	- Celle vuote e «None»
	- Classificazione tipi di cella",formato celle celle vuote none classificazione tipi cella
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#4,4,"Formato delle celle
	- Frequenza di termini all’interno del dataset",formato celle frequenza termini allinterno dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#5,5,"Formato delle celle
	- Frequenza di termini all’interno del dataset",formato celle frequenza termini allinterno dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#6,6,"Formato delle righe
	- Righe con celle vuote e con celle «None»",formato righe righe celle vuote celle none
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#7,7,"Formato delle colonne
	- Colonne con celle vuote e con celle «None»
	- Classificazione tipi di colonna",formato colonne colonne celle vuote celle none classificazione tipi colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#8,8,Distribuzione numero di righe,distribuzione numero righe
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#9,9,"Fun Fact
	- Tabelle con 100 righe: 5 076",fun fact tabelle righe
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#0,0,"Ingegneria Dei Dati:Valutazione Sperimentale Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638dedo99/Homework3 (github.com)Link Repository Progetto:",ingegneria dati valutazione sperimentale homework federico bianchi matr andrea donato matr paolo simone matr repository progetto
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#1,1,"Organizzazione del progetto: packageIndex
indicizzazione di tutto il file in inputModel
modello utilizzato per estrarre i dati dal datasetQuery
esecuzione delle query ed estrazione dei documenti ritenuti compatibili",organizzazione progetto package index indicizzazione file input model modello utilizzato estrarre dati dataset query esecuzione query estrazione documenti ritenuti compatibili
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#10,10,"Valutazione sperimentale del progetto (2)Tempo necessario per l’indicizzazione dell’intero file JSON contenente 550.271 tabelle (14,2 Gb): 297.882 s (c.a. 5 minuti)

Query d’esempio [«singlular», «plural», «fmou», «dual»], tempo di esecuzione:
Con SimpleTextCodec: 18 minuti
Senza SimpleTextCodec: 6 secondi",valutazione sperimentale progetto tempo necessario dellintero file contenente tabelle minuti query desempio singlular plural fmou dual tempo esecuzione simple text codec minuti senza simple text codec secondi
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#11,11,"Valutazione sperimentale del progetto (3)Per testare l’efficacia e l’efficienza del sistema sono state effettuate tre tipologie di test:

Test al variare di k

Test al variare della lunghezza della query

Precision, Recall, F1 e Accuracy su dataset di test",valutazione sperimentale progetto per testare lefficacia lefficienza sistema state effettuate tre tipologie test test variare test variare lunghezza query precision recall accuracy dataset test
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#12,12,Test al variare di k,test variare
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#13,13,Test al variare della lunghezza della query,test variare lunghezza query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#14,14,"Dataset di testÈ stato costruito un dataset per testare l’efficacia del sistema, con le seguenti caratteristiche:

30 tabelle

Ogni tabella riporta informazioni su film, libri, autori, attori, …",dataset test stato costruito dataset testare lefficacia sistema seguenti tabelle ogni tabella riporta informazioni film libri autori attori
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#15,15,Dataset di test,dataset test
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#16,16,Dataset di test: distribuzione righe,dataset test distribuzione righe
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#17,17,Dataset di test: distribuzione colonne,dataset test distribuzione colonne
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#18,18,Dataset di test: distribuzione valori distinti,dataset test distribuzione valori distinti
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#19,19,"QuerySono state costruite 23 query di test, ottenute calcolando lo score Jaccard fra tutte le possibili coppie di colonne all’interno del dataset. Ogni query di test contiene:

Colonna di valori che rappresenta la query

Top 3 colonne con score Jaccard più alto",query state costruite query test ottenute calcolando score jaccard fra tutte possibili coppie colonne allinterno dataset ogni query test contiene colonna valori rappresenta query top colonne score jaccard alto
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#2,2,Le classiIndexCellModelCoordinatesQueryJSONObjectJSONIndexerQueryManager,classi index cell model coordinates query object indexer query manager
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#20,20,Query,query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#21,21,"Precision, Recall, F1 e Accuracy",precision recall accuracy
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#22,22,"QuerySolo per una query il sistema non restituisce alcun risultato corretto:
[«USA», «USA», «USA», «USA», «USA», «USA», «USA»]

Le altre query su cui il sistema fatica a restituire il risultato corretto sono molto simili:
[«USA», «Italia», «Italia», «Francia», «Inghilterra», …]",query solo query sistema restituisce alcun risultato corretto sa sa sa sa sa sa sa altre query sistema fatica restituire risultato corretto molto simili sa italia italia francia inghilterra
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#3,3,"Classe JSONIndexer (1)La classe JSONIndexer è composta da due metodi:


readJsonStream(InputStream in, Codec codec): lettura dell’input dal file JSON


indexJSONStream(JsonReader reader, Codec codec): estrazioni degli oggetti JSON (tabelle) dal reader, parsing in un oggetto Java e successiva indicizzazione. I documenti inseriti nell’indice corrispondono ciascuno ad una colonna di una tabella.


Uso della libreria Gson per convertire rappresentazioni JSON in oggetti Java e viceversa.",classe nindexer classe nindexer composta due metodi read json streaminput stream codec codec lettura dellinput file index streamjson reader reader codec codec estrazioni oggetti tabelle reader parsing oggetto java successiva indicizzazione documenti inseriti nellindice corrispondono ciascuno colonna tabella uso libreria gson convertire oggetti java viceversa
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#4,4,"Classe JSONIndexer (2)Definizione di un Tokenizer CustomCreazione dei documentiAnalyzer analyzer = CustomAnalyzer.builder()        .withTokenizer(PatternTokenizerFactory.NAME, ""pattern"", ""~"", ""group"", ""-1"")        .build();for(Cell c : obj.getCells())    if (!c.getHeader()) {        if(colonnaXvalori.containsKey(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString())) {            String value = colonnaXvalori.get(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString());            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), value + ""~"" + c.getCleanedText());        } else            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), c.getCleanedText());    }",classe nindexer definizione tokenizer custom creazione documenti analyzer analyzer custom with tokenizer factoryn pattern group objget cells cget header ifcolonna keyobjget cget columnto string string value colonna cget columnto string colonna cget columnto string value cget cleaned text else colonna cget columnto string cget cleaned text
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#5,5,"Classi JsonObject, Cell e CoordinatesLe classi JsonObject, Cell e Coordinates sono stati realizzate per rendere agevole la trasformazione da un oggetto Json ad un oggetto Java.

Le seguenti classi sono dotate di variabili di istanza, relative alle sole informazioni necessarie rispetto al completo contenuto dell’oggetto Json, e i corrispondenti metodi setter e getter.public class JSONObject {
 String id;
 Cell[] cells;
}public class Cell {
 Boolean isHeader;
 String cleanedText;
 Coordinates Coordinates;
}public class Coordinates {
 Double row;
 Double column;
}",classi json object cell coordinates classi json object cell coordinates stati realizzate rendere agevole trasformazione oggetto json oggetto java seguenti classi dotate variabili istanza relative sole informazioni necessarie rispetto completo contenuto delloggetto json corrispondenti metodi setter getterpublic class nobject string cell cells public class cell boolean header string cleaned text coordinates coordinates public class coordinates double row double column
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#6,6,"Classe QueryManager
mergeList(int n, String[] queryString) restituisce le prime n colonne tra tutte le tabelle che hanno corrispondenze con il maggior numero di termini nella query

executeQuery(String field, String[] queryString) genera una mappa (idTabella_idcolonna -> numero corrispondenze) scansionando tutti gli elementi presenti nella query

sortMapByValues(Map<String, Integer> columnsXcount) effettua l’ordinamento della mappa sull’intero contenuto nel campo valore

runQuery(IndexSearcher searcher, Query query,  Map<String, Integer> columnsXcount) restituisce per ciascun elemento della query una mappa con le colonne delle tabelle in cui è presente

",classe query manager merge listint string query string restituisce prime colonne tutte tabelle corrispondenze maggior numero termini query execute querystring field string query string genera mappa numero corrispondenze scansionando elementi presenti query sort map integer columns xcount effettua lordinamento mappa sullintero contenuto campo valore run queryindex searcher searcher query query mapstring integer columns xcount restituisce ciascun elemento query mappa colonne tabelle presente
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#7,7,"Problemi riscontratiIndividuare la corretta rappresentazione dei documenti nell’indice

Individuare un modo corretto di tokenizzare i documenti (nello specifico il campo ‘value’)

Tempi di indicizzazione",problemi riscontrati individuare corretta documenti nellindice individuare modo corretto tokenizzare documenti nello specifico campo value tempi indicizzazione
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#8,8,"ObiettiviImplementare nel modo più efficiente l’indicizzazione di una grande quantità di dati

Restituire, a seguito di una query, le tabelle con la relativa colonna in cui sono state incontrate delle corrispondenze senza includere nel conteggio eventuali ripetizioni dello stesso termine nella colonna 

Restituire in ordine decrescente i risultati sulla base del numero di corrispondenze ottenute",obiettivi implementare modo efficiente grande quantit dati restituire seguito query tabelle relativa colonna state incontrate corrispondenze senza includere conteggio eventuali ripetizioni stesso termine colonna restituire ordine decrescente risultati base numero corrispondenze ottenute
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#9,9,"Valutazione sperimentale del progetto (1)Tutti i risultati sono stati ottenuti utilizzando un calcolatore con le seguenti specifiche:

Processore Intel core i7 di 8° gen

RAM 8Gb

SSD 512Gb",valutazione sperimentale progetto tutti risultati stati ottenuti utilizzando calcolatore seguenti specifiche processore intel core gen
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#0,0,"Web Scraping:Scraping business informationDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
13 Dicembre 2022Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselGitHub: Web Scraping- Homework5",web scraping scraping business information dipartimento ingegneria corso laurea magistrale ingegneria informatica anno accademico dicembre corso ingegneria dati professore paolo merialdo studenti paolo simone pietro baroni matteo wissel git hub web scraping homework
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#1,1,"Purpose del progettoIntroduzioneAutomatizzazione della ricerca ed estrazione di informazioni relative ad aziende


Utilità

Creazione di un dataset relativo ad aziende per diversi task:
Addestramento modello AI
Analytics

Data IntegrationScopo",purpose progetto introduzione ricerca estrazione informazioni relative aziende utilit creazione dataset relativo aziende diversi task addestramento modello analytics data integration scopo
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#10,10,Sorgente: gov.ukLilla System,sorgente govuk lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#11,11,Sorgente: gov.ukLilla System,sorgente govuk lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#12,12,"Efficacia X-Paths: Data ConsistencyAnalisi pattern

Address, Business code, Business name (E-business), Date, ecc…

Analisi frequenza valori celle 
Legal form, Status, ecc…



Analisi frequenza token 
Business name, ecc…Lilla System",efficacia paths data consistency analisi pattern address business code business name business date ecc analisi frequenza valori celle legal form status ecc analisi frequenza token business name ecclilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#13,13,"Efficacia X-Paths: Analisi PatternTable: GOV.UK

Field: Address

Example values: '38SpringfieldRoad Gillingham Kent England ME71YJ’



    
Regex: 
	([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|
	(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|
	([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\s?[0-9][A-Za-z]{2})
UK Postal codeLilla System",efficacia paths analisi pattern table ovu field address example values springfield road gillingham kent england yj regex ggiirr aaa postal code lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#14,14,"Efficacia X-Paths: Analisi PatternIndirizzi non conformi

Austrasse429490 Vaduz Liechtenstein

Pasiadou5KatoLakatamia 2332Nicosia Nicosia Cyprus

LaChausseeStreet PortLouis MauritiusLilla System",efficacia paths analisi pattern indirizzi conformi austrasse vaduz liechtenstein pasiadou kato lakatamia nicosia nicosia cyprus chaussee street port louis mauritius lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#15,15,"Efficacia X-Paths: Frequenza ValoriTable: E-Business

Field: Legal form

Example values:
Private limited company, Public limited company, Non-profit association, ecc…


    
Lilla System",efficacia paths frequenza valori table business field legal form example values private limited company public limited company profit association ecc lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#16,16,Efficacia X-Paths: Frequenza ValoriLilla System,efficacia paths frequenza valori lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#17,17,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Example values: P & A PROPERTY (WESTON) LIMITED, P A JONES LIMITED, P A H 		       CARPENTRY & JOINERY LTD  

	
    
Lilla System",efficacia paths frequenza token table ovu field name example values lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#18,18,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Most frequent tokens:
Limited, LTD,LTD., Services, …


    
Analisi

1466 su 1469 hanno nel loro nome 
      i 10 token più frequenti
1 ) LIMITED -> 728
2 ) LTD -> 533
3 ) SERVICES -> 94
4 ) ELECTRICAL -> 38
5 ) CONSTRUCTION -> 37
6 ) BUSINESS -> 36
7 ) CORP. -> 35
8 ) PROPERTIES -> 34
9 ) HOMES -> 27
10 ) LTD. -> 26
Lilla System",efficacia paths frequenza token table ovu field name frequent tokens limited tdl services analisi nome token frequenti lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#19,19,"Test sistema: WorkflowIl sistema è stato testato nel seguente modo:
Campionamento casuale del dataset estratto:
Companiesmarketcap  30 URL
Infoclipper  50 URL
GovUK  29 URL
Ebusiness  30 URL
Estrazione manuale dei dati contenuti nel campione selezionato
Confronto dati estratti dal sistema e dati ottenuti manualmente
Lilla System",test sistema workflow sistema stato testato seguente modo campionamento casuale dataset estratto infoclipper gov ebusiness estrazione manuale dati contenuti campione selezionato confronto dati estratti sistema dati ottenuti manualmente lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#2,2,"Ricerca sitiFiltraggio sitiSchema datiParsing dati &
Data ConsistencyAcquisizione datiAnalisi datiRoad mapIntroduzione",ricerca siti filtraggio siti schema dati parsing dati data consistency acquisizione dati analisi dati road map introduzione
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#20,20,"Test sistema: companiesmarketcap.comLilla SystemErrori dovuti esclusivamente alla variabilità giornaliera dei campi
",test sistema lilla system errori dovuti esclusivamente variabilit giornaliera campi
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#21,21,Test sistema: e-BusinessLilla System,test sistema business lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#22,22,Test sistema: info-clipper.comLilla System,test sistema info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#23,23,"Test sistema: info-clipper.comLilla SystemPostalcode
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {187’, 00187’} 
State
Nel nostro sistema nel campo state inseriamo anche la sigla dello stato, nei test l’utente non inserisce nel campo State la sigla  {'California(CA)', 'California'} ",test sistema info clippercom lilla system postalcode differenze dovute fatto celle formattate intere eliminano sinistra stringa state sistema campo state inseriamo sigla stato test lutente inserisce campo state sigla californiac california
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#24,24,Test sistema: gov.ukLilla System,test sistema govuk lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#25,25,"Test sistema: gov.ukLilla SystemCompany ID
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {'6174105', '06174105’} 
Company Status
Gli errori sono dovuti al cambiamento di status dell’azienda  {'Active', 'Dissolved'}
Dissolution Date
L’azienda nel frattempo è stata dissolta  {'nan', 14 February 2023 '} 
",test sistema govuk lilla system company differenze dovute fatto celle formattate intere eliminano sinistra stringa company status errori dovuti cambiamento status dellazienda active dissolved dissolution date lazienda frattempo stata dissolta nan february
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#26,26,"Efficienza temporale: Estrazione datiTempo complessivo

Tempo di request 

Tempo di estrazione del dato (navigazione del dom via X-Path)
Lilla System",efficienza temporale estrazione dati tempo complessivo tempo request tempo estrazione dato navigazione dom via path lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#27,27,Efficienza temporale: RequestLilla System,efficienza temporale request lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#28,28,"Efficienza temporale: Estrazione datiLilla System//div[@class = ""company-code""]//*[@id=""cmkt""]/div[3]/div[1]/div[2]/div[3]/div[1]/a/text()",efficienza temporale estrazione dati lilla company
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#29,29,Dataset: companiesmarketcap.comLilla System,dataset lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#3,3,"
Beautiful soup

Request

LXML & Etree
Web ScrapingPandas & numpy                    	
Matplotlib

Geopandas
Data ProfilingTecnologieLilla SystemPython",beautiful soup request etree web scraping pandas numpy matplotlib geopandas data profiling tecnologie lilla system python
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#30,30,"Dataset: companiesmarketcap.com   Analisi campi

Name: Nome dell’azienda
Company Code: Codice identificativo delle società quotate in borsa (WMT, AMZN, UPS, KR, …)
Marketcap: Somma del valore totale delle azioni in circolo
Share Price: Costo singola azione
Earnings: Profitto annuo
Revenue: Ricavi annui
Shares: Numero totale di azioni in circolo
Employees: Numero totale di dipendenti


  Numeriche generali

Totale istanze: 1400
Totale colonne: 10


Celle totali: 14000
Valori nulli: 21Lilla System",dataset analisi campi name nome dellazienda company code codice identificativo societ quotate borsa marketcap somma valore totale azioni circolo share price costo singola azione earnings profitto annuo revenue ricavi annui shares numero totale azioni circolo employees numero totale dipendenti numeriche generali totale istanze totale colonne celle totali valori nulli lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#31,31,Dataset: companiesmarketcap.comLilla System,dataset lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#32,32,Dataset: companiesmarketcap.comLilla System,dataset lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#33,33,Dataset: e-BusinessLilla System,dataset business lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#34,34,"Dataset: e-BusinessAnalisi campi

Name: Nome dell’azienda
Company code: Codice identificativo dell’azienda
Legal Form: Forma giuridica dell’azienda
Status: Status dell’azienda (Deleted, Entered into the register, ecc…)
Registration Date: Data di inserimento dell’azienda nel registro
Capital: Capitale dell’azienda
Address: Indirizzo sede dell’azienda
Deletion Time: Data di eliminazione dell’azienda dal registro

  Numeriche generali

Totale istanze: 1469
Totale colonne: 10



Celle totali: 14690
Valori nulli: 2120 Lilla System",dataset business analisi campi name nome dellazienda company code codice identificativo dellazienda legal form forma giuridica dellazienda status status dellazienda deleted entered register ecc registration date data inserimento dellazienda registro capital capitale dellazienda address indirizzo sede dellazienda deletion time data eliminazione dellazienda registro numeriche generali totale istanze totale colonne celle totali valori nulli lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#35,35,Dataset: e-BusinessLilla System,dataset business lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#36,36,Dataset: e-BusinessESTONIALilla System,dataset business alilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#37,37,"Dataset: info-clipper.comAnalisi campi

Name: Nome dell’azienda
Trade Name: Nome commerciale dell’azienda
Address: Indirizzo sede dell’azienda
City: Città 
Postalcode: Codice postale nei formati UK, USA, Italia, Estonia
State: Stato Americano di residenza o Nazione di residenza
Country: Nazione di residenza
Location type: Tipo di sede (es. Headquarter, Secondary Office, ecc…)



  Numeriche generali

Totale istanze: 1504
Totale colonne: 10



Celle totali: 15040
Valori nulli: 1289Lilla System",dataset info clippercom analisi campi name nome dellazienda trade name nome commerciale dellazienda address indirizzo sede dellazienda city citt postalcode codice postale formati italia estonia state stato americano residenza nazione residenza country nazione residenza location type tipo sede headquarter secondary office ecc numeriche generali totale istanze totale colonne celle totali valori nulli lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#38,38,"Dataset: info-clipper.com


Lilla System",dataset info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#39,39,"Dataset: info-clipper.com


STATI UNITILilla System",dataset info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#4,4,"Lilla
SystemGeneral web pageRequest: get informationResponse: list of linksRequest: get all linksResponse:  informationCreate datasetSpecific web pageDatasetData Parsing and
Data ConsistencyArchitetturaLilla System",lilla system general web page request get information response list links request get links response information create dataset specific web page dataset data parsing data consistency architettura lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#40,40,"Dataset: info-clipper.com


ESTONIALilla System",dataset info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#41,41,"Dataset: info-clipper.com


ITALIALilla System",dataset info clippercom alilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#42,42,"Dataset: info-clipper.com


INGHILTERRALilla System",dataset info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#43,43,"Analisi campi

Name: Nome dell’azienda
Company ID: Codice identificativo dell’azienda
Company Status: Status dell’azienda (Active, Dissolved, Registered, Liquidated)
Company Type: Tipo dell’azienda (Overseas Entity, Private Limited Company, ecc…)
Registration Date: Data di registrazione di aziende estere
Incorporation Date: Data di inserimento delle aziende inglesi nel registro
Dissolution Date: Data di dissoluzione dell’azienda
Office Address: Indirizzo dell’azienda


Dataset: gov.uk  Numeriche generali

Totale istanze: 1331
Totale colonne: 10



Celle totali: 13310
Valori nulli: 2555Lilla System",analisi campi name nome dellazienda company codice identificativo dellazienda company status status dellazienda active dissolved registered liquidated company type tipo dellazienda overseas entity private limited company ecc registration date data registrazione aziende estere incorporation date data inserimento aziende inglesi registro dissolution date data dissoluzione dellazienda office address indirizzo dellazienda dataset govuk numeriche generali totale istanze totale colonne celle totali valori nulli lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#44,44,Dataset: gov.ukLilla System,dataset govuk lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#45,45,Dataset: gov.ukREGNO UNITOLilla System,dataset govuk lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#46,46,Dataset: gov.ukINGHILTERRALilla System,dataset govuk alilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#47,47,"Member: Pietro Baroni
Matricola: 536373
Task: Algoritmi
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Task: Analytics
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693 
Task: AlgoritmiLinkedin: Matteo WisselTeamLilla System",member pietro baroni matricola task algoritmi linkedin pietro baroni member paolo simone matricola task analytics linkedin paolo simone member matteo wissel matricola task algoritmi linkedin matteo wissel team lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#48,48,"GRAZIE PER L’ATTENZIONERoma, 13  Dicembre 2022GitHub: Web Scraping- Homework5",la eroma dicembre git hub web scraping homework
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#5,5,Sorgente: companiesmarketcap.comLilla System,sorgente lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#6,6,Sorgente: ariregister.rik.ee (e-Business)Lilla System,sorgente businesslilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#7,7,Sorgente: ariregister.rik.ee (e-Business)Lilla System,sorgente businesslilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#8,8,Sorgente: info-clipper.comLilla System,sorgente info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#9,9,Sorgente: info-clipper.comLilla System,sorgente info clippercom lilla system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#0,0,"Data integration:Arlecchino systemDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
22 Febbraio 2023Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselArlecchino System
",data integration arlecchino system dipartimento ingegneria corso laurea magistrale ingegneria informatica anno accademico febbraio corso ingegneria dati professore paolo merialdo studenti paolo simone pietro baroni matteo wissel arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#1,1,"Purpose del progettoIntroduzioneUse Case

Integrazione di dataset aziendaliScopo

Implementazione di un sistema di Data IntegrationDataset

Dataset_Corso_Ingegneria_dei_Dati_2022/23
",purpose progetto introduzione use case integrazione dataset aziendali scopo implementazione sistema data integration dataset dataset corso ingegneriadei dati
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#10,10,"ParsingArlecchino SystemParsing nomi colonne
Trasformazione in lower case  
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)  Parsing valori celle 

Parsing di stringhe: 
Trasformazione in lower case
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)
Esempio: Amazon -> amazon
  
Parsing di valori monetari:
Normalizzazione valori 
Inserimento unità di misura
Esempio: $102 million -> doll_ 0.102 b 

Parsing valori percentuali
Parsing valori rank
Parsing valori date
",parsing arlecchino system parsing nomi colonne trasformazione lower case eliminazione caratteri speciali eliminazione skip words the del parsing valori celle parsing stringhe trasformazione lower case eliminazione caratteri speciali eliminazione skip words the del esempio amazon amazon parsing valori monetari normalizzazione valori inserimento unit misura esempio million doll parsing valori percentuali parsing valori rank parsing valori date
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#11,11,Schema matching: Formulazione problemaArlecchino System,schema matching formulazione problema arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#12,12,"Schema Matching: Matching Module (SMM)Arlecchino SystemPre-processing module

Input: colonne e samples di valori 
Output: un dizionario parziale di sinonimi
Utilità: 1. riduzione del search space del JaccardModule
    2. inferisce informazioni al JaccardModule  
JaccardModule

Input: dizionario sinonimi_preprocessing
Output: dizionario sinonimi_finale
Utilità: trova le reali correlazioni semantiche tra le colonneUser",schema matching matching module mmarlecchino system pre processing module input colonne samples valori output dizionario parziale sinonimi utilit riduzione search space jaccard module inferisce informazioni jaccard module jaccard module input dizionario output dizionario sinonimifinale utilit trova reali correlazioni semantiche colonne user
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#13,13,"SMM: MotivazioniArlecchino SystemAnalisi senza pre-processingAnalisi con pre-processingSample data: 1000 per colonna
Colonne totali: 18
Numero medio di sinonimi reali: 1.6 

Stima confronti totali: ≈ 153
Numero medio confronti per colonna: ≈ 18
Numero medio di confronti inutili: ≈ 17
Esempio 
cluster cbinsightsSample data: 1000 per colonna

Colonne totali: 18

Numero medio di sinonimi reali: 1.6

Stima confronti totali: 14
Numero medio confronti per colonna:  2.5
Numero medio di confronti inutili: 0.84

Fattore di riduzione: ≈ 12",motivazioni arlecchino system analisi senza pre processing analisi pre processing sample data colonna colonne totali numero medio sinonimi reali stima confronti totali numero medio confronti colonna numero medio confronti inutili esempio cluster cbinsights sample data colonna colonne totali numero medio sinonimi reali stima confronti totali numero medio confronti colonna numero medio confronti inutili fattore riduzione
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#14,14,"Pre-processing: Name SimilarityArlecchino SystemName similarity di colonne

Input: (column_names, dizionario_sinonimi_pregressi)
Output: un dizionario parziale di sinonimi
Utilità: individua i sinonimi schema-wise 
	(dettati da similarità di nome)Logica:	
",pre processing name similarity arlecchino system name similarity colonne input columnnames output dizionario parziale sinonimi utilit individua sinonimi schema wise dettati similarit nomelogica
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#15,15,"Pre-processing: Data CorrelationArlecchino System

Data similarity di colonne [1]

Input: (sample_dati_colonne)
Output: un dizionario sinonimi4cluster
Utilità: individua i sinonimi data-wise
	(dettati da similarità di dati) [1] Schema Matching using Machine LearningTanvi Sahay, Ankita Mehta, Shruti Jadon",pre processing data correlation arlecchino system data similarity colonne input output dizionario utilit individua sinonimi data wise dettati similarit dati schema matching using machine learning tanvi sahay ankita mehta shruti jadon
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#16,16,"SMM: Features EngineeringArlecchino SystemFeatures selezionate
Min_val
Max_val
Avg
Variance
Standard_Dev
Is_incremental
Is_year Type_of_string (1 perc_, 2 rank_, 3 link, 4-5 monetari, 6 resto)
AVG_monetary_value
AVG_len_of_field
VAR_len_of_field
SDEV_len_of_field
Ratio_white_space
Ratio_numeric_values
Is_country (1 se country, 0 altrimenti)
Is_sector (1 se sector, 0 altrimenti)1. Type_of_data (0 string, 1 integer, 2 date)for Integerfor stringsfor date",features engineering arlecchino system features selezionate minval maxval avg variance standard dev isincremental isyear typeofstring perc rank link monetari resto vglenoffield arlenoffield vlenoffield iscountry country altrimenti issector sector altrimenti typeofdata string integer datefor integerfor stringsfor date
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#17,17,"Pre-processing: Analisi OutputArlecchino SystemDizionario sinonimi_preprocessing (largo)

Unione dei dizionari di sinonimi prodotti dai due step di pre-processing
Scopo: limitare eventuali errori (high recall)
Esempio (companiesmarketcap):
Token: market_cap

True_sinonimi
	market_cap->{marketcap, market_capitalization, pricecap, …}
sinonimi4NameCorr
	market_cap->{marketcap, market_capitalization,…}

sinonimi4Clusters
	market_cap->{marketcap, pricecap, …}

sinonimi_preprocessing
	market_cap->{marketcap, market_capitalization, pricecap, …}
",pre processing analisi output arlecchino system dizionario largo unione dizionari sinonimi prodotti due step pre processing scopo limitare eventuali errori high recall esempio token marketcap truesinonimi marketcap marketcap pricecap sinonimi name corr marketcap marketcap sinonimi clusters marketcap marketcap pricecap marketcap marketcap pricecap
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#18,18,"SMM: JaccardModuleArlecchino SystemJaccardModule

Input: sinonimi_preprocessing

Logica: per ogni colonna c presente nel dizionario dei sinonimi_preprocessing, il sistema genera un file .csv contenente tutte le colonne giudicate sinonimi",jaccard module arlecchino system jaccard module input logica ogni colonna presente dizionario sistema genera file csv contenente tutte colonne giudicate sinonimi
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#19,19,"SMM: OutputArlecchino SystemDizionario sinonimi finali

Risultato finale del Matching module
Per ogni colonna dello schema mediato è definita  una lista di  possibili sinonimi (colonne semanticamente simili)

L’utente seleziona i match opportuni eliminando eventuali errori del sistema

Al netto della validazione dell’utente, il sistema aggiorna il dizionario dei sinonimi pregressi


User",output arlecchino system dizionario sinonimi finali risultato finale matching module ogni colonna schema mediato definita lista possibili sinonimi colonne semanticamente simili lutente seleziona match opportuni eliminando eventuali errori sistema netto validazione dellutente sistema aggiorna dizionario sinonimi pregressi user
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#2,2,Caratteristiche dei sorgenti: ClusterSorgenti	,caratteristiche sorgenti cluster sorgenti
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#20,20,Schema MediatoArlecchino System,schema mediato arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#21,21,"Record LinkageArlecchino SystemInput: schema mediato (184.587 record)

Output: dataset finale

Scopo: Trovare nella tabella in input i record relativi alla stessa entità ed unirli in un unico record

 Record Linkage
",record linkage arlecchino system input schema mediato record output dataset finale scopo trovare tabella input record relativi stessa entit unirli unico record record linkage
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#22,22,"Record Linkage: BlockingArlecchino SystemNumero di confronti iniziali: 34.072.360.569 Numero di confronti post-blocking: 2.177.713Tempi: 76 min 36 secBlocking step1. overlap di una parola nel nome delle aziende

2. overlap di una parola nel paese delle aziende (se presente)

3. Indice di Levenshtein < 0.7 tra i nomi
 delle aziende

",record linkage blocking arlecchino system numero confronti iniziali numero confronti post blocking tempi min sec blocking step overlap parola nome aziende overlap parola paese aziende presente indice levenshtein nomi aziende
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#23,23,"Record Linkage: Training SetArlecchino SystemTotale record: 1300

Divisi in training set, test set e validation set (ratio 3:1:1)

Label Match: 695

Label No-Match: 605

Training set",record linkage training set arlecchino system totale record divisi training set test set validation set ratio label match label match training set
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#24,24,"Record Linkage: Model TrainingArlecchino SystemIperparametri:
Epoche = 10
Dimensione batch = 16 
Statistiche:
Tempo impiegato: 10 min 29 secModello utilizzato: Matching Model di Deep MatcherModel Training",record linkage model training arlecchino system iperparametri epoche dimensione batch statistiche tempo impiegato min sec modello utilizzato matching model deep matcher model training
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#25,25,"Record Linkage: PredictionArlecchino SystemStatistiche:
Predizioni effettuate: 2.177.713
Predizioni Match: 1.480.727
Tempo impiegato: 14 ore e 45 minuti
Utilizzo del modello addestrato per eseguire le predizioni sulle coppie non bloccatePrediction",record linkage prediction arlecchino system statistiche predizioni effettuate predizioni match tempo impiegato ore minuti utilizzo modello addestrato eseguire predizioni coppie bloccate prediction
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#26,26,Record Linkage: JoinArlecchino System,record linkage join arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#27,27,Schema IntegratoArlecchino System,schema integrato arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#28,28,"ArricchimentoColonna usate come input:
Nome dell’azienda
CEO dell’aziendaTabelle con più occorrenze in output:
List of S&P 500 companies
List of largest companies by revenue
List of largest European manufacturing companies by revenue
List of multinationals with research and development centres in Israel
List of largest Nordic companies
Automotive industryPMF system(HW3)Top table ids Dataset utenteinput (Schema mediato, 
[name, ceo] )Indice HW3Arlecchino System",arricchimento colonna usate input nome dellazienda dellazienda tabelle occorrenze output list companies list largest companies revenue list largest european manufacturing companies revenue list multinationals research development centres israel list largest nordic companies automotive industry system wtop table ids dataset utenteinput schema mediato name ceo indice arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#29,29,Schema ArricchitoArlecchino System142 celle riempite,schema arricchito arlecchino system celle riempite
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#3,3,Caratteristiche dei sorgenti: ClusterSorgenti	,caratteristiche sorgenti cluster sorgenti
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#30,30,"Testing SMM: MetricheArlecchino SystemLogica

 Confronto tra i sinonimi computati per una colonna dello schema mediato S e i sinonimi veri S’

Metriche

Numero di confronti inutili effettuato per sorgente

Similarità tra sinonimi computati:
Precision
Recall
F1",testing metriche arlecchino system logica confronto sinonimi computati colonna schema mediato sinonimi veri metriche numero confronti inutili effettuato sorgente similarit sinonimi computati precision recall
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#31,31,Testing: Pre-Processing per clustering (Conf.)Arlecchino System,testing pre processing clustering system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#32,32,Testing: performance SMM clusterArlecchino System,testing performance cluster arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#33,33,"Testing: Pre-Processing per clusteringArlecchino SystemRisultati
",testing pre processing clustering arlecchino system risultati
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#34,34,"Testing: JaccardModule for cluster Arlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0.5 ",testing jaccard module cluster arlecchino system configurazione threshold jaccard threshold edit
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#35,35,Testing: Pre-processing for schema mediatoArlecchino SystemRisultati,testing pre processing schema mediato arlecchino system risultati
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#36,36,Testing: performance SMM schema finaleArlecchino System,testing performance schema finale arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#37,37,"Testing: Schema MediatoArlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0..5Pre-processingJaccardModule",testing schema mediato arlecchino system configurazione threshold jaccard threshold edit pre processing jaccard module
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#38,38,Testing: Record LinkageArlecchino System,testing record linkage arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#39,39,MiglioramentiArlecchino System,miglioramenti arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#4,4,Caratteristiche dei sorgenti: ClusterSorgenti	,caratteristiche sorgenti cluster sorgenti
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#40,40,"Member: Pietro Baroni
Matricola: 536373
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693Linkedin: Matteo WisselTeamArlecchino System",member pietro baroni matricola linkedin pietro baroni member paolo simone matricola linkedin paolo simone member matteo wissel matricola linkedin matteo wissel team arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#41,41,"GRAZIE PER L’ATTENZIONERoma, 22 Febbraio 2023GitHub: Arlecchino System",la eroma febbraio git hub arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#5,5,"Analisi dei sorgentiDati finanziari
Dati giuridici
Dati geografici
Dati di personale
Etichette tipologie datiSorgenti	",analisi sorgenti dati finanziari dati giuridici dati geografici dati personale etichette tipologie dati sorgenti
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#6,6,"Struttura dello schema mediato Schema mediatoVisione unificata delle informazioni


Schema mediato
Benefici",struttura schema mediato schema mediato visione unificata informazioni schema mediato benefici
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#7,7,Arlecchino SystemArlecchino System…,arlecchino system arlecchino system
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#8,8,"TecnologieArlecchino SystemSchema Matching

Preprocessing Module - custom
JaccardModule - customRecord Linkage

Magellan (py_entitymatching)
DeepMatcherData Enrichment

 Sistema HW3",tecnologie arlecchino system schema matching preprocessing module custom jaccard module custom record linkage magellan deep matcher data enrichment sistema
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#9,9,ArchitetturaArlecchino SystemParsing&CleaningSchema MatchingRecord Linkage,architettura arlecchino system schema matching record linkage
