path,page,text
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#0,0,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Notazione asintotica
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#1,1,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#10,10,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione O-grande
• Denotiamo O( g(n)) (“O grande di gdi n”) l’insieme 
delle funzioni “ limitate superiormente da g(n) ”
• Definite come segue:
• Oppure, più formalmente:f(n) ∈O(g(n)) ⇔esistono due costanti positive c
edn0tali che per ogni n≥n0si verifica
0 ≤f(n) ≤c ⋅g(n)f(n) ∈O(g(n)) ⇔esistono due costanti positive c
edn0tali che per ogni n≥n0si verifica
0 ≤f(n) ≤c ⋅g(n)
O(g(n)) = { f(n) : ∃c> 0, ∃n0> 0, tali che ∀n≥n0 
0 ≤f(n) ≤c ⋅g(n)}O(g(n)) = { f(n) : ∃c> 0, ∃n0> 0, tali che ∀n≥n0 
0 ≤f(n) ≤c ⋅g(n)}"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#11,11,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione O-grande
n0c ⋅g(n)
f(n)
n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#12,12,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itOsservazioni sulla definizione di O( g(n))
•O ( g(n)) = ∅(l’insieme vuoto) se g(n) è una 
funzione asintoticamente negativa
– conveniamo che g(n) non sia mai asintoticamente 
negativa
• Le costanti ced n0dipendono dalla specifica f(n)
• Qual è il ruolo della costante c?
– se la costante cnon ci fosse 
• correttamente avremmo 2 n∈O(n2)
• ma avremmo anche 2 n∉O(n), oppure n2+1 ∉O(n2)
• Vale la proprietà riflessiva: g(n) ∈O(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#13,13,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni limitate superiormente da g(n)
O(g(n))
g(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#14,14,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsempio di funzione ∈O(n2)
• dimostriamo che      n2–3n∈O(n2)
– dobbiamo trovare almeno una c > 0 ed una n0> 0 tali che
∀n≥n0,  0  ≤f(n) ≤c ⋅g(n)
0  ≤ n2–3n≤c ⋅n2
– dividiamo per n2e otteniamo 
– proviamo a fissare c=
è soddisfatta per   n> 0
è soddisfatta per   n≥6
– dunque c = 0.5 e n0= 6 dimostrano l’asserto21
21
0≤21–n3≤c
2 21–n3≤1
0≤21–n321"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#15,15,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsempio di funzione ∈O(n2)
-20020406080
0123456789 1 0 1 1n2 -3n21n0
2n2"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#16,16,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itGeneralizzazione
•p e r  c1>0 e c2>0 si ha c1nk–c2nk-1∈O(nk)
– dobbiamo trovare almeno una c> 0 ed una n0> 0 tali che
∀n≥n0,  0  ≤f(n) ≤c ⋅g(n)
0 ≤c1nk–c2nk-1≤c ⋅nk
– dividiamo per nk e otteniamo:
– proviamo a fissare c= c1
è soddisfatta per   n≥0
è soddisfatta per   n≥
– dunque la coppia c = c1e n0=  c2/c1dimostrano l’asserto0≤c1–nc2≤c
0≤c1–nc2c1–nc2≤c1
c1c2"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#17,17,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizio: n3∉O(n2)
• dimostriamo che n3∉O(n2)
– dovremmo trovare ced n0tali che
∀n≥n0, 0 ≤f(n) ≤c ⋅g(n)
0  ≤n3≤c ⋅n2
– dividiamo per n2
0 ≤n≤c
– assurdo
• quale che sia cesiste sempre un valore di nper cui n> c
• analogamente, è facile dimostrare che 
nk+1∉O(nk) "
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#18,18,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizio: n2∈O(n3)
• dimostriamo, viceversa che n2∈O(n3)
– dobbiamo trovare ced n0tali che
∀n≥n0, 0 ≤f(n) ≤c ⋅g(n)
0  ≤n2≤c ⋅n3
– dividiamo per n2
0 ≤1 ≤c ⋅n
– che è soddisfatta, per esempio, per c= 1 ed n0= 1
• analogamente, è facile dimostrare che 
nk∈O(nk+1) "
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#19,19,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni incommensurabili
• è sempre vero che: f(n) ∈O(g(n)) 
oppure: g(n) ∈O(f(n)) ? 
• consideriamo le seguenti funzioni
• poiché n2∉O(n)
–f(n) ∉O(g(n)) per via degli npari
–g(n) ∉O(f(n)) per via degli ndispari=pari è  sedispari è  se)(2n nn nnf
=
pari è  sedispari è  se)(2
n nn nng"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#2,2,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione Asintotica
• Definizioni
• Proprietà delle notazioni asintotiche 
• Uso esteso (o improprio) della notazione"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#20,20,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itDue funzioni incommensurabili
020040060080010001200140016001800
1
3
5
7
9
1113
15
171921
23
25
27
2931
33
353739g(n)
f(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#21,21,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsploriamo O( g(n))
• quali funzioni (oltre a g(n)) sono in O( g(n)) ?
O(g(n))
g(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#22,22,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni in O( g(n))
• dimostriamo che appartengono ad O( g(n)) le 
seguenti funzioni f(n): 
proprietà transitiva
f(n) ∈O(h(n))   per quanche   h(n) ∈O(g(n))
regola dei fattori costanti positivi
f(n) = d·h(n)   per qualche   h(n) ∈O(g(n)) e d> 0
regola della somma
f(n) = h(n) + k(n)   con   h(n) e k(n) ∈O(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#23,23,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itProprietà transitiva
• dimostriamo che:
• per ipotesi
∃c'> 0, ∃n'0> 0, t.c. ∀n≥n'0, 0 ≤f(n) ≤c'⋅h(n)
∃c"" > 0, ∃n""0> 0, t.c. ∀n≥n""0, 0 ≤h(n) ≤c""⋅g(n)
• componendo le due
0 ≤f(n) ≤c'⋅c""⋅g(n)
• e dunque
∃c'"" > 0, ∃n'""0> 0, t.c. ∀n≥n'""0, 0 ≤f(n) ≤c'""⋅g(n) 
con c'"" = c' ⋅c"" e con n'""0= max( n'0,n""0)()
()())( )(
)( )()( )(
ng nf
ng nhnh nf
Ο∈ ⇒

Ο∈∧Ο∈"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#24,24,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itRegola dei fattori costanti positivi
•s e  d> 0 è una costante
f(n) ∈O(g(n)) ⇔ d·f(n) ∈O(g(n))
• infatti, per ipotesi si ha:
∃c> 0, ∃n0> 0, t.c. ∀n≥n0, 0 ≤f(n) ≤c⋅g(n)
• definisco 
c’=  c⋅d(c’ > 0 dato che d> 0)
• sostituendo c= c’/dottengo
∃c’ > 0, ∃n0> 0, t.c. ∀n≥n0, 0 ≤f(n) ≤c’/d⋅g(n)
• finalmente moltiplicando per d
∃c’ > 0, ∃n0> 0, t.c. ∀n≥n0, 0 ≤d⋅f(n) ≤c’⋅g(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#25,25,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itRegola della somma
• dimostriamo che:
• per ipotesi
∃c'> 0, ∃n'0> 0, t.c. ∀n≥n'0, 0 ≤h(n) ≤c'⋅g(n)
∃c"" > 0, ∃n""0> 0, t.c. ∀n≥n""0, 0 ≤k(n) ≤c""⋅g(n)
• sommando le due disequazioni si ottiene
0 ≤h(n) + k(n) ≤c'⋅g(n) +c""⋅g(n)
• da cui
∃c'"" > 0, ∃n'""0> 0, t.c. ∀n≥n'""0, 0 ≤h(n) + k(n) ≤c'""⋅g(n) 
con c'"" = c' + c""   e con   n'""0= max( n'0,n""0)( )
()())( )()(
)( )()( )(
ng nknh
ng nkng nh
Ο∈ + ⇒

Ο∈∧Ο∈"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#26,26,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itUsi estesi (o impropri) della notazione
• abuso della notazione
– spesso in luogo di f(n) ∈O(g(n)) si trova 
f(n) = O( g(n))
– questo corrisponde alla lettura “ f(n) è O( g(n))”
piuttosto che “ f(n) è un elemento di O( g(n))”
• operazioni con la notazione asintotica 
3n3+ O(n)   si intende: 3 n3sommata con una
qualche funzione appartenente adO(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#27,27,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizio
• dimostriamo che
6n4–3n3+ 2n2+ 5n + 6 ∈O(n4)
O(n4) – O( n3) + O( n2) + O( n) + O(1)
O(n4)   +    O( n2)   +     O( n)
O(n4)         +        O( n)
O(n4)fattori costanti positivi
appartenenze note 
proprietà transitiva
regola della somma
regola della somma"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#28,28,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sulla notazione O-grande
• Quali di questi rapporti di contenimento sono 
corretti?
O(n) O(n2)O(n)
O(n2) O(n)O(n2)
Risposta 1 Risposta 2 Risposta 3"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#29,29,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione  Ω
• Denotiamo Ω(g(n)) (“Omega di gdi n”) l’insieme 
delle funzioni “ limitate inferiormente da g(n) ”
• Definite come segue:
• Oppure, più formalmente:f(n) ∈Ω(g(n)) ⇔esistono due costanti positive c
ed n0tali che per ogni n≥n0si verifica
0 ≤c ⋅g(n) ≤f(n)f(n) ∈Ω(g(n)) ⇔esistono due costanti positive c
ed n0tali che per ogni n≥n0si verifica
0 ≤c ⋅g(n) ≤f(n)
Ω(g(n)) = { f(n) : ∃c> 0, ∃n0> 0, tali che ∀n≥n0 
0 ≤c ⋅g(n) ≤f(n)}Ω(g(n)) = { f(n) : ∃c> 0, ∃n0> 0, tali che ∀n≥n0 
0 ≤c ⋅g(n) ≤f(n)}"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#3,3,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itStudio di funzioni
• Intersezioni con gli assi e segno
• Simmetrie e periodicità
• Continuità, discontinuità, derivazione
• Massimi, minimi e punti di flesso• Comportamento agli estremi del dominio 
– asintoti orizzontali, verticali, obliqui
– notazione asintotica voi siete qui"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#30,30,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione Ω
n0c ⋅g(n)f(n)
n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#31,31,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itOsservazioni sulla definizione di Ω(g(n))
• si può facilmente dimostrare che
f(n) ∈Ω(g(n)) ⇔g(n) ∈O(f(n))
• nel caso della notazione Ωoccorre spesso 
ricorrere a valori minori di uno per la costante c
– la costante cnon è necessariamente un intero
• sarebbe stato analogo scrivere: 0  ≤g(n) ≤c⋅f(n)
• anche per Ω(g(n)) esistono funzioni 
incommensurabili
• vale la proprietà riflessiva: g(n) ∈Ω(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#32,32,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni limitate inferiormente da g(n)
g(n)Ω(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#33,33,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni in Ω(g(n))
•p e r  Ω(g(n)) valgono proprietà analoghe a quelle 
che abbiamo dimostrato per O( g(n))
• appartengono ad Ω(g(n)) le seguenti funzioni:
proprietà transitiva
f(n) ∈Ω(h(n))   per qualche   h(n) ∈Ω(g(n))
regola dei fattori costanti positivi
f(n) = d·h(n)   per qualche   h(n) ∈Ω(g(n)) e d> 0
regola della somma
f(n) = h(n) + k(n)   con   h(n) e k(n) ∈Ω(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#34,34,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sulla notazione Ω
• Quali di questi rapporti di contenimento sono 
corretti?
Ω(n) Ω(n2)Ω(n)
Ω(n2) Ω(n)Ω(n2)
Risposta 1 Risposta 2 Risposta 3"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#35,35,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione  Θ
• denotiamo Θ(g(n)) (“Teta di gdi n”) l’insieme delle funzioni 
“limitate inferiormente e superiormente da g(n) ”
• definite come segue:
• oppure, più formalmente:f(n) ∈Θ(g(n))  ⇔esistono tre costanti positive c1, 
c2, ed n0tali che per ogni n≥n0si verifica
0 ≤c1⋅g(n) ≤f(n) ≤c2⋅g(n) f(n) ∈Θ(g(n))  ⇔esistono tre costanti positive c1, 
c2, ed n0tali che per ogni n≥n0si verifica
0 ≤c1⋅g(n) ≤f(n) ≤c2⋅g(n) 
Θ(g(n)) = { f(n) : ∃n0> 0, ∃c1> 0, ∃c2> 0, tali che
0 ≤c1⋅g(n) ≤f(n) ≤c2⋅g(n) 
∀n≥n0 }Θ(g(n)) = { f(n) : ∃n0> 0, ∃c1> 0, ∃c2> 0, tali che
0 ≤c1⋅g(n) ≤f(n) ≤c2⋅g(n) 
∀n≥n0 }"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#36,36,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itNotazione Θ
n0c2 ⋅g(n)
f(n)
c1 ⋅g(n)
n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#37,37,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itOsservazioni sulla definizione di Θ(g(n))
• dalla definizione si ricava immediatamente che
– questa considerazione offre una definizione alternativa di 
Θ(g(n))
• vale la proprietà riflessiva: g(n) ∈Θ(g(n))
• valgono tutte le proprietà che abbiamo dimostrato per 
O-grande e per Ω()( )
()
Ω∈∧Ο∈
⇔ Θ∈
)( )()( )(
)( )(
ng nfng nf
ng nf"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#38,38,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni ∈Θ(g(n))
O(g(n))
g(n)Ω(g(n))
Θ(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#39,39,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itProprietà simmetrica
• è immediato dimostrare che 
f(n) ∈Θ(g(n)) ⇔g(n) ∈Θ(f(n))
• infatti
f(n) ∈O(g(n))  ⇒ g(n) ∈Ω(f(n))
f(n) ∈Ω(g(n))  ⇒ g(n) ∈O(f(n))
• dunque 
f(n) ∈Θ(g(n)) ⇒g(n) ∈Θ(f(n)) 
• in maniera analoga si dimostra che 
g(n) ∈Θ(f(n)) ⇒f(n) ∈Θ(g(n)) "
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#4,4,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itLa funzione lineare 10n
0100200300400500600
0 5 10 15 20 25 30 35 40 45 50n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#40,40,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itLa relazione di equivalenza Θ
• poiché f(n) ∈Θ(g(n)) ⇔g(n) ∈Θ(f(n)), la 
relazione f(n) ∈Θ(g(n)) tra f(n) e g(n) gode 
della proprietà simmetrica
• dunque la notazione Θdefinisce una relazione 
di equivalenza
– valgono infatti le tre proprietà riflessiva, 
simmetrica e transitiva
– la notazione Θconsente di classificare tutte le 
funzioni in classi di equiva lenza, che descrivono il 
loro comportamento al crescere di n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#41,41,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itRapporti tra classi
Θ(n)
O(n) O(n2)Ω(n)Ω(n2)
Θ(n2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#42,42,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itGerarchia delle funzioni
Θ(n!)
...
Θ(2n)
...
Θ(n3)
Θ(n2)
Θ(nlog n)
Θ(n)
Θ(log n)
Θ(1)• le funzioni nella classe Θ(g(n))
• sono O( f(n)) per tutte le f(n) 
appartenenti alle classi 
superiori a Θ(g(n))
• sono Ω(f(n)) per tutte le f(n) 
appartenenti alle classi 
inferiori a Θ(g(n))"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#5,5,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itLa funzione lineare 20n
020040060080010001200
0 5 10 15 20 25 30 35 40 45 50n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#6,6,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itla funzione quadratica n2
050010001500200025003000
0 5 10 15 20 25 30 35 40 45 50n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#7,7,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itla funzione cubica n3
020000400006000080000100000120000140000
0 5 10 15 20 25 30 35 40 45 50n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#8,8,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itLa funzione esponenziale 2n
02E+144E+146E+148E+141E+151.2E+15
0 5 10 15 20 25 30 35 40 45 50n"
data_test\rootfolder\università\AlgoritmiStruttureDati\040-notazione-asintotica-14.pdf#9,9,"040-notazione-asintotica-14 copyright ©2022 maurizio.patrignani@uniroma3.itScopo delle notazioni asintotiche
• Si applicano alle funzioni f(n) il cui dominio è
l’insieme Ndei naturali
– possono essere facilmente estese ai reali
• Classificano le funzioni dal punto di vista del 
loro comportamento per grandi valori di n
• Forniscono un limite superiore e/o inferiore 
della funzione
– la limitazione avviene per confronto con altre 
funzioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#0,0,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Il problema dell’ordinamento
Algoritmi greedy e algoritmi iterativi
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#1,1,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, anim azioni, video, audio, musica e 
testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non a fini
di lucro, da università e scuole pubbliche e da istituti pubblici diricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il contenuto delle
slides, che sono comunque soggette a cambiamento
• questa nota di copyright non deve essere mai rimossa e deve essere
riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#10,10,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi che operano in loco
• gli algoritimi che operano in loco non 
necessitano di copiare l’input in strutture di dati 
diverse da quella utilizzata per l’input
– questa caratteristica è utile per input di grosse 
dimensioni
• l’algoritmo SELECTION_SORT opera in loco
– gli elementi vengono solo scambiati
– l’algoritmo necessita di una quantità di memoria 
costante oltre a quella per memorizzare A
• la memoria utilizzata dall’algoritmo è O(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#11,11,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento stabili
• un algoritmo di ordinamento si dice stabile se 
non modifica l’ordine degli elementi che hanno 
lo stesso valore
– in alcune applicazioni ciò può essere utile
• quando agli elementi sono co llegati dei dati satellite
• quando gli elementi con la stessa chiave hanno una 
posizione reciproca significativa
• l’algoritmo SELECTION_SORT è stabile
–s e  A [ j] = A[ k] con j< k, allora A[ j] viene 
selezionato per primo"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#12,12,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itInsertion sort
Un algoritmo incrementale"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#13,13,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itGli algoritmi incrementali
• si basano sulla seguente osservazione
– la soluzione di un’istanza di dimensione 
n-1 può essere utile per risolvere un’istanza di 
dimensione n
•e s e m p i o
a) istanza di dimensione cinque:
b) istanza di dimensione sei:
la soluzione di (a) mi aiuta a risolvere (b) ? 
+ =   ?5246152461
341256+3"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#14,14,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.it♥♥
♥
♥♥♥♥♥♥♥
♥♥
♥♥
♥♥Insertion sort
• manteniamo un sottoinsieme 
ordinato di elementi
– cominciando da un singolo 
elemento
• inseriamo un elemento alla 
volta
– il sottoinsieme ordinato cresce
– i suoi elementi vengono traslati 
per far posto al nuovo elemento
• quando tutti gli elementi sono 
inseriti il problema è risolto
♥ ♥♥
♥♥♥♥
♥
♥♥♥♥♥♥♥
♥♥
♥♥
♥♥ ♥♥♥
♥♥♥♥
♥
♥♥♥♥♥♥♥♥♥
♥♥
♥♥♥♥♥
♥♥♥♥
♥
♥♥♥♥
♥
♥
♥♥♥
♥♥
♥♥ ♥♥♥
♥♥♥♥
♥
♥♥
♥
♥♥
♥
♥♥♥
♥♥
♥♥ ♥♥♥
♥♥♥♥
♥
♥♥♥♥♥♥♥
♥♥
♥♥
♥♥♥
♥♥
♥♥"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#15,15,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itINSERTION_SORT
ordinatoAj
da ordinare0 i8. A[i+1] = key7. i = i-16. A[i+1] = A[i]5. while i>-1andA[i]>key4. i = j-13. Zinserisce key nella sequenza ordinata A[0..j-1]2. key = A[j]1. forj = 1toA.length-1INSERTION_SORT(A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#16,16,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itInsertion sort con input
5ji
2
4ji5ji
2key
ji
4
ji
44613
4613
25613
25
25613
613
5ji
4 2613
5ji
2461356 2413jikey
524613ji
51 2463ji
51 2463ji
1 24563ji
41 2563j i
41 2563j i412563ij
43 1256ij
43 1256ji524613
43 1256ji
3 12456j i
312456j i
312456jkey"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#17,17,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itProprietà di INSERTION_SORT
•INSERTION_SORT è stabile
– supponiamo che per i< jsi abbia A[ i] = A[ j]
– quando l’algoritmo inserisce A[ j], l’elemento A[ i] è
già stato inserito
– l’algoritmo inserisce A[ j] dopo A[ i] preservando 
dunque la loro posizione reciproca originale
•INSERTION_SORT opera in loco
– richiede O(1) memoria addizionale rispetto alla 
memoria utilizzata per l’input"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#18,18,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itComplessità nel caso peggiore
• il ciclo esterno viene eseguito O( n) volte
• nel caso peggiore 
– l’elemento corrente deve essere inserito sempre al primo posto
• l’array A in input è ordinato in maniera decrescente
– il numero delle operazioni è Θ(n2)8. A[i+1] = key7. i = i-16. A[i+1] = A[i]5. while i>-1andA[i]>key4. i = j-13. Zinserisce key nella sequenza ordinata A[0..j-1]2. key = A[j]1. forj = 1toA.length-1INSERTION_SORT(A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#19,19,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itComplessità nel caso migliore
• il ciclo esterno viene eseguito comunque O( n) volte
• nel caso migliore 
– l’elemento corrente è già posizionato al punto giusto
• l’array A in input è già ordinato
– il numero delle operazioni è Θ(n)8. A[i+1] = key7. i = i-16. A[i+1] = A[i]5. while i>-1andA[i]>key4. i = j-13. Zinserisce key nella sequenza ordinata A[0..j-1]2. key = A[j]1. forj = 1toA.length-1INSERTION_SORT(A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#2,2,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itPanoramica
• il problema dell’ordinamento
• gli algoritmi greedy
– l’algoritmo selection sort
• gli algoritmi iterativi
– l’algoritmo insertion sort"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#20,20,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itComplessità nel caso medio
• il ciclo esterno viene eseguito comunque O( n) volte
• nel caso medio
– l’elemento corrente va posizionato nel mezzo di A[0… j]
– il numero delle operazioni è Θ(n2)8. A[i+1] = key7. i = i-16. A[i+1] = A[i]5. while i>-1andA[i]>key4. i = j-13. Zinserisce key nella sequenza ordinata A[0..j-1]2. key = A[j]1. forj = 1toA.length-1INSERTION_SORT(A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#21,21,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itProprietà dell’insertion sort
• efficente su piccole istanze
– più efficiente in pratica che il selection sort
– nel caso migliore ha complessità lineare 
– si può calcolare che la complessità media è n2/4
• adattivo
– veloce su instanze già parzialmente ordinate
• complessità O( n+ d) dove dè il numero delle inversioni
•s t a b i l e  
– non cambia l’ordine degli elem enti che hanno lo stesso valore
•i n  l o c o
– la memoria addizionale richiesta è O(1) 
• online
– può essere utilizzato quando i numeri arrivano uno alla volta"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#22,22,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento visti finora
sisi stabile
sisi in loco
Θ(n2) Θ(n2) Θ(n) INSERTION-SORTΘ(n2) SELECTION-SORTcaso 
peggiore
caso 
medio
caso 
migliore"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#3,3,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itIl problema dell’ordinamento
•input : una sequenza di nnumeri <a1, a2, ..., an>
•output : una permutazione <a1’, a2’, ..., an’> della 
sequenza tale che a1’≤a2’≤... ≤an’
• esempio 
– un’istanza
<31, 41, 59, 26, 41, 58>
– la soluzione dell’istanza qui sopra
<26, 31, 41, 41, 58, 59>
• nel seguito supporremo che l’istanza sia fornita 
tramite un array A con nposizioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#4,4,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itSelection sort
La tecnica greedy"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#5,5,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itLa tecnica greedy
• la tecnica greedy (golosa) consiste nel scegliere 
sempre l’alternativa che al momento sembra piùappetibile
– corrisponde ad eseguire una scelta localmente ottima
– ciò non sempre comporta una scelta globalmente ottima
• esempio in cui greedy no n dà la soluzione ottima
– trovare il cammino più breve tra ncittà
– algoritmo greedy: muoviti sempre verso la città più vicina 
non ancora visitata
soluzione 
trovata 
dall’algoritmo 
greedysoluzione 
migliore"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#6,6,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmo selection sort
• utilizza una tecnica greedy per ordinare un 
array
• strategia generale 
– seleziona l’elemento più piccolo 
e mettilo al primo posto
– seleziona l’elemento più piccolo 
dei rimanenti e mettilo al secondo posto
–…58471326
18475326
12475386"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#7,7,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmo SELECTION_SORT
• pseudocodice dell’algortimo
– si fa uso di due cicli annidati
8.A[min] = temp7.A[i] = A[min]6.temp = A[i] Zscambio A[i] con A[min]5. min = j4. if A[j] < A[min] Zdevo aggiornare min3. for j = i + 1 toA.length-1 Zscorro l’array2.min = i Zindice elemento minimo in A[i..n-1]1. fori = 0toA.length–2SELECTION_SORT( A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#8,8,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itComplessità del SELECTION_SORT
• i valori dell’input non modificano il numero delle 
iterazioni del ciclo esterno e del ciclo interno
– quindi il caso migliore, il caso peggiore ed il caso medio 
hanno la stessa complessità8.A[min] = temp7.A[i] = A[min]6.temp = A[i] Zscambio A[i] con A[min]5. min = j4. if A[j] < A[min] Zdevo aggiornare min3. for j = i + 1 toA.length-1 Zscorro l’array2.min = i Zindice elemento minimo in A[i..n-1]1. fori = 0toA.length–2SELECTION_SORT( A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\060-ordinamento-06.pdf#9,9,"060-ordinamento-06 copyright ©2019 maurizio.patrignani@uniroma3.itComplessità del SELECTION_SORT
• l’algoritmo esegue O( n) cicli esterni e O( n) cicli interni
– dunque SELECTION-SORT ha complessità O( n2)
• la riga 4 viene eseguita ( n-1)+( n-2)+...+1 = [ n(n-1)]/2 volte
– dunque SELECTION-SORT ha complessità Ω(n2)
• il tempo di esecuzione dell’algoritmo è Θ(n2)8.A[min] = temp7.A[i] = A[min]6.temp = A[i] Zscambio A[i] con A[min]5. min = j4. if A[j] < A[min] Zdevo aggiornare min3. for j = i + 1 toA.length-1 Zscorro l’array2.min = i Zindice elemento minimo in A[i..n-1]1. fori = 0toA.length–2SELECTION_SORT( A)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#0,0,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Ricorsione e complessità
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#1,1,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#10,10,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
2 variabile i2 variabile sum 2 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#11,11,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
2 variabile i2 variabile sum 3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)3 variabile i2 variabile f 8 istruzioneFACT(2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#12,12,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
2 variabile i4 variabile sum 3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#13,13,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
3 variabile i4 variabile sum 2 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#14,14,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
3 variabile i4 variabile sum 3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)4 variabile i6 variabile f 8 istruzioneFACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#15,15,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
3 variabile i10 variabile sum 3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#16,16,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
4 variabile i10 variabile sum 2 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#17,17,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
4 variabile i10 variabile sum 4 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#18,18,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itFunzioni ricorsive
• abbiamo già visto che l’algoritmo iterativo FACT per 
il calcolo del fattoriale ha complessità Θ(n)
• il calcolo del fattoriale può essere facilmente realizzato 
anche tramite un algoritmo ricorsivo5. return f4. f=n  *  FACT_RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#19,19,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT_RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#2,2,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itSommario
• funzioni e record di attivazione
• ricorsione e record di attivazione
• formule di ricorrenza
– teorema dell’esperto
• strategie algoritmiche
– algoritmi divide et impera e merge sort"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#20,20,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)0 variabile f4 istruzioneFACT_RIC(2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#21,21,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)0 variabile f4 istruzioneFACT_RIC(2)0 variabile f4 istruzioneFACT_RIC(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#22,22,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)0 variabile f4 istruzioneFACT_RIC(2)0 variabile f4 istruzioneFACT_RIC(1)1 variabile f2 istruzioneFACT_RIC(0)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#23,23,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)0 variabile f4 istruzioneFACT_RIC(2)1 variabile f4 istruzioneFACT_RIC(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#24,24,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
0 variabile f4 istruzioneFACT_RIC(3)2 variabile f4 istruzioneFACT_RIC(2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#25,25,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di funzioni ricorsive
• supponiamo di eseguire 
FACT_RIC (3)
• seguiamo l’evoluzione 
dello stack dei record di attivazione5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
6 variabile f4 istruzioneFACT_RIC(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#26,26,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itCosto di FACT_RIC
• il costo di FACT_RIC (n) è
–Θ(1) quando nèz e r o
– pari al costo di FACT_RIC (n-1) + Θ(1) negli altri 
casi5. return f4. f=n  *  FACT-RIC( n-1)3. else2.f=11. ifn == 0FACT_RIC(n)
T(0) = Θ(1) 
T(n) = T( n-1) + Θ(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#27,27,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itFormule di ricorrenza
• equazioni o disequazioni che descrivono una 
funzione in termini del suo valore su input più
piccoli
– prevedono sempre dei casi base e dei casi induttivi
•e s e m p i
a per n= 0
T(n-1) + g(n)p e r  n> 0
 a per n= 0 o n= 1
2T(n/2) + f(n) per n> 1T(n) =
T(n) ="
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#28,28,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itFormule di ricorrenza
• le soluzioni delle formule di ricorrenza non 
sempre sono facili da trovare
• quando esprimono delle complessità asintotiche 
talvolta i casi base vengono omessi
–s e  T ( n) esprime il tempo di esecuzione di un 
algoritmo, T( n) è sempre Θ(1) per npiccolo
•e s e m p i o
T(n) = 2T( n/2) + Θ(n)
• è sottointeso che T( n) = Θ(1) per n = 0 e n = 1"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#29,29,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itSoluzione di una equazione di ricorrenza
• dimostriamo che l’equazione di ricorrenza
• ammette come soluzione
• per dimostrarlo sostituiamo la soluzione 
proposta a destra e sinistra dell’equazione di 
ricorrenzak=1g(k) ∑n
T(n) = a+a per n= 0
T(n-1) + g(n)p e r  n> 0T(n) ="
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#3,3,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
0 variabile i0 variabile sum3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#30,30,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itVerifica della correttezza della soluzione
• caso base per n=0
T(n=0) = a+               = a + 0 = a (verificato)
• caso induttivo 
so chek=1g(k) ∑0
g(k) T(n-1) = a+ 
k=1∑n-1
g(k) + g(n) T(n)=  a+ 
k=1∑n-1
g(k) T(n)=  a+ 
k=1∑n
(verificato)(ipotesi induttiva)
T(n) = T( n-1) + g(n)    (dalla definizione)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#31,31,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itGraficamente
g(n) n
n-1
0
nn-2
2
1g(n-1)
g(n-2)
g(2)
g(1)
a
g(k) a+ 
k=1∑ndimensione del problemaalbero delle 
chiamate ricorsivecontributi"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#32,32,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di FACT_RIC
• sappiamo che FACT_RIC ha complessità
a per n= 0
T(n-1) + g(n)p e r  n> 0T(n) =Θ(1) per n= 0
T(n-1) + Θ(1) per n> 0T(n) =
• sappiamo che l’equazione di ricorrenza
• ammette come soluzione g(k) T(n)=  a+ 
k=1∑n
• la complessità di FACT_RIC è dunque
Θ(1) T(n)=  Θ(1) + 
k=1∑n
=  Θ(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#33,33,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itVersione ricorsiva del selection sort
9. SELECTION-RIC (A,i+1)8.A[min] = temp7.A[i] = A[min]6.temp = A[i] Zscambio A[i] con A[min]5. min = j4. if A[j] < A[min] Zdevo aggiornare min3. for j = i + 1 toA.length-1 Zscorro l’array2.min = i Zindice elemento minimo in A[i..n-1]1. ifi < A.length–1 Zaltrimenti è già ordinatoSELECTION_RIC( A,i) Zordina A da i a A.length-11. SELECTION_RIC (A,0) Zordina A da 0 in poiSELECTION( A) Zordina A"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#34,34,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di SELECTION_RIC
• possiamo scrivere la seguente equazione di 
ricorrenza, in cui nè il numero degli elementi 
di A ancora da ordinare
Θ(1) per n= 1
T(n-1) + Θ(n)p e r  n> 1T(n) =
• la complessità di SELECTION_RIC è dunque
Θ(k) T(n)=  Θ(1) + 
k=1∑n
=  Θ(n2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#35,35,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itGraficamente
n
n-1
n-2
2
1 Θ(1)Θ(2)Θ(n-2)Θ(n-1)Θ(n)
Θ(n) Θ(n)
n/2 · Θ(n) = Θ(n2)dimensione del problema
albero delle 
chiamate ricorsivecontributi"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#36,36,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itLa tecnica divide et impera
• detta anche “divide and conquer”
• consiste nel suddividere il problema in diversi 
sottoproblemi
– i sottoproblemi sono dello stes so tipo del problema originale
• ma di dimensioni più piccole
– i sottoproblemi possono essere risolti in maniera ricorsiva
• suddividendoli a loro volta
–c a s o  b a s e
• quando i sottoproblemi sono di di mensioni ridottissime la loro 
soluzione è banale"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#37,37,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itRicorsione del divide et impera
• a ciascun passo della ricorsione
– divide
• l’istanza corrente viene divi sa in due o più istanze più
piccole
– impera
• l’algoritmo viene lanciato sulle istanze più piccole 
– combina
• le soluzioni delle istanze più piccole vengono utilizzate 
per produrre una soluzione dell’istanza corrente"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#38,38,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itMerge sort
• introdotto da John von Neumann nel 1945
• osservazione elementare
– due sequenze ordinate possono essere fuse in un’unica 
sequenza ordinata molto facilmente
• un possibile algoritmo
– dividere la sequenza di input in due sottosequenze
– ordinare le due sottosequenze
• tramite lo stesso merge sort
– fondere le due sottosequenze ordinate
• caso base
– un array di un solo elemento è ordinato per definizione"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#39,39,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itMerge sort con input 52471326
52471326
5247 1326s
52471326ss ss13 26 52 47ss
25 4713 26m m m m
2457 1236m m
12234567ms
m= split
= merge"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#4,4,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
0 variabile i0 variabile sum 3 istruzionevariabile i1 variabile f 5 istruzioneFACT(0)4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#40,40,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itFusione: l’algoritmo MERGE
…(continua nella prossima slide)…9.R[n2] =  ∞Zchiudo con “infinito”8.L[n1] =  ∞Zchiudo con “infinito”7.R[j] = A[q+j+1] Zcopio la 2asequenza6. for j = 0ton2-15.L[i] = A[p+i] Zcopio la 1asequenza4. for i = 0ton1-13. Zcreo array L[0…n1] e R[0…n2] (con una casella in +)2.n2=r  -q  Zlunghezza della seconda sequenza1.n1= q - p + 1 Zlunghezza della prima sequenzaMERGE(A,p,q,r)
A << <<
<< << L[] R[] ∞ ∞pq r"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#41,41,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itFusione (continua)
18. j = j + 117. A[k] = R[j] Zpesco da R16. else15. i = i + 114. A[k] = L[i] Zpesco da L13. if L[i] ≤R[j] then 12.for k = ptor11.j = 0 Ziteratore per array R10.i = 0 Ziteratore per array L…(dalla slide precedente)…
• il confronto con “ ≤” sulla riga 13 garantisce la stabilità
dell’algoritmo
–s e  L[i]=R[j] allora L[i] ha la precedenza"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#42,42,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itL’algoritmo MERGE_SORT
5. MERGE( A,p,q,r)4. MERGE_SORT( A,q+1,r)3. MERGE_SORT( A,p,q)2. q =  (p+r)/2 Zdivido l’array in due1. if p < r then Znel caso base esco subitoMERGE_SORT( A,p,r)
• all’inizio della computazione lanciamo• l’algoritmo MERGE_SORT esegue la parte “divide”, risolve i 
sottoproblemi ed esegue la parte “combine”
1. MERGE_SORT( A,0,A.length-1 )MERGE(A) Zordina A"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#43,43,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itTempo di esecuzione di merge sort
• calcoliamo il costo T( n) di esecuzione del merge sort 
su un’istanza con nelementi
• caso base
–c o s t o Θ(1)
• divide 
– calcolo di n/2: costo D( n) = Θ(1)
• impera
– ogni sottoproblema ha dimensione n/2
– i sottoproblemi sono 2– costo: 2·T( n/2)
• combina
– l’algoritmo MERGE ha costo lineare: C( n) = Θ(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#44,44,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itTempo di esecuzione di merge sort
• complessivamente
• poiché D( n) + C( n) = Θ(1) + Θ(n) = Θ(n) si ha
• dimostreremo che questa particolare equazione 
di ricorrenza ammette come soluzione Θ(1) per n= 0 o n= 1
2·T(n/2) + D( n) + C( n) per n> 1
 Θ(1) per n= 0 o n= 1
2·T(n/2) + Θ(n) per n> 1T(n) =
T(n) =
T(n) = Θ(nlog n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#45,45,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itMaster theorem (teorema dell’esperto)
• siano a, b≥1
• il master theorem considera l’equazione di ricorrenza 
seguente
• il master theorem afferma che tale equazione di 
ricorrenza ammette le soluzioni seguenti
1. se a< bkallora T( n) = Θ(nk)
2. se a= bkallora T( n) = Θ(nklog n)
3. se a> bkallora T( n) = Θ(nlogba)Θ(1) per n= 0
a⋅T(n/b) + O(nk) per n> 0T(n) ="
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#46,46,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itAlbero di ricorsionelog bnn
1bn
bn
bn
bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
1 1 11
a
a2
a3
n/bh= 1 ⇒ n = bh⇒ h = logbnnumero 
nodi
nbalog"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#47,47,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itCosto per ogni livellolog bnn
1bn
bn
bn
bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
1 1 1costo
kn
()kbna/
()kbna2 2/
()kbna3 3/
nbalog"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#48,48,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itCosto per ogni livellolog bnn
1bn
bn
bn
bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
1 1 1costo
kn
()kbna/
()kbna2 2/
()kbna3 3/
nbalogMaster Theorem:
T(n) = a⋅T(n/b) + O( nk) 
1. se a< bkallora T( n) = O( nk)
In pratica se a< bkla complessità è
dominata dal primo livello 
dell’albero di ricorsione"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#49,49,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itCosto per ogni livellolog bnn
1bn
bn
bn
bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
1 1 1costo
kn
()kbna/
()kbna2 2/
()kbna3 3/
nbalogMaster Theorem:
T(n) = a⋅T(n/b) + O( nk) 
2. se a= bkallora T( n) = O( nklog n)
Se a= bkla complessità è uguale per 
tutti i livelli
- infatti ai(n/bi)k=bki(n/bi)k=nk"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#5,5,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
0 variabile i0 variabile sum 3 istruzione2 variabile i1 variabile f 8 istruzioneFACT(0)4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#50,50,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itCosto per ogni livellolog bnn
1bn
bn
bn
bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
2bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
3bn
1 1 1costo
kn
()kbna/
()kbna2 2/
()kbna3 3/
nbalogMaster Theorem:
T(n) = a⋅T(n/b) + O( nk) 
3. se a> bkallora T( n) = O( nlogb a)
Se a> bkla complessità è dominata 
dall’ultimo livello
- infatti alogb n=nlogb a"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#51,51,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itDimostriamo che xlog y= ylog x
• Partiamo da
xlogy= ylogx
• Facciamo il logaritmo da entrambe le parti
log(xlog y) = log( ylogx)  
• Ricordando che
log ab= blog a
• Otteniamo 
(log y)(log x) = (log x)(log y) 
• Che è vera per la proprietà commutativa del prodotto"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#52,52,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itDimostrazione del primo caso ( a < bk)
• La somma del costo di tutti i livelli è
• è una serie geometrica con ragione
• Se         , cioè se          , la sommatoria, anche se 
avesse infiniti termini, sarebbe comunque una costante
• Dunque∑ ∑ ∑
= = =

= =

=h
ii
kkh
iikk
ih
ik
ii
banbnabna nT
0 0 0)(
kbar=
1<rkba<
)1/(1 r−
()knOnT =)(∑
=

h
ii
kba
0"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#53,53,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itDimostrazione del terzo caso ( a > bk)
• Torniamo alla serie geometrica con 
• Se           , cioè se            , la sommatoria vale∑
=

=h
ii
kk
bannT
0)(kbar=
1>rkba>
()hh h
rOrr
rr∈−−=−−
11
11
kn
knn
n kn n
kh
na
ba
ba
barb
bb
bbb log
loglog
loglog log
) (= = = 

="
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#54,54,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itDimostrazione del terzo caso ( a > bk)
• Dunque
•D a  c u i() () ()


⋅ = ⋅ =kn
k h k
naOnO rOnOnTblog
)(
( )()a nb bnO aOnTlog log)( = ="
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#55,55,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEsempi di applicazione del master theorem
•T (n) = 9T( n/3) + n
– abbiamo: a= 9;b= 3; p(nk) = n;k= 1
– quindi a> bk
–s ih a  T ( n) = Θ(nlogba) = Θ(nlog39) = Θ(n2)
•T (n) = T(2 n/3) + 1
– abbiamo: a= 1; b= 3/2; p(nk) = 1; k= 0
– quindi a= bk
–s i  h a  T ( n) = Θ(nk log n) = Θ(n0log n) = Θ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#56,56,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itComplessità del merge sort
• la complessità del merge sort è data dalla 
formula di ricorrenza 
T(n) = 2·T( n/2) + Θ(n)
• applichiamo il teorema dell’esperto
– abbiamo: a= 2; b= 2; p(nk) = n; k= 1
– quindi a= bk
–s i  h a  T ( n) = Θ(nk log n) = Θ(nlog n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#57,57,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itGraficamente
Θ(n)log2nn
1n
2n
2
n
4n
4n
4n
4
24Θ(n)
Θ(n)
Θ(n)
Θ(n)
1
Θ(n log n)albero delle 
chiamate ricorsivecontributi"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#58,58,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento visti finora
si no Θ(n logn) MERGE-SORTsisi stabile
sisi in loco
Θ(n2) Θ(n2) Θ(n) INSERTION-SORTΘ(n2) SELECTION-SORTcaso 
peggiore
caso 
medio
caso 
migliore"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#6,6,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
0 variabile i1 variabile sum3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#7,7,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
1 variabile i1 variabile sum 2 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#8,8,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
1 variabile i1 variabile sum 3 istruzione2 variabile i1 variabile f 8 istruzioneFACT(1)4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\070-ricorsione-e-complessita-06.pdf#9,9,"070-ricorsione-e-complessita-06 copyright ©2022 maurizio.patrignani@uniroma3.itEffetti di una chiamata a funzione
• supponiamo di eseguire 
SUM_OF_FACT (3)
• seguiamo l’evoluzione 
dello stack dei record di 
attivazione
1 variabile i2 variabile sum 3 istruzione4. return sum3.sum = sum + FACT(i)2. fori = 0 ton1.sum = 0SUM_OF_FACT(n)
8. return f7.f = f * i6. fori = 2 ton5.f = 1FACT(n)
SUM_OF_FACT(3)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#0,0,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Tipi astratti di dato
(pile e code realizzate tramite array)
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#1,1,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#10,10,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di una pila con array
• Una pila ppuò essere realizzata tramite un 
oggetto contenente un array p.A e un intero 
p.top che specifica l’indice dell’elemento 
affiorante
4712
• Quando la pila è vuota p.top vale -1
-1p.top
3
p.topp.A
p.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#11,11,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itPUSH(p,9)Sequenza di operazioni su una pila
p.top
-1
3p.top
0
31p.top
13149p.top
2PUSH(p,3)
PUSH(p,1)POP(p)PUSH(p,4)
3149p.top
3
3149p.top
1POP(p)p.A
p.A
p.Ap.Ap.Ap.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#12,12,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itOperazione NEW_STACK
• Implementazione in pseudocodice della 
funzione di creazione
• L’uso della funzione NEW_STACK èi l  
seguente4. return p3. p.top = –12.Z p.top intero1.Zcreo un oggetto p con: p.A array di maxsize interiNEW_STACK(maxsize)
...p = NEW_STACK (10) Zcreo una pila con 10 posizioni..."
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#13,13,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itOperazioni PUSH e POP
• Implementazione delle funzioni di modifica
5.return p.A[p.top + 1]4.p.top = p.top – 13. else 2. error (“underflow”)1. if p.top == -1POP(p)5.p.A[p.top] = x4.p.top = p.top + 13. else 2. error (“overflow”)1. if p.top == p.A.length-1PUSH(p,x)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#14,14,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAltre operazioni sulle pile
1. return p.top == -1 Ztrue se la pila è vuotaIS_EMPTY(p)
1.p.top = -1 Zvuoto la pilaEMPTY(p)
1. return p.A[p.top] Zl’elemento affiorante TOP(p)
• Il tempo di esecuzione di ogni operazione è Θ(1)1. return p.top + 1 Zil numero di elementiSIZE(p)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#15,15,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itGestione telescopica della pila
• Strategia utilizzata per non avere limiti sulla 
dimensione della pila
• Si adotta una dimensione iniziale di default
– può essere un numero fissato dal programmatore
• per esempio 128 posizioni
– può essere il numero di celle specificato dall’utente 
nella funzione NEW_STACK
• Quando viene eseguita una PUSH sulla pila 
piena si raddoppia la dimensione della pila 
corrente per poter inserire ulteriori elementi"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#16,16,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itNuova funzione PUSH
• Questa funzione PUSH raddoppia la dimensione 
dell’array p.A quando l’array è pieno
7.p.A[p.top] = x6.p.top = p.top + 1 Zinserisco l’elemento x5.p.A = B Zsostituisco B a p.A4. B[i] = p.A[i] Zcopio p.A dentro B3. for i = 0 top.A.length-12. ZB nuovo array di 2*p.A.length posizioni1. if p.top == p.A.length-1PUSH(p,x)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#17,17,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAnalisi ammortizzata
12 34 8 1 6 3 3 5 9 17 3212
1° inserimento, costo 1
2° inserimento, costo 134
3° inserimento, costo 1
4° inserimento, costo 1 (array pieno)
1• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi:"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#18,18,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAnalisi ammortizzata
12 344
81 6 3 35° inserimento, costo 5 
(4 per la copia, 1 per l’inserimento)
5 9 17 325° inserimento
5 1234
raddoppio la dimensione 
dell’array e ci copio dentro i 
primi 4 elementi• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi:"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#19,19,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.it5Analisi ammortizzata
• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi:
12 344
81 6 3 3 5 9 17 321234678
6° inserimento, costo 1
7° inserimento, costo 1
8° inserimento, costo 1"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#2,2,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itSommario
• Tipi astratti di dato
• Strutture di dati elementari
– le pile
– le code
• Realizzazione con array di queste strutture
• La complessità ammortizzata"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#20,20,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.it• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi:5Analisi ammortizzata
8
12 344
81 6 3 3 5 9 17 321234678 9° inserimento9
raddoppio la dimensione 
dell’array e ci copio dentro i 
primi 8 elementi
9° inserimento, costo 9 
(8 per la copia, 1 per l’inserimento)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#21,21,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAnalisi ammortizzata
81632
12 344
81 6 33 59 1 7 32• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi dopo molti inserimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#22,22,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAnalisi ammortizzata
81632
12 344
81 6 33 59 1 7 32• Calcoliamo il costo degli inserimenti partendo 
da un array da 4 elementi
• Diagramma dei costi dopo molti inserimenti
• Distribuiamo i costi sugli inserimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#23,23,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itComplessità ammortizzata
• Alcuni inserimenti costano effettivamente 
Θ(n), dove n è il numero di elementi già
contenuti nella pila
– è corretto dire che il costo di un inserimento nel 
caso peggiore è Θ(n)
• Una sequenza di n inserimenti costa Θ(n)
– si dice che la complessità “ammortizzata” di un 
inserimento è Θ(1)
4
12 34 8 1 6 59 1 7 3332"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#24,24,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itUso delle realizzazioni di un ADT
• Dopo aver realizzato un ADT possiamo mettere 
l’implementazione a disposizione di altri programmatori specificando
– le eventuali limitazioni della realizzazione
– l’elenco delle operazioni supportate e la loro complessità
asintotica o ammortizzata
•E s e m p i o
– si dispone di una realizzazione di una pila con le seguenti 
funzioni e complessità nel caso peggiore
• NEW_STACK(maxsize) Θ(1)
• IS_EMPTY(p) Θ(1)
• PUSH(p,x) Θ(1)
• POP(p) Θ(1)
• EMPTY(p) Θ(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#25,25,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itIl tipo astratto di dato coda
• Le code (o queue) realizzano una strategia 
FIFO (first-in first-out) 
• Tipo astratto: coda di interi
–d o m i n i
• il dominio di interesse è l’ins ieme delle code Q di interi
• dominio di supporto: gli interi Z = {0, 1, -1, 2, -2, …}• dominio di supporto: i booleani B = {true, false}
– costanti
• la coda vuota"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#26,26,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itIl tipo astratto di dato coda
• Tipo astratto: coda di interi
– operazioni
• verifica se una coda è vuota
IS_EMPTY: Q →B
• inserimento di un elemento nella coda
ENQUEUE: Q ×Z →Q
• rimozione e restituzione dell’elemento più vecchio della coda
DEQUEUE: Q →Q ×Z
– operazioni aggiuntive
• lettura dell’elemento più vecchio della coda
FRONT: Q →Z
• svuotamento della coda
EMPTY: Q →Q
• numero degli elementi nella coda
SIZE: Q →Z"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#27,27,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione dell’ADT coda
• NEW_QUEUE(maxsize)
– ritorna un riferimento ad una coda vuota che può contenere 
al massimo maxsize interi
• IS_EMPTY(c)
– ritorna true se la coda è vuota, altrimenti ritorna false
• ENQUEUE(c,x)
– inserisce un elemento xnella coda
• può dare un errore di “overflow” se l’implementazione prevede un 
numero massimo di elementi 
• DEQUEUE(c)
– rimuove l’elemento più vecchio della coda e lo restituisce
• dà un errore di “underflow” se la coda è vuota"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#28,28,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAltre operazioni sulle code
•FRONT(c)
– ritorna l’elemento più vecchio senza rimuoverlo
• può dare errore se la coda è vuota
•EMPTY(c)
– svuota la coda
•SIZE(c)
– ritorna il numero degli elementi in coda"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#29,29,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di una coda tramite array
• Una coda cpuò essere realizzata con un array c.A
arricchito da due attributi c.head e c.tail che 
contengono gli indici dell’el emento più vecchio e della 
prima posizione utile
4712
• Un nuovo elemento viene aggiunto da ENQUEUE nella 
posizione c.tail (che viene incrementato) c.tail4c.head
0
47127
c.tail5c.head
0c.A
c.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#3,3,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itTipo astratto di dato
•U n  tipo astratto di dato (o ADT, abstract data 
type) è una descrizione di un tipo di dato 
indipendente dalla sua realizzazione in un 
linguaggio di programmazione
• Un tipo astratto di dato è costituito da:
– i domini interessati
• tra cui il dominio di intere sse ed eventualmente altri 
domini di supporto
– un insieme di costanti
– una collezione di operazioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#30,30,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di una coda tramite array
• L’elemento ritornato da DEQUEUE è quello in 
posizione c.head (che viene incrementato)
4712
• L’array è gestito come una lista circolarec.tail4c.head
0
57124362
c.tail1c.head
44712
c.tail4c.head
1c.A
c.A
c.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#31,31,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di una coda tramite array
• La coda è vuota quando c.head e c.tail puntano 
alla stessa casella
• La coda non può avere più di n-1 elementi
– se avesse nelementi, che valore potremmo dare a c.tail
senza creare equivoco con la coda vuota?c.tailc.head
4617362
c.tailc.headc.A
c.A5 5
4 3"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#32,32,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itOperazioni ENQUEUE e DEQUEUE
6. else c.tail = c.tail + 15. c.tail = 04. if c.tail == c.A.length-13. else c.A[c.tail] = x2. error (“overflow”)1. if c.head==c.tail+1 or(c.tail==c.A.length-1 andc.head==0)ENQUEUE(c,x)
7. return x6. else c.head = c.head + 15. c.head = 04. if c.head == c.A.length-13. else x = c.A[c.head]2. error (“underflow”)1. if c.head == c.tailDEQUEUE(c)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#33,33,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAltre operazioni sulle code
1. return c.head == c.tailIS_EMPTY(c)
1.c.head = c.tail = 0EMPTY(c)
4. return c.A[c.head]3. else2. error (“empty queue”)1. if c.head == c.tailFRONT(c)
• Il tempo di esecuzione di ogni operazione è Θ(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#34,34,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi sulle code
1. Scrivi lo pseudocodice della procedura 
NEW_QUEUE () che restituisce il riferimento ad 
una coda vuota 
2. Scrivi lo pseudocodice della procedura 
SIZE (c) che restituisce il numero di elementi 
in una coda
3. Scrivi lo pseudocodice della procedura 
ENQUEUE(q,x) che abbia complessità
ammortizzata Θ(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#35,35,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi su pile e code
4. Supponi di disporre di una realizzazione di una pila con le 
seguenti caratteristiche
– funzioni NEW_STACK , IS_EMPTY e POP di complessità Θ(1)
– funzione PUSH di complesità nel caso peggiore Θ(n) e complessità
ammortizzata Θ(1)
Descrivi come sia possibile implementare un coda utilizzando 
esclusivamente pile
– ti occorreranno due pile p1e p2da usare simultaneamente
– l’operazione NEW_QUEUE creerà le due pile p1e p2
– le operazioni ENQUEUE e DEQUEUE si tradurranno in opportune 
operazioni di PUSH e POP sulle due pile p1e p2
Discuti la complessità delle operazioni ENQUEUE e DEQUEUE"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#36,36,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi su pile e code
5. Supponi di disporre di una realizzazione di una coda con le 
seguenti caratteristiche
– funzioni NEW_QUEUE , IS_EMPTY e DEQUEUE di complessità Θ(1)
– funzione ENQUEUE di complesità nel caso peggiore Θ(n) e 
complessità ammortizzata Θ(1)
Descrivi come sia possibile implementare un pila utilizzando 
esclusivamente code
– ti occorreranno due code q1e q2da usare simultaneamente
– le operazioni PUSH e POP si tradurranno in opportune operazioni di 
ENQUEUE e DEQUEUE sulle due code q1e q2
Discuti la complessità delle operazioni PUSH e POP"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#37,37,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi su pile e code
6. Scrivi lo pseudocodice della procedura 
CONTAINS(p,x) che ritorna true se l’elemento 
xè contenuto nella pila pe ritorna false se xnon 
è contenuto (lasciando la pila invariata)
7. Scrivi lo pseudocodice di una struttura dati in cui si 
possa inserire/rimuovere elem enti sia in testa che in 
coda
– deve avere contemporaneamente PUSH , POP, DEQUEUE , 
ENQUEUE (dove evidentemente ENQUEUE è uguale a 
PUSH ) "
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#4,4,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itIl tipo astratto di dato pila
• Le pile (o stack) realizzano una strategia LIFO 
(last-in first-out) 
• Tipo astratto: pila di interi
–d o m i n i
• il dominio di interesse è l’insieme delle pile P di interi
• dominio di supporto: gli interi Z = {0, 1, -1, 2, -2, …}• dominio di supporto: i booleani B = {true, false}
– costanti
• la pila vuota "
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#5,5,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itIl tipo astratto di dato pila
• Tipo astratto: pila di interi
– operazioni
• verifica se una pila è vuota
IS_EMPTY: P →B
• inserimento di un elemento nella pila
PUSH: P ×Z →P
• rimozione e restituzione dell’elemento affiorante della pila
POP: P →P ×Z
– operazioni aggiuntive
• lettura dell’elemento affiorante della pila
TOP: P →Z
• svuotamento della pila
EMPTY: P →P
• numero degli elementi nella pila
SIZE: P →Z"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#6,6,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di un tipo astratto di dato
• Un tipo astratto di dato può essere realizzato (o 
implementato ) in uno specifico linguaggio di 
programmazione tramite la definizione di
– tipi concreti o strutture dati nello specifico 
linguaggio di programmazione corrispondenti ai domini necessari
– costrutti che consentono di codificare le costanti
– funzioni che realizzano le operazioni previste
• Ovviamente uno stesso tipo astratto di dato può 
avere diverse realizzazioni con diverse proprietà"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#7,7,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itRealizzazione di un ADT: osservazioni
• La definizione dei tipi concreti o delle strutture che 
corrispondono ai domini può comportare delle limitazioni
– esempi di limitazioni 
• il dominio P delle pile viene ristrett o alle pile di dimensione massima 
maxsize , nota a priori
• il dominio Z degli interi viene re alizzato tramite il tipo concreto int
che ha un valore minimo MININT e massimo MAXINT
• Le costanti vengono spesso codificate tramite delle 
funzioni che ritornano la  struttura corrispondente
– esempio di costante: 
• la pila vuota viene realizzata tramite
CREATE-STACK(maxsize)
che ritorna il riferimento ad una pila vuota che potrà contenere al 
massimo maxsize elementi"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#8,8,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itFunzioni che operano su pile
• NEW_STACK(maxsize)
– ritorna il riferimento ad una pila vuota che potrà contenere al 
massimo maxsize elementi 
• IS_EMPTY(p)
– ritorna true se la pila è vuota, false altrimenti
• PUSH(p,x)
– inserimento di un elemento nella pila
• può dare un errore di “overflow” se l’implementazione prevede un 
numero massimo di elementi nella pila
• POP(p)
– rimozione e restituzione dell’elemento affiorante della pila
• dà un errore di “underflow” se la pila è vuota"
data_test\rootfolder\università\AlgoritmiStruttureDati\080-tipi-astratti-di-dato-04.pdf#9,9,"080-tipi-astratti-di-dato-04         copyright ©2019 maurizio.patrignani@uniroma3.itAltre funzioni su pile
•TOP(p)
– ritorna l’elemento affiorante senza rimuoverlo
• può dare errore se la pila è vuota
•EMPTY(p)
– svuota la pila
•SIZE(p)
– ritorna il numero degli elementi in pila"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#0,0,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itAlgoritmi e Strutture di Dati
Liste implementate tramite array
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#1,1,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#10,10,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itLista doppiamente concatenata
• La struttura di dati supporta il passaggio diretto da un 
iteratore al successivo e al precedente
– si vogliono le operazioni FIRST, NEXT e PREV in Θ(1)
I
INFOFIRST
I
INFONEXTI
INFOiteratori
elementi E E EL
PREVlista
NEXT
PREV"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#11,11,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itListe con accesso agli estremi
• La struttura di dati supporta l’accesso diretto al 
primo e all’ultimo iteratore della lista
– si vogliono le operazioni FIRST e LAST in Θ(1)
I
INFOFIRST
I
INFONEXTI
INFOiteratori
elementi E E EL
PREVlista
NEXT
PREVLAST"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#12,12,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itRealizzazione di una lista con array
• Supponiamo di mettere gli elementi della lista nelle 
celle successive di un array l.info
– come facciamo a gestire la cancellazione di un elemento 
intermedio della lista?
– come facciamo a sapere quali celle dell’array sono 
utilizzate?
• non c’è nessun valore intero che possiamo associare ad una cella 
vuota2385l.info
285l.info"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#13,13,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itRealizzazione di una lista con array
• Gli elementi della 
lista sono memorizzati in un 
array l.info
• L’array l.next
contiene l’indice 
dell’elemento che segue
• L’array l.prev
contiene l’indice 
dell’elemento che 
segue235
31l.head6
l.next
352l.info
61l.prevsequenza:         ,         ,"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#14,14,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itRealizzazione di una lista con array
• L’iteratore della 
lista è un intero
– è l’indice della 
posizione dell’elemento 
corrispondente
• L’iteratore non 
valido èrappresentato dal valore -1235
3-11l.head6
l.next
352l.info
61-1l.prevsequenza:         ,         ,"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#15,15,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itPiù liste con gli stessi array?
• Gli array 
l.next , 
l.info ed 
l.prev possono 
essere condivisi 
da due o più liste
– le liste non 
interferiscono, perché utilizzano 
posizioni diverse 
degli array 3-1-121l2.head5
l1.next = l2.next
37542l1.info = l2.info
651-1-1l1.prev = l2.prevl1.head6235 sequenza 1:         ,         ,
47 sequenza 2:         ,         "
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#16,16,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itUso della lista libera
• Per inserire un nuovo elemento 
in lista occorre sapere quali posizioni degli array sono 
ancora libere
• Tutte le posizioni libere 
possono essere memorizzate in 
una seconda lista l.free
– un inserimento di un elemento in 
lè un trasferimento di una 
posizione dalla lista l.free
alla lista l.head
– una cancellazione da lè un 
trasferimento di una posizione 
dalla lista l.head alla lista 
l.free430-1721-1l.free5
l.next
352l.info
26510-1-14l.prevl.head6"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#17,17,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itConfigurazione iniziale: lista vuota
• Quando la lista lè vuota tutte le posizioni sono 
assegnate alla lista l.free
1234567-1l.free0
l.next
l.info
-10123456l.prevl.head-1
-1234567-1l.free1
l.next
4l.info
-1-1123456l.prevl.head0inserimento 
del primo elemento"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#18,18,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itCreazione di una lista vuota di interi
• Procedura per inizializzare una lista vuota di 
interi
10.return l9.l.free = 08.l.head = -17.l.next[maxsize-1] = -16.l.prev[i] = i-15.l.next[i] = i+14. for i = 0 to maxsize-13.Zl.head, l.free interi2.Zl.next, l.info, l.prev array di maxsize interi1.Zcreo un nuovo oggetto l con:NEW_LIST(maxsize) "
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#19,19,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itGestione della lista l.free
• Procedura di servizio per ottenere una posizione 
libera dalla lista l.free
8. return i 7. l.prev[l.free] = -16. if l.free!=- 15.l.free = l.next[l.free]4.i = l.free Zi è l’indice della nuova posizione3. else2. error (“overflow”)1. if l.free == -1ALLOCATE-COLUMN(l) "
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#2,2,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itSommario
• Il tipo astratto di dato lista
– tipologie di liste e strategie di realizzazione 
• Realizzazione delle liste con array
– uso di tre array
– uso di un solo array
– liste disomogenee"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#20,20,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itGestione della lista l.free
• Procedura di servizio per restituire una 
posizione alla lista l.free
5.l.free = i4. l.prev[l.free] = i3. if l.free != -12.l.next[i] = l.free1.l.prev[i] = -1FREE-COLUMN(l,i) "
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#21,21,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itCodice di INSERT (l,x)
7.l.head = i6.l.prev[l.head] = i5. ifl.head != -14.l.next[i] = l.head Zil resto della lista segue i3.l.prev[i] = -1 Zi diventa primo elemento2.l.info[i] = x1.i =ALLOCATE-COLUMN(l) Zindice di una nuova colonna liberaINSERT(l,x) Zx è il valore da aggiungere in lista
3-11l.head6
l.next
352l.info
61-1l.previ
3-116l.head7
l.next
352xl.info
617-1l.prev7"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#22,22,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itEsercizi: liste implementate con array
1. Scrivi lo pseudocodice della procedura SIZE (l) che 
conta gli elementi della lista l
2. Scrivi lo pseudocodice della procedura 
SEARCH (l,k) che restituisce la posizione del primo 
elemento di lcon valore della chiave k
3. Scrivi lo pseudocodice della procedura 
DELETE (l,i) che rimuove da ll’elemento in 
posizione i
4. Scrivi lo pseudocodice della procedura 
DELETE (l,x) che rimuove da lil primo elemento 
che ha valore x"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#23,23,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itRappresentazione con un solo array
3-11l.head6
l.next
352l.info
61-1l.prev
39 -1l.head18
518 3 23-1• Un solo array è sufficiente a rappresentare le 
informazioni degli 
array l.next , l.info
ed l.prev
l.all
nextprev• Ovviamente è anche 
necessaria una lista 
l.free (non 
rappresentata in figura)"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#24,24,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itEsercizi: liste su un solo array
Negli esercizi seguenti supponi che la lista lsia 
doppiamente concatenata ed implementata tramite 
un solo array
5. Scrivi lo pseudocodice della procedura 
ALLOCATE_OBJECT (l) 
6. Scrivi lo pseudocodice della procedura  
FREE_OBJECT (l,i)
7. Scrivi lo pseudocodice della procedura 
LOWER_FREE_POSITION (l) che trova la 
posizione con indice più basso tra gli elementi della 
lista libera l.free"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#25,25,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itListe con elementi eterogenei
• L’uso di un singolo array consente la gestione di liste 
di elementi eterogenei
– un campo aggiuntivo specifica la dimensione di ogni 
elemento
– la lista l.free (non rappresentata in figura) viene gestita 
con criteri analoghi
1613 5l.head22
22 22 -14194-1
sizel.all"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#26,26,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itEsercizi: liste eterogenee
negli esercizi seguenti supponi che la lista lsia eterogenea, 
doppiamente concatenata, ed implementata tramite un 
singolo array 
8. Scrivi lo pseudocodice della procedura ALLOCATE-
OBJECT-WITH-SIZE (l,x) che trova nella lista libera 
l.free una posizione adatta ad ospitare un elemento di 
dimensione x
9. Scrivi lo pseudocodice della procedura FREE-OBJECT (l,i) 
che inserisce nella lista libera l.free l’oggetto in 
posizione i
10. Scrivi lo pseudocodice della procedura INSERT (l,A) che 
inserisce nella lista lun elemento di dimensione A.length
che contiene tutti i valori dell’array A"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#27,27,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itEsercizio: cancellazione lazysu liste eterogenee
Negli esercizi seguenti supponi che una lista eterogenea doppiamente 
concatenata ed implementata con un singolo array preveda, per ogni 
elemento, un valore che specifica se  l’elemento è da considerarsi 
“rimosso” oppure no
11. Scrivi lo pseudocodice della procedura DELETE (l,i) dove iè l’indice 
della posizione di un elemento  da marcare come “rimosso”
12. Scrivi lo pseudocodice della procedura GARBAGE-COLLECTION (l) che 
trasferisce nella lista l.free tutti gli elementi marcati come “rimossi”
106 2 -14
21 13 5-14
0 = elemento rimosso 1 = elemento non rimossol.head
l.all"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#3,3,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itListe
• Le liste sono strutture di dati in cui gli oggetti 
sono disposti in una sequenza lineare
– si assume che l’utente voglia scorrere gli elementi 
tramite un iteratore
• Tipo astratto: lista di interi
–d o m i n i
• il dominio di interesse è l’ins ieme delle liste L di interi
• dominio di supporto: gli iteratori I che identificano le 
posizioni
• dominio di supporto: gli interi Z = {0, 1, -1, 2, -2, …}
• dominio di supporto: i booleani B = {true, false}"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#4,4,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itRealizzazione di una lista
• Costanti
– la lista vuota viene reali zzata tramite la funzione NEW_LIST (maxsize )
• ritorna il riferimento ad una lista vuota che può contenere al massimo 
maxsize elementi
– l’iteratore non valido è solitamente uno specifico valore dell’iteratore
• Operazioni di aggiornamento
– l’inserimento in testa alla lista INSERT: L ×Z →L viene realizzato 
tramite la funzione INSERT (l,x)
– l’inserimento in coda ADD: L ×Z→L viene realizzato tramite la 
funzione ADD(l,x)
– l’eliminazione di un elemento a partire dal suo iteratore DELETE: L ×I
→L viene realizzata tramite la funzione DELETE (l,i)
– la ricerca e l’eliminazione  di un elemento DELETE: L ×Z→L viene 
realizzata tramite la funzione DELETE (l,x)"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#5,5,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itOperazioni possibili sulle liste
• Altre operazioni di aggiornamento
– l’inserimento prima di una posizione specifica 
INSERT_BEFORE: L ×I ×Z →L viene realizzato 
tramite la funzione INSERT_BEFORE (l,x,i)
– l’inserimento dopo una posizione specifica 
ADD_AFTER: L ×I  ×Z →L viene realizzato 
tramite la funzione ADD_AFTER (l,x,i)
– lo svuotamento della lista EMPTY: L →L viene 
realizzato tramite la funzione EMPTY (l)"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#6,6,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itOperazioni possibili sulle liste
• Operazioni di consultazione
– l’iteratore del 1° elemento della lista HEAD: L →I si ottiene 
tramite la funzione HEAD (l)
• ritorna l’iteratore non valido se la lista è vuota
– l’iteratore successivo all’iteratore corrente NEXT: L ×I→I 
si ottiene tramite la funzione NEXT (l,i)
• ritorna l’iteratore non valido se iè l’iteratore dell’ultimo elemento
– l’iteratore precedente all’iteratore corrente PREV: L ×I→I 
si ottiene tramite la funzione PREV( l,i)
• ritorna l’iteratore non valido se iè l’iteratore del primo elemento
– l’intero associato alla posizion e specificata da un iteratore 
INFO: L ×I→Z si ottiene con la funzione INFO( l,i)"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#7,7,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itOperazioni possibili sulle liste
• Altre operazioni di consultazione
– la ricerca della posizione di un elemento SEARCH: L ×Z→
I si ottiene tramite la funzione SEARCH (l,k)
• ritorna l’iteratore dell’elemento con chiave knella lista loppure 
l’iteratore non valido
– l’iteratore associato all’ultimo  elemento della lista LAST: L 
→I si ottiene tramite la funzione LAST (l)
• ritorna l’iteratore non valido se la lista è vuota
– la verifica se una lista è vuota IS_EMPTY: L →B è
realizzata dalla funzione IS_EMPTY (l)
– il numero degli elementi in lista SIZE: L →Z si ottiene 
tramite la funzione SIZE (l)"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#8,8,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itStrategie di realizzazione delle liste
• Dipendentemente dal tipo di operazioni che è
necessario compiere in maniera efficiente sulla lista esistono diverse strategie implementative:
– lista concatenata
• consente lo scorrimento effici ente della lista in avanti ma 
non consente un efficiente scorrimento all’indietro
– lista doppiamente concatenata
• supporta in maniera efficiente lo scorrimento in avanti e 
indietro
– accesso agli estremi
• consente un veloce accesso sia al primo che all’ultimo 
elemento della lista"
data_test\rootfolder\università\AlgoritmiStruttureDati\090-liste-tramite-array-03.pdf#9,9,"090-liste-tramite-array-03         copyright ©2021 patrignani@dia.uniroma3.itLista semplicemente concatenata
• La struttura di dati supporta il passaggio diretto 
da un iteratore all’iteratore successivo
– si vogliono le operazioni FIRST e NEXT in Θ(1)
I
INFOFIRST
I
INFONEXT I
INFONEXT iteratori
elementi E E EL lista"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#0,0,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Implementazioni di liste con
oggetti e riferimenti
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#1,1,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#10,10,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi: liste singolarmente concatenate
Esercizi sullo scorrimento delle liste
1. Scrivi lo pseudocodice della procedura 
SOMMA (l) che ritorna la somma degli 
elementi contenuti in una lista singolarmente 
concatenata di interi
2. Scrivi lo pseudocodice della procedura 
MASSIMO (l) che ritorna il valore del 
massimo elemento contenuto in una lista 
singolarmente concatenata di interi
• assumi che la lista non sia mai vuota"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#11,11,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata: cancellazione 
• DELETE (l,i): cancellazione del nodo i
• La cancellazione di un nodo diverso dal primo è poco 
efficiente in una lista singolarmente concatenata
• Occorre infatti modificare l’attributo next del nodo 
che lo precedel.head
l.headi
l
l"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#12,12,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi: liste singolarmente concatenate
3. Scrivi lo pseudocodice della procedura SEARCH (l,u) 
che ritorna il riferimento all’elemento iche contiene 
il valore intero uin una lista singolarmente 
concatenata di interi (oppure NULL se unon è nella 
lista)
– discuti la complessità dell’algoritmo in funzione del 
numero n degli elementi in lista
4. Scrivi lo pseudocodice della procedura PREV (l,i) 
che ritorna il riferimento all’elemento che precede 
l’elemento identificato dall’iteratore iin una lista 
singolarmente concatenata di interi (oppure NULL se 
icorrisponde al primo elemento della lista)"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#13,13,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi: liste singolarmente concatenate
5. Scrivi lo pseudocodice dell’operazione 
DELETE (l,i) che cancella il nodo idi una 
lista singolarmente concatenata
– discuti della complessità dell’algoritmo
6. Scrivi lo pseudocodice dell’operazione 
DELETE (l,u) che cancella il nodo che 
contiene il valore intero uin una lista 
singolarmente concatenata di interi
– discuti della complessità dell’algoritmo"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#14,14,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi: liste singolarmente concatenate
7. Implementa una pila di interi utilizzando 
oggetti e riferimenti
– devi realizzare le funzioni  NEW_STACK (),
IS_EMPTY (p), PUSH (p,u), e POP(p) facendo 
uso di oggetti e riferimenti
8. Implementa una coda di interi utilizzando 
oggetti e riferimenti
– devi realizzare le funzioni NEW_QUEUE (),
IS_EMPTY (c), ENQUEUE (c,u), e DEQUEUE (c) 
facendo uso di oggetti e riferimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#15,15,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi: liste singolarmente concatenate
9. Scrivi lo pseudocodice della procedura 
COMUNI (l1,l2) che ritorna il numero di elementi 
della lista l1che sono anche contenuti nella lista l2
– discuti la complessità dell’algoritmo proposto
10. Scrivi lo pseudocodice della procedura non ricorsiva 
INVERSA (l) che ritorna una nuova lista 
singolarmente concatenata in cui gli elementi sono in 
ordine inverso
11. Scrivi lo pseudocodice della precedura 
ACCODA (l1,l2) che accoda gli elementi della lista l2alla lista l1mantenendo l’ordine relativo che gli 
elementi avevano nelle liste originarie
– puoi supporre di poter modificare le liste in input"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#16,16,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista doppiamente concatenata
• Oltre all’attributo next i nodi dispongono 
anche dell’attributo prev
l.head
• Talvolta la lista ldispone anche di un attributo 
l.tail
l.head
l.tailll"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#17,17,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itInserimento nella lista
•INSERT (l,n): inserimento in testa alla lista
l.headl
l.headnx
l
nx"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#18,18,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itInserimento nella lista
•INSERT (l,n): inserimento in testa alla lista
9.l.head = x8.l.head.prev = x7. ifl.head != NULL6.x.prev = NULL5.x.next = l.head4.x.info = n3.Zx.prev, x.next (riferimenti  ad oggetti analoghi)2.Zx.info (intero)1.Zx è un nuovo oggetto con tre campi:INSERT(l,n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#19,19,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itCancellazione di un elemento
6.i.next.prev = i.prev5. if i.next != NULL4.l.head = i.next3. else 2.i.prev.next = i.next1. if i.prev != NULLDELETE(l,i)l.headi
l.headl
l"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#2,2,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itStrutture di dati con oggetti e riferimenti
• alcuni linguaggi supportano oggetti e riferimenti
– lo pseudocodice è uno di questi
• con oggetti e riferimenti si possono realizzare strutture 
di dati elementari in modo più naturale 
• vedremo la realizzazione del tipo astratto di dato lista
– pile e code possono essere rivisti come casi particolari di 
liste
– due principali varianti implementative:
• lista singolarmente concatenata
• lista doppiamente concatenata"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#20,20,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi su liste doppiamente concatenate
12. Scrivi lo pseudocodice dell’operazione 
INSERT_BEFORE (l,n,i) che riceva come 
parametri una lista doppiamente concatenata l, un 
intero ned un iteratore i, e inserisca nnella lista 
prima dell’elemento riferito da i
• discuti la complessità della procedura
13. Scrivi lo pseudocodice dell’operazione 
ADD_AFTER (l,n,i) che riceva come parametri una 
lista doppiamente concatenata l, un intero ned un 
iteratore i, e inserisca nnella lista dopo l’elemento 
riferito da i
• discuti la complessità della procedura"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#21,21,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi su liste doppiamente concatenate
14. Implementa una coda utilizzando una lista 
doppiamente concatenata 
• è possibile che le operazioni ENQUEUE e 
DEQUEUE abbiano entrambe complessità Θ(1)? 
• come si potrebbe fare per ottenere questo 
risultato?
15. Scrivi lo pseudocodice della procedura 
DELETE (l,u) che rimuova l’elemento che ha 
valore uda una lista doppiamente concatenata 
di interi
• discuti la complessità dell’algoritmo"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#22,22,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi su liste doppiamente concatenate
16. Scrivi lo pseudocodice della procedura 
INSERT_ORDERED (l,u) che inserisca nella lista l
(che si suppone ordinata in senso crescente) un 
intero umantenendo l’ordinamento crescente della 
lista
17. Scrivi lo pseudocodice della procedura MERGE (l1, 
l2) che accetti come parametri due liste doppiamente 
concatenate di interi ordinate in senso crescente e 
restituisca una lista ordinata in senso crescente con 
gli elementi di entrambe
– puoi supporre che tutti gli elem enti delle liste siano diversi"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#23,23,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi sulle liste ordinate
18. Scrivi lo pseudocodice della procedura 
DOPPIONI (l) che verifichi che una lista 
(non ordinata) doppiamente concatenata di 
interi non abbia doppioni
19. Scrivi lo pseudocodice della procedura 
DOPPIONI_SORTED (l) che verifichi che 
una lista doppiamente concatenata di interi 
ordinata in senso non-decrescente non abbia 
doppioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#24,24,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itListe con sentinelle
• Le liste realizzate con oggetti e puntatori 
offrono l’opportunità di introdurre speciali 
iteratori chiamati “sentinelle”
• Il primo iteratore della lista (la “sentinella”) è
sempre presente e non ha nessun elemento 
associato
• L’interatore non valido coincide con 
l’interatore che identifica la sentinella
• La struttura dati è circolare"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#25,25,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itListe con sentinelle
• Dalla lista si accede direttamente (ed 
esclusivamente) all’iteratore non-valido, cioè
alla sentinella
SNULL
I
INFONEXTI
INFO
elementi E EL
PREVlista
NEXT
PREVNEXT
PREV"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#26,26,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itUso della sentinella
• Concatenando NULL+NEXT si ottiene FIRST
• Concatenando NULL+PREV si ottiene LAST
• Questa strategia comporta diversi altri vantaggi
– molte procedure risultaranno semplificate
SFIRST
I
INFONEXTI
INFO
elementi E EL
PREVlista
NEXT
PREVNEXT
PREVLAST"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#27,27,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itRealizzazione della sentinella
• La sentinella è un nodo fittizio introdotto in 
testa alla lista
l.null
• La lista vuota contiene solamente la sentinella
l.nulll
l"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#28,28,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itProcedure nelle liste con sentinelle
• Esempi di procedura semplificata dall’uso di sentinelle
– lista doppiamente concatenata (senza sentinella)
– lista doppiamente concatenata con sentinella
2.i.next.prev = i.prev1.i.prev.next = i.nextDELETE(l,i) Zversione con sentinella (i != l.null)6.i.next.prev = i.prev5. if i.next != NULL4.l.head = i.next3. else 2.i.prev.next = i.next1. if i.prev != NULLDELETE(l,i) Zversione senza sentinella (i != NULL)"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#29,29,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itEsercizi sulle liste con sentinelle
20. Scrivi lo pseudocodice della procedura 
INSERT (l,n) che inserisce in testa ad una 
lista con sentinella lun intero n
21. Scrivi lo pseudocodice della procedura 
SEARCH (l,n) che ritorna un iteratore 
all’elemento della lista con sentinella lche ha 
valore n
• SEARCH (l,n) ritorna l.null se nnon è
presente nella lista l"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#3,3,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itOperazioni su una lista di interi
NEW_LIST () ritorna il riferimento ad una lista vuota
HEAD (l) ritorna l’iteratore del primo elemento della lista
LAST (l) ritorna l’iteratore dell’ultimo elemento della lista 
NEXT (l,i) ritorna l’iteratore dell’elemento che segue inella lista
ritorna un iteratore invalido se iè l’ultimo elemento
PREV (l,i) ritorna l’interatore dell’elemento che precede inella lista
ritorna un iteratore invalido se iè il primo elemento
INSERT (l,n) inserisce l’elemento nin testa alla lista l
INSERT_BEFORE (l,n,i) inserisce l’elemento nprima della posizione i
ADD(l,n) aggiunge nin coda alla lista l
ADD_AFTER (l,n,i) aggiunge l’elemento ndopo la  posizione i
DELETE (l,i) rimuove l’elemento in posizione i dalla lista l
DELETE (l,n) rimuove l’elemento ndalla lista l
EMPTY (l) vuota la lista
SEARCH (l,n) ritorna l’iteratore dell’elemento n nella lista l
IS_EMPTY (l) ritorna true se la lista è vuota, altrimenti ritorna false"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#4,4,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata (singly linked list)
• l’iteratore iè un riferimento ad un nodo della lista, 
che è un oggetto composto dai seguenti attributi
– i.info
• elemento in lista  del tipo opportuno
• può essere un riferimento ad un oggetto 
esterno con dati satellite 
– i.next
• riferimento al nodo seguente o NULL
• una lista lha un solo attributo
– l.head
• riferimento al primo nodo 
l.head
i.infoi.next
l"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#5,5,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata: lista vuota
• Quando la lista lè vuota l.head èNULL
1. return l.head == NULLIS_EMPTY(l)
1.l.head = NULL Zlo pseudocodice non dealloca memoriaEMPTY(l)• Pseudocodice delle procedure IS_EMPTY e 
EMPTYl.headl"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#6,6,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata: first e next
•FIRST : iteratore dell’elemento affiorante
•NEXT : prossimo elemento
1. return i.next Zil parametro l non è utilizzatoNEXT(l,i)1. return l.head Zpotrebbe essere NULLFIRST(l)l.head
l.headi
ll"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#7,7,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itRealizzazione di funzioni elementari
• La semplicità di alcune funzioni (come IS_EMPTY , 
EMPTY , FIRST , NEXT , ecc) induce a sostituirle con le 
istruzioni opportune direttamente nello pseudocodice
– questo ovviamente fa perdere di generalità al codice scritto
•E s e m p i o
...x = NEXT(l,x)...then...if !IS-EMPTY (l) ...
...x = x.next...then...if l.head != NULL ..."
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#8,8,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata: inserimento in testa
•INSERT : inserimento di nin testa alla lista
nl.head x
nl.headl
l
5.l.head = x4.x.next = l.head3. Zx.next (rif. ad analogo oggetto)2. Zx.info (intero)1.x.info = n Zx è un nuovo oggetto con due campi:INSERT(l,n) Zn è un intero"
data_test\rootfolder\università\AlgoritmiStruttureDati\100-liste-tramite-oggetti-08.pdf#9,9,"100-liste-tramite-oggetti-08         copyright©2022 maurizio.patrignani@uniroma3.itLista concatenata: cancellazione 
• DELETE_FIRST : rimozione del primo nodo
5.l.head = l.head.next4. else 3. error (“lista vuota”)2. if l.head == NULL1.ZNOTA: lo pseudocodice non dealloca l’elementoDELETE_FIRST(l)l.head
l.headl
l"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#0,0,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Alberi radicati
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#1,1,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#10,10,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.it
Alberi: definizioni
• Qualunque nodo xsul cammino (unico) dalla yalla radice è un 
antenato diy, mentre yè un discendente dix;
• L’insieme costituito da un nodo ze da tutti i suoi discendenti è
ilsottoalbero radicato a zx
yzantenato 
del nodo y 
discendente del 
nodo x zsottoalbero 
radicato a z"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#11,11,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlberi: definizioni
•U n a l b e r o ordinato è un albero per il quale l’ordine dei figli di ogni nodo è
significativo (non possono essere permutati)
•U n  a l b e r o  binario è un albero ordinato in cui i nodi hanno grado al più due
• Un albero binario è completo se ogni livello presenta tutti i nodi possibilialbero binario albero binario completo"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#12,12,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlberi: definizioni
• Un albero binario completo di altezza h
–h a  2hfoglie, dunque h= log2(numero foglie)
–h a  2h-1 nodi interni
–h a  2h+1-1 nodi albero binario completoprofondità
nodi
0 1
1 2
2 4
3 8
nodi totali
1
3
7
15"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#13,13,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itIl tipo astratto albero
• Tipo astratto albero di interi
–d o m i n i
• il dominio di interesse è l’insieme degli alberi di interi
• dominio di supporto: i riferimenti R che identificano le 
posizioni nell’albero
• dominio di supporto: gli interi Z = {0, 1, -1, 2, -2, …}• dominio di supporto: i booleani B = {true, false}
– costanti
• l’albero vuoto"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#14,14,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itOperazioni del tipo astratto albero
• Operazioni sugli alberi di interi
– ritorna il riferimento alla radice: ROOT: T →R
– ritorna il riferimento al figlio sinistro: LEFT: T ×R→R
– ritorna il riferimento al figlio destro: RIGHT: T ×R→R
– ritorna l’intero nel nodo specificato: INFO: T ×R→Z
– verifica se un albero è vuoto: IS_EMPTY: T →B
– aggiunge un nodo come radice: ADD_ROOT: T ×Z →T
– aggiunge un nodo come figlio sinistro: ADD_LEFT: T ×R ×Z →T
– aggiunge un nodo come figlio destro: ADD_RIGHT: T ×R ×Z →T
– elimina una foglia: DELETE_LEAF: L ×R→L
– cerca un nodo: SEARCH: T ×Z→R
– svuota l’albero: EMPTY: T →T
– conta i nodi dell’albero: SIZE: T →Z
–…"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#15,15,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itRappresentazione di alberi binari
• Analogamente alle liste, gli alberi binari possono 
essere rappresentati mediante oggetti e riferimenti
t.roott"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#16,16,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itRappresentazione di alberi binari
• Un nodo dell’albero binario è un oggetto con i 
quattro campi
– parent : riferimento al nodo genitore
–l e f t : riferimento al figlio sinistro
– right : riferimento al figlio destro
–i n f o : dati satellite
• Un albero binario è un oggetto con un solo 
campo root che è un riferimento al nodo 
radice"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#17,17,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itOperazioni sugli alberi binari
• NEW_TREE ()
– restituisce una struttura rappresentante l’albero vuoto
– questa funzione rappresenta la costante
• IS_EMPTY (t)
– restituisce TRUE se l’albero è vuoto
• ROOT (t)
– restituisce il riferimento alla radice dell’albero ( NULL se t è vuoto)
• LEFT (t,n)
– restituisce il riferimento (può essere NULL ) al figlio sinistro del nodo n
• RIGHT (t,n) 
– restituisce il riferimento (può essere NULL ) al figlio destro del nodo n
• INFO (t,n) 
– restituisce le informazioni (dat i satellite) memorizzate nel nodo n
•…"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#18,18,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
1. Scrivi lo pseudocodice delle funzioni
NEW_TREE () 
IS_EMPTY (t) 
ROOT (t) 
LEFT (t,n) 
RIGHT (t,n)
INFO (t,n) 
descritte nella slide precedente
2. Scrivi lo pseudocodice della funzione 
TWO_CHILDREN (n) che ritorna TRUE se il 
nodo nha due figli, FALSE altrimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#19,19,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
3. Scrivi lo pseudocodice della procedura
ADD_ROOT (t,z) che aggiunga il nodo radice con 
valore zall’albero binario t
– assumi che tsia vuoto
4. Scrivi lo pseudocodice delle procedure 
ADD_LEFT (t,n,z) e ADD_RIGHT (t,n,z) che 
aggiungono il figlio sinistro e destro al nodo n, 
contenente il valore z
5. Scrivi lo pseudocodice della funzione 
ONLY_LEFT (t) che restituisce TRUE se tutti i nodi 
dell’albero binario thanno solamente il figlio 
sinistro (o nessun figlio), FALSE altrimenti
• se l’albero è vuoto restituisci TRUE"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#2,2,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itSommario
• Alberi radicati
– definizione e uso
• Strutture di dati per rappresentare alberi
– alberi binari, alberi di grado arbitrario
• Esercizi sugli alberi"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#20,20,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itRappresentazione di alberi di grado arbitrario
• Per rappresentare alberi di grado arbitrario si 
possono utilizzare diverse strategie
– uso di una lista per i figli di ogni nodo
• poco usato perché molto prolisso
– uso di una struttura detta “figlio-sinistro-fratello-
destro”
• più sintetico"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#21,21,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itUso di una lista per i figli di ogni nodo
t.root
head
head headt"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#22,22,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itStruttura “figlio-sinistro-fratello-destro”
• I nodi hanno gli usuali campi parent , left , 
right e info
– i campi parent e info hanno il significato usuale
–i l  c a m p o  left è un riferimento al figlio di sinistra 
(cioè al primo figlio)
–i l  c a m p o  right , invece di essere un riferimento al 
figlio destro, è un riferimento al prossimo fratello
parent
1° figliofratello destro"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#23,23,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itFiglio-sinistro-fratello-destro
t.root
radice
figli della radice
figli del primo figliot"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#24,24,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itOperazioni sugli alberi qualsiasi
• NEW_TREE ()
– restituisce una struttura rappresentante l’albero vuoto
• IS_EMPTY (t)
– restituisce TRUE se l’albero è vuoto
• ROOT (t)
– restituisce il riferimento alla radice dell’albero ( NULL se tè vuoto)
• FIRST_CHILD (t,n)
– restituisce il riferimento (può essere NULL ) al figlio sinistro del nodo n
• NEXT_SIBLING (t,n) 
– restituisce il riferimento (può essere NULL ) al fratello destro del nodo n
• INFO (t,n) 
– restituisce l’intero memorizzato nel nodo n
•…"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#25,25,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itEsercizi sugli alberi qualsiasi
6. Scrivi lo pseudocodice della procedura 
ADD_ROOT (t,z) che aggiunga un nodo 
radice con valore zall’albero t
– supponi che l’albero tsia vuoto
7. Scrivi lo pseudocodice della procedura 
ADD_SIBLING (t,n,z) che aggiunge al nodo 
nun figlio che contiene il valore z"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#3,3,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itDefinizione di albero radicato (rooted tree)
•U n  albero radicato è
un insieme di nodi, su cui è definita una relazione binaria “ xè
figlio di y” (oppure “ y
è genitore di x”) tale 
che:
1. ogni nodo ha un solo 
genitore, con 
l’eccezione della radice 
che non ha genitori
2. c’è un cammino diretto 
da ogni nodo alla radice
• l’albero, cioè, è
connessoradice"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#4,4,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itEsempio di albero radicato
• Un albero può essere costruito a partire dalla radice 
aggiungendo ogni volta un nodo xcome figlio di un 
nodo ygià esistente
– ciò giustifica il fatto che, se l’albero ha nnodi, allora ci sono 
n-1 relazioni genitore/figlioradice"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#5,5,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itNumerose applicazioni usano alberi
• I rapporti di ereditarietà determinano alberi
– alberi genealogici o filogenetici
– ereditarietà di classi nella programmazione ad oggetti
• I rapporti gerarchici sono alberi
– gerarchie organizzative, di controllo, di responsabilità
• I rapporti di contenimento formano alberi
– la classificazione scientifica degli organismi (tassonomie)– le directory del filesystem– i cammini minimi da una sorgente  a tutti i nodi di una rete 
• La struttura sintattica di una frase è un’albero
– alberi sintattici 
•…"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#6,6,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlberi: definizioni
• Due nodi che hanno lo stesso genitore si dicono fratelli
• Il numero di figli di un nodo è il suo grado
• I nodi di grado zero sono foglie
• Un nodo non foglia è detto nodo internofratelli
nodo interno
foglianodo di grado due"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#7,7,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itTipi di alberi
• Alberi binari
– ogni nodo può avere solamente un figlio sinistro e 
un figlio destro
• l’ordine dei figli è generalmente significativo
• si distingue tra avere il solo fi glio sinistro e avere il solo 
figlio destro
• Alberi di grado arbitrario
– non è noto a priori il numero massimo dei figli di un 
nodo
• l’ordine dei figli generalmente non è significativo"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#8,8,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlberi: definizioni
• Una sequenza di nodi tali che uno è il genitore del successivo è
detta cammino
– il cammino percorre gli archi alla r ovescia rispetto alla figura qui sopra
• Il numero degli archi di un cammino è la sua lunghezzail cammino blu ha 
lunghezza due"
data_test\rootfolder\università\AlgoritmiStruttureDati\110-alberi-radicati-08.pdf#9,9,"110-alberi-radicati-08 copyright ©2019 maurizio.patrignani@uniroma3.itAlberi: definizioni
•L a  profondità di un nodo è la lunghezza del cammino dal nodo 
alla radice
• La profondità del nodo più profondo è l’altezza dell’alberoprofondità zero
profondità uno
profondità due
profondità trel’altezza 
dell’albero
èt r e"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#0,0,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Visite di alberi
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#1,1,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#10,10,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
• Visita in simmetrica
– processo il nodo dopo aver processato il figlio sinistro e 
prima di aver processato il figlio destro
– ordine di visita: 8, 4, 9, 2, 5, 1, 6, 3, 7 
– complessità: Θ(n)1
2
4
83
5 6 7
9"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#11,11,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
2. Scrivi lo pseudocodice della procedura 
CERCA (t,n) che ritorna TRUE se il valore nè
presente nell’albero binario t
– facendo uso di una visita in preordine
– facendo uso di una visita in postordine
– facendo uso di una visita simmetrica
3. Scrivi lo pseudocodice della procedura 
CONTA_NODI (t) che ritorna il numero di 
nodi dell’albero binario t
– fai uso di una visita in postordine"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#12,12,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
4. Scrivi lo pseudocodice della procedura CAMMINO (t) 
che verifica se un albero binario tè un cammino
– cioè se tutti i nodi hanno grado uno con l’eccezione 
dell’unica foglia
– assumi che un albero vuoto sia un cammino
5. Scrivi lo pseudocodice della procedura HEIGHT (t) 
che calcola l’altezza di un albero binario t
– cioè il numero di archi del cammino che va dalla radice 
alla foglia più profonda
– ritorna -1 se l’albero è vuoto"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#13,13,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itCERCA (t,v) in preordine
CERCA(t,v)  // ritorna TRUE se il nodo v e’ nell’albero t
1. return CERCA_PREORDINE (t.root,v) Zinnesco
CERCA_PREORDINE( n,v)
1. ifn == NULL 
2. return FALSE
3. ifn.info == v
4. return TRUE
5.l =CERCA_PREORDINE (n.left,v) Zsottoalbero sinistro
6.r =CERCA_PREORDINE (n.right,v) Zsottoalbero destro
7. return lor r"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#14,14,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itCERCA (t,v) in postordine
CERCA(t,v)   // ritorna TRUE se il nodo v è nell’albero t
1. return CERCA_POSTORDINE (t.root,v) Zinnesco
CERCA_POSTORDINE( n,v)
1. ifn == NULL 
2. return FALSE
3. if CERCA_POSTORDINE (n.left,v)
4. return TRUE
5. if CERCA_POSTORDINE (n.right,v)
6. return TRUE
7. return n.info == v"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#15,15,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itCERCA (t,v) con visita simmetrica
CERCA(t,v)
1. return RICERCA_SIMMETRICA (t.root,v) Zinnesco
RICERCA_SIMMETRICA( n,v)
1. ifn == NULL 
2. return FALSE
3. if RICERCA_SIMMETRICA (n.left,v)
4. return TRUE
5. ifn.info == v
6. return TRUE
7. return RICERCA_SIMMETRICA (n.right,v)"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#16,16,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itAltri esercizi sugli alberi binari
6. Scrivi lo pseudocodice della procedura 
AVERAGE (t) che calcoli la media dei valori 
contenuti in un albero binario t
– puoi far uso o meno di CONTA_NODI (t)
– se l’albero è vuoto produci un errore 
7. Scrivi lo pseudocodice della procedura 
COMPLETO (t) che verifichi se un albero 
binario tè completo
– puoi far uso o meno della procedura HEIGHT (t)
– se l’albero è vuoto ritorna TRUE"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#17,17,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itAltri esercizi sugli alberi binari
8. Scrivi lo pseudocodice della procedura 
DEALLOCA (t) che rimuova (deallocandoli) tutti i 
nodi di un albero t
9. Scrivi lo pseudocodice della procedura POTA (t,x) 
che elimini da un albero binario il sottoalbero 
radicato ad un nodo xspecificato tramite riferimento
– puoi omettere di deallocare i nodi potati
10. Scrivi lo pseudocodice della procedura POTA (t,h) 
che poti un albero binario lasciando solamente i nodi 
a profondità minore di h
– puoi fare uso o meno di POTA (t,x)"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#18,18,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itRappresentazioni testuali di alberi binari
11. Scrivi lo pseudocodice della procedura 
PARENTETICA_SIMMETRICA (t) che stampi un 
albero binario tnella rappresentazione parentetica 
simmetrica
–c i o è n e l  f o r m a t o :  
“(“ <sottoalbero-sx>  <val-radice> <sottoalbero-dx> “)”
– esempio: ((()2())1(()3()))
12. Scrivi lo pseudocodice della procedura 
PARENTETICA_PREORDINE (t) che stampi un 
albero binario tnella rappresentazione parentetica in 
preordine 
–c i o è n e l  f o r m a t o :
“(“ <val-radice> <sottoalbero-sx> <sottoalbero-dx> “)”
– esempio: (1(2()())(3()()))"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#19,19,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itAncora sugli alberi binari
13. Scrivi lo pseudocodice della procedura 
DUE_FIGLI (t) che calcoli il numero di nodi 
nell’albero binario tche hanno esattamente due figli
14. Scrivi lo pseudocodice della procedura 
VALORE_NONNO (t) che calcoli il numero di nodi 
dell’albero binario tche hanno lo stesso valore del 
genitore del genitore (cioè del nonno)
15. Scrivi lo pseudocodice della procedura 
QUATTRO_NIPOTI (t) che calcoli il numero di nodi 
dell’albero binario tche hanno quattro nipotini"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#2,2,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itSommario
• Visite di un albero
– visita in postordine (postorder traversal)
– visita in preordine (preorder traversal)– visita simmetrica di alberi binari (inorder traversal)
• Esercizi sulle visite di alberi"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#20,20,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itAncora sugli alberi binari
16. Scrivi la procedura CAMMINO (t,n) che ritorni una 
lista con gli identificatori dei nodi del cammino dalla 
radice fino al nodo il cui riferimento è n
– puoi supporre che nappartenga all’albero
17. Scrivi la procedura PARENTELA (t, n1, n2) che 
calcoli il grado di parentela di due nodi  con 
riferimenti n1ed n2
– il grado di parentela è definito come la lunghezza del 
cammino che unisce i due nodi
– puoi supporre di avere a disposizione la procedura 
CAMMINO (t,n)
• come potresti utilizzarla?"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#21,21,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi di grado arbitrario
18. Scrivi lo pseudocodice della procedura 
CONTA_NODI (t) che ritorni il numero dei 
nodi di un albero trealizzato tramite una 
struttura di dati “figlio-sinistro-fratello-
destro”
19. Scrivi la procedura CERCA (t,k) che ritorni il 
riferimento al nodo che contiene il valore kin 
un albero trealizzato tramite una struttura di 
dati “figlio-sinistro-fratello-destro”"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#22,22,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi di grado arbitrario
20. Scrivi la procedura BINARIO (t) che verifica 
se un albero trealizzato tramite una struttura 
di dati “figlio-sinistro-fratello-destro” sia in 
realtà un albero binario (in cui cioè i nodi hanno grado massimo due)
21. Scrivi la procedura GRADO_MASSIMO (t) che 
ritorni il numero massimo dei figli dei nodi di 
un albero trealizzato tramite una struttura di 
dati “figlio-sinistro-fratello-destro”"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#23,23,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sulla copia di alberi
22. Scrivi lo pseudocodice della funzione 
COPIA_ALBERO (t) che accetti in input un 
albero binario te restituisca in output una sua 
copia (senza modificare l’albero t)
23. Scrivi lo pseudocodice della funzione analoga 
per alberi di grado arbitrario"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#24,24,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itSoluzioni: COPIA_ALBERO (1)
COPIA_ALBERO(t)
/* t2 è un nuovo albero con il solo campo t.root */if ( t.root == NULL)
t2.root = NULL
else
/* temp è un nuovo nodo con i campi parent, left, right 
(riferimenti) e info (intero) */
t2.root = temptemp.parent = NULLCOPIA_RIC(t.root, temp)
return t2"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#25,25,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itSoluzioni: COPIA_ALBERO (2)
COPIA_RIC(n, n2)  /* lanciato sempre su due riferimenti non NULL */
n2.info = n.infoif (n.left == NULL) 
n2.left = NULL
else
/* temp nuovo nodo con i campi parent, le ft, right (rif) e info (intero) */
n2.left = temptemp.parent = n2COPIA_RIC(n.left, temp)
if (n.right == NULL) 
n2.right = temp
else
/* temp nuovo nodo con i campi parent, le ft, right (rif) e info (intero) */
n2.right = temptemp.parent = n2COPIA_RIC(n.right, temp)"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#3,3,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itVisite di alberi
• Un albero può essere visitato ricorsivamente con due 
opposte discipline
– visita in preordine (preorder traversal)
• dopo aver processato un nodo si pr ocede a processare i suoi figli
• le operazioni sui nodi vengono effettuate top-down
– visita in postordine (postorder traversal)
• un nodo può essere processato solo  quando i suoi figli sono stati 
processati
• le operazioni sui nodi vengono effettuate bottom-up
• Se l’albero è binario è possibile anche una strategia 
intermedia
– visita simmetrica (inorder traversal)
• si processa prima il figlio sinist ro, poi il nodo stesso, poi il figlio 
destro"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#4,4,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itVisita in preordine
I. entro nel generico nodo n
• ricevo dei parametri dalla 
procedura eseguita sul genitore
II. eseguo la computazione su n
• mi avvalgo dei valori già
computati sul genitore
III.e IV. lancio la procedura sul 
figlio sinistro e destro 
• passo dei parametri alle 
procedure eseguite sui figli 
V. esco dal nodo nnV I
II
III IV"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#5,5,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itVisita in postordine
I. entro nel generico nodo n
II. e III: lancio la procedura sul   
figlio sinistro e destro 
• raccolgo gli output dalle 
procedure lanciate sui figli
IV.eseguo la computazione su n
• mi avvalgo dei valori computati 
sui figli
V. esco dal nodo n
• restituisco un output alla 
procedura lanciata sul genitorenV I
IV
II III"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#6,6,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itVisita simmetrica
I. entro nel generico nodo n
• ricevo parametri dalla procedura eseguita 
sul genitore
II. lancio la procedura sul figlio sinistro
• posso passare dei parametri e ricevere un 
output
III. eseguo la computazione su n
• posso avvalermi dei parametri passati dal 
genitore
• posso avvalermi del valore computato sul 
solo figlio sinistro
IV. lancio la procedura sul figlio destro
• posso passare dei parametri e ricevere un 
output
V. esco dal nodo n
• posso resitituire un output alla procedura 
lanciata sul genitorenV I
IIIII IV"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#7,7,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
1. Scrivi la sequenza con cui i nodi vengono processati da una 
visita in preordine/postordine/simmetrica di questo albero binario
– qual è la complessità asintotica delle tre visite?
– nota: la sequenza dei nodi visitati è sempre la stessa. Ciò che cambia è
il momento in cui avvengono le computazioni sul nodo  1
2
4
83
5 6 7
9"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#8,8,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
• Visita in preordine
– appena arrivo su un nodo lo processo
– ordine di visita: 1, 2, 4, 8, 9, 5, 3, 6, 7 
– complessità: Θ(n)1
2
4
83
5 6 7
9"
data_test\rootfolder\università\AlgoritmiStruttureDati\120-visite-di-alberi-05.pdf#9,9,"120-visite-di-alberi-05         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli alberi binari
• Visita in postordine
– processo un nodo prima di lasciarlo definitivamente
– ordine di visita: 8, 9, 4, 5, 2, 6, 7, 3, 1 
– complessità: Θ(n)1
2
4
83
5 6 7
9"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#0,0,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Code di priorità
(Heap e HEAP_SORT )
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#1,1,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#10,10,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itUn heap codifica un albero
•L ’ h e a p  
consiste di un 
array h.A che 
codifica, 
livello per 
livello, un albero binario 
quasi 
completo0
1234
5
67
8h.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#11,11,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itUn heap codifica un albero
• h.A[0] èl a  
radice 
dell’albero 
• Dato il nodo 
associato alla 
posizione i:
– i nodi figli si 
trovano in posizione 2 i+1 
e 2i+2
– il nodo genitore 
(se i≠0) si 
trova in 
posizione  
(i-1)/2 0
1234
5
67
8
−
21i
i
12+i
22+ih.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#12,12,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itSemplificazione dello pseudocodice
• Per rendere più leggibile lo pseudocodice 
definiamo le seguenti funzioni
PARENT(i)  /* ritorna l’indice del parent del nodo i */
1. return (i-1)/2 
LEFT(i)    /* ritorna l’indice del figlio sinistro di i */
1. return 2i + 1
RIGHT(i)   /* ritorna l’indice del figlio destro di i */
1. return 2i + 2"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#13,13,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itDettagli implementativi
• Per maggiore flessibilità, anche se l’array è
lungo h.A.length , supponiamo che solo i 
valori compresi tra 0e h.size-1 siano 
significativi
– dove ovviamente h.size ≤h.A.length
h.Ahh.size
h.A.length
h.A[0]
h.A[1]"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#14,14,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itValori contenuti in un max-heap
• In un max-heap
l’elemento memorizzato nel 
nodo iha valore 
maggiore o uguale degli elementi memorizzati nei 
suoi figli
– la radice contiene il 
valore più alto 
dell’array
–p e r  j> 0, 
h.A[PARENT (j)] ≥
h.A[j] 16
14
8
210
7
9
3
416
14
10
8
7
9
3
2
40
1234
5
67
8h.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#15,15,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itMin-heap
• Esiste anche il 
min-heap che 
ha la proprietà
simmetrica
–l a  r a d i c e  
contiene il valore minore 
dell’array2
6
8
204
7
5
11
102
6
4
8
7
5
11
20
100
1234
5
67
8h.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#16,16,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProprietà degli heap
•S e  hè un heap che codifica un albero quasi-
completo con nelementi, gli n/2elementi da 
0 a n/2-1 sono nodi interni"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#17,17,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itDimostrazione della proprietà
Dimostriamo per induzione che i nodi interni sono n/2
• Passo base
– dimostriamo l’asserto per gli alberi completi
• un albero completo è un particolare albero quasi completo
• Passo induttivo
– dimostriamo che se vale per un albero quasi completo con n
nodi, vale anche per un albero quasi completo con n-1 nodi
• distinguiamo due casi: rimozione de l figlio destro e rimozione del 
figlio sinistro"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#18,18,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itPasso base: albero binario completo
• Sappiamo che un albero binario completo di altezza hha 2h
foglie e 2h-1 nodi interni e dunque n=2h+1-1 nodi totali
• Verifichiamo la formula: 
nodi interni = n/2= (2h+1-1)/2 = 2h-1/2= 2h-1"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#19,19,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itPasso induttivo: rimuovo un figlio destro
• Prima della rimozione avevo nnodi e n/2nodi interni (con ndispari)
– dalla disparità di nsegue che n/2= (n-1)/2 
• Dopo la rimozione ho n’ = n-1 nodi e il numero dei nodi interni non è
cambiato 
– ne segue che i nodi interni sono n/2= (n-1)/2 = n’/2"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#2,2,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itSommario
• Il tipo astratto di dato coda di priorità
• La struttura di dati heap
– procedura MAX_HEAPIFY
– procedura BUILD_MAX_HEAP
• Coda di priorità realizzata con un heap
• Algoritmo di ordinamento HEAP_SORT
– analisi della sua complessità"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#20,20,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itPasso induttivo: rimuovo un figlio sinistro
• Prima della rimozione avevo nnodi e n/2nodi interni (con npari)
– dalla parità di nsegue che n/2= (n-1)/2 + 1
• Dopo la rimozione ho n ’= n-1 nodi e i nodi interni sono diminuiti di uno
– dunque i nodi interni sono (n-1)/2 = n’/2"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#21,21,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProcedura MAX_HEAPIFY
MAX_HEAPIFY( h,i)
1.l = LEFT(i) Zindice del figlio sinistro 
2.r = RIGHT(i) Zindice del figlio destro
3. if(l ≤h.size-1 andh.A[l] > h.A[i]) massimo = l
4. else massimo = i
5. if (r ≤h.size-1 andh.A[r] > h.A[massimo] massimo = r
6./* ora massimo è il massimo  tra h.A[l], h.A[r] ed h.A[i]
7. ifmassimo ≠i
8. SCAMBIA_CASELLE (h.A,i,massimo)
9. MAX_HEAPIFY (h,massimo)• Se i due sottalberi radicati a LEFT (i) e a RIGHT (i) sono dei 
max-heap, allora la procedura MAX-HEAPIFY (h,i) trasforma il 
sottoalbero radicato ad iin un max-heap"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#22,22,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.it
Esecuzione di MAX_HEAPIFY sul nodo i
16
4
14
210
7 9 3
8 116
14
4
210
7 9 3
8 1
16
14
8
210
7 9 3
4 1i
l r
il sottoalbero 
radicato ad iè
diventato un 
max-heapi sottoalberi 
radicati ad l
ed rsono 
max-heap"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#23,23,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAnalisi di MAX_HEAPIFY
• Il tempo di esecuzione di MAX_HEAPIFY (h,i) si ottiene sommando
– il tempo di calcolo di massimo (linee 1-8), che è evidentemente Θ(1)
– il tempo di calcolo MAX_HEAPIFY (h, massimo ) dove il sottoalbero radicato a 
massimo ha dimensione ridotta rispetto a quello radicato ad iMAX_HEAPIFY( h,i)
1.l = LEFT(i) Zindice del figlio sinistro 
2.r = RIGHT(i) Zindice del figlio destro
3. if(l ≤h.size-1 andh.A[l] > h.A[i]) massimo = l
4. else massimo = i
5. if (r ≤h.size-1 andh.A[r] > h.A[massimo] massimo = r
6./* ora massimo è il massimo  tra h.A[l], h.A[r] ed h.A[i]
7. ifmassimo ≠i
8. SCAMBIA_CASELLE (h.A,i,massimo)
9. MAX_HEAPIFY (h,massimo)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#24,24,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.it
Analisi di MAX_HEAPIFY
• Il caso peggiore si presenta quando occorre ricorrere su un 
sottoalbero di profondità h-1, mentre il sottoalbero radicato al 
nodo fratello ha profondità h-2
– ricorda che l’albero è quasi-completo
• In questo caso, se i nodi dell’albero sono n, i nodi del 
sottoalbero più pesante sono n·2 / 33
16
8
210
7 9 6
4 1 516
3
8
210
7 9 6
4 1 5h-1hh-2"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#25,25,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAnalisi di MAX_HEAPIFY
• Il tempo di calcolo di MAX_HEAPIFY su un 
sottoalbero con nnodi è
T(n) ≤T(2n/3) + c
• Questa disequazione di ricorrenza può essere risolta 
con il master theorem 
T(n) = a·T (n/b) + p( nk) 
nello speciale caso in cui
a=1 b=3/2 k=0
che per a= bksi risolve in 
T(n) = Θ(nklog n) = Θ(log n)
• Dunque la complessità di MAX_HEAPIFY èΘ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#26,26,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAnalisi alternativa di MAX_HEAPIFY
• Il tempo di calcolo di MAX_HEAPIFY su un 
sottoalbero con nnodi è chiaramente pari a Θ(1)
moltiplicato per il numero di lanci ricorsivi di 
MAX_HEAPIFY
–Θ(1) è dovuto alle linee 1-8 dello speudocodice
• Poiché un albero binario quasi-completo ha altezza 
Θ(log n), il numero di lanci ricorsivi nel caso peggiore 
èΘ(log n)
• La complessità di MAX_HEAPIFY nel caso peggiore è
dunque: 
Θ(1) · Θ(log n) = Θ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#27,27,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProcedura BUILD_MAX_HEAP
• BUILD_MAX_HEAP trasforma un array A in un heap
• Se n = h.A.length, gli elementi con indice ≥ n/2sono 
tutte foglie
– ognuna è un heap con un solo elemento
• BUILD_MAX_HEAP esegue MAX_HEAPIFY sui nodi 
che non sono foglie, dal basso verso l’alto
BUILD_MAX_HEAP( h)
1.h.size = h.A.length
2. fori = h.A.length/2 -1 downto0  // i nodi interni 
3. MAX_HEAPIFY (h,i)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#28,28,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di BUILD_MAX_HEAP (1/2)
5
9
23
6
7
15
9
2
6
7
1
5
9
27
6
3
15
7
2
6
3
13
95
9
27
6
3
17
2
6
3
195
9
23
6
7
15
3
2
6
7
19
5i = 2
i = 1i = 0"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#29,29,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di BUILD_MAX_HEAP (2/2)
5
9
27
6
3
17
2
6
3
195 9
5
27
6
3
17
2
6
3
19
9
6
27
5
3
17
2
3
169 9
6
27
5
3
17
2
5
3
169
55i = 0"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#3,3,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itCode di priorità
• Una coda di priorità (priority queue) è una 
collezione di elementi
– ad ogni elemento è associato un valore di priorità
– i valori di priorità definiscono un ordinamento
• Operazioni sulle code di priorità
– l’utente vuole inserire efficientemente nuovi 
elementi con valori arbitrari di priorità
– l’utente vuole estrarre efficientemente l’elemento a 
più alta priorità"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#30,30,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAnalisi di BUILD_MAX_HEAP
• BUILD_MAX_HEAP lancia MAX_HEAPIFY un numero Θ(n) di 
volte
– il tempo di esecuzione di MAX_HEAPIFY nel caso peggiore è Θ(log n’)
• dove n’è il numero dei nodi del sottoalbero radicato al nodo sul quale è
lanciato MAX_HEAPIFY
• Siccome Θ(log n’) ⊆O(log n) possiamo dire che la complesità
di BUILD_MAX_HEAP nel caso peggiore è O( nlog n) 
–O ( nlog n) non è un limite asintoticamente stretto
– con un’analisi più rigorosa dimostreremo che la complessità di 
BUILD_MAX_HEAP nel caso peggiore è Θ(n)BUILD_MAX_HEAP( h)
1.h.size = h.A.length
2. fori = h.A.length/2 -1 downto0  // i nodi interni 
3. MAX_HEAPIFY (h,i)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#31,31,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di BUILD_MAX_HEAP
• La complessità di BUILD_MAX_HEAP coincide con la 
somma delle altezze di tutti i sottoalberi radicati ai 
nodi dell’albero
• Dimostriamo che tale somma sia Θ(n) per un albero 
completo con nnodi
•S i a  S(n) la somma delle altezze di tutti i sottoalberi di 
un albero binario completo con nnodi
– ricorda che la sua altezza è
• Dimostriamo per induzione che
)( )1(log 1 )(2 n n n hnnS Θ∈+ −=−−=1)1(log2 −+ = n h"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#32,32,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di BUILD_MAX_HEAP
• Caso base
– per un albero con la sola radice abbiamo
– infatti un albero con la sola radice ha un solo 
sottoalbero (l’albero stesso) che ha altezza zero1 )( −−= hnnS
0101)1( =−−=Sn= 1 h= 0"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#33,33,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di BUILD_MAX_HEAP
• Caso induttivo
– supponiamo che la formula sia vera per tutti gli 
alberi con un numero di nodi minore di n
n
21−n
21−nh
h-1
formula già dimostrata"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#34,34,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itComplessità di BUILD_MAX_HEAP
• Caso induttivo
=+

−− −−= h hn1)1 (212
hh n + −−= 21=+

−= hnS nS212)(ipotesi induttiva
1−−= hn=+

−+−−= h hn112121 )( −−= hnnS"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#35,35,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazione di una coda di priorità
• Le code di priorità possono essere gestite tramite un 
heap
• Supponiamo di gestire le dimensioni dell’array h.A 
tramite una crescita telescopica
• La complessità di questa funzione è costante Θ(1)NEW_QUEUE()
1./* h è un nuovo oggetto con i campi size (intero) ed A
2.(array di 100 interi) */
3.h.size = 0
4.return h"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#36,36,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazione di una coda di priorità
• Le due funzioni qui sopra hanno evidentemente una 
complessità costante Θ(1)IS_EMPTY( h)
1. return h.size == 0
MAXIMUM( h)
1. return h.A[0]"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#37,37,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProcedura EXTRACT_MAX
EXTRACT_MAX( h)
1. if IS_EMPTY (h)
2.error(“heap underflow”)
3.max = h.A[0]
4.h.A[0] = h.A[h.size - 1]
5.h.size = h.size - 1
6. MAX_HEAPIFY (h,0)
7. return max 
• Viene eliminato il primo elemento dalla coda
• L’ultimo elemento viene messo al suo posto
• Viene decrementato h.size
• La complessità totale è quella di MAX_HEAPIFY , cioè Θ(log n) 
nel caso peggiore"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#38,38,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProcedura INSERT
9.h.A[i] = key 8.i =PARENT(i)INSERT(h,key)
1. ifh.size == h.A.length
2.error(“overflow”)
3.h.size = h.size + 1
4.i = h.size - 1
5. while i>0 andh.A[PARENT(i)] < key
6.h.A[i] = h.A[ PARENT(i)]
6./* il genitore di i è stato spostato in basso */
• h.size viene incrementato di 1
• Il nuovo elemento viene “spinto in a lto” fino a trovare la posizione giusta
• La complessità nel caso peggiore è data dall’altezza dell’albero, 
cioè Θ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#39,39,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di INSERT (1)
9
6
27
5
87
2
5
869INSERT(h,8)
9
6
28
5
78
2
5
7699
6
27
57
2
569"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#4,4,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itDue applicazioni delle code di priorità
• Allocazione ai processi delle risorse condivise
– gli elementi della coda sono le ri chieste da parte dei processi di una 
specifica risorsa
• per esempio l’accesso all’hard disk o ad una periferica
– i processi in esecuzione generano n uove richieste con priorità dipendenti 
dall’utente o dal tipo di  operazione richiesta
– la risorsa è assegnata al processo con più alta priorità
• Simulazione di un sistema complesso guidata dagli eventi
– gli elementi della coda sono eventi , con associato il tempo in cui si 
devono verificare
– gli eventi vengono simulati in ordine temporale
– la simulazione di un evento può pr ovocare l’inserimento nella coda di 
altri eventi a distanza di tempo"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#40,40,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di INSERT (2)
9
6
28
5
78
2
5
7
1069INSERT(h,10)
9
6
28
5
78
2
5
769
10
9
6
210
5
710
2
5
7
869
810
6
29
5
79
2
5
7
8610
8"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#41,41,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itConclusioni sulle strutture di dati heap
• Consentono di realizzare delle code di priorità
in cui
– la creazione della coda di priorità ha complessità
Θ(n) 
• procedura BUILD_MAX_HEAP (h)
– l’inserimento di un elemento con priorità arbitraria 
ha complessità Θ(log n)
• procedura INSERT (h,key)
– l’estrazione dell’elemento con chiave maggiore ha 
complessità Θ(log n)
• procedura EXTRACT_MAX (h)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#42,42,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sugli heap
1. Illustra le operazioni di INSERT (h,10) sullo 
heap 
h.A = <15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1> 
2. Illustra le operazioni di EXTRACT_MAX (h) 
sullo heap 
h.A = <15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1>"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#43,43,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itProcedura HEAP_SORT
• A viene trasformato in un heap ( Θ(n))
•P e r  iche va da 0 ad A.length -1 (cioè Θ(n) volte)
– viene estratto il primo elemento  di A e viene posto in coda 
all’array ( Θ(1))
– viene lanciato MAX_HEAPIFY per ripristinare le proprietà
dell’heap (tempo Θ(log n) se gli elementi sono tutti distinti)HEAP_SORT( A)
1.h.A = A /* h è un nuovo heap */
2.h.size = A.length
3. BUILD_MAX_HEAP (h)
4. fori = h.A.length-1 downto1 
5. SCAMBIA_CASELLE (A,0,i)
6.h.size = h.size – 1
7. MAX_HEAPIFY (h,0)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#44,44,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di HEAP_SORT (1/5)
1
6
27
5
37
2
5
3
965
9
23
6
7
15
3
2
6
7
19
19
6
27
5
3
17
2
5
3
169BUILD_MAX_HEAP
1
6
27
5
37
2
5
3
961MAX_HEAPIFY
i = 6"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#45,45,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di HEAP_SORT (2/5)
1
6
23
53
2
5
7
961MAX_HEAPIFY7
6
2
5
12
5
1
967
3 31
6
2
52
5
7
961
3 3
6
5
23
13
2
1
7
956i = 5"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#46,46,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di HEAP_SORT (3/5)
MAX_HEAPIFY
1
5
2 2
6
7
951
3 31
5
23 3
2
6
7
951
5
2
1 1
6
7
925
3 31
2
5
6
7
921
3 3i = 4
i = 3"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#47,47,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di HEAP_SORT (4/5)
MAX_HEAPIFY
1
2
5
6
7
921
3 33
2
5
6
7
923
1 1
1
2
5
6
7
921
31
2
5
6
7
921
3MAX_HEAPIFY
i = 2"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#48,48,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsecuzione di HEAP_SORT (5/5)
2
1
5
6
7
912
31
5
6
7
921
3
5
6
7
921
31
5
6
7
921
3MAX_HEAPIFYi = 1"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#49,49,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itHEAP_SORT non è stabile
• Lo dimostriamo con un controesempio
• Ora la posizione dei due elementi è invertita5”
5’5’
5”5’
5”
5”5’
5” 5”5’BUILD_MAX_HEAP
MAX_HEAPIFY
5”
5’5”
i = 1 5’5”"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#5,5,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itCoda di priorità di interi
• Domini
– il dominio di interesse Q di tutt e le code di priorità di interi
– dominio di supporto: l’insieme degli interi Z
– dominio di supporto: l’insieme dei booleani { true , false }
• Costanti
– la coda di priorità vuota
• NEW_QUEUE (): inizializza e ritorna una coda di priorità vuota
• Operazioni
INSERT (Q,x): inserisce l’elemento x nella coda Q
MAXIMUM (Q): restituisce l’elemento di Q con chiave più grande
EXTRACT_MAX (Q): restituisce l’elemento di Q con chiave più grande e lo 
rimuove da Q
IS_EMPTY (Q): riporta true se la coda Q è vuota, false altrimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#50,50,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento visti finoracaso 
migliorecaso 
mediocaso 
peggiorein locostabile
SELECTION_SORT Θ(n2) si si
INSERTION_SORT Θ(n) Θ(n2) Θ(n2) si si
MERGE_SORT Θ(n logn) no si
HEAP_SORT Θ(n logn) si no
Nota: nel caso migliore HEAP_SORT ha complessità  Θ(nlog n) se gli elementi 
sono tutti distinti e complessità Θ(n) se gli elementi sono tutti uguali "
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#51,51,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itDomande sugli heap
3. Quali sono il numero mi nimo ed il numero massimo 
di elementi in uno heap di altezza h? 
4. In un max-heap, dove potrebbe risiedere l’elemento 
più piccolo, assumendo che siano tutti distinti? 
5. Un heap in cui l’array è ordinato in ordine inverso è
un max-heap? 
6. La sequenza <23, 17, 14, 6, 13, 10, 1, 5, 7, 12> è un 
max-heap? 
7. Qual è l’effetto di MAX_HEAPIFY (h,i) se l’elemento 
h.A[i] è più grande dei suoi figli?
8. Qual è l’effetto di MAX_HEAPIFY (h,i) se 
i > h.size/2-1 ? "
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#52,52,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi sulle code di priorità
9. Illustra le operazioni di MAX_HEAPIFY (h,2) sullo 
heap 
h.A = <27, 17, 3, 16, 13, 10, 1, 5, 7, 12, 4, 8, 9, 0> 
10. Illustra le operazioni di BUILD_MAX_HEAP (h) sullo 
heap 
h.A = <5, 3, 17, 10, 84, 19, 6, 22, 9>
11. Illustra le operazioni di HEAP_SORT sull’array 
A = <5, 13, 2, 25, 7, 17, 20, 8, 4> "
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#6,6,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazioni inefficienti di code di priorità
• Si potrebbe realizzare una coda di priorità tramite una 
lista ordinata
– l’inserimento nella lista di un nuovo elemento avrebbe 
complessità Θ(n)
– la rimozione dell’elemento a più alta priorità (il primo della 
lista) avrebbe complessità Θ(1)
• Si potrebbe realizzare una coda di priorità tramite una 
lista non ordinata
– l’inserimento (in testa) di un nuovo elemento avrebbe 
complessità Θ(1)
– la ricerca e la rimozione dell’elemento a più alta priorità
avrebbe complessità Θ(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#7,7,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itSono possibili realizzazioni più efficienti?
• L’obiettivo è quello di bilanciare i due costi
Rimozione dell’elemento a più alta prioritàInserimento di un nuovo elementoO(n)
O(log n)
O(1)
O(1) O(log n) O(n)?Realizzazione 
tramite una lista 
ordinata
Realizzazione 
tramite una lista 
non ordinata"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#8,8,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itLa struttura dati heap
• Un heap
– è una struttura dati che può essere utilizzata per 
realizzare una coda di priorità
– è uno speciale array i cui valori sono in rapporto 
con la loro posizione nell’array
– può essere un max-heap o un min-heap
• noi vedremo in dettaglio il max-heap"
data_test\rootfolder\università\AlgoritmiStruttureDati\130-heap-11.pdf#9,9,"130-heap-11         copyright ©2022 maurizio.patrignani@uniroma3.itAlberi binari “quasi completi”
• Gli heap rappresentano alberi binari quasi completi
• Un albero binario è quasi completo se l’ultimo livello può 
essere incompleto nella sua parte destra"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#0,0,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Algoritmi e Strutture di Dati
Quick-sort
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#1,1,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Nota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#10,10,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Tempo di esecuzione di PARTITION
• Le assegnazioni iniziali  e finali richiedono tempo costante
• Nel caso peggiore, come nel ca so migliore, il sottoarray A[p...r] 
viene scorso per intero da sinistra verso destra
• Il tempo di esecuzione TPARTITION (n) ∈Θ(n)PARTITION( A,p,r)    /* si assume p < r */
1.i = p /* i è il primo elemento > A[r] = pivot */
2. for j = p tor – 1  /* scorro l’array (non il pivot)*/
3. if A[j] ≤A[r]   /* A[r] è il pivot */
4. SCAMBIA (A,i,j)
5. i = i + 1
6. SCAMBIA (A,i,r)     /* metto il pivot al centro */
7. return i /* ritorno la posizione del pivot */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#11,11,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esercizi
1. Che cosa succederebbe nel QUICK_SORT se 
PARTITION (A,p,r) restituisse un valore quguale 
a r?
2. Illustrare le operazioni di PARTITION sull’array 
A = <13, 19, 9, 5, 12, 8, 7, 4, 11, 2, 6, 21>
3. Illustrare le operazioni di PARTITION su un array
– già ordinato in senso decrescente
– già ordinato in senso crescente
4. Quale valore restituisce PARTITION se tutti gli 
elementi dell’array A[ p...r] hanno lo stesso valore? "
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#12,12,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di PARTITION su 87654321
87654321j
ir
87654321j
ir
1765432887654321j
ir
87654321j
ir
87654321j
ir87654321j
ir
87654321j
ir
87654321
ir
17654328
ir"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#13,13,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di PARTITION su 12345678
12345678j
ir
12345678j
ir
12345678j
ir
12345678j
ir
12345678j
ir12345678j
ir
12345678j
ir
12345678j
ir
12345678j
ir
12345678j
ir12345678j
ir
12345678j
ir
12345678j
ir
12345678j
ir
12345678
ir"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#14,14,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Caso peggiore e migliore per QUICK_SORT
• Il caso peggiore per QUICK_SORT è quando 
PARTITION elegge a pivot il valore massimo 
o minimo dell’array
– in questo caso QUICK_SORT non ricorre su due 
sottoarray bilanciati, ma ricorre su un sottoarray più
corto di una casella ed un sottoarray degenere
• Il caso migliore per QUICK_SORT è invece 
quando PARTITION elegge a pivot il valore 
mediano dell’array
– in questo caso QUICK_SORT ricorre su due 
sottoarray bilanciati"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#15,15,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Analisi del caso migliore per QUICK_SORT
• Nel caso migliore il tempo di calcolo di QUICK_SORT
su un array con nposizioni è
T(n) = 2 · T( n/2) + Θ(n)
• Questa equazione di ricorrenza può essere risolta con il 
teorema dell’esperto 
T(n) = a·T (n/b) + p( nk) 
• Nello speciale caso in cui
a=2 b=2 k=1
•C h e  p e r  a= bksi risolve in 
T(n) = Θ(nklog n) = Θ(nlog n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#16,16,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Analisi del caso peggiore per QUICK_SORT
•S i  h a
T(0) = a
T(n) = T( n-1) + Θ(n) 
• Sappiamo che la soluzione di questa equazione 
di riccorrenza è
T(n) = a+ 
• E dunquen
∑g(k)
k=1
n
Θ(k) = Θ(n
k)= Θ(n2) T(n) =∑∑
k=1 k=1"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#17,17,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Analisi del caso medio per QUICK_SORT
• Si può dimostrare formalmente che nel caso medio 
QUICK_SORT ha una complessità Θ(n logn)
– l’analisi, però, è molto più complessa del caso migliore e 
del caso peggiore
• Nel seguito vedremo solamente due considerazioni 
intuitive che ci aiutano a giustificare questo risultato
1. qual è la complessità nel caso in cui lo sbilanciamento della 
ricorsione non supera mai una determinata soglia
2. qual è la complessità nel caso in cui ricorsioni sbilanciate si 
alternano a ricorsioni più bilanciate"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#18,18,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Caso bilanciato 9-a-1
• Supponiamo che PARTITION divida il 
sottoarray in due parti che hanno una 
proporzione fissa
– supponiamo che la proporzione sia 9-a-1
• Abbiamo
T(n) ≤T(9n/10) + T( n/10) + cn 
dove cn esplicita Θ(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#19,19,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Ricorsione con proporzione 9-a-1
cn
cn
cn
cn
≤cnn
1n109n10
1n1009n1009n100
181n100
81n1000729n1000
1≤cnlog 10 nlog 10/9 n
O(n lgn)• Ciò fa presumere che il costo nel caso medio sia 
molto vicino al caso migliore"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#2,2,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Quick-sort
• Algoritmo di ordinamento in loco ma non stabile
• Tempo di esecuzione 
– nel caso peggiore Θ(n2)
– nel caso migliore e medio Θ(nlog n)
• i fattori costanti na scosti nella notazione Θsono abbastanza piccoli
• Introdotto da Hoare nel 1962
– la versione che vedremo è una variante dovuta a Lomuto
• Basato sul paradigma divide et impera"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#20,20,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Alternanza di ricorsioni bilanciate e sbilanciate
• Supponiamo che nel 20% dei casi PARTITION produca una 
partizione meno bilanciata di 9-a-1
• Supponiamo che nell’albero delle chiamate ricorsive una 
ripartizione sbilanciata sia se mpre seguita da una bilanciata
• Il costo di una ripartizione sbilanciata può essere assorbito dal 
costo della ripartizione bilanciata
Θ(n)
Θ(n)n
n-2
2n-2
20 n-1Θ(n)
Θ(n)n
n-2
2n-2
2"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#21,21,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Versione randomizzata di QUICK_SORT
• E’ possibile modificare QUICK_SORT in 
maniera che i casi peggiori non coincidano con 
disposizioni notevoli degli elementi
RANDOMIZED_PARTITION( A,p,r)
1.i = RANDOM(p,r) 
2. SCAMBIA (A,r,i) 
3. return PARTITION (A,p,r)
RANDOMIZED_QUICK_SORT( A,p,r)
1. ifp < r then
2.q = RANDOMIZED_PARTITION (A,p,r) 
3. RANDOMIZED_QUICK_SORT (A,p,q-1)
4. RANDOMIZED_QUICK_SORT (A,q+1,r)"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#22,22,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Stabilità di QUICK_SORT
•QUICK_SORT non è stabile:
56514j
ir
56514j
ir
56514j
ir
56514j
ir56514j
ir
16554j
ir
16554
ir
14556
ir"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#23,23,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Algoritmi di ordinamento per confrontocaso 
migliorecaso 
mediocaso 
peggiorein locostabile
SELECTION-SORT Θ(n2) si si
INSERTION-SORT Θ(n) Θ(n2) Θ(n2) si si
MERGE-SORT Θ(n logn) no si
HEAP-SORT Θ(n logn) si no
QUICK-SORT Θ(nlog n)Θ(n log n) Θ(n2) si no"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#3,3,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Divide et impera nel quick-sort
Per ordinare un sottoarray A[p...r]
•D i v i d e
– A[p...r] viene ripartito (e risistemato) in due sottoarray non 
vuoti A[p...q–1] e A[q+1...r], in modo che ogni elemento del 
primo sia minore o uguale ad A[q] e ogni elemento del secondo sia maggiore ad A[q]
– l’indice q viene calcolato dalla  procedura di partizionamento
•I m p e r a
– i due sottoarray A[p...q–1] e A[q+1...r] sono ordinati, 
ricorsivamente
• Combina
– non c’è niente da fare: A[p...r] è ordinato"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#4,4,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Procedura QUICK_SORT
• La procedura QUICK_SORT ordina in loco l’intervallo A[ p..r]
–s e  p = r, allora l’intervallo contiene una  sola casella ed è già ordinato: 
l’invocazione di QUICK_SORT non ha effetto
–s e  p > r, allora l’intervallo è un interval lo degenere e l’invocazione di 
QUICK_SORT non ha effetto 
• Il valore qritornato da PARTITION è tale che p≤q≤r
• Per ordinare l’intero array viene invocata la procedura:
QUICK_SORT (A,0,A.length-1)QUICK_SORT( A,p,r)
1. ifp < r 
2.q = PARTITION (A,p,r) 
3. QUICK_SORT (A,p,q-1)
4. QUICK_SORT (A,q+1,r)"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#5,5,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di QUICK_SORT su
16732584pr
1324pr13247586
47586pr
1234 45687
1pr
45pr
23pr
4 687pr
678
78pr6 2
123456 7816732584
pr
76PARTITION
PARTITION
PARTITIONPARTITION"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#6,6,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Procedura PARTITION
• La procedura PARTITION viene invocata su 
un intervallo di almeno due elementi ( p< r)
– due casi base
• i due elementi sono ordinati
• i due elementi non sono ordinatiPARTITION( A,p,r)    /* si assume p < r */
1.i = p /* i è il primo elemento > A[r] = pivot */
2. for j = p tor – 1  /* scorro l’array (non il pivot)*/
3. if A[j] ≤A[r]   /* A[r] è il pivot */
4. SCAMBIA (A,i,j)
5. i = i + 1
6. SCAMBIA (A,i,r)     /* metto il pivot al centro */
7. return i /* ritorno la posizione del pivot */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#7,7,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di PARTITION su 16732584
16732584j
ir
16732584j
ir
16732584j
ir16732584j
ir
16732584j
ir
13762584j
ir
13762584j
ir13267584j
ir
13267584j
ir
13267584
ir
1324758616732584j
ir"
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#8,8,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di PARTITION su
• Caso base 1: PARTITION su una coppia ordinata16
16j
ir
16j
ir
16
ir
16PARTITION( A,p,r)    /* si assume p < r */
1.i = p /* i è il primo elemento > A[r] = pivot */
2. for j = p tor – 1  /* scorro l’array (non il pivot)*/
3. if A[j] ≤A[r]   /* A[r] è il pivot */
4. SCAMBIA (A,i,j)
5. i = i + 1
6. SCAMBIA (A,i,r)     /* metto il pivot al centro */
7. return i /* ritorno la posizione del pivot */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\140-quick-sort-06.pdf#9,9,"140-quick-sort-06         copyright ©2019 maurizio.patrignani@uniroma3.it Esecuzione di PARTITION su
• Caso base 2: PARTITION su una coppia non ordinata87
87j
ir
87
ir
87
ir
78PARTITION( A,p,r)    /* si assume p < r */
1.i = p /* i è il primo elemento > A[r] = pivot */
2. for j = p tor – 1  /* scorro l’array (non il pivot)*/
3. if A[j] ≤A[r]   /* A[r] è il pivot */
4. SCAMBIA (A,i,j)
5. i = i + 1
6. SCAMBIA (A,i,r)     /* metto il pivot al centro */
7. return i /* ritorno la posizione del pivot */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#0,0,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Alberi rosso-neri
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#1,1,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itContenuto
• Definizione di alberi rosso-neri
• Proprietà degli alberi rosso-neri
• Complessità delle operazioni elementari
• Rotazioni• Inserimenti e cancellazioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#10,10,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlberi rosso-neri e numero dei nodi
•Abbiamo appena dimostrato che in un albero 
rosso-nero h∈O(log n)
•Sappiamo però che in un albero binario h è
almeno l’altezza di un albero completo con n
nodi, cioè h∈Ω(log n) 
•Dunque in un albero rosso-nero h∈Θ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#11,11,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itOperazioni sugli alberi rosso-neri
• L’altezza dell’albero è logaritmica nel numero 
dei nodi ( h∈Θ(log n))
• Tutte le operazioni di consultazione eseguibili 
in tempo Θ(h) su un albero binario di ricerca 
sono eseguibili in tempo Θ(log n) su un albero 
rosso-nero:
–SEARCH
–MINIMUM–MAXIMUM"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#12,12,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itOperazioni INSERT e DELETE
• Le operazioni INSERT e DELETE possono 
ugualmente essere eseguite in Θ(log n)
•TREE_INSERT e TREE_DELETE , però, non 
garantiscono la conservazione delle proprietà
degli alberi rosso-neri
– a valle delle operazioni di inserimento e 
cancellazione devono essere lanciate delle 
procedure che ripristinano tali proprietà in Θ(log n)
• Nel seguito vedremo a titolo di esempio la sola 
procedura RB_INSERT per l’inserimento di un 
nodo"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#13,13,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itProcedura RB_INSERT
16. RB_INSERT_FIXUP( t,new)// ripristina le proprietà15.new.color = RED // i nuovi nodi sono sempre rossi14.new.left = new.right = t.null13. else y.right = new12.y.left = new11. else if new.key < y.key10.t.root = new // …aggiorno t.root9. ify == t.null // se new de ve diventare la radice…8.new.p = y // aggiorno il genitore di new7. else x=x . r i g h t6. x = x.left5. if new.key < x.key4.y = x // cerco il padre y a cui appendere new3. while x != t.null // finché non sono arrivato a t.null2.x = t.root1.y = t.nullRB_INSERT( t,new)/* inserisco il nodo new nell’albero t */"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#14,14,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itRotazioni
• L’operazione base che viene utilizzata per ripristinare le proprietà
dell’albero rosso-nero è la rotazione 
– le rotazioni non alterano i colori dei nodi
– l’albero rimane un albero binario di ricerca
– l’operazione può essere eseguita in tempo Θ(1)
x
y α
βγy
αβγxLEFT-ROTATE (t,x)
RIGHT-ROTATE (t,y)
α xβy γ α xβy γ"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#15,15,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itEsempio di rotazione a sinistra
7
4
3 6 911
218
14 19
12 17 22
12 7
4
3 618
211
914
12 1719
22
12"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#16,16,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itProcedura LEFT_ROTATE
12.x.p = y11.y.left = x10. else x.p.right = y9.x.p.left = y8. else if x == x.p.left7.t.root = y6. if x.p == t.null5.y.p = x.p4.y.left.p = x3. ify.left != t.null2.x.right = y.left // sposto β1.y = x.right // trovo yLEFT_ROTATE( t,x)x
yα
βγ
y
αβγ x"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#17,17,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itRipristino dell’albero rosso-nero
• Il nuovo nodo aggiunto è una foglia e ha colore rosso
• Ricordiamo i vincoli di un albero rosso-nero
1. ogni nodo è rosso o nero
2. la radice e la sentinella t.null sono nere
3. se un nodo è rosso entrambi i suoi figli sono neri
4. tutti i cammini che vanno dalla radice a t.null
contengono lo stesso numero di nodi neri
• Se l’albero era vuoto la proprietà 2 è violata
– in questo caso è sufficiente colorare la radice di nero
• Altrimenti solo la proprietà 3 potrebbe essere violata
– situazione più complicata"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#18,18,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itViolazione: nodo rosso con un figlio rosso 
•S e  RB_INSERT ha appeso il nuovo nodo new (che è
sempre rosso) ad un genitore rosso 
– chiamiamo “zio di new” il nodo fratello del genitore di new
• lo zio di new esiste sempre, 
eventualmente è t.null
– sono possibili tre casi
caso 1: new è un figlio sinistro e 
lo zio è nero e figlio destro
caso 1’: new è un figlio destro e 
lo zio è nero e figlio sinistro
caso 2: new è un figlio destro e lo zio è nero e figlio destro
caso 2’: new è un figlio sinistro e lo zio è nero e figlio sinistro
caso 3: lo zio di new è rosso7
5 8
4newzio di new new.p"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#19,19,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itViolazione: caso 1
caso 1:
new è un figlio sinistro e 
lo zio è nero e figlio destro
ricolorazione
di new.p e di new.p.p5811
1514
4zio di new
new
127
58
4new
127
151411rotazione destra su 
new.p.p
ora l’albero è rosso-neronew.pnew.p.p"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#2,2,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itMotivazioni
• Un dizionario realizzato con un albero binario 
di ricerca consente operazioni efficienti quando l’albero è bilanciato
• Ha senso investire delle risorse per mantenere 
l’albero bilanciatoalberi binari di ricerca (complessità nel caso peggiore)
Θ(log n) Θ(n) cancellazioneΘ(log n) Θ(n) inserimentoΘ(log n) Θ(n) ricercabilanciati sbilanciati operazione"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#20,20,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itViolazione: caso 2
1 7
5 8211
1514
4caso 2:
new è un figlio destro e lo 
zio è nero e figlio destro
rotazione sinistra su 
new.pzio di new
new
5811
1514
4zio di new
127i due nodi violano 
ancora la regola 3 
(ma questa volta new è
un figlio sinistro e posso 
applicare la procedura 
del caso 1)new.p
newnew.p"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#21,21,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itViolazione: caso 3
1 7
5 8211
1514
4
1 7
5 8211
1514
4caso 3:
lo zio di new è rosso
ricolorazione
di new.p , dello zio di
new e di new.p.pnewzio di new
newzio di newiterazione:
new = new.p.p
ora new e new.p
potrebbero ancora 
violare la regola 3 
(ma new èp i ù
vicino alla radice)new.pnew.p.p
new.p"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#22,22,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itViolazione: caso 3
• Nel caso 3 new è più vicino alla radice ma potrebbe 
violare la regola 3 con new.p
• Occorre rilanciare la procedura con il nuovo new
• Il caso peggiore è quando si ha una sequenza di casi 3 
fino a che non si risale alla radice
• Quando arriviamo alla radice questa diventa rossa
– in questo caso è sufficiente ricolorare la radice di nero
– questo equivale ad incrementa re di uno il numero dei nodi in 
ogni cammino dalla radice al nodo t.null"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#23,23,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itComplessità di RB_INSERT_FIXUP
• Le violazioni nel caso 1 e 2 vengono risolte in 
tempo Θ(1)
• Poiché l’albero è alto Θ(log n), la procedura per 
risolvere una violazione nel caso 3  può essere 
rilanciata al massimo Θ(log n) volte
• La complessità di RB_INSERT_FIXUP , e 
dunque di RB_INSERT , èΘ(log n) "
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#24,24,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itCancellazioni in un albero rosso-nero
• Analogamente ad RB_INSERT , la procedura 
RB_DELETE
– prima cancella un nodo con la stessa strategia di 
TREE_DELETE degli alberi binari di ricerca
– poi ripristina le proprietà degli alberi rosso-neri 
chiamando una opportuna procedura 
RB_DELETE_FIXUP
•RB_DELETE_FIXUP utilizza rotazioni e ricolorazioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#25,25,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itConclusioni
• Complessivamente gli alberi rosso-neri offrono 
una realizzazione di alberi binari di ricerca con 
le seguenti complessità nel caso peggiore
– inserimento in Θ(log n)
– cancellazione in Θ(log n)
– ricerca in Θ(log n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#26,26,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itEsercizi
1. Qual è la complessità dell’algoritmo TREE_SORT , 
che utilizza un albero binario di ricerca per ordinare 
un array, nel caso in cui l’albero sia un albero rosso-nero?
2. Data una realizzazione del tipo astratto di dato 
“insieme” tramite un albero rosso-nero con le 
seguenti funzioni
– INSERT(t,k) in Θ(log n)
– REMOVE(t,k) in Θ(log n)
– SEARCH(t,k) in Θ(log n)
realizza la funzione UNIONE (t1,t2) che calcola 
l’unione di due insiemi t1e t2e discutine la 
complessità"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#27,27,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itEsercizi
3. Mostra come un albero rosso-nero possa 
essere utilizzato per costruire una coda di 
priorità
– come si può fare per accedere all’elemento 
minimo/massimo della coda?
– qual è il costo delle operazioni di accesso, di 
cancellazione e di inserimento?"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#3,3,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlbero con sentinelle
• Gestire il bilanciamento di un albero è un obiettivo complesso
• Per semplicità vorremmo che non ci siano nodi con un solo 
figlio destro o un solo figlio sinistro
– questo può essere realizzato aggiungendo all’albero tun nodo 
“sentinella” t.null e sostituendo con un puntatore a t.null ogni 
valore NULL del puntatore x.left o x.right di un nodo x
14
10
7
316
12 15 NULL
NULL NULL NULL
NULL NULLNULL NULL14
10
7 12 1516
3
t.null"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#4,4,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itDefinizione di alberi rosso-neri
• Un albero rosso-nero è un albero binario di ricerca 
nel quale 
1. ogni nodo è rosso o nero
2. la radice t.root e la sentinella t.null sono nere
3. se un nodo è rosso entrambi i suoi figli sono neri
4. tutti i cammini che vanno dalla radice a t.null
contengono lo stesso numero di nodi neri
• Convenzionalmente chiamiamo “altezza” dell’albero 
rosso-nero la lunghezza del cammino più lungo tra la 
radice e t.null
– corrisponde in realtà all’altezza + 1"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#5,5,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itt.nullEsempio di albero rosso-nero
14
10
7
316
12 1521
19 23
2017
30
2826
38
39 354741• Attenzione
– l’albero deve essere un albero binario di ricerca
– non tutti gli alberi binari di ricerca possono essere colorati in maniera da 
diventare alberi rosso-neri
……"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#6,6,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlberi rosso-neri e bilanciamento
14
10
7
316
12 1521
19 23
2017
30
2826
38
39 354741• Tutti i cammini dalla radice a t.null hanno knodi neri (nell’esempio k=4)
– ogni cammino ha almeno k-1 archi (nell’esempio: 3 archi)
– il cammino più lungo alterna nodi neri e rossi e ha 2( k-1) archi (nell’esempio: 6 archi)
cammino 
più corto 
(3 archi)cammino più lungo 
(6 archi)esempio con 
k=4
h=6
t.null"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#7,7,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlberi rosso-neri e bilanciamento
14
10
7
316
12 1521
19 23
2017
30
2826
38
39 354741• Tutti i cammini dalla radice a t.null hanno knodi neri (nell’esempio k=4)
– la lunghezza del cammino più lungo (2( k-1)) è al massimo due volte la lunghezza 
del cammino più corto ( k-1)
cammino 
più corto 
(3 archi)cammino più lungo 
(6 archi)esempio con 
k=4
h=6
t.null"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#8,8,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlberi rosso-neri e profondità
14
10
7
316
12 1521
19 23
2017
30
2826
38
39 354741• Tutti i cammini dalla radice a t.null hanno knodi neri (nell’esempio k=4)
– l’albero contiene un sottoalbero completo di profondità h’=  h/2 – 1 
esempio con 
k=4
h=6
h’=2
cammino 
più corto 
(3 archi)cammino più lungo 
(6 archi)sottoalbero completo
t.null"
data_test\rootfolder\università\AlgoritmiStruttureDati\160-alberi-rosso-neri-11.pdf#9,9,"160-alberi-rosso-neri-11 copyright ©2020 maurizio.patrignani@uniroma3.itAlberi rosso-neri e numero dei nodi
• Tutti i cammini dalla radice a t.null hanno knodi neri (nell’esempio k=4)
– l’albero ha profondità massima h= 2(k-1) 
– l’albero contiene un sottoalbero completo di profondità h’=  h/2 – 1
• I nodi dell’albero sono almeno quelli del sottoalbero completo
– ricorda che un albero completo di altezza xha 2x+1-1 nodi 
121 21 22112 1'− =− =− ≥+

−+h h
hn
)1 log(2 + ≤ n h221h
n ≥+
• Dunque h∈O(log n))1 log(2+ ≤ nh"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#0,0,"170-complessita-problemi-08
1170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Complessità dei problemi
m.patrignani
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono prote tte dalle leggi sul copyright 
• il titolo ed il copyright relati vi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli a utori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#1,1,"170-complessita-problemi-08
2170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itContenuto
• Definizioni
– complessità O( f(n)), Ω(f(n)) e Θ(f(n)) di un 
problema 
• Problemi e complessità
– esempi di problemi di complessità ignota
– lower bound per gli algoritmi di ricerca basati su 
confronti
– lower bound per gli algoritmi di ordinamento per 
confronto
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itProblemi e complessità
• Sappiamo che
– un algoritmo corretto per un problema computazionale è una 
“ricetta” per la sua soluzione
• termina sempre
• produce un output che, nella definizione del problema, corrisponde 
all’istanza in input
• Un problema ammette infiniti algoritmi corretti
– di ogni algoritmo possiamo calcolare la complessità
asintotica
• Alcuni problemi ammettono algoritmi più efficienti di 
altri problemi
– i problemi hanno una comple ssità asintotica intrinseca?"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#10,10,"170-complessita-problemi-08
11170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlbero di decisione 
• Possiamo definire un albero i cui nodi interni 
sono i vari confronti es eguiti dall’algoritmo e le 
cui foglie sono le possibili risposte
• Questo albero è un albero binario con n foglie
– l’altezza dell’albero è Ω(log n)
– il numero dei confronti n ecessari per individuare 
una foglia è Ω(log n)
• Ne consegue che nel cas o peggiore una ricerca 
implica Ω(log n) confronti
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento
• Con considerazioni an aloghe dimostreremo un 
lower bound sugli algoritmi di ordinamento per confronto
• Gli algoritmi più veloci che conosciamo, come 
il  MERGE_SORT , hanno una complessità
temporale Θ(nlog n)
• Dimostreremo che tutti gli algoritmi di 
ordinamento per confronto hanno una 
complessità nel caso peggiore Ω(nlog n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#11,11,"170-complessita-problemi-08
12170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlgoritmi di ordinamento per confronto
• Un algoritmo di ordinamento è detto “ algoritmo 
di ordinamento per confronto ” se il flusso delle 
operazioni dipende dal confronto tra due 
elementi della sequenza
•E s e m p i o
–n e l  MERGE_SORT l’operazione MERGE confronta i 
valori delle due sotto-seque nze ordinate per ottenere 
un’unica sequenza ordinata
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itEsecuzione di un algoritmo per confronto
• Immaginiamo di lanciare un algoritmo di ordinamento per 
confronto con una generica sequenza di input (a,b,c)
a ≤b
c ≤b
a ≤c
b, c, anonono• L’algoritmo 
eseguirà un certo 
numero di confronti per poi produrre un output
– l’output è un’opportuna  
permutazione dei valori di input
• Se lo lanciamo con una 
sequenza con valori diversi 
alcuni confronti avranno esito 
diverso
– l’output prodotto è una diversa 
permutazione dei valori di inputb, a, csi"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#12,12,"170-complessita-problemi-08
13170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlbero di decisione
• L’esecuzione di un algoritmo di ordinamento per 
confronto equivale alla discesa in un immaginario albero di decisione
b ≤c
a, b, ca ≤b
a ≤c
a, c, b c, a, bc ≤b
c, b, a a ≤c
b, a, c b, c, asi
si
sisi
si nonono
no
no
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itNumero di confronti necessari
• Tutte le permutazioni degli elementi da ordinare 
devono essere foglie dell’albero di decisione
– ogni possibile permutazione dei valori di input deve essere 
raggiungibile
–s e  nsono gli elementi da ordinare  le possibili permutazioni 
sono n!
• Il numero di confronti eseguiti nel caso peggiore 
equivale al cammino più lungo tra la radice ed una 
foglia
– l’altezza di un al bero binario con n! foglie è almeno log2 n!
– il problema dell’ordin amento per confronto è Ω(log2 n!)"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#13,13,"170-complessita-problemi-08
14170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itApprossimazione di Stirling
• Consideriamo la funzione ln n!
– nel calcolo asintotico la base  del logaritmo è indifferente
00.511.522.5
123456789 1 0∑∫
=≈=+++=n
knxdx k n n
11ln ln ln 2ln1ln!ln L
∑
=n
kk
1ln∫nxdx
1ln
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itCalcolo di
• Integrazione per parti:
• Nel nostro caso
u=ln xv =x
•dv/dx= 1; du/dx= 1/x∫∫−= dxdxduv uvdxdxdvu
∫ ∫−=−=⋅ xxx dxxx xxdxx ln1ln 1ln
1 ln1) ln( ln ln
11+−=−= ≈∫∑
=nnnnxxx xdx knn
k∫nxdx
1ln"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#14,14,"170-complessita-problemi-08
15170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itOrdinamento per confronto: lower bound
• L’esecuzione di un al goritmo di ordinamento 
per confronto corrisponde alla discesa in un albero di decisione con n! foglie
–nè il numero di elementi da ordinare
• Nel caso peggiore il numero di confronti (nodi 
interni nel cammino radice-foglia) è Ω(nln n)
–MERGE_SORT è un algoritmo di ordinamento per 
confronto asintoticamente ottimo
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itDomande sulla complessità dei problemi
1. Supponiamo che il problema P abbia 
complessità O(n). E’ possibile che esista un 
algoritmo A che risolve P che abbia una 
complessità Ω(n2)?
2. Supponiamo che un problema P abbia 
complessità Θ(n2). Può esistere un algoritmo 
A che risolve P e ha compessità Ω(n)?
3. Supponiamo che un problema P abbia 
complessità Θ(n). Può esistere  un algoritmo A 
che risolve P e ha complessità Θ(n2)?"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#15,15,"170-complessita-problemi-08
16170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itSoluzioni
1. P ∈O(n). Può esistere A ∈Ω(n2)?
•S ì ,  s e  P  ∈O(n) vuol dire che esiste un (opportuno) 
algoritmo A’ ∈O(n). Gli altri algoritmi, tra cui A, 
che risolvono P possono avere complessità
arbitrariamente elevata 
2. P ∈Θ(n2). Può esistere A ∈Ω(n)?
• Sì. Non solo, tutti gli algoritmi che risolvono P 
hanno complessità Ω(n2) e dunque anche Ω(n)
3. P ∈Θ(n). Può esistere A ∈Θ(n2)?
• Sì, ciò non contraddice P ∈O(n) né P ∈Ω(n). "
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#2,2,"170-complessita-problemi-08
3170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAnalisi della complessità dei problemi
• Obiettivo
– classificare i problemi in ba se alla loro difficoltà di 
soluzione intrinseca
• determinare la quantità di risorse che comunque è necessario 
spendere per risolverli
• Strumento
– associare al problema la co mplessità dell’algoritmo più
efficiente che lo risolve
• Inconveniente
– dato un problema non è possibile considerare tutti gli infiniti 
algoritmi che lo risolvono
• non possiamo determinare direttamente la complessità dell’algoritmo 
più efficiente
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itComplessità O( f(n)) di un problema
• Un problema ha complessità temporale O(f(n)) se 
esiste un algoritmo che lo riso lve che ha complessità
temporale O( f(n))
• In forma stenografica:
P ∈O(f(n))⇔∃ A ∈O(f(n))
•O ( f(n)) sono le risorse sufficienti a risolvere il 
problema"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#3,3,"170-complessita-problemi-08
4170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itComplessità O( f(n)) di un problema
• Se un problema ha complessità temporale O( f(n))
– è garantito che il problema possa essere risolto spendendo 
O(f(n)) risorse
– è possibile che il problema possa essere risolto spendendo 
meno di O( f(n)) risorse
• potrebbe esistere un algoritmo più efficiente che non conosciamo
–f(n) è un limite superiore (upper bound) alle risorse 
sufficienti a risolvere il problema 
• Per dimostrare che un problema ha complessità O( f(n))
– occorre produrre un algoritmo che lo risolva e che abbia 
complessità O( f(n))
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itEsempio: problema O( f(n))
• La complessità temporale dell’algoritmo SOMMA è
O(n), dove nè il numero degli elementi dell’array A
• Il problema della somma di ninteri
– ha complessità temporale O( n)
– è limitato superiormente da f(n) = n
–“ è O ( n)”4. return somma3.somma = somma + A[i]2. fori = 1 toA.length-11.somma = A[0]SOMMA(A) Zrestituisce la somma degli elementi dell’array A"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#4,4,"170-complessita-problemi-08
5170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itComplessità Ω(f(n)) di un problema
• Un problema ha complessità temporale Ω(f(n)) se 
ogni algoritmo che lo ri solve ha complessità
temporale Ω(f(n))
• In forma stenografica:
P ∈Ω(f(n))⇔∀ A ∈Ω(f(n))
•Ω(f(n)) sono le risorse necessarie a risolvere il 
problema
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itComplessità Ω(f(n)) di un problema
• Se un problema ha complessità temporale Ω(f(n))
– non è possibile che il prob lema possa essere risolto 
spendendo meno di Ω(f(n))
– non è detto che il problema  sia risolvibile spendendo O( f(n))
–f(n) è un limite inferiore (lower bound) alle risorse 
necessarie per risolvere il problema 
• Per dimostrare che un problema ha complessità Ω(f(n))
– non possiamo considerare tutti gli algoritmi ch e lo risolvono
– non esiste un metodo preciso per determinare Ω(f(n))
• generalmente si ragiona sulla natura delle istanze e delle relative 
soluzioni"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#5,5,"170-complessita-problemi-08
6170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itEsempio: problema Ω(f(n))
• Consideriamo il problema del calcolo della somma di 
ninteri
• Tutti gli algoritmi che riso lvono il problema devono 
necessariamente prendere in considerazione gli n
interi in input
– altrimenti cambiando un valore di input l’algoritmo darebbe 
lo stesso output, e questo è assurdo  
• Il problema della somma di ninteri
– ha complessità temporale Ω(n) 
– è limitato inferiormente da f(n) = n
–“ èΩ(n)”
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itComplessità Θ(f(n)) di un problema
• Un problema ha complessità temporale Θ(f(n)) se 
se ha contemporaneament e complessità temporale 
O(f(n)) e Ω(f(n)) 
– non è possibile che il prob lema possa essere risolto 
spendendo meno di O( f(n))
– esiste almeno un algoritmo ch e risolve il problema in Θ(f(n))
• Limite inferiore e limite superiore coincidono
–f(n) è la complessità intrinseca del problema
• Non sempre è possibile determinare Θ(f(n))
– di molti problemi la complessità intrinseca è ignota"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#6,6,"170-complessita-problemi-08
7170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itEsempio: problema Θ(f(n))
• Per quanto detto sopra il problema della somma 
di ninteri ha complessità Θ(n)
– l’algoritmo proposto per dimostrare che il problema 
èO (n) è un algoritmo asintoticamente ottimo
• possiamo desistere dalla ricer ca di algoritmi più efficienti
• è anche vero che questo algoritmo ha complessità
temporale Θ(n)
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itProblemi dalla complessità ignota
• Problema del commesso viaggiatore
– trovare il circuito più breve che tocca ncittà
• Upper-bound
– esiste un algoritmo che ha complessità O( n22n)
• Lower-bound
– siccome occorre leggere l’input, il problema è Ω(n) 
– non è mai stato dimostrato che il problema non 
possa essere risolto in tempo polinomiale
• in realtà non è mai stato dimo strato che il problema non 
possa essere risolto in tempo lineare!"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#7,7,"170-complessita-problemi-08
8170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itProblemi NP-completi
• Il problema del commesso viaggiatore 
appartiene ad una classe  di problemi noti come 
problemi NP-completi
• I problemi NP-completi sono tutti equivalenti
– se si trovasse un algoritmo polinomiale in grado di 
risolvere un qualunque problema NP-completo si potrebbero risolvere in tempo polinomiale tutti i problemi NP-completi
• Si ritiene (ma non è sta to mai dimostrato) che 
un algoritmo polinomiale per un problema NP-
completo non possa esistere
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itLower bound di problemi comuni
• E’ molto difficile dimo strare un lower bound 
per un problema
• Nel seguito dimostre remo dei lower bound 
limitati al caso in cui gli algoritmi utilizzati 
siano basati su confronti
• In particolare dimostreremo
– lower bound Ω(log n) per algoritmi di ricerca basati 
su confronti
– lower bound Ω(n log n) per algoritmi di 
ordinamento basati su confronti"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#8,8,"170-complessita-problemi-08
9170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itIl problema della ricerca
• Il problema della ricerca può essere descritto 
come segue
– è nota una collezione di coppie <chiave,valore>
– un’istanza del problema è il valore di una chiave
– la soluzione del problema è il relativo valore
• oppure l’informazione che una coppia con tale chiave è
assente nella collezione
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itCosa sappiamo del problema della ricerca 
• Dipendentemente dal tipo di struttura dati che 
adottiamo per la co llezione di coppie 
<chiave,valore> il problema della ricerca ha 
diverse complessità nel caso peggiore
• Esiste un algoritmo più veloce di O(log n)?O(log n) Alberi rosso-neriO(log n) Array ordinatiO(n) Array non ordinatiO(n) Liste"
data_test\rootfolder\università\AlgoritmiStruttureDati\170-complessita-problemi-08.pdf#9,9,"170-complessita-problemi-08
10170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itAlgoritmi basati su confronti
• Un algoritmo di ricerca è detto “ algoritmo di 
ricerca basato su confronti ” se il flusso delle 
operazioni dipende esclusivamente dal 
confronto tra la chiave cercata ed una chiave 
della collezione
•E s e m p i o
– nella ricerca binaria si accede all’elemento 
intermedio dell’intervallo di  ricerca e si ricorre su 
uno dei due sottointervalli generati in base al 
confronto della chiave cercata con il valore della chiave dell’elemento intermedio
170-complessita-problemi-08 copyright ©2018 maurizio.patrignani@uniroma3.itEsecuzione di una ricerca per confronto
• Immaginiamo di lanciare un algoritmo di ricerca 
basato su confronti
x ≤y
z ≤w
u ≤v
soluzione 2nosìno• L’algoritmo 
eseguirà un certo numero di confronti per 
poi produrre un output
– l’output è un’opportuna  
cella di memoria
• Uno qualsiasi dei valori 
della collezione potrebbe essere l’output giusto"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#0,0,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Tabelle Hash
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#1,1,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#10,10,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFunzione hash
• La funzione hash h
– definisce una corrispondenza tra l’universo K delle 
chiavi e gli indici della tabella hash T[0…m-1]
h: K  →{0, 1, . . . , m-1}
– deve essere deterministica
• altrimenti dopo aver messo i valori nell’array non riesco 
più a ritrovare la loro posizione
– si richiede che sia calcolabile in tempo costante
• per contenere i tempi di calcolo
• L’elemento con chiave k∈K si troverà nella 
posizione h(k) nella tabella T"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#11,11,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itIl problema della collisione
• La funzione hha un codominio (gli mindici di T) 
molto più piccolo del dominio (tutti gli elementi di K)
– è inevitabile che si generino collisioni
0
h(k3)=1
h(k2)=2
3
h(k1)=4k3
k2
k1k4h(k4)=2universo 
delle chiavi K
chiavi 
utilizzate 
a runtime?
k1T
k3
?
v1v3"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#12,12,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itGestione delle collisioni con liste di trabocco
• Ogni posizione di Tè un riferimento al primo 
elemento di una lista detta “di trabocco”
0
h(k7)=1
h(k2)=h(k4)=2
3
h(k1)=h(k3)=h(k6)=4k7v7
k2v2
k1v1k4v4
k3v3k6v6T"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#13,13,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itListe di trabocco
• La lista di trabocco è una lista semplicemente 
concatenata
• Ogni nodo della lista è un oggetto con tre campi
–key : valore della chiave
• può essere un riferimento ad oggetto
–info : valore associato alla chiave
• può essere un riferimento ad oggetto
–next : riferimento al prossimo nodo
•èNULL per l’ultimo nodo della lista"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#14,14,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itRicerca di un elemento in base alla chiave
• Per ricercare un elemento devo scorrere la lista 
di trabocco opportuna
7. return NULL // non l’ho trovato6.x = x.next5. return x.info // l’ho trovato!4. if EQUAL (k,x.key) 3. while x != NULL2.x = T[i] // iteratore per  elementi della lista T[i]1.i = HASH(k) // devo guardare la lista i-esimaGET(T,k) // ritorna il valore associa to alla chiave (o NULL)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#15,15,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itInserimento di una coppia 〈chiave, valore 〉
• Anche l’inserimento prevede una ricerca
8.y.key = k // y nuovo elemento della lista
9.y.info = v
10.y.next = T[i]1.i = HASH(k) // devo cercare nella lista i-esima di T
2.x = T[i] // iteratore per  elementi della lista T[i]
3. while x != NULL
4. if EQUAL (x.key,k) 
5. x.info = v // sovrascrivo il vecchio valore
6. return // ho finito ed esco
11.T[i] = y // inserimento in testa7.x = x.nextPUT(T,k,v) // inserisce <k,v> (e ventualmente sovrascrive)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#16,16,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itCancellazione di un elemento
• L’elemento viene rimosso in base alla chiave
5. if EQUAL (x.key,k) // l’ho trovato
6. if prev == NULL // x è il primo della lista
7. T[i] = x.next
8. else // non è il primo della lista
9. prev.next = x.next // lo saltiamo
10. return // ho finito ed esco
11.prev = x // non trovato, provo il prossimo 
12.x = x.next4. while x != NULL1.i = HASH(k) // devo cercare nella lista i-esima di T
2.x = T[i] // iteratore per  elementi della lista T[i]
3.prev = NULL // punterà all’elemento che precede x DELETE(T,k) // rimuove l’elemento (se esistente)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#17,17,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFunzione EQUAL e funzione HASH
• Una precondizione perché si possa realizzare un 
array associativo con hashtable è che siano definite
– una funzione EQUAL
– una funzione HASH
• Entrambe le funzioni devono essere definite in 
base al contesto applicativo 
• Per motivi di efficienza si richiede generalmene 
che entrambe le funzioni siano calcolabili in tempo costante
– rispetto al numero ndegli elementi nell’hashtable"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#18,18,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itUna funzione EQUAL errata
• Supponi che le chiavi siano stringhe
– per esempio realizzate tramite array di caratteri
• La funzione EQUAL seguente è errata:
– in questo modo non vengono confrontati i valori 
contenuti negli array A e B, ma i loro riferimenti
• cioè gli indirizzi, che sono necessariamente diversi anche 
quando le due stringhe sono uguali1. return A == B EQUAL_WRONG (A,B) // A e B sono due array di caratteri"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#19,19,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itUna funzione EQUAL corretta
• La funzione seguente è una funzione corretta per 
questo contesto applicativo
– questa volta vengono confrontat i tutti i caratteri delle due 
stringhe
• la complessità della procedura è ancora Θ(1) se le stringhe hanno una 
dimensione massima nota e indipendente da n5. return FALSE // almeno un carattere diverso
6. return TRUE4. if A[i] != B[i]1. ifA.length != B.length
2. return FALSE // lunghezza diversa
3. fori=0 toA.length-1EQUAL(A,B) // A e B sono due array di caratteri"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#2,2,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itSommario
• Richiami sui tipi astratti di dato
– array associativo
– insieme
• Tabelle hash
– collisioni e liste di trabocco– uso per la realizzazione di tipi astratti di dato 
• Funzioni hash
– per interi, per stringhe, per oggetti"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#20,20,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itHASH: requisiti
• Requisiti funzionali
– è deterministica
• data una chiave k, dà sempre lo stesso risultato HASH(k)
• Requisiti prestazionali
– è calcolabile in tempo costante
– distribuisce le chiavi utilizza te in esecuzione in maniera 
pseudocasuale nell’intervallo [0… m-1]
• questo requisito potrà solo essere soddisfatto solo in modo 
probabilistico 
– le chiavi che saranno utilizzate dall’utente in esecuzione non sono note 
a priori
– comunque si scelga la funzione HASH esisterà sempre un insieme di 
chiavi che corrispondono alla stessa casella di T"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#21,21,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itHASH: ipotesi di distribuzione uniforme
• E’ soddisfatta dalla funzione HASH quando, data una 
chiave k∈K, la probabilità che HASH (k)=csia la stessa 
per ogni casella c∈[0…m-1] di T
– indipendentemente da quali al tre chiavi siano state già
inserite in T
• Implicazioni dell’ipotesi di distribuzione uniforme
– per chiavi simili vengono generati hash diversi
• spesso le chiavi utilizzate sono molto simili
– quali che siano le chiavi utilizzate, queste vengono con alta 
probabilità distribuite uniformemente nell’intervallo [0…m-1]"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#22,22,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFattore di carico
• Si definisce fattore di carico il rapporto αtra il 
numero ndi elementi memorizzati e il numero mdi 
posizioni disponibili
mnα=
•αè il numero medio di elementi memorizzati in ogni 
lista concatenata
• A seconda del valore di αabbiamo
α< 1 molte posizioni disponibili rispetto agli elementi 
memorizzati
α= 1 il numero di elementi corrisponde al numero delle 
posizioni disponibili
α> 1 molti elementi da memorizza re rispetto al numero delle 
posizioni disponibili"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#23,23,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itComplessità delle operazioni
• Caso migliore
– l’operazione è eseguita su una lista di trabocco vuota o con 
un solo elemento
– la complessità dell’operazione è data dalla complessità di 
HASH oppure di HASH + EQUAL
• complessità Θ(1)
• Caso peggiore
– tutte le chiavi utilizzate corrispondono alla stessa posizione
– la complessità coincide con quella che si ha per il calcolo di 
HASH (k) + la ricerca in una lista con n posizioni + il calcolo 
di EQUAL per n volte 
• complessità Θ(1) + Θ(n) + Θ(n) = Θ(n)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#24,24,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itComplessità nel caso medio
• Caso medio
– se la funzione HASH distribuisce le chiavi in modo 
uniforme nell’intervallo [0… m-1] 
• la lunghezza attesa delle liste di trabocco coincide con la 
lunghezza media α
• le operazioni hanno complessità Θ(α)
•s e  αnon supera mai una soglia fissata αmaxla 
complessità di ogni operazione è Θ(1)
– se la funzione HASH non dà garanzie rispetto alla 
distribuzione delle chiavi
• la complessità è la stessa del caso peggiore"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#25,25,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itNote sulla complessità nel caso medio
• Abbiamo stabilito che nel caso medio la complessità
delle operazioni sulle tabelle hash è Θ(α)
– dove αè per definizione α= n/m
• Dunque sembrerebbe che α∈Θ (n)
• Questo vorrebbe dire che, anche nel caso medio, la 
complessità delle operazioni è Θ(α) = Θ(n)
– cioè lineare come nel caso delle liste
– non si avrebbe nessun vantaggi o dall’adozione delle tabelle 
hash
• In che cosa sono errate le considerazioni qui sopra?"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#26,26,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itNote sulla complessità nel caso medio
• E’ errato considerare α∈Θ (n) a partire dalla 
definizione α= n/m
•A n c h e  m, infatti, cambia al crescere di n
– quando il fattore di carico αsupera una determinata soglia la 
dimensione mdella tabella viene raddoppiata
• il fattore di carico αviene dimezzato
– il costo medio delle operazioni è ancora costante in virtù del 
fatto che il costo (lineare) del raddoppio della tabella viene 
assorbito dai precedenti inserimenti eseguiti in tempo costante
• vedi slides sulla gestione telesc opica delle pile e sulla complessità
ammortizzata
• Una realizzazione delle tabelle hash che non preveda 
la gestione telescopica della tabella non può garantire 
tempi costanti di accesso"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#27,27,190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFunzioni hash
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#28,28,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFunzioni hash
• Considereremo delle funzioni hash per le 
seguenti tipologie di chiavi
– funzioni hash per interi
• metodo della divisione
– veloce ma raramente adottato
• metodo della moltiplicazione
– funzioni hash per stringhe
– funzioni hash per oggetti arbitrari"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#29,29,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della divisione: MOD_HASH
• Utilizza il resto di una divisione intera
h(k) = kmod m
• In pseudocodice:
• E’ un metodo molto veloce
• Se le chiavi sono già degli interi pseudocasuali 
la funzione MOD_HASH viene utilizzata per 
riportare le chiavi nell’intervallo [0… m-1]1. return k mod mMOD_HASH( k,m) // k ed m sono interi "
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#3,3,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itArray associativi
• Gli array associativi sono tipi astratti di dato costituiti 
da coppie <chiave,valore>
– le operazioni che vogliamo fare sono l’inserimento di una 
nuova coppia, la cancellazione di una specifica chiave e la ricerca del valore corrispondente ad una chiave
• Possono essere realizzati con coppie di array, liste, 
alberi binari di ricerca, alberi rosso-neri
• Le realizzazioni di array associativi si prestano anche a 
realizzare insiemi generici
– basta omettere il valore  e tenere solo la chiave
– le operazioni supportate sono inserisci elemento, cancella 
elemento e verifica esistenza elemento"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#30,30,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della divisione: MOD_HASH
• Se le chiavi non sono pseudocasuali
– la praticità del metodo è compromessa 
–MOD_HASH ha delle forti proprietà di località
• con altissima probabilità MOD_HASH (k+1) = 
MOD_HASH (k)+1
•s e  mè una potenza di 2 o di 10, MOD_HASH (k) produce 
la parte meno significativa del numero kespresso in 
quella base
– se si vuole usare questo metodo, è raccomandabile 
adottare come mun numero primo lontano da una 
potenza di due per limitare le collisioni
• per esempio 701"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#31,31,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della moltiplicazione: osservazione 1
• Supponiamo che le chiavi siano numeri reali 
pseudocasuali nell’intervallo (0,1) 
• La funzione
h(k) =  m · k 
è una buona funzione hash
–h(k) è deterministica
–h(k) può essere calcolata in Θ(1)
–h(k) distribuisce uniformemente le chiavi 
nell’intervallo [0… m-1]
• in quanto le chiavi erano già uniformemente distribuite!"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#32,32,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della moltiplicazione: osservazione 2
•S i a  irrun numero irrazionale
–irrha infinite cifre dopo la virgola, ma non è periodico
• Date delle chiavi intere qualsiasi, le cifre decimali 
dopo la virgola del prodotto k ·irrsi possono assumere 
uniformemente distribuite nell’intervallo (0,1)
– questo valore coincide con  k·irr − k·irr
– Knuth propone
• è la parte dopo la virgola della sezione aurea 
• è un numero irrazionale... 6180339.0215=−=irr
... 6180339.1215=+=
ϕ"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#33,33,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della moltiplicazione
• Si utilizza come hash la parte intera di un 
prodotto
h(k) =m ·(k·irr−k·irr) 
• Dove 
–irrè un numero irrazionale in (0,1) 
• per esempio la parte dopo la virgola della sezione aurea ϕ
definita nella slide precedente
–m può essere scelto arbitrariamente
• di solito si usa una potenza di due: m=2p, dove pèu n  
intero"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#34,34,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itMetodo della moltiplicazione: MUL_HASH
• La costante irrviene calcolata una volta sola
• La funzione MUL_HASH riceve in input l’array 
associativo a (per avere med irr) e la chiave k
– la funzione INT tronca un reale all’intero inferiore3.prod = m * (prod – INT(prod)) // reale in (0,m)
4.out = INT(prod) // intero in [0,m-1]1.m = a.T.length // m è un numero intero
2.prod = k * a.irr // prod è un numero reale
5. return out MUL_HASH( a,k) // a array associativo, k intero1.a.irr = ( SQRT(5)-1)*0.5 // a.irr costante irrazionale"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#35,35,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itHASH per stringhe: SIMPLE_HASH
• Ritorna un numero intero che poi deve essere ridotto 
nell’intervallo [0… m-1] con la funzione MOD_HASH
• Introdotta nella prima edizione del Kernigham-Ritchie
• Veloce ma generalmente considerata poco efficace nel 
distribuire i valori in modo pseudocausuale 
– permutazioni di caratteri hanno lo stesso hash!3.hash = hash + ASCII(S[i])
4. return hash2. fori = 0 toS.length-11.hash = 0 SIMPLE_HASH( S) // S è una stringa (array di caratteri)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#36,36,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itHASH per stringhe: DJB2_HASH
• Introdotta da Daniel J. Bernstein (donde il nome)
• Il numero 5381 è un numero primo
• Il “magic numer” 33 non è giustificato teoricamente
– ma dà ottimi risultati nella pratica
– corrisponde al prodotto * 32 (traslazione di cinque caselle 
della rappresentazione) + un incremento di uno
• può essere realizzato velocemente 3.hash = hash*33 + ASCII(S[i])
4. return hash2. fori = 0 toS.length-11.hash = 5381 DJB2_HASH( S) // S è una stringa (array di caratteri)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#37,37,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itFunzioni hash per oggetti
• Supponiamo che 
– l’oggetto abbia come chiave hcampi c1, c2, …, ch
– siano già definite opportune funzioni hash 
HASH1(c1), HASH2(c2), …HASHh(ch)
• Una funzione hash si può ottenere facilmente 
con la loro somma
HASH (o) = HASH1(o.c1)+HASH2(o.c2)+…+HASHh(o.ch) 
• Il risultato può essere riportato nell’intervallo 
opportuno tramite MOD_HASH"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#38,38,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itInsiemi
• Un insieme è una collezione di elementi 
omogenei
• Esempi di insieme
– l’insieme degli studenti
– l’insieme degli oggetti creati da un programma– l’insieme delle variabili utilizzate da un programma"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#39,39,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itIl tipo astratto di dato insieme
•D o m i n i
– il dominio di interesse è l’insieme I degli insiemi
– dominio di supporto: gli elementi E dell’insieme– dominio di supporto: i booleani B = {true, false}
• Costanti
– l’insieme vuoto
• Operazioni
– aggiunge un elemento: ADD: I ×E →I
– elimina un elemento dall’insieme: REMOVE: I ×E→I
– verifica l’appartenenza: CONTAINS: I ×E→B
–…"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#4,4,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itRealizzazioni efficienti di array associativi
• La realizzazione più efficiente che conosciamo 
degli array associativi utilizza alberi rosso-neri
– garantisce un tempo Θ(log n) per la ricerca, 
l’inserimento e la cancellazione nel caso peggiore e 
nel caso medio 
– occorre che sulle chiavi siano definite le funzioni 
MINORE e UGUALE
• Tutti gli algoritmi di ricerca basati su confronti 
hanno complessità Ω(log n) nel caso peggiore
– la ricerca è l’operazione più frequente e critica"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#40,40,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itRealizzazione di un insieme
• Si può usare una hashtable in cui lo stesso 
elemento funge da valore e da chiave
i
0
h(k7)=1
h(k2)=h(k4)=2
3
h(k1)=h(k3)=h(k6)=4T
k7
k2
k1k4
k3k6"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#41,41,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itProblemi
1. Illustra l’inserimento in una tabella hash di 
dimensione m=10 gestita con liste di trabocco 
delle chiavi 32, 17, 19, 31, 33, 15, 38, 46, 
utilizzando la funzione hash MOD-H
2. Scrivi lo pseudocodice delle funzioni 
ADD(I,e), REMOVE (I,e) e CONTAINS (I,e) 
dove Iè un insieme realizzato tramite una 
hashtable ed eè un elemento dell’insieme
– assumi che siano definite opportune funzioni 
HASH (e) e EQUAL (e1,e2)"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#42,42,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itProblemi
1. Quali sono le prestazioni delle tabelle hash se 
al posto di una lista semplicemente 
concatenata usiamo come trabocco un albero 
rosso-nero?"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#5,5,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itTabelle hash
• Le tabelle hash realizzano array associativi con le 
seguenti caratteristiche
– gli algoritmi di ricerca, inse rimento e cancellazione non sono 
basati su confronti
– le ricerche, gli inserimenti e le cancellazioni avvengono con 
un tempo Θ(n) nel caso peggiore
• peggiorativo rispetto agli alberi rosso-neri
– le ricerche, gli inserimenti e le cancellazioni avvengono con 
un tempo Θ(1) nel caso medio
• migliorativo rispetto ag li alberi rosso-neri
– la struttura di dati utilizzata è effettivamente un singolo array"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#6,6,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itDifficoltà da superare nella realizzazione
• Due difficoltà principali
1. la tipologia delle chiavi
• le chiavi non sono necessariamente degli interi
• non possiamo confidare nelle chiavi per indicizzare 
direttamente un array
2. la numerosità delle possibili chiavi
• anche se le chiavi fossero degli interi, un array in 
grado di contenere tutte le chiavi sarebbe troppo 
grande e troppo sparso
– per esempio se la chiave fosse un numero di matricola di 
sei cifre dovrei allocare un array con un milione di 
posizioni anche se gli studenti del corso che voglio 
considerare sono solo qualche centinaio"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#7,7,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itArray associativi: osservazione
• Il numero di chiavi effettivamente utilizzate dal 
programma in esecuzione è molto minore del numero delle chiavi possibili
– quest’ultimo è chiamato “universo” delle chiavi K
k3
k2
k1universo 
delle chiavi K
chiavi 
utilizzate 
a runtime
dati associati"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#8,8,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itRealizzazione tramite tabelle hash
1. Utilizzo un array Tper memorizzare i dati 
associati
– la dimensione mdell’array T
• è molto minore della dimensione dell’universo K
• è molto vicina al numero delle chiavi effettivamente 
utilizzate dal programma in esecuzione
– l’array T, come tutti gli array, può essere 
indicizzato solo da un intero 
2. Definisco una funzione hash h che trasforma 
le chiavi di K negli interi nel range [0… m-1]"
data_test\rootfolder\università\AlgoritmiStruttureDati\190-tabelle-hash-08.pdf#9,9,"190-tabelle-hash-08 copyright ©2021 maruzio.patrignani@uniroma3.itTabella hash
• L’array Tindicizzato tramite la funzione hash h
è chiamato tabella hash (oppure hashtable )
0
h(k3)=1
h(k2)=2
3
h(k1)=4k3
k2
k1universo 
delle chiavi K
chiavi 
utilizzate 
a runtime k2
k1T
k3
v2
v1v3"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#0,0,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
I grafi
rappresentati con matrici e liste di adiacenza
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#1,1,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istitutipubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#10,10,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itIl tipo astratto di dato grafo
•D o m i n i
– il dominio di interesse è l’insieme G dei grafi (diretti o non diretti)
– dominio di supporto: l’insieme degli iteratori NI per i nodi
– dominio di supporto: l’insieme degli iteratori AI per gli archi
– dominio di supporto: i booleani B = {true, false}
•C o s t a n t i
– il grafo vuoto
– gli iteratori non validi per nodi e archi
• Operazioni
– trova il primo nodo del grafo: FIRST_NODE: G →NI
– trova il prossimo nodo:                                         NEXT_NODE: G ×NI→NI
– trova il primo arco di un nodo:                                 FIRST_EDGE: G ×NI→AI
– trova il nodo adiacente tramite l’arco:                ADJ_NODE: G ×N1 ×AI→N1
– trova il prossimo arco: NEXT_EDGE: G ×N1 ×AI→AI
– determina se due nodi sono adiacenti                      ARE_ADJ: G ×N1 ×NI→B
– aggiunge un nodo al grafo: ADD_NODE: G →NI
– aggiunge un arco tra due nodi: ADD_EDGE: G ×N1 ×NI→AI"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#11,11,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazione mediante matrice di adiacenza
• Rappresentazione preferita per 
grafi densi
– cioè per i quali il numero degli 
archi mè prossimo ad n2
• Consente di sapere rapidamente 
se c’è un arco tra due nodi
• Usa una matrice (o un array di 
array) in cui l’elemento in 
posizione ( i,j) segnala se esiste 
l’arco ( i,j)
•O c c u p a  Θ(n2) spazio0 100001 1000 100000000000 10 10 100000000012345
0
1
2
3
4
50
23
4
1
5g
g.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#12,12,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazione tramite liste di adiacenza
• Si fa uso di un array Adi liste doppiamente concatenate
– generalmente si mette nell’array di rettamente il riferimento al primo 
elemento della lista
0
1
2
3
42
54
0
5 0 4prevkey
next
40
23
4
1
5g g.A"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#13,13,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRappresentazione dei grafi: liste di adiacenza
• Questa rappresentazione occupa spazio O( n) + O( m)
– nel caso peggiore, siccome m= O(n2) utilizza uno spazio 
O(n2) come le rappresentazioni con matrici di adiacenza
– in numerose applicazioni, però, m∈O(n)
• in questo caso le rappresentazio ni con liste di adiacenza sono 
preferibili
• La lista di adiacenza di un nodo può essere lunga O( n)
• Percorrendo tutte le liste di adiacenza di tutti i nodi si 
impiega un tempo O( n) + O( m) 
– che diventa O( n2) se il grafo è denso"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#14,14,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazioni del tipo astratto di dato grafo
• Matrice di adiacenza
– l’iteratore per un nodo è un intero
• è valido se è nell’intervallo legittimo per l’array g.A
– l’iteratore per un arco uscente da un nodo è ancora un intero
• è valido se è nell’intervallo legittimo e se la cella corrispondente dell’array 
g.A contiene un uno
– si riuncia a realizzare efficienteme nte l’operazione di aggiunta di un 
nodo
• Liste di adiacenza
– l’iteratore per un nodo è un intero
• è valido se è nell’intervallo legittimo per l’array g.A
– l’iteratore per un arco è un riferi mento ad un elemento di una lista
• l’iteratore non valido è NULL
– anche in questo caso l’operazione di  aggiunta di un nodo richiede una 
gestione non semplice e non sempre efficiente"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#15,15,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRappresentazione di grafi non orientati
• Per ogni arco non orientato ( u,v) vengono 
rappresentati i due archi orientati ( u,v) e (v,u)
• Nel caso di matrice di adiacenza
– la matrice è simmetrica
• Nel caso di liste di adiacenza
– se la lista del nodo icontiene il nodo j, allora la lista 
del nodo jcontiene il nodo i"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#16,16,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itGrafi pesati sugli archi
• Sono grafi in cui ad ogni arco eè associato un peso we
• Nella rapprentazione tramite matrici di adiacenza si 
usano i valori dei pesi al posto degli uni:
– si assume che non esistano archi con peso zero e si usa lo 
zero per rappresentare l’assenza dell’arco
–s i  u s a  weper rappresentare un arco di peso we
• Nella rappresentazione tramite liste di adiacenza
– ogni elemento della lista ha, oltre all’indice del nodo 
adiacente, anche un attributo weight con valore we"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#17,17,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itRealizzazioni in linguaggio C
• La rappresentazione dei grafi in linguaggio C 
segue gli stessi paradigmi della 
rappresentazione in pseudocodifica
– tuttavia, poiché gli array in linguaggio C non hanno 
un campo “length” che ne riveli la lunghezza 
occorre aggiungere un campo “numero_nodi” ad entrambe le rappresentazioni
g.Ag.numero_nodi
g
....."
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#18,18,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi su matrici di adiacenza
• Dato un grafo grappresentato tramite una matrice di 
adiacenza g.A(un array di array)
1. scrivi una procedura LISTE (g) che ne restituisca la sua 
rappresentazione mediante un array di liste di adiacenza 
doppiamente concatenate
2. scrivi una procedura GRADO_USCITA (g,u) che calcoli il 
grado di uscita del nodo con indice u
3. scrivi una procedura GRADO_INGRESSO (g,u) per il calcolo 
del grado di ingresso del nodo con indice u
4. scrivi una procedura GRADO_USCITA_MEDIO (g) per il 
calcolo del grado di uscita medio dei nodi del grafo
5. scrivi una procedura GRAFO_SEMPLICE (g) che verifica se 
il grafo è semplice (privo di cappi)
• Discuti la complessità degli algoritmi che hai proposto"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#19,19,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi su liste di adiacenza 1/3
• Dato un grafo diretto grappresentato tramite un array 
g.Adi liste di adiacenza doppiamente concatenate
6. scrivi una procedura MATRICE (g) che ne restituisca la sua 
rappresentazione mediante una matrice di adiacenza
7. scrivi una procedura GRADO_USCITA (g,u) che calcoli il 
grado di uscita del nodo con indice u
8. scrivi una procedura GRADO_INGRESSO (g,u) per il 
calcolo del grado di ingresso del nodo con indice u
9. scrivi una procedura GRADO_USCITA_MEDIO (g) per il 
calcolo del grado di uscita medio dei nodi del grafo
10. scrivi una procedura GRAFO_SEMPLICE (g) che verifica 
se il grafo è semplice (privo di cappi)
• Discuti la complessità degli algoritmi che hai 
proposto"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#2,2,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itContenuto
• Definizione di grafi diretti e indiretti
• Rappresentazione di grafi tramite:
– matrici di adiacenza
– liste di adiacenza
• Esercizi su grafi"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#20,20,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi su liste di adiacenza 2/3
• Dato un grafo diretto grappresentato tramite un array g.Adi 
liste di adiacenza doppiamente concatenate
11. scrivi lo pseudocodice della funzione VERIFICA_ARCO (g,u,v) che 
restituisce true se esiste l’arco che va dal nodo identificato dall’indice 
ual nodo indentificato dall’indice ve false altrimenti
12. scrivi lo pseudocodice della funzione 
VERIFICA_NON_ORIENTATO (g) che  restituisce true se il grafo 
presenta un arco ( u,v) per ogni arco ( v,u) e false altrimenti
• puoi utilizzare la funzione VERIFICA_ARCO (g,u,v)
13. scrivi lo pseudocodice della funzione VERIFICA_POZZO (g,u) che 
restituisce true se il nodo identificato dall’indice unon ha archi 
uscenti, false altrimenti
14. scrivi lo pseudocodice della funzione VERIFICA_SORGENTE (g,u) 
che restituisce true se il nodo identificato dall’indice unon ha archi 
entranti, false altrimenti
• Discuti la complessità degli algoritmi che hai proposto"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#21,21,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itEsercizi su liste di adiacenza 3/3
• Dati due grafi g1e g2rappresentati tramite array di liste di 
adiacenza doppiamente concatenate
15. scrivi lo pseudocodice della funzione VERIFICA_UNIONE (g1,g2) 
che verifica che tra ogni possibile co ppia di nodi ci sia un arco in g1o 
in g2(o in entrambi)
• puoi supporre che g1e g2abbiano lo stesso numero di nodi 
(g1.A.length =g2.A.length )
16. scrivi lo pseudocodice della funzione 
VERIFICA_POZZI_E_SORGENTI (g1,g2) che restituisce true se 
tutti i pozzi di g1sono sorgenti di g2e tutte le sorgenti di g1sono 
pozzi di g2e restituisce false altrimenti
• puoi suppore che g1e g2abbiano lo stesso numero di nodi
• puoi utilizzare le funzioni VERIFICA_POZZO (g,u) e 
VERIFICA_SORGENTE (g,u)
• Discuti la complessità degli algoritmi che hai proposto"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#3,3,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itGrafi nelle applicazioni
• Molti diagrammi utilizzati in ingegneria sono dei grafi
impianti industriali
data flow
topologie di rete
circuiti integrati
schemi circuitali
diagrammi ER"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#4,4,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itGrafi diretti
•U n  grafo orientato (o diretto ) G=(V,E) è costituito da 
un insieme di nodi Ve un insieme di archi E
– ogni arco è una coppia ordinata di nodi ( u,v)
• Denotiamo con nil numero dei nodi ( n= |V|) e con m
il numero degli archi ( m = |E|)
– si ha sempre m∈O(n2)
•E s e m p i o :
V= {0, 1, 2, 3, 4, 5}
E= {(2,0) (1,2) (4,0) (4,4) 
(4,5) (5,4) (1,4)}0
23
4
1
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#5,5,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itGrafi diretti e relazioni
• La versatilità dei grafi diretti deriva dal fatto 
che essi corrispondono a relazioni binarie
• Per esempio
– contatti tra utenti di una rete di telefonia
– dipendenze tra invocazioni di metodi in un software– partecipazioni di aziende nel capitale di altre
– rapporti di eredità
– rapporti di precedenza tra attività– reti sociali
–…"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#6,6,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itArchi uscenti ed entranti
• Dato un nodo u
– un suo arco uscente è un arco ( u,v) ∈E
– un suo arco entrante è un arco ( v,u) ∈E
– un nodo adiacente è un nodo vper cui esiste ( u,v) ∈E
– il suo grado di uscita è il numero dei suoi archi uscenti
– il suo grado di ingresso è il numero dei suoi archi entranti
• Un nodo uèd e t t o …
–sorgente se non ha archi entranti
–pozzo se non ha archi uscenti0
23
4
1
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#7,7,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itCammini
•U n  cammino (è sottinteso che sia diretto) è una 
sequenza di nodi u1, u2, …, uktali che per i=1,2, …, k-1 
esistono gli archi ( ui,ui+1)
• Il cammino è detto semplice se tutti i suoi nodi sono 
distinti
• Il numero di archi è la lunghezza del cammino
0
23
4
1
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#8,8,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itCicli
•U n  ciclo è un cammino (non semplice) in cui il primo e l’ultimo 
nodo coincidono
• Un ciclo è detto semplice se il primo e l’ultimo nodo sono gli 
unici nodi che coincidono
•U n  cappio (o loop) è un ciclo di un solo arco (e un solo nodo)
•U n  grafo semplice è un grafo senza cappi
• Un grafo diretto è aciclico se non ha cicli (diretti)
0
23
4
1
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\210-grafi-matrici-e-liste-03.pdf#9,9,"210-grafi-matrici-e-liste--03 copyright ©2022 maurizio.patrignani@uniroma3.itGrafi non orientati
• In un grafo non orientato (o non diretto ) 
G=(V,E) l’insieme degli archi E è un insieme di 
coppie non ordinate ( u,v)
–(u,v) e (v,u) rappresentano lo stesso arco
• Graficamente si conviene di rappresentare una 
sola linea tra i nodi ue v
V= {0, 1, 2, 3, 4, 5}
E= {(0,2) (0,4) (1,2) (1,4) 
(4,4) (4,5)}0
23
4
1
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#0,0,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Visita in ampiezza di un grafo
m.patrignani
"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#1,1,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non a fini
di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente autorizzata
per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il contenuto delle
slides, che sono comunque soggette a cambiamento
• questa nota di copyright non deve essere mai rimossa e deve essere
riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#10,10,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itProcedura BFS (liste di adiacenza)
14. x = x.next13. ENQUEUE (q,k)12. color[k] = 1 /* raggiunto e messo in coda */11. if (color[k] == 0)  /* se k non è stato già raggiunto */ 10. k = x.info /* k è l’indice d el nodo adiacente a u */9. while x != NULL /* finché c’è un nodo adiacente */8. x = g.A[u] /* mi preparo ad espor are gli adiacenti di u */7. u=DEQUEUE(q) /* estraggo un indice dalla coda */6. while not QUEUE-VOID (q) /* finché la coda q non è vuota */ 5. ENQUEUE (q,v) /* metto in coda l’indice v */ 4.color[v] = 1 /* uno = raggiunt o e messo in coda */3.q = QUEUE-EMPTY () /* creo una coda vuota */2. color[i] = 0 /* zero = non raggiunto */1. for i = 0 tog.A.length-1BFS(g,v) // g.A è un array di liste di adiacenza, v è un indice"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#11,11,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itComplessità della visita BFS
• In una visita in ampiezza
– ogni nodo è inserito ed estratto dalla coda una sola volta 
– ogni arco (adiacenza) è considerata sia dal nodo di 
partenza che dal nodo di arrivo
• Dunque la complessità nel caso peggiore è Θ(n+m )"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#12,12,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsercizi sulle visite in ampiezza
1. Scrivi lo pseudocodice della procedura BFS(g,v) nel 
caso in cui il grafo non diretto gsia rappresentato 
tramite una matrice di adiacenza 
2. Scrivi lo pseudocodice della procedura BFS(g,v) nel 
caso in cui il grafo non diretto gsia rappresentato 
tramite oggetti e riferimenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#13,13,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itGrafi non orientati e connettività
• Dato un grafo non orientato G=(V,E) 
– un nodo vèraggiungibile da un nodo use esiste un cammino da ua v
– se per ogni coppia di nodi ue vdi Vesiste un cammino da ua vil grafo è detto 
connesso
– la proprietà raggiungibilità tra nodi di un grafo non orientato è una proprietà di 
equivalenza le cui classi di equivalenza sono chiamate componenti connesse
0
23
4
1
58
6
9
7"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#14,14,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsercizi sulle visite in ampiezza
3. Scrivi lo pseudocodice della procedura 
IS_CONNECTED (g) che restituisce TRUE se il 
grafo è connesso
– possibile strategia: 
• eseguo una visita a partire da un nodo qualunque
• se alcuni nodi rimangono non marcati il grafo non è connesso "
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#15,15,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itVisite di un grafo non connesso
• Per eseguire una BFS di un grafo non necessariamente 
connesso è sufficiente lanciare diverse visite con lo stesso array color
– per esempio nel caso di grafo rappresentato con liste/matrice di
adiacenza il codice potrebbe essere il seguente
5. BFS (g,i,color) /* …comincia una BFS da qui */ 4. if color[i] == 0 /* se i non ancora visitato… */3. for i = 0 tog.A.length-12. color[i] = 0 /* zero = non raggiunto */1. for i = 0 tog.A.length-1BFS_non_connesso( g)/* g è rappresentato tramite liste di adiacenza */"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#16,16,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itCalcolo delle componenti connesse
4. Scrivi lo pseudocodice della procedura 
COMPONENTI_CONNESSE (g) 
– input: un grafo non diretto g
– output: il numero delle componenti connesse del grafo g
– possibile strategia: 
• pongo il contatore delle componenti connesse a zero
• finché c’è un nodo non visitato
– incremento il contatore delle componenti connesse
– eseguo una visita a partire dal nodo non visitato marcando tutti i nodi 
visitati"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#17,17,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsercizi sulle visite in ampiezza
5. Supponi di disporre di un’implementazione di una tabella hash dai 
nodi agli interi
• new_table ()
• ritorna una nuova tabella hash vuota
• add_pair (h,n,i)
• aggiunge alla tabella huna coppia formata da un nodo ned un intero i
• get_value (h,n) 
• ritorna il valore associato al nodo n
Scrivi lo pseudocodice della procedura BFS_order (g,v) che 
restituisce in output una tabella hash order dove 
get_value (order , n) è il numero d’ordine con cui il nodo nè
stato visitato
• nel caso in cui il grafo sia rappresentato  come una matrice o un array di liste di 
adiacenza al posto della tabella hash si potrebbe ritornare un semplice array"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#18,18,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsercizi sulle visite in ampiezza
6. Scrivi lo pseudocodice della procedura DISTANZE (g,v) che 
restituisce una tabella hash delle distanze di tutti i nodi dal 
nodo v
– i nodi non raggiunti devono avere distanza -1
– possibile strategia
• eseguo un visita in ampiezza a partire da v
• quando un nodo viene marcato, la sua distanza da vè pari alla distanza del 
nodo da cui è raggiunto più uno 
– nel caso in cui il grafo si rappresentato tramite un array di liste di 
adiacenza o una matrice di adiacenza la funzione potrebbe restituire un semplice array di interi"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#19,19,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsercizi sulle visite in ampiezza
7. Scrivi lo pseudocodice della funzione 
CAMMINO_MINIMO (g,u,v) che prende in input un grafo g
e gli identificatori di due nodi ue ve produce in output la 
lista dei nodi del cammino più corto da ua v
– possibile strategia
• eseguo una visita in ampiezza a partire da ve memorizzo per ogni nodo u
il parent di u, cioè il nodo dal quale è stato raggiunto
• la catena di parent che conduce da ua vè il cammino minimo cercato"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#2,2,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itContenuto
• Visita in ampiezza di un grafo indiretto
• Grafi e connettività
• Esercizi sulle visite in ampiezza"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#3,3,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itAlgoritmi di visita di un grafo
• Lo scopo di questi algoritmi è quello di visitare tutti i nodi 
raggiungibili a partire da un nodo di partenza
• Caratteristiche:
– i nodi non sono raggiunti in ordine casuale, ma in un ordine 
determinato dalla forma del grafo
• diversi algoritmi su grafi sono modifiche di algoritmi di visita
– non tutti i nodi vengono raggiunti
• perché il grafo potrebbe avere più componenti connesse 
– alcuni nodi possono essere raggiunti da più nodi adiacenti
• occorre marcare i nodi per non rischiare di ciclare ad infinito "
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#4,4,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itUso dei marcatori
• Gli algoritmi di visita dei grafi fanno tutti uso di 
marcatori 
• Un marcatore è un valore associato ad ogni nodo di 
un grafo
– per esempio un booleano (TRUE o FALSE) oppure un 
intero (generalmente 1 o 0)
• Nel caso più generale si può associare ad un nodo un 
generico intero che viene spesso chiamato “colore”
(color) del nodo"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#5,5,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itRealizzazioni di marcatori
• Se un nodo è identificato da un intero è sufficiente affiancare 
(o aggiungere) alla struttura del grafo un array di interi con n 
posizioni, dove nè il numero dei nodi
4.color[6] = 1 // coloro con 1 il nodo con indice 63.color[i] = 0 // inizializzo l’array con zero2. for i = 0 tocolor.length-11.// “color” è un array di interi con n posizioni
• Per verificare se il nodo iè marcato eseguiremo:
1. if( color[i] == 1 ) // nodo i marcato"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#6,6,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itRealizzazioni di marcatori
• Se un nodo è identificato da un riferimento ad un oggetto è
sufficiente aggiungere alla struttura del nodo un campo intero “color”
4.x = x.next 3.x.info.color = 0 // inizializzo il colore con zero2.  while x != NULL // scorro la lista dei nodi1.x = g.nodi
• Per verificare se il nodo nè marcato eseguiremo:
1. if( n.color == 1 ) // nodo n marcato"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#7,7,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itVisita in ampiezza (Breadth-First Search)
• A partire da un nodo vsi visitano i nodi raggiungibili 
da vnell’ordine imposto dalla loro distanza
– prima i più vicini, poi i più lontani
0
23
4
1
58
69
7"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#8,8,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itStrategia per una visita in ampiezza
• Facciamo uso di una coda sulla quale è possibile eseguire le operazioni 
ENQUEUE e DEQUEUE
• La coda viene inizializzata inserendoci il nodo di partenza
• I nodi raggiunti vengono marcati e messi in coda
– per essere sicuri di non metterli in coda  due volte li marchiamo appena li mettiamo 
in coda
• Finché la coda non è vuota 
– estraiamo un nodo dalla coda
– consideriamo tutti i suoi adiacenti e se sono raggiunti per la prima volta (non sono 
marcati) li marchiamo e li mettiamo in coda 
• L’ordine con cui i nodi sono estratti dalla coda corrisponde ad una visita 
in ampiezza
– è lo stesso ordine con cui i nodi sono messi nella coda e marcati"
data_test\rootfolder\università\AlgoritmiStruttureDati\230-visita-in-ampiezza-02.pdf#9,9,"230-visita-in-ampiezza-02 copyright ©2023 maurizio.patrignani@uniroma3.itEsempio di visita in ampiezza
1,5,6,8 0,2,4,33,1,5,6 0,2,44,3,1 0,22,4,3 00coda esplorati
0,2,4,3,1,5,6,8,7,99 0,2,4,3,1,5,6,8,77,9 0,2,4,3,1,5,6,88,7 0,2,4,3,1,5,66,8 0,2,4,3,1,55,6,8 0,2,4,3,10
23
4
1
58
69
7"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#0,0,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Esercitazioni in linguaggio C
Compilazione in linguaggio C
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#1,1,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#10,10,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCreazione del file eseguibile
• Per generare un file eseguibile è necessario
1. che la compilazione vada a boun fine e generi un 
file oggetto per ogni singolo file compilato
2. che il linkaggio vada a buon fine
– ogni funzione che viene utilizzata in un file oggetto 
deve essere contenuta in un altro file oggetto o in una 
libreria specificata nella fase di linking "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#11,11,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempio di errore di compilazione
localhost:~$ cc file.c -o eseguimi
file.c: In function ‘main’:file.c:3:13: warning: incompatible implicit declaration of built-in function ‘sin’
float b = sin(a);
^
/tmp/cctqIk3Y.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$localhost:~$ cc file.c -o eseguimi
file.c: In function ‘main’:file.c:3:13: warning: incompatible implicit declaration of built-in function ‘sin’
float b = sin(a);
^
/tmp/cctqIk3Y.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#12,12,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempio di errore di compilazione
• Anche includendo il file math.h l’eseguibile 
non viene generatolocalhost:~$ cc file.c -o eseguimi 
/tmp/cc6y9GHF.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$ localhost:~$ cc file.c -o eseguimi 
/tmp/cc6y9GHF.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$ #include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#13,13,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempio di errore di compilazione
• La compilazione, in realtà, va a buon finelocalhost:~$ cc -c file.c 
localhost:~$ ls
file.c file.olocalhost:~$ lslocalhost:~$ cc -c file.c 
localhost:~$ ls
file.c file.olocalhost:~$ ls#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#14,14,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempio di errore di compilazione
• L’errore è nella fase di linkaggiolocalhost:~$ cc file.o -o eseguimi 
file.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$localhost:~$ cc file.o -o eseguimi 
file.o: In function `main':file.c:(.text+0x1e): undefined reference to `sin'collect2: error: ld returned 1 exit statuslocalhost:~$#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#15,15,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCorrezione dell’errore
• Il parametro -lmrichiede di linkare la libreria 
“m” (si tratta della libreria “ libm.a ”)localhost:~$ cc file.o -lm -o eseguimi 
localhost:~$ ls
eseguimi file.c file.olocalhost:~$localhost:~$ cc file.o -lm -o eseguimi 
localhost:~$ ls
eseguimi file.c file.olocalhost:~$#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#16,16,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione e linkaggio corretti
localhost:~$ ls
file.clocalhost:~$ cc file.c -lm -o eseguimi 
localhost:~$ ls
eseguimi file.clocalhost:~$localhost:~$ ls
file.clocalhost:~$ cc file.c -lm -o eseguimi 
localhost:~$ ls
eseguimi file.clocalhost:~$#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}
#include <math.h> /* contiene sin */
intmain(intargc, char** argv) {
floata = 0.5;
floatb = sin(a);
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#17,17,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione ad una sola passata
• La sintassi del linguaggio C prevede che il codice 
possa essere compilato con una sola passata
• tipi, variabili e funzioni, devono essere dichiarati 
prima di essere usati
– attenzione: devono essere dichiarati , non necessariamente 
definiti
– le funzioni che riportano un intero possono essere usate 
senza essere dichiarate 
• il loro prototipo viene desunto dai parametri
– molte volte ciò può essere garantito scegliendo un opportuno 
ordine per le definizioni "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#18,18,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itDichiarazione e definizione
• Dichiarazione di variabile o funzione
– è un costrutto che annuncia al co mpilatore che la variabile o 
la funzione potrà essere utilizzata
– non introduce codice nel file oggetto e può essere iterata
• purché sia coerente con le precedenti
• la compilazione di un file con sole dichiarazion i produce un file 
oggetto vuoto (con la sola intestazione)
• Definizione di variabile o funzione
– è un costrutto che descrive in dettaglio come è composta la 
variabile o la funzione che viene definita
– una definizione è anche implicitamente una dichiarazione– introduce codice nel file oggetto e non può essere iterata"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#19,19,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempi di dichiarazioni
• Dichiarazione di una funzione
analoga a
• Dichiarazione di una variabile
– in questo caso la parola chiave extern è
necessaria, altrimenti il co mpilatore equivoca la 
dichiarazione per una definizionefloat funzione(float parametro);
float funzione(float parametro);
extern float funzione(float parametro);
extern float funzione(float parametro);
extern int variabile_globale;
extern int variabile_globale;"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#2,2,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itRichiami di linguaggio C
• Compilazione
• Linking
• Suddivisione del codice in più file
• Dichiarazioni e definizioni• Compilazione secondo lo standard ANSI"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#20,20,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itDichiarazione e definizione di tipi
• Dichiarazioni di tipi
– sono costrutti che annunciano al compilatore ciò che potrà
essere utilizzato
– non introducono codice nel file oggetto e possono essere 
iterate
• purché siano coerenti con le precedenti
• Definizioni di tipi
– sono costrutti che descrivono in dettaglio come sono 
composti i tipi che vengono definiti
– le definizioni di tipi non introducono codice nel file oggetto 
e possono essere iterate
• purché siano coerenti con le precedenti"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#21,21,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsempio di ordine di definizione errato
intmain(intargc, char** argv) {
floata = doppio(2.5);
}floatdoppio(floatv) {
returnv * 2.0; 
}
intmain(intargc, char** argv) {
floata = doppio( 2.5);
}floatdoppio(floatv) {
returnv * 2.0; 
}
localhost:~$ cc -c file.c
file.c:4:7: error: conflicting types for ‘doppio’
float doppio(float v) {
^
file.c:2:13: note: previous implicit declaration of ‘doppio’ was here
float a = doppio(2.5);
^
localhost:~$localhost:~$ cc -c file.c
file.c:4:7: error: conflicting types for ‘doppio’
float doppio(float v) {
^
file.c:2:13: note: previous implicit declaration of ‘doppio’ was here
float a = doppio(2.5);
^
localhost:~$funzione ancora 
non dichiarata"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#22,22,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itOrdine di definizione corretto
floatdoppio(floatv) {
returnv * 2.0; 
}
intmain(intargc, char** argv) {
floata = doppio(2.5);
}
floatdoppio(floatv) {
returnv * 2.0; 
}
intmain(intargc, char** argv) {
floata = doppio( 2.5);
}
localhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.olocalhost:~$ localhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.olocalhost:~$ "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#23,23,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itAlternativamente: uso di una dichiarazione
floatdoppio(floatv);
intmain(intargc, char** argv) {
floata = doppio(2.5);
}floatdoppio(floatv) {
returnv * 2.0; 
}
floatdoppio(floatv);
intmain(intargc, char** argv) {
floata = doppio( 2.5);
}floatdoppio(floatv) {
returnv * 2.0; 
}dichiarazione
definizione
localhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.olocalhost:~$ localhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.olocalhost:~$ "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#24,24,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itUso obbligatorio di una dichiarazione
• Non esiste un ordine di definizione delle due 
funzioni che metta al riparo da un errore di 
compilazionefloatfunzione1( floatv) {
if( v > 10 ) returnfunzione2(v)-1;
returnv; 
}
floatfunzione2( floatv) {
if( v > 10 ) return0.5*funzione1(v);
returnv;
}
floatfunzione1( floatv) {
if( v > 10 ) returnfunzione2(v)- 1;
returnv; 
}
floatfunzione2( floatv) {
if( v > 10 ) return0.5*funzione1(v);
returnv;
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#25,25,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itUso obbligatorio di una dichiarazione
floatfunzione2( floatv);
floatfunzione1( floatv) {
if( v > 10 ) returnfunzione2(v)-1;
returnv; 
}
floatfunzione2( floatv) {
if( v > 10 ) return0.5*funzione1(v);
returnv;
}
floatfunzione2( floatv);
floatfunzione1( floatv) {
if( v > 10 ) returnfunzione2(v)- 1;
returnv; 
}
floatfunzione2( floatv) {
if( v > 10 ) return0.5*funzione1(v);
returnv;
}dichiarazione"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#26,26,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itDichiarazione di un tipo
• Poiché la definizione può essere iterata è più
raro trovarsi nella necessità di dichiarare un tipo
• In alcuni casi, però, ciò è indispensabile
typedef struct str1 struttura1;   
typedef struct str2 struttura2;   
typedef struct str1 {
struttura2* puntatore;
} struttura1;
typedef struct str2 {
struttura1* puntatore;
} struttura2;
typedef struct str1 struttura1;   
typedef struct str2 struttura2;   
typedef struct str1 {
struttura2* puntatore;
} struttura1;
typedef struct str2 {
struttura1* puntatore;
} struttura2;forward
declarations"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#27,27,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itLocalizzazione delle dichiarazioni
• Generalmente, tutte le dichiarazioni vengono messe in 
un file .h che può essere importato da altri file .c
• Le variabili e le funzioni dichiarate nel file .h devono 
essere contenute in un file .o (quindi definite nel corrispondente file .c) perché la fase di linking vada a buon fine#ifndef _NOME_DEL_FILE
#define _NOME_DEL_FILE
/* dichiarazioni varie */#endif 
#ifndef _NOME_DEL_FILE
#define _NOME_DEL_FILE
/* dichiarazioni varie */#endif "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#28,28,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itDistribuizione del codice nei file
• Ogni file .c contiene il codice relativo alle 
dichiarazioni del corrispondente .h 
file1.cint 
main(int 
argc, 
char ** argv), 
{} 
int 
main(int 
argc, 
char ** argv), 
{} 
file2.cint 
funct2 
(int a) 
{ bla bla bla 
bla bla} 
int 
funct2 
(int a) 
{ bla bla bla 
bla bla} 
fileN.cint 
functN 
(int a) 
{bla bla bla bla 
bla bla} 
int 
functN 
(int a) 
{bla bla bla bla 
bla bla} file1.hint 
main(int 
argc, 
char ** argv), 
{} 
int 
main(int 
argc, 
char ** argv), 
{} 
file2.hint 
funct2 
(int a); 
……
…
int 
funct2 
(int a); 
……
…
fileN.hint 
functN 
(int a);
……
…
int 
functN 
(int a);
……
…
relazioni #include"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#29,29,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itVariabili globali
• Le variabili globali 
– sono dichiarate e definite in un solo file .c 
(tipicamente il file principale)
– sono dichiarate come “extern” in tutti i file .c che le 
utilizzano
file1.cint status = 0;
int main(int argc, 
char ** argv){………
} 
int status = 0;
int main(int argc, 
char ** argv){………
} 
fileK.cextern int status; 
int functK (int a) 
{ ………
} 
extern int status; 
int functK (int a) 
{ ………
} "
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#3,3,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione in linguaggio C
• La compilazione traduce il codice sorgente nel 
codice oggetto (cioè compilato)
– usualmente il codice sorgente è in uno o più file con 
estensione .c
– il codice oggetto viene messo in file con 
estensione .o
file.cint 
main(int 
argc, 
char ** 
argv), {} 
int 
main(int 
argc, 
char ** 
argv), {} 
file.o0100 111 
101010 0 
10101 11 
01010111 
101 1001 10101000
0100 111 
101010 0 
10101 11 
01010111 
101 1001 10101000compilazione"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#30,30,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione secondo lo standard ANSI
• Lo standard ANSI C originale (X3.159-1989) 
fu ratificato nel 1989 e pubblicato nel 1990
– per questo motivo è spesso chiamato C89 o C90
• Se si vuole che il compilatore si attenga 
strettamente allo standard ANSI originale 
occorre compilare con l’opzione -pedantic-
errors
localhost:~$ cc file.c -pedantic-errors -o filelocalhost:~$ cc file.c -pedantic-errors -o file"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#31,31,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione secondo lo standard ANSI
intmain(intargc, char** argv) {
inta = 10;  // commento 
intb = a;
}
intmain(intargc, char** argv) {
inta = 10;  // commento 
intb = a;
}
localhost:~$ cc file.c -pedantic-errors -o file
file.c: In function ‘main’:file.c:3:16: error: C++ style comments are not allowed in ISO C90
int a = 10;  // commento
^
file.c:3:16: error: (this will be reported only once per input file)localhost:~$localhost:~$ cc file.c -pedantic-errors -o file
file.c: In function ‘main’:file.c:3:16: error: C++ style comments are not allowed in ISO C90
int a = 10;  // commento
^
file.c:3:16: error: (this will be reported only once per input file)localhost:~$"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#32,32,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione secondo lo standard ANSI
intmain(intargc, char** argv) {
inta = 10, b = 5, c;
c = a + b;charch;
}
intmain(intargc, char** argv) {
inta = 10, b = 5, c;
c = a + b;charch;
}
localhost:~$ cc file.c -pedantic-errors -o file
file.c: In function ‘main’:file.c:5:3: error: ISO C90 forbids mixed declarations and code [-Wpedantic]
char ch;^
localhost:~$localhost:~$ cc file.c -pedantic-errors -o file
file.c: In function ‘main’:file.c:5:3: error: ISO C90 forbids mixed declarations and code [-Wpedantic]
char ch;^
localhost:~$"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#33,33,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itEsercizi
1. Scrivi una funzione in linguaggio C che 
verifichi se in un array di interi ci sia almeno 
un intero ripetuto due volte
2. Scrivi una funzione in linguaggio C che 
verifichi se in un array di interi ci sia almeno 
un intero ripetuto trevolte"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#4,4,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione da linea di comando
• Avviene chiamando un compilatore (cc, gcc, 
ecc) specificando che si vuole compilare un file 
sorgente
– l’opzione -csignifica “voglio solo la compilazione”localhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.olocalhost:~$ ls
file.clocalhost:~$ cc -c file.c
localhost:~$ ls
file.c file.o"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#5,5,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itLinking in linguaggio C
• La fase di linking trasforma il codice oggetto in 
un file eseguibile
– vengono anche utilizzate (linkate, appunto) le 
librerie standard del linguaggio C
file.o a.out0100 111 
101010 0 10101 11 
01010111 
101 1001 
10101000
0100 111 
101010 0 10101 11 
01010111 
101 1001 
10101000linking
0100 111 
101010 0 10101 11 
01010111 
101 1001 
10101000
0100 111 
101010 0 10101 11 
01010111 
101 1001 
10101000"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#6,6,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itLinking da linea di comando
• Avviene chiamando un compilatore (cc, gcc, 
ecc) e fornendo come parametro il file oggetto
• Se non viene specificato il nome del file di 
output (-o eseguimi ) allora viene generato un 
file eseguibile di nome a.outlocalhost:~$ ls
file.c file.olocalhost:~$ cc file.o -o eseguimi
localhost:~$ ls
eseguimi file.c file.olocalhost:~$ ls
file.c file.olocalhost:~$ cc file.o -o eseguimi
localhost:~$ ls
eseguimi file.c file.o"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#7,7,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itUn esempio di errore di linking
• Il file linkato deve contenere la funzione main
– in realtà il messaggio d’errore dice che la funzione 
standard _start non ha trovato la funzione mainlocalhost:~$ cc file.o -o eseguimi
/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu/crt1.o: In function `_start':
(.text+0x20): undefined reference to 
`main'collect2: error: ld returned 1 exit statuslocalhost:~$localhost:~$ cc file.o -o eseguimi
/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu/crt1.o: In function `_start':
(.text+0x20): undefined reference to 
`main'collect2: error: ld returned 1 exit statuslocalhost:~$"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#8,8,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itCompilazione e linking
• Si può compilare e linkare con un solo 
comando
• Il file prova.o non viene nemmeno conservato
• In un Integrated Development Environment 
(IDE) la compilazione e il linking avvengono automaticamente al “build” del progettolocalhost:~$ ls
prova.clocalhost:~$ cc prova.c -o prova
localhost:~$ ls
prova prova.clocalhost:~$ ls
prova.clocalhost:~$ cc prova.c -o prova
localhost:~$ ls
prova prova.c"
data_test\rootfolder\università\AlgoritmiStruttureDati\c010-compilazione-in-c-03.pdf#9,9,"c010-compilazione-in-c-03         copyright ©2021 maurizio.patrignani@uniroma3.itint 
main(int 
argc, 
char ** argv), 
{} 
int 
main(int 
argc, 
char ** argv), 
{} Codice distribuito in file diversi
• Quando il codice viene distribuito in diversi file 
…
… la compilazione e il linking generano un 
singolo file eseguibile
– uno e uno solo dei file oggetto deve contenere la 
funzione mainfile1.c
int 
main(int 
argc, 
char ** 
argv), {} 
int 
main(int 
argc, 
char ** 
argv), {} 
eseguimi0100 111 
101010 0 
10101 11 
01010111 
101 1001 10101000
0100 111 
101010 0 
10101 11 
01010111 
101 1001 10101000compilazione
e linking
file2.c"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#0,0,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itAlgoritmi e Strutture di Dati
Esercitazioni in linguaggio C
Array e puntatori
m.patrignani"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#1,1,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itNota di copyright
• queste slides sono protette dalle leggi sul copyright 
• il titolo ed il copyright relativi alle slides (inclusi, ma non 
limitatamente, immagini, foto, animazioni, video, audio, musica 
e testo) sono di proprietà degli autori indicati sulla prima pagina
• le slides possono essere riprodotte ed utilizzate liberamente, non 
a fini di lucro, da università e scuole pubbliche e da istituti pubblici di ricerca
• ogni altro uso o riproduzione è vietata, se non esplicitamente 
autorizzata per iscritto, a priori, da parte degli autori
• gli autori non si assumono nessuna responsabilità per il 
contenuto delle slides, che sono comunque soggette a 
cambiamento
• questa nota di copyright non deve essere mai rimossa e deve 
essere riportata anche in casi di uso parziale"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#10,10,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itAlgebra degli operatori *e &
• Regola mnemonica
– ogniqualvolta si incontra l’operatore *lo si può 
sostituire con “il puntato da” oppure “il contenuto 
di”
– ogniqualvolta si incontra l’operatore &lo si può 
sostituire con “l’indirizzo di”
int a;
int* b;b = &a;    /* “l’indirizzo di a” */*b = 3;    /* “il puntato da b” */
int a;int* b;b = &a;    /* “l’indirizzo di a” */*b = 3;    /* “il puntato da b” */"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#11,11,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itAlgebra degli operatori *e &
• I due operatori possono essere combinati 
insieme in modo spesso complesso
• Osservazione
–*x identifica un right value (cioè un valore)
–&y identifica un left value (cioè una variabile)int a = 3;
int* b = &a;int** c = &b;*b = *b+1;         /* ora a vale 4 */
**c = **c+1        /* ora a vale 5 */ 
int a = 3;
int* b = &a;int** c = &b;*b = *b+1;         /* ora a vale 4 */
**c = **c+1        /* ora a vale 5 */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#12,12,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itPassaggio di parametri
• Tutti i passaggi di parametri in linguaggio C 
sono per valore
– esempio
…
int a = 3;mia_funzione(a);  /* viene passato 3 */
/* qui “a” vale sempre 3 */
…
…
int a = 3;mia_funzione(a);  /* viene passato 3 */
/* qui “a” vale sempre 3 */
…
void mia_funzione(int a){
a = a + 1;  /* non ha side effects */
}
void mia_funzione(int a){
a = a + 1;  /* non ha side effects */
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#13,13,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itPassaggio di parametri
• Passaggio di parametri “per riferimento”
– in realtà il passaggio è sempre per valore
– esempio
…
int a = 3;mia_funzione(&a);   /* l’indirizzo */        
/* qui “a” vale 4 */
…
…
int a = 3;mia_funzione(&a);   /* l’indirizzo */        
/* qui “a” vale 4 */
…
void mia_funzione(int* a){
(*a) = (*a) + 1;  /* side effects */
}
void mia_funzione(int* a){
(*a) = (*a) + 1;  /* side effects */
}"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#14,14,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itGli array
• Un array è una sequenza di variabili omogenee, tutte 
memorizzate in celle contigue  di memoria e indicizzate 
con un indice intero
• In linguaggio C un array si dichiara premettendo il tipo 
degli elementi e posponendo il numero degli elementi tra parentesi quadre
– in ansi C il numero di elementi  deve essere una costante, non 
può essere una variabile o un’espressione genericaint a[10];   /* a array di 10 interi */
float b[5];  /* b array di 5 float */
int a[10];   /* a array di 10 interi */float b[5];  /* b array di 5 float */
int n=10;    /* numero di celle */
int a[n];    /* errore! */
int n=10;    /* numero di celle */int a[n];    /* errore! */"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#15,15,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itArray e allocazione della memoria
• Cosa succede in memoria quando dichiariamo un 
array?
int a[5]; /* a array di 5 interi */ 
int a[5]; /* a array di 5 interi */ 
a
10001001 a[0] 1001
a[1] 1002
a[2] 1003
a[3] 1004
a[4] 1005
• Quante celle di memoria vengono allocate quando 
dichiaro un array di 5 interi?"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#16,16,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itArray e puntatori
• Un array è a tutti gli effetti un puntatore
– è l’indirizzo della prima cella di memoria dell’array
• In linguaggio C l’identità tra array e puntatori è
esplicita
• Tuttavia un array è un puntatore costante 
– non è legittimo sovrascrivere o modificare 
l’indirizzo di memoria associato ad un arrayint a[5];     /* a è di tipo int* */
int* b = a;   /* b ha lo stesso valore
di a */
int a[5];     /* a è di tipo int* */int* b = a;   /* b ha lo stesso valore
di a */"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#17,17,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itIncremento di un puntatore
• Incrementando un puntatore si salta una 
porzione di memoria pari alla dimensione 
dell’oggetto puntato
int a[5];    /* a array di 5 interi */
int* b = a;  /* b punta alla prima 
cella di a */
b = b + 1;   /* b punta alla seconda
cella di a */
b++;         /* b punta alla terza 
cella di a */
int a[5];    /* a array di 5 interi */int* b = a;  /* b punta alla prima 
cella di a */
b = b + 1;   /* b punta alla seconda
cella di a */
b++;         /* b punta alla terza 
cella di a */"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#18,18,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itInterpretazione delle parentesi quadre
• Date due espressioni xe y, il costrutto x[y] è
equivalente all’operazione *(x+y)
• Quindi queste espressioni sono equivalenti
a[0] = 100; 
a[0] = 100; *(a+0) = 100; 
*(a+0) = 100; 
a[1] = 200; 
a[1] = 200; *(a+1) = 200; 
*(a+1) = 200; 
• Si può verificare l’equivalenza persino delle seguenti 
espressioni
– infatti *(a+1) è uguale a *(1+a)a[1] = 200; 
a[1] = 200; 1[a] = 200; 
1[a] = 200; "
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#19,19,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itTempi di accesso agli array
• Consideriamo il tempo di esecuzione di
– è evidente che le due operazioni sulla destra si 
possono fare in tempo costante
– il tempo di accesso è costante anche se si afferisce 
ad una cella lontana dalla prima
• Il tempo di accesso ad un array è sempre θ(1)a[0] = 100; 
a[0] = 100; *(a+0) = 100; 
*(a+0) = 100; 
a[9999] = 200; 
a[9999] = 200; *(a+9999) = 200; 
*(a+9999) = 200; "
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#2,2,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itRichiami di linguaggio C
• Puntatori in linguaggio C
• Gli operatori *e &
• Algebra dei puntatori
• Array• Allocazione statica e dinamica di array"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#20,20,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itAllocazione statica degli array
• La dichiarazione di array che abbiamo visto 
alloca le celle dell’array direttamente sullo 
stack
• Questo comporta due vincoli
– il numero delle celle non può essere modificato
– il valore di anon può essere modificato int a[5]; /* a è nello stack.
Anche a[0],a[1],… ,a[4]
sono nello stack */ 
int a[5]; /* a è nello stack.
Anche a[0],a[1],… ,a[4]
sono nello stack */ "
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#21,21,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itAllocazione dinamica degli array
• Nell’allocazione dinamica l’array viene posto 
nello heap tramite la funzione calloc
int* a;      /* a è nello stack */
a = (int *)calloc(5,sizeof(int)); a[0] = 5;
int* a;      /* a è nello stack */a = (int *)calloc(5,sizeof(int)); a[0] = 5;
a
10002001a[0] 2001
a[1] 2002
a[2] 2003
a[3] 2004
a[4] 2005Stack Heap
5"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#22,22,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itVantaggi della dichiarazione dinamica
• La dichiarazione dinamica degli array comporta 
diversi vantaggi
– il numero di celle dell’array può essere specificato tramite 
una variabile o un’espressione generica
– l’indirizzo dell’array può essere modificato– il numero delle celle dell ’array può essere modificato
int* a; 
a = (int *)calloc(5,sizeof(int));a[0] = 100; 
…
a = realloc(a,10*sizeof(int));a[8] = a[0];          /* cioè 100 */
int* a; a = (int *)calloc(5,sizeof(int));a[0] = 100; 
…
a = realloc(a,10*sizeof(int));a[8] = a[0];          /* cioè 100 */"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#23,23,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itEsercizi
1. Implementa in linguaggio C uno stack di interi con le 
funzioni NEW_STACK , IS_EMPTY , PUSH , e POP e 
con la gestione telescopica della memoria
• operazione PUSH con complessità ammortizzata O(1)
2. Implementa in linguaggio C una coda di interi con le 
funzioni NEW_QUEUE , IS_EMPTY , ENQUEUE , e 
DEQUEUE e con la gestione telescopica della 
memoria
• operazione ENQUEUE con complessità ammortizzata O(1)"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#3,3,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itPuntatori in linguaggio C
• Molti linguaggi supportano i riferimenti
– un riferimento è una variabile che viene utilizzata per 
identificare un’altra variabile (o un oggetto)
• Nel linguaggio C i riferimenti sono i puntatori
– un puntatore è una variabile (cioè una cella di memoria con 
un tipo e un nome) che contiene l’indirizzo di un’altra cella di memoria
• per esempio l’indirizzo di un’altra variabilea
10002000b
2000a b"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#4,4,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itL’operatore *
• Nel linguaggio C il tipo di una variabile puntatore si 
ottiene dal tipo della variabile puntata seguito dal 
simbolo *(leggi “star”)
•E s e m p i
– un puntatore ad intero ha tipo int*
• leggi “int star”
• è indifferente la presenza di spazi o meno tra la stringa “ int”e  i l  
simbolo “*”
– un puntatore a carattere ha tipo char*
• leggi “char star”
– un puntatore a puntatore ad intero ha tipo int**
• leggi “int star star”"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#5,5,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itEsempi di dichiarazioni di puntatori
• La variabile aè un puntatore ad intero
• La variabile bè un puntatore a puntatore ad intero
• La variabile cè un puntatore ad un float
• La variabile dè un puntatore ad una strutturaint* a;
int* a;
int** b;
int** b;
struct {
int minimo;int massimo;
}* d; 
struct {
int minimo;int massimo;
}* d; float* c;
float* c;"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#6,6,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itLa costante NULL
• Il valore costante NULL è un valore 
convenzionale che si suppone assegnato ad un 
puntatore che non contiene alcun indirizzo 
significativo
– nella rappresentazione interna NULL corrisponde al 
valore 0(zero), che non è legittimo per un indirizzo 
di memoria a disposizione dell’utente"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#7,7,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itLa costante NULL
• Quando viene dichiarato un puntatore senza 
inizializzarlo, si suppone che il suo valore sia 
NULL
• Questo può essere anche esplicitato da 
un’assegnazioneint* a;  /* a è ancora uguale a NULL */
int* a;  /* a è ancora uguale a NULL */
int* a = NULL;  
int* a = NULL;  "
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#8,8,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itDue diverse interpretazioni dell’operatore *
• L’espressione “ int* a ”p u ò  e s s e r e  
interpretata in due modi equivalenti
1. la variabile “ a”èd i  t i p o  “ int* ”
2. “*a”, cioè “l’oggetto puntato da a” è di 
tipo “int”int* a
int*a
int*a
• Infatti, l’operatore *anteposto ad un indirizzo di 
memoria identifica il contenuto della memoria 
stessa
–“*(a+b) ” è il contenuto della cella di memoria che si 
trova in posizione a+b"
data_test\rootfolder\università\AlgoritmiStruttureDati\c020-array-e-puntatori-06.pdf#9,9,"c020-array-e-puntatori-06         copyright ©2021 maurizio.patrignani@uniroma3.itL’operatore &
• L’operatore &(e commerciale) anteposto ad una 
variabile ne estrae l’indirizzo
•E s e m p i o
– l’indirizzo della variabile intera “ a”è“&a”
•“&a” è un’espressione di tipo “ int* ”
• Non ha senso utilizzare l’operatore &con 
espressioni generiche
–l a  s c r i t t u r a  “ &(a+b) ” non ha senso perché “ a+b”
non è una variabile, ma solo un valore
• tecnicamente: non ha left-value ma solo right-value"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#0,0,Prof. Riccardo TorloneUniversità di Roma TreCalcolatori ElettroniciParte I: Evoluzione dei calcolatori e tipologie di Calcolatori 
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#1,1,"Riccardo Torlone -Corso di Calcolatori Elettronici2Architetture..
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#10,10,"Il Boom del MercatonFinora gli elaboratori sono limitati all’ambito scientifico, a quello militare e istituzionale (censimento)nDiventa ormai chiara l’occasione di mercatonNel 1950 Mauchleye Eckertescono dal progetto EDVAC (~1950 USA, successore dell’ENIAC, mai giunto a termine) e fondano la UNIVAC, la prima grossa società del settore
Riccardo Torlone -Corso di Calcolatori Elettronici11
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#11,11,"La Macchina di Von Neumann
IAS(~ 1950, Princeton USA)nProgramma memorizzatonAritmetica binarianMemoria: 4096 x 40 bitnFormato istruzioni a 20 bit:
Riccardo Torlone -Corso di Calcolatori Elettronici12OPCODEINDIRIZZO128
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#12,12,"Riccardo Torlone -Corso di Calcolatori Elettronici13Sistemi CommercialiInizialmente il mercato è dominato dalla UNIVACL’IBM entra nel mercato nel 1953, e assume una posizione dominante che manterrà fino agli anni ‘80:nIBM 701 (1953):nMemoria: 2K word di 36 bitn2 istruzioni per wordnIBM 704 (1956):nMemoria: 4K word di 36 bitnIstruzioni a 36 bitnFloating-point hardwarenIBM 709 (1958)nPraticamente un 704 potenziatonUltima macchine IBM a valvole
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#13,13,"II  Generazione  (1955-1965)(Tecnologia a transistor)TXO e TX2 macchine sperimentali costruite al MITUno dei progettisti del TX2 fonda una propria società la Digital EquipmentCorporation (DEC)La DEC produce il PDP-1 (1961):nMemoria: 4Kword di 18 bitnTempo di ciclo di 5 µsecnPrestazioni simili all’IBM 7090nPrezzo meno di un decimonSchermo grafico 512 ´512 pixel nComincia la produzione di massa
Riccardo Torlone -Corso di Calcolatori Elettronici14
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#14,14,"Il Minicomputer 
nDEC PDP-8 (1965) nSuccessore diretto del PDP-1nInterconnessione a bus, molto flessibilenArchitettura incentrata sull’I/OnPossibilità di connettere qualsiasi perifericanProdotto in oltre 50.000 esemplari
Riccardo Torlone -Corso di Calcolatori Elettronici15
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#15,15,"Sistemi CommercialiMainframe: grossi calcolatori per applicazioni scientifiche, militari e PubblicaAmministrazioneIBM 7090nVersione transistorizzata del 709nMemoria 32Kword da 36 bitnTempo di ciclo 2 µsecnDomina il mercato fino agli anni ‘70nPochi esemplari, costano milioni di dollariPiccoli sistemi: per medie aziende o di appoggio ai mainframeIBM 1401nStessa capacità di I/O del 7090nMemoria 4K word 8bit (1byte)nOrientata a caratterinIstruzioni per la manipolazione di stringheRiccardo Torlone -Corso di Calcolatori Elettronici16
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#16,16,"III  Generazione (1965-1980)(Tecnologia LSI e VLSI) Evoluzione dell’architettura HWnMicroprogrammazionenUnità veloci floating-pointnProcessori ausiliari dedicati alla gestione dell’I/OEvoluzione dei Sistemi OperativinVirtualizzazione delle risorsenMultiprogrammazione: esecuzione concorrente di più programminMemoria Virtuale: rimuove le limitazioni dovute alle dimensioni della memoria fisica 
Riccardo Torlone -Corso di Calcolatori Elettronici18"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#17,17,"Serie IBM System/360
nL’IBMintroduce una famigliadi elaboratori (passo decisivo)nSerie IBM System/360nMacchine con lo stesso linguaggio nRangedi prestazioni (e prezzo) 1-20nCompleta compatibilitànPortabilità totale delle applicazioninSistema Operativo comune OS/360Riccardo Torlone -Corso di Calcolatori Elettronici19
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#18,18,"Serie DEC PDP-11 e UNIXnEvoluzione diretta del PDP-8 nParole di memoria e istruzioni a 16 bitnArchitettura a bus (Unibus)nGrande flessibilità nella gestione e nell’interfacciamento di periferiche e strumentazione al busnDomina il mercato fino alla fine degli anni ’70nProdotto in milioni di esemplarinDiffusissimo nelle universitànSupporta il sistema operativo UNIX, indipendente dalla piattaformanInfluenzerà un’intera generazione di progettisti e di utentiRiccardo Torlone -Corso di Calcolatori Elettronici20
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#19,19,"Riccardo Torlone -Corso di Calcolatori Elettronici21IV Generazione: PCDiretto discendente del minicomputer:nArchitettura a busnParole e istruzioni a 16 bit Boom negli anni 80 con i PC prodotti da IBM Esplosione del mercato dei “cloni”Macintosh introduce le interfacce graficheOsborneintroduce i portatiliCrollo dei costi ed enorme espansione dell’utenzaDai grandi Centri di Elaborazione a un contesto di Informatica DistribuitaL’espansione del PC è trainata da tre fattori:nAumento della capacità della CPUnDiscesa dei costi della memoria principalenDiscesa dei costi delle memorie secondarie
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#2,2,"Riccardo Torlone -Corso di Calcolatori Elettronici3Come si arriva ad una architettura complessa?
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#20,20,"Evoluzioni modernen1986: PDA (Personal Digital Assistants)nOrganizer II -Psionn1994: SmartphonesnSimon –IBMn2002: TabletnMicrosoft Tablet PCn2000: Architetture multi-corenPOWER4 -IBM
Riccardo Torlone -Corso di Calcolatori Elettronici22
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#21,21,"V Generazione: i computer invisibiliLa Apple introduce il primo computer palmare (PDA)Successivamente, si sono diffusi i computer embeddednElettrodomesticinAutomobilinCellularinOrologinBancomatn…Architetture non nuove ma diversa prospettivaModello del ubiquitous(o pervasive) computingo dell’Internet of ThingsRiccardo Torlone -Corso di Calcolatori Elettronici23
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#22,22,"La legge di Moore (1965)
Il numero di transistor su di un chip raddoppia ogni 18 mesiCirca un aumento del 60% all’annoConseguenze:nAumento della capacità dei chip di memorianAumento della capacità delle CPU Riccardo Torlone -Corso di Calcolatori Elettronici24
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#23,23,"Legge di Moore per le CPU
Più transistor in una CPU significano:nEseguire direttamente istruzioni più complessenMaggiore memoria sul chip (cache)nMaggiore parallelismo interno Riccardo Torlone -Corso di Calcolatori Elettronici25
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#24,24,"Andamento corrente della legge di Moore
Riccardo Torlone -Corso di Calcolatori Elettronici26
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#25,25,"Recentiavanzamentinellascaladi integrazione(2nm)
Riccardo Torlone -Corso di Calcolatori Elettronici27
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#26,26,"Evoluzionedellatecnologiarispetto allaleggedi Moore
Riccardo Torlone -Corso di Calcolatori Elettronici28"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#27,27,"Futuro della legge di Moore
Riccardo Torlone-Corso di Calcolatori Elettronici29
Oppureicomputer “analitici”: https://www.youtube.com/watch?v=GVsUOuSjvcg"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#28,28,"Legge di NathanIl software è un gas: riempie sempre completamente qualsiasi contenitore in cui lo si mettaAl calare dei costi e all’aumentare della memoria disponibile, le dimensioni del software sono sempre cresciute in proporzioneIl Circolo VirtuosonSpinta tecnologica (Moore law)nCosti più bassi e prodotti migliorinNuove applicazioni software nNuovi mercati e maggiore competizionenEsigenza di migliori prestazioni hardware nSpinta tecnologica …...
Riccardo Torlone -Corso di Calcolatori Elettronici30"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#29,29,"Riccardo Torlone -Corso di Calcolatori Elettronici31Tipologie di Computer
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#3,3,"Una architettura opera di molti artisti..nLeon Battista AlbertinBernardo RossellinonBramante nRaffaello SanzionAntonio da SangallonMichelangelo BuonarrotinVignolanPirro LigorionGiacomo Della Porta nDomenico Fontana nCarlo MadernonGian Lorenzo Bernini Riccardo Torlone -Corso di Calcolatori Elettronici4
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#30,30,"Riccardo Torlone -Corso di Calcolatori Elettronici32RFID (Radio FrequencyIDentification)Appartengono alla categoria usa-e-gettanSu chipnTipicamente senza batteria (passivi)n0.5 mm di diametronDotati di un piccolo transponder radionMemorizzano un numero di 128 bitnEsistono anche RFID attiviQuando ricevono un segnale radio trasmettono il proprio numeroVengono usati in molte applicazioninMagazzini e punti venditanTrasportinControllo presenze ed accessinIdentificazione degli animalinBiblioteche -movimento librinAntitaccheggionCarte di pagamento
video 1video 2
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#31,31,"Riccardo Torlone -Corso di Calcolatori Elettronici33MicrocontrolloriPiccoli computer inclusi in vari dispositivi, tipicamente connessi in rete:nElettrodomesticinTelefoninAutomobilinPeriferichenGiochinMacchine fotografichenDispositivi medicin…Dotati dinUna CPUnUna piccola memorianQualche dispositivo di I/O
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#32,32,"Riccardo Torlone -Corso di Calcolatori Elettronici34Game computersComputer “normali”nEffetti grafici specialinSoftware di base limitatonNon estendibiliPlay Station 5nCPU: AMD a 8 core da 3.5 GHzn16GB di RAM (+VRAM)nGPU: AMD a 2.2 Ghz, > 10 TFLOPSXbox OneX/SnCPU: AMD a 8 core da 3.8 GHzn16GB di RAM (+VRAM)nGPU: AMD a 1,8 Ghz, > 10 TFLOPSSono sistemi specializzati e “chiusi”
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#33,33,"SmartphoneTelefoni cellulari dotati di CPU nCon sistema operativo (Android, iOS, Windows)nTelecameranFunzionalità estendibilinCPU relativamente potenti (ARM, 1.6 Ghz, octa-core)
Riccardo Torlone -Corso di Calcolatori Elettronici35
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#34,34,"Tablet (Phablet, 2-in-1)Quasi dei computer ""normali"" con schermi ridotti (9.7inc.)nDotati di interfacce grafiche basate su touch-screennTastiere virtualinCPU potenti (>1.5Ghz, quad/octa-core)nProcessore graficonMemorie ridotte (512MB-2GB RAM, 128-256GB SSD)
Riccardo Torlone -Corso di Calcolatori Elettronici36
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#35,35,"Riccardo Torlone -Corso di Calcolatori Elettronici37Tipologie di Computer ""tradizionali""Personal ComputernSappiamo cosa è (desktop, laptop)Server -WorkstationnSu rete locale o Web servernMemorie fino a diversi GBnDiversi TBdi disconGestione di rete efficiente COW (Cluster of workstations)nSistema multiprocessore ad accoppiamento lasconHardware di tipo standard: costi contenutinStrutture di connessione velocinElevata affidabilità e capacità di elaborazione complessivanDetti COTS (Commodity Off The Shelf) o Server Farm
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#36,36,"Riccardo Torlone -Corso di Calcolatori Elettronici38Tipologie di Computer ""tradizionali""MainframenDiretti discendenti della serie 360nGestione efficiente dell’I/OnPeriferie a dischi di molti TbytenCentinaia di terminali connessinCosti di parecchi milioni di EuroVersione moderna (in cluster)nServer farms+ client intelligentinData centersnOffrono soluzioni di ""cloudcomputing""video"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#37,37,"Riccardo Torlone -Corso di Calcolatori Elettronici39La famiglia Intel
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#38,38,"Riccardo Torlone -Corso di Calcolatori Elettronici40CPU attualmente sul mercato13th Generation Intel Core: nome commerciale di una serie di microprocessori Intel (fascia desktop) di nuova generazione a 64 bit (x86-64) –Architettura: nomi come ""Coffee Lake""nRaggruppa processori destinati a diversi settori di mercato nIntel Core i3nIntel Core i5nIntel Core i7nIntel Core i9nXeonnSono tutte architetture multi core ibride (p-core vs e-core)nEsistono versioni per portatilinTecnologia di integrazione fino a 7 nmnFinoa 25 MB cache L3 condivisenPiù di 8 miliardi di transistors!nFino a 24 stadi di pipeline
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#39,39,"Come produrre tanti modelli?nCon un’unica catena di produzione!! (o poche)nOgni CPU prodotta viene venduta come modello diverso sulla base della qualità di produzione
Riccardo Torlone -Corso di Calcolatori Elettronici41
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#4,4,"Riccardo Torlone -Corso di Calcolatori Elettronici5Evoluzione degli Elaboratori (opera di molti artisti)
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#40,40,"Intel Core i7 (x86)nArchitettura Sandy Bridgen8 core di cui 6 abilitati nVersione full: xeonnOltre 1,4 miliardi di transistor in un chipnNuove istruzione SSE per applicazioni multimedialinTecnologia di integrazione a 22nmnDue cache locali per ogni core (64KB-256KB)nCacheglobaleL3(2MB-8MB)n2.6–3.5GHz di frequenza di clocknDissipazione: <60 WattnHyper-ThereadingPipeline
Riccardo Torlone -Corso di Calcolatori Elettronici42
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#41,41,"Architetture ARMnNasce negli anni 80 da un progetto AcornnBasato su principi RISC (AcornRISC Machine)nPrima versione su PC ""Archimedes"" (1985)nUsato nel progetto Newton di ApplenTarget: applicazioni embedded/mobile a basso consumo di energianArchitettura ""aperta""ndiversi produttorinEsempio di uso: Nvidia Tegra2n2 CPU ARM Cortex-A9 a 1.2Ghzn1 GPU GeForce333-Mhzn1 CPU AM7 per la configurazionenL2 condivisa di 1MB Riccardo Torlone -Corso di Calcolatori Elettronici44
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#42,42,"Architettura AVRnTarget: sistemi embeddeda bassissimo consumo di energianNasce da un progetto del NIT nel 1996n(A)lfand (V)ergardRISC processornStesso pinoutdell’8051 IntelnPeriferiche disponibili nel AVR XMEGA:n3 timer –Orologio interno -Trasmettitori di impulso –Interfaccia per sensori -Convertitori analogico/digitali -Transponder -Comparatore di tensioni  
Riccardo Torlone -Corso di Calcolatori Elettronici45
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#5,5,"Riccardo Torlone -Corso di Calcolatori Elettronici6Quasi tutta l’evoluzione ha avuto luogo negli ultimi 70 anni
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#6,6,"Generazione 0  (1600-1945)Pascal (1623-1662)naddizioni e sottrazioniLeibniz (1646-1716)nanche moltiplicazioni e divisioni
Riccardo Torlone -Corso di Calcolatori Elettronici7
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#7,7,"La macchina di BabbageCharles Babbage(1792-1871)nA) Macchina DifferenzialenCalcolo funzioni polinomialinAlgoritmo fisso (differenze finite)nOutput su piastra di ramenB) Macchina AnaliticanPrima macchina programmabilenMemoria: 1000 x 50 cifre decimalinMulino (CPU)nI/O su schede perforatenLimite: tecnologia meccanicanPrimo programmatore: nAda LovelaceRiccardo Torlone -Corso di Calcolatori Elettronici8
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#8,8,"Generazione 0  (continua)(Macchine elettromeccaniche)Konrad Zuse(~1930 Germania)nMacchina a relènDistrutta nella guerraJohn Atanasoffe George Stibbitz(~1940 USA)nAritmetica binarianMemoria a condensatoriHoward Aiken (~1940 USA)nMARK 1: versione a relè della macchina di BabbagenMemoria: 72 x 23 cifre decimalintempo di ciclo: 6 sec.nI/O su nastro perforatoRiccardo Torlone -Corso di Calcolatori Elettronici9
"
data_test\rootfolder\università\CalcolatoriElettronici2\02 Evoluzione dei calcolatori e tipologie di Calcolatori.pdf#9,9,"I  Generazione (1945-1955)(Tecnologia a valvole) COLOSSUS  (~1940 GB)nGruppo di Alan TuringnDecifrazione del codice EnigmanProgetto mantenuto segretoENIAC  (~1946 USA)nJ. Mauchley, J. Eckertn18.000 valvolen30 tonnellate di peson140KWconsumo energianProgrammabile tramite 6000 interruttori e pannelli cablatin20 registri da 10 cifreRiccardo Torlone -Corso di Calcolatori Elettronici10
"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#0,0,CalcolatoriElettroniciParte II:SistemidiNumerazioneBinariaProf. Riccardo TorloneUniversità di Roma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#1,1,"Riccardo Torlone -Corso di Calcolatori Elettronici2Unità di misura
Attenzioneperò, se stiamo parlando di memoria:n1Byte = 8 bitn1K (KiB: KibiByte) = 210= 1.024                            ~ 103n1M (MeB: MebiByte) = 220= 210210=1.048.576          ~ 106n1G (GiB: GibiByte) = 230= 210210210=1.073.741.824~ 109n1T (TiB: TebiByte) = 240= ... =1.099.511.627.770~ 10121 Mb = 1 Mega bit = 106bit (misura di velocità)4 GB = 4 Giga bytes= 232bytes(misura di memoria)
"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#10,10,"Addizioni tra numeri naturalinLe addizioni fra numerali si effettuano cifra a cifra (come in decimale) portando il riporto alla cifra successiva
Riccardo Torlone -Corso di Calcolatori Elettronici120 + 0 = 00 + 1 = 11 + 0 = 11 + 1 = 0 con il riporto di 1ES     3 + 2 = 50011+0010 =0101Se il numero di cifre non permette di rappresentare il risultato si ha un trabocco nella propagazione del riporto"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#11,11,Moltiplicazioni fra numeri naturalinLa tabellina delle moltiplicazioni èmolto semplice:0    10  0    01  0    1nL’operazione fra numerali si effettua come in decimale: si incolonnano e si sommano i prodotti parziali scalandoli opportunamente:(11)101011x(5 )100101=101100001011 (55)10110111nNotare che ciascun prodotto parziale èpari a zero o al moltiplicandoRiccardo Torlone -Corso di Calcolatori Elettronici13
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#12,12,Riccardo Torlone -Corso di Calcolatori Elettronici14Numeri in virgola fissa senza segnonNaturale estensione della rappresentazione dei numeri naturalinSi stabilisce il numero di bitnViene fissata la posizione della virgolanSi interpreta con il meccanismo posizionale di basenEsempio:n6 cifre di cui due decimalinNumerale: 1010.01nInterpretazione: 1·23+0·22+1·21+0·20+0·2-1+1·2-2=10.25
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#13,13,"Riccardo Torlone -Corso di Calcolatori Elettronici15Addizioni tra numeri positivi in virgola fissanSi opera come in decimaleES     3,5 + 2,75 = 6,250011.10+0010.11 =0110.01"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#14,14,"Riccardo Torlone -Corso di Calcolatori Elettronici16Moltiplicazioni tra numeri positivi in virgola fissanSi opera come in decimale, tenendo conto del numero di cifre frazionarie e riposizionando il punto:(2.75)1010.11x(1.25)1001.01=10 110 00010 11 (3.4375)1011.0111nNotare che:nmoltiplicareper 2nequivale a spostare il punto di n posti a destranmoltiplicareper 2-nequivale a spostare il punto di n posti a sinistra(2.75)10010.11x(2)1010=00 001 01 1(5.5)101 01.10"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#15,15,Riccardo Torlone -Corso di Calcolatori Elettronici17Moltiplicazione per potenze di duenMoltiplicareper 2nequivale a spostare il punto di n posti a destra(3.75)100011.11  x22= (4)100100.00  =0000000000000000000001111(15)1001111.0000
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#16,16,"Riccardo Torlone -Corso di Calcolatori Elettronici18Moltiplicazione per potenze di duenMoltiplicareper 2-nequivale a spostare il punto di n posti a sinistra(3.75)1011.11  x2-2= (0.25)1000.01  =1111000000000000(0,9375)10000.1111"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#17,17,"Riccardo Torlone -Corso di Calcolatori Elettronici19Interi con segnonPer rappresentare gli interi relativi, a parità di cifre si dimezza l’intervallo  dei valori assolutinSi utilizzano varie rappresentazioniModulo e segnonun bit per il segno   0: +   1: –nn-1 bit per il modulonintervallo    [–2n–1+1, +2n–1–1]ESn=4 bit       intervallo  [–7,+7]5 = 0101 –5 = 1101NBnintervallo simmetricondoppia rappresentazione dello zero"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#18,18,"Complemento a 1nSi aggiunge uno 0 a sinistranI numeri positivi si rappresentano con il sistema posizionale nPer cambiare di segno si complementail numerale bit a bitnI numerali positivi iniziano per 0, i negativi per 1nCon n bit:   [–2n-1+1, +2n-1–1]ESn=4 bit     intervallo [–7, +7]5 = 0101            –5 =1010nComplementare = cambiare segnonDoppia rappresentazione dello 0
Riccardo Torlone -Corso di Calcolatori Elettronici20"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#19,19,"Complemento a 2nI positivi hanno la stessa rappresentazione che in complemento a 1nI negativi si ottengono sommando 1 alla loro rappresentazione in complemento a 1nIntervallo con n bit:   [–2n–1, +2n–1–1]nRegola pratica per complementare (cambiare segno al numerale): nPartendo da destra si lasciano invariati tutti i bit fino al primo uno compreso, e poi si complementabit a bitESn=4  bit    intervallo [–8, +7]5 = 0101            –5 = 1011   nIntervallo più estesonUna sola rappresentazione dello 0nComplementare (a 2) = cambiare segnoRiccardo Torlone -Corso di Calcolatori Elettronici21"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#2,2,"Riccardo Torlone -Corso di Calcolatori Elettronici3Ordini di grandezzaLe potenze di 2:§20... 29= 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, ..§210= 1.024                            ~ 1031K§220= 210210=1.048.576          ~ 1061M§230= 210210210=1.073.741.824~ 1091G §240= ... =1.099.511.627.770~ 1012  1T§250= ... =1.125.899.906.842.624~ 10151PES    226=  26×220= 64 MIl numero n di bit di un indirizzo binario determina le dimensioni della memoria (disposizioni con ripetizione di 0/1 su n posizioni):CPUbit indirizzoMemoria808016 bit64 K8086 20 bit1 Mega8028624 bit16 Mega8048632 bit4 GigaPentium32 bit4 Giga"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#20,20,"Rappresentazioni in CP1 e CP2
Riccardo Torlone -Corso di Calcolatori Elettronici22ES  rappresentare (-347)10in CP2§28= 256 < 347 < 512 = 29§intervallo con n bit:  [-2n-1,+2n-1-1]§pertanto   nmin=10§+347 in notazione a 10 bit:512256128643216842101     0     1    0     1     1    0    1    1§complementandoa 2:-51225612864321684211     0     1     0    1    0    0    1    0    1§Se il numero è positivo:a)determinare il numero di bit nb)rappresentare il numero con il sistema posizionale su n bit§Se il numero è negativo:a)determinare il numero di bit nb)rappresentare il numero positivo con il sistema posizionale su nbitc)complementare (a 1 o a 2) il numerale così ottenuto"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#21,21,"Interpretazionein CP1 e in CP2nDato un numerale:nEs. 00110 oppure10101nSi determinail segnonSe èpositivosiinterpretacon il sistemaposizionalen00110 →22+21= 6nSe ènegativosicomplementa(a 1 o a 2) e poi siinterpretacon il sistemaposizionale(aggiungendoil -)n10101 (CP2) →-(01011) →-(23+21+20) = -11
Riccardo Torlone-Corso di Calcolatori Elettronici23"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#22,22,"Riccardo Torlone -Corso di Calcolatori Elettronici24Addizioni in complemento a duenIn CP2 somme e sottrazioni tra numerali sono gestite nello stesso modo, ma si deve ignorare il trabocco:4+0100+                            2=0010=60110nSe i due operandi hanno segno diverso il risultato è sempre corretto:4+0100+-1=1111=310011nSe i due operandi hanno lo stesso segno e il risultato segno diverso c’è errore6+0110+3=0011=91001( 9 non è compreso nell’intervallo )×"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#23,23,"Riccardo Torlone -Corso di Calcolatori Elettronici25Altre operazioni su numeri con segnonPer fare la differenza si complementail sottraendo e si somma:6−0110+                            2=                   0010 1110=40100nLe moltiplicazioni si fanno tra i valori assoluti e alla fine, se necessario, si complementa:(11)10x01011x(-5)1000101=010110000001011 0000000000000110111(-55) 10111001001"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#24,24,"Eccesso 2n-1nI numeri vengono rappresentati come somma fra il numero dato e una potenza di 2, detta eccessonCon n bit l’eccesso è tipicamente 2n–1nIntervallo come CP2:  [–2n–1,+2n–1–1]nI numerali positivi iniziano per 1, i negativi per 0nRegola pratica: nI numerali si ottengono da quelli in CP2 complementandoil bit più significativo ESn=4 bit: eccesso 8,  intervallo [-8,+7]–3       –3+8=5     :  0101+4      +4+8=12   :  1100nIntervallo asimmetriconRappresentazione unica dello 0Riccardo Torlone -Corso di Calcolatori Elettronici26"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#25,25,"Rappresentazioni in eccesso 2n-1nDato un numero m (positivo o negativo) determinare il numero minimo di cifre nminnecessarie nDeterminare l’eccesso corrispondentenSommare m all’eccesso e rappresentare il numero ottenutoESrappresentare (-347)10in eccesso 2n-1n28= 256 < 347 < 512 = 29nintervallo con n bit:  [–2n-1,+2n-1–1]npertanto   nmin=10, eccesso 29= 512n–347 + 512 = 165n165 = 128+32+4+1n(–347)10in eccesso 29è:512 25612864321684210     0    1   0   1    0    0   1   0   1  Riccardo Torlone -Corso di Calcolatori Elettronici27"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#26,26,"Interpretazionein eccessonDato un numerale:nEs. 00110 oppure10101 in ecc. a 16nIndipendentementedal segno siinterpretacon il sistemaposizionalee poi sitogliel’eccesson00110 →22+21-16 = -10n10101 →24+22+20-16 = 5nOppure:nSe èpositivosiinterpretacon il sistemaposizionaleignorandoil primo bitn10101 →22+20= 5nSe ènegativosiinverteil primo bit, sicomplementaa 2 e poi siinterpretacon il sistemaposizionale(aggiungendoil -)n00110 →10110 →01010 = -11Riccardo Torlone -Corso di Calcolatori Elettronici28"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#27,27,Riccardo Torlone -Corso di Calcolatori Elettronici29Rappresentazioni a confrontoDecimaleM&SCP1CP2Ecc 8+ 70111011101111111 + 60110011001101110 + 50101010101011101+ 40100010001001100+ 30011001100111011+ 20010001000101010 + 10001000100011001+ 00000000000001000–010001111–––––––11001111011110111–21010110111100110–31011110011010101–41100101111000100–51101101010110011–61110100110100010–71111100010010001–8––––––10000000
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#28,28,"Notazione in base 16nPer i numerali esadecimali occorrono 16 cifre {0,1,…,9,A,B,C,D,E,F}nConversione esadecimale-binario:nSi fa corrispondere a ciascuna cifra esadecimale il gruppo di 4 bit che ne rappresenta il valorenConversione binario-esadecimale:nPartendo da destra si fa corrispondere a ciascun gruppo di 4 o meno cifre binarie la cifra esadecimale che ne rappresenta il valoreESF57A31111101010111101000110001nSi usano spesso stringhe esadecimali per rappresentare stringhe binariein forma compattaRiccardo Torlone -Corso di Calcolatori Elettronici30"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#29,29,Riccardo Torlone -Corso di Calcolatori Elettronici31Numerali e numerinUn numerale è solo una stringa di cifrenUn numerale rappresenta un numero solo se si specifica un sistema di numerazionenLo stesso numerale rappresenta diversi numeri in diverse notazioniESla stringa   110100  rappresenta:nCentodiecimilacentoin base 10n(+52)10in binario naturalen(-11)10in complemento a 1n(-12)10in complemento a 2n(+20)10in eccesso 32nIn esadecimale un numero grandissimo
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#3,3,"Riccardo Torlone -Corso di Calcolatori Elettronici4Un sistema di riferimento impreciso..
"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#30,30,"Riccardo Torlone -Corso di Calcolatori Elettronici32Notazione in virgola mobilenEstende l’intervallo di numeri rappresentati a parità di cifre, rispetto alla notazione in virgola fissanNumeri reali rappresentati tramite una coppia di numeri  <m,e>n = m ×benm : mantissa(normalizzata tra due potenze successive della base)bi-1 £| m | <bine : esponenteintero con segnonSia m che e hanno un numero finitodi cifre:nIntervalli limitatinErrori di arrotondamento"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#31,31,"Esempio in base 10nNumerali a 5 cifre   + .XXX + EEnMantissa: 3 cifre con segno     0.1 £|m| <1nEsponente: 2 cifre con segno -99 £e £+99
nNotare che con lo stesso numero di cifre in notazione a virgola fissa  +XXX.YY   nL’intervallo scende [-999.99,+999.99]nMa si hanno 5 cifre significative invece di 3Riccardo Torlone -Corso di Calcolatori Elettronici330.999*10+9900.1*10-99-0.1*10-99Underflownegativo-0.999*10+99OverflowpositivoOverflownegativo-10+99Underflowpositivo-10-10010-10010+9910-105"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#32,32,"Standard IEEE 754 (1985)nFormato non proprietario cioè non dipendente dall’architetturanSemplice precisione a 32 bit: 
nDoppia precisione a 64 bit
nNotazioni con mantissa normalizzata e nonAlcune configurazioni dell’esponente sono riservateRiccardo Torlone-Corso di Calcolatori Elettronici341espmantissa823+/-1espmantissa1152+/-"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#33,33,"Standard IEEE 754 a 32 bit: numeri normalizzati§Esponente: eccesso 127  [–127, +128]non si usano gli estremi, quindi:–126 £e £127§Mantissa: rappresentata solo la parte decimale con la notazione posizionale:1 £m<2§Intervallo numeri normalizzati   [ 2–126, ~2128]§Uso delle configurazioni riservate:§med etutti 0: rappresenta lo 0§mtutti 0 ed etutti 1: overflow§m¹0 ed etutti 1: NotA Number§m¹0 ed etutti 0: numero denormalizzatoRiccardo Torlone -Corso di Calcolatori Elettronici351espmantissa823+/-"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#34,34,Riccardo Torlone -Corso di Calcolatori Elettronici36Standard IEEE normalizzati: estremi intervallonPiù grande normalizzato~2128:X1111111011111111111111111111111+/–2127(1.11...1)2»~2nPiù piccolo normalizzato2-126:X0000000100000000000000000000000+/–2–126(1.00...0)2= 1
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#35,35,"Standard IEEE 754 a 32 bit: numeri denormalizzati§Esponente§Uguale a 00000000§evale convenzionalmente 2-126 §Mantissa: §diversa da 0§0 < m < 1 §Intervallo di rappresentazione§[2-1262-23= 2-149 , ~2-126]
Riccardo Torlone -Corso di Calcolatori Elettronici371espmantissa823+/-"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#36,36,Riccardo Torlone -Corso di Calcolatori Elettronici38Standard IEEE denormalizzati: estremi intervallonPiù grande denormalizzato~2-126:X0000000011111111111111111111111+/–2-126(0.11...1)2»~1nPiù piccolo denormalizzato2-149:X0000000000000000000000000000001+/–2–126(0.00...1)2= 2 -23
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#37,37,"Riccardo Torlone -Corso di Calcolatori Elettronici39Addizioni in virgola mobilenPer addizione e sottrazione occorre scalare le mantisse per eguagliare gli esponentiES     nn1+ n2n1:01001100100010111011100101100111n2:01010101011001100111000111000100ne1= (26)10, e2= (43)10:occorre scalare n1di 17 postin'1:01010101000000000000000001000101 +n2:0101010101100110011100011100010001010101011001100111001000001001 nNotare che l’addendo più piccolo perde cifre significative"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#38,38,"Riccardo Torlone -Corso di Calcolatori Elettronici40Moltiplicazioni in virgola mobile§Si moltiplicano le mantisse e si sommano algebricamente gli esponenti§Se necessario si scala la mantissa per normalizzarla e si riaggiusta l’esponenteESn3 = n1x  n2n1:   0 10011001 10010111011100101100111n2:   1 10101010 10000000000000000000000§e1= (26 )10, e2= (43 )10§e1+ e2 = (69)10= 11000100§m1x m2 = 10.011000110010101110110101§si scala la mantissa di un posto §si aumenta di  1  l’esponenten3:    1 11000101  00110001100101011101101 "
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#39,39,Riccardo Torlone -Corso di Calcolatori Elettronici41Errore assoluto e relativonRappresentando un numero reale nin una notazione floating-point si commette un errore di approssimazionenIn realtà viene rappresentato un numero razionale n´con un numero limitato di cifre significativenErrore assoluto:  eA= n–n´nErrore relativo:eR=eA/n = (n–n´)/nnSe la mantissa è normalizzata l’errorerelativo massimo ècostante su tutto l’intervallo rappresentato ed è pari ad un’unitàsull’ultima cifra rappresentaES     10cifre frazionarie  eR = 2 -10nNelle notazioni non normalizzate l’errore relativo massimo non è costante
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#4,4,"Numeri e numeralinNumero: entità astratta nNumerale: stringa di caratteri che rappresenta un numero in un dato sistema di numerazionenLo stesso numero è rappresentato da numerali diversi in sistemi di numerazione diversi n156 nel sistema decimale -CLVI in numeri romaninLo stesso numerale rappresenta numeri diversi in sistemi di numerazione diversin11 vale undici nel sistema decimale tre nel sistema binarionIl numero di caratteri del numerale determina l’intervallo di numeri rappresentabilininteri a 3 cifre con segno nel sistema decimale:[-999,+999] Riccardo Torlone -Corso di Calcolatori Elettronici5"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#40,40,"Riccardo Torlone -Corso di Calcolatori Elettronici42Codifica di caratteri: codice ASCII (Hex0-1F)
"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#41,41,"Riccardo Torlone -Corso di Calcolatori Elettronici43Codice ASCII (Hex 20-7F)
"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#42,42,"Codifica di caratteri: Codice UNICODEnCodice UNICODE a 16 bit, nuova proposta di standard:n65.536 code pointsnSemplifica la scrittura del softwaren336 code points: alfabeti latinin112 accenti e simboli diacriticinGreco, cirillico, ebraico, ecc.n21.000 ideogrammi cinesi……nUn consorzio assegna quello che restanUTF-8: codice a lunghezza variabile basato su Unicoden0ddddddd: ASCIInAltri prefissi che iniziano per 1: codifiche più lunghe
Riccardo Torlone -Corso di Calcolatori Elettronici44"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#43,43,"Esempio 1: virgola mobilenRappresentazione binaria in virgola mobile a 16 bit:n1 bit per il segno (0=positivo)n8 bit per l'esponente, in eccesso 128n7 bit per la parte frazionaria della mantissa normalizzata tra 1 e 2nCalcolare gli estremi degli intervalli rappresentati, i numerali corrispondenti, e l’ordine di grandezza decimale assumendo che le configurazioni con tutti 0 e con tutti 1 siano riservate.nRappresentare in tale notazione:nil numero m rappresentato in compl. a 2 dai tre byte FF5AB9nil numero n rappresentato in compl. a 1 dai tre byte 13B472 nCalcolare l’errore relativo ed assoluto che si commette rappresentando i numero m ed n nella notazione data
Riccardo Torlone -Corso di Calcolatori Elettronici45"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#44,44,"Esempio 2: virgola mobilenRappresentazione binaria in virgola mobile a 16 bit:n1 bit per il segno (0=positivo)n8 bit per l'esponente, in eccesso 128 (configurazioni con tutti 0 e con tutti 1 riservate)n7 bit per la parte frazionaria della mantissa normalizzata tra 1 e 2nDato il numero m rappresentato in tale notazionedai due byte C3A5, calcolare l’intero n che approssima m per difetto, e rappresentarlo in complemento a 2 con 16 bit.
Riccardo Torlone -Corso di Calcolatori Elettronici46"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#45,45,"Esempio 3: virgola mobilenRappresentazione binaria in virgola mobile a 16 bit:n1 bit per il segno (0=positivo)ne bit per l'esponente, in eccesso 2e-1n15–e bit per la parte decimale della mantissa normalizzata tra 1 e 2nconfigurazioni dell’esponente con tutti 0 e con tutti 1 riservatenCalcolare il valore minimo emindi bit per l’esponente che consenta di rappresentare il numero n rappresentato in complementoa 2 dai tre byte FF5AB9nRappresentare nnel sistema trovato
Riccardo Torlone -Corso di Calcolatori Elettronici47"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#46,46,"Esempio 4: virgola mobilenRappresentazione binaria in virgola mobile a 16 bit:n1 bit per il segno (0=positivo)n7 bit per l'esponente, in eccesso 64n8 bit per la parte decimale della mantissanormalizzata tra 1 e 2nconfigurazioni dell’esponente con tutti 0 e con tutti 1 riservatenDati m e n rappresentati in tale notazione dalle stringhe esadecimali FC53 e F8F2 nCalcolare la somma di m e n e fornire la stringa esadecimale che la rappresenta nella notazione suddettanIndicare l’eventuale errore assoluto che si commettenProvare anche con FC53 e 78F2nProvare anche con 7C53 e F8F2
Riccardo Torlone -Corso di Calcolatori Elettronici48"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#47,47,"Esercizio 5: virgola mobileSi considerino i numeri m ed nche, nel sistema di rappresentazione in eccesso a 27, sono rappresentati rispettivamente dalle le stringhe esadecimali 63 e 93.A.Calcolare il valore di s= m + ne rappresentare snel sistema di rappresentazione in complemento a due su 12 bit.B.Individuare una rappresentazione in virgola mobile che consenta di rappresentare il suddetto numero scon il numero minimo possibile di bit ed indicare l’intervallo di rappresentazione della rappresentazione individuata tenendo conto del fatto che le configurazioni dell’esponente composte da tutti 0 e da tutti 1 sono riservate;C.Rappresentare, nella notazione in virgola mobile definita al punto B, i numeri decimali 0, -2 e 1,25 indicando gli eventuali errori di rappresentazione commessi;D.Individuare il numero e di bit dell’esponente e il numero m di bit della mantissa di una notazione in virgola mobile a 16 bit che sia in grado di rappresentare tutti i numeri rappresentabili nella definita al punto A e che abbia l’intervallo di rappresentazione più grande possibile."
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#48,48,"Esercizio 6: virgola mobileSi consideri una rappresentazione binaria in virgola mobile a 12 bit, di cui (nell’ordine da sinistra a destra) 1 bit per il segno (0=positivo), e per l’esponente, che è rappresentato in eccesso a 2e−1, e i rimanenti bit per la parte frazionaria della mantissa m che è normalizzata tra 1 e 2.A.Calcolare il valore di e che consente di rappresentare, con la massima precisione possibile, numeri compresi in valore assoluto tra 1000 e 0,001;B.tenendo conto del fatto che le configurazioni dell’esponente composte da tutti 0 e da tutti 1 sono riservate, indicare il più piccolo e il più grande numero che è possibile rappresentare nella notazione in virgola mobile definita al punto A specificando i numerali corrispondenti;C.rappresentare nella notazione individuata al punto A il numero 512 e il numero -1, indicando gli eventuali errori assoluti che si commettono;D.dato il numero nrappresentato nella notazione definita al punto A dalla stringa esadecimale D85, rappresentarlo: (a) in complemento a 2 su 8 bit e (b) in eccesso 29su 10 bit.Riccardo Torlone -Corso di Calcolatori Elettronici50"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#49,49,"Esercizio 7: virgola mobileSi consideri una rappresentazione binaria in virgola mobile a 20 bit, di cui si usa: 1 per il segno (0=positivo), 7 per l'esponente, che è rappresentato in eccesso a 64, e 12 per la parte decimale della mantissa. Con valori dell'esponente diversi da 0000000 la mantissa è normalizzata tra 1 e 2 (1 ≤ man < 2). Con esponente pari a 0000000 si rappresentano invece numeri denormalizzati, con esponente uguale a -63 e mantissa compresa tra 0 e 1 (0 < man < 1). A.Calcolare l'ordine di grandezza decimale del più piccolo numero positivo normalizzato e del più grande numero positivo denormalizzato, rappresentabili nella notazione suddetta.B.Dato il numero n rappresentato in complemento a 2 dai tre byte FF323B, ricavare il numerale che approssima meglio nella notazione suddetta il numero m = n×2-85, esprimendolo come stringa esadecimale.C.Calcolare gli ordini di grandezza sia binari che decimali dell'errore assoluto che si commette rappresentando m nella notazione suddetta.Riccardo Torlone -Corso di Calcolatori Elettronici51"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#5,5,"Numeri a precisione finitanNumero finito di cifre nSi perdono alcune proprietà:nchiusura operatori ( + , -, ´)nproprietà associativa, distributiva,..nEsempio:n2 cifre decimali e segno [–99,+99]n78+36=114  (chiusura)n60+(50–40) ¹(60+50)–40 (associatività)nErrori di arrotondamenton""Buchi"" nella rappresentazione dei realinEsempio:nnumerali decimali con due sole cifre frazionarie
Riccardo Torlone -Corso di Calcolatori Elettronici60?0.010.02"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#6,6,"Meccanismo di base: sistema posizionaleCiascuna cifra rappresenta il coefficiente di una potenza della base L’esponente è dato dalla posizione della cifra
Se la base è b occorrono b simboli:nb = 10  {0,1,…,9}nb =  2   {0,1}nb =  8   {0,1,…,7}nb = 16  {0,1,…,9,A,B,C,D,E,F}Riccardo Torlone -Corso di Calcolatori Elettronici7125.4210010-110-2101102am.... a1a0. a-1 a-2... a-kb = base 0 £ai £b-1ESN=aibii=-kmS"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#7,7,"Riccardo Torlone -Corso di Calcolatori Elettronici8Esempio in base binaria (virgola fissa)
Numero rappresentato in formato decimale:1·23+ 0·22+ 1·21+ 0·20+ 0·2-1+ 1·2-2 = 10.251010.01202-12-2212223"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#8,8,"Riccardo Torlone -Corso di Calcolatori Elettronici9Esempio in base ottale (virgola fissa)
Numero rappresentato in formato decimale:2·83+ 1·82+ 0·81+ 7·80+ 4·8-1+ 5·8-2 = 1095.5781252107.45808-18-2818283"
data_test\rootfolder\università\CalcolatoriElettronici2\03 Sistemi di Numerazione Binaria.pdf#9,9,"Numeri naturalinRappresentando gli interi positivi in notazione binaria con nbit si copre l’intervallo [0 , 2n–1]nSi sfruttano tutte le 2ndisposizioniES      n=3    [0,7]00001001201030114100510161107111N.B.  Anche gli 0 non significativi devono essere rappresentatiRiccardo Torlone -Corso di Calcolatori Elettronici11"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#0,0,Calcolatori ElettroniciParte III:L’organizzazione generale del calcolatoreProf. Riccardo TorloneUniversità Roma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#1,1,Riccardo Torlone -Corso di Calcolatori Elettronici2Terminologia di basenCalcolatore elettronico: macchina fatta di dispositivi elettronici che può risolvere problemi eseguendo istruzioni forniteglinProgramma: sequenza di istruzioni in un linguaggionLinguaggio macchina: eseguibile direttamente da un calcolatore (binario)Con dispositivi elettronici si possono eseguire direttamente solo un numero limitato di istruzioni semplici (costi)I linguaggi macchina non sono adatti per le persone
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#10,10,"Vari Tipi di ParallelismoIl parallelismo è ormai l’unica strada per aumentare le prestazioni Limite di un’esecuzione sequenziale: velocità della luce (30 cm in 1 nsec)Due tipi di parallelismo:A)alivello di istruzioninDiverse istruzioni eseguite insiemenDiverse fasi della stessa istruzione eseguite insiemeB)alivello di processorinMolti processori lavorano insieme allo stesso problemanFattori di parallelismo molto elevatinDiversi tipi di interconnessione e di cooperazione (più o meno stretta)
Riccardo Torlone -Corso di Calcolatori Elettronici13"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#11,11,"Riccardo Torlone -Corso di Calcolatori Elettronici14Parallelismo a livello di istruzioni: Pipelining
nCiascuna istruzione è divisa in fasinL’esecuzione avviene in una pipelinea più stadinPiù istruzioni in esecuzione contemporaneanUna istruzione completata per ogni cicloN.B.Si guadagna un fattore pari al numero di stadi della pipeline
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#12,12,"Riccardo Torlone -Corso di Calcolatori Elettronici15Caratteristiche di una pipelineUna pipeline consente un compromesso tra:nLatenza: tempo per eseguire una istruzionenAmpiezza di banda: numero di istruzioni completate per unità di tempo misurata in MIPS (milioni di istruzioni al secondo) -oggi in GFLOPS o TFLOPS (109o 1012istruzioni in virgola mobile al secondo)Con:nVelocità di clock = Tnsec(periodo del segnale di clock)nNumero di stadi = nAbbiamo:nLatenza= nTnAmpiezza di banda= 1 istr. ogni T nsec, ovvero: 109/T istr. ogni sec., ovvero: 1000/TMIPS"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#13,13,"Architetture SuperscalariArchitetture nelle quali si avviano più istruzioni (4-6) insiemeSi aumenta il parallelismo avendo più di una pipeline nel microprocessoreLe pipeline possono essere specializzate:nUna versione dell’i7 ha diverse pipeline a più stadinPuò eseguire fino a 6 micro-istruzioni in paralleloProblema: compatibilità dell’esecuzione parallelanIndipendenza tra le istruzioninCiascuna istruzione non deve utilizzare i risultati dell’altraRiccardo Torlone -Corso di Calcolatori Elettronici16
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#14,14,"Unità Funzionali Multiple 
nVariante: solo lo stadio più lento della pipeline (che condiziona la velocità) viene parallelizzatonLa CPU contiene al suo interno diverse unità funzionali indipendentinArchitettura adottata nei processori Intel CoreRiccardo Torlone -Corso di Calcolatori Elettronici17
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#15,15,"Parallelismo a livello di processorinMiglioramento delle prestazioni con parallelismo a livello di istruzioni: 5-10 voltenPer migliorare ancora: CPU multiplenApprocci:nData parallelism(SIMD)nProcessori matricialinProcessori vettorialinGPUnTask parallelism(MIMD)nMultiprocessorinMulticorenMulticomputer
Riccardo Torlone -Corso di Calcolatori Elettronici18[  || (inti : 100) array[i]++;  ][   a++;  ||  b+c;   ]  "
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#16,16,"GPUnOperazioni comuni su pixel, vertici, archi, figurenEs.: Nvidia Fermi GPU (2009)n16 processori streamSIMDnOgni processore ha 32 corenFino a 512 operazioni per ciclo di clock
Riccardo Torlone -Corso di Calcolatori Elettronici21
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#17,17,"Multiprocessori
nLe CPUlavorano indipendentementenSharedmemory: il bus può divenire collo di bottiglianPrivate memory: contiene il codice e parte dei datinScambio dati tramite la sharedmemory
Riccardo Torlone -Corso di Calcolatori Elettronici22
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#18,18,"ArchitetturemulticorenLa CPU è composta da più core, ovvero da più nuclei di processori fisici montati sullo stesso packagenOgni core:nè un processore indipendentenpuò essere dotato di cache autonomanArchitetture omogenee (core identici) o eterogenee (p-core vs e-core)nOgni corepuò essere multiscalarenAccoppiamento dei core:nstretto: sharedcachenlasco: private cachenNascono a partire dal 2003:nIBM: PowerPCnIntel: Pentium D, Core 2, Core I3-i5-i7 nAMD: Athlon, Opteron, Phenom, RyzenRiccardo Torlone-Corso di Calcolatori Elettronici23
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#19,19,"MulticomputernI singoli elementi sono normali Workstationo PCnComunicazionetramitescambiodi messaggi(shared nothing)
Riccardo Torlone -Corso di Calcolatori Elettronici24
MIMD (Multiple InstructionMultiple Data)"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#2,2,"Riccardo Torlone -Corso di Calcolatori Elettronici5Struttura del computer
nLa memoria contiene sia i dati che le istruzioninIl contenuto dei registri può essere scambiato con la memoria e l’I/OnLe istruzioni trasferiscono i dati e modificano il contenuto dei registrinRegistri particolari:nPC: indirizza la prossima istruzionenIR: contiene l’istruzione corrente
PC:Program CounterIR:  Instruction Register"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#20,20,"Le varie forme di parallelismo
Riccardo Torlone -Corso di Calcolatori Elettronici25
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#21,21,La Memoria CentralenContiene sia i programmi che i datinMemorizzazione binaria (bit)nCella (o locazione): unità indirizzabilenbyte: 8 bit (minimo indirizzabile)nword: insieme di Kbyte (Kdipende dall’architettura)nIndirizzo (della cella): tramite il quale la CPU accede al dato nella cellanIndirizzi binari a m bit: spazio di indirizzamento  2mcelleESPentium IVnArchitettura a 32 bitnRegistri e ALU a 32 bit nWord di 4 byte 32 bitnIndirizzi a 32 bitnSpazio indirizzabile 232= 4 GB(64GB con opportuniaccorgimenti)Riccardo Torlone -Corso di Calcolatori Elettronici26
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#22,22,"Riccardo Torlone -Corso di Calcolatori Elettronici27Organizzazione della memoriaDiverse possibilitànEsempio con 96 bit totali:
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#23,23,"Riccardo Torlone -Corso di Calcolatori Elettronici28Dimensione locazioni di memoriaDiverse soluzioni possibili
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#24,24,"Riccardo Torlone -Corso di Calcolatori Elettronici30Codici a correzione di erroreTecniche per garantire maggiore affidabilità nella registrazione / trasmissione di informazioni binarieRecupero degli errori hardware tramite codifiche ridondantiCodifiche con n= m + rbitnnbit complessivi codificanmbit datinrcheckbit (ridondanti)Si utilizza solo un sottoinsieme (2m) delle codifiche (dette valide)ESCodicecon n=10, m=2, r=800000000000000011111111110000011111111112m= 4 codifiche valide (su 210)"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#25,25,"Riccardo Torlone -Corso di Calcolatori Elettronici31Distanza di HammingDistanza di Hammingtra due codifiche:numero di bit diversi:  0101 e 1001 sono a distanza 2Distanza di Hammingdi un codice:h = distanza di Hammingminima tra due codifiche valide del codice
nPer rilevareerrori su k bit occorre che sia: nalmeno h = k + 1 ovvero k ≤ h -1 nPer correggereerrori su k bit occorre che sia: nalmeno h = 2k + 1 ovvero k ≤ (h –1)/2 0000000000000001111111111000001111111111Distanza di Hamming del codice h=5ES"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#26,26,"Riccardo Torlone -Corso di Calcolatori Elettronici32Codici a correzione di errore (Esempio)ESCodice con n=10, m=2, r=80000000000000001111111111000001111111111Distanza di Hamming = 5h=5=k+1 ÞE’ possibile rilevareerrori quadrupli0000011111 →11110111111111011111 viene riconosciuto come erratoh=5=2k+1 ÞE’ possibile correggereerrori doppi0000011111 → 11000111111100011111 viene corretto in 0000011111"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#27,27,"Riccardo Torlone -Corso di Calcolatori Elettronici33Rilevazione di errore singolo (controllo di parità)nNel caso più semplice si vogliono solo rilevare errori singolinBasta aggiungere un solo check bit r=1, n=m+1nBit di parità: scelto in modo che il numero complessivo di 1 nella codifica sia sempre pari (o dispari)nQuesto codice ha distanza h=2nErrore rilevato da circuiti molto semplicinLe memorie segnalano parity errorquando un errore si manifestaES. 11011010 bit di parità:1 →110110101OK01100101 bit di parità:0 →011011010Error"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#28,28,"Correzione di errore singolonm data bit, rcheckbit, nbit totalin2mcodifiche validenncodifiche errate a distanza 1 da ciascuna delle validenOgni codifica valida ne richiede in tutto n+1ESLa codifica:0000Richiede le codifiche errate:1000010000100001Riccardo Torlone -Corso di Calcolatori Elettronici34"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#29,29,"Riccardo Torlone -Corso di Calcolatori Elettronici35Correzione di errore singolonSe ogni codifica valida ne richiede n+1 deve essere:(n+1) 2m£2ncioè(m+r+1) £2r
N.B.Al crescere di m l’overheadscende
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#3,3,"Struttura della CPU
nEsecuzione di operazioni aritmetiche e logiche sui dati contenuti nei registrinSpostamento di dati fra registri e fra registri e memorianCiclo elementare: due operandi sono inviati alla ALU e il risultato e messo in un registroRiccardo Torlone -Corso di Calcolatori Elettronici6
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#30,30,"Esercizio 1Riferendosi all'organizzazione generale di un calcolatore, indicare se le seguenti affermazioni sono vere o false.nNelle architetture RISC le istruzioni macchina vengono tradotte in microistruzioni che vengono poi eseguite dall'hardware.nLe tecnica del pipeline non è compatibile con una architettura superscalare.nUna architettura con indirizzi a 16 bit con indirizzamento al byte non può gestire una memoria più grande di 64KB.nIn processore con pipeline a 4 stadi e un clock con periodo di 2 nsecuna istruzione macchina richiede 2 nsecper essere eseguita.nUn processore con pipeline a 5 stadi e un clock con periodo di 5 nsecha un'ampiezza di banda di 200 MIPS.nL'ampiezza di banda (numero di istruzioni eseguite al secondo a regime) di un processore con pipeline non dipende dal numero di stadi della pipeline.nIn una architettura con pipeline sono necessari più cicli di clock per completare una istruzione macchina.nIn linea di principio, se si raddoppia la frequenza del clock si dimezza la latenza e si raddoppia l’ampiezza di banda.FALSO
VEROVEROFALSOVEROFALSOVEROVERO"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#31,31,"Esercizio 2Con riferimento ai codici a rilevazione e correzione di errore indicare se le seguenti affermazioni sono vere o false.nLa distanza di Hammingtra una codifica e il suo complemento a uno e pari alla lunghezza della codifica.nCon distanza di Hammingh=3 è possibile correggere 2 errori.nIl numero di bit di controllo necessari per rilevare un errore singolo su un codice a 8 bit è minore rispetto al numero bit di controllo necessari per un codice a 16 bit.nLa distanza di Hammingnel codice composto solo dalle parole 1100, 0011 e 1111 è 4.nLa percentuale di bit di controllo rispetto alla lunghezza complessiva di un codice a correzione di errore singolo diminuisce all'aumentare della lunghezza del codice.nPer rilevare r errori è necessario che un codice abbia una distanza di Hammingpari a 2r+1.nUn bit di parità permette solo di rilevare errori singoli.nSe in una parola si commette un errore singolo ma si conosce la sua posizione, il bit di parità è sufficiente a correggerlo.VERO
VEROVEROFALSOFALSOFALSOVEROFALSO"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#32,32,"Riccardo Torlone -Corso di Calcolatori Elettronici40Caching…
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#33,33,"Memorie Cache
nLa memoria è sempre più lenta della CPU e tende a rallentarlanMemorie veloci sono disponibili ma solo per piccole dimensioninLa cache (da cacher) funziona alla velocità del processore, e quindi nasconde la “lentezza” della memorianContiene le ultime porzioni di memoria acceduta: se la CPU vuole leggere una di esse evita un accesso a memorianFunziona bene a causa della località degli accessiRiccardo Torlone -Corso di Calcolatori Elettronici41
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#34,34,"Riccardo Torlone -Corso di Calcolatori Elettronici42Cache Hit RatioSeuna parola viene letta kvolte di seguito, k –1volte sarà trovata in cachenCache hit ratio:H = (k –1) /knTempo medio di accesso a memoria:nm: tempo di accesso della memorianc:  tempo di accesso della cacheA = c + (1 –H)mLa memoria è organizzata in blocchiPer ogni cache missun intero blocco è spostato in cache"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#35,35,"Tipologie schede memoria
nSIMM (Single InlineMemory Module)n72 piedini, 32 bit, 8-16 chip, 128 MBytenA coppie nel Pentium (bus dati 64 bit) nDIMM (Double InlineMemory Module)n120/240 piedini, 64 bit, 8 chip, 256 MBytenSO-DIMM (Small OutlineDIMM)nPer notebook di dimensioni più piccolenDDR, DDR2, DDR3, (M)DDR4, DDR5 (Double Data Rate): introducono un meccanismo di pipeline nella lettura/scrittura, fino a 288 pin.nAlcune hanno bit di parità altre noRiccardo Torlone -Corso di Calcolatori Elettronici43
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#36,36,"DDR a confronto
Riccardo Torlone -Corso di Calcolatori Elettronici44
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#37,37,"Gerarchie di memoria
Scendendo nella gerarchia:nCresce il tempo di accessonAumenta lacapacitànDiminuisce ilcosto per bitSolo il livello più alto della gerarchia è a contatto con la CPUMigrazione dei dati fra livelli della gerarchiaRiccardo Torlone -Corso di Calcolatori Elettronici45≤10-9~2 ·10-9~ 10 ·10-9~ 10-6/10-3100 ·10-3Access time (sec)24219230240>240Capacity(byte)"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#38,38,"Dischi magnetici
nDimensione: <10cm, Densità: 25Gb/cmnRegistrazione seriale su tracceconcentrichen50.000 tracce/cm (larghe ~200nm)nDischi ad alta densità con bit registrati perpendicolarmentenTracce divise in settoricontenenti i dati, un preamboloe un ECC(Error-CorrectingCode) (la capacità formattatascende del 15%)nVelocità di rotazione costante (5.400-10.800 RPM)nVelocità di trasferimento di 150 MB/sec (1 settore in 3.5 µsec)nBurstrate: velocità da quando la testina è sopra il primo bitnSustainedrate: velocità di trasferimento in un certo intervalloRiccardo Torlone -Corso di Calcolatori Elettronici46
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#39,39,"Riccardo Torlone -Corso di Calcolatori Elettronici47Dischi magnetici (2)
nCilindro: insieme di tracce sulla stessa verticalenTempo di seektseek: spostamento delle testine sul cilindro desiderato, dipende in parte dalla distanza (~5-10ms)nTempo di latencytlat: spostamento sul settore desiderato (~3-6ms)nTempo di accesso:tacc= tsee+ tlat
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#4,4,"Riccardo Torlone -Corso di Calcolatori Elettronici7Il ciclo Fetch-Decode-ExecuteL’esecuzione di ciascuna istruzione nella CPU richiede i seguenti passi:1.Carica l’istruzione da memoria in IR(Instruction Register) (Fetch)2.Incrementa PC(Program Counter)3.Decodifica l’istruzione (Decode)4.Se l’istruzione usa un dato in memoria calcolane l’indirizzo5.Carica l’operando in un registro6.Esegui l’istruzione (Execute)7. Torna al passo 1.Per l’esecuzione dell’istruzione successivaAccessi alla  memoria sono effettuati sempreal passo 1, e non sempreai passi 4 e 5"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#40,40,"Riccardo Torlone -Corso di Calcolatori Elettronici48Organizzazione dei dati su discoDensità di registrazione variabile con il raggio della traccia (~ 25 Gbit/cm)
La gestione è fatta da controllori di disco(CPU specializzate)
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#41,41,"Riccardo Torlone -Corso di Calcolatori Elettronici49Un hard disk
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#42,42,"Riccardo Torlone -Corso di Calcolatori Elettronici50Dischi IDE e EIDEnIDE: standard nato con il PC XT IBMnLimite di 16 testine, 63 settori e 1024 cilindri: in tutto 504 MB, transfer rate: ~4MB/secnEIDE estende lo standard mediante lo schema LBA (LogicalBlock Addressing) che prevede 228settorinTotale di 228×29B = 128GBn2 controllori -4 dischi per controllore ntransfer rate più alta ~17MB/secnATA-3 (AT Attachment) a 33MB/secnATAPI-5 (ATA PAcketInterface) a 66MB/sec nATAPI-6 a 100MB/sec nLBA a 48 bit –Massimo: 248×29B=128PBnATAPI-8 e successivi: basato su SATA (Serial ATA)nconnettori a meno bit (da 80 a 7), tensioni più basse (0.5V), velocità maggiori (>500MB/sec)nSCSI: Controller e interfaccia più intelligente, Bus con connessione daisychain, versione moderna: Serial attachedSCSI (>10Gb/sec)"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#43,43,"Riccardo Torlone -Corso di Calcolatori Elettronici52Dischi RAIDProblema: miglioramento lento delle prestazioni dei dischi (1970: tseek=50ms; 2018: tseek=5-10ms)Soluzione: RAID(RedundantArray of  InexpensiveDisks)nDividere i dati su più dischinParallelizzare l’accessonAumentare il data ratenIntrodurre una resistenza ai guasti Contrapposti a SLED (Single Large ExpensiveDisk)Data Striping: dati consecutivi nello stesso file vengono ""affettati"" e disposti  su dischi diversi, dai quali possono essere letti (e scritti) in parallelo"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#44,44,"Riccardo Torlone -Corso di Calcolatori Elettronici53RAID Level 0 e Level 1
nSu n dischi si può guadagnare un fattore n sia in lettura che in scritturanLo MTBF (Mean Time Between Failures) peggioranNon c’è ridondanza: non è un vero RAID
§Ciascun disco è duplicato: shadowing§Ottime prestazioni soprattutto in lettura: molte possibilità di bilanciare carico§Eccellente resistenza ai guasti§Supportato anche da vari SO (Es. Windows)"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#45,45,"Riccardo Torlone -Corso di Calcolatori Elettronici54RAID Level 2
nStripinga livello di word o di bytenEsempio: un nibble(mezzo byte) più 3 bit: codice di Hamming a 7 bitnRegistrazione ad 1 bit per ogni disconRotazione dei dischi sincronizzatanResiste a guasti semplicinGuadagna un fattore 4 in read e writenForte overhead(nell’esempio 75%)nHa senso con molti dischi:n32 bit+(6+1) parità Þ39 dischinOverhead del 19%nGuadagna un fattore 32 in read e write
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#46,46,"Riccardo Torlone -Corso di Calcolatori Elettronici55RAID Level 3
nVersione semplificata di RAID 2nResiste a guasti semplici! Il bit di parità, sapendo quale drive è rotto, consente la correzionenOverheadabbastanza contenutoRAID 2e 3offrono un’eccellente data rate ma permettono di gestire solo una operazione su disco per volta perché ciascuna operazione coinvolge tutti i dischi
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#47,47,"Riccardo Torlone -Corso di Calcolatori Elettronici56RAID 4 e RAID 5
nStripinga livello di blocco: drive non sincronizzatinRAID 4: la stripnell’ultimo disco contiene i bit di parita dell’insieme di bit omologhi di tutte le altre stripnResiste a guasti singoli (vedi RAID 3)nSe una sola stripè scritta occorre leggere tutte le altre per calcolare la parità nIl disco di parità è il collo di bottiglianRAID 5distribuisce le stripdi parità 
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#48,48,"Unità a stato solido (SSD)nBasata sul fenomeno ""Hot-carrierinjection"" dei transistornCelle di memoria flash a stato solidonMontate sopra un normale transistornApplicando una tensione al CG:nIl FG si carica (no alimentazione)nAumenta la tensione di commutazionenTest di commutazione a basso voltaggionTempi di trasferimento: >200MB/secnAdatto a dispositivi mobilinCosti più alti: ~1c/GB ®~1€/GBnMaggiore ""failurerate"": ~ 100.000 WritenWearleveling: distribuzione uniforme delle scritture sulle celle dell’unitànAumento di capacità con celle multilivellonVersione moderna: 3D XPointRiccardo Torlone -Corso di Calcolatori Elettronici57
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#49,49,"Riccardo Torlone -Corso di Calcolatori Elettronici64Dispositivi di I/O
nI dispositivi di I/O sono connessi al bus tramite controllernI controller gestiscono autonomamente i trasferimenti da e per la memoria: DMA (Direct Memory Access)nPossono comunicare con la CPU tramite le interruzioninIl bus è condiviso da CPU e controller, e gli accessi sono regolati da un arbitro
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#5,5,Esecuzione e InterpretazioneEsecuzione direttanLe istruzioni possono venire eseguite direttamente dai circuiti hardware nApproccio molto complesso: nRepertorio di istruzioni limitatonProgettazione dell’HW complessanEsecuzione molto efficienteInterpretazionenL’hardware può eseguire solo alcune operazioni elementari molto semplici dette microistruzioninCiascuna istruzione è scomposta in una successione di microistruzioni poi eseguite dall’hardwarenVantaggi:nRepertorio di istruzioni estesonHW più compattonFlessibilità di progettoRiccardo Torlone -Corso di Calcolatori Elettronici8
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#50,50,"Struttura fisica del PC
nLa base della struttura è costituita dalla Scheda Madre (MotherBoard) nSulla scheda madre sono la CPU, il Chipset, il bus e vari connettori per la memoria e i dispositivi di I/OnIl bus è costituito da una serie di piste sul circuito stampatonSpesso sono presenti più bus, secondo diversi standard nLe schede di I/O vengono inserite nei connettoriRiccardo Torlone -Corso di Calcolatori Elettronici65
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#51,51,"Riccardo Torlone -Corso di Calcolatori Elettronici66Una schema madre
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#52,52,"Scheda madre “moderna”
Riccardo Torlone -Corso di Calcolatori Elettronici67
"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#53,53,"Esercizio 3Si consideri una CPU con pipeline a 6 stadi che lavora a una frequenza di 400 Mhze in cui ogni stadio viene eseguito in un ciclo di clock; indicare se le seguenti affermazioni sono vere o false.nA regime e in condizioni ideali la CPU completa un'istruzione ogni 2.5 nsec.nUna istruzione richiede 10 nsecper essere eseguita.nL'ampiezza di banda della CPU è di 500 MIPS.nLa latenza della CPU è di 15 nsec.nIn linea di principio, se la frequenza del clock aumenta a 800 Mhzsi raddoppia l'ampiezza di banda.nIn linea di principio, se la frequenza del clock scende a 200 Mhzsi raddoppia la latenza.nIl tempo di esecuzione di un programma di 3 istruzioni è di 20 nsec.nIn linea di principio, togliendo uno stadio si aumenta la latenza e si diminuisce l'ampiezza di banda.
n.VERO
FALSOVEROFALSOVEROFALSOVEROVERO"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#54,54,"Esercizio 4Si consideri un programma che confronta il contenuto di una variabile X con tutti gli elementi di un vettore di interi A. Il vettore è composto da 5 elementi di 4 byte memorizzati in locazioni contigue della memoria principale mentre X è memorizzato in un’altra zona della memoria principale. L’esecuzione del programma avviene su un microprocessore che dispone di una cache con tempo di accesso di 2 nsece di una memoria con tempo di accesso di 20 nsec. Si assuma che i trasferimenti tra memoria e cache avvengano per blocchi di 16B. nIndicare la percentuale di successo nell'accesso alla cache (cache hit ratio) per la variabile XnIndicare il tempo necessario per il primo accesso alla variabile X, espresso in nanosecondi. nIndicare il tempo medio di accesso alla variabile X, espresso in nanosecondi. nIndicare il cache hit ratio complessivo (percentuale globale di successo nell’accesso alla cache) e il tempo medio di accesso alla memoria del programma;nAssumendo che il confronto di due elementi sia eseguito dal microprocessore in 1 nsec, indicare il tempo complessivo necessario all’esecuzione del programma, espresso in nanosecondi. Riccardo Torlone -Corso di Calcolatori Elettronici86"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#55,55,"Esercizio 4Si consideri un programma che confronta il contenuto di una variabile X con tutti gli elementi di un vettore di interi A. Il vettore è composto da 5 elementi di 4 byte memorizzati in locazioni contigue della memoria principale mentre X è memorizzato in un’altra zona della memoria principale. L’esecuzione del programma avviene su un microprocessore che dispone di una cache con tempo di accesso di 2 nsece di una memoria con tempo di accesso di 20 nsec. Si assuma che i trasferimenti tra memoria e cache avvengano per blocchi di 16B. nIndicare la percentuale di successo nell'accesso alla cache (cache hit ratio) per la variabile XLa variabile X viene acceduta 5 volte, la prima volta si trova in memoria principale, le altre in cache:Cache hit ratio=4/5=0,8 ®80%nIndicare il tempo necessario per il primo accesso alla variabile X, espresso in nanosecondi. Tempo di accesso alla cache + tempo di accesso alla RAM = 22nsecnIndicare il tempo medio di accesso alla variabile X, espresso in nanosecondi. Tempo medio di accesso a X=2+(20×1/5)=6nsecnIndicare il cache hit ratio complessivo (percentuale globale di successo nell’accesso alla cache) e il tempo medio di accesso alla memoria del programma;Cache hit ratio complessivo=7/10=0,7 ®70%Tempo medio di accesso mem.=2+(20×3/10)=8 nsecnAssumendo che il confronto di due elementi sia eseguito dal microprocessore in 1 nsec, indicare il tempo complessivo necessario all’esecuzione del programma, espresso in nanosecondi. Per eseguire il programma sono necessari: 10 letture di cui 3 richiedono l’accesso a memoria principale e 10 a cache (la cache è comunque sempre acceduta). Inoltre, il calcolo richiede 5 confronti.Tempo compl.=3×20nsec+10×2nsec+5×1nsec=85nsecRiccardo Torlone -Corso di Calcolatori Elettronici92"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#56,56,"Esercizio 5Illustrare la composizione e funzionamento di un'unità RAID di 200 GB (spazio utilizzabile di memoria fisica) e con blocchi (strip) di 512 KB, con riferimento: (A)ad una configurazione di livello 1 con 4 dischi, (B)ad una configurazione di livello 2,(C)ad una configurazione di livello 4 con 5 dischi e (D)ad una configurazione di livello 5 con 3 dischi.Indicare in entrambi i casi la dimensione effettiva di memoria fisica necessaria per la realizzazione (in numero di byte)."
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#57,57,Soluzione esercizio 5(A)100G200Kstrip100G100G100GTotale400GB(B)50G400Gbit50G50G50GTotale350GB50G50G50G(C)100Kstrip50G50G50GTotale250GB50G50G(D)200KstripTotale300GB100G100G100G
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#6,6,La MicroprogrammazioneL’HW può eseguire microistruzioni:nTrasferimenti tra registrinTrasferimenti da e per la memorianOperazioni della ALU su registriCiascuna istruzione viene scomposta in una sequenza di microistruzioniL’unità di controllo della CPU esegue un microprogramma per effettuare l’interpretazione delle istruzioni macchinaIl microprogramma è contenuto in una memoria ROM sul chip del processoreVantaggi:nDisegno strutturatonSemplice correggere errorinFacile aggiungere nuove istruzioniRiccardo Torlone -Corso di Calcolatori Elettronici9
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#7,7,"CISC e RISCArchitetture RISC(ReducedInstructionSet Computer):nEsecuzione direttanRepertorio ristretto (alcune decine)nIstruzioni prevalentemente su registrinUna istruzione per ciclo di macchina (del data path)Architetture CISC (ComplexInstructionSet Computer) nInterpretazione tramite microprogrammanRepertorio esteso (alcune centinaia)nIstruzioni anche su memorianMolti cicli di macchina per istruzioneEsempi:nPowerPC, SPARC, MIPS, ARM: RISCnVAX (DEC), Pentium II/III/IV/i7(Intel), AMD: CISCAll’inizio degli anni ’80 i progettisti di sistemi veloci riconsiderano l’approccio dell’esecuzione direttaRiccardo Torlone -Corso di Calcolatori Elettronici10"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#8,8,"Principi progettuali dei computer moderninFar eseguire le istruzioni macchina dall’hardwarenMassimizzare la velocità con la quale le istruzioni sono eseguite misurata in MIPS (Millionsof Instr. per Second) o XFLOPS (M/G/T floatingpointoper. per Second)nSemplificare la decodifica delle istruzioni: formati molto regolarinLimitare i riferimenti alla memoria (solo LOAD e STORE)nAmpliare il numero di registriN.B. Questi principi sono tipici della filosofia RISC ma anche le architetture CISC vi si adeguano, almeno in parteRiccardo Torlone -Corso di Calcolatori Elettronici11"
data_test\rootfolder\università\CalcolatoriElettronici2\04 Organizzazione di un Calcolatore.pdf#9,9,"Riccardo Torlone -Corso di Calcolatori Elettronici12Introduzione del parallelismo
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#0,0,Calcolatori ElettroniciParte IV: I Circuiti Digitali e le MemorieProf. Riccardo TorloneUniversità di Roma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#1,1,"LogisimUno strumento freeware per il progetto e la simulazione di circuiti digitali.
Molto utile per comprendere quello che vedremo a lezione.Verrà usato negli homework.Riccardo Torlone -Corso di Calcolatori Elettronici2
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#10,10,"Riccardo Torlone -Corso di Calcolatori Elettronici12Algebra Circuitale (Booleana)nRappresentazione algebrica di funzioni booleaneInsieme:   I= { 0,1}Operatori:  AND , ORComplementazione:  NOTNotazionenSe x e y sono due variabili booleane:nL’AND  di x e y si indica con  x · y (o xy)nL’OR  di x e y si indica con x + ynIl NOT  di x si indica con x"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#11,11,"Riccardo Torlone -Corso di Calcolatori Elettronici13Espressioni AlgebricheTeorema: ogni funzione booleana è algebrica, cioè rappresentabile con un’espressione dell’algebra§Prima Forma Canonicadi funzione a nvariabili:f = Sj=1..mPi=1..n   xij*§xij*vale  xioppure xi§f  è espressa come OR delle combinazioni per cui la funzione è vera (somma dimintermini)§in base al teorema, qualsiasi funzione booleana può essere espressa in questa forma"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#12,12,"Riccardo Torlone -Corso di Calcolatori Elettronici14Funzioni Booleane (Esempio)ESnTre variabili booleane A, B, CnFunzione di maggioranza  M: è vera solo se almeno due delle tre variabili sono vere
ABCABCABCABCM = ABC + ABC + ABC + ABC"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#13,13,"Riccardo Torlone -Corso di Calcolatori Elettronici15Circuiti Logici
nPorte Logiche: circuiti elementari che realizzano gli operatori dell’algebraQualsiasi funzione booleana può essere calcolata con un circuito realizzato con sole porteAND,OReNOT
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#14,14,"Riccardo Torlone -Corso di Calcolatori Elettronici16Realizzazione di porte logiche con circuiti elettronici
NOTNAND                     NOR
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#15,15,"Riccardo Torlone -Corso di Calcolatori Elettronici17Implementazione di Funzioni Booleane con Circuiti Logici
M = ABC + ABC + ABC + ABC"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#16,16,"Riccardo Torlone -Corso di Calcolatori Elettronici18Proprietà dell’Algebra Booleana
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#17,17,"Riccardo Torlone -Corso di Calcolatori Elettronici19Completezza delle porte NANDe NORÈ possibile simulareAND, OR eNOT, e quindi realizzare qualsiasi circuito, usando soliNAND oppure soliNOR
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#18,18,"Riccardo Torlone -Corso di Calcolatori Elettronici20Realizzazione della maggioranza con solo NAND
8"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#19,19,"Riccardo Torlone -Corso di Calcolatori Elettronici21Ottimizzazione di circuiti logici (esempio)
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#2,2,Riccardo Torlone -Corso di Calcolatori Elettronici3Astrazione di un calcolatoreMACCHINA VIRTUALE(compilazione o interpretazione)L1L0MACCHINA REALE(esecuzione diretta)Se L0 ed L1 sono troppo diversi il problema si decompone introducendo livelli intermedi
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#20,20,"Porte XOR
nCalcola la funzione OR esclusivo: dà uscita 1(vero) quando uno solo degli ingressi (ma non entrambi) vale 1nFacilmente realizzabile con porte AND,ORe NAND
Riccardo Torlone -Corso di Calcolatori Elettronici22
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#21,21,"Riccardo Torlone -Corso di Calcolatori Elettronici23Circuiti Integrati
nMolte porte realizzate sulla stessa piastrina di silicio (chip)nContenitori (schede) da 14 a 68 piedininVari livelli di integrazione:nSSI(Small Scale)         1-10 portenMSI(Medium Scale)   10-100 portenLSI(Large Scale)       102-105portenVLSI(VeryLarge Sc.)  > 105portenTempi di commutazione: 0,1-10 nsec
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#22,22,"Esempipratici
Riccardo Torlone -Corso di Calcolatori Elettronici24
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#23,23,"Circuiti integrati moderninDual InlinePackages(DIPs)nPin GridArrays (PGAs)nLand GridArrays (LGAs)
Riccardo Torlone -Corso di Calcolatori Elettronici25
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#24,24,"Riccardo Torlone -Corso di Calcolatori Elettronici26Circuiti CombinatoriCircuiti  in cui l’uscita dipende solo dagli ingressi, e non dallo stato cioè dalla storia passataES……………………………………...MULTIPLEXER2ningressi controllatiningressi dicontrollouna uscita§Gli ingressi di controllo selezionano quale degli ingressi controllati viene mandato in uscita"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#25,25,"Riccardo Torlone -Corso di Calcolatori Elettronici27Multiplexer (circuito)
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#26,26,"Realizzazione di funzioni booleane tramite multiplexer nCon un multiplexer ad n bit si può calcolare qualsiasi funzione di n variabilinGli ingressi controllati corrispondono ai mintermini nSi cablano a 0 o 1, a seconda che il mintermine compaia o meno nella forma canonica
Riccardo Torlone -Corso di Calcolatori Elettronici28ES(Funzione di maggioranza)
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#27,27,"Decodificatore
nCircuito a n ingressi e 2nuscitenUna ed una sola delle 2nuscite assume valore vero in corrispondenza della configurazione di nbit in ingressoRiccardo Torlone -Corso di Calcolatori Elettronici29
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#28,28,"Comparatore
nCompara i bit omologhi di due stringhenL'uscita vale 1 se e solo se Ai=Bi  ""inSe  Ai=Bi  allora  Ai XOR Bi = 0nIl NOR da uscita 1 solo quando tutti i suoi ingressi valgono 0Riccardo Torlone -Corso di Calcolatori Elettronici30
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#29,29,"Shifter
nIl segnale C determina il verso dello shift(sinistra/destra)Riccardo Torlone -Corso di Calcolatori Elettronici31
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#3,3,"Architettura a livelli
nAl livello icorrispondono una macchina virtuale Mied un linguaggio LinIl linguaggioLiètradotto nel linguaggio Li-1o interpretato da un programma che gira sulla macchina Mi-1Riccardo Torlone -Corso di Calcolatori Elettronici5
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#30,30,"Semiaddizionatore (Half Adder)
nCircuito a 2 ingressi e 2 uscite: somma e riporto (carry)nNon può essere usato per la somma di numerali a più bit, dove occorre sommare anche il riporto della cifra precedenteRiccardo Torlone -Corso di Calcolatori Elettronici32
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#31,31,"Addizionatore Completo (Full Adder)nCircuito a 3 ingressi e 2 uscitenRiceve il riporto dalla cifra precedente
Riccardo Torlone -Corso di Calcolatori Elettronici33
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#32,32,"Riccardo Torlone -Corso di Calcolatori Elettronici34ALU a 1 bit (bit slice)
Operazioni00: AND01: OR10: NOT11: SUM"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#33,33,"ALU ad n bitnRealizzata connettendo nALU ad 1 bit (bit slices)nINC incrementa la somma di 1 (A+1, A+B+1)nProblema: propagazione dei riportinCiascuno stadio deve attendere il riporto dal precedentenTempo di addizione lineare con n
Riccardo Torlone -Corso di Calcolatori Elettronici35
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#34,34,"Clock
nTutti i cambiamenti di stato vengono sincronizzati da un segnale (clock)nDa un clock primario ne vengono ricavati per sfasatura, sottrazione ecc.nLe transizioni di stato del circuito possono avvenire:nIn corrispondenza dei livellinIn corrispondenza dei frontiRiccardo Torlone -Corso di Calcolatori Elettronici36
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#35,35,"Riccardo Torlone -Corso di Calcolatori Elettronici37Circuiti Sequenziali
nLe uscite del circuito dipendono dagli ingressi e dalla storia passatanLa storia passata è riassunta nello stato che è codificato nelle variabili di stato booleane s1,…,srnLe variabili di stato sono memorizzate in elementi di memoria binarinCircuiti combinatori calcolano le uscite e il nuovo valore dello statos1…srSTATOi1ino1omUSCITEINGRESSIoi = fi(i1,...,in ,s1,…,sr)i=1,…,ms’i =gi(i1,...,in ,s1,…,sr)j=1,…,r"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#36,36,"Latch
nDispositivo di memoria elementarenDue stati stabili Q=0 e Q=1nS(SET): forza  Qa  1nR(RESET): forza  Qa 0nCon S=R=0 il circuito mantiene lo statonIl circuito commuta sui livelli cioè quando So Rvalgono 1 nSed Rnon devono mai andare insieme ad 1Riccardo Torlone -Corso di Calcolatori Elettronici38
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#37,37,"Latch con Clock, Latch D
nRed Svengono trasferiti sugli ingressi del latch solo quando il clock è ad 1nQuando il clock è a 0 vengono ignorati
nIl latchD (Delay) quando il clock va ad 1 registra nello stato Qil valore dell’ingresso  DRiccardo Torlone -Corso di Calcolatori Elettronici39
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#38,38,"Riccardo Torlone -Corso di Calcolatori Elettronici40Flip-flop
Il flip-flope’ una variante del latch checommuta sui fronti del clockGeneratore diimpulsiPossibile realizzazione di un flip-flop D:"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#39,39,"Riccardo Torlone -Corso di Calcolatori Elettronici41Latch e Flip-FlopI Latchcommutano sui livelli del clock ( a) alto, b) basso)I Flip-Flopcommutano sui fronti del clock:a)  Commuta sul fronte di salitab)  Commuta sul fronte di discesa
a)b)
a)b)"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#4,4,"Riccardo Torlone -Corso di Calcolatori Elettronici6Perché la stratificazione?nM0è facilmente realizzabile in hardware, ma difficile da programmarenMnè facile da programmare ma impossibile da realizzabile in hardwarenImplementazione progressiva e modularenTrasparenza per l’utente e le applicazioninIl linguaggio Lnnon dipende dalla piattaforma (hardware) M0:nDiversi linguaggi disponibili sulla stessa piattaformanLo stesso linguaggio disponibile su diverse piattaforme"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#40,40,"Registri
nI Flip-Flop sono gli elementi base di memorizzazione nel computernMolti Flip-Flop possono essere messi su un unico chipnOccorrono in genere da 6 a 10 transistor per ogni Flip-Flop Riccardo Torlone -Corso di Calcolatori Elettronici42
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#41,41,"Riccardo Torlone -Corso di Calcolatori Elettronici43Organizzazione della Memoria
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#42,42,"Dispositivi a 3 stati
nIn base ad un segnale di controllo C si comporta:nC=1: come circuito chiuso nC=0: come circuito apertonTempo di commutazione: pochi nsecnConsente di usare gli stessi piedini sia per la lettura che per scritturanUsato anche per la connessione ai bus e a qualsiasi linea bidirezionaleRiccardo Torlone -Corso di Calcolatori Elettronici44
10i
0IiOUTIN"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#43,43,"Chip di Memoria
nChip da n´m  bit complessivi (nparole da m bit)nm linee dati bidirezionalinlog2n  linee di indirizzonSegnali di controllo:nCS (Chip Select)nOE (Output Enable)nWE (Write Enable)nProblema: numero limitato di piedini del contenitoreRiccardo Torlone -Corso di Calcolatori Elettronici45……………….….….log2n linee indirizzom linee dati in/out CSOEWECHIP DI MEMORIAn ´m"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#44,44,"Riccardo Torlone -Corso di Calcolatori Elettronici46Matrice di selezione
nSi risparmia nella complessità della logica di decodificanUn decoder n®2n richiede 2nporte ANDnRAS (RowAddressStrobe), CAS (ColumnAddressStrobe)ESn4M parole da 1 bit ®22 linee di indirizzo n1 decoder a 22 ®4M  porte ANDn2 decoder a 11 ®2×211= 4Kporte ANDDECODERn/2 ®2n/2DECODERn/2 ®2n/2n/2n/2n
1 BitRASCAS2nparole di 1 bit"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#45,45,"Riccardo Torlone -Corso di Calcolatori Elettronici47Segnali asseriti e negatiIn alcuni casi (a seconda delle scelte di progetto) un segnale provoca l’azione corrispondente quando la sua tensione è alta, in altri quando è bassaPer evitare confusione si parla di:nSegnale asserito: quando assume il valore che provoca l’azionenSegnale negato: altrimentiSi adotta la seguente notazione:nS: segnale che è asserito altonS: segnale che è asserito bassoUlteriore notazione (usata da Intel):nS: segnale che è asserito altonS#: segnale che è asserito basson(adatta al set di caratteri UNICODE)"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#46,46,"Riccardo Torlone -Corso di Calcolatori Elettronici48Chip di Memoria (Esempi)
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#47,47,"Tassonomia delle RAM e ROMnRAM  (Random Access Memory) nROM  (Read OnlyMemory)nSRAM (StaticRAM): a Flip-Flop, molto veloce (~5nsec)nDRAM (DynamicRAM): basata su capacità parassite; richiede refresh, alta densità, basso costo (~70 nsec)nFPM: selezione a matricenEDO: (Extended Data Output) lettura in pipeline, più bandanSDRAM (SynchronousDRAM)nSincrona, prestazioni migliorinDDR (Double Data Rate)nLettura/scrittura in pipelinenDDR2-3-4-5: 100Mhz/1.6Ghz, fino a 25.6 GBsnPROM (ProgrammableROM)nEPROM (ErasablePROM) raggi UVnEEPROM: cancellabile elettricamentenFlash Memory: tipo di EEPROM, ciclo 50 nsec, max100.000 riscrittureRiccardo Torlone -Corso di Calcolatori Elettronici53"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#48,48,"Riccardo Torlone -Corso di Calcolatori Elettronici54Tipi di RAM e di ROM e loro impieghi
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#49,49,"Field ProgrammableGate Array (FPGA)nConsentono di realizzare circuiti logici arbitrarinDue componenti replicatinLookUpTables(LUT): piccola memoria che si usa per implementare una qualunque funzione booleananConnessioni programmabili
Riccardo Torlone -Corso di Calcolatori Elettronici55
f1f2f3f40000000100100011"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#5,5,"Tipica struttura a livelli
nIl livello 2 è il più basso al quale un utente può programmare la macchina (confine tra software e hardware)nNormalmente si programma a livello 5Riccardo Torlone -Corso di Calcolatori Elettronici7
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#50,50,Riccardo Torlone -Corso di Calcolatori Elettronici56EsercizioSi vuole realizzare un circuito combinatorio che effettui un controllo di paritàsu tre linee digitali:nrealizzare il circuito mediante porte logiche;nindicare come bisogna trasformare il circuito ottenuto per ottenere un circuito equivalente contenente solo porte NAND;nrealizzare il circuito con un singolo multiplexer.
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#51,51,Riccardo Torlone -Corso di Calcolatori Elettronici57SoluzioneABCOUT00010010010001111000101111011110P = ABC + ABC + ABC + ABC
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#52,52,"Riccardo Torlone -Corso di Calcolatori Elettronici58Soluzione con porte logiche qualsiasi
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#53,53,"Riccardo Torlone -Corso di Calcolatori Elettronici59Soluzione con solo Porte NAND
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#54,54,"Riccardo Torlone -Corso di Calcolatori Elettronici60Soluzione con multiplexer
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#55,55,"Riccardo Torlone -Corso di Calcolatori Elettronici61EsercizioSi vuole realizzare un circuito combinatorio che ha in ingresso tre segnali A, B e C e che si comporta come segue: a)quando C=0 fa un test di uguaglianza ovvero restituisce 1 se A e B sono uguali e 0 altrimenti,  b)quando C=1 fa un test di disuguaglianza ovvero restituisce 1 se A e B sono diversi e 0 altrimenti.nrealizzare il circuito mediante porte logiche qualunque;nrealizzare il circuito con un multiplexer;nrealizzare il circuito utilizzando solo porte NAND e XOR."
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#56,56,"EsercizioSi consideri il seguente circuito combinatorio:
nDeterminare la tabella di verità corrispondente al circuito.nIndicare la funzione booleana in prima forma canonica corrispondente alla tabella di verità ottenutanSemplificare, se possibile, l'espressione booleana rappresentata dalla prima forma canonica ottenuta e disegnare il circuito corrispondenteRiccardo Torlone -Corso di Calcolatori Elettronici62
DEFG"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#57,57,"Riccardo Torlone -Corso di Calcolatori Elettronici63EsercizioFornire lo schema di uno shiftera 4 ingressi e 4 uscite che, sulla base di un segnale di controllo C: a)sposta l'ingresso di un bit a sinistra riempiendo il bit meno significativo con 0 se C=0 e b)sposta l'ingresso di un bit a destra riempiendo il bit piusignificativo con 1 se C=1. Illustrare sinteticamente il funzionamento del circuito."
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#58,58,"Riccardo Torlone -Corso di Calcolatori Elettronici64Possibile soluzione
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#59,59,"Riccardo Torlone -Corso di Calcolatori Elettronici65EsercizioFornire lo schema di uno shiftera 2 ingressi e 2 uscite che, sulla base di un segnale di controllo C: a)sposta l'ingresso di un bit a sinistra riempiendo il bit meno significativo con 0 se C=0 e b)sposta l'ingresso di un bit a destra riempiendo il bit più significativo con il bit più significativo dell’ingresso se C=1. Illustrare sinteticamente il funzionamento del circuito."
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#6,6,"Riccardo Torlone -Corso di Calcolatori Elettronici8Semplici elementi alla base di sistemi complessi …
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#60,60,"Riccardo Torlone -Corso di Calcolatori Elettronici66EsercizioFornire lo schema di un sottrattore a 4 bit per notazione in complemento a 2 realizzato con sommatori completi.nIllustrarne concisamente il funzionamento,nspecificare il valore di uscita di ciascuna componente quando in un ingresso (minuendo) c‘è il numerale 0011 e nell'altro (sottraendo) il numerale 0100."
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#61,61,"Riccardo Torlone -Corso di Calcolatori Elettronici67Una possibile soluzione
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#62,62,"EsercizioFornire lo schema di un circuito combinatorio a 4 bit in grado di calcolare il valore assoluto di un numero, secondo il sistema di rappresentazione in complemento a due. Tale circuito, ricevuto in ingresso un numerale X a 4 bit, deve restituire in uscita: nlo stesso numero in ingresso, se X rappresenta un numero positivo, e nil numero in ingresso con il segno invertito, se X rappresenta un numero negativo (per esempio, se X = 3 allora l’uscita vale 3, se X = −1 allora l’uscita vale 1)E’ possibile utilizzare componenti di base quali half-addere full-adder. Illustrare concisamente il funzionamento del circuito e specificare il valore di uscita di ciascuna componente quando l’ingresso sitrovaa 1011.
Riccardo Torlone -Corso di Calcolatori Elettronici68"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#63,63,"Possibile soluzione
Riccardo Torlone -Corso di Calcolatori Elettronici69
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#64,64,"EsercizioSi vuole progettare una piccola ALU avente due operandi in ingresso da 4 bit (A e B). Tale ALU deve essere in grado di svolgere, in base al valore di due segnali di controllo, le seguenti operazioni:nla trasmissione di A inalterato (segnali di controllo: 00), nl’inversione bit a bit di B (segnali di controllo: 01)nla somma di A e B (segnali di controllo: 10) e nla differenza di A e B (segnali di controllo: 11)Definire lo schema di una ALU di questo tipo e illustrare sinteticamente il suo funzionamento. E’ possibile utilizzare componenti predefiniti quali decodificatori e full adder.
Riccardo Torlone -Corso di Calcolatori Elettronici72"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#65,65,"Possibile soluzione a 1 bit
Riccardo Torlone -Corso di Calcolatori Elettronici73
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#66,66,"ALU a 4 bit ottenuta componendo quella a 1 bit
Riccardo Torlone -Corso di Calcolatori Elettronici74
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#67,67,"Riccardo Torlone -Corso di Calcolatori Elettronici75EsercizioFornire lo schema e illustrare sinteticamente il funzionamento di una piccola memoria di 4 locazioni da 1 bit ciascuna, realizzata con flip-flop e porte logiche. Tale memoria deve avere: n2 linee per la selezione della locazione, n1 linea condivisa per gli ingressi e le uscite, nuna linea di chip select,nuna linea per indicare se si vuole compiere una operazione di lettura o scrittura. Indicare poi come è possibile utilizzare la memoria concepita per costruire una memoria di 8 locazioni da 4 bit."
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#68,68,"Riccardo Torlone -Corso di Calcolatori Elettronici76Una possibile soluzione
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#69,69,"EsercizioFornire lo schema di un circuito sequenziale che realizza un registro a 4 bit complementabile, utilizzando half-adder, full-addere flip-flop (come scatole chiuse). Tale circuito deve avere un segnale di set (S), un segnale di controllo (C), 4 linee di ingresso (X3X2X1X0) e 4 linee di uscita (Y3Y2Y1Y0). nQuando S=1 e C=0 il registro memorizza i segnali presenti sugli ingressi. nQuando C=1 e S=0 gli ingressi vengono ignorati e il contenuto del registro viene complementatoa due (es. da 0101 si passa a 1011). nIn ogni istante il contenuto del registro può essere letto sulle uscite. Illustrare concisamente il funzionamento e specificare il valore di uscita di ciascuna componente del circuito quando C=1, S=0 e il registro memorizza 0111.
Riccardo Torlone -Corso di Calcolatori Elettronici79"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#7,7,"Circuiti DigitalinCircuiti elettronici i cui ingressi e le cui uscite assumono solo due livellinAl circuito sono associate le funzioni che calcolano le uscite a partire dagli ingressio1= f1( i1,….,in)...om= fm( i1,….,in)
Riccardo Torlone -Corso di Calcolatori Elettronici9CIRCUITODIGITALEi1ino1omUSCITEINGRESSI"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#70,70,"Possibile soluzione
Riccardo Torlone -Corso di Calcolatori Elettronici80
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#71,71,"Altra soluzione che compone un modulo da 1 bit
Riccardo Torlone -Corso di Calcolatori Elettronici81
"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#8,8,"Funzioni Logiche (Booleane)ny = f(x1,…,xn)     y, x1,…, xnÎ{ 0,1}{ 0,1}n®{ 0,1}nVariabili che possono assumere due soli valori:{ 0, 1}                  { F, T }nDefinizione tramite tavola di verità:x1x2……xn-1xnf00……00000……011..................         11……110n2ncombinazioni di ingresson22funzioni distinte di nvariabiliRiccardo Torlone-Corso di Calcolatori Elettronici10fFALSOVEROFALSETRUE
n"
data_test\rootfolder\università\CalcolatoriElettronici2\05 Circuiti Digitali e Memorie.pdf#9,9,"Riccardo Torlone -Corso di Calcolatori Elettronici11Funzioni Booleane (Esempi)nCon n=1si hanno 4funzioni:x1f0f1f2f30        0     0    1     11        0     1    0     1nLa funzione f2è detta  NOTnCon n=2si hanno 16funzioni, tra cui:x1x2f0f1f2f3f4f5f6f70    0     0     0    0    0    0    0    0     00    1     0     0    0    0    1    1    1     11    0     0     0    1    1    0    0    1     11    1     0     1    0    1    0    1    0     1nLa funzione f1è nota come ANDnLa funzione f7è nota come OR"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#0,0,CalcolatoriElettroniciParte V: BusProf. Riccardo TorloneUniversita di Roma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#1,1,"Architettura a più  Bus
nDiversi bus, interni ed esterni al chipnSoddisfano diverse esigenze:nVelocità di trasferimentonNumero di lineenCompatibilità all’indietronNegli attuali PC almeno due bus esterniRiccardo Torlone -Corso di Calcolatori Elettronici2
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#10,10,"Arbitraggio Decentralizzato
nQuando nessun dispositivo vuole il Bus, la linea di arbitraggio è asserita con propagazione a tutti i dispositivinQuando un dispositivo vuole il Bus:ninvia una richiesta di busnverifica se il bus è libero nse In è asserito diventa master, nega Out e asserisce Busynse In non è asserito non diventa master e nega Out nNon necessita di arbitro, è più semplice e più veloce Riccardo Torlone -Corso di Calcolatori Elettronici11
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#11,11,"Esercizio su BUSCon riferimento al funzionamento dei bus di un calcolatore:ntracciare e illustrare il diagramma di temporizzazione di un bus sincrono a 40 Mhzcon linee separate per dati e indirizzie segnali di MREQ, RD e WAIT, per una lettura da una memoria con un tempo di risposta di 40 nsecdal momento in cui gli indirizzi sono disponibilintracciare e illustrare il diagramma di temporizzazione di un bus asincrono con linee separate per dati e indirizzi per una scrittura in una memoria con un tempo di risposta di 50 nsec.Si assuma di lavorare in condizioni ideali (nessun ritardo nell'asserimento dei segnali)"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#12,12,"Soluzione esercizio su BUS sincrono
ADDRDATAMREQRDWAITT125 nsecT2T340 nsecacquisizione dato sul master"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#13,13,"Soluzione esercizio su BUS asincrono50 nsecADDRESSMREQRDMSYNDATASSYNIndirizzo
Dati"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#14,14,"Esercizio su BUSCon riferimento al funzionamento dei bus di un calcolatore:ntracciare e illustrare il diagramma di temporizzazione di un bus sincrono con linee separate per dati e indirizzi che lavora alla frequenza di 50 Mhz, per una lettura da una dispositivo I/O con un tempo di risposta di 100 nsecdal momento in cui gli indirizzi sono disponibili;ntracciare e illustrare il diagramma di temporizzazione di un bus asincrono con linee separate per dati e indirizzi per una scrittura in una memoria con un tempo di risposta di 30 nsecdal momento in cui il segnale di master syncronizationè stato asserito.
Riccardo Torlone -Corso di Calcolatori Elettronici15"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#15,15,"Esercizio sull’arbitraggio di busRiferendosi agli schemi di arbitraggio dei bus discussi a lezione, indicare le affermazioni esatte tra le seguenti.nNell'arbitraggio decentralizzato non è necessaria la linea che segnala l'occupazione del bus.nNell'arbitraggio centralizzato con livelli di priorità la posizione del dispositivo non influisce sulla concessione del grant.nNell'arbitraggio centralizzato non è possibile che due dispositivi si prenotino contemporaneamente asserendo la linea di request.nNell'arbitraggio decentralizzato ai fini delle attese la posizione fisica dei dispositivi è comunque ininfluente.nNell'arbitraggio centralizzato a più livelli di priorità un dispositivo può dover attendere un tempo indefinitamente lungo.nPer motivi di imparzialità l'arbitro è sempre un dispositivo diverso ed esterno al microprocessore.nLa priorità dei dispositivi di I/O è generalmente più alta della CPU.FALSO
VEROFALSOFALSOFALSOVEROFALSO"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#16,16,"Bus realinRequisiti:nVideo a 1024×768 con 3B per pixel (truecolor)n1 frame: 2.25 MBn30 frame al secondo: 67.5 MB/secnHD →RAM →VRAM: 135 MB/secnVideo a 1920×1080 con 3B per pixel n1 frame: ~5.2 MBn30 frame al secondo: 155 MB/secnHD →RAM →VRAM: 310 MB/secnBus legacy:nISA: 8.33Mhz, 2B per ciclo, 16.7MB/secnEISA: 8.33Mhz, 4B per ciclo, 33.3MB/secnBus PCI (1990, Intel): fino a 528 MB/secnBus AGP (fine anni ’90): fino a 2.1 GB/secnBus PCIe(2004): 20GB/sec e oltre nBus USB (1995): 10Gb/sec e oltre Riccardo Torlone -Corso di Calcolatori Elettronici24"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#17,17,"Riccardo Torlone -Corso di Calcolatori Elettronici26
Schede e slot PCI e AGP
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#18,18,"Bus PCI: Transazioni
nInT1 il master invial’indirizzo su AD e il comando su C/BE#nPoi asserisce FRAME# e poi IRDY#nIn T2  C/BE# specifica quali byte leggerenIn T3 lo slave asserisce DEVSEL# e quando i dati sono su AD asserisce TRDY#nTra due transazioni c’è un ciclo di idlenLa transazione di scrittura è più compattaRiccardo Torlone -Corso di Calcolatori Elettronici33"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#19,19,"Esercizio su BUSCon riferimento al funzionamento dei bus di un calcolatore:ntracciare e illustrare il diagramma di temporizzazione di un bus sincrono a 40 Mhzcon linee condiviseper dati e indirizzie segnali di MREQ, RD e WAIT, per una lettura da una memoria con un tempo di risposta di 40 nsecdal momento in cui gli indirizzi sono disponibilintracciare e illustrare il diagramma di temporizzazione di un di bus asincrono con linee separate per dati e indirizzi e segnali di MREQ, RD, MSYN e SSYN, per una lettura da una memoria con un tempo di risposta di 50 nsecdal momento in cui gli indirizzi sono disponibiliSi assuma in entrambi i casi di lavorare in condizioni ideali (nessun ritardo nell'asserimento dei segnali)"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#2,2,"Comunicazione sul Bus
nLa comunicazione sul bus è regolata da un protocollo di busnIn ciascun ciclo comunicano due soli dispositivi il master e lo slavenLo stesso dispositivo può avere ruoli diversi a seconda dei casinI dispositivi sono connessi al bus tramite un bus transceivernLa connessione al bus o avviene tramite dispositivi a tre stati oppure è di tipo open collectorRiccardo Torlone-Corso di Calcolatori Elettronici3
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#20,20,"Soluzione esercizio su BUS sincrono
MREQADRDT1T2T3T4T5TurnaroundAddressDataWAIT(25 nsec)40 nsec"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#21,21,"Soluzione esercizio su BUS asincrono50 nsecADDRESSMREQRDMSYNDATASSYNIndirizzo
Dati"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#22,22,"PCI expressLinea di tendenza nei bus:nbypassare il bus PCI nel caso di periferiche velocincomunicazione seriale!nusare slot più piccoleSoluzione: PCI expressnConnessione punto-a-punto
Riccardo Torlone -Corso di Calcolatori Elettronici37
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#23,23,"Caratteristiche PCI expressnTrasmissione serialenTrasferimenti come in una rete di computer:ndati in pacchetti (header+ payload+ CRC)nmaggiore lunghezza dei cavinplug-and-playnBanda: attualmente >120GB/sec (ver. 6.0, x16) nControllo del flusso in base alle dimensioni dei buffern4 spazi di indirizzamento (ovvero ti tipologie ci comunicazione):nMemorianI/OnConfigurazionenMessaggiRiccardo Torlone -Corso di Calcolatori Elettronici38
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#24,24,"PCI Express Protocol StacknTrasmissione basata su protocollo multi-layerlungo coppie di corsie (lane)nCodifica: 8b/10b nUn meccanismo di acknowledgmentgarantisce maggiore affidabilitànIl software layergarantisce: nla gestione dei pacchettinla compatibilità con il passato
Riccardo Torlone -Corso di Calcolatori Elettronici39
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#25,25,"Bus USB (Universal Serial Bus)nBus economico concordato da varie aziende per la gestione di dispositivi di I/O a bassa velocità (~ 1995)nObiettivi:1) Evitare switch, jumpers2) Installazione di tipo esterno3) Cavo di connessione unificato4) Alimentazione fornita dal cavo5) Fino a 127 dispositivi collegabili6) Supporto di dispositivi real-time7) Installazione a PC acceso8) Rebootnon necessario 9) Bus e dispositivi economicinTutti gli obiettivi sono di fatto rispettatiRiccardo Torlone -Corso di Calcolatori Elettronici40"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#26,26,"Riccardo Torlone -Corso di Calcolatori Elettronici41USB (Universal Serial Bus): Specifiche di basenBus economico concordato da varie aziende per la gestione di dispositivi di I/O a bassa velocità (~ 1995)nDifferenti connettori (A/B/C)nBanda complessivanUSB 1.X: 1.5 –12 Mb/secnUSB 2.0: 480 Mb/secnUSB 3.X: 5 Gb/sec –20 Gb/sec (<3GB/s)nUSB4: 40Gb/secnUSB42.0: 120Gb/secn
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#27,27,"Riccardo Torlone -Corso di Calcolatori Elettronici42USB: comunicazionesubus
nRoot hubdi connessione a bus internonConnessione con dispositivi e con altri hubnStruttura complessiva ad alberonCavo a 4 fili: +5V, GND, 2 di segnalenAlla connessione di un dispositivo:nInterrupt: intervento del SOnRichiesta di bandanAssegnazione di indirizzonLogicamente: connessione dedicata tra roothube ciascun devicenCompetitor: nFireWire IEEE 1394 serial bus"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#28,28,"USB: Struttura dei Frame
nFrame emessi ogni 1.00±0.05 msecnIdleframe se non c’è comunicazionenContenuto del frame:nSOF: Start of FramenIN / OUT: richiesta in lettura/scritturanDATA: payloadfino a 64 byte più controllo e codice di errorenACK / NACK: acknowledgeo errorenPolling usato invece delle interruzioni  Riccardo Torlone -Corso di Calcolatori Elettronici43
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#3,3,"“Larghezza”del Bus
nLarghezza = numero di lineenLinee indirizzo: dimensione dello spazio (di memoria) indirizzabile, 2nlocazioni con n bit di indirizzonLinee + velocità di trasmissione: banda di trasferimentonCondivisione di più segnali sulla stessa lineaper diminuireicostinProblema: al crescere della velocità del bus aumenta il bus skew(differenza nella velocità di propagazione dei segnali su linee diverse)Riccardo Torlone -Corso di Calcolatori Elettronici4
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#4,4,"Riccardo Torlone -Corso di Calcolatori Elettronici5Segnali asseriti e negatiIn alcuni casi (a seconda delle scelte di progetto) un segnale provoca l’azione corrispondente quando la sua  tensione  è alta(1), in altri quando è bassa(0).Per evitare confusione si parla di:nSegnale asserito: quando assume il valore (alto o basso) che provoca l’azionenSegnale negato: altrimentiSi adotta la seguente notazione:nS: segnale che è asserito altonS: segnale che è asserito bassoUlteriore notazione (usata da Intel):nS: segnale che è asserito altonS#: segnale che è asserito basson(adatta al set di caratteri ASCII)"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#5,5,"Riccardo Torlone -Corso di Calcolatori Elettronici6
Bus Sincroni: ciclo di letturaT=10nsec
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#6,6,"Bus Sincrono: TemporizzazioneESFrequenza 100 MHz, periodo 10 nsec.nprimo vincolo: tempoa disposizione della memoria fra:nla comparsa dell’indirizzo sul Busnla disponibilità dei dati sul Bust1= 2.5´T –TAD–TDS= 25–4 –2 = 19 nsec(unamemoria da 10 nsecce la fa di sicuro)nsecondo vincolo: tempoa disposizione della memoria fra:nl’asserzione di MREQ e RDnla disponibilità dei dati sul Bust2= 2 ´T –TM–TDS= 20–3 –2 = 15 nsecSe ilchip di memorianon soddisfaquestirequisitimantiene asserito il segnale di WAIT per introdurre stati di wait, cioè cicli di bus addizionali.Riccardo Torlone -Corso di Calcolatori Elettronici7"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#7,7,"Bus Asincrono: ciclo di lettura
nAccoppiamento di dispositivi con velocità diversenGli eventi avvengono in  risposta ad altri eventi nFullhandshake:nMSYN asseritonSSYN asserito in risposta a MSYN quando il dato è prontonMSYN negato in risposta a SSYNnSSYN negato in risposta alla negazione di MSYNRiccardo Torlone -Corso di Calcolatori Elettronici8
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#8,8,"Arbitraggio del Bus
nPermette di decidere quale dispositivo sarà il prossimo Bus Master risolvendo eventuali conflittinSpesso l’arbitro è nel chip del microprocessorenLinea di richiesta condivisanIl Bus grantè propagato dall’arbitro prima dell’inizio del ciclonViene intercettato dal futuro masternNB:Favoriti i dispositivi situati vicino all’arbitroRiccardo Torlone -Corso di Calcolatori Elettronici9
"
data_test\rootfolder\università\CalcolatoriElettronici2\06 Bus.pdf#9,9,"Livelli Multipli di priorità
nDiverse linee di richiesta associate a diversi livelli di priorità nIn caso di conflitto favorite le catene a priorità più altanAll’interno di ciascuna catena vale la posizionenIn genere se c’è un solo bus con anche la memoria,la CPU ha priorità più bassa dei dispositivi di I/O (e.g. dischi) Riccardo Torlone -Corso di Calcolatori Elettronici10
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#0,0,CalcolatoriElettroniciParte VI: Microarchitetturadi una CPUProf. Riccardo TorloneUniversita di Roma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#1,1,"Riccardo Torlone -Corso di Calcolatori Elettronici2L’approccio di San Clemente..
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#10,10,"Funzioni della ALU
nENA e ENB abilitano o inibiscono gli ingressi della ALU nINVA e INC permettono di fare il C2 di A, utile per le sottrazioninPossibile incrementare sia A che B e generare le costanti 0,1 e -1Riccardo Torlone -Corso di Calcolatori Elettronici12
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#11,11,"Riccardo Torlone -Corso di Calcolatori Elettronici13Il Cammino dei Dati nella JVM
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#12,12,"Riccardo Torlone -Corso di Calcolatori Elettronici14Temporizzazione del ciclo base
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#13,13,"Temporizzazione del CicloIn ciascun ciclo di clock viene eseguita una microistruzione, cioè:1)Caricamento di un registro sul bus B2)Assestamento di ALU e shifter3)Caricamento di registri dal bus CTemporizzazione:nFronte di discesa: inizio del ciclonDw: tempo assestamento segnali di controllonDx: tempo propagazione lungo bus BnDy: tempo assestamento ALU e shifternDz: tempo propagazione lungo bus CnFronte di salita: caricamento registri dal bus CI tempi Dw, Dx, Dy, Dz, possono essere pensati come sottocicli(impliciti)Riccardo Torlone -Corso di Calcolatori Elettronici15"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#14,14,Riccardo Torlone -Corso di Calcolatori Elettronici16Accesso alla MemoriaAccesso parallelo a due memorie:nMemoria Dati: 32 bit indirizzabili a word  (in lettura e scrittura)nMemoria Istruzioni: 8 bit indirizzabili a byte (solo in lettura)Registri coinvolti:nMAR (Memory Address Register): contiene l’indirizzo della word datinMDR (Memory Data Register): contiene la word datinPC (Program Counter): contiene l’indirizzo del byte di codicenMBR (Memory Buffer Register): riceve il byte di codice (sola lettura)Caricamento di B da parte di MBR:nEstensione a 32 bit con tutti 0nEstensione del bit più significativo (sign extension)
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#15,15,"Riccardo Torlone -Corso di Calcolatori Elettronici17Il Cammino dei Dati nella JVM
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#16,16,"Riccardo Torlone -Corso di Calcolatori Elettronici18Struttura delle µ-istruzioniUna µ-istruzione da 36 bit deve contenere:nTutti i segnali di controllo da inviare al data pathdurante il ciclonLe informazioni per la scelta della µ-istruzione successivaSegnali di controllo:n9  Selezione registri sul bus Cn9  Selezione registro sul bus Bn8  Funzioni ALU e shiftern2  Lettura e scrittura dati (MAR/MDR)n1  Lettura istruzioni (PC/MBR)Selezione µ-istruzione successiva:n9  Indirizzo µ-istruzione (su 512)n3  Modalità di sceltaDato che si invia su B solo un registro per volta, si codificano 9 segnali con 4"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#17,17,"Riccardo Torlone -Corso di Calcolatori Elettronici19
Formato delle µ-istruzioni
§Addr: Indirizzo prossima µ-istruzione§JAM: Scelta prossima µ-istruzione§ALU: Comandi ALU e shifter§C: Registri da caricare da C§Mem: Controllo memoria§B: Registro da inviare su B"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#18,18,"Riccardo Torlone -Corso di Calcolatori Elettronici20La Sezione di Controllo
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#19,19,"Riccardo Torlone -Corso di Calcolatori Elettronici21Temporizzazione del ciclo base
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#2,2,"Il livello della microarchitettura
nAl livello della microarchitettura studiamo come la CPU “implementa” le istruzioni macchina mediante i dispositivi digitali (l’hardware) a sua disposizionenLa descrizione considera i componenti di base della CPU (registri, ALU, ecc.) e il flusso dei dati tra di essi trascurandone i dettagli realizzativiRiccardo Torlone -Corso di Calcolatori Elettronici3
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#20,20,"La Sezione di Controllo (2)nControl Store: è una ROM 512´36 bit che contiene le µ-istruzioninMPC (Micro Program Counter): contiene l’indirizzo della prossima µ-istruzionenMIR (MicroInstructionRegister): contiene la µ-istruzione correntenIl contenuto di MPC diviene stabile sul livello alto del clocknLa microistruzione viene caricata in MIR sul fronte di discesa dell’impulso di clocknTemporizzazione della memoria:nInizio ciclo di memoria subito dopo il caricamento di MAR e di PCnCiclo di memoria durante il successivo ciclo di clocknDati disponibili in MDR e MBR all’inizio del ciclo ancora successivo
Riccardo Torlone -Corso di Calcolatori Elettronici22"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#21,21,"Riccardo Torlone -Corso di Calcolatori Elettronici23Scelta della µ-istruzionenCiascuna µ-istruzione indica sempre l’indirizzo della successiva (Addr)nNotare: il default non è un esecuzione sequenzialenIl bit più alto di Addr(Addr[8])è dato da:n(JAMZ AND Z) OR (JAMN AND N) OR Addr[8]nPossibile realizzare salti condizionatiESnAddr = 0 1001 0010 (0x92)nJAM [JAMPC,JAMN,JAMZ] = 001nse Z=0 allora Addr= 0 1001 0010(0x92)nse Z=1 allora Addr = 1 1001 0010(0x192)nSe JMPC = 1 allora gli 8 bit bassi di Addr (tipicamente a 0) vanno in OR con il contenuto di MBR nPossibile realizzare salti in tutto il Control Store"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#22,22,"Riccardo Torlone -Corso di Calcolatori Elettronici24Salti condizionatiEsempio di salto condizionato basato su Z
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#23,23,"Come migliorare le prestazioniMigliorare le prestazioni significa massimizzare il rapporto: VelocitàPrezzoDa un punto di vista progettuale esistono tre approcci:nRiduzione del numero di cicli necessari per eseguire una istruzione (introducendo hardware “dedicato”);nAumento della frequenza del clock (semplificando l’organizzazione);nIntroduzione del parallelismo (sovrapponendo l’esecuzione delle istruzioni).
Riccardo Torlone -Corso di Calcolatori Elettronici25"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#24,24,"Riccardo Torlone -Corso di Calcolatori Elettronici26Introduzione di componenti “dedicate”
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#25,25,"Riccardo Torlone -Corso di Calcolatori Elettronici27Il Cammino dei Dati nella JVM base
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#26,26,"Riccardo Torlone -Corso di Calcolatori Elettronici28Aumento del numero di Bus
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#27,27,"Instruction Fetch Unit
nIl carico della ALU può essere alleviato introducendo una unità indipendente che carica le istruzioni da eseguirenUna possibile IFU incrementa autonomamente il PC e anticipa il caricamento delle istruzioniRiccardo Torlone -Corso di Calcolatori Elettronici29
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#28,28,"Riccardo Torlone -Corso di Calcolatori Elettronici30Partizionamento del data-path
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#29,29,"Riccardo Torlone -Corso di Calcolatori Elettronici31Introduzione di pipeline
Ildata pathrichiede più cicli di clock ma ad una frequenza maggiore!"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#3,3,"Microarchitettura generica e data path
nLa microarchitettura della CPU è tipicamente composta da alcuni registri, una ALU, dei bus interni e alcune linee “di controllo”nLe istruzioni macchina comandano il funzionamento della CPU e il percorso dei dati (data path)Riccardo Torlone -Corso di Calcolatori Elettronici4
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#30,30,"Memorie Cache
nScopo della cache: disaccoppiare le velocità di CPU e RAMnLocalità spaziale: alta probabilità di accedere in tempi successivi a indirizzi molto vicininLocalità temporale: alta probabilità di accedere più volte agli stessi indirizzi in tempi molto vicini nGerarchie di cache: a 2 o 3 livellinCache inclusive: ciascuna contiene quella del livello superioreRiccardo Torlone -Corso di Calcolatori Elettronici34
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#31,31,"Ci accorgiamo della presenza della cache?Matrice 30.000x30.000, Intel Core i7 @ 3.6 GHz, 16GB RAM
Riccardo Torlone -Corso di Calcolatori Elettronici35intsum1(int** m, intn) {inti, j, sum = 0;for(i=0; i<n; i++)for(j=0; j<n; j++)sum += m[i][j];returnsum;}intsum1(int** m, intn) {inti, j, sum = 0;for(i=0; i<n; i++)for(j=0; j<n; j++)sum += m[j][i];returnsum;}18,63 secondi(circa 10 volte più lento)1,84 secondi"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#32,32,"Organizzazione della Memoria in presenza di cachenLo spazio di memoria è organizzato in blocchi (da 4 a 64 byte), chiamati anche linee di cachenCiascuna linea contiene più wordnCiascuna word contiene più bytenLe cache sono organizzate in righe (o slot): ciascuna contiene una linea di cache, cioè un blocco di memorianTutti i trasferimenti avvengono a livello di blocconQuando una word non viene trovata in cache, si trasferisce l’intera linea dalla memoria, o dalla cache di livello più basso
Riccardo Torlone -Corso di Calcolatori Elettronici36"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#33,33,"Organizzazione della Memoria(esempio)
nIndirizzi a 32 bit (spazio di indirizzamento di 232byte)nLinee di cache (blocchi) di 32 bytenWord di 4 bytenStruttura dell’indirizzo:nI 27 bit più significativi rappresentano il numero di blocconI successivi 3 bit il numero della word all’interno del blocconGli ultimi due bit il numero del byte all’interno della wordRiccardo Torlone -Corso di Calcolatori Elettronici37BLOCCOWORDBYTE2732Struttura degli indirizzi"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#34,34,Riccardo Torlone -Corso di Calcolatori Elettronici38Esempi di indirizzin000000000000000000000000000 000 00 n1°blocco –1°word –1°byte n000000000000000000000000000 000 01 n1°blocco –1°word –2°byte n000000000000000000000000000 001 00 n1°blocco –2°word –1°byte (5°byte del blocco)n000000000000000000000000000 011 10 n1°blocco –4°word –3°byte (15°byte del blocco)n000000000000000000000000001 010 11 n2°blocco –3°word –4°byte n000000000000000000000000101 110 10 n6°blocco –7°word –3°byte n000000000000000000000010110 101 00 n23°blocco –6°word –1°byte 
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#35,35,"Ricerca di un blocco in cachenUna cache contiene un sottoinsieme di blocchi di memoria di indirizzo non contiguonQuando la CPU cerca una word, non sa in quale posizione essa si possa trovare nella cache (se effettivamente c’è)nNon c’è modo di risalire dall’indirizzo di un blocco di memoria alla sua posizione in cache nNon è possibile utilizzare il normale meccanismo di indirizzamento delle RAM:nSi fornisce un indirizzonViene letto il dato che si trova  allo indirizzo specificatonSi usano allora Memorie Associative
Riccardo Torlone -Corso di Calcolatori Elettronici39"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#36,36,"Memorie Associative
nCiascun elemento(riga)è costituito da due parti: la chiave e il dato nL’accesso ad un elemento viene effettuato non solo in base all’indirizzo ma anche in base a parte del suo contenuto (chiave)nL’accesso associativo avviene in un unico ciclonNel caso di una cache:nUn elementovienechiamatoslot di cachenLa chiave vienechiamatatag (etichetta)nL’informazione èunacache line (o blocco)Riccardo Torlone -Corso di Calcolatori Elettronici40CHIAVEINFORMAZIONECHIAVE DELL’INFORMAZIONE
INFORMAZIONE"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#37,37,"Cache a Mappatura Diretta
nSpazio di memoria di 2nbyte, diviso in blocchi da 2rbytenGli n-rbit più significatividell’indirizzospecificanoilblocconIn una cache con 2sslot si associa ad ogni blocco la slot di cache indicata dagli sbit meno significativi del suo indirizzo nSe il blocco è in cache deve essere in quella slot, e lì bisogna cercarlonIl TAG sono gli n-s-rbit più significativi dell’indirizzonIl TAG è contenuto nella slotnIl TAG permette di distinguere tra tutti i blocchi che condividono la stessa slot (collidono)Riccardo Torlone -Corso di Calcolatori Elettronici41Indirizzoa n bitSlot di CacheBLOCCO DI MEMORIATAGVTAGINDIRIZZO DI SLOTBYTEn-s-rsw            b      1   n-r-s bit                          2rbyteWORDrn–r"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#38,38,"Riccardo Torlone -Corso di Calcolatori Elettronici42EsempionIndirizzi a 8 bit (n = 8)nLinee di cache a 8 byte (r = 3)nWord di 2 bytenCache di 8 slotnStruttura indirizzo: 
nStruttura slot: ind. bloccowordbyteslottagbyte nel bloccotagbitvalidBlocco (8 byte)"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#39,39,"Riccardo Torlone -Corso di Calcolatori Elettronici4300000011000000110000100100001001Esempio –continua (è un’animazione che si può scaricare dal sito)
0 0 00 0 00 0 00 0 00 0 00 0 0....00001 11100001 11000001 10100001 10000001 01100001 01000001 00100001 00000000 11100000 11000000 10100000 10000000 01100000 01000000 00100000 000rqponmlihgfedcba1111111111111110
Accessi:MemoriaCachea          b         c         d         e          f          g          h10 0i          l         m         n         o          p         q          r1 0 00 0 00 0 0
01001110000001010000010101001110w         x         y         z         £          $         %          &10 1111110101100011010001000Bit validTag"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#4,4,Possibili implementazioninEsecuzione diretta delle istruzioni (RISC)nLe istruzioni possono venire eseguite direttamente dalla microarchitetturanPro e contro: nRepertorio di istruzioni limitatonProgettazione dell’HW complessanEsecuzione molto efficientenInterpretazione delle istruzioni (CISC)nLa microarchitettura sa eseguire direttamente solo alcune semplici operazioninCiascuna istruzione è scomposta in una successione di operazioni base poi eseguite dalla microarchitetturanPro e contro:nRepertorio di istruzioni estesonHW più compattonFlessibilità di progettoRiccardo Torlone -Corso di Calcolatori Elettronici5
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#40,40,"Riccardo Torlone -Corso di Calcolatori Elettronici44Cache a Mappa Diretta (esempio)
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#41,41,"Cache Associative ad Insiemi
nOgni slot è costituita da nelementi, ciascuno composto di bit valid, tag e blocconUn blocco può stare in un elemento qualsiasi della slot che gli corrispondenAttenua il problema della collisione di più blocchi sulla stessa slotRiccardo Torlone -Corso di Calcolatori Elettronici45
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#42,42,"Gestione della CachenLa CPU deduce numero di slot e TAG del blocco a partire dall’indirizzonSe lo slot è valido, si confronta il TAG nella slot con quello del blocco nCache Hit in lettura: tutto oknCache Hit in scrittura:nwritethrough: scrive anche in memorianwriteback: unica scrittura finale, quando il blocco è rimosso dalla cachenCache Miss in lettura: il blocco viene trasferito in cache e sovrascrive quello presente (questo va copiato in memoria se modificato)nCache Miss in scrittura:nwriteallocation: porta il blocco in cache (conviene per scritture ripetute)nwriteto memory: si effettua la scritturain memoriaRiccardo Torlone -Corso di Calcolatori Elettronici46"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#43,43,"Esercizio su memorie cache IUna cache a mappa diretta con 16K slot e  cache line di 64 byte, è installata  in un sistema con indirizzi a 32 bit:nspecificare la struttura di ciascuna slot, indicando esplicitamente la dimensione complessiva della slot e quella di ciascun campo;ncalcolare il numero di slot e la posizione nella slot del byte con indirizzo esadecimale 7B80034A;nverificare se i due byte di indirizzo esadecimale  32353793 e 3F5537BC collidono sulla stessa slot.
Riccardo Torlone -Corso di Calcolatori Elettronici47"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#44,44,"Riccardo Torlone -Corso di Calcolatori Elettronici48Esercizio su memorie cache II Si consideri una memoria cache associativa a 4 vie composta da 4K slot in un sistema con indirizzi a 24 bit e cache line da 16 byte. Indicando con X la cifra meno significativa non nulla del proprio numero di matricola, specificare:nla struttura dell'indirizzo di memoria, specificando la dimensione dei vari campi in bit;nla struttura della slot di cache, specificando la dimensione dei vari campi in bit;nla dimensione totale della cache (ordine di grandezza decimale);ni passi necessari alla ricerca nella cache del byte di indirizzo BXAXF2."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#45,45,"Memoria cache IIISi vuole progettare una cache a mappatura diretta per un sistema con indirizzi a 32 bit e linee di cache di 32 byte. Calcolare:nil numero minimo di slot necessario a garantire che non più di 213blocchi collidano sulla stessa slot;nla relativa struttura dell'indirizzo di memoria e della slot di cache, specificando la dimensione dei campi in bit;nquanto varia il numero di slot necessari nel caso di cache associativa a due vie;ni passi necessari alla scrittura del byte di indirizzo 7CA3F37D con riferimento a situazioni di cache hit e cache miss."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#46,46,Memoria cache IVSi vuole progettare una cache unificata a mappatura diretta per una CPU con indirizzi a 32 bit e linee di cache di 32 byte. Supponendo di avere a disposizione una memoria di 4MB e 40KB di spazio disponibile massimo sul chip della CPU determinare:nla struttura di una possibile slot di cache che soddisfi questi requisiti e la relativa struttura dell’indirizzo di memoria;nle dimensioni totali della cache progettata;nse e come sia possibile modificare la struttura determinata al punto A per ridurre le collisioni sulle slot di cache;ncosa può succedere se la CPU vuole leggere il byte 260 della memoria principale.
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#47,47,"Domande cacheCon riferimento ad una cache a mappatura diretta con 16K slot e cache line di 64 byte installata in un'architettura a 32 bit, indicare se le seguenti affermazioni sono vere o false.nIl campo TAG della cache è di 14 bit.nI primi 6 bit dell'indirizzo non vengono usati per indirizzare una slot di cache.nIl numero di collisioni su una slot di cache aumenta se aumentiamo le dimensioni della cache fino a 32K.nI byte di indirizzo F4B6A598 e 3CE6A5B3 collidono sulla stessa slot della cache.nI byte di indirizzo 4F3B7318 e 4F3B733A collidono sulla stessa slot della cache.nUna slot della cache è grande 525 bit.nSu una slot della cache collidono 4K cache line di memoria.nL'accesso a un byte di memoria contiguo a un byte presente nella cache non genera mai cache miss."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#48,48,"Soluzioni esercizio precedenteCon riferimento ad una cache a mappatura diretta con 16K slot e cache line di 64 byte installata in un'architettura a 32 bit, indicare se le seguenti affermazioni sono vere o false.n@NO Il campo TAG della cache è di 14 bit.n@SI I primi 6 bit dell'indirizzo non vengono usati per indirizzare una slot di cache.n@NO Il numero di collisioni su una slot di cache aumenta se aumentiamo le dimensioni della cache fino a 32K.n@SI I byte di indirizzo F4B6A598 e 3CE6A5B3 collidono sulla stessa slot della cache.n@NO I byte di indirizzo 4F3B7318 e 4F3B733A collidono sulla stessa slot della cache.n@SI Una slot della cache è grande 525 bit.n@SI Su una slot della cache collidono 4K cache line di memoria.n@NO L'accesso a un byte di memoria contiguo a un byte presente nella cache non genera mai cache miss."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#49,49,"CPU Core i7Esternamente:nMacchina CISC tradizionale nOperazioni su interi a 8/16/32 bitnOperazioni FP a 32/64 bit (IEEE 754) nSet di istruzioni esteso e molto disordinatonLunghezza variabile da 1 a 17 bytesn8 registriInternamente:nArchitettura ""Sandy Bridge” (32 nm)nSuccessivi: nIvyBridge e Haswell(22nm)nBroadwell, Skylake, KabyLake e Coffee Lake (14nm)nIce/CometLake (10nm) (10th generation)nTiger/Rocket Lake (10/14nm) (11th generation)nAlderLake (7nm) (12th generation)nRaptor Lake (7nm) (13th generation)nNucleo RISCnLunga pipelinenMulti-core (4/6)Riccardo Torlone -Corso di Calcolatori Elettronici76"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#5,5,Riccardo Torlone -Corso di Calcolatori Elettronici7Un esempio di µ-architetturanImplementazione di un JVM (Java Virtual Machine) con sole istruzioni su interinIn questo corso ci limitiamo a:nLa microarchitettura(data path)nLa temporizzazione di esecuzionenL’accesso alla memoria (cache)nIl formato delle micro-istruzioninLa sezione di controllonSul libro l’esempio è sviluppato fino alla definizione di un microprogramma completo per una JVM (con aritmetica intera)nQuesta ultima parte non fa parte del programma
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#50,50,"Intel Core i7
nSandy Bridge (2011): 1,16 miliardi di transistor, 32nm, 3.5 GhznArchitettura a 64 bit compatibile con i predecessorinAritmetica Floating-pointIEEE 754nArchitettura multicore(2-6) nHyper-threaded, superscalare (fattore 4), pipelinednBus di memoria sincrono a 64 bit + Bus PCIenQPI (QuickPathInterconnect): comunicazione con altri processorinCache 1olivello 32KB dati +32KB istruzioninCache 2olivello 256 KB per core (snooping)nCache 3olivello condivisa da 4 a 15 MB nScheda con 1155 pin (diversa dai predecessori)nConsuma da 17 a 150W (stati differenti per ridurre il consumo)Riccardo Torlone -Corso di Calcolatori Elettronici77
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#51,51,"Riccardo Torlone -Corso di Calcolatori Elettronici78Intel Core i7: PinoutLogico
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#52,52,"Intel Core i7: PinoutLogico (2)n1155 piedinin447 per i segnali (alcuni duplicati, 131 in tutto) n286 connessioni di alimentazionen360 connessioni di massan62 per “uso futuro”nDue gruppiindipendentiper l’interfacciacon unaDRAMn64bit, 666Mhz, 1.333 MTPS, 20 GB/sec complessivinUn gruppoper  l’interfacciacon lineePCIen16 linee(lane), 16GB/sec complessivinUn gruppo per la comunicazione con i chipset(DMI)nP67: SATA, USB, Audio, PCIe, Flash; nICH10: PCI, 8259A, clock, timer, controlloriDMAnGestione delle interruzioni sia come l’8088 che con APIC (Advanced ProgrammableInterrupt Controller)nGestione della tensione: (possibili diversi valori di Voltaggio)nThermal monitoring: sensori di calore per il ""thermalthrottling""n11 linee di diagnosi secondo lo standard IEEE 1149.1 JTAGRiccardo Torlone -Corso di Calcolatori Elettronici79"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#53,53,"Struttura di un sistema moderno basato su i7
Riccardo Torlone -Corso di Calcolatori Elettronici80
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#54,54,"Intel Core i7: Memory Bus
nBus gestito con pipelining: è possibile sovrapporre 4 transazioninOgni interfaccia DRAM ha 3 gruppi di lineenFasi di una transazione (usano gruppi di linee indipendenti):nAttivazione e invio indirizzinComando di Read/Write di parole contigue della memoria (bank)nRichiede due passi: comando e trasferimento datinChiusura e preparazione per la prossima transazionenFunziona solo con memorie sincroneRiccardo Torlone -Corso di Calcolatori Elettronici81
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#55,55,"Riccardo Torlone -Corso di Calcolatori Elettronici82MicroarchitetturaSandy Bridge di un core i7
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#56,56,"Riccardo Torlone -Corso di Calcolatori Elettronici84MicroarchitetturaSandy Bridge i7Sottosistema di memoria:nContiene una cache L2 unificata n8-way, 256KB, cache line 64B, write-backnInterfaccia verso L3 condivisa che contiene una unità di prefetchingn12-way, da 8 a 20MB, cache line 64B, interfaccia con RAMFront end:nPreleva istruzioni dalla cache L2 e le decodificanIstruzioni in L1 (8-way, 64KB, cache line 64B)nScompone istruzioni in micro-op RISC e le appoggia in una cache L0Controllo dell’esecuzione:nSceglie le microistruzioni che possono andare in esecuzione nRitira in ordine le microistruzioniUnità di esecuzione:nEsegue le microistruzioni su unità funzionali multiplenAccede a dati nei registri e nella cache dati L1nInvia informazioni al perditore di salti"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#57,57,"Riccardo Torlone -Corso di Calcolatori Elettronici85Pipeline dell’architettura Sandy Bridge
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#58,58,"Riccardo Torlone -Corso di Calcolatori Elettronici88CPU OMAP4430SOC con 2 microprocessori ARM CortexA9nImplementazione Texas Instruments dell’architettura ARMnA 32 bit, bus di memoria a 32 bitnRISC puran2 livelli di cachenSet di istruzioni ridotto e ordinatonLunghezza fissa (4 bytes)nHardware dedicato per istruzioni multimedialin16 registri generalin32 registri opzionali per operazioni in virgola mobilenOrganizzazione piuttosto semplicenMulticore(fino a 4 core)nPipeline a 11 stadi"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#59,59,"OMAP4430 della Texas InstrumentsnSoCbasato su ISA ARMnTarget: sistemi mobile o embeddednEquipaggiamento:n2-core CPU ARM RISC Cortex-A9 a 1Ghz, 45nmn1 GPU POWERV SGX540 (rendering3D)n1 ISP (manipolazione immagini)n1 VPU IVA3 (video enc/dec)nInterfacce I/O:nTouchscreen, keypadnDRAM, FlashnUSB, HDMInBasso consumo di potenzan660mW/100µWndynamicvoltagescalingnpowergatingnSuperscalare (2 istruzioni per ciclo)n2 L1: 32KB+32KB, 1 L2: 1MBnInterfaccia DRAM (LPDDR2)nScheda a 547 pinRiccardo Torlone -Corso di Calcolatori Elettronici89
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#6,6,"Riccardo Torlone -Corso di Calcolatori Elettronici8Il Cammino dei Dati nella JVM
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#60,60,"Riccardo Torlone -Corso di Calcolatori Elettronici90Architettura OMAP4430
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#61,61,"Riccardo Torlone -Corso di Calcolatori Elettronici91MicroarchitetturaARM CortexA9
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#62,62,"MicroarchitetturaARM CortexA9nCache L2:nUnificata da 1MBnI-cache L1: n32KB 4-wayncache linedi 32 byte: 8K istruzioni in tuttonUnità di lancio:nprepara fino a4 istruzioni per ciclo e le mette in un buffernUnità di esecuzionenDecodifica e sequenzia le istruzioni nProduce una coda di istruzioni da eseguirenAlmeno 2 Unità di esecuzione n1 con 2 I-ALU per somme + 1 I-ALU per prodotti con registri dedicatin1 di load/storecon:n4-way D-L1 da 32KB con line di cache a 32BnPrefetchingdi datin1 FP-ALU (VFP) e 1 SIMD vettoriale (NEON) opzionalenInterfaccia con la memoria:nArchitettura a 32 bit, word da 4Bn4GB di memoria indirizzabile su 2 canali indipendenti (8GB totali)Riccardo Torlone -Corso di Calcolatori Elettronici93"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#63,63,"Riccardo Torlone -Corso di Calcolatori Elettronici94Pipeline ARM CortexA9
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#64,64,Riccardo Torlone -Corso di Calcolatori Elettronici97CPU ATmega168Chip semplificato con <1M transistornEconomicità prevale sulle prestazioninMacchina RISC a 8 bit n32 registri eterogeneinIstruzioni eseguite in un ciclonPipeline a due stadi: fetch+esecuzioneInternamente:nOrganizzazione semplicenBasata su un Bus principalen1 SRAM da 1KB per i dati volatilin1 EEPROM da 1KB per dati staticinEsecuzioni e ritiri in ordine
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#65,65,"Riccardo Torlone -Corso di Calcolatori Elettronici98AtmelATmega168 nMicrocontrollore per applicazioni embedded(~1$)nCPU a 8 bit basata su ISA AVRnScheda a 28 pinn23 porte di I/On8 per porte B e Dn7 per porta C (analogica)n1 Vcc+2GNDn2 per configurare circuiti analogicinMemorie incorporaten16KB Flashn1KB EEPROMn1KB SRAMnNo RAM esternanClock realtimenInterfaccia seriale
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#66,66,"Riccardo Torlone -Corso di Calcolatori Elettronici100MicroarchitetturaATmega168RAM
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#67,67,MicroarchitetturaATmega168nRegistri collegati al Bus principale a 8 bitnRegisterfile: contiene 32 registri a 8 bit per dati temporaneinStatus e control: registro di stato nProgram counter: indirizzo istruzione da eseguirenRegistro delle istruzioni: istruzione correntenCiclo macchina attraverso il mainbusnIndirizzamento a memoria ndati: 2 registri (64KB max)nistruzioni: 3 registri (16MB max)nUnità di controllo delle interruzioninInterfaccia serialenTimernComparatore analogicon3 porte digitali di I/O (fino a 24 dispositivi)Riccardo Torlone -Corso di Calcolatori Elettronici101
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#68,68,Riccardo Torlone -Corso di Calcolatori Elettronici102Esecuzione di una istruzione nell’ATmega168nSemplice pipelinenDue stadi1.Fetchdell’istruzione nel registro delle istruzioni2.Esecuzione dell’istruzione:a)Lettura dei registri sorgenteb)Elaborazione della ALUc)Memorizzazione del risultato nel registro targetnTutto in 2 cicli di clock a 10-20Mhz
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#69,69,"Esercizio sulle architetture di CPU ISi vuole realizzare una semplice CPU con architettura CISC a 8 bit dotata di due registri generalpurpose, due registri per il fetchdelle istruzioni (il ProgramCountere il registro istruzione corrente) e due registri per il trasferimento dei dati da/per la memoria (uno per gli indirizzi e l'altro per i dati). La CPU deve essere in grado di svolgere 8 operazioni aritmetiche a numeri interi. Tutte le altre specifiche possono essere liberamente scelte.nDisegnare l'architettura generale (in particolare il data path) di tale CPU (comprensiva dei segnali di controllo) e illustrare concisamente il suo funzionamento.nDefinire il formato di una microistruzione per tale architettura cercando di minimizzare la sua lunghezza.nIndicare possibili modiche dell'architettura proposta in grado di migliorare le prestazioni."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#7,7,Il Cammino dei Dati (2)nRegistri: contraddistinti da nomi simbolici ciascuno con una precisa funzionenBus B: presenta il contenuto di un registro all’ingresso B della ALUnALU: ha come ingressi il bus B e il registro H (holding register)nShifter: consente di effettuare vari tipi di shift sull’uscita della ALUnBus C: permette di caricare l’uscita dello shifter in uno o più registrinSegnali di controllo: nB bus enable: trasferisce il contenuto di un registro sul bus BnWrite C bus: trasferisce il contenuto dello shifter in uno o più registrinControllo della ALU: seleziona una delle funzioni calcolabili dalla ALUnControllo dello shifter: specifica se e come scalare l’uscita della ALU Riccardo Torlone -Corso di Calcolatori Elettronici9
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#70,70,"Architettura di riferimento
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#71,71,"Esercizio sulle architetture di CPU IISi vuole realizzare una semplice CPU con architettura RISC a 8 bit dotata di un registro general purpose, un registro accumulatore, due registri per il fetch delle istruzioni (il Program Counter e il Registro Istruzione Corrente) e due registri per il trasferimento dei dati da/per la memoria (uno per gli indirizzi e l'altro per i dati). La CPU deve essere in grado di svolgere 16 operazioni aritmetiche a numeri interi. Tutte le altre specifiche possono essere liberamente scelte.nDisegnare l'architettura generale (in particolare il data path) di tale CPU (comprensiva dei segnali di controllo) e illustrare coincisamente il suo funzionamentonDefinire il formato di una istruzione macchina per tale architettura cercando di minimizzare la sua lunghezza.nIndicare possibili modifiche dell'architettura proposta per trasformarla in un'architettura CISC."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#72,72,"Architetture di CPU IIISi vuole realizzare una CPU per applicazioni embeddedche non possiede RAM e nella quale tutte le istruzioni macchina da eseguire sono memorizzate in una ROM. Tale CPU è dotata di due registri generalpurpose, un registro accumulatore, una porta di I/O e due registri per il caricamento delle istruzioni dalla ROM. La CPU deve essere in grado di eseguire 8 operazioni aritmetiche a numeri interi. L’esecuzione delle istruzioni macchina è strettamente sequenziale. Tutte le altre specifiche possono essere liberamente scelte.nDisegnare l’architettura generale (in particolare il data path) di tale CPU (comprensiva dei segnali di controllo) secondo i principi RISC e illustrare coincisamenteil suo funzionamento.nDefinire il formato di una istruzione macchina per tale architettura fissando la dimensione dei registri.nIndicare possibili modifiche dell’architettura proposta per poter leggere e scrivere dati memorizzati su una memoria RAM."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#73,73,"Riccardo Torlone -Corso di Calcolatori Elettronici107Architettura di riferimento
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#74,74,"Architetture di CPU IVSi vuole realizzare una CPU con architettura CISC dotata di tre registri general purpose, un registro accumulatore e due coppie di registri per il trasferimento di dati e istruzioni da/per la memoria. La CPU deve essere in grado di eseguire 16 operazioni aritmetiche a numeri interi e deve essere dotata di 4 stadi di pipeline, il primo dei quali è costituito da una unità IFU. Tutte le altre specifiche possono essere liberamente scelte.nDisegnare l’architettura generale (in particolare il data path) di tale CPU (comprensiva dei segnali di controllo) e illustrare coincisamenteil suo funzionamento.nDefinire il formato di una istruzione macchina per tale architettura fissando la dimensione dei registri.nIndicare possibili modifiche dell’architettura proposta per diminuire il fenomeno delle collisioni tra istruzioni macchina."
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#75,75,"Riccardo Torlone -Corso di Calcolatori Elettronici109Architettura di riferimento
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#76,76,"Riccardo Torlone -Corso di Calcolatori Elettronici110Esempio di pipeline
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#8,8,"Utilizziamo la ALU vista
nA e B sono bit omologhi degli operandinF0 e F1 selezionano la funzione (00: AND), (01: OR), (10: NOT), (11: SUM)nENA ed ENB sono segnali di enablee INVA permette di negare AnDefault ENA=ENB=1 e INVA=0 Riccardo Torlone -Corso di Calcolatori Elettronici10
"
data_test\rootfolder\università\CalcolatoriElettronici2\07 Microarchitettura di una CPU.pdf#9,9,"L’ALU è a 32 bit
nRealizzata connettendo 32 ALU ad 1 bit (bit slices)nINC incrementa la somma di 1 (A+1, A+B+1)
Riccardo Torlone -Corso di Calcolatori Elettronici11
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#0,0,Calcolatori ElettroniciParte VII: Il linguaggio assemblativo 8088(basato su materiale di M. Di Felice)Prof. Riccardo TorloneUniversitaRoma Tre
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#1,1,"Linguaggi assemblativiIl linguaggio assemblativo(assembly)nRappresentazione simbolica dell'insieme di istruzioni macchina di un'architettura.nAssocia ai dati nomi simbolici che identificano le corrispondenti posizioni nei registri della CPU o in memorianNasconde i dettagli relativi alle singole istruzioni (codici operativi, formati, ecc.), non quelli relativi all'architettura della macchinanFornisce un set di istruzioni (direttive) che facilitano la traduzione in linguaggio macchina
Riccardo Torlone -Corso di Calcolatori Elettronici2"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#10,10,"I registri di uso generalenAX: registro accumulatore, usato per memorizzare il risultato dell'elaborazione e come destinazione di molte istruzioni (a volte implicitamente)Esempio: ADD AX,20nBX: registro base, usato come accumulatore o come puntatore alla memoriaEsempio: MOV AX,(BX)nCX: registro contatore, usato come contatore dei ciclinDX: registro dati, usato insieme ad AX per contenere le istruzioni lunghe due parole (32 bit)nDX:AX
Riccardo Torlone -Corso di Calcolatori Elettronici11"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#100,100,"Esercizio VIIIScrivere un programma in linguaggio assemblativo 8088 che, dato un numero memorizzato in memoria principale, calcola il fattoriale del numero (n! = n×(n−1)×. . .×1) e lo stampa."
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#101,101,"Esercizio VIII!Calcolo del fattoriale_EXIT= 1_PRINTF = 127.SECT .TEXTstart:MOV    AX,(number)CMP     AX,1JG       1fMOV     AX,1JMP     3f1:MOVCX,AXDECCX2:IMULCXLOOP2b3:MOV(result), AXPUSH(result)PUSH(number)PUSH    fmtPUSH    _PRINTFSYSMOVSP,BPPUSH0PUSH_EXITSYS.SECT .DATAnumber: .WORD5result: .WORD   1fmt:.ASCII ""il fattoriale di %d e'%d\0"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#102,102,Esercizio XScrivere un versione ricorsiva del programma del calcolo del fattoriale.
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#103,103,"Esercizio X: Possibile soluzione!Calcolo del fattoriale: versione ricorsiva_EXIT = 1_PRINTF = 127.SECT .TEXTstart:PUSH  (number)CALL   fattPOP    CXMOV   SP,BPPUSH  CXPUSH  (number)PUSH  fmtPUSH  _PRINTFSYSMOV   SP,BPPUSH  0PUSH  _EXITSYSfatt:PUSH  BPMOV   BP,SPMOV   CX,4(BP)CMP    CX,1JG      1fMOV   4(BP),1JMP    2f1:DEC   CXPUSH  CXCALL  fattPOP   CXMOV   AX,4(BP)IMUL  CXMOV   4(BP),AX2:MOV   SP,BPPOP   BPRET.SECT .DATAnumber: .WORD 3fmt:.ASCII ""il fattoriale di %d e'%d\n"""
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#104,104,"Esercizio IXScrivere un programma in linguaggio assemblativo 8088 che dato un numero nmemorizzato in memoria principale, verifica se è un numero primo.Consiglio: utilizzare l'istruzione DIV che divide l'argomento per il contenuto di AX mettendo il risultato in AX e il resto in DX"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#105,105,"Esercizio IX_EXIT= 1_PRINTF= 127.SECT .TEXTstart:MOVBX,(n)MOVCX,BX1:DECCXCMPCX,1JLE3fMOV AX,BXMOVDX,0DIVCXCMPDX,0JE2fJMP1b2:MOVBX, nonprimoJMP4f3:MOVBX, primo4:PUSH(n)PUSH    BXPUSH    _PRINTFSYSMOVSP,BPPUSH0PUSH_EXITSYS.SECT .DATAn:.WORD49primo: .ASCII ""%d e'un numero primo\0""nonprimo: .ASCII ""%d non e'un numero primo\0"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#106,106,"Esercizio IXbis: altra possibile soluzione_EXIT= 1_PRINTF = 127.SECT .TEXTstart:MOVBX,(n)MOVCX,BXDECCX1:CMPCX,1JLE3fMOV AX,BXMOVDX,0IDIVCXCMPDX,0LOOPNZ  1b2:MOVBX, nonprimoJMP4f3:MOVBX, primo4:PUSH(n)PUSH    BXPUSH    _PRINTFSYSMOVSP,BPPUSH0PUSH_EXITSYS.SECT .DATAn:.WORD49primo: .ASCII ""%d e'un numero primo\0""nonprimo: .ASCII ""%d non e'un numero primo\0"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#107,107,Esercizio XIScrivere un programma in linguaggio assemblativo 8088 che calcola il del prodotto scalare di due vettori (somma dei prodotti degli elementi omologhi). Il programma deve essere dotato di una subrountineprodvecavente quattro parametri:nvec1 (indirizzo del primo vettore)nvec2 (indirizzo del secondo vettore)ndimensione (dimensione dei vettori –si assuma che siano della stessa lughezza)nrisultato (parametro di output che al termine dell'esecuzione della subroutine memorizza il risultato del prodotto).
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#108,108,"Esercizio XI: possibile soluzione_EXIT= 1_PRINTF= 127.SECT .TEXTstart:MOV CX,vec2-vec1 SHR  CX,1PUSH 0       !quarto parametro inz. a zeroPUSH CX     !terzo parametro PUSH vec2  !secondo parametro PUSH vec1  !primo parametro CALL prodvecADD SP,6   !tolgo i primi tre parametriPOP AXMOV  SP,BPPUSH AXPUSH fmtPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYSprodvec:PUSH BPMOV  BP,SPMOV  CX,8(BP)MOV  SI,0PUSH 0         !variabile locale inz. a zero1:MOV  BX,4(BP)  MOV  AX,(BX)(SI) MOV  BX,6(BP)MUL  (BX)(SI)ADD  -2(BP),AXADD  SI,2LOOP 1bPOP  10(BP)  !salvo la var. nel 4 argomento POP  BPRET.SECT .DATAvec1: .WORD 3,4,7,11,3vec2: .WORD 2,6,3,1,0fmt: .ASCII ""Il prodotto dei due vettori e': %d!\0""!.SECT.BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#109,109,"Esercizio XIIScrivere una subroutine PAL in assembler8088 che, dato una stringa (vettore di caratteri) S memorizzata in memoria principale, stampa restituisce 1 se la stringa S è palindroma (è uguale leggendola nei due versi; per esempio la stringa ""anna"" è palindroma) e 0 altrimenti. La subroutine PAL ha come parametri:nL’indirizzo della stringa da verificare e nla lunghezza della stringa"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#11,11,"Registri a 8 e a 16 bitTutti i registri possono essere visti come coppie di registri di 8 bit accessibili autonomamente (esempio: AX=AH:AL)
Riccardo Torlone -Corso di Calcolatori Elettronici120000000000000000AXAHALMOVE AX,2580000000100000010AXAHALADD AH,AL0000001100000010AXAHALAX=770"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#110,110,"Soluzione Esercizio XII! Verifica di stringhe palindrome_EXIT= 1_PRINTF= 127.SECT .TEXTstart:PUSH ends-str!secondo parametro PUSH str!primo parametro CALL palMOV  SP,BPPUSH AXPUSH fmtPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYSpal:PUSH BPMOV  BP,SPMOV  BX,4(BP)MOV  CX,6(BP)MOV  SI,CXDEC  SIMOV  DI,str21:MOVB  AL,(BX)(SI)STOSB  DEC  SILOOP 1bMOV  SI,4(BP)MOV  DI,str2MOV  CX,6(BP)REPE CMPSBJE   2fMOV  AX,0JMP  3f2:      MOV  AX,13:POP  BPRET.SECT .DATAstr: .ASCII ""ingegni""ends: .SPACE 1fmt: .ASCII ""%d"" endf: .SPACE 1str2: .ASCII ""."" .SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#111,111,Esercizio XIIIScrivere un programma in linguaggio assemblativo 8088 che trova il più grande degli elementi di un vettore vecmemorizzato in memoria principale. Si assuma che il vettore abbia almeno un elemento.Il risultato deve essere stampato sullo standard output (video). 
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#112,112,"Soluzione Esercizio XIII! Trova il piu'grande tra gli elementi di un vettore di interi_EXIT= 1_PRINTF= 127 .SECT .TEXTstart:MOV  CX,end-vecSHR  CX,1 !in CX va la dimensione di vecMOV  BX,vec!il registro base punta al primo elemento di vecMOV  AX,(vec) !inizializzo AX con il primo elemento di vec1:CMP  AX,(BX)(SI)JGE  2fMOV  AX,(BX)(SI)2:ADD  SI,2LOOP 1bPUSH AXPUSH formatPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYS.SECT .DATAvec:   .WORD 3,-4,7,11,34,-4,22,0,5end:   .SPACE 1format: .ASCII ""Il piu'grande tra elementi del vettore e'%d"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#113,113,"Laboratorio di ricerca sui Big DataVari temi di ricerca:nData managementnData analyticsnData integrationnData wranglingStrumenti:nDistributed processingnMachine LearningnLarge Language ModelsCosa offriamo agli studenti:nTirocini aziendali/interninIncubatore di start-up nContratti su progettiRiccardo Torlone -Corso di Calcolatori Elettronici115
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#12,12,"I registri puntatore ed indicenSP: registro puntatore alla cima dello stack. nViene modificato automaticamente dalle operazioni sullo stack(PUSH, POP).nBP: registro puntatore base dello stack. nPunta alla base del frame (record di attivazione) assegnato alla procedura correntenSI: registro indice sorgentenusato in combinazione con BP per riferirsi a dati sullo stacko con BX per localizzare dati in memoria.nDI: registro indice destinazionenusato come SI
Riccardo Torlone -Corso di Calcolatori Elettronici13"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#13,13,Registro di statonIl registro di stato (flag) e un insieme di registri da 1 bit.nI bit sono impostati da istruzioni aritmetiche:nZ-il risultato e zeronS-il risultato e negativo (bit di segno)nO-il risultato ha causato un overflownC-il risultato ha generato un riportonA-riporto ausiliario (oltre il bit 3)nP-parità del risultatonGli altri bit del registro controllano alcuni aspetti dell'attività del processore nI= attiva gli interruptnT= abilita il tracingnD= operazioni su stringhenNon tutti i bit sono utilizzatiRiccardo Torlone -Corso di Calcolatori Elettronici14
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#14,14,"Segmenti e registri di segmentonLo spazio di memoria indirizzabile dalla CPU e suddiviso in segmenti logici. Ogni segmento e costituito da 65.536 (64K) byte consecutivi.nQuattro registri di segmento puntano ai quattro segmenti correntemente attivi.
nCSpunta al segmento contenente le istruzioni da eseguirenDSpunta al segmento contenente le variabili del programmanSSpunta al segmento contenente lo stackcorrentenESpunta al segmento extra, usato tipicamente per i datiRiccardo Torlone -Corso di Calcolatori Elettronici15
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#15,15,"Segmentazione della memorianLo spazio di memoria viene visto come un gruppo di segmentinOgni segmento:nCostituisce un'unita di memoria indipendentenE' formata da locazioni contigue di memorianHa un limite massimo di 64KBnInizia ad un indirizzo di memoria multiplo di 16nOgni riferimento alla memoria richiede l'intervento di un registro di segmento per la costruzione di un indirizzo fisico:Indirizzo Effettivo = indirizzo nel programma  + indirizzo segmento
Riccardo Torlone -Corso di Calcolatori Elettronici17"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#16,16,"Costruzione indirizzo fisico1.Si considera il registro di segmento corrispondente2.Si aggiungono 4 zero a destra (×16)nindirizzo a 20 bit3.Si somma all'indirizzo da 20 bit
Riccardo Torlone -Corso di Calcolatori Elettronici18
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#17,17,"Segmento per la gestione dello stacknIl segmento di stacke costituito da parole di 2 bytenLo stackcresce andando dagli indirizzi alti a quelli bassinSS punta all'indirizzo di partenza dello stacknSP punta alla locazione in cima allo stack
Riccardo Torlone -Corso di Calcolatori Elettronici19
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#18,18,"Indirizzamento immediato e a registronIndirizzamento a registronL'operando si trova nei registri, e non è necessario accedere alla memoriaEsempio: CX=5→MOV AX,CX →AX=5nIndirizzamento immediatonL'operando e contenuto nell'istruzione. nIl dato può essere una costante di 8 o 16 bitEsempio: MOV AX,5 →AX=5
Riccardo Torlone -Corso di Calcolatori Elettronici20"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#19,19,"Indirizzamento direttoL'istruzione contiene l'indirizzo dei dati nell'operando stesso
Riccardo Torlone -Corso di Calcolatori Elettronici21
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#2,2,"Perché imparare un linguaggio assemblativo?nPer scrivere routine di sistema operativo? NOnSi scrive in C (o in C++)nPer scrivere codice ottimizzato? Solo in partenImpossibile battere i compilatorinSolo localmente abbiamo qualche chancenRegola 90%-10%nPer conoscere meglio il calcolatore? SI!nPer imparare l’assemberbisogna conoscere l’architetturanIl debugdell’assemblerci fa comprendere come funziona l’architettura 
3Riccardo Torlone -Corso di Calcolatori Elettronici"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#20,20,"Indirizzamento indiretto a registroL'indirizzo dell'operando e memorizzato in uno dei registri BX, SI o DI
Riccardo Torlone -Corso di Calcolatori Elettronici22
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#21,21,"Indirizzamento indiretto a registro con spiazzamentoL'indirizzo si ottiene dalla somma del contenuto di uno dei registri BX, SI o DI e una costante
Riccardo Torlone -Corso di Calcolatori Elettronici23
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#22,22,"Indirizzamento a registro indiceL'indirizzo si ottiene dalla somma del contenuto dei dei registri SI o DI e BX
Riccardo Torlone -Corso di Calcolatori Elettronici24
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#23,23,"Indirizzamento a registro indice con spiazzamentoL'indirizzo si ottiene dalla somma del contenuto dei registri SI o DI, BX ed una costante
Riccardo Torlone -Corso di Calcolatori Elettronici25
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#24,24,"Modalità di indirizzamento
Riccardo Torlone -Corso di Calcolatori Elettronici26
#=operando immediato"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#25,25,"L'assemblatore as88Disponibile presso:nCD-ROM allegato al libro di testo del corsonSito Web del corsoIl toolcomprende:nProgramma assemblatore (as88)nUtilizzo Generale: as88 Nomeprogetto(.s)nEmulatore-Interprete dell'architettura 8088 (s88)nUtilizzo Generale: s88 NomeprogettonProgramma tracerper il debugging(t88)nUtilizzo Generale: t88 Nomeprogetto(.$)
Riccardo Torlone -Corso di Calcolatori Elettronici27"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#26,26,"Direttive dell’assemblatorenOgni programma assemblye strutturato in 3 sezioni:1.sezione di TESTO (direttiva: .SECT .TEXT): contiene le istruzioni del programma2.sezione DATI (direttiva: .SECT .DATA): alloca spazio nel segmento DATI per i dati (inizializzati)3.sezione BSS (direttiva: .SECT .BSS): alloca spazio nel segmento DATI per i dati (non inizializzati)nE' possibile definire etichette di due tipi:nglobali: identificatori alfanumerici seguiti dal simbolo “:” (possono occupare una intera riga)nlocali: utilizzabili solo nel segmento TESTO, costituite da una sola cifra seguita dal simbolo “:”.Riccardo Torlone -Corso di Calcolatori Elettronici28"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#27,27,"Vincoli sulle etichettenLe etichette globali DEVONO essere univochenEs: .SECT .DATA   hw: .ASCII ""Hello""nLe etichette locali possono occorrere più voltenEs. JMP 1fnSalto verso la prossima etichetta denominata ""1""nE' possibile attribuire nomi simbolici alle costanti mediante la sintassi: identificatore=espressionenEs. BLOCKSIZE=1024nI valori numerici possono essere:ndecimali,nottali (cominciano per zero), nesadecimali (cominciano per 0x)nI commenti iniziano con il carattere ""!""Riccardo Torlone -Corso di Calcolatori Elettronici29"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#28,28,"Direttive del compilatore
Riccardo Torlone -Corso di Calcolatori Elettronici30
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#29,29,"The Tracer(debugger)
Il tracerconsente di effettuare l'esecuzione step-by-stepdel programma e di monitorare lo stato di registri/memoriaRiccardo Torlone -Corso di Calcolatori Elettronici31
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#3,3,"Assembler ""embedded""#include<stdio.h>voidmain(void) {staticintx = 3;asm{MOV %EAX, xADD %EAX, xADD %EAX, xNOPMOV x, %EAX}printf(""%2u"",x);return;}4Riccardo Torlone -Corso di Calcolatori Elettronici"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#30,30,"Uso dei registri con il tracer
(a) Parte del programma(b) I registri dopo l’esecuzione di 7 righe(c) I registri dopo l’esecuzione di 6 iterazioni del cicloRiccardo Torlone -Corso di Calcolatori Elettronici32
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#31,31,"The ACK-BasedAssembler, as88
Valori di escapeconsentiti nell’as88.Riccardo Torlone -Corso di Calcolatori Elettronici33
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#32,32,"Comandi del tracer(1)
E' possibile interagire con il tracer: nin modalità batch (fornendo in input un file con i comandi del tracer) nin modalità interattiva (inserendo comandi da tastiera seguiti dal tasto INVIO)Riccardo Torlone -Corso di Calcolatori Elettronici34
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#33,33,"Comandi del tracer(2)
Riccardo Torlone -Corso di Calcolatori Elettronici35
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#34,34,"Chiamate di sistemanLe chiamate di sistema consentono di utilizzare le procedure fornite dal sistema operativo.nLe routine di sistema possono essere attivate con la sequenza di chiamata standard:nSi impilano gli argomenti sullo stacknSi impila il numero di chiamatanSi esegue l'istruzione SYSnI risultati sono restituiti nel registro AX o nella combinazione di registri AX:DX (se il risultato e di tipo long)nGli argomenti sullo stackdevono essere rimossi dalla funzione chiamante
Riccardo Torlone -Corso di Calcolatori Elettronici36"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#35,35,"Chiamate di sistema in as88 (1)L'interprete 8088 supporta 12 chiamate di sistema.n_OPEN: Apre il file namein lettura-scritturaIdentificativo chiamata:5Argomenti: *name, 0=lettura/1=scrittura/2=lettura-scrittura;Valore Ritorno: un descrittore di file (fd)n_CREAT: Crea un nuovo file di nome nameIdentificativo chiamata: 8Argomenti: *name, *mode= permessi UNIX;Valore Ritorno: un descrittore di file (fd)n_READ: Legge nbyte da un file con descrittore fdtrasferendoli nel buffer bufIdentificativo chiamata: 3Argomenti: fd, buf, n;Valore Ritorno: numero di byte letti correttamenteRiccardo Torlone -Corso di Calcolatori Elettronici37"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#36,36,"Chiamate di sistema in as88 (2)n_WRITE: Scrive n byte sul file con descrittore fdprelevandoli dal buffer bufIdentificativo chiamata: 4Argomenti: fd, buf, n;Valore Ritorno: numero di byte scritti correttamenten_CLOSE: Chiude un file precedentemente apertoIdentificativo chiamata: 6Argomenti: fd(descrittore di file)Valore Ritorno: 0 se l'operazione ha successon_LSEEK: Sposta il puntatore del file con descrittore fddioffset bytesIdentificativo chiamata: 19Argomenti: fd, offset, 0/1/2;Valore Ritorno: nuova posizione all'interno del filen_EXIT: Interrompe un processoIdentificativo chiamata: 1;Argomenti: 0=successo/1=errore;Riccardo Torlone -Corso di Calcolatori Elettronici38"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#37,37,"Chiamate di sistema in as88 (3)n_GETCHAR: Legge un carattere dallo standard inputIdentificativo chiamata: 117Valore ritorno: il carattere letto e posto in ALn_PUTCHAR: Scrive un carattere sullo standard outputIdentificativo chiamata: 122Argomenti: carattere da scriveren_PRINTF: Stampa una stringa formattata sullo standard outputIdentificativo chiamata: 127Argomenti: stringa di formato, argomentin_SSCANF: Legge gli argomenti dal bufferbufIdentificativo chiamata: 125Argomenti: buf, stringa di formato, argomentin_SPRINTF: Stampa una stringa formattata sul buffer bufIdentificativo chiamata: 121Argomenti: buf, stringa di formato, argomentiRiccardo Torlone -Corso di Calcolatori Elettronici39"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#38,38,"Primo esempio!calcolo di (a+3)*b_EXIT= 1.SECT .TEXTstart:MOVAX,(a)ADDAX,3MUL     (b)PUSH0PUSH_EXITSYS.SECT .DATAa: .WORD 5b: .WORD 3.SECT .BSSRiccardo Torlone -Corso di Calcolatori Elettronici40"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#39,39,"Istruzione di copia e trasferimentoMOV(B): Trasferisce un byte (MOVB) o una word (MOV) da una sorgente ad una destinazione senza alterare il contenuto della sorgenteIndirizzamento effettivo: un qualunque indirizzamento tra quelli vistinIndirizzamento:nregistro ←indirizzo effettivo (Es. MOV AX,(200))nindirizzo effettivo←registro (Es. MOV (BX), AX)nindirizzo effettivo←dato immediato (Es. MOV AX,100)nVincoli:nNon e possibile caricare un valore immediato in un registro segmentonIl registro CS non e utilizzabile come destinazione di un'istruzione MOV.
Riccardo Torlone -Corso di Calcolatori Elettronici41"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#4,4,"Assemblatore e TracerAssembler (assemblatore)nProgramma che riceve in ingresso un programma in linguaggio assemblativoe genera un programma in linguaggio macchina (binario) pronto per essere eseguito dall'hardware.Tracer(interprete)nSimulatore dell’esecuzione di un programma scritto in un linguaggio assemblativonConsente di procedere “passo-passo”nDebuggerper l’Assembler
5Riccardo Torlone -Corso di Calcolatori Elettronici"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#40,40,"Operazioni sullo stackPUSH e POP aggiungono/rimuovono un elemento dalla cima dello stackselezionato da SS:SPnLe operazioni sullo stackmodicano il valore di SP:nIndirizzamento a stackimplicitonOperandi validi:nPUSH: operando immediato o indirizzo effettivo (es. PUSH 30 oppure PUSH AX)nPOP: indirizzo effettivo (esPOP AX)Le operazioni PUSHF e POPF trasferiscono il contenuto del registro flagnella cima dello stacke viceversa.
Riccardo Torlone -Corso di Calcolatori Elettronici42"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#41,41,"Operazioni di PUSH e POPnL'operazione di PUSH decrementa SP di 2 bytenL'operazione di POP incrementa SP di 2 byte
Riccardo Torlone -Corso di Calcolatori Elettronici43
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#42,42,"AddizioneADD(B): somma l'operando sorgente all'operando destinazione e memorizza il risultato nell'operando destinazionenIndirizzamento:nregistro ←indirizzo effettivo (Es. ADD AX,(200))nindirizzo effettivo←registro (Es. ADD (BX), AX)nindirizzo effettivo←dato immediato (Es. ADD AX,100)nL'istruzione ADD modica i bit del registro di flagADC comprende nella somma il flagdel riporto.
Riccardo Torlone -Corso di Calcolatori Elettronici44"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#43,43,"SottrazioneSUB(B): sottrae l'operando sorgente all'operando destinazione e memorizza il risultato nell'operando destinazione.nIndirizzamento:nregistro←indirizzo effettivo (Es. SUB AX,(200))nindirizzo effettivo←registro (Es. SUB (BX), AX)nindirizzo effettivo←dato immediato (Es. SUB AX,100)nL'istruzione SUB modica i bit del registro di flagSBB comprende nella sottrazione il flagdel riporto.
Riccardo Torlone -Corso di Calcolatori Elettronici45"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#44,44,"Moltiplicazione(I)MUL(B): moltiplica due operandi con/senza segnonE’ un'operazione unaria: MUL sourcenIl primo operando (implicito) è il registro accumulatore (AL per moltiplicazione tra byte, AX per word).nIl secondo operando e specificato da source e può essere un qualsiasi indirizzo effettivo.nIl risultato e posto in AX se si moltiplicano byte, in AX:DX se si moltiplicano wordIMUL effettua la moltiplicazione con segno
Riccardo Torlone -Corso di Calcolatori Elettronici46"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#45,45,"Divisione(I)DIV(B): divide due operandi con/senza segno.nE’ un’operazione unaria: DIV sourcenIl divisore e specificato da sourcee può essere un qualsiasi indirizzo effettivo.nSe sourceha dimensioni di 1 byte:nIl dividendo (implicito) e AXnIl risultato della divisione è in AL, il resto in AHnSe sourceha dimensioni di 1 word:nIl dividendo (implicito) e DX:AXnIl risultato della divisione è in AX, il resto in DXIDIV effettua la divisione con segno.Riccardo Torlone -Corso di Calcolatori Elettronici47"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#46,46,"Riepilogo istruzioni di movimento e aritmetiche
Riccardo Torlone -Corso di Calcolatori Elettronici48
e=indirizzoeffettivo, r=registro, #=operando immediato"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#47,47,"Operazioni logiche, su bit e di scorrimentoPrincipali Operazioni logiche: NEG(B), NOT(B), INC(B), DEC(B)nL'operando è un indirizzo effettivoPrincipali Operazioni su bit: AND(B), OR(B), XOR(B)nregistro ←indirizzo effettivo (Es. AND AX,(200))nindirizzo effettivo←registro (Es. AND (BX), AX)nindirizzo effettivo←dato immediato (Es. AND AX,1)Principali Operazioni di scorrimento: SHR(B), SHL(B), ROL(B), ROR(B)nLa destinazione è un indirizzo effettivonIl secondo argomento quantifica lo spostamento
Riccardo Torlone -Corso di Calcolatori Elettronici49"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#48,48,"Operazioni logiche, su bit e scorrimento
Riccardo Torlone -Corso di Calcolatori Elettronici50
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#49,49,"Salti incondizionatiJMP: trasferisce il controllo all'istruzione specificata dall'operando in maniera incondizionata.Due tipi di salto:nSalto Corto: la destinazione si trova nel segmento di codice corrente (cui fa riferimento il registro CS)nSalto Lungo: l'istruzione modifica il contenuto del registro CSEsempio:JMP labelADD AX,BXlabel:AND AX,BXN.B. La prossima istruzione ad essere eseguita è la ANDRiccardo Torlone -Corso di Calcolatori Elettronici51"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#5,5,"Assemblye linguaggio macchina
6Riccardo Torlone -Corso di Calcolatori Elettroniciassemblaggiocompilazione"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#50,50,"ConfrontiCMP(B): Effettua una sottrazione fra due operandi senza modificare nessuno dei due operandiEsempio: CMP operando1  operando2nIl risultato della sottrazione viene scartato.nI bit del registro di flagvengono modificati.
Riccardo Torlone -Corso di Calcolatori Elettronici52"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#51,51,"Salti condizionatiJxx: istruzioni di salto in base ai valori del registro di flagnLe istruzioni di salto condizionato controllano se una certa condizione e verificata. nLa condizione è specificata dal valore dei registri di flag. nAzioni:nSe la condizione e verificata, il controllo passa all' istruzione il cui indirizzo e specificato come operandonSe la condizione non e verificata, l'esecuzione prosegue con l'istruzione successivanVincoli:nJxxconsente salti di lunghezza massima pari a 128 byte
Riccardo Torlone -Corso di Calcolatori Elettronici53"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#52,52,"Salti condizionati
Riccardo Torlone -Corso di Calcolatori Elettronici54
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#53,53,Registro di statonIl registro di stato (flag) e un insieme di registri da 1 bit.nI bit sono impostati da istruzioni aritmetiche:nZ-il risultato e zeronS-il risultato e negativo (bit di segno)nO-il risultato ha causato un overflownC-il risultato ha generato un riportonA-riporto ausiliario (oltre il bit 3)nP-parità del risultatonGli altri bit del registro controllano alcuni aspetti dell'attività del processore nI= attiva gli interruptnT= abilita il tracingnD= operazioni su stringhenNon tutti i bit sono utilizzatiRiccardo Torlone -Corso di Calcolatori Elettronici55
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#54,54,"Implementazione di istruzioni condizionali e cicliIf(a> b) thenCMP AX,BXa=b; JLE else_labelelse MOV AX,BXb=a; JMP end_labelelse_label:MOV BX,AXend_label:….while(a<1000) whileSum:... CMP AX,1000...JGE end_whileend while; ...JMP whileSumend_while:Riccardo Torlone -Corso di Calcolatori Elettronici56"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#55,55,"CicliL'istruzione LOOP consente di implementare esplicitamente cicli nIl registro CX deve essere inizializzato con il numero di cicli dell'istruzione LOOPnLOOP statementLabelnIl valore di CXviene decrementatonSe CXvale zero, l'esecuzione continua con l'istruzione successiva all'istruzione LOOPnSe CXe diverso da zero, allora viene eseguito un salto all'etichetta statementLabel
Riccardo Torlone -Corso di Calcolatori Elettronici57"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#56,56,"Esempi di uso di loope sue variantifor(i=0; i<5; i++) { MOV AX,(a)a=a+3; MOV CX,5}repeat:ADD AX,3LOOP repeatnLOOPE statementLabelnDecrementa CX e cicla(saltando all'etichetta statementLabel) se CX≠0 e il flagZF=1nLOOPNE statementLabelnDecrementa CX e cicla(saltando all'etichetta statementLabel) se CX≠0 e il flagZF=0.Riccardo Torlone -Corso di Calcolatori Elettronici58"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#57,57,"Altre istruzioni
Riccardo Torlone -Corso di Calcolatori Elettronici59
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#58,58,"Esercizio IIScrivere un programma in linguaggio assemblativo 8088 che, preso un intero n in memoria, calcola la somma dei primi n interi.Il risultato deve essere stampato sullo standard output (video). "
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#59,59,"Soluzione Esercizio!Somma dei primi n numeri_EXIT= 1_PRINTF= 127.SECT .TEXTstart:MOVAX,0            MOVCX,(number)1:ADDAX,CXLOOP1bMOV(result), AXPUSH(result)PUSH(number)PUSH    formatPUSH    _PRINTFSYSMOVSP,BPPUSH0PUSH_EXITSYS.SECT .DATAnumber:.WORD5result:.WORD   1!format: .ASCII ""La somma dei primi %d interi e' %d"""
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#6,6,"Il Tracer
(a) Un programma in linguaggio assemblativo(b) Il tracerin esecuzione sul programma Riccardo Torlone -Corso di Calcolatori Elettronici7
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#60,60,Esercizio IVScrivere un programma in linguaggio assemblativo 8088 che calcola la somma degli elementi di un vettore vecmemorizzato in memoria principale. Il risultato deve essere stampato sullo standard output (video). 
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#61,61,"Soluzione Esercizio! Stampa la somma di un vettore di interi_EXIT= 1_PRINTF= 127 .SECT .TEXTstart:MOV  CX,end-vecSHR   CX,1! In CXva la lunghezza del vettoreMOV  BX,vecMOV  SI,0MOV  AX,01:ADD  AX,(BX)(SI)ADD  SI,2LOOP 1bPUSH AXPUSH formatPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYS.SECT .DATAvec:   .WORD 3,4,7,11,3end:   .SPACE 1format: .ASCII ""La somma degli elementi del vettore e'%d"""
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#62,62,"Chiamate di procedura (subroutine)Un programma in linguaggio assemblativopuò essere suddiviso in sottoprogrammi detti subroutine.nVantaggi:nConsentono di suddividere il codice in blocchi funzionalinConsentono di riutilizzare codicenCaratteristiche:nPossono ricevere parametri in ingressonPossono disporre di variabili localinPossono restituire un valore di ritorno.
Riccardo Torlone -Corso di Calcolatori Elettronici64"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#63,63,"Chiamata di procedura e indirizzo di ritorno
Riccardo Torlone -Corso di Calcolatori Elettronici65
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#64,64,"Struttura tipica Stacknell’invocazione di subroutine
Riccardo Torlone -Corso di Calcolatori Elettronici66
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#65,65,"Invocazione di subroutine in x86L'istruzione CALL trasferisce il controllo dal programma chiamante alla procedura chiamatanSintassi: CALL Nome FunzionenSalva l'indirizzo di ritorno sulla cima dello stacknPassa il controllo alla procedura chiamatanEsistono invocazioni:nravvicinate (all'interno dello stesso segmento di codice) na distanza (tra segmenti diversi, occorre salvare CS ed indirizzo di ritorno)
Riccardo Torlone -Corso di Calcolatori Elettronici67"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#66,66,"Ritorno da subroutineL'istruzione RET trasferisce il controllo dalla procedura chiamata alla procedura chiamantenSintassi: RET [No argomenti]nLegge dalla cima dello stackl'indirizzo di ritorno salvato dalla precedente CALL.nRestituisce il controllo alla procedura chiamantenN.B. Al momento dell'esecuzione della RET, la cima dello stackdeve contenere l'indirizzo di ritorno
Riccardo Torlone -Corso di Calcolatori Elettronici68"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#67,67,"Invocazione sempliceEsempio di subroutine con CALL e RET che non usa variabili locali e parametriMOV AX,BXCALL esempio ;Chiamo la subroutine....esempio:MOV BX,2....RET ;Restituisco il controllo al chiamante
Riccardo Torlone -Corso di Calcolatori Elettronici69"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#68,68,"Invocazione con argomenti (1)
Riccardo Torlone -Corso di Calcolatori Elettronici70
BP"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#69,69,"Invocazione con argomenti (2)
Riccardo Torlone -Corso di Calcolatori Elettronici71
BP"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#7,7,Assembler 8088 / IA32 / x86nx86: famiglia di ISA della famiglia Intel. Varie estenzioni:n8086 →… →80386 →… →Pentium IV →… →Core i7nx86-32 (IA32): linguaggio macchina dei processori x86 a 32 bitnVersione moderna: x86-64 estensione a 64 bit dell'x86nFaremo riferimento ad una delle prime versioni: 8088nversione semplificata di un microprocessore Intel modernonil relativo codice assemblerpuò essere eseguito anche su i microprocessori correntinCaratteristiche principalinArchitettura a 16 bitnIndirizzi: 20 bit (1 MB di RAM)nData bus: 8 bitnL'unita minima indirizzabile: 1 bytenRangedi indirizzi: [00000:FFFFF]8Riccardo Torlone -Corso di Calcolatori Elettronici
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#70,70,"Invocazione con argomenti (3)
Riccardo Torlone -Corso di Calcolatori Elettronici72
BP"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#71,71,"Invocazione con argomenti (4)
Riccardo Torlone -Corso di Calcolatori Elettronici73
BP"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#72,72,"Invocazione con argomenti (5)
Riccardo Torlone -Corso di Calcolatori Elettronici74
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#73,73,"Invocazione con argomenti (6)
Riccardo Torlone -Corso di Calcolatori Elettronici75
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#74,74,"Invocazione con argomenti (7)
Riccardo Torlone -Corso di Calcolatori Elettronici76
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#75,75,"Stackdurante l’esecuzione di una subroutine
Riccardo Torlone -Corso di Calcolatori Elettronici77
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#76,76,Invocazione di subrountinecon argomentinLa funzione chiamante deve:nImpilare sullo stackgli argomenti della funzione in ordine inverso (dall'ultimo al primo)nTrasferire il controllo con l'istruzione CALLnLa funzione chiamata deve:nSalvare sullo stackil valore corrente del registro BPnSovrascrivere BP con il contenuto corrente di SP (inizializza il record di attivazione)nAllocare le variabili locali sullo stacknAl termine della funzione occorre:nSovrascrivere SP con il contenuto di BP (svuota il record di attivazione)nEffettuare una POP dallo stacksu BPnEseguire l'istruzione RETnRimuovere gli argomenti dallo stackRiccardo Torlone -Corso di Calcolatori Elettronici78
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#77,77,"Chiamate di procedura: esempioEsempio di subroutine che calcola a + b + cPUSH (c)PUSH (b)PUSH (a)CALL subroutineADD SP,6....subroutine:PUSH BPMOV BP, SPMOV AX,4(BP)MOV BX,6(BP)MOV DX,8(BP)ADD AX,BXADD AX,DXMOVE SP, BP  !Inutile in questo caso. Serve se ho allocato variabili locali.POP BPRETRiccardo Torlone -Corso di Calcolatori Elettronici79Indirizzo di ritornovecchio BPbacSPBPsituazionestackBP+4BP+6BP+8"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#78,78,"Chiamate di sistemanLe chiamate di sistema consentono di utilizzare le procedure fornite dal sistema operativonLe routine di sistema possono essere attivate con la sequenza di chiamata standard:nSi copiano gli argomenti sullo stacknSi impila il numero di chiamatanSi esegue l'istruzione SYSnI risultati sono restituiti nel registro AX o nella combinazione di registri AX:DX (se il risultato e di tipo long)nGli argomenti sullo stackdevono essere rimossi dalla funzione chiamante
Riccardo Torlone -Corso di Calcolatori Elettronici80"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#79,79,"System Callsand System Subroutines
Riccardo Torlone -Corso di Calcolatori Elettronici81
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#8,8,"I registri generali
Disponibili 14 registri, suddivisi in 4 gruppi funzionaliRiccardo Torlone -Corso di Calcolatori Elettronici9
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#80,80,"EsercizioScrivere un programma in linguaggio assemblativo 8088 che, preso un numero ain memoria, calcola il quadrato del numero facendo uso di una subroutine “square” che ha come unico argomento il numero a.Il risultato deve essere stampato sullo standard output (video). "
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#81,81,"Soluzione Esercizio III! Calcola la il quadrato di un numero con la subroutine “square”_EXIT= 1_PRINTF= 127.SECT .TEXTstart:PUSH (a)CALL squareMOV  SP,BPPUSH AXPUSH pfmtPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYSsquare:PUSH BPMOV  BP,SPMOV  AX,4(BP)MOV  BX,AXMUL  BXPOP  BPRET.SECT .DATApfmt: .ASCIZ ""Il quadrato e' %d!\n""a:.WORD 3"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#82,82,"Esercizio VScrivere un programma in linguaggio assemblativo 8088 che calcola la somma degli elementi di un vettore vecmemorizzato in memoria principale, facendo uso di una subroutine ""vecsum"" che ha come argomento la dimensione del vettore e il vettore. Il risultato deve essere stampato sullo standard output (video). "
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#83,83,"Soluzione Esercizio V! Stampa la somma di un arraydi interi mediante una subroutine ""vecsum""_EXIT= 1_PRINTF= 127 .SECT .TEXTvecpstrt:PUSH vecMOV  CX,end-vecSHR  CX,1PUSH CXCALL vecsumMOV  SP,BPPUSH AXPUSH formatPUSH _PRINTFSYSMOV SP,BPPUSH 0PUSH _EXITSYSvecsum:PUSH BPMOV  BP,SPMOV  CX,4(BP)MOV  BX,6(BP)MOV  SI,0MOV  AX,01:ADD  AX,(BX)(SI)ADD  SI,2LOOP 1bMOV  SP,BPPOP  BPRET.SECT .DATAvec:   .WORD 3,4,7,11,3end:   .SPACE 1format: .ASCII ""La somma della stringa e' %d"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#84,84,"Operazioni su arraye stringhe: MOVSBL'istruzione MOVSB sposta un byte dalla posizione indirizzata dal registro SI alla posizione indirizzata dal registro DI.nSintassi: MOVSB [No Operandi]nL'indirizzo del byte sorgente deve trovarsi in SInL'indirizzo del byte destinazione deve trovarsi in DInAl termine dell'operazione, i registri SI/DIvengono incrementati o decrementati a seconda del valore corrente del bit di direzione nel registro di flag:nCLD: con questa istruzione, i registri SI e DIvengono incrementati (scorrimento in avanti)nSTD: con questa istruzione, i registri SI e DI vengono decrementati (scorrimento all'indietro)nMOVSB per operazioni su byte (8bit), MOVSW per operazioni su parole (16 bit).Riccardo Torlone -Corso di Calcolatori Elettronici86"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#85,85,"Operazioni su arraye stringhe: REPL'istruzione REP MOVSB itera l'esecuzione dell'istruzione MOVSB un numero di volte pari al valore corrente del registro CX.nSintassi: REP MOVSBnI registri SI e DIsono inizializzati con l'indirizzo della stringa sorgente e della stringa destinazione.nCX deve essere inizializzato con la lunghezza della stringa.nL'istruzione REP MOVSB ripete l'esecuzione di MOVSB finché CX=0.nIn ogni iterazione, il valore dei registri SI e DI viene incrementato/decrementato.
Riccardo Torlone -Corso di Calcolatori Elettronici87"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#86,86,"Esempio (1)
Riccardo Torlone -Corso di Calcolatori Elettronici88
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#87,87,"Esempio (2)
Riccardo Torlone -Corso di Calcolatori Elettronici89
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#88,88,"Esempio (3)
Riccardo Torlone -Corso di Calcolatori Elettronici90
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#89,89,"Esempio (4)
Riccardo Torlone -Corso di Calcolatori Elettronici91
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#9,9,"Riccardo Torlone -Corso di Calcolatori Elettronici10Confronto con i registri del Core i7
"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#90,90,"Operazioni su array e stringhe: LODSBL'istruzione LODSB trasferisce il contenuto del byte di memoria indirizzato dal registro DI nel registro AL.nSintassi: LODSB [No Operandi]nL'indirizzo di memoria del dato da trasferire deve trovarsi in DI.nLa destinazione è il registro AL.nAl termine dell'operazione, il registro DI viene incrementato o decrementato a seconda del valore corrente del bit di direzione nel registro di flag.nLODSB per operazioni su byte (8bit), LODSW per operazioni su parole (16 bit, destinazione registro AX).
Riccardo Torlone -Corso di Calcolatori Elettronici92"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#91,91,"Operazioni su arraye stringhe: STOSBL'istruzione STOSB trasferisce il contenuto del registro AL nel byte di memoria indirizzato dal registro DI.nSintassi: STOSB [No Operandi]nIl dato da trasferire deve trovarsi in AL.nL'indirizzo di memoria della destinazione deve trovarsi in DI.nAl termine dell'operazione, il registro DI viene incrementato o decrementato a seconda del valore corrente del bit di direzione nel registro di flag.nSTOSB per operazioni su byte (8bit), STOSW per operazioni su parole (16 bit).
Riccardo Torlone -Corso di Calcolatori Elettronici93"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#92,92,"Operazioni su arraye stringhe: CMPSBL'istruzione CMPSB confronta due byte, indirizzati rispettivamente dal registro SI e dal registro DI.nSintassi: CMPSB [No Operandi]nL'indirizzo del primo byte deve trovarsi in SI.nL'indirizzo del secondo byte deve trovarsi in DI.nAl termine dell'operazione, i registri SI/DIvengono incrementati o decrementati a seconda del valore corrente del bit di direzione nel registro di flag.nCMPSB per confronto tra byte (8bit), CMPSW per confronto tra parole (16 bit).
Riccardo Torlone -Corso di Calcolatori Elettronici94"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#93,93,"Operazioni su arraye stringhe: SCASBL'istruzione SCASB confronta il byte indirizzato dal registro DI con il contenuto del registro AL.nSintassi: SCASB [No Operandi]nL'indirizzo del primo byte deve trovarsi in DI.nIl secondo byte deve trovarsi in AL.nAl termine dell'operazione, il registri DIviene incrementato o decrementato a seconda del valore corrente del bit di direzione nel registro di flag.nIl registro AL non viene alterato, ma i bit del registro di flagvengono modificatinSCASB per operazioni su byte (8bit), SCASW per operazioni su parole (16 bit, confronto con registro AX).Riccardo Torlone -Corso di Calcolatori Elettronici95"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#94,94,"Operazioni su arraye stringhe: REP, REPE, REPNEnREP {MOVSB|MOVSW|LODSB|LODSW|STOSB|STOSW}nRipete l'istruzione fino a fine stringa (CX=0).nREPE (o REPZ) {SCASB|SCASW|CMPSB|CMPSW}nRipete l'istruzione fino a fine stringa (CX=0), oppure fino a quando il confronto fallisce (se ZF=0 ripete, se ZF=1 si ferma).nREPNE (o REPNZ) {SCASB|SCASW|CMPSB|CMPSW}nRipete l'istruzione fino a fine stringa (CX=0), oppure fino a quando il confronto ha successo (se ZF=1 ripete, se ZF=0 si ferma)
Riccardo Torlone-Corso di Calcolatori Elettronici96"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#95,95,"Esercizio VICon riferimento al programma assemblativo 8088 che segue, indicare cosa fa e il valore stampato. "
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#96,96,"Esercizio VI_EXIT = 1_PRINTF= 127 .SECT .TEXTstart:MOV  CX,num-vecSHR  CX,1MOV BX,vecMOV  SI,0MOV  AX,(num)1:CMP  AX,(BX)(SI)JE   2fADD  SI,2LOOP 1bMOV  DX,0JMP  3f2:      MOV  DX,13:PUSH DXPUSH formatPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYS.SECT .DATAvec:   .WORD 3,4,7,11,3num:   .WORD 5format: .ASCII ""%d"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#97,97,"Esercizio VIbis! Equivalente al VI utilizzando pero'l'istruzione SCASW insieme alla REPNE_EXIT= 1_PRINTF= 127 .SECT .TEXTstart:MOV  CX,num-vecSHR  CX,1MOV  AX,(num)MOV  DI, vecCLDREPNE SCASWJE   1fMOV  DX,0JMP  2f1:   MOV  DX,12:PUSH DXPUSH formatPUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYS.SECT .DATAvec:   .WORD 3,4,7,11,3num:   .WORD 11format: .ASCII ""%d"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#98,98,Esercizio VIIScrivere un programma in linguaggio assemblativo 8088 che verifica se due vettori di interi memorizzati in memoria principale sono identici. 
data_test\rootfolder\università\CalcolatoriElettronici2\08 Il linguaggio assemblativo 8088.pdf#99,99,"Esercizio VII_EXIT= 1_PRINTF= 127 .SECT .TEXTinizio:MOV  CX,end1-vec1SHR  CX,1MOV  AX,end2-vec2SHR  AX,1CMP  AX,CXJNE  1fMOV  SI,vec1MOV  DI,vec2CLDREPE CMPSWJNE  1fPUSH ugualiJMP  2f1:PUSH diversi2:PUSH _PRINTFSYSMOV  SP,BPPUSH 0PUSH _EXITSYS.SECT .DATAvec1: .WORD 3,4,7,11,3end1: .SPACE 1vec2: .WORD 3,4,7,11,3end2: .SPACE 1uguali: .ASCII ""Uguali!\0""diversi: .ASCII ""Diversi!\0"".SECT .BSS"
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#0,0,Calcolatori  Elettronici T  Complementi ed Esercizi  di Reti Logiche  
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#1,1,Stefano Mattoccia  Ricevimento : su appuntamento via email    Telefono  : 051 2093860  Email   : stefano.mattoccia@unibo.it  Web   : www.vision.deis.unibo.it/smatt 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#10,10,"OE=0 0 1 U=? Quale valore logico assume U ? 
Che cosa è necessario garantire nella rete seguente ?  Quando il segnale U assume un valore logico significativo ? 1 U=? OE1 OE2 I1 I2 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#11,11,"Esercizio 1  Registro a 1 bit con uscita tri-state Utilizzando latch SR progettare una rete che, quando WE=1,memorizza sulluscita OUT il segnale di ingresso IN. Lultimo valore trasferito in uscita deve essere mantenuto per tutto il tempo in cui il segnale WE=0. La rete deve essere inoltre dotata di un segnale OE che, se a livello logico 0, pone il segnale di OUT nello stato di alta impedenza. WE IN OUT OE ? WE IN OE OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#12,12,"S Q Q* R WE IN OE OUT Soluzione 
La rete tratteggiata (8X) è un latch CD dotato di uscita tri-state ed esiste in forma integrata (‘373). Q 
NOTA - Perché le due reti seguenti NON sono equivalenti ? a b c b a c "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#13,13,"RSA notevoli: Flip-Flop D FFD D CK Q Q* D CK Q Q* FFD: RSA che assume il valore logico presente sull’ingresso D durante i fronti di salita (positive edge triggered) dell’ingresso CK 
Il FFD è tipicamente utilizzato come cella elementare di memoria  nelle reti sequenziali sincrone. In tal caso, il segnale CK, è un segnale di tipo periodico (clock). CK D Q "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#14,14,"FFD D CK Q Q* D CK Q Q* A_SET* A_RES* 
A_RES* A_SET* 
CK D Q* Q I FFD sono dotati di due ulteriori ingressi “asincroni” che consentono di settare (A_SET) o resettare (A_RES) Q indipendentemente da CK e D. A_SET* 
A_RES* Tipica realizzazione di  un FFD della famiglia  TTL (‘374) mediante 3  latch SR.  Q=0 se A_RES=1 Q=1 se A_SET=1  A_SET e A_RES sono  prioritari rispetto  a CK e D NOTA: i segnali asincroni di set e reset denominati nella slide (rispettivamente) A_SET e A_RES  sono spesso denominati (rispettivamente) PR e CL oppure S e R. Inoltre, se non indicati nello  schema logico si suppone che tali comandi siano non asseriti (A_SET=0 e A_RES=0). "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#15,15,"Vincoli di corretto impiego per i FFD   Tempi di Setup (τSU), Hold (τH) e Risposta (τR) FFD D CK Q Q* D CK Q Q* CK D Q τH τSU τR Il corretto funzionamento è garantito solo se τSU≥ τSUmin e τH ≥ τHmin. In caso contrario, metastabilità.   Cosa implicano i parametri τSUmin e τRmin indicati nei datasheet ? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#16,16,"Il FFD come elemento fondamentale delle RSS 
D CK Q Se all’ingresso CK viene inviato un segnale periodico (clock):   il FFD ritarda (D = Delay) il segnale di uscita Q, rispetto al  segnale di ingresso D, di un tempo pari al periodo di clock T  Qn+1 = Dn FFD D CK Q Q* D CK Q Q* 
T T T T "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#17,17,"Vincoli di campionamento e metastabilità Il mancato rispetto dei vincoli sul campionamento dei segnali porta  a metastabilità.  CK D Q τSU τH ???????????? 
0 1 metastabile 
stabile stabile ? ? 1? 0? τ = ??? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#18,18,"Sincronizzazione di segnali (non sincroni) FFD D CK Q I metastabile FFD D CK Q Stabile (?) I_sync I_M Normalmente i segnali provenienti dall’esterno (ma non solo) non sono sincroni con il clock della RSS. Questo è un problema molto comune.   Come gestire potenziali situazioni di metastabilità che potrebbero  compromettere il corretto funzionamento della RSS?  
CK •  La soluzione mostrata garantisce che l’uscita I_sync assume il valore   di I nel momento in cui tale segnale è stato campionato?   •  Sono sufficienti due livelli di FF?  •  Quali sono gli effetti collaterali di questa soluzione? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#19,19,Reti Sequenziali Sincrone (RSS) ? k (k) FFD k k FFD sull’anello di retroazione  Tutti con lo stesso clock di periodo T S S* S S* CK S U S* It t+T t+2·T t-T Nel caso specifico: Moore o Mealy ? Lo stato cambia anche se non cambia l’ingresso ? L’uscita cambia anche se non cambia l’ingresso ? CK 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#2,2,"Introduzione Reti Logiche: sintesi mediante approccio “formale” 
Calcolatori Elettronici: sintesi mediante approccio “diretto” Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL 
Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#20,20,"Alcune considerazioni sulle RSS •  Lo stato della rete cambia solo in corrispondenza dei fronti di   salita del clock che si susseguono con periodo T  •  La rete risponde ogni T ⇒ se si desidera massimizzare la velocità   di risposta della rete è necessario adottare il modello di Mealy   •  La rete è svincolata dai ritardi della rete G! Quindi, nessun   problema di corse critiche (purché T > τSUmin + τRmin !)  •  All’interno di uno stesso progetto sono tipicamente presenti più    RSS e non necessariamente per tutte le RSS il clock è lo stesso   e/o coincide con il clock del processore  •  Le RSS sono (più) facili da progettare delle RSA "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#21,21,"Clock gating e glitch sul clock Nelle reti sincrone è necessario evitare variazioni spurie (glitch) del segnale di clock che possono provocare commutazioni indesiderate dei FFD.   Ad esempio, per via dei reciproci ritardi tra i t segnali D[t-1..0] e/o le alee introdotte dalla rete combinatoria di decodifica, a causa del “clock gating“, può verificarsi quanto segue FFD D CK Q Q* D CK Q Q* CK P CK_G 
CK_G Glitch sul clock → commutazione spuria del FFD ! NO !! Rete di  Decodifica D[t-1..0] P t "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#22,22,"Il clock gating, oltre a generare potenziali glitch introduce  “clock-skew”. Ad esempio, consideriamo le due RSS seguenti Clock gating e clock-skew 
CK CK_G τAND FFD D CK Q Q* I1 CK B B* CK_G 1 FFD D CK Q Q* I2 CK A A* τAND 
τAND I clock delle due reti sono sfasati di un tempo pari al ritardo introdotto dall’AND. Tale fenomeno (“clock-skew”) è potenzialmente dannoso. Perchè ? 
Il “clock-skew” non è causato solo dal clock gating ma anche (ad esempio) da percorsi elettrici di lunghezza diversa. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#23,23,"Esercizio 2  Progettare un registro a 8 bit con uscita tri-state utilizzando FFD positive edge triggered.  La rete, ad ogni fronte di salita del clock, memorizza il byte IN[7..0] in ingresso se WE=1 mentre mantiene il valore precedentemente memorizzato in caso contrario (WE=0). L’uscita OUT[7..0] della rete deve essere posta nello stato di alta impedenza quando il segnale OE=0. Inoltre, la rete deve essere dotata di un ingresso asincrono di RESET (A_RESET) che, se 1, pone al livello logico 0 l’uscita OUT[7..0] indipendentemente dal valore dei segnali WE, IN e CK. Quali condizioni devono essere soddisfatte perché sia garantito il corretto funzionamento della rete ? ? WE A_RESET IN[7..0] CK OUT[7..0] OE WE IN[7..0] OE OUT[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#24,24,"WE OE FFD D Q Q* R IN OUT 0 1 Q A_RESET Soluzione Caso singolo bit 
NOTA  - Per garantire il corretto funzionamento della rete è   necessario rispettare tempi di setup e hold  - Il FFD esiste (8X) in forma integrata (74XX374) ed è dotato   di comando di OE CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#25,25,"NOTA  - La soluzione seguente NON è corretta in quanto:       a) variazioni spurie (glitch), dovute a instabilità del        segnale WE, possono causare commutazioni indesiderate         del flip-flop       b) il gate ritarda il segnale di clock del FFD e potrebbe        causare potenziali sfasamenti (“clock-skew”) tra i clock        dei vari componenti della rete sincrona complessiva WE OE FFD D Q Q* R IN OUT Q A_RESET CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#26,26,"FFD D Q Q* R IN7 WE OE OUT7 0 1 
FFD D Q Q* R IN1 OUT1 0 1 
FFD D Q Q* R IN0 OUT0 0 1 Q7 
Q1 Q0 A_RESET Estensione a 8 bit CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#27,27,"Estensione a 8 bit (meglio) 
WE OE FFD D Q Q* R IN[7..0] OUT[7..0] 0 1 Q[7..0] A_RESET CK 8 8 8 8 8 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#28,28,"Esercizio 3  Progettare una rete che periodicamente dopo tre periodi di clock setta al livello logico 1 la propria uscita per un periodo clock. 
A_RESET CK OUT 
CK OUT (0) (1) (2) (0) (1) (2) (3) (3) ? OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#29,29,"COUNTER X4 Una possibile soluzione si basa sullutilizzo di un contatore modulo 4.  Soluzione 3.1  
CK u1 u0 OUT A_RESET Progettare un contatore modulo 4…. A_RES Perchè ? u1 u0 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#3,3,"Modello della Macchina a Stati Finiti (FSM) - Mealy F G k n I? r U S S* U=F(S,I) S*=G(S,I) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#30,30,FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#31,31,"Contatore modulo 4 con comando di ENABLE (EN) 
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 EN 0 1 EN "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#32,32,"0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 UP/DOWN (U/D*)  
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 U/D* "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#33,33,Contatore modulo 4 con LOAD (L) FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 1 0 L 1 0 L i0 i1 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#34,34,"Esercizi E3-1) Progettare un contatore modulo 4 dotato dei segnali       U/D*, EN e L nei seguenti 2 casi:   a) segnale L prioritario rispetto a EN    b) segnale EN prioritario rispetto a L       In entrambi i casi si supponga che U/D* sia il     segnale meno prioritario tra i tre.  E3-2) Progettare un contatore modulo 8  E3-3) Progettare un contatore modulo 5 utilizzando un       contatore modulo 8 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#35,35,Osservando le forme donda mostrate sotto si può ottenere una soluzione alternativa alla precedente (3.1) Soluzione 3.2  CK u1 u0 OUT (0) (1) (2) (0) (1) (2) (3) (3) 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#36,36,FFD D Q Q* R* CK A_RESET* FFD D Q Q* R* OUT NOTA - Questa soluzione non può essere ottenuta con il metodo   della sintesi formale studiato a Reti Logiche 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#37,37,"ττττNOTA - Non è il caso della rete della pagina precedente, ma la   presenza di alee può creare problemi alle reti che seguono   se queste utilizzano come ingresso di clock un segnale che    presenta oscillazioni spurie (glitches).    Si consideri ad esempio il caso seguente: 
FFD D Q Q* c b a 1 1 IN OUT S u u S τττ
Alea statica: provoca un campionamento indesiderato del FFD "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#38,38,NOTA -  Le alee possono essere eliminate introducendo ulteriori   gates (vedi reti logiche)   -  In alcuni casi le alee possono essere filtrate dagli   stessi gates (ad esempio nel caso di ‘lentezza’ dei   dispositivi rispetto ai tempi del glitch); questa   possibilità deve essere verificata attentamente   analizzando i datasheets dei componenti utilizzati a b c a b c Un impulso troppo breve potrebbe essere filtrato dallAND 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#39,39,"Soluzione canonica ottenuta mediante sintesi formale. Soluzione 3.3  
A,0 B,0 C,0 D,1 Grafo degli stati  
Tabella di flusso  sn sn+1 sn,u u A B 0 B C 0 C D 0 D A 1 Tabella delle  transizioni  y1n y0n u 0 0 0  1 0 0 1 1  0 0 1 0 1  1 0 1 1 0  0 1 y1n+1 y0n+1 Sintesi minima (mappe di Karnaugh,…) u = y1n·y0n y0n+1 = y0n* y1n+1 = y1n XOR y0n "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#4,4,"F G k n I? r U S S* U=F(S) S*=G(S,I) Modello della Macchina a Stati Finiti (FSM) - Moore "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#40,40,"FFD D Q Q* FFD D Q Q* XOR y0 y1 R* R* CK u NOTA  - Se si desidera aggiungere un segnale di ENABLE alla rete   precedente mediante il metodo della sintesi formale ?   - E necessario ripetere tutti i passi precedenti (grafo,   diagramma stati, …) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#41,41,Esercizio 4  Progettare un registro a scorrimento (shift-register) a 3 bit. ? IN A_RESET CK OUT1 OUT2 OUT0 IN A_RESET O1 O2 O0 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#42,42,"CK IN A_RESET OUT1 Soluzione 
OUT2 OUT0 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#43,43,"FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* IN OUT2 OUT1 OUT0 
CK Esercizi E4-1) Progettare uno shift-register dotato di comandi         di enable EN e LOAD (parallelo e prioritario         rispetto allenable).  E4-2) Utilizzando due shift-register a 4 bit e un        contatore modulo 8: progettare un convertitore         serie parallelo a 8 bit dotato di un segnale (ACK)    che comunica lavventura ricezione degli 8 bit.  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#44,44,Esercizio 5  Progettare una rete sincrona dotata di un ingresso  IN e di un’uscita OUT. L’uscita OUT deve asserirsi esattamente per un periodo di clock se viene rilevata una transizione da 0 a 1 del segnale di ingresso (monoimpulsore). Si noti che il segnale di ingresso potrebbe anche essere non sincrono (purché rispetti tempi di setup  e hold) ? IN CK OUT CK IN OUT IN OUT 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#45,45,"FFD D Q Q* FFD D Q Q* IN OUT CK Soluzione 
CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#46,46,"FFD D Q Q* IN OUT CK Perchè questa soluzione è sbagliata (1) ? 
CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#47,47,"Perchè questa soluzione è sbagliata (2) ? 
FFD D Q Q* IN OUT CK CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#48,48,"Perchè questa soluzione è sbagliata (3) ? 
FFD D Q Q* IN OUT CK CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#49,49,"Esercizio 6  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati sull’ingresso IN[7..0] mentre il segnale EN era a livello logico 1 sono stati FFh (primo carattere della sequenza), 27h e 30h. Nel caso sia rilevata la sequenza FF-27-30, nel periodo di clock successivo a quello dell’ultimo carattere ricevuto (30h), deve essere asserita l’uscita OUT e rimanere tale fino a che non viene asserito il segnale (asincrono) di reset A_RESET. In seguito ad un reset deve riprendere immediatamente il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere. ? EN A_RESET IN[7..0] CK OUT EN A_RESET IN[7..0] OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#5,5,"Reti Sequenziali Asincrone (RSA) ? k τk Retroazione diretta (τ: ritardo intrinseco della RC G) S U S* IS S* S S* 
t t+τ(1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#50,50,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#51,51,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK DEC_30 DEC_27 DEC_FF OE* OE* 0 0 Soluzione 6.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#52,52,"Soluzione 6.2 
CK A_RESET* LOAD ENABLE 0 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Una soluzione alternativa utilizzando un contatore dotato di  comando di LOAD 
Cè un problema… "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#53,53,"CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  .. nella soluzione della pagina precedente cosa accade se i  caratteri ricevuti (con EN=1) sono FF-FF-27-30 ? 
DEC_FF "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#54,54,"Esercizi E5-1) Riprogettare la rete dellesercizio 6 in modo che     OUT assuma il valore logico 1 in seguito alla     ricezione anche non consecutiva (con EN=1) dei     caratteri FFh, 27h e 30h.          Ad esempio, OUT=1 se i caratteri ricevuti (mentre     EN=1) sono stati: FF-7A-80-9F-27-B2-30-…  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#55,55,"Esercizio 7  Modificare lesercizio precedente in modo che, in seguito al rilevamento della sequenza, luscita OUT assuma il valore logico 1 per un solo periodo di clock. Appena ricevuta una sequenza completa il controllo dei caratteri in ingresso deve riprendere immediatamente. ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#56,56,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) Soluzione 7.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#57,57,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* A_RESET* 
A_RESET* CK CK 
CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#58,58,"Soluzione 7.2 
CK A_RESET LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30* + OUT ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Rispetto allesercizio 6.2 è sufficiente modificare il comando di LOAD facendo in modo che LOAD=1 quando OUT=1 ?  
EN·DEC_FF 
Cosa accade se (con EN=1) la sequenza è 45-FF-27-30-FF-27-30-… ? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#59,59,"Esercizi E6-1) Riprogettare la rete dellesercizio 6 in modo che    OUT=1 in seguito alla ricezione anche non consecutiva    (con EN=1) dei caratteri FFh, 27h e 30h.         Ad esempio, OUT=1 se i caratteri ricevuti mentre EN=1    sono stati: FF-7A-80-9F-27-B2-30-…   E6-2) Cosa accade alle soluzioni 6.1 e 6.2 se (mentre EN=1)       la sequenza è: 45-FF-27-30-FF-27-30-… ?  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#6,6,"•  Le reti asincrone rispondono molto rapidamente (appena possibile)   alle variazioni degli ingressi •  Non è necessario un segnale di sincronismo (clock) •  Ridotta dissipazione di potenza Aspetti positivi delle RSA (vs RSS) Aspetti negativi delle RSA (vs RSS) •  Vincoli per il corretto impiego   - l’ingresso può variare solo quando la rete ha raggiunto     una condizione di stabilità   - i segnali di ingresso possono variare uno alla volta •  Esposte a potenziali malfunzionamenti (corse critiche)  •  Difficili da progettare In pratica, sono utilizzate per realizzare latch e flip-flop.  A noi interessano (maggiormente) le reti sincrone (RSS) ! "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#60,60,"Esercizio 8  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati in ingresso IN[7..0] mentre il segnale EN=1 sono stati FFh (primo carattere della sequenza), 27h  e 30h. Nel caso sia rilevata tale sequenza, due periodi di clock successivi a quello dell’ultimo carattere della sequenza ricevuto deve essere asserita l’uscita OUT e rimanere tale fino a che il segnale di reset (asincrono) A_RESET non assume il valore logico 1. In seguito ad un reset (asincrono) la rete deve riprendere immediatamente  il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere.  ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#61,61,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 18h 16h 80h 
OUT (1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#62,62,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK FFD D Q Q* R* A_RESET* CK Soluzione 8.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#63,63,CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = (ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*)·OUT_1*  ENABLE = (ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30)·OUT_1*  DEC_FF Soluzione 8.2 FFD D Q Q* R* A_RESET* CK OUT_1 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#64,64,"Esercizio 9  Progettare una rete dotata di tre ingressi E, A/I*, A_RES e unuscita OUT. Il segnale di ingresso A/I* influisce sulla rete solo se contemporaneamente E=1. Luscita della rete deve andare al livello logico 1 per un periodo di clock se viene rilevato per cinque volte, anche non consecutive, il valore 1 del segnale A/I* in presenza del segnale E=1. Ogni volta che il segnale A/I* assume il valore 0 (con E=1) deve essere ridotto di uno il numero di eventi rilevati fino a quel momento. Successivamente a un reset (segnale asincrono) o nel caso nessun evento sia stato ancora rilevato (o che il numero di incrementi sia stato compensato da un numero equivalente di decrementi la rete deve rimanere nello stato 000 anche se A/I*=0 ed E=1. Dopo avere rilevato cinque eventi la rete deve riprendere l’analisi degli ingressi. ? E A/I* A_RESET CLOCK OUT OUT E A/I* A_RES "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#65,65,"COUNTER X 8 EN U/D# LOAD I2 I1 I0 O2 O1 O0 E A/I* OUT OUT CLOCK 0 0 A/I* 
O2 O1 O0 A/I* RESET A_RESET Soluzione 9.1 E L’OR blocca il conteggio (EN=0), anche con E=1, se il contatore si trova nello stato 000 e il comando DOWN è asserito (A/I*=0). Perché ? 
O1 è strettamente necessario ?  (No, perché ?) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#66,66,"A,0 B,0 C,0 D,0 E,0 F,1 E A/I* 0 – 1 0 0 – 0 – 0 – 0 – 1 1 1 1 1 1 1 1 1 1 1 1 0 – 1 0 1 0 1 0 1 0 1 0 Soluzione mediante sintesi formale: grafo -> tabella di  flusso -> tabella delle transizioni,... NON SI USA !!!! Soluzione 9.2 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#67,67,Esercizio 10  Utilizzando un microprocessore dotato di un bus indirizzi a 16 bit e di un bus dati a 8 bit: mappare nello parte bassa dello spazio di indirizzamento 12k di RAM e nella parte alta 16k di EPROM. 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#68,68,"Soluzione RAM (12K) 
EPROM (16K) 0000h  2FFFh 
C000h FFFFh A15..A12 A11..A8 A7..A4 A3..A0 0000 0000 0000 0000 (0000h)  
1111 1111 1111 1111 (FFFFh) 0010 1111 1111 1111  (2FFFh) 
1100 0000 0000 0000 (C000h) RAM_1 (8k) RAM_2 (2k) RAM_3 (2k) 
EPROM (16k) 0001 1111 1111 1111 (1FFFh)  0010 0000 0000 0000  (2000h) 0010 0111 1111 1111  (27FFh) 0010 1000 0000 0000  (2800h) CS_RAM_1=A15*·A13* CS_RAM_2=A15*·A13· A11* CS_RAM_3=A15*·A13· A11 CS_EPROM=A15 Segnali di decodifica: "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#69,69,"- Il segnale CS_EPROM si attiva per ogni indirizzo maggiore   o uguale di 8000h (seconda metà dello spazio di   indirizzamento) 0000h  
C000h FFFFh 8000h Indirizzi di memoria con A15=1 CS_EPROM=A15 NOTA  - La codifica semplificata implica lattivazione dei   segnali di selezioni anche per indirizzi diversi da   quelli in cui sono realmente presenti i dispositivi    di memoria.  
EPROM (16K) EPROM (16K) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#7,7,"RSA notevoli: Latch SR SR S R Q Q* S R Q Q* S R 0 0 0 1 1 0 1 1 Q Q* Q Q* 0 1 1 0 
Q = S’ ↑ (q ↑ R’) S’ R’ Q Q*  Q = R ↓ (S ↓ q) S R Q Q*  
I comandi di set e reset devono avere una durata minima (vedi datasheet) per consentire il raggiungimento della condizione di stabilità "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#70,70,"- Il segnale CS_RAM_1 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=0:  0000h  
FFFFh 8000h CS_RAM_1=A15*·A13* RAM_1 (8k) A15..A12  A11..A8    A7..A4   A3....A0 0000  0000  0000  0000 (0000h)  0001  1111  1111  1111 (1FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0100  0000  0000  0000 (4000h)  0101  1111  1111  1111 (5FFFh)  Quindi, CS_RAM_1=1 per entrambi i  seguenti intervalli di memoria: 1FFFh  4000h RAM_1 (8k) 5FFFh "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#71,71,"- Il segnale CS_RAM_2 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=0 :  0000h  
FFFFh 8000h CS_RAM_2=A15*·A13·A11* A15..A12  A11..A8    A7..A4   A3....A0 0010  0000  0000  0000 (2000h)  0010  0111  1111  1111 (27FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  0000  0000  0000 (3000h)  0011  0111  1111  1111 (37FFh)  Quindi, CS_RAM_2=1 per i seguenti quattro intervalli di memoria: 2000h  4000h 6000h A15..A12  A11..A8    A7..A4   A3....A0 0110  0000  0000  0000 (6000h)  0110  0111  1111  1111 (67FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  0000  0000  0000 (7000h)  0111  0111  1111  1111 (77FFh)  RAM_2 (2k) RAM_2 (2k) 3000h  RAM_2 (2k) RAM_2 (2k) 7000h "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#72,72,"- Il segnale CS_RAM_3 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=1 :  0000h  
FFFFh CS_RAM_3=A15*·A13·A11 A15..A12  A11..A8    A7..A4   A3....A0 0010  1000  0000  0000 (2800h)  0010  1111  1111  1111 (2FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  1000  0000  0000 (3800h)  0011  1111  1111  1111 (3FFFh)  Quindi, CS_RAM_3=1 per i seguenti quattro intervalli di memoria: 2800h  6800h A15..A12  A11..A8    A7..A4   A3....A0 0110  1000  0000  0000 (6800h)  0110  1111  1111  1111 (6FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  1000  0000  0000 (7800h)  0111  1111  1111  1111 (7FFFh)  RAM_3 (2k) RAM_3 (2k) 3800h  RAM_3 (2k) RAM_3 (2k) 7800h "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#73,73,"0000h  
FFFFh 2800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 2000h  3800h  RAM_2 (2k) RAM_3 (2k) 3000h  4000h  6800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 6000h  7800h  RAM_2 (2k) RAM_3 (2k) 7000h  EPROM (16K) EPROM (16K) 8000h  C000h Effetto di replica nella mappatura in memoria dovuto alla  decodifica semplificata. Nella figura seguente sono indicati  solo gli indirizzi iniziali. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#74,74,"Esercizio 11  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:  - mappare nello parte bassa dello spazio di indirizzamento    32k di RAM e nella parte alta 32k di EPROM   Nel sistema sono presenti anche due dispositivi di I/O denominati D1 (dotato di due registri interni) e D2 (dotato di quattro registri interni):  - mappare in memoria anche i due dispositivi di I/O D1 e    D2 agli indirizzi 2000h e 1000h  Osservando che esiste una sovrapposizione tra gli indirizzi di una memoria e dei due dispositivi di IO, si scrivano i CS, in forma semplificata, di tutti i dispositivi presenti nel sistema riducendo al minimo gli indirizzi “sottratti” dai dispositivi di IO alla memoria. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#75,75,"Soluzione  RAM: 1 chip da 32KB RAM  (00000h->07FFFh) CS_RAM = BA19*·CS_D1*·CS_D2*   EPROM: 1 chip da 32KB EPROM (F8000h – FFFFFh) CS_EPROM = BA19   D1: Mappato in memoria allindirizzo 02000h, occupa 2 locazioni (A0)     nello spazio di indirizzamento. CS_D1 = BA19*·BA14*·BA13·BA12*·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·          BA5*·BA4*·BA3*·BA2*·BA1*   D2: Mappato in memoria allindirizzo 01000h, occupa 4 locazioni (A1A0) nello spazio di indirizzamento.  CS_D2 = BA19*·BA14*·BA13*·BA12·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·       BA5*·BA4*·BA3*·BA2*  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#76,76,"Esercizio 12  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:    - mappare 32k di RAM nella parte bassa dello spazio di    indirizzamento, 32k di RAM a partire dallindirizzo     1C000h e 64k EPROM nella parte alta dello spazio di    indirizzamento "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#77,77,"RAM_1 (32k) RAM_2 (32k) 
EPROM (64k) 00000h 10000h 20000h 30000h 
F0000h 1C000h    0001 1100 0000 0000 0000  23FFFh    0010 0011 1111 1111 1111     
FFFFFh Soluzione 00000h    0000 0000 0000 0000 0000  07FFFh    0000 0111 1111 1111 1111     
F0000h    1111 0000 0000 0000 0000  FFFFFh    1011 1111 1111 1111 1111     CS_RAM_1=A19*·A17*·A16* CS_RAM_2=A19*·(A17 + A16) CS_EPROM=A19 CS_RAM_2=A19*·CS_RAM_1* oppure "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#8,8,RSA notevoli: Latch CD CD C D Q Q* C D Q Q* C D 0 0 0 1 1 0 1 1 Q Q* Q Q* Q Q* 0 1 1 0 SR S R Q Q* C D Q Q* C D Q τSU τH τSU ≥ τSUmin τH≥ τHmin Vincoli: Tempo di risposta: τR > τH Latch CD: il problema/vantaggio delle “uscite trasparenti” 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#9,9,"Driver 3-state 
OE I U OE=0 I U OE=1 I U I OE U Quale è il valore della tensione  ? OE I 1 0 1 1 0 0 0 1 U 0 1 Z Z ? "
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#0,0,"01 IntroduzioneCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#1,1,"DocentiStefanoMattocciaRicevimento:pressostudio,vicinoaula5.7,suappuntamentoconcordatoviaemailEmail:stefano.mattoccia@unibo.itHomepage:http://vision.disi.unibo.it/~smattMatteoPoggi(tutor,AA2020/21)Ricevimento:pressoLaboratoriodiComputerVision,suappuntamentoconcordatoviaemailEmail:m.poggi@unibo.itHomepage:https://mattpoggi.github.io/"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#10,10,"Struttura di una prova d’esame 
Esercizio 1: progetto di un sistema a microprocessore.Per superare l’esame, è necessario proporre una soluzione ragionevole. L’esercizio 1 determina il superamento/non superamentodella prova.Esercizi 2 e 3: domande di teoria che richiedono qualcheragionamento. Volutamente non è fornita la soluzione."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#11,11,"Elaborazione delle informazioni
InputOutputUnessereviventeelaboracontinuamentedelleinformazionieforniscedellerisposteoagisceinundeterminatomodoinbasealleinformazioniiningresso.
Unsistemadiqualsiasinaturaperl’elaborazionedelleinformazioniisolatodall’esternoservirebbeabenpoco(meglio,nulla).Inputeoutputdebbonoesserecodificatiinmodoappropriato
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#12,12,"Elaborazione delle informazioniOvviamente,inquestocorso,siamointeressatiasistemidinaturaelettronicaperelaborareleinformazioni.Inparticolare,perleragionievidenziateaRetiLogicheT,siamointeressatiasistemidigitali->RetiLogiche
InputOutput
RL01101101011101"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#13,13,Elaborazione delle informazioniUnprimoproblema:leretilogicheelaboranoinformazioniditipodigitaleMoltiinputeoutputdiparticolareinteressenonsonodinaturadigitalemaanalogica(quellapreferitadagliesseriumani)•Prossimitàaunsemaforoounostacolo•Monitor•Movimentodelmouse•Voce/Audio•Pressionetasti•Touchscreen•etc
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#14,14,"InputOutput
RLA/D
D/A
Pertanto,è(spesso)necessarioconvertiresegnalidinaturaanalogicainsegnalidigitalieviceversaElaborazione delle informazioni
‘01001101’ ‘110111’ Inunsistemadielaborazione,iningressoeinuscitatroviamosolosegnalidigitali(binari)"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#15,15,Elaborazione delle informazioniAltroproblema:laretelogicacheelaboraleinformazionièspessomoltoefficienti/veloce/etcmaallostessotempopocoflessibileperquantoriguardaillinguaggioutilizzabileperfornireleinformazioni(digitali)ininputeinterpretareleinformazioni(digitali)elaborateinoutput.Sesidesiderainteragireconunsistemadielaborazionedigitaleenecessarioadeguarsiallinguaggiochelaretelogicautilizza.Questolinguaggioècodificatodall’evoluzionetemporaledialcunisegnali(ilminimoindispensabile)emessioricevibilidallaretelogica.L’evoluzionetemporalediquestisegnalisidefinisceciclodibus(buscycle).
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#16,16,"RLElaborazione delle informazioni
ttttttttQuindi,l’unicomodoperinteragireconunsistemadigitaleperl’elaborazionedelleinformazioniconsistenell’adottarequestaconvenzione(ie,iciclidibus,descrittiindettagliosuidatasheetcheilproduttoredelsistemarendesempredisponibili).
ciclo di busciclo di bus"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#17,17,"Quale rete logica utilizzare?Sonodisponibilidiversearchitetturedielaborazione(i,e,retilogiche).Qualescegliere?Dipendedalcontestoapplicativoedalleprestazioni,consumi,ingombri,peso,etc:-sistemageneralpurpose-sistemaembedded-sistemapervideogiochi-etcUnatipologiadiarchitettura,basatasulmodellodiVonNeumann,èmoltopiùflessibiledellealtreepuòessereutilizzata,anchesenonsempreconrisultatiottimali,inognicontesto.Questomodelloèl’oggettodiquestocorsoeutilizzacomeelementodibaseunaCPU(microprocessore)."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#18,18,"Esempi di architetture di elaborazione
19
•CPU(CentralProcessingUnit)•CPUMulticore•CPUEmbedded•SOC(SystemonaChip)•GPU(GraphicProcessingUnit)•FPGA(FieldProgrammableGateArray)•Sistemiibridi(e.g.FPGA+CPU)•..."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#19,19,■Architetturadeltuttogeneralecheportaarealizzazionipocodipendentidalfunzionamentodesiderato■Ilfunzionamentodesideratoèespressointerminidi✸sequenzadiistruzioni(programma)✸memorizzatesuunsupportodimemoria■Percambiarefunzionamentoèsufficientecambiareilprogramma:questodifattomodificalaretelogicadicontrolloperogniistruzioneeseguita■L’architetturaèadattaatrattareproblemimoltopiùcomplessidiquellivistinelcorsodiretilogichemaconefficienza(tipicamente)inferiore■L'importanzaeladiffusionedeicalcolatoridipendefortementedallaflessibilitàdiquestomodelloIl modello di riferimento: Von Neumann
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#2,2,"Obiettivi del corsoApprendere,•i principi di funzionamento•le architetture•la progettazione hardware e softwaredei sistemi per l’elaborazione delle informazioni basati microprocessore(o CPU –Central Processing Unit)
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#20,20,"Rete combinatoriaUscite OjIngressi Xi  Variabilidi statoYk(n+1)Variabili di statoYk(n)Rete Sequenziale(Sincrona)RegistriSistema di elaborazione: rete sequenzialeIl sistema di elaborazione può essere schematizzato in modoastratto come una Rete Sequenziale (Sincrona), RSS"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#21,21,"Come cambiareil funzionamento della RL?
RegistriUscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RetecombinatoriaSegnali dicontrolloProgramma(software)RispettoaRetiLogiche,lanovitàèilsoftware(programma)checonsentedivariareilfunzionamentodellareteinbasealleesigenzedesiderate(ie,ilcodicescrittodalprogrammatore)."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#22,22,"In realtà le cose sono più complesse
Uscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RCSegnali dicontrolloProgramma(software)Unità dicontrollo(RSS)Istruzioni (dalla memoria)
LunitàdicontrollononsologovernalaretecombinatoriamaanchetuttelealtreretilogichepresentinelsistemaEsempio:abilitagliingressieleuscitequandonecessario,etcRegistri
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#23,23,"•Ilprogrammarisiedeinmemoriaedècostituitodaistruzionicodificateinformabinaria(linguaggiomacchina)•Inmemoriarisiedonoancheglioperandidelleistruzioni,cioèidatielaboratiedaelaborare(formabinaria)•LeistruzionivengonoeseguiteinsequenzadallaCPU•LaCPUèunamacchinasequenzialesincrona(conunclock)Modello di esecuzione del programma
Uscite
istruzioniIngressiCPUIstr. #1Istr. #2. . .Istr. #NCk"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#24,24,"Alivellodimassimaastrazione,ilfunzionamentodell’interosistemapuòesseredescrittomedianteduesolistati:–StatoincuilaCPUleggeinmemorialaprossimaistruzionedaeseguire(INSTRUCTIONFETCHoIF)–StatoincuilaCPUeseguelistruzionelettainIF(EXECUTEoEX)ISTRUCTIONFETCH(IF)EXECUTE(EX)
CPUIstr. #1Istr. #2. . .Istr. #N"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#25,25,"RL CPU e istruzioni•Leretilogichevistearetilogicheelaboravanoeproducevanosegnalibinari•SelaCPUèunaRL,comesonocodificateleistruzioni?•Ovviamenteinbinario...•Esempioistruzione#1->00010100000101111101010000010011istruzione#2->10110101100100011001010000011001......istruzione#N->01010110100101010101010110011110•OgniistruzioneindicaallaCPUqualeoperazionedevesvolgere/eseguire•Nonsembraessereunmodomoltocomodo(pergliesseriumani)"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#26,26,"Esempi di istruzioni•QualiistruzionipossonoessereeseguitedaunaCPU?•Somme•Moltiplicazioni•Divisioni•Confronto•Letturedallamemoriaodaaltridispositivi*•Scrittureinmemoriaoversoaltridispositivi*•...EsistonosostanzialmenteduetipologiediCPU:•RISC(ReducedInstructionSetComputer)Pocheesempliciistruzioni,retilogichesempliciemoltoveloci(frequenzadiclockelevata).eg,ARM•CISC(ComplexInstructionSetComputer)Molteistruzioni,alcunemoltocomplesse,retilogichecomplicate.eg,InteleAMD"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#27,27,"RISC vs CISC•TipicamenteaunasolaistruzioneCISCcorrispondonopiùistruzioniRISC•Tuttavia,ognisingolaistruzioneRISCèeseguitaspessopiùrapidamentediunaistruzioneCISC•Spesso,ilcodiceRISC,anchesepiùdenso,èpiùveloce•LeRLRISCsonotipicamentepiùsemplicidiquelleCISC•Seleretisonopiùsemplicilospazio(silicio)puòessereutilizzatoperaltrefinalità(registri,cache,etc)•IprocessoriRISCsonomoltodiffusi(smartphone,tablete)•AncheiprocessoriCISCsonomoltodiffusi(PC)perviadelsoftwareesistente*•LeCPUCISCmodernesonoinrealtàinternamentedeiRISC"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#28,28,"•IndipendentementedaltipodiCPU,leistruzioniinformabinarianonsonofacilmenteinterpretabilieperquestononutilizzateinquestaformaquandosiscriveilcodice•Illinguaggiochesiutilizzaèl’assembler:ADDR1,R2,R3;poneinR1lasommatraregistriR2eR3Questaistruzionepotrebbeesserecodificatacon:00010100000101111101010000010011Iltraduttoreassembler->codicemacchinainbinarioèunaLookUpTable(LUT),ovverounatabellaL’assemblersembraessereunpassoavantinotevolema...Perchénonavetemaiutilizzatoillinguaggioassemblernonostantescrivetecodicedalprimoanno?Istruzioni in forma più comprensibile"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#29,29,"Compilatore e istruzioni binarie•Ilmotivoècheavetescrittocodiceadaltolivello(C)eutilizzatouncompilatore(e.g.,GCC)•Ilcompilatore,converteilcodicescrittoinlinguaggioadaltolivelloinistruzionimacchinabinarie#include<stdio.h>intmain(intargc,char**argv){inta=5;intb=6;intc;c=a+b;printf(“Lasommatra%de%dè%d\n”,a,b,c);}GCC0001010000010111110101000001001110110101100100011001010000011001. . .01010110100101010101010110011110"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#3,3,Orario lezioniOrario ufficiale:https://corsi.unibo.it/laurea/IngegneriaInformatica/orario-lezioni?anno=2&curricula=Lunedì inizio ore 9.00-11onlineGiovedì inizio ore 14.00-17.00Aula 6.1
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#30,30,"Come si accede alla memoria (e non solo)?•SappiamocheilcodicenelmodellodiVonNeumannrisiedeinmemoria•Comesilegge(escrivedallamemoria)?•Comesileggonoescrivonoidati?
CPU
?•L’unico modo è attraverso dei segnali predefiniti (con un ben definito andamento temporale, ciclo di bus)  "
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#31,31,"IndirizziBA[K..0]DatiBD[R..0] READControlloWRITEREADYINT
CPU
K+1R+1
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#32,32,"Come avviene la comunicazione?CPU
K+1MemoriaPeriferica#i
R+1•Tutto viaggia sui bus di sistema•Tutto è regolato da cicli di bus"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#33,33,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#34,34,CKADDRESSMEMRDMEMWRDATADATA_OUTReady?Esempio di ciclo di scrittura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#35,35,"Range di indirizzi•Sesonodisponibili32bit(BA[31..0])èpossibileavereaccessoa2^32elementi(memorie,periferiche)•32segnalidiindirizzo,4GB•Aogniindirizzoèassociatoundispositivo(memorie,periferiche)•E’necessariodecodificarel’indirizzoemessodallaCPUperdeterminareconqualedispositivolaCPUintendecomunicare•Quantibytepossonoesseretrasferitiduranteunciclodibus?Dipendedall’ampiezzadelbusdati"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#36,36,"Relazione tra hardware e software•ConsideriamounaistruzioneperleggeredallamemoriaunbyteaundeterminatoindirizzoxxxLBdestinazione,indirizzo;letturadiunbytePerprimacosaèeseguitoilfetchdell’istruzioneall’indirizzoxxx.come?Conunciclodibus,naturalmenteComefacciamoaconoscerel’indirizzoxxx?LaCPUhaaccessoalprogramcounterPCUnavoltalettaedecodificata,l’istruzioneèeseguita.Durantel’esecuzioneèeseguitounciclodibusdiletturaDuranteilciclodibusèemessol’indirizzo"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#4,4,"Materiale didatticoDisponibile in formato PDF sul sito del corso:http://vision.disi.unibo.it/~smatt/Site/Courses.htmlNel sito sono presenti anche numerose prove d’esameI lucidi non sono un libro, seguire con attenzione le lezioni è fondamentale per superare rapidamente e con buoni risultati l’esame..."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#5,5,"Materiale didattico per approfondimentiSeguendo il corso con attenzione e utilizzando i lucidiforniti NON è necessario utilizzare altro materialeper la preparazione dell’esame.Tuttavia, per chi desiderasse approfondire:–Hennessy & Patterson, ""Computer architecture: a quantitative  approach, Morgan Kaufmann, Anche in versione italiana. La seconda edizione (inglese, a dx) descrive approfonditamente il processore DLX-G. Bucci, Architettura e organizzazione dei calcolatori elettronici. Fondamenti, McGraw-Hill-J. Yiu, The definitive guide to the ARM Cortex M0, Newnes-Patterson &  Waterman, RISC-V, Strawberry Canyon
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#6,6,RequisitiPer superare in modo proficuo il corso di Calcolatori Elettronici T è fondamentale avere compreso bene:1) Fondamenti di Informatica T2) Reti Logiche TPer Reti Logiche T è cruciale la progettazione diretta.Si sconsiglia vivamente di seguire questo corso senza avere solide basi in 1) e soprattutto di Reti Logiche T
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#7,7,"Avvisi e altre comunicazioni Eventuali comunicazione di carattere generale sarannoinserite nella pagina web del corso, nella sezione “Avvisi” di Calcolatori Elettronici T o chat Teams
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#8,8,"Modalità di svolgimento dell’esame •L’esame consiste in una prova SCRITTA di 2.5 ore•Nessuna prova orale• Non è possibile portare libri, appunti, computer, telefoni, smartphone, tablet, smartwatch, etc• E’ indispensabile (pena l’esclusione dall’esame) presentarsi con documento di identitàe badge•Esami gravemente insufficienti saranno verbalizzati"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#9,9,"Prossimi appelli d’esame 
•La date degli esami sono consultabili su Almaesami•L’iscrizioneagli appelli via Almaesamiè obbligatoria e si chiude (circa) una settimana prima• Non è ammessa alcuna deroghe all’iscrizione•Sono previsti 6 appelli all’anno: -3 Dicembre/Febbraio -2 Giugno/Luglio -1 SettembreNessun appello straordinarioSe possibile (aule, etc) il primo appello subito dopo il termine delle lezioni"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#0,0,"02 Mappinge decodificaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#1,1,"Spazio di indirizzamento•Una CPU emette un certo numero di indirizzi e altri segnalisui bus di sistema per comunicare con altri moduli  •Il numero di diversi indirizzi emessi dalla CPU costituiscelo spazio di indirizzamento•Una CPU che emette un indirizzo a 20 bit ha uno spazio diindirizzamento di 1 MB (2^20)•Una CPU che emette un indirizzo a 32 bit ha uno spazio diindirizzamento di 4 GB (2^32)•Le prime CPU avevano spazi di indirizzamento molto ridottodi alcuni KB (e.g., 64 KB o meno)•Oggi è consuetudine avere almeno 32 bit di indirizzo"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#10,10,"11Memorie RAM (SRAM)
•Memorie volatili, leggibili e scrivibili•Capacità a multipli di 4:8K, 32K, 128K, 512K, etc•DRAM: 1 transistore per  bit, maggiore capacità, più lenteAiCE*OE*I/OiTceTaccToe(Out)ReadCycleAiCE*WE*I/OiTawTwp(In)TdsWriteCycleNCA16A14A12A7A6A5A4A3A2A1A0I/O0I/O1I/O2GNDVCCA15NCWE*A13A8A9A11OE*A10CE*I/O7I/O6I/O5I/O4I/O31234567891011121314151632313029282726252423222120191817128K ´8RAM"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#11,11,"12
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#12,12,"13
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#13,13,"14
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#14,14,"15
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#15,15,"16
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#16,16,17Integrati Notevoli: 2441A11A21A31A42A12A22A32A41Y11Y21Y31Y42Y12Y22Y32Y4EN1*EN2*74XX244ENx*xAixYiDriver 3-state ad 8-bit(strutturato in 2 gruppi di 4 bit) 
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#17,17,"18
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#18,18,"19
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#19,19,"20
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#2,2,"Un indirizzo per distribuire merci
WR(consegna)RD(preleva)
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#20,20,21EN*BiDIRAiA1A2A3A4A5A6A7A8B1B2B3B4B5B6B7B8EN*DIR74XX245IntegratiNotevoli: 245Driver bidirezionale (transceiver) ad 8-bit.
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#21,21,"22
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#22,22,"23
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#23,23,"24
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#24,24,"25Integrati Notevoli: 373D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7COE*74XX373
CDiQiOE*OiZCQiDCDiOE*OiLatch CD 
Latch a 8-bit con uscite 3-state"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#25,25,"26Integrati Notevoli: 374D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7CKOE*74XX374
CKDiQiOE*OiZQiDCKDiOE*OiFlip-Flop D
Registro edge-triggeredcon uscite 3-state"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#26,26,
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#27,27,"28
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#28,28,"29
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#29,29,"30Registro Edge-Triggered con WE*WE*D0OE*O0Flip-Flop DMUX10CKDQ0O1Flip-Flop DDQ1MUX10ON-1Flip-Flop DDQNMUX10D1
DN-1D[0..N-1]WE*OE*O[0..N-1]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#3,3,"CPU
Decoder(RC)I livelloCS_ACS_BCS_CCS_DCS_ECS_FCS_GCS_HABCD
EFGHUn indirizzo per distribuire dati (CPU)
Il decoder di II livello è all’interno di ciascundispositivo (memoria, etc) 
BA[K-1..0]BD[R-1..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#30,30,"Register File (1 read-port, 1 write-port)DEC01M-1EN*m  Read_AddressDEC01M-1EN*m  Write_AddressRD*WR*N  Write_DataRead_DataN CKD[0..N-1]WE*OE*O[0..N-1]R0D[0..N-1]WE*OE*O[0..N-1]R1
D[0..N-1]WE*OE*O[0..N-1]RM-1N.B. :M=2m"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#31,31,Mappingdi dispositivi da 8 bit in sistemicon bus dati da 8 bit•Consideriamodispositiviconportadatia8bit•Imponiamo(temporaneamente)lulteriorecondizionecheilparallelismodelbusdatisiaa8bit•Inquesteipotesilassegnamentoaundispositivodiunafinestradiindirizziinunospaziodiindirizzamentoavverràingeneralenelrispettodelledueseguentiulterioricondizionirestrittive:–ladimensionedellafinestradiindirizziassociataaundispositivoèunapotenzadidue–lafinestraècompostadaindirizzicontigui
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#32,32,"33Dimensione della finestra occupata da un dispositivo -esempi•Undispositivoaccessibileattraversoilbusoccupaingeneralen=2^Kposizioninellospaziodiindirizzamento•nrappresentailnumerodioggettia8bitindirizzabiliallinternodeldispositivo(es.numerodicelledimemorianelleRAMedEPROM)•K(numerodibitdiindirizzointernialdispositivo)èfortementevariabilealvariaredeldispositivo:–Ingeneraleneidispositividiinput/output(i.e.,leinterfacce)Kèpiccolo(e.g.,2)–ingeneraleneidispositividimemoriaKègrande(e.g.,perunaRAMda128KBsihaK=17)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#33,33,"Caratteristiche ai morsetti di un dispositivo indirizzabile su una finestra di n = 2^K byteQualunquedispositivoda8bitconall’internon=2^kelementiindirizzabiliseparatamentehaalsuointernoundecoder(IIlivello)diKvariabiliconingressodienablecheselezionaisingolioggettiindirizzabili–Read(RD),dettoancheOutputEnable(OE)èilcomandodilettura.QuandoRDeCSsonoattivi,ildispositivoesponeilsuBD[7..0]ilcontenutodellacellaindirizzata–Write(WR),èilcomandodiscrittura.QuandoCSasseritosulfrontedidiscesediWRècampionatoildaatopresentesuBD[7..0]DISPCSA[K-1..0].RDWRD[R..0]?KBA[K-1..0]CS_DISP8BD[7..0]RDWR"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#34,34,"350K32K8K8K8K8KSpazio di memoria8KDispositivo di memoria fisico che realizza una zona della memoria logica00001FFF0121314Ind. delBloccoIndirizzo interno al blocco
CS = A14 AND A13*(Dispositivo da 8K di memoria)Esempio con 15 bit di indirizzo del sistema 
In questo caso "
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#35,35,"Mapping allineato di dispositivi da 8 bit in sistemi con bus dati da 8 bitSiconsideriundispositivoDdin=2^Kbyteindirizzabili•SidicecheDèmappatoallindirizzoAsegliindirizzideibytediDsonocompresitraAeA+(n-1),cioèseAèlindirizzopiùbassotratuttigliindirizziassociatiaD•SidicecheDèallineatoseAèunmultiplodin(numerodibytesinternialdispositivo),cioèse:(indirizzopiùbassodiD)MODn=0(condizionediallineamento)•SeDèallineatoalloraikbitmenosignificatividiAsonougualiazeroEsempi:•Undispositivodaduebyteèallineatoseèmappatoaunindirizzopari•Unadispositivoda8byteèallineatoseèmappatoaunindirizzoilcuivalorecodificatoinbinarioterminacon3zeri•Undispositivoda16byteèallineatoseilsuoindirizzoinizialeincodiceesadecimalehalaciframenosignificativaugualeazero•Undispositivoda64KBèallineatoseilsuoindirizzoincodiceesadecimalehalequattrocifremenosignificativeugualiazero"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#36,36,"Come individuare univocamente una finestra allineata di 2^K byte in uno spazio di indirizzamento•Supponiamo di mappare un dispositivo D di 2^k bytes(k=4) a un indirizzo A allineato di uno spazio di indirizzamento di 1 MB (bus di indirizzi di 20 bit): •Allora possiamo porre A = α ## (0)k(ex F8570) ove αè una configurazione binaria di 20 -K bit e gli indirizzi associati a D saranno compresi traAmin= A = α ## (0)k e Amax= Amin+ 2k -1 = α## (1)k    (Amin= F8570–Amax=  F857F)•Dunque, possiamo indicare lindirizzo  Aidelli-esimo byte di D come linsieme di due campi concatenati: Ai = α ## i(Ai = F8573)αindividua tra le 2^(20-K) finestre allineate di 2^K byte presenti nello spazio di indirizzamento, quella su cui è mappato (a = F857)iindividua loffset nel chip del byte indirizzato (i = 3)(NB ## è l’operatore simbolico concatenazione)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#37,37,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 1IndirizzamentodiunbytediunaRAMallindirizzo40010Hinunospaziodiindirizzamentodi1MBnellipotesididisporrediunchipda128KBmappatoallindirizzo40000H:Lindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi128KBincuièmappatalaRAM,ilsecondoidentificaloffsetall’internodellaRAM
A0A19A17A16Identificatore dellafinestra di 128Kin cui si trova la RAMOffset del byte indirizzato allinterno del dispositivo di 128KB 0      1       00  0000  0000  0001  0000iα"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#38,38,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 2Indirizzamentodiunbyteall’indirizzo1026HinundispositivodiI/Odi16bytemappatoall’indirizzo1020Hdiunospaziodiindirizzamentodi64KBLindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi16Bincuièmappatoildispositivo,ilsecondoidentificaloffsetneldispositivo
A0A15A4A3Identificatore dellafinestra di 16Bin cui si trova DOffset del byte indirizzato allinterno del dispositivo Ddi 16 Bindirizzato 0 0 0 1       0 0 0 0         0 0 1 00       1        1        0iα"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#39,39,"Decodifica degli indirizzi in caso di mappingallineato•Consideriamounospaziodiindirizzamentodi1MBincuisiamappatoundispositivodi2^Kbyte•PerindividuareunacelladiindirizzoAi=α##ipossiamodecodificaretuttii20bitchecompongonoAi•Questadecodificaèeffettuataricorrendoallastrutturadeidecoderadalbero,conalberodiduelivelli:–IlIlivelloèusatoperdecodificareα(cheidentificalaposizioneincuiilchipèmappato);perdecodificareαdobbiamodecodificare20-Kvariabili–ilIIlivellovieneutilizzatoperdecodificarei(cheidentificailbyteallinternodelchip,serveundecoderdikvariabili)•IldecoderdiIIlivellositrovaallinternodelchipmentreladecodificadiαèacaricodelprogettistadelsistemachepuòutilizzareundecoderdi20-kvariabiliconcuisidecodificaα•Ladecodificaècompletasesiutilizzanotuttii20-Kbitperdecodificareα,semplificatasesiutilizzasolounsottoinsieme(minimo)dei20-Kbit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#4,4,"Condizione di visibilità di un dispositivo da parte del software•Condizionenecessariaaffinchéundispositivofisico(memoria,interfaccia,oaltraentità)siaaccessibilealsoftwareè:–ildispositivodeveesseremappatoinunospaziodiindirizzamento•Mappareinunospaziodiindirizzamentosignifica:–associarealdispositivounafinestradiindirizzidiquellospaziodiindirizzamento•Siaccedeaidispositivimappatiinunospaziodiindirizzamentoconciclidibus"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#40,40,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèdifattoattivato(mappato)induedifferentizonedellamemorialogica00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13*Segliindirizziusatidaunprogrammasonoquellichevannoda16Ka24K(overoda4000Ha5FFFH)equellida24Ka32K(da6000Ha7FFF)nonsonousatialloraèpossibileladecodificaincompletaoparzialeinquantolazona24K-32Knonvienemaiindirizzata.EspressioneCSpiùsemplice
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#41,41,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèattivato(mappato)induedifferentizonedellamemorialogicanonconsecutive00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13Decodifica parziale 2/2
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#42,42,EsercizioSiconsideriunsistemaconbusindirizzia16bitebusdatia8bit.Scrivereleespressionididecodificacompletaesemplificata(quelladausareall’esame)neiseguenticasi:1)Dispositivodimemoriada16KBmappatoa8000h2)Dispositivodimemoriada8KBmappatoa0000h3)EntrambiidispositiviprecedentiSec’èunsolodispositivo(casi1e2)ilCSèmoltoparticolare….
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#43,43,44
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#44,44,"Mapping, read, write e set/reset di un FFD
•Il FFD èun elementaredispositivodi memoria•Con unaCPU, come possiamo:•scriverenelFFD•leggerenelFFD •settareo resettarein modoasincronoilFFD FFDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]?
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassi"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#45,45,"NellepagineseguentiassumiamocheicomandidelFFDsianomappatineiseguentiindirizzi:CS_READ_FFD ->  80003hCS_WRITE_FFD ->  80002hCS_A_RES_FFD ->  80001hCS_A_SET_FFD ->  80000hAssumiamoinoltrediutilizzareilsegnaleBD0delbusdatiperleggereescrivereilsingolobitdidato.Ovviamentesarebbepossibileutilizzarealtriindirizzinonappartenentiallememorieeanchealtrisegnalidelbusdati(anchediversiperlettureescritture).Seiltestodell’esamenonspecificaqualiindirizziusarelasceltaèlasciataallostudente.Spesso,lasceltadegliindirizzisemplifica/complicaisegnalididecodifica."
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#46,46,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#47,47,"CKADDRESS
DATADATA_OUTReady?Esempio di ciclo di scrittura
MEMRDMEMWR"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#48,48,"FFDDQA_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD0BD0MEMWR*CS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_FFD = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_FFD = BA19·BA18*·BA1·BA0*       (ist. scrittura)CS_A_RES_FFD = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_FFD = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).01"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#49,49,"FFD(x8)D[7..0]Q[7..0]A_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD[7..0]BD[7..0]MEMWR*Estensione a 8 bit
01
StessiCSdellapaginaprecedente,cambiasoloilnumerodibitdidatotrasferiti.8888"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#5,5,"Esempio: una CPU con K=3 bit di indirizzo
CPU3•Lospaziodiindirizzamentosarebbedisolo8elementi•Supponiamodiavereduedispositividimemoria,da4byte:AeB76543210111110101100011010001000Decoder(RC)I livelloCS_ACS_BBA[2..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#50,50,"Mapping, read, write e set/reset di un latch
•Anche il latch CD è un elementare dispositivo di memoria•Con una CPU, come possiamo:•scriverenel latch•leggerenel latch •settare o resettare in modo asincrono il latch CDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassiC?"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#51,51,"CDA_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD0BD0CS_WRITE_LATCHCS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_LATCH = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_LATCH = BA19·BA18*·BA1·BA0*·MEMWR(ist. scrittura)CS_A_RES_LATCH = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_LATCH = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).CDQMappiamo i quattro comandi del latch agli stessi indirizzi usati per il FFD."
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#52,52,"Estensione a 8 bit
Stessi CS della pagina precedente, cambia solo il numero di bit di dato trasferiti.CD(x8)A_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD[7..0]CS_WRITE_LATCHCBD[7..0]888D[7..0]Q[7..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#53,53,"Incrementare il parallelismo dei dati
•Abbiamoconsideratofinoaorasistemiconunparallelismo(busdati)a8bit•Ognitrasferimentorichiedeunciclodibus•Nelementi(byte)->Nciclidibus•Sappiamochelememorie(enonsolo)sonolente(vsCPU)
1"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#54,54,"i)
ii)
iii)
111"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#55,55,"•Possiamo fare meglio?•Si, aumentando il parallelismo dei dati•Riducendo la dimensione di ciascuna memoria•Trasferendo più dati nello stesso ciclo di bus 
¼¼¼¼i)i)i)i)IS"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#56,56,"•CosaNON fare?•Trasferireglielementisequenzialmentein memoriepiùpiccole•Elementicontiguivannosumemoriediverse 
¼¼¼¼NOilparallelismodi ciascunamemoriaèsempre8 bit!
i)ii)iii)iv)i)ii)iii)iv)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#57,57,"Memoria con processori a parallelismo > 8Il caso dei 16 bitIndirizzo fisicomemorie = Indirizzo logico/ 2Sul piedino  A0della memoria -> BA1busA1della memoria ->BA2 bus……………………………..
MemorialogicaMemoriafisicaBUS ALTOBUS BASSO876543210876543210abcdefghi
acegibdfhlWord(3) -> Byteh(1) e Byteb(2) -> 2 lettureLogicoFisicoFisicoLe memorie  fisiche vanno sempre in coppiaPer ogni bancoci deve essere un ByteEnableBE0 per banco 7-0 e BE1 per banco 15-8078bit 15Indirizzo interno ai chip
Memorie sempre in coppia Ad esempio 2 x8K = 16 K (Lettura bytes 3 e 4 che però stanno a indirizzi fisici interni delle memorie differenti)(d ,e)(d )(e )"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#58,58,"Memorie con bus a 16 bitBE1      BE01           1       Word1           0       Byte alto (ind. dispari)0           1       Byte basso (ind. pari)0           0       Non possibile  Lo scambio byte alto esterno, byte basso del registro  e viceversa avviene allinternodel microprocessore
BA0del processorenon viene generato (di fatto seleziona il banco -al suo posto BE0 e BE1)BA1del processore connesso ai piedini A0delle memorieBA2del processore connesso ai piedini A1delle memorie etc. etc.7      015     8Memorie fisicheMicroprocessoreRiMUX"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#59,59,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  740000h5FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19*BA18BA17*BE1CSEPROM0= BA19*BA18BA17* BE0Individua la zona di memoria da realizzareLe memorie vanno sempre in coppia (16 bit)La decodifica si fa come se si avesse una memoria a 8 bit. Si usano dispositivi di taglia metà selezionati con BE0 e BE1Memoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#6,6,"•Comefacciamoadattivareunadelleduememorieinbaseall’indirizzoBA[2..0]emessodallaCPU?•Ovvero,comeèfattalaretedidecodifica(Ilivello)chegeneraiduesegnaliCS_AeCS_B?•CS_A=BA2CS_B=BA2*•Questisegnalisarannoinviatiaallememorie(decodificadiIlivello)•Poi,saràindividuatol’elementoall’internodellememoriaselezionata(decodificadiIIlivello)76543210111110101100011010001000BA2=1BA2=0II livello"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#60,60,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  780000h9FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19BA18*BA17*BE1CSEPROM0= BA19BA18*BA17*BE0Individua la zona di memoria da realizzareMemoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#61,61,"BUS BASSO4000540004400034000240001400005FFFF5FFFE5FFFD5FFFC5FFFBMemoria Logica
128K0   Eprom Pin0    Bus Pin77EPROM0BE0 -64KFFFFFFFEFFFDFFFC0003000200010000BUS ALTO07EPROM1BE1 -64KFFFFFFFEFFFDFFFC0003000200010000Eprom PinBus Pin       15              8Indirizzi interni della EPROMIndirizzi interni della EPROM
Indirizzi della memoria logicaMemoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#62,62,"Memoria con processori a parallelismo 32 bitMemorialogicaMemoriafisica
BUS 3BE3876543210abcdefghi
aeibfl07815cgdh162324bit 3187654210BUS 2BE2BUS 1BE1BUS 0BE0Indirizzo fisico = Indirizzo logico/4"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#63,63,"64Bus enable con parallelismo 32 bitBE3      BE2     BE1     BE01            1            1           1       Word 32 bit0            0            1           1       Half word bassa 1            1            0           0      Half word alta  0            0            0           1       Byte 0-7  N.B. BA0 e BA1  del processorenon vengono generati (di fatto selezionano uno  dei banchi -al loro posto BE0, BE1, BE2, BE3)BA2del processore connesso ai piedini A0delle memorieBA3del processore connesso ai piedini A1delle memorie etc. etc.etc.0            0            1           0       Byte 15-8  Lo scambio fra i bytes (half word) dei banchi di memoria e i byte (half word)  dei registri  e viceversa avviene allinternodel microprocessore"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#64,64,"65Memoria logicaMemoria fisica
BUS 32MB2MB2MBFFFFFFFFh
00000000h512K243140000000h401FFFFFh00000h7FFFFhIndirizzi interni alle EPROM
4 Memorie x 512K= 2MBEPROM3BE3*
CSEPROM3= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE3CSEPROM2 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE2CSEPROM1 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE1CSEPROM0= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE0Individua la zona di  memoria da realizzare512K1623EPROM2BE2*512K815EPROM1BE1*512K07EPROM0BE0*BUS 2BUS 1BUS0Selezionail BUS
CS espressi in forma veraMemoria allineata11 bitdi indirizzosono fissiMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#65,65,"Memoria logicaMemoria fisicaBUS 3  -D24-312MB2MB2MBFFFFFFFFh
00000000h512K40000000h401FFFFFh00000h7FFFFhEPROM3DLX512K512KEPROM2EPROM100000h7FFFFh00000h7FFFFh512KEPROM000000h7FFFFhBUS 2  -D23-16BUS1  -D15-8BUS 0  -D7-0BE0BE1BE2BE3
Emessi dal processoreal posto di BA1e BA0Memorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#66,66,"Memoria logica(come vista dal programmatore)512K
40000000h401FFFFFh
00000h7FFFFhEPROM3Memoria fisica(come realizzatafisicamente)
dh00001h2MB
512K00000h7FFFFhEPROM2
cg00001h512K00000h7FFFFhEPROM1
bf00001h512K00000h7FFFFhEPROM0
ae00001habcde40000001h40000002h40000003h40000004hIndirizzi fisicidei singolidispositivi
------x
I dati di indirizzi logiciconsecutivisi trovano su dispositivi diversiLa cella x di indirizzo logico abcdefghsi troverà allindirizzo fisicoabcdefgh/4 del dispositivo EPROMi ove iè il resto della divisioneabcdefghMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#67,67,"Esempio:sivuolerealizzarenelDLX(bus32bit)unamemoriaRAMda256Kpostaallindirizzo84000000(allineata).Campodiindirizzamento84000000-8403FFFF.Dispositivi:8RAMda32K(leRAMda64KstaticheNONesistono!!!!)Difattoquindivisonoduebanchida128Kluno:ilprimorealizzalamemoriada84000000a8401FFFFelaltroda84020000a8403FFFF.Ichipdimemoriada32Kutilizzanoallorointerno(fisicamente)comeindirizzidiselezionedellecelleipinA14-A0chesonoperòcollegatirispettivamenteagliindirizziemessidalDLXBA16-BA2(ricordiamoinfatticheBA1eBA0delDLXNONsonoemessiealloropostovengonoemessiBE3,BE2,BE1eBE0).SinotiilruolodellindirizzoDLXBA17chedivideiduebanchiPrimobanco(decodificanonsemplificata)CSRAM00=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE0CSRAM01=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE1CSRAM02=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE2CSRAM03=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE3Secondobanco(decodificanonsemplificata)CSRAM10=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE0CSRAM11=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE1CSRAM12=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE2CSRAM13=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE3Ovviamentenelcasodidecodificasemplificata(memorialogicaincompletamenterealizzatafisicamente)lefunzionididecodificavengonoridottedicomplessità.OvequestiduebanchifosserogliunicidarealizzareiCSdipenderebberosolodaBA17edaBEiMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#7,7,"Come è fatto un generico dispositivo?•Unqualsiasidispositivo(memoria,periferica,etc),comunicaconlaCPUmedianteunainterfacciastandardasxDISPCSA[K-1..0].RDWRD[R-1..0]?KBA[K-1..0]CS_DISPRBD[R-1..0]RDWRCPU•Lacomunicazioneconl’esternoavvienesecondomodalitàchesonospecifichedeldispositivoequindinonstandard•BA[K-1..0]utilizzati(internamente)perdecodificadiIIlivello"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#8,8,"9Memorie EPROM•Memorie non volatili a sola lettura•Capacità a multipli di 2:32K, 64K, 128K, 256K, etcVPPA16A15A12A7A6A5A4A3A2A1A0D0D1D2GNDVCCPGM*NCA14A13A8A9A11OE*A10CE*D7D6D5D4D3EPROM1234567891011121314151632313029282726252423222120191817128K ´8AiCE*OE*DiTceTaccToeCE*OE*DiCella M/bit i"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#9,9,CQiDCella di indirizzo jA0  A1    An-1WR RDD0   DiDN-1La cella di una RAMDECODERIIj2n´N
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#0,0,"03 Linguaggio macchinaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#1,1,"Instruction Set Architecture•L’insieme delle istruzioni e dei registri di una CPU costituiscono l’InstructionSet Architecture(ISA)•Mediante l’ISA è possibile accedere alle risorseinterne (e.g., registri) ed esterne (e.g., memoria)•Tipicamente le istruzioni in linguaggio macchina sono generate da un compilatore•Più raramente, come in questo corso, scritte daiprogrammatori•Purtroppo, (quasi) ogni CPU possiede un proprio ISA •A proposito di ISA, esistono due linee di pensiero:•RISC: insieme ridotto di istruzioni semplici -> moltiregistri interni (DLX, ARM, RISC-V, etc)•CISC: insieme ampio di istruzioni complesse -> pochiregistri (Intel X86)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#10,10,Consentediesprimereefficacementeconfigurazionibinarie:•Traslazionelogicaasinistradinbit:<<n(inserendo“0”adestra)•Traslazionelogicaadestradinbit:>>n(inserendo“0”asinistra)•Concatenazionediduecampi:##•Ripetizionenvoltedix:(x)n•Ennesimobitdiunaconf.binariax:xn(ilpediceselezionaunbit)•Selezionediuncampoinunastringadibitx:xn..m(unrangeinpediceselezionailcampo)•Datalaconfigurazionebinariadi8bitC=011011002:–C<<2:101100002–C3..0##1111:1100|11112–(C3..0)2:110011002–(C6)4##C>>4:1111|000001102Notazioneper la costruzionedi configurazionibinarie
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#11,11,"•Trasferimentodiundato:←Ilnumerodibittrasferitièdatodalladimensionedelcampodestinazione;lalunghezzadelcampovaspecificatasecondolanotazioneseguentetuttelevoltechenonèaltrimentievidente•Trasferimentodiundatodinbit:←nQuestanotazionesiusapertrasferireuncampodinbit,tuttelevoltecheilnumerodibitdatrasferirenonèevidentesenzalarelativaindicazioneesplicita•Contenutodicelledimemoriaadiacentiapartiredall’indirizzox:M[x]Esempio:R1←32M[x]indicailtrasferimentodallamemoriaversoilregistroR1dei4byte:M[x],M[x+1],M[x+2],M[x+3]Altranotazione"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#12,12,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
IlsegnalediRESETèasserito,all’avvio,daunareteesterna.AncheisegnalidiREADY,INTsonogeneratidaretiesternemautilizzatiduranteilnormalefunzionamento.Segnali del processore DLX30
32"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#13,13,"•Unicospaziodiindirizzamentodi4G•32registrida32bitGP(R0,…,R31,conR0=0)•Istruzionidilunghezzacostante,32bitallineate•Campidelleistruzionididimensioni/posizionifisse•3formatidiistruzione:I,R,J•Noncisonoistruzionipergestirelostack•Peristruzionicheprevedonounindirizzodiritorno(JAL/JALR),essoèsalvatoinR31•NonesisteunregistrodiFLAGsettatodalleistruzioniALU.Lecondizionisonosettateesplicitamenteneiregistri(istruzioniSET)•E’presenteun’unicamodalitàdiindirizzamentoinmemoria(indiretto,medianteregistro+offset)•Leoperazioniaritmetico/logichesonoeseguitesolotraregistri(nontraregistriememoria)•Esistonoalcuneistruzioni(MOVS2IeMOVI2S)perspostaredatitraregistriGPeregistrispecialieviceversaCaratteristiche dell’ISA DLX (integer)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#14,14,"Registri del DLX (integer)R0=0R1R2R3R28R29R30R3132PCIARMARMDR32Registri GP*accessibilidirettamentedal codiceRegistri nonaccessibilidirettamentedal codice*
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#15,15,DLX (integer): tipi di datoNelDLX(integer)sonodisponibilitretipididato:BYTE(8bit)HALF-WORD(16bit)WORD(32bit)•Idatididimensioneinferiorea32bit(quindia8o16bit)lettidallamemoriadebbonoessereestesia32bitduranteilcaricamentoneiregistri(semprea32bit)•Questaoperazionepuòessereeseguitamantenendoomenoilsegnodeldatolettodallamemoria07015031
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#16,16,"Estensione del segnoInmolticasiènecessarioèestenderelarappresentazionediundatocodificatoconnbit,inundatoconunarappresentazioneambit(conm>n).Peresempio,volendotrasferireunbyte(n=8)dallamemoriainunregistroa32bit(m=32)ènecessarioconoscerelamodalitàconlaqualeèrappresentatoildatoletto.Esempio:10110101(n=8)Assumendoildatosenzasegno(unsigned),l‘estensionea32bitavvieneaggiungeno24zeri:00000000000000000000000010110101oppure(0)24##10110101Assumendoildatoconsegno(signed),l’estesioneavvienereplicando24volteilbitdisegno11111111111111111111111110110101oppure(1)24##10110101"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#17,17,"Il set di istruzioni (integer) del DLX•Le principali istruzioni aritmetiche e logiche•Istruzioni logiche anche con op. immediato: AND, ANDI, OR, ORI, XOR, XORI•Istruzioni aritmetiche: ADD, ADDI, SUB, SUBI•Istruzioni di shift(a destra anche aritmetico): SLL1, SRL, SRA2•Istruzioni di SET CONDITION: Sx, con x= {EQ, NE, LT, GT, LE, GE} •Le principali istruzioni di trasferimento dati•Loadbyte signede unsigned(LB, LBU), loadhalfwordsignede unsigned(LH, LHU), loadword (LW)•Storebyte, storehalfword, storeword: SB, SH, SW•Copia un dato da un registro GP a un registro speciale e viceversa MOVS2Ie MOVI2S•Le principali istruzioni di trasferimento del controllo•Istruzioni di salto condizionato (PC+4 relative): BNEZ, BEQZ•Istruzioni di salto incondizionato J: assoluto (con reg.) e PC-relative•Istruzioni di chiamata a procedura Jumpand Link (JAL). L’indirizzo di ritorno viene automaticamente salvato in R31. JAL con registro e immediato  (PC-relative)•Istruzione di ritorno dalla procedura di servizio delle interruzioni: RFE1)Shiftlogicoasinistraeshiftaritmeticoasinistracoincidono(entrano0neibitmenosignificativi).PerquestaragioneNONesisteSLA.Fareattenzioneconshiftasinistra,nonpreservailsegnoepuògenerareoverflow2)Trascinandoadestradiunaposizioneunregistroeinserendoasinistrasempreilbitdelsegnosimantieneilsegnodeldatomentrelosidividesuccessivamenteper2"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#18,18,"Elencoistruzionidel DLX (integer)Data TransferLWRa,Imm16bit(Rb)LB Ra,Imm16bit(Rb)LBU Ra,Imm16bit(Rb)LH  Ra,Imm16bit(Rb)LHURa,Imm16bit(Rb)SW  Ra,Imm16bit(Rb)SH  Ra,Imm16bit(Rb)SB  Ra,Imm16bit(Rb)MOVS2IRa,Rs*MOVI2SRs*,RaSpecial registerRs* (IAR)Aritmetiche/logicheADD Ra,Rb,RcADDIRa,Rb,Imm16bitADDURa,Rb,RcADDUI Ra,Rb,Imm16bitSUB Ra,Rb,RcSUBIRa,Rb,Imm16bitSUBURa,Rb,RcSUBUIRa,Rb,Imm16bitSLL Ra,Rb,RcSLLI Ra,Rb,Imm16bitSRL Ra,Rb,RcSRLI Ra,Rb,Imm16bitSRA Ra,Rb,RcSRAI Ra,Rb,Imm16bitOR Ra,Rb,RcORIRa,Rb,Imm16bitXORRa,Rb,RcXORIRa,Rb,Imm16bitANDRa,Rb,RcANDIRa,Rb,Imm16bitLHI Ra,Imm16bitControlloSxRa,Rb,RcSxIRa,Rb,Imm16bitBEQZRa,Imm16bitBNEZ Ra,Imm16bitJImm26bitJRRaJALImm26bitJALRRaxpuò essere: LT,GT,LE,GE,EQ,NE
Ra{R0+,R1,..,R30,R31}Rb{R0,R1,..,R30,R31}Rc{R0,R1,..,R30,R31}+RanonpuòessereR0comeregistrodestinazionediistruzioniload,MOV2SI,aritmetico/logiche,LHIeSET∈∈∈
Per le istruzioni aritmetiche: l’immediato a 16 bit è esteso senza segno se di tipo U (unsigned) altrimenti con segno.  Per istruzioni logiche, sempre estensione senza segno.  "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#19,19,"DLX: formato delle istruzioni
•Istruzionidiload,store,branch,JeJALconregistro,serconditionSxIeALUconoperandoimmediato.L’immediatoèa16bit•NelleoperazioniloadeALURS2/RdèRd.NellestoreRS2/RdèRS2.InentrambiicasiRS1perindirizzosorgente(loadostore)oregistrosorgente(operazioniALUconconoperandoimmediato)IOpCodeRS2/RdRS1Immediato di 16 bit
JOpCodeImmediato/offset di 26 bit (PC relative)•Salti incondizionato con e senza ritorno (Je JAL) con immediatoROpCodeRS2RS1RdOpCodeext. (11 bit)•IstruzioniALUdeltipoRd¬Rs1opRs2oppuresetconditionSxtraregistri6 bit5 bit5 bit5 bit11 bit031•In alcuneistruzionidi tipoI (LOAD e ALU), RS2 rappresentailregistrodestinazioneRd•Alcuneistruzioni(e.g., J e JAL con registro) potrebberoesserecodificatecon piùdi un formatotraquellidisponibili"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#2,2,"Requisitidi un linguaggiomacchina/ISAOltreallapossibilitàdipoterrisolvereunqualsiasiproblema*,unrequisitofondamentalediunlinguaggiomacchina/ISAèquellodiminimizzareiltempodiesecuzionedelcodice*•SeCPImedioèilnumeromediodiclockperl’esecuzionediunaistruzione,l’obiettivoèquellodiminimizzareCPUTime=Nistruzioni*CPImedio*TCK•Lostessoproblema,puòesserequindirisoltoconCPUTimediversiinbasea:•Nistruzioni(RISC,richiedonoingenerepiùistruzioni)•CPImedio(RISC,tipicamenteistruzionipiùveloci)•TCK(Retilogichesemplicipotenzialmentepiùveloci)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#20,20,"Modalitàdi accessoallamemoria•OgniISAdisponediistruzioniperaccedereallamemoriainletturaescrittura•Normalmenteèpossibilestabilireladimensionedeldatochepuòesseretrasferito(BYTE,HALF-WORD,WORD,etc)•Idueprincipalimetodidiaccessoallamemoria(indirizzamento)sono:–Diretto(indirizzocablatonell’istruzione)–Indiretto(indirizzomodificabilearun-time)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#21,21,"Indirizzamentodiretto•Conquestamodalitàl’istruzionecontienealsuointernounvalore(cablato)chespecifical’indirizzodiaccessoallamemoriaLBR7,0800h-“LeggiunBYTE(8bit)all’indirizzo0800hememorizzalanelregistroR7”A0870800Ipotetica codifica dell’istruzione con 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#22,22,"Indirizzamentoindiretto•Conquestamodalitàl’indirizzodiaccessoallamemoriaèottenutosommandounvalorecostantepresentenell’istruzioneconilcontenutodiunregistro•Indirizzo=costante+registro•Ilregistroècablatonell’istruzionemailsuocontenutopuòcambiareatempodiesecuzioneLBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hememorizzalanelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#23,23,"Indirizzamentodirettovsindiretto1/2•Ladifferenzatraleduemodalitàdiindirizzamentoènotevole•Perrenderveneconto,poteteconsiderareuncasopiuttostocomune:“sommareglielementidiunarrayAdi8elementimemorizzatoapartiredall’indirizzo0800h”
00800h10801h20802h30803h40804h50805h60806h70807h
A[0]"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#24,24,"Indirizzamentodirettovsindiretto2/2Diretto(non usato):XOR  R8,R8,R8; R8=0LBU R7,0800hADD R8,R8,R7 ; R8=R8+R7LBU R7,0801hADD R8,R8,R7 ; R8=R8+R7LBU R7,0802hADD R8,R8,R7 ; R8=R8+R7LBU R7,0803hADD R8,R8,R7 ; R8=R8+R7LBU R7,0804hADD R8,R8,R7 ; R8=R8+R7LBU R7,0805hADD R8,R8,R7 ; R8=R8+R7LBU R7,0806hADD R8,R8,R7 ; R8=R8+R7LBU R7,0807hADD R8,R8,R7 ; R8=R8+R7Indiretto:XOR  R8,R8,R8; R8=0ADDI R9,R8,8; R9=8LOOP: SUBI R9,R9,1; R9=R9-1LBU R7,0800h(R9); legge BYTE ; a 0800+R9ADD R8,R8,R7; R8=R8+R7BNEZ R9,LOOP; se R9!=0; salta a LOOP•Il registro R9 è utilizzato in ogniiterazione per cambiare l’indirizzobase (0800h)•Pensate se l’array fosse di 1000000elementi..."
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#25,25,"DLX: modalitàdi accessoallamemoria•IlDLXprevedeun’unicamodalitàdiindirizzamento:indiretto•L’indirizzo(a32bit)èsempreottenutosommandounregistroa32bitconunvaloreimmediatoa16bitestesoa32bitconsegno.•Esempio:LWR7,Imm16_bit(R8)•CaricainR7,lawordall’indirizzo(a32bit)ottenutosommandoR8ilvaloredell’immediatoestesoa32bitconsegno:R7ç32M[R8+Imm16_bit[15]16##Imm16_bit[15..0]]•Nell’eserciziodellepagineprecedentiabbiamosottointeso,persemplicità,chel’indirizzofossea16bit.Inrealtà,nelDLXl’indirizzoèsemprea32bit(lospaziodiindirizzamentoè4G)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#26,26,"Come sonomemorizzatiidatiin memoriain un sistemacon parallelismo> 8? •Consideriamounsistemaconbusdatia16bit•Comepossiamomemorizzareilvalorea16bit0468hapartiredall’indirizzo(chesupponiamoa20bit)00010h?•Esistonodueconvenzioni:04680468046800010h00011h00010h00011h880000Fh00012h0000Fh00012h16HL
Little Endian(e.g., Intel)Big Endian(e.g., Motorola)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#27,27,"Istruzioni Aritmetico Logiche (ALU)•Istruzioni a 3 operandi:–2 operandi “sorgente”–1 operando “destinazione”. •“destinazione”: sempre un registro (a 32 bit)•“sorgente”: registro, registro •“sorgente”: operando immediato(16 bit)Esempi: ADD R1,R2,R3; R1 çR2 + R3 formato RADDIR1,R2,3; R1 çR2 + 3 formato I; il valore (3) dell’immediato a 16 bit ; è esteso a 32 bit "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#28,28,"Istruzioni di Set ConditionQuesteistruzioniconfrontanoidueoperandisorgenteemettonoa“1”oppurea“0”l’operandodestinazioneinfunzionedelrisultatodelconfronto•“SET EQUAL” (SEQ, =) : settase uguale•“SET NOT EQUAL” (SNE, !=): settase diverso•“SET LESSER THAN” (SLT, <) : settase <•. . . Gli operandi possono anche essere unsigned:•“SET LESSER THAN UNSIGNED” (SLTU, <)Esempi SLT R1,R2,R3; R1 ç1 se R2<R3 altrimenti R1 ç0; formato RSLTIR1,R2,3; R1 ç1 se R2<3 altrimenti R1 ç0; formato I"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#29,29,"Istruzioni per il trasferimento dati •Sonoistruzionicheaccedonoallamemoria(loadestore):LB,LBU,SB,LH,LHU,SH,LW,SW•L’indirizzodell’operandoinmemoriaèlasommadelcontenutodiunregistroa32bitconun“offset”di16bit(Imm16bit)estesoconsegnoa32bit•L’istruzioneècodificatasecondoilformatoIEsempi:LWR1,40(R3);R1←32M[40+R3]LBR1,40(R3);R1←32(M[40+R3]7)24##M[40+R3]LBUR1,40(R3);R1←32(0)24##M[40+R3]"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#3,3,"Istruzionie risorseinterne a unaCPULeistruzionieseguibilidaunaCPU,codificateinbinario,sonoingeneremoltopiùsemplicidelleistruzionicheutilizzateneilinguaggiadaltolivello.Tipicheoperazionisono:-somme,sottrazioni,divisioni,moltiplicazioni,etc-lettureescrittureinmemoriaeperiferiche-confrontotraoperandi(“A>B?”)-salticondizionati(“saltase”)eincondizionati(“salta”)-...E’possibile,medianteleistruzioni,accederearisorseinternedellaCPUcomeregistriarchitetturalietalvoltaaregistridistato(e.g.,AeramaggiorediB?)LerisorsechesonoaccessibilialleistruzioniinlinguaggiomacchinasonodefinitedaiprogettistidallaCPUTuttavia,nontuttiiregistriinternisonoaccessibilialprogrammatore(senzachequestorappresentiunproblema)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#30,30,"Istruzioni per il trasferimento del controllo:salti incondizionati (con e senza ritorno)•“JUMP”: salto incondizionato•“JUMP AND LINK: salto incondizionato con ritornoEsempiJoffset; PC = PC + 4 + (offset[25])6## offset, tipo JJR R3; PC = R3, tipo RJAL offset; R31 = PC+4; PC = PC + 4 + (offset[25])6## offset, tipo JJALR R5; R31 = PC + 4, PC = R5JR R31; PC = R31; istruzione per tornare da una procedura "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#31,31,"BCONDRd,Imm16E’ possiibleverificare solo due condizioni (COND):•BEQZ“BEQUAL ZERO”: salta se registro è 0•BNEQZ“BRANCH NOT EQUAL ZERO”: salta se registro è ≠ 0EsempiBEQZR4,Imm16; se R4==0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4BNEZR4,Imm16; se R4!=0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4Conunaistruzioneditiposetseguitadaun’istruzionedibranchsirealizzalafunzionedicompareandbranch(confrontoesaltocondizionatodalrisultatodelconfronto)senzabisognodiflagdedicatiIstruzioni per il trasferimento del controllo: salti condizionati (Branch)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#32,32,"Come generare valori a 32 bitNelDLXèpresenteunaistruzione,LHI(“LoadHighImmediate”)checonsentedicrearerapidamentevaloria32bit(NONèunaistruzionediaccessoallamemoria!).LHI Rd,Imm16; Rd= Imm16 ## 0000h  InserisceinRdilvaloredell’immediatonei16bitpiùsignificativie0neirimanentibitTipicamente,LHIèutilizzatapergenerareindirizzia32bitpartendodaimmediatia16bit.QualipotrebberoesseredellealternativeallaLHI?Esempio LHI R1,8420; R1 = 8420 ## 0000h = 84200000h"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#33,33,"Esempio di codice assemblerDLX 1QualevaloreassumonoiregistriR3edR4alterminedell’esecuzionedelcodiceseguente?LHIR1,0xE000ADDUIR2,R0,0x0081SB0x0000(R1),R2LBUR3,0x0000(R1)LBR4,0x0000(R1)R3=?,R4=?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#34,34,"EsercizioScrivereilcodiceDLXchesommaduewordmemorizzateapartiredallametàdellospaziodiindirizzamento(80000000h).LHIR4,8000h;R4=8000##0000hLWR5,0(R4);R5<-M[R4+0]LWR6,4(R4);R6<-M[R4+4]ADDR7,R5,R6;R7=R5+R6"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#35,35,"EsercizioProgettareunsistemabasatosulprocessoreDLXcon512MBdiEPROMnellapartebassadellospaziodiindirizzamento,1GBdiRAMapartiredall’indirizzo0x40000000e512MBdiRAMnellapartefinaledellospaziodiindirizzamento.Nelsistema,medianteopportuneistruzionisoftware,ènecessariopoter:-impostareallivellologico0o1unsegnaledenominatoSTARTUP,mappatoa0xC0000000einizialmentealvalore1-invertirelostatodiunLED,inizialmentespentoemappatoall’indirizzo0x90000000,prevedendoanchelapossibilitàdipoterneleggerelostato(ie,determinareseilLEDèaccesoospento)EPROM512 MBRAM 1 GBRAM512 MB
0xC00000000x90000000
0x1FFFFFFF
0x40000000
0x7FFFFFFFSTARTUPLED
0xE0000000"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#36,36,"Struttura di una soluzioneRispostaaeventualidomandespecificheindicateneltestoIndicazionedeidispositiviedellememorieutilizzaticonrelativiindirizzidimappingreali(inizioefineinesadecimale)Scritturadeichip-selectdiciascundispositivocondecodificasemplificataProgettodieventualiretilogichenecessarieperrisolvereilproblema
ScritturadelcodiceinassemblerDLX,necessarioarisolvereilproblemaIndicazionedicomesonoconnessituttiidispostivi(inclusetuttelememorie)presentinellasouzioneaibusdisistemadelDLXCognomeNomeMatricolaDataTipoesame(CalcolatoriToLA)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#37,37,Soluzione -chip selectCS_EPROM_512_3=CS_EPROM_512_2=CS_EPROM_512_1=CS_EPROM_512_0=CS_RAM_1_GB_L_3=CS_RAM_1_GB_L_2=CS_RAM_1_GB_L_1=CS_RAM_1_GB_L_0=CS_RAM_1_GB_H_3=CS_RAM_1_GB_H_2=CS_RAM_1_GB_H_1=CS_RAM_1_GB_H_0=CS_READ_LED=(0x90000000)CS_SWITCH_LED=(0x90000004)CS_READ_STARTUP=(0xC0000000)CS_WRITE_STARTUP=(0xC0000004)CS_RAM_512_3=CS_RAM_512_2=CS_RAM_512_1=CS_RAM_512_0=
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#38,38,Soluzione –rete segnale STARTUPAll’avviodelsistemaSTARTUP=1
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#39,39,Soluzione –rete segnale LEDAll’avviodelsistemaLED=0
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#4,4,"Registridi unaCPU•OgniCPUpossiedeuncertonumerodiregistriaccessibilialprogrammatore•Ilnumeroeladimensionedeiregistridipendonodall’ISA(equestohaimpattosullaretelogicarisultante)•Ovviamente,averemoltiregistrigeneralpurpose(GP)èvantaggioso(menoaccessiallalentamemoria)•Avereistruzionichepossonousaretutti,oquasi,iregistriGPsenzavincolièvantaggioso•LostessoISApuòessererealizzatoconretilogichecompletamentedifferenti(e.g.,InteleAMD)•Questeretihannoingenereprestazionidiverse(diversoCPUTimesebbeneabbianostessoNistruzioni)•NonsarebbestatomeglioavereunsoloISA?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#40,40,"Soluzione –connessione memorie
_3_2_1_0BA[  ..  ]MEMWRMEMRDCS_CS_CS_CS_
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[  ..  ]RD WR CSRD WR CSRD WR CSRD WR CS"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#41,41,"Soluzione –codice assemblerDLX 1/2 LetturasegnaleSTARTUP
ImpostazionesegnaleSTARTUPalvalorelogico0"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#42,42,"Soluzione –codice assemblerDLX 2/2 LetturasegnaleLED
InversionevaloredelsegnaleLED"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#43,43,"Simulatore DLXNell’ambitodialcunetestidilaureaèstatosviluppatounsimulatorediistruzioniDLXperscopididatticidisponibileaquestoindirizzo:http://dlx-simulator.disi.unibo.it/dlxAncorainfasedisperimentazionemapotrebbeessereunavalidaalternativaalsoftwareindicatonellepagineseguenti.Perchifosseinteressato,sebbenesiaancorainformamoltopreliminare,èpossibilesimulareancheistruzioniRISC-VSonograditesegnalazionidibachiesuggerimentipermigliorareisimulatoriinprossimetesiTesidilaureasvolteinquestocontesto:FedericoPomponii,“SviluppodiunsimulatoreDLXperscopididattici”,AA2019/20FabrizioMaccagnani,“ProgettodiunsimulatorediDLXperscopididattici”,AA2018/19AlessandroFoglia,“ProgettodiunsimulatorediRISC-Vperscopididattici”,AA2018/19"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#44,44,"AlcunenotesulsimulatoreDLXattuale-Negliimmediatinecessarioilprefisso0X(eg,0x8000)-Nellestoreladestinazioneasinistra(eg,SW0x800(R0),R18)-Altro?Esempio:sommaelementidiunarrayinit:XORR8,R8,R8;R8=0ADDIR9,R8,0x0008;R9=8LOOP:SUBIR9,R9,0x0001;R9=R9-1LBUR7,0x0800(R9);leggeunBYTEa00000800+R9ADDUR8,R8,R7;R8=R8+R7BNEZR9,LOOP;seR9!=0saltaaLOOP
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#45,45,
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#46,46,"Esempio di codice assemblerDLX 2E’correttoilcodiceseguente?LHIR1,0x0000ADDIR2,R0,0x0081SH0x7FF1(R1),R2LHUR3,0x7FF1(R1)LHR4,0x7FF1(R1)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#47,47,"Esempio di codice assemblerDLX 3ScrivereilcodiceassemblerDLXperinserireinmemoria,apartiredall’indirizzoE0000800hl’arraydiwordindicatoinfigura.
01234567
0xE00008000xE00008040xE00008080xE000080C0xE00008100xE00008140xE00008180xE000081C0xE0000820
32"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#48,48,"ADDR2,R0,R0;R2usatocomeindicedelcicloLHIR3,0xE000;R3=E0000000Loop:SWR2,0800(R3);scriveindiceinmemoriaADDIR2,R2,1;incrementaindicedelciclodi1ADDIR3,R3,4;incrementaindiceoffestdi4SNEIR4,R2,8;confrontaindiceR2con8BNEZR4,Loop;saltaseR4nonèzeroi)QualevaloreènecessariosostituireaLoopinBNEZ?i)Sipuòfaremeglio(ie,usaremenoistruzioni)?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#49,49,"76543210
0x000008000x000008040x000008080x0000080C0x000008100x000008140x000008180x0000081C0x00000820
32Esempio di codice assemblerDLX 4Scrivereilcodiceassemblerperilcalcolodellasommadeiprimi8elementidiunvettorediWORDmemorizzatoapartiredall’indirizzo00000800h.Ilrisultatodell’elaborazionedeveesserememorizzatoall’indirizzoE0000200h.Σ
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#5,5,"IA: Intel X86 (CISC)
IA: ARM (RISC)
ATMEL (RISC 8 bit)ArduinoUnoDesktopSmartphonee Tablet"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#50,50,"ADDR1,R0,R0;azzeraR1,accumulatoreADDIR2,R0,20h;R2=3210Loop:SUBIR2,R2,4h;R2=R2-410LWR3,0800(R2);leggewordinmemoriaADDR1,R1,R3;aggiornaaccumulatoreR1BNEZR2,Loop;saltaseR2nonèzeroLHIR7,0xE000;R7=E0000000SWR1,0200h(R7);memorizzaaccumulatoreinE0000200h"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#51,51,Esercizio
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#6,6,"RISC-V (1/2)•IlprogettoRISC-Vmiraproprioaquesto:creareunISAunicoeopensource•Ovviamentel’obiettivononèquellodiuniformareleretilogichecheimplementanol’ISA•L’ISAbasedelprogettoRISC-VèmoltosimileaquelladelDLXchestudieremoeprogetteremoinquestocorso•Esistonospecificheperestenderel’ISAbasealfinedicontemplareparticolarifunzionalità(floating-point,SingleInstructionMutipleData(SIMD),32/64/128bit,etc)
https://riscv.org/
RISC-V: The Free and Open RISC Instruction Set Architecture"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#7,7,"RISC-V (2/2)
https://www.slideshare.net/KrsteAsanovic/riscv-20160507patterson
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#8,8,"Codificabinariadelleistruzioni•LeistruzioniperessereeseguitedallaretelogicaCPUdebbonoesserecodificateinbinariosecondounformatonotoedocumentatodalproduttore(datasheet)•Lacodificabinariadeveconteneretutteleinformazioninecessarieall’UnitàdiControlloperpotereseguirel’istruzione•EsistonoCPUconcodificadelleistruzionialunghezza:-costante(e.g.,32bitcasoRISCDLXemoltialtri)-variabiledaistruzioneaistruzione(IntelX86)Esempio:LBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hetrasferiscinelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit. I bit non utilizzati per codificare R3, R7e 0800rappresentano il codice operativo (op code) "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#9,9,"Linguaggioassembler•Lacodificadelleistruzioniinlinguaggiomacchinaèpocointuitivapergliesseriumani•Nellinguaggio*assemblersicodificanoleinformazioniinunmodo(unpo’)piùintuitivoMacchina->Assembler014FA27Dh->ADDR1,R2,R3;R1=R2+R3Escludendolacaratteristicaappenaevidenziata,unaltrosignificativovantaggioèquellodipoterdefiniredellelabelutili(spesso)neisaltiLOOP:SUBR1,R1,R3......BNEZ(R1),LOOP;saltaaLOOPseR1!=0"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#0,0,"04 InterruzioniCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#1,1,"•Inunsistemaamicroprocessoreèdifondamentaleimportanzapotergestireeventichesiverificanoall’esterno(manonsolo)dellaCPU•Peresempio,determinareseèstatopremutountastosullatastiera,seilmouseèstatospostato,etc•Unastrategia,pocoefficiente,perraggiungerequestoscopoconsistenelcontrollareperiodicamentesetalieventisisonoverificati(polling)•Questopuòesserefattointerrogandodicontinuolaperifericachesidesideragestire•Ovviamente,conquestastrategia,laCPUspendemolticiclimacchinaperlaverifica(oleverifiche)•Unastrategiamoltopiùefficiente,basatasuunastrategia“push”,consistenell’usodiinterruptGestioneeventicon unaCPU: polling"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#10,10,"Interruzionimultiple e priorità
•Inunsistemanelqualeèpresentepiùdiunasorgentediinterruzioneèfondamentalepoterassociareunlivellodiprioritàaciascunainterruzione•Sarebbeauspicabilepoterinterromperel’interrupthandlerinesecuzionesegiungeunarichiestadiinterruzionepiùprioritaria(annidamento)•Esempio:
PROBLEMA_SISTEMA_FRENIPROBLEMA_SISTEMA_AUDIOINT?
"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#11,11,"•AssumeremocheilDLXsiasensibileallivellodelsegnalediinterruptINTenonalsuofronte•L’indirizzodiritorno(PC+4)èsalvatoinIAR•Inseguitoall’arrivodiuninterrupt,l’istruzioneincorsoècompletataedèeseguitoilcodiceall’indirizzo00000000h•Ilritornodall’interrupthandler(PCçIAR)avvienemediantel’istruzioneRFE(ReturnFromException)•Ingenere,manonnelDLXbase,gliinterruptpossonoessereabilitatiodisabilitatimedianteistruzioni•Nell’ISADLX,ègestitounsoloindirizzodiritorno.Pertanto,ilDLXdisabilitaleinterruzionimentreeseguel’handlereleriabilitaautomaticamenteritornandodall’handler(RFE).Incasocontrario,nelDLX,servirebbeunostacksoftwareInterrupt nelDLX"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#12,12,"•Conannidamento(nesting)delleinterruzionisiintendelapossibilitàdipoteravviareuninterrupthandlerdurantel’esecuzionediunaltrohandler•QuestacaratteristicaèstandardnellamaggiorpartedelleCPUincommerciomanonèprevistadalDLXbase•Perpoterannidaregliinterruptsarebbenecessariounostacksoftware(utilizzandol’istruzioneMOVS2I)eaverelapossibilitàdiri-abilitaregliinterruptnell’handlermedianteopportuneistruzioni(ENI)nonprevistadall’ISAbase•Incasomultiplesorgentidiinterruzione,nasceilproblemadicomeassociareunascaladiprioritàalleinterruzioni•Atalfineesistonovariepolitiche:prioritàfissa,variabile,etc.Ovviamentelaprioritàècrucialenonsoloquandoèpossibileannidaregliinterrupt"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#13,13,"•Lerichiestediinterruptpossonoverificarsiinqualsiasimomento•E’perònecessariomantenerelaconsistenzadeidatiinmodocheilcodiceinesecuzionenonsiamodificatodall’arrivoomenodiinterruptediconseguenzadall’esecuzioneomenodegliinterrupthandler•Perquestaragioneènecessariofareinmodochel’interrupthandler(i.e.,ildriverdeldispositivo)noninterferiscaconilcodicedelprogramma(main)inesecuzione•Comefare?Salvandoeripristinandoiregistrimodificatidall’interrupthandlerall’internodellostessocodice(handler)•Nellapaginaseguenteèmostratol’effettodiunpessimointerrupthandlerchenonpreservairegistriInterrupt handler e consistenzadeidati"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#14,14,"1
+
2
=
33
a)b)c)
d)e)
1+2=33??Chi ha scrittoildriver/handler del nuovodispositivo, avràsalvatoe ripristinatolo statodeiregistri?Temodi no…"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#15,15,"Nelcasodiunasingolasorgentediinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;codicedirispostaallarichiesta;diinterruzione;istruzionidiripristinodeiregistri;modificatiinprecedenzaXXXXXXXXhRFE;ritornodall’interrupt(PCçIAR)Interrupt handlercon singolainterruzione"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#16,16,"Nelcasodimultiplesorgentidiinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;Identificazionedell’interruptpiù;prioritariotraquelliasseriti;ripristinaregistriesaltaalcodice;dell’interruptpiùprioritario;salvaregistrimodificatiinseguito;codicehandler_1XXXXXXXXh;ripristinaregistrieritorno(RFE);salvaregistrimodificatiinseguito;codicehandler_2YYYYYYYYh;ripristinaregistrieritorno(RFE)Interrupt handlercon multiple interruzione
RFERFEPreambolo"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#17,17,"•Conlastrategiamostratanellapaginaprecedenteèilsoftware,interrogandoognisingolaperiferica,adoverdeterminarequalèl’interruptpiùprioritario•Atalfinesaràanchenecessariaunaopportunainfrastrutturahardware(itri-stateserviranno?)•Tuttavia,èpossibilevelocizzareesemplificareleretilogichedisupportoaquestocompitomediantel’utilizzodiundispositivoadhoc(PIC)•IlPICsioccupadigestiremultiplesorgentidiinterruzioneediforniredirettamenteallaCPU(surichiesta)qualèilcodice/indirizzodell’interruptpiùprioritariotraquelliasseritiinquelmomento•Tipicamente,inunPICèpossibiledisabilitarelesingolesorgentidiinterruzioneestabilireillivellodiprioritàdiciascunainaccordoavariepolitiche(prioritàfissa,variabile,etc)Programmable Interrupt Controller (PIC)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#18,18,PICCSA[K-1..0]RDWRD[7..0]KBA[?..?]CS_PIC8BD[7..0]RDWRINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTINTINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0•LastrutturadiunipoteticoPICpotrebbeesserequellamostratainseguito•LevariesorgentidiinterruzioneINT[7..0]sonoinviatealPICchesioccupadiinviarelarichiestasull’unicopinINTdelDLX•Piùavantineprogetteremounomoltosempliceconfunzionalitàdibase(abilita/disabilitaINT_i)
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#19,19,"INTPICCSA[K-1..0]RDWRD[7..0]INT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTCPU•IlPICinviailsegnalediINTefornisceallaCPU,surichiesta,ilcodicedell’interruptconprioritàpiùelevatatraquelliasseritiinquelmomento•PerchénelPICèpresenteancheilsegnaleWR?Perché dei timer?Come può essere realizzato un timer?
Cosa comunicano alla CPU le reti?"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#2,2,"main(){bool tasto_premuto=false;while(1){if (tasto_premuto==true)gestisci_evento();. . .}}void gestisci_evento(){. . .return;}Premuto?Premuto?Premuto?Premuto?
LaCPUspendemoltotemponelcontrollare(polling)sel’eventosièverificato.Questastrategiarallental’esecuzionedelmainPocoefficiente…."
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#20,20,"(i)(ii)INT
ΔxΔyΔwheelpressed_Lpressed_R•Inrealtàleinformazionisonoconvogliatesuuncanaleseriale(USB,PS/2)perridurreilnumerodiconnessioni/fili•Tuttavia,possiamopensareperlenostrefinalitàchel’interfacciamouse/CPUespongaisegnalidiunaportadiI/Ostandard(CS,RD,WR,D[7..0],indirizzi)
Inrealtàgliinterruptsonoemessiperiodicamente(e.g.,100Hz)esolosenecessario(uneventonelmouse)
"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#21,21,
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#22,22,"•InunaCPU(manonnelDLX)puòesserepresenteunulterioresegnale(ininput)denominatoNMI(NotMaskableInterrupt)•Atalesegnalesonocollegateunnumerolimitatodisorgentidiinterruzioniparticolarmentecritiche•Peresempio,l’outputdiunaretecherilevaesegnalaunaimminenteperditadialimentazioneelettrica•UnarichiestadiinterruptinviatasulpinNMInonpuòessereignorata(eventualiistruzionichedisabilitanogliinterruptnonagisconoperquestosegnale)einterrompel’esecuzionedialtrihandler•L’handlerassociatoalpinNMIèaprioritàmassimaedeveessereseguitonelminortempopossibileInterrupt non mascherabili(segnaleNMI)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#23,23,"•IlsegnaleNMIvausatoconcautelaesolopersegnalazionicriticheallaCPU•NelcasodelDLXutilizzeremosoloINT•Sefossedisponibile,perlagestionedelsegnaleNMIsarebbenecessarioinserireleistruzioninellaprimapartedel“preambolo”all’indirizzo00000000h,primadigestiregliinterruptchesonoinviatiattraversoINT"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#24,24,"ProgettareunsistemabasatosulprocessoreDLX,conun1GBdiEPROMaindirizzibassie512MBdiRAMaindirizzialti.Intalesistema,utilizzandounpulsante,deveesserepossibileaccendere/spegnereunledmedianteinterrupt.All’avvioilleddeveessereacceso.Sifaccial’ipotesicheR29eR30possanoessereusatisenzalanecessitàdiessereripristinati.Esercizio"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#25,25,"Alcune considerazioni sul reset asincrono
FFDDQQ*A_SETA_RESRESETClockRESET_SYNCTuttavia,presentadeiproblemi:•E’semprenecessariounsegnalediclock•QuandoRESETvaa1,RESET_SYNCsiasserisce(ie,diventaattivo)alprimofrontediclockL’applicazionediunsegnaleasincronodireset,puòportareaproblemidimetastabilitànelmomentoincuitalesegnalevienepostoalvalore0(ie,quandosiescedalreset,assumendochetalesegnalesiaattivoalto).Leproblematichesonoanalogheaquelleevidenziateduranteilcampionamentodiunsegnalechenonrispettaitempidisetupehold.Unapossibilesoluzioneèlaseguente:"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#26,26,"FFDDQQ*A_SETA_RES0ClockRESET_SYNCRESETUnasoluzionecheeliminaidueproblemiprecedenti,echegarantisceun’uscitasincronadalreset,èlaseguente:
ClockRESETRESET_SYNCAttivazionenonsincronadelresetUscitasincronadalreset"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#3,3,"•UninterruptèuneventocheinterrompelaCPUduranteilregolareflussodiesecuzionedelcodice•L’interruptsegnalachesièverificatouneventochemeritaimmediata*attenzionedapartedellaCPU•SelaCPUèabilitata*ariceveretalesegnalazione,esegueautomaticamenteunaporzionedicodicedenominatainterrupthandleralfinedigestirel’evento•Glieventipossonoessererelativiafattoriesterni(e.g.,premutountasto)ointerni(e.g.,èstataeseguitaunadivisioneperzero,overflow,etc)•Quandodipendonodafattoriinternisiparladieccezioni(exceptions)•Inoltre,èpossibileinvocarel’handlermedianteopportuneistruzioni(e.g.,perinvocaresystemcall)Gestioneeventicon CPU: interrupt"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#4,4,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
Inogniprocessore,èpresentealmenounsegnaledenominatoINTpergestireleinterruzioni.Inmolticasi,manonnelDLX,èpresenteancheunulterioresegnaledenominatoNMIpergestireinterruzionichenonpossonoessereignorate.Gestione interruzioni nel DLX30
32NMI(NA nelDLX)NMI"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#5,5,"•Nelcasodiinterruptgeneratodall’esternolasituazioneèquesta:
•Lapressionedeltastoinnesca*l’esecuzionedelcodicedell’interrupthandler(2)(1)(2); Interrupt hander. . . . . . . . . .. . . . .RFEINT
LaCPUnormalmentesvolgeoperazioniutiliedèavvisatasoloquandosiverifical’evento(inquestocaso,lapressionedeltasto)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#6,6,"•Nelcasodiinterruptgeneratodall’esternolasituazione,dalpuntodivistasoftware,èquesta:main(){Istruzione1;Istruzione2;Istruzione3;Istruzione4;Istruzione5;Istruzione6;Istruzione7;Istruzione8;}
(i); Interrupt handler ADD R1,R0,R0. . . . . . . . . .RFE(ii)(iii)•L’interruptpuòverificarsiinqualsiasimomento(i.e.,durantel’esecuzionediqualsiasiistruzione)enonèsincronizzatoconilclock•Assumeremosempreche,l’esecuzionedell’istruzionedurantelaqualesiverifical’interruptsiasempreportataatermineprimadieseguirel’handler
L’is tr uzio n e4èportataatermineprimadieseguirel’interrupthandler"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#7,7,"•EsistonoCPUsensibiliallivellodelsegnalediinterrupt,altrealfrontedisalitaealtreaentrambelecose•NelcasodelDLXassumeremochelaCPUsiasensibileallivellodelsegnale(1sel’interruptèattivoe0incasocontrario)•Nelcasodeidispositivichegeneranointerrupt,assumeremocheessorimangaa1fintantochélacausachelohageneratononsiastatagestitadallaCPU•Pertanto,seunaperifericahauninterruptalivelloasserito,rimanetalefintantochél’interruptnonègestitodallaCPU(nonnecessariamentesubito*)•Inalcunicasi,nell’handlerpuòesserenecessarioeseguiredelleoperazionisoftwareperpoterportareallivellologico0ilsegnalediinterruptprovenientedall’esternodopoavergestitol’eventoSegnaledi interrupt: fronteo livello"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#8,8,"FFDDQ1A_RESINT_FRONTEINT_LIVELLOCS_RESET_INT
•Comefareseildispositivochegeneral’interruptassumechelaCPUsiasensibileaifrontimentrelaCPUèsensibilesoloallivellodelsegnale?•E’necessarioeseguireunatrasformazionedafrontealivellodelsegnaleINT_FRONTE•Inuncasocomequesto,illivellologicodelsegnaleINT_LIVELLOdeveessereportatoazerodaunopportunocomandosoftware(CPU)cheasserisceilsegnaleCS_RESET_INTTrasformazioneda frontea livello"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#9,9,"•C’èperòunproblema:escludendoNMI(discussodopo)ilDLXhaunsolosegnalediinterruptdenominatoINT.Comefacciamoagestire,cometipicamenteaccade,multiplesorgentidiinterrupt?•Siconvogliano(e.g.,medianteunORoaltrefunzioniinbaseallespecificheesigenze)tuttigliinterruptversol’unicosegnaleINTpresentenelDLX•Rimaneunaltroproblema:comedeterminarequale/qualiinterruptsonoasseritiinundeterminatoistante?•Atalpropositoè(tipicamente)necessariopoterdeterminarelostatodellerichiestediinterruptmedianteopportuneistruzionisoftware•Vedremocheesistonoanchedellereti,denominatePIC,chepossonoagevolarequestocompitoallaCPUGestionedi interruzionimultiple"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#0,0,"05 Periferiche di I/O con handshakeCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#1,1,"Porte di Input/Output (I/O)•InprecedenzaabbiamovistocomeprogettaredellesempliciperiferichediI/O,perscambiaredatitraCPUemondoesternomedianteunbuffer•Tuttavia,nonvieranessunagaranziasulcorrettoesitodeitrasferimenti•Infatti,cosaaccadese,mentrelaCPUscrivenellaportainoutput,undispositivoesternoleggedallamedesimaporta?Inoltre,cosaaccadeselaCPUleggeundatocheinrealtànonèmaistatoscrittodaundispositivoesterno?Comepuòsaperlo?Perquesto,itrasferimentisonointrinsecamenteespostiaerrori•Inpiù,lagestionedeltrasferimentieratotalmenteacaricodellaCPU(chepotrebbefarealtro)•LeportediI/Ononeranoingradodigenerareinterruptcontutteleproblematichechenederivano"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#10,10,"WROBFINT_OACKHandshake (OUTPUT): formed’onda
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUTOUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#11,11,"Unesempiodiunitàesternainoutputpotrebbeessererappresentatadaunastampantecheimprimesullacartaunacarattereallavolta.LaCPU,fornisce*idatiallastampanteattraversolaperifericadioutputquandoilsegnaleINT_Oèasserito(questoimplicacheOBFsia0)LastampanteleggeildatosoloquandoilsegnaleOBFèasserito(i.e.,quandolaportainoutputcomunicaallastampantecheunnuovodatoèstatoscrittodallaCPUnelbufferedèquindidisponibile)
OUTPUTINT_OACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK
Lastampantedevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#12,12,"ProgettareunaretelogicabasatasuFFDingradodigestirelecomunicazioniconduedispositiviesterni–unoininputmappatoaCS+0eunoinoutputmappatoaCS+1–utilizzandoilprotocollodihandshakeEsercizio
ParallelI/OBD[7..0]RDINT_ICSA0WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFA_RESETRDINT_ICSBA2WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFRESET
BD[7..0]"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#13,13,"ProgettodellinterfacciaL’interfacciaparallelaèdotatadidueporte,ciascunaingradoditraferiredatia8bit:•PortainINPUTmappataall’indirizzoCS+0•PortainOUTPUTmappataall’indirizzoCS+1Alfinedirisolvereilproblema,risultautilepensarelaportadiI/Ocomecompostadadueporteindipendenti:unaportaininputeunaportainoutputInoltre,nellasoluzionesidesideraevitareclockgatingIlpuntodipartenzasonoleformed’ondadelprotocollodihandhsake,mostratenellepagineprecedenti"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#14,14,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#15,15,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUT01230INPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#16,16,"STBIBFINT_IRDU0U1U2U300 0 010 0 011 0 011 1 011 1 101 1 100 1 100 0 100 0 010 0 011 0 011 1 011 1 1Handshake (INPUT): soluzionesenzaclock gating
013715141280137151otrasferimento2otrasferimento3otrasferimentoOsservando le forme donda, è possibile individuare unasoluzione senza clock gating
Due trasferimenti, un ciclo completo "
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#17,17,"IlsegnaleDEC(x)identificalaconfigurazionebinariaU3U2U1U0equivalenteaxinbase10.Pertanto,isegnaliIBFeINT_Irisultano:IBF=(DEC(1)+DEC(3)+DEC(7))+(DEC(14)+DEC(12)+DEC(8))INT_I=DEC(3)+DEC(12)Oppure,IBF=U0XORU3INT_I=U1XORU2CSèilchip-selectdellaperifericaininputFFDDQ0A_RESQ0*RESETSTBU0FFDDQ1A_RESQ1*RESETSTB*U1
FFDDQ3A_RESQ3*RESETRD*U3Q3*Q310CS·A0*FFDDQ2A_RESQ2*RESETRDU2Q2*Q210CS·A0*"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#18,18,"373D[7..0]Q[7..0]OECCS·RD·A0*D_IN[7..0]BD[7..0]STBHandshake (INPUT): buffer di ingressocon 373 Ipotizzando di mappare la porta in INPUTall’indirizzoCS + 0e di voler utilizzare dei latch 373 come buffer.
Ovviamentesarebbepossibileunasoluzionedeltuttoequivalentecon374comemostratonellapaginasuccessiva"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#19,19,374D[7..0]Q[7..0]OECS·RD·A0*D_IN[7..0]BD[7..0]STB*Handshake (INPUT): buffer di ingressocon 374 IpotizzandodimapparelaportainINPUTall’indirizzoCS+0edivolerutilizzaredeiFFD374comebuffer
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#2,2,"FFD(x8)D[7..0]Q[7..0]CS·RDDI[7..0]BD[7..0]WRITE*Unasempliceperifericaperleggeredatidall’esterno,senzautilizzareinterrupt,èlaseguente:CPU
EsternoTuttavia,conquestasoluzione,sorgonodeglievidentiproblemi:•ComepuòsaperelaCPUcheèdisponibileunnuovodatoscrittodall’esternonellaporta?•Comesipuòsaperedall’esternochelaCPUhalettoildatoscrittoinprecedenzanellaporta?
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#20,20,Esercizio: progettodellaportain outputProgettarelaperifericapergestireitrasferimentiinOutputmediantehandshakeapartiredalleformedondamostratenelleslidesuccessive.OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#21,21,"WROBFINT_OACKHandshake (OUTPUT)
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUT01230OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#22,22,"Registridi statoe programmazioneSarebbeutileaggiungereallaperifericachegestisceinputeoutputconprotocollodihandshakeiseguentiregistri:•Registrodistato(letturasegnalidistatopergestioneapolling)indirizzoA1A0=10•Registrodiprogrammazione(enable/disablesingolainterfaccia,etc)indirizzoA1A0=11Ovviamente,serveunulteriorebit(A1)perindirizzaregliulterioridueregistriEsercizioComesipotrebbemodificareilprogettodellaportadiI/Oconhandshakeperaggiungerequestenuovefunzionalità?"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#23,23,"ProgettareunsistemabasatosulmicroprocessoreDLX,con1GBdiEPROMagliindirizzibassie2GBdiRAMagliindirizzialti.Nelsistemaèpresenteunaportaininput,giàprogettataedenominataINPUT_PORT,eunpulsantedenominatoP.Ilbyte(unsigned)lettodaINPUT_PORTdeveesserememorizzatoall’indirizzoFFFF0020hmentreilregistroR20deveessereincrementatodiuno,viasoftware,aognipressionediPeinizializzatoa0all’avviodelsistema.Inoltre,siassumache:1)IlpulsantePabbiaprioritàmaggiorediINPUT_PORT2)IlpulsantePnonpossaesserepremutoprimachesiaterminatalagestionediPdapartedell’interrupthandler.Atalfinesegnalare,conunLED,quandoilpulsantenondeveesserepremuto3)IregistridaR25aR30possonoessereutilizzatisenzalanecessitàdiessereripristinati4)IlregistroR20siamodificabilesolodall’handlerchegestisceilpulsanteEsercizio"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#3,3,"Unesempiocheevidenziaquestiproblemiriguardaloscambiodibeni/datitraunproduttoreeunconsumatore
Seilproduttoreproduceuncaffècheèprelevatoprimadell’arrivodiunaltrotuttopotrebbeapparentementefunzionarecorrettamente(setupehold?)Tuttavia,comepuòsapereilproduttorecheilcaffèèstatoprelevato?Comepuòsapereilconsumatorecheèdisponibileunnuovocaffèpreparatodalproduttore?Perquesteragioni,sorgonoaltriproblemi...PC
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#4,4,"Unprimoproblemasiverificaseilconsumatoresmettediprelevarecaffèperchénonèpronto(e.g.,ilconsumatoreèaltelefono).Comepuòsaperloilproduttore?
PC
bla,bla,bla"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#5,5,"Ilproblemadualesiverificaseilproduttoresmettediprepararecaffèperchéimpegnatoafarealtro(e.g.,parlarealtelefono).Comepuòsaperloilconsumatore?
bla,bla,bla
•IdueproblemievidenziatipossonoessererisoltiinmodomoltosemplicericorrendoaqualcheformadisincronizzazionetraledueentitàPeC•Perquestoscopol’handshakeèunapprocciosemplice,efficienteeampiamenteutilizzatoPC
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#6,6,"Segnali del protocollo handshake: INPUT
1.SeIBF=0,quandopossibile*UEpuòscrivereildatonelbufferdingressodellaporta2.UE,portandoSTBa1,scriveildatonellaportachecontemporaneamenteasserisceIBF(InputBufferFull)3.QuandoUEportaSTBazero(scritturaterminata),linterfacciaattivaINT_I(InterruptRequest)4.Quandopossibile*,laCPUandràaleggereildatoscrittonellaportadaUE.Altermine,IBFandràazero(mentreINT_Ivaa0,dall’iniziodellalettura)INPUTUnitàEsterna(UE)InputRDINT_IBD[7..0]D_IN[7..0]STBIBFCSRDINTRBD[7..0]CSD[7..0]STBIBF"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#7,7,"STBIBFINT_IRDHandshake (INPUT): formed’ondaINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTCSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#8,8,"Unesempiodiunitàesternaininputpotrebbeessererappresentatadaunsensore(e.g.,ditemperatura)IlsensoreinviaidatiallaCPUattraversolaperifericadiinputquandounanuovamisuraèdisponibileeIBF=0.Alterminediogniscritturanellaportadapartedelsensoreditemperatura,ilsegnaleINT_IsiasserisceINPUTINT_ISTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB
Ilsensoredevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#9,9,"Segnali del protocollo handshake: OUTPUTOUTPUTUnità Esterna(UE)Output1.IlsegnaleINT_OasseritocomunicaallaCPUchelaportapuòaccettareunnuovodato2.InrispostoallarichiestadiinterruptlaCPUscrive,quandopossibile*,ildatosulbufferdellaporta1.LinterfacciasegnalaaUEcheèdisponibileunnuovodatoattivandoOBF(OutputBufferFull)2.Quandopossibile*,UEleggeildatoscrittodallaCPUasserendoACK(acknowledge)WRINT_OBD[7..0]D_OUT[7..0]ACKOBFCSWRINTRBD[7..0]CSD[7..0]ACKOBF"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#0,0,"06 ProgrammableInterrupt Controller (PIC)Calcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#1,1,"•Abbiamogiàvistocheèpossibile,opzionalmente,utilizzareundispositivoad-hocperlagestionedimultiplesorgentiinterruzionidenominatoPIC•IlPICvelocizzaefacilitalafasedianalisiegestionedegliinterrupt•TipicamenteunPICconsentedi:•Abilitaredisabilitaresingoleinterruzioni•Fornireinformazionisulleinterruzioniasserite•Gestirelaprioritàdelleinterruzioni•Perleragionievidenziate,unPICèprogrammabilemediantel’utilizzodiopportuniregistriinterni•Sebbenesiasemprepossibileunagestioneinteramentesoftwaredelleinterruzioni,l’utilizzodiunPICpuòessereunavalidaalternativa•Perquesteragioni,progettiamounPICmoltosempliceGestionedelleinterruzionicon PIC"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#10,10,"EN_INT_0INT_0Diconseguenza,inogniistante,gliinterruptabilitatirisultanodalleuscitediquestarete:EN_INT_1INT_1EN_INT_2INT_2EN_INT_3INT_3RAW_ENABLED_INT_0RAW_ENABLED_INT_1RAW_ENABLED_INT_2RAW_ENABLED_INT_3Si ricorda che, come mostrato nello schema ai morsetti del PIC, risulta:INT_0= INT_OUT_PORT_0INT_1= INT_OUT_PORT_1INT_2= INT_IN_PORT_0INT_3= INT_IN_PORT_1Al pin di interrupt del DLX è pertanto inviato il segnale:INT_DLX= RAW_ENABLED_INT_0+RAW_ENABLED_INT_1+RAW_ENABLED_INT_2+RAW_ENABLED_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#11,11,"Perevitareproblemidimetastabiitàèpossibilecampionarelostatodegliinterrupt,primadiprocedereallalorolettura,peresempioconquattroFFDchecampionanogliinterruptsulfrontedisalitadiMEMRD.RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_0SYNC_ENABLED_INT_0RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_1SYNC_ENABLED_INT_1RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_2SYNC_ENABLED_INT_2RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_3SYNC_ENABLED_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#12,12,"Alfinedileggerelostatodegliinterruptasseriti,traquellichesonostatiabilitati,siutilizzanodeibuffertri-statepilotatidalsegnaleCS_PIC_READ_INTscomesegue:CS_PIC_READ_INTsSYNC_ENABLED_INT_0CS_PIC_READ_INTsSYNC_ENABLED_INT_1CS_PIC_READ_INTsSYNC_ENABLED_INT_2CS_PIC_READ_INTsSYNC_ENABLED_INT_3CS_PIC_READ_INTs‘0000’ENABLED_INT[0]ENABLED_INT[1]ENABLED_INT[2]ENABLED_INT[3]ENABLED_INT[7..4]IsegnaliENABLED_INT[7..0]sonoconnessialbusdatiBD[7..0]44"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#13,13,"Lareteseguente,consentedileggereaCS_PIC_READ_CODEilcodicea16bit(perragionimostratedopo)dell’interruptpiùprioritario(BD[15..0])
CS_PIC_READ_CODESYNC_ENABLED_INT_0·SYNC_ENABLED_INT_1*· SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3* CS_PIC_READ_CODESYNC_ENABLED_INT_1·SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_2·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_3CS_PIC_READ_CODE‘00000000’
CS_PIC_READ_CODE‘0000’INT_CODE[7..0]INT_CODE[8]INT_CODE[9]INT_CODE[10]INT_CODE[11]INT_CODE[15..12]NOTA: come richiesto dal testo del problema, si assegna il seguente ordine crescente di priorità:0) INT_0 (Minima) 1) INT_12) INT_23) INT_3 (Massima)4488"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#14,14,"Icodicidipriorità,a16bitpervelocizzarel’handler,associatiallequattrointerruzionielettiall’indirizzoCS_PIC_READ_CODE,risultano:0800hseèasseritoSYNC_ENABLED_INT_3(massimapriorità)0400hseèasseritoSYNC_ENABLED_INT_2enonSYNC_ENABLED_INT_30200h se è asseritoSYNC_ENABLED_INT_1e non SYNC_ENABLED_INT_2oSYNC_ENABLED_INT_30100h se è asserito SYNC_ENABLED_INT_0e nessun altro segnaleIl codice per abilitare le interruzioni dalle 4 porte risulta:LHI R25,8000h; R25 = 80000000hADDI R26,R0,000Fh; R26 = 0 + 0000000FSBR26,(R25)04h; scrive il byte 0Fh contenuto in R26; all’indirizzo CS_PIC_SET_INTs(80000004h)Il codice per leggere quali sono le interruzioni asserite:LHI R25,8000h; R25 = 80000000hLBUR26,(R25)08h; legge in R26 gli interrupt asseriti, tra quelli; abilitati, all’indirizzo CS_PIC_READ_INTs; (80000008h)"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#15,15,"Il codice dell’interrupt handlerè il seguente:00000000: LHI R25,8000h; prepara indirizzo 80000000h00000004: LHU R26,(R25)0Ch; lettura del codice di priorità a 16 bit; all’indirizzo CS_PIC_READ_CODE00000008: LHIR27,FFFF; prepara in R27 l’indirizzo per : operazioni comuni successive al salto 0000000C: JRR26; salta all’indirizzo presente in R26; checorrisponde al codice di interrupt ; più prioritario letto mediante LHU00000100: LBU R28,(R27)10h; legge in memoria un byte a FFFF0010h00000104: SB R28,(R25)2h; scrive quanto letto in OUTPUT_PORT_000000108: RFE; (80000002h) e ritorna dall’interrupt00000200: LBU R28,(R27)20h; legge in memoria un byte a FFFF0020h00000204: SB R28,(R25)3h; scrive quanto letto in OUTPUT_PORT_100000208: RFE; (80000003h) e ritorna dall’interrupt00000400: LBU R28,(R25)0; legge da INPUT_PORT_0(80000000h)00000404: SB R28,(R27)40h; scrive byte in memoria a FFFF0040h  00000408: RFE; ritorna dall’interrupt00000800: LBU R28,(R25)1; legge da INPUT_PORT_1(80000001h)00000804: SB R28,(R27)80h; scrive byte in memoria a FFFF0080h  00000808: RFE; ritorna dall’interrupt"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#16,16,"RAM_3RAM_2RAM_1RAM_0BA[28..2]Interfacciamento RAMMEMWRMEMRDCS_RAM_0CS_RAM_1CS_RAM_2CS_RAM_3
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[26..0]RD WR CSRD WR CSRD WR CSRD WR CS"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#17,17,"Interfacciamento EPROM
BD[7..0]BD[15..8]BD[23..16]BD[31..24]EPROM_3EPROM_2EPROM_1EPROM_0BA[29..2]MEMRDCS_EPROM_0CS_EPROM_1CS_EPROM_2CS_EPROM_3
A[27..0]RD  CSRD  CSRD  CSRD  CS"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#2,2,"InunsistemabasatosulDLX,con1GBdiEPROMmappatanegliindirizzibassie512MBdiRAMmappatanegliindirizzialti,sonopresentiegiàprogettate2portea8bitinINPUT(IN_1eIN_0)e2portea8bitinOUTPUT(OUT_1eOUT_0)basatesulprotocollodihandshake.ProgettareunsemplicePICalfinediassegnareleseguentiprioritàstaticheallequattrointerruzioni:IN_1(massimapriorità),IN_0,OUT_1eOUT_0(minimapriorità).IlPICdovràinoltreconsentiredi:a)disabilitare/abilitareselettivamente,medianteparoledicontrollo,ciascunainterruzionegeneratadalle4perifericheb)fornireleinterruzioniasserite(traquelleabilitate)c)fornireuncodicecheindicaqualèl’interruzionepiùprioritaria(traquelleabilitate)inundeterminatoistanteUtilizzandolaretelogicaprogettatagestirelequattrointerruzioniinmodochedurantel’esecuzionedell’interrupthandlersiaeseguito,nelmodopiùrapidopossibile,soloiltrasferimentoattivopiùprioritarioinquelmomento.Eventualialtrerichiesteditrasferimentoattivesarannogestitedurantesuccessiveesecuzionidell’interrupthandler.IdatilettidalleporteinINPUTdovrannoesserescrittiaFFFF0080(IN_1)eFFFF0040(IN_0)mentreidatidascriverenelleporteinOUTPUTdovrannoesserelettidaFFFF0020(OUT_1)eFFFF0010(OUT_0).All’avviodelsistemailPICdovràautomaticamentedisabilitaretuttelerichiestediinterruzioneprovenientidallequattroporte.-ScrivereilcodicecheabilitatutteleinterruzioninelPICeilcodicecheconsentedileggerelostatodegliinterrupt-Scrivereilcodiceottimizzatodell’interrupthandler(iregistridaR25aR29possonoessereutilizzatisenzalanecessitàdidoverliripristinare).Progettodi un semplicePIC"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#3,3,"PICProgrammableInterruptControllerA_RESETINT_0 (-)INT_1INT_2INT_3 (+)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_INTs_CODED[3..0]INT_TO_DLXENABLED_INT[7..0]INT_CODE[15..0]4816BD[7..0]BD[15..0]BD[3..0]INT(to DLX)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_CODEINT_OUT_PORT_0INT_OUT_PORT_1INT_IN_PORT_0INT_IN_PORT_1RESETIlPIC(ProgrammableInterruptController),ingradodigestire4interruzioni,puòessereschematizzatonelmodoseguente:
RDWRMEMRDMEMWR"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#4,4,"NelPIC,lamassimaprioritàèassegnataaINT_3,quellaminimaaINT_0.Leprioritàsonostatiche,comeprevistodaltesto.IsegnalidiingressodelPICINT_3,INT_2,INT_1eINT_0sonoconnessiai4interruptdelleperifericheinmododasoddisfareivincolisullaprioritàprevistidaltestodelproblema.ScrivendoaCS_PIC_SET_INTs,idatipresentisuipinD[3..0]consentonodiabilitare/disabilitareisingoliinterrupt.Gliinterruptasseritidalleperiferiche,traquelliabilitati,possonoessereletti,aCS_PIC_READ_INTs,attraversoisegnaliENABLED_INT[7..0].Essendoprevistisolo4interrupt,4degli8bitsonocablatia0(i4bitpiùsignificativi).Ilcodicechecorrispondeall’interruptpiùprioritario,traquelliabilitati,potràessereletto,aCS_PIC_READ_CODE,attraversoisegnaliINT_CODE[15..0].Diquestiultimi16segnali,12sarannosemprecablatia0perragionichiariteinseguito."
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#5,5,"Dispositivi e segnali presenti nel sistemaMemorie:RAM_512_MBmappata da E0000000h:FFFFFFFFh, 4 banchi da 128 MBEPROM_1_GB mappata da 00000000h:3FFFFFFFh, 4 banchi da 256 MBPorte di input, output e altri chip-selecte/o segnali:CS_INPUT_PORT_0mappato a 80000000hCS_INPUT_PORT_1mappato a 80000001hCS_OUTPUT_PORT_0mappato a 80000002hCS_OUTPUT_PORT_1mappato a 80000003hCS_PIC_SET_INTsmappato a 80000004hCS_PIC_READ_INTsmappato a 80000008hCS_PIC_READ_CODEmappato a 8000000Ch"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#6,6,"Segnali di decodifica di memorie, periferiche e segnali:CS_RAM_0 = BA31·BA30·BE0CS_RAM_1= BA31·BA30·BE1CS_RAM_2= BA31·BA30·BE2CS_RAM_3= BA31·BA30·BE3CS_INPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE0·IBF_0mappato a 80000000hCS_INPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE1·IBF_1mappato a 80000001h CS_OUTPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE2·OBF_0*mappato a 80000002h CS_OUTPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE3·OBF_1*mappato a80000003hCS_PIC_SET_INTs= BA31·BA30*·BA3*·BA2mappato a 80000004hCS_PIC_READ_INTs= BA31·BA30*·BA3·BA2*·MEMRDmappato a 80000008hCS_PIC_READ_CODE= BA31·BA30*·BA3·BA2·MEMRDmappato a 8000000ChCS_EPROM_0 = BA31*·BE0 CS_EPROM_1= BA31*·BE1CS_EPROM_2 = BA31*·BE2CS_EPROM_3 = BA31*·BE3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#7,7,"INPUTPORT_0D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_0MEMRDUNITA’ESTERNA#0INT_IN_PORT_0BD[7..0]IBF_0Nelsistemasonopresentidueporteininput,collegateaibusdatiBD[7..0](INPUT_PORT_0)eBD[15..8](INPUT_PORT_1)
INPUTPORT_1D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_1MEMRDUNITA’ESTERNA#1INT_IN_PORT_1BD[15..8]IBF_1STB_1STB_0A_RESETRESET
A_RESETRESET"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#8,8,"OUTPUTPORT_0D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFA_RESETCS_OUTPUT_PORT_0MEMWRRESETUNITA’ESTERNA#2INT_OUT_PORT_0     BD[23..16]NelsistemasonopresentianchedueporteinoutputcollegateaibusdatiBD[23..16](OUTPUT_PORT_0)eBD[31..24](OUTPUT_PORT_1)
OUTPUTPORT_1D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFCS_OUTPUT_PORT_1MEMWRUNITA’ESTERNA#3INT_OUT_PORT_1     BD[31..24]ACK_1OBF_1ACK_0OBF_0
A_RESETRESET"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#9,9,"RESETFFDDQA_RES10MEMWR*D0EN_INT_0AlfinediabilitareedisabilitareselettivamentegliinterruptsipossonoutilizzarequattroFFD.IquattrobitD[3..0]sonoconnessiaisegnaliBD[3..0]delbusdatieutilizzatipercondizionareognisingolainterruzionemedianteisegnaliEN_INT_0,EN_INT_1,EN_INT_2eEN_INT_3generatidalleretiseguenti:CS_PIC_SET_INTsEN_INT_0RESETFFDDQA_RES10MEMWR*D1EN_INT_1CS_PIC_SET_INTsEN_INT_1RESETFFDDQA_RES10MEMWR*D2EN_INT_2CS_PIC_SET_INTsEN_INT_2RESETFFDDQA_RES10MEMWR*D3EN_INT_3CS_PIC_SET_INTsEN_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#0,0,"DLX: implementazione sequenziale  Calcolatori Elettronici T Ingegneria Informatica 
"
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#1,1,"Datapath e Unità di Controllo  • La struttura di una CPU, come tutte le reti logiche sincrone che  elaborano dati, può essere strutturata in due blocchi: Unità di Controllo e Datapath  • La CPU, per funzionare, ha bisogno della memoria esterna su cui risiedono il programma e i dati 
reset interrupt ready 
CPU istruzioni Dati (in)  indirizzi 
Dati (out) U.d.C. Data Path clock memoria Rete logica CPU "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#10,10,"Estrazione “automatica” dei registri durante la fase di decode di una istruzione (qualsiasi)  I Codice  operativo  RS2/Rd RS1 Operando immediato di 16 bit J Codice  operativo  Offset di 26 bit (PC relative) R Codice  operativo  RS2 RS1 Rd Estensione al Cod. op (11 bit) 0 31 < A B 
Questi 5 + 5 bit  sono utilizzati per estrarre, preventivamente e ancora prima di conoscere che tipo  di istruzione che è stata letta dalla memoria, dal Register File due registri in A e B. Nel caso di  istruzione J non ci sono registri coinvolti e quindi saranno estratti bit corrispondenti all’offset. Nel  caso di istruzione I, in B potrebbe finire il valore del registro destinazione (e.g. in una LD o  operazione ALU (tipo I)). Infine: i 5 + 5 bit rappresentano gli indici (o presunti tali) ma non il valore dei due registri che è  contenuto nel Register File. "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#11,11,"Gli stati della fase di fetch  • In questa fase si deve verificare se è presente un interrupt (evento esterno asincrono che la CPU deve “servire” con apposito software); • se l’interrupt è presente e può essere servito (IEN = true) si esegue implicitamente l’istruzione di chiamata a procedura all’indirizzo 0, e si salva l’indirizzo di ritorno nell’apposito registro IAR; • se l’interrupt non è presente o le interruzioni non sono abilitate, si va a leggere in memoria la prossima istruzione da eseguire (il cui indirizzo è in PC) MAR ← PC Dall’ultimo stato  dell’istruzione precedente  IAR:  Interrupt  Address  Register  IAR ← PC PC ← 0 IEN ← 0 IEN:  Interrupt  Enable  Flag  (int and IEN) = 1 (int and IEN) = 0 IR ← M(MAR) Alla fase di decodifica Ready = 1 Ready = 0 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#12,12,Si modifica il  DATAPATH in  maniera da poter  indirizzare  la memoria dal PC.  Meno stati ma maggiore complessità  Data transfer ALU Set Jump Branch Ready ? INSTRUCTION FETCH INSTRUCTION  DECODE* Tutte le istruzioni impiegano un clock in meno per essere eseguite !  Ma potenzialmente aggiore lentezza  -> minore freq. clock Il diagramma  degli  stati del  controller  PC <- PC +4  A <- RS1 B <- RS2  IR <- M [PC] 
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#13,13,"Ready ? IR <- M [PC] 
 MAR <- A + (IR15)16 ## IR15..0 LOAD MDR <- M[MAR]  LB Ready ? C <- (MDR7)24 ## MDR7..0 RD <- C   PC <- PC +4  A <- RS1  B <- RS2  Controllo per  l’istruzione LB  (LOAD BYTE) ALU ALU Parte comune 
RS2 è da intendersi come registro di destinazione (A) = (RS1) Estensione segno "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#14,14,"Estensione del segno   (IR15)16 ## IR15..0 0    15      31 IR 
31 30…………17  16 BUS S1 o S0 Da UdC 
15-0 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#15,15,"MDR <- M[MAR]
MDR <- B.C <- MDRRD <- C M[MAR] <-MDRINIT STORE 
LB LBU LH LHU LW Controllo per  le istruzioni di  DATA  TRANSFER  LB  LBU LH LHU LW STORE  Byte -> SB Half Word –> SH Word -> SW  C <-(MDR7)24 ## MDR7..0C <- (0)24 ## MDR7..0C <- (MDR15)16 ## MDR15..0 C <-(0)16 ## MDR15..0MAR <- A + (IR15)16 ## IR15..0 LOAD 
Mancano nell’esempio  SH e SB (sempre unsigned)  che corrispondono a attivazione degli specifici WE delle memorie e “traslatori” dei bytes del registro MDR.  Come si realizzerebbero ?  NB: in lettura la parte meno  significativa del dato viene letta  sempre allineata al registro MDR per permettere il filling SW Il contenuto di A come unsigned Ready ? 
Ready ? "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#16,16,"17  17  Trasferimenti BYTE, HW  •  I trasferimenti di bytes sono SEMPRE considerati allineati •  I trasferimenti di HW debbono avvenire a indirizzi multipli di 2 •  I trasferimenti di Word debbono sempre avvenire a indirizzi multipli di 4 •  In caso di disallineamento: fault •  Nel caso di store di dati di dimensione inferiore alla word NON si ha estensione del segno •  La lettura/scrittura di bytes e HW (a causa del reciproco disallineamento fra i registri e la memoria) implica che fra i registri e la memoria siano interposti dei mux/demux (realizzati con tristate) Registro MDR 
Memoria Come sono attivati i WE delle memorie ? Progettare la rete  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#17,17,"Trasferimenti BYTE, HW  MDR 
Memoria 31 0 Mux Demux I MUX 23-16 e 31-24 hanno come ingresso anche il bit 7 del byte 7-0 della memoria (LB) e il bit 15 del byte 15-8 della memoria (LH)  Ad esempio in una LB il MUX 7-0 si collega direttamente alla memoria mentre i MUX 15-8, 23-16 e 31-24 si collegano al bit 7 del MUX 7-0 proveniente dalla memoria.  In una SH a indirizzo multiplo di 2 e non di 4  il DEMUX 7-0  dal MDR si collega alla memoria 23-16 e il DEMUX 15-8 alla memoria 31-24. Gli altri due bytes della memoria rimangono invariati Mux Demux “0” Bit più signif. byte precedenti Solo in lettura Trasferimento  “unsigned” 24 23 16 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#18,18,"C <- A + TempC <- A xor TempC <- A - Temp C <- A and TempC <- A or TempINIT RD <- CRegistro (formato R) Immediato (formato I) 
ADD AND SUB XOR OR   Temp <- BTemp <- (IR15)16 ## IR15..0Esempi di istruzioni  ALU  Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP  Lo stesso schema si può usare per gli shift etc.  Il contenuto dei registri come signed se op aritmetica "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#19,19," RD <- C A = Temp
C <- 1SEQ SLT SGE SNE SGT SLE YES NO  Il risultato del test è un input per il controller ! Registro (formato R) Immediato (formato I) Controllo per  le istruzioni  di SET  (confronto) ex. SLT R1,R2,R3  
INIT Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP   Temp<- BTemp <- (IR15)16 ## IR15..0 A < Temp A >= Temp A <= Temp A > Temp A! = TempC <- 0I micropassi sono eseguiti  in ALU ma il risultato  NON è memorizzato in un registro: i flag sono utilizzati dalla ALU per impostare (almeno) il bit 0 del registro C  Il contenuto dei registri come signed "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#2,2,"•  Datapath: contiene tutte le unità di elaborazione ed  i registri necessari per l’esecuzione delle istruzioni  della CPU. Ogni istruzione appartenente all’ISA è  eseguita mediante una successione di operazioni  elementari, dette micro-operazioni •  Micro-operazione: operazione eseguita all’interno  del DATAPATH in un ciclo di clock ( e s e m p i :  trasferimento di un dato da un registro ad un altro  registro, elaborazione ALU) •  Unità di Controllo: è una RSS che in ogni ciclo di  clock invia un ben preciso insieme di segnali di  controllo al DATAPATH al fine di specificare  l’esecuzione di una determinata micro-operazione  Datapath e Unità di Controllo  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#20,20,"INIT  C <- PCJALR JAL JMP JR JALR 
JALR JR JAL 
JMP JAL JALR  JAL Controllo per  le istruzioni  di JUMP  (IR15)16 ## IR15..0  C <- PC
PC <-  PC + (IR25)6 ## IR25..0 PC <- A R31 <- CPer il salvataggio in R31 
Istruzione  formato I  Istruzione  formato J  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#21,21,"INIT A = 0 BRANCH 
YES YES NO NO BEQZ BNEZ Controllo per  le istruzioni  di BRANCH  A! = 0 PC <-  PC + (IR15)16 ## IR15..0 Ex. BNEQZ R5, 100 Il controllo se 0 (o !=0) è fatto sull’intero registro A (a 32 bit) e non solo sul bit meno significativo "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#22,22,"Numero di clock necessari per eseguire le istruzioni  Istruzione Cicli Wait Totale Load 6 2 8 Store 5 2 7 ALU 5 1 6 Set 6 1 7 Jump 3 1 4 Jump and link 5 1 6 Branch (taken) 4 1 5 Branch (not taken) 3 1 4 CPICPIN numero totale di istruzioni iin=i = 1 ∑(*)Esempio su DLX  LOAD: 21%, STORE: 12%, ALU: 37%, SET: 6%, JUMP: 2% BRANCH (taken): 12%, BRANCH (not-taken): 11%    CPI = 6.3 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#23,23,"Controllo cablato (“hardwired”) Segnali di  controllo 
INSTRUCTION REGISTER (IR) 40 Opcode +  OpCode Extension   6 Datapath Stato presente Rete combinatoria che  genera uscite e stato futuro Int e ready 2 6+11 3 Stato futuro 228 righe Rs1, Rs2, Rd - Indici di Rs1, Rs2 e Rd provengono da IR - IR25..0 sono portati ai bus S1 ed S2 del data path attraverso due buffer tristate IR25..0 U.d.C. 
32 bit dalla  memoria - U.d.C. genera anche i segnali di comando per la memoria (MEMRD e  MEMWR) Flag "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#24,24,"I passi dell’esecuzione delle istruzioni  Nel DLX l’esecuzione di tutte le istruzioni può essere scomposta in 5 passi, ciascuno eseguito in uno o più cicli di clock.   Tali passi sono detti:  1) FETCH:   l’istruzione viene prelevata dalla memoria e posta in IR.  2) DECODE: l’istruzione in IR viene decodificata e vengono prelevati gli   operandi sorgente dal Register File.   3) EXECUTE: elaborazione aritmetica o logica mediante la ALU.   4) MEMORY: accesso alla memoria e, nel caso di BRANCH aggiornamento   del PC (“branch completion”).   5) WRITE-BACK:   scrittura sul Register File. "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#25,25,"Le micro-operazioni eseguite  in ciascun passo  1) FETCH MAR   ß PC ;   ß  M[MAR]; 2) DECODE A  ß RS1, B  ß RS2,  PC  ß PC+4 IR   "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#26,26,"Le micro-operazioni eseguite  in ciascun passo  MEMORIA: MDR   ß   B;        ALU:   BRANCH: 3) EXECUTE MAR      A + (IR15)16 ## IR15..0 ; ß C  <- A op B (oppure A op (IR15)16 ## IR15..0) ; Temp       PC + (IR15)16 ## IR15..0) ; (utilizza ALU, S1, S2, dest: qui non si sa       ancora se si deve saltare) ß (utilizzano ALU, S1, S2, dest)  C <-  sign( A op B (oppure A op (IR15)16 ## IR15..0));  se SCn (NB: serve nelle Store  ove RD=RS2 operazione non significativa nelle LOAD)  J e JAL  Temp       PC + (IR25)6 ## IR25..0) ;  ß JR e JALR Temp       A;  ß "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#27,27,"Le micro-operazioni eseguite  in ciascun passo  4) MEMORY MDR   ß M[MAR];  (LOAD) ß  MDR;    (STORE)  BRANCH: M[MAR]  If (Cond)      PC       Temp; ß Memoria: 
[A] è il registro che condiziona il salto (Cond) ; JAL e JALR: C       PC; ß "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#28,28,"5) WRITE-BACK RD  ß C ; C ß MDR; (se è una LOAD – due micropassi)) Le micro-operazioni eseguite  in ciascun passo  
PC       Temp; ß  istruzioni J, JR, JAL, JALR  istruzioni diverse da J, JR, JAL, JALR RD  ß C ; "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#3,3,"Register file C A B Struttura del DLX (esecuzione sequenziale)  
TEMP IAR PC S1 S2 dest alu 
CPU Memoria dati in scrittura dati/istruzioni in lettura Indirizzi Instruction register C O N T R O L U N I T 
fetch MDR MAR execute Parallelismo dell’architettura: 32 bit (bus, alu e registri hanno parallelismo 32) I segnali di controllo non sono riportati !  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#4,4,"I registri del DLX (tutti a 32 bit)  • Register f i l e: 32 General Purpose Registers R 0 … . R 3 1  con  R0=0 • IAR: Interrupt Address Register –  D e p o s i t o  dell’indirizzo di ritorno in caso di interruzione • PC: Program Counter • MAR: Memory Address Register –  C o n t i e n e  l’indirizzo  del dato da scrivere o leggere in memoria • IR: Instruction Register –  C o n t i e n e  l’istruzione  attualmente in esecuzione • TEMP: Temporary Register –  R e g i s t r o  d i  d e p o s i t o  temporaneo di risultati  • MDR: Memory Data Register –  R e g i s t r o  d i  t r a n s i t o  temporaneo dei dati da e per la memoria • A e B: Registri di uscita dal Register File A parte il Register File questi registri NON sono accessibili  al programmatore. In alcuni casi istruzioni speciali per  accedere ad alcuni (e.g., IAR) "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#5,5,"Funzioni della ALU       Dest (uscite) – 4 bit di comando  S1 + S2 S1 – S2 S1 and S2 S1 or S2 S1 exor S2 Shift S1 a sinistra di S2 posizioni Shift S1 a destra di S2 posizioni Shfit S1 aritmetico a destra di S2 posizioni S1 S2 0 1   Flag di uscita  Zero Segno negativo Carry 
• La ALU è una rete PURAMENTE combinatoria • Non esiste nel DLX un registro di flag "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#6,6,"Trasferimento dati sul datapath • I bus S1 ed S2 sono multiplexati (tri-state) con parallelismo 32 bit. • I registri campionano sul fronte positivo del clock, hanno due porte di uscita O1 e O2 per i due bus (o i registri A e B) e dispongono di tre ingressi di controllo:  – un ingresso di Write Enable (WE*)  ed  uno di Output Enable per ogni porta di uscita, una per ogni bus S1 e S2 (OE1* e OE2*). • Al fine di valutare la massima frequenza a cui è possibile far funzionare il datapath è importante conoscere le seguenti temporizzazioni: – TC (max) : ritardo max tra il fronte positivo del clock e l’istante in cui i  segnali di controllo generati dall’unità di controllo sono validi; – TOE (max): ritardo max tra l’arrivo del segnale OE e l’istante in cui i dati del registro sono disponibili sul bus; – TALU (max): ritardo massimo introdotto dalla ALU; – TSU (min)  : tempo di set-up minimo dei registri (requisito minimo per il corretto campionamento da parte dei registri).  • La massima frequenza di funzionamento del data path si calcola come segue:      fCK(max) = 1/TCK TCK  > TC (max) + TOE (max) + TALU (max) + TSU (min) "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#7,7,"Esempio : esecuzione della microistruzione  Rin ← Rout  S2 
alu WE*  OE1* OE2* WE* OE1* OE2* S1 Rout Rin dest clock O2 O1 O2 O1 I I i1 i2 u = i2 WERin* OE2Rout* I segnali in blu (segnali di controllo) provengono dall’Unità di Controllo 
I segnali di controllo in grassetto sono attivi nel ciclo di clock in cui il micro-step Rin ← Rout viene eseguito  (e.g. TEMP) (e.g. MAR) Clock sempre collegato:  write enable !  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#8,8,"Il progetto dell’Unità di Controllo  • Una volta definito il Set di Istruzioni e progettato il DATAPATH, il passo successivo del progetto di una CPU è il progetto dell’Unità di Controllo  (CONTROLLER). • Il CONTROLLER è una RSS: il suo funzionamento può essere specificato tramite un diagramma degli stati.  •  Il CONTROLLER (come tutte le RSS) permane in un determinato stato per un ciclo di clock e transita (può transitare) da uno stato all’altro in corrispondenza degli istanti di sincronismo (fronti del clock).  •  Ad ogni stato corrisponde quindi un ciclo di clock.  Le micro-operazioni che devono essere eseguite in quel ciclo di clock sono specificate (in linguaggio RTL) nel diagramma degli stati che descrive il funzionamento del CONTROLLER all’interno degli stati. •  A partire dalla descrizione RTL si sintetizzano poi i segnali di controllo che  devono essere inviati al DATAPATH per eseguire le operazioni elementari  associate ad ogni stato.   "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#9,9,"Il diagramma  degli  stati del  controller  Data transfer ALU Set Jump Branch Ready ?  IR <- M [MAR] INSTRUCTION  FETCH INSTRUCTION  DECODE* MAR <- PC  
 PC<- PC+4 A <- RS1 B <- RS2 Oltre a decodificare l’istruzione si prelevano  gli operandi sorgente dal RF (anche se non utilizzati !) e si incrementa il PC.  Qui non si sa ancora quale sia l’istruzione ma il trasferimento ai registri è fatto  comunque !! N.B. I primi tre stadi sono comuni a tutte  le istruzioni  "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#0,0,"ISA DLX: implementazione pipelinedCalcolatori Elettronici TIngegneria Informatica
"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#1,1,"Principio del PipeliningIl pipeliningè oggi la principale tecnica di base impiegata per rendere veloceuna CPU . Lidea alla base del pipeliningè generale, e trova applicazione in molteplici settori dellindustria (linee di produzione, oleodotti …)Un sistema, S, deve eseguire Nvolte unattività A: A1 , A2 , A3…ANSR1 , R2 , R3…RNLatency: tempo che intercorre fra linizio ed il completamentodellattività A(TA).Throughput: frequenza con cui vengono  completate le attività."
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#10,10,"Requisiti per l’implementazione in pipeline•Ogni stadio deve essere attivo in ogni ciclo di clock. •Enecessario incrementare il PC in IF (invece che in ID).•Enecessario introdurre un ADDER (PC <--PC+4 –PC <-PC+1) nello stadio IF.•Sono necessari due MDR (che chiameremo LMDR e SMDR) per gestire il caso di una LOAD seguita immediatamente da una STORE (WB-MEM sovrapposti –sovrapposizione di due dati in attesa di essere scritti, uno in memoria e l’altro nel RF). •In ogni ciclo di clock devono poter essere eseguiti 2 accessi alla memoria (IF, MEM): InstructionMemory (IM) e Data Memory (DM) ->  Architettura ‘Harvard’•Il clock della CPU è determinato dallo stadio più lento: IM, DM devono essere delle memorie cache(on-chip) •I Pipeline Registerstrasportano sia dati sia informazioni di controllo (l’unità di controllo è ‘distribuita’  fra gli stadi della pipeline)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#11,11,"GerarchiadellamemoriaL0 (registri CPU)L1L2L3Memoria (DDR)
DiscoCosto/ByteTempo di accessoH
LL
HCPU "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#12,12,"13MemoriecacheCPUCacheMemoria (DDR)Una(opiùlivelli)memoriavelocemadiridottedimensioni,iecache,ingradodisfruttareilprincipiodilocalitàfannoapparirela(lenta)memoriaDDRmoltopiùveloce"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#13,13,"14
Area di silicio occupata da cache L1,L2,L3 in un Intel Core i5Fonte: https://thecodeartist.blogspot.com/2011/12/why-readmostly-does-not-work-as-it.html"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#14,14,"IFIDEXMEMWBDatapath in Pipeline del DLX
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBEstensionedel segnoNumero reg. dest.nel caso di LOADe ALU instr.JL (il PC in   R31)JLRPer il calcolo del nuovo PC nei salti
Per le operazioni con immediatiRDDRS1RS2
Numero del registro di destinazioneDatiPCIn realtà è un contatore programmabile  visto che i due bit meno significativi sono a 0se saltoContiene anche i circuiti di swapPer SCn(anche <0 e >0)[agisce sulluscita]
=0?per BranchDurante JMP e BRANCH taken in IF/ID entra PC… Pazienza, sarà eliminata l’istruzione mediante NOP"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#15,15,"Stadiodi Fetch con contatore1/2
Counter 30 bitENU[29..0]ClockSTALL*LDJUMPPC[31..2]I[29..0]JUMP_ADDRESS[31..2]
Sempre con riferimento allo stesso schema del DLX. Il segnale JUMPcodifica se il DLX deve saltare alla destinazione specificata daJUMP_ADDRESS[31.2]. Entrambi i segnali sono inviati dallo stadio MEM.Il segnale STALL, è generato dalla Unità di Controllo quando lostadio di IF deve essere bloccato. PC (to memory)ConriferimentoalprimoschemadelDLXpipelinedstudiatoduranteilcorso(maconsiderazionianaloghesiapplicanoallealtreversionidelDLX),lareteseguenteconsentedisostituireloschemabasatosuregistroemultiplexerconuncontatorea30bit(iduebitmenosignificatividell’indirizzosonosuperfluiperchéilDLXesegueilfetchsempreaindirizziallineati).PC +1 (to IF/ID)Come?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#16,16,"REGISTER30 bitStadio di Fetch con contatore 2/2Un’osservazione: come possiamo generare PC + 1 per lo stadio IF/ID(quando viene eseguito il fetch a PC è necessario fare entrare nellapipeline (stadio IF/ID) PC +1 ?
CKD[29..0]OUT[29..0]+1PC +1 (to IF/ID)
PC  (to memory)Stato presenteStato futuro
PC[31..2]"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#17,17,"Sezione IDIRRFSERDDRS1RS2IF/IDID/EX
IR25-21IR20-16
Numero registro destinaz.(dallo stadio WB) Dati (dallo stadio WB)(31-16) Immed./Branch(31-26)  JumpIR15IR25LBSWIR31-26 (Codop)IR15-0    (Offset/Immediato/Branch/Load -Reg. dest.)IR25-16   (J; JL))
PC31-0    (JAL)PCAB26 (J e JL)
61632323232
32Info che viaggiacon listruzioneIR10-00 (ExtCO)DEC
Estensione segno"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#18,18,"Datapath in Pipeline del DLX ADD4MUX
DMALUMUXMUXIMRFSEPCDEC
MUXIF/IDID/EXEX/MEMMEM/WBIR1ABIR2PC2CONDX
X: ALUOUPUT/DMAR/BTASMDRYLMDR
Y: ALUOUPUT1IFIDEX MEMWBPC1PC3PC4IndirizzoDatiIR3IR4n.  registro di destinazionePer SCn(anche <0 e >0)[agisce sulluscita]
=0?=0?per BranchJLJLR(il PC in R31)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#19,19,"Esecuzione in pipeline di istruzione ALU
X : ALUOUTPUT(in EX/MEM),  Y : ALUOUTPUT1NB in questa come nelle altre istruzioni RD (RS2) è trasferita fino allo stadio WBIFIDEXMEMY <-X (parcheggioin attesa di WB)WBRD <-YIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;X <-A op BoppureX <-A op (IR215)16##IR215..0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]N.B. al passare degli stadi IRperde i bit che non servono più in tutte le istruzioni. Da uno stadio al successivo vengono mantenuti i bit che servono qualunque sia listruzione"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#2,2,"Motore: 2000 ccTipo:BenzinaColore:Rosso
"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#20,20,Esecuzione in pipeline di istruzione MEMIFIDEXMEMLMDR <-M[MAR]  (LOAD)oppureM[MAR] <-SMDR  (STORE)WBRD <-LMDR   (LOAD)  [ext. Segno]IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;MAR <-A op (IR215)16##IR215..0SMDR <-B[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2[IR4  <.-IR3]
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#21,21,"Esecuzione in pipeline di istruzione BRANCH 
X : BTA (BRANCH TARGET ADDRESS)IFIDEXMEMif (Cond) PC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-PC2 op (IR15)16##IR15..0Cond <-A op 0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3Il test avviene sul valore del registro"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#22,22,"Esecuzione in pipeline di unistruzione JRIDMEMWBIFIDEXMEMPC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-A [PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]
Come sarebbe la sequenza degli stati per una J ?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#23,23,"Esecuzione in pipeline di istruzione JL  o JLRIDIFIDEXMEMPC <-X ; PC4<-PC3WBR31 <-PC4IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;PC3 <-PC2X <-A (Se JLR)     X <-PC2 + (IR25)6##IR25..0(Se JL)
NB: La scrittura in R31 NON può essere anticipata perché potrebbe sovrapporsi ad altra scrittura di registro Decod. in tutti gli stadi[IR4 <-IR3][IR3  <.-IR2]
Evidenziati perché in questo caso utilizzati"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#24,24,"25Qual sarebbe la sequenza nel caso di SCN  (ex SLT R1,R2,R3) ?IDIFIDEXMEMWBIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;???"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#25,25,"Alee nelle Pipeline•AleeStrutturali-Unarisorsaècondivisafraduestadidellapipeline:leistruzionichesitrovanocorrentementeintalistadinonpossonoessereeseguitesimultaneamente.•AleediDato–Sonodovuteadipendenzefraleistruzioni.Adesempiounaistruzionecheleggeunregistroscrittodaunistruzioneprecedente(RAW).•AleediControllo–Leistruzionicheseguonounbranchdipendonodalrisultatodelbranch(taken/nottaken).SiverificaunasituazionediAlea(Hazard)quandoinundeterminatociclodiclockunistruzionepresenteinunostadiodellapipelinenonpuòessereeseguitainquelclock.
Listruzionechenonpuòessereeseguitavienebloccata(stallodellapipeline),insiemeatuttequellechelaseguono,mentreleistruzionichelaprecedonoavanzanonormalmente(cosìdarimuoverelacausadellalea)."
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#26,26,"Clk 6Clk 7Clk 8Alee e Stalli
IDIFIDEXMEMWBIi-3Ii-2Ii-1IiIDEXMEMIDEXIDIFIFIFIFIi+1Clk 1Clk 2Clk 3Clk 4Clk 5WBClk 9Clk 10Clk 11Clk 12WBWBT5=  8 * CLK = (5 + 3) * CLKT5= 5 * (1 + 3/5 ) * CLKCPI  idealeStalli per istruzioneTN= N *  1  * CLKTN= N *  (1 + S) * CLKCPI  effettivoSSSSSIFSMEMWBStallo: blocco del clock dello stadio e di tutti quelli precedentie propagazione progressiva agli stadi successiviEffetto–adesempio-diunaaleadidato:selistruzioneIinecessitadiundatoprodottodallaistruzioneIi-1deveaspettarefinoalWBdellaIi-1"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#27,27,"IFIDEXMEMWBStalli nel salto (1/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoal campionamento della  verifica della condizione di salto sono inserite 3 NOP al posto dei codici operativi provenienti dalla memoria"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#28,28,"IFIDEXMEMWBStalli nel salto (2/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoalla verifica della condizione di salto sono inserite 2 NOP al posto dei codici operativi provenienti dalla memoriaNB In questo caso la condizione di salto e il nuovo PC sono presentatial MUX nello stesso periodo di produzione  della condizione"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#29,29,"IFIDEXMEMWBStalli nel salto (3/3)ADD4
DATAMEMALUMUXMUX=0?INSTRMEMRFSEDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOP per salto
Al primo fronte positivo del clock successivoalla produzione della verifica della condizione di salto e inserita una NOP al posto del codice operativo proveniente dalla stadio IF/IDNB In questo caso la condizione di salto e il nuovo PC agisconosul MUX nello stesso periodo di produzione  della condizione
PCMUX"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#3,3,"Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
t"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#30,30,"ForwardingADD  R3, R1, R4Clk 6Clk 7Clk 8MEMWBIFIDEXMEMWBIDEXMEMIDEXIDIFIFIFIFClk 1Clk 2Clk 3Clk 4Clk 5WBEXMEMIDEXClk 9MEMWBWBIDIDIDIl forwardingconsente di eliminare quasi tutte le alee di tipo RAW dellapipeline del DLX senza stallarela pipeline. (NB: nel DLX si alteranoi registri  soloin WB)SUB  R7, R3, R5 aleaOR  R1, R3, R5 aleaLW  R6, 100 (R3) aleaAND R9, R5, R3  no aleaAnche qui il dato non è ancora in RF per essere estratto in ID !"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#31,31,"Implementazione del ForwardingFU
EX/MEMMUXMEM/WBALUMUXID/EXMUXMUXRS1/RS2CODOPRD2/CodOpRD1 (registro di destinazione/CodOpConfronto fraRS1, RS2 e RD1, RD2 e i cod. Op.RFMUX
Spesso realizzato allinterno del RFOppure SPLIT-CYCLE(v. dopo)scrittura prima di lettura
Permette di anticipareil registro su ID/EXControllo MUX: codice operativo IF/ID e confronto RD con RS1 e RS2 IF/IDFU –> Forwarding Unit"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#32,32,"33Split-cycleT
In questo semiperiodo si scriveil registroIn questo semiperiodo si leggeil registro"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#33,33,"34Alea di dato dovuta alle istruzioni di LOAD
N.B.ildatorichiestodallaADDèpresentesoloallafinediMEM.Laleanonpuòessereeliminataconilforwarding(amenodinonaprireunaulteriorediingressoaimuxdellaALUdallamemoria–ritardi!)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7LW    R1,32(R6)MEMWBIFIDEXMEMIFIDEXIFIDIFIDEX
LW     R1,32(R6)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7IFIDEXMEMWBIFIDSEXMEMIFSIDEXSIFIDEnecessario stallare lapipelineDi fatto non viene generato il clock. Il blocco di un  clock si propaga lungo  la pipeline uno stadio alla volta. Dalla fine di questo stadio in poi normale forwarding"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#34,34,"Delayed loadIn diverse CPU RISC lalea associata alla LOAD non è gestita in HW stallando la pipeline ma è gestita via SW dal compilatore (delayed load): Istruzione LOADdelay slotIstruzione SuccessivaIl compilatore cercadi riempire il delay-slotcon unistruzione utile(caso peggiore: NOP).LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#35,35,"36Alee di Controllo
BEQZ R4, 200PCBEQZ R4, 200PC+4SUB  R7, R3, R5PC+8OR   R1, R3, R5PC+12LW   R6, 100 (R8)PC+4+200AND R9, R5, R3(BTA)Next InstructionAddressR4 = 0 :    Branch Target Address(taken)R4 ¹0 :   PC+4(not taken)Clk 6Clk 7Clk 8IFIDEXMEMWBIDIDClk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFWBIDIDIDIFEXWBIDMEMFetch connuovo PCNuovo valore PC calcolato (Aluout)SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Nuovo valore in PC (un clock dopo)  
IDIFEXWBIDMEM"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#36,36,"ADD4
IMRFSEPCDECInstruction FetchInstruction DecodeExecuteMemoryWriteBack
IF/IDID/EXALUMUXEX/MEMMUXMUXDatapath in Pipeline del DLX  (caso 1/3) -(Branch o JMP)BEQZ R4, 200
MUXDMMEM/WBNel momento in cui il nuovo PC agisce sulla IM treistruzioni hanno eseguito i primi trestadi (fino a EXincluso)=0?=0?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#37,37,"Gestione delle Alee di ControlloBEQZ R4,200Clk 6Clk 7Clk 8IFIDEXMEMWBClk 1Clk 2Clk 3Clk 4Clk 5SSIFSFetch at new PC•Always Stall (blocco di tre clock che si propaga)
Hyp.:  Freq.Branch = 25 %CPI = (1 + S) = ( 1 + 3 * 0.25) = 1.75•Predict Not TakenIFIDEXMEMWBIDIDIDBEQZ R4, 200SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Clk 6Clk 7Clk 8Clk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFIFWBEXWBIDIDIDMEMBranch CompletionFlush:diventanoNOPNOP           NOP           NOP           IF–maquilistruzioneprecedentenonancoradecodificataSIFIFIDSSituazione realeIF ripetuto PC <-PC -4Qui il nuovo valoreè campionato dal PC
Nessun danno: nessuna istruzione ha effettuato WB !"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#38,38,"Delayed branchSimilmentealcasodellaLOAD,indiverseCPUditipoRISClaleaassociataalleistruzionidiBRANCHègestitaviaSWdalcompilatore(delayedbranch):Istruzione BRANCHdelay slotIstruzione SuccessivaIl compilatore cercadi riempire i delay-slotcon istruzioni utili(caso peggiore: NOP).delay slotdelay slot"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#39,39,"Delayed branch/jumpAdd  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21Sne   R1, R8, R9; condizione di branchBr     R1, +100Sne   R1, R8, R9; condizione di branchBr     R1, +100Add  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21CompilatoOriginale
Eseguite inentrambi i casiOvviamente in questo gruppo  non debbono esserci salti !!!!Al posto di una o più istruzioni posposteil compilatore mette delle NOP in caso non riesca a trovarne di adatte"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#4,4,"•Latenza: 5 fasi(clock)•Throughput: a regime, dopo5 fasi(clock), un’automobileper fase(clock)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#40,40,Gestione delle Alee di Controllo con BTBDynamic Prediction: Branch Target Buffer -> nessuno stallo (quasi)T/NTTAGSPredicted PCPC=HIT:  Fetch a PC  predettoMISS: Fetch a  PC + 4Predizione Corretta :    0 stalli Predizione Errata :       da 1 a 3 stalli  (fetch corretto in  ID o EX   v. precedentemente)N.B.  Qui il branch è individuato durante il periodo del clock IF che carica IR1 in IF/ID
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#41,41,"Buffer di predizione: caso più semplice un bit che  indica cosa è successo l'ultima volta.
In presenza di preponderanza di un caso quando si verifica il caso opposto si hannodueerrorisuccessivi.Loop1Loop2Quando esce da loop2 sbaglia (predetto takenma in realtà untaken) ma sbagli ancora quando predice untakenrientrando nuovamente in loop2 a causa di  loop1 "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#42,42,"Normalmente duebits.TAKENTAKEN
UNTAKENUNTAKENTAKENUNTAKENTAKENUNTAKENTAKENTAKEN
UNTAKENUNTAKEN"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#43,43,"Esempio, molto frequente, di loop annidato:for (i=0; i<5000; i++)for (j=0; j<1000; j++}{x[i,j] = i*j + i + j;...... }"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#5,5,"Principio del Pipelining1) Sistema Sequenziale A2A3tANA1TALatency(tempo di esecuzione di una istruzione)= TAThroughput=1TA2) Sistema in Pipeline
SAP1P2P3P4tS1S2S3S4Si: pipeline stage"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#6,6,"Principio del PipeliningP1TPP2P1A2P2P3P1A3tA1
SS1S2S3S4P4P3P2P1A4P4P3P4P2P3P4AnLatency(2)= 4 *TP = TAThroughput(2)@1TP4TA==4 * Throughput(1)TP : pipeline cycle "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#7,7,"Pipeliningin una CPU (DLX)Attività:    A1 , A2 , A3…ANIstruzioni:    I1 , I2 , I3…INIEXIDtMEMWBIF
CPI=1 (idealmente !)IF/IDID/EXEX/MEMMEM/WBCPU (datapath)IFIDEXMEMWBPipeline CycleClock CycleRitardo dello stadio piùlentoRegistri(Pipeline)Registers)ReticombinatorieN.B. architettura TOTALMENTEdiversa !!!!!"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#8,8,"Pipeline del DLXInstr iInstr i+1Instr i+2Instr i+3Instr i+4IFIDEXMEMWB
Tclk=  Td  +  TP+  TsuClock CycleCPI (ideale)  = 1
Overhead introdotto dai Pipeline Registers:Ritardo registroa monteSet-up registro a valleRitardo stadio combinatorio più lentoIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBt"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#9,9,DDRCTp
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#0,0,"Strumen￿ matema￿ci per l’analisi deisistemi tempo discreto – LT Cap.￿Controllo DigitaleCorso di Laurea in Ingegneria Informa￿caProf. Federica PascucciMarch ￿, ￿￿￿￿
￿/￿￿ "
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#1,1,"Indice￿ Equazioni alle di￿erenzeIEquazioni alle di￿erenzeITrasformata Z
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#10,10,"Ritardo temporale￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, alloraZ[x(t nT)] =z nX(z)Dim.Z[x(kT nT)],P1k=0x(kT nT)z k==z nP1k=0x(kT nT)z (k n)=[si ponem=k n]=z nP1m= nx(mT)z m[poich`ex( kT)=0perk 0]=z n1Xm=0x(mT)z m=z nX(z)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#11,11,"An￿cipo temporale￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, alloraZ[x(t+nT)] =znX(z) n 1Xk=0x(kT)z k Dim.Z[x(kT+nT)],P1k=0x(kT+nT)z k==znP1k=0x(kT+nT)z (k+n)=[si pone↵=Pn 1k=0x(kT)z k]=zn[P1k=0x(kT+nT)z (k+n)++↵ ↵]==zn[P1m=0x(mT)z m ↵]==zn[X(z) ↵]￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#12,12,"Teorema del valor iniziale e ￿nale￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, allora•Teorema del valor iniziale (se esistex(0))x(0)= l i mz!1X(z)•Teorema del valor ￿nale (se esiste il lim)limk!1x(kT)=l i mz!1[(1 z 1)X(z)]￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#13,13,"Teorema del valor iniziale￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, allorax(0)= l i mz!1X(z)Dim.limz!1X(z)= l i mz!11Xk=0x(kT)z k==l i mz!1[x(0)+x(T)z 1+x(2T)z 2+...]==x(0)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#14,14,"Teorema del valor ￿nale￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, alloralimk!1x(kT)=l i mz!1[(1 z 1)X(z)]Dim.limz!1[(1 z 1)X(z)] = limz!1[X(z) z 1X(z)] ==l i mz!1[P1k=0x(kT)z k+ P1k=0x((k 1)T)z k]==1Xk=0[x(kT) x((k 1)T)]z k==l i mk!1x(kT)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#15,15,Trasformate notevoli￿ Trasformata Z•Impulso di Kronecker•Gradino unitario•Rampa unitaria•Funzione esponenziale•Funzione sinusoidale￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#16,16,"Impulso di Kronecker￿ Trasformata Z 0(t)=⇢1set=00altrove 0(kT)={1,0,0,...}
Z[ 0(kT)] =1Xk=0 0(kT)z k==1+0z 1+0z 2+···==1￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#17,17,"Gradino unitario￿ Trasformata Z  1(t)=⇢1set 00altrove  1(kT)={1,1,...}
Z[  1(kT)] =1Xk=0  1(kT)z k==1+z 1+z 2+···==11 z 1=zz 1￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#18,18,"Rampa unitaria￿ Trasformata Z  2(t)=⇢tset 00altrove  2(kT)={kT}
Z[  2(kT)] =T1Xk=0kz k==T(z 1+2z 2+...)==Tz 1(1+2z 1+...)==Tz(z 1)2￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#19,19,"Funzione esponenziale￿ Trasformata Zx(t)=⇢e atset 00altrovex(kT)={e akT}
Z[x(kT)] =1Xk=0e akTz k==1+e aTz 1+e 2aTz 2+···==11 e aTz 1=zz e aT￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#2,2,"Equazioni alle di￿erenze (ricorsive)￿ Equazioni alle di￿erenze
flegame tra le sequenze{ek}ed{uk}uk=f(e0,e1,...,ek;u0,u1,...,uk 1)seflineare, tempo invariante, a memoria ￿nitauk= a1uk 1 a2uk 2 ··· anuk n++b0ek+b1ek 1+···+bmek msi o￿engonoequazioni alle di￿erenze ricorsive￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#20,20,"Funzione sinusoidale￿ Trasformata Zx(t)=⇢sin (!t)set 00altrovex(kT)={sin (!kT)}
Z[x(kT)] = [formule di Eulero]=12j✓11 ej!Tz 1 11 e j!Tz 1◆==12j(ej!T e j!T)z 11 (ej!T+e j!T)z 1+z 2==z 1sin(!T)1 2z 1cos(!T)+z 2=zsin(!T)z2 2zcos(!T)+1￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#21,21,Metodi per an￿trasformare￿ Trasformata Z￿.Lunga divisione(successione)￿.Computazionale(successione)￿.Scomposizione in fra￿ semplici o Heaviside(forma chiusa)￿.Integrale di inversione(forma chiusa)￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#22,22,"Metodo della lunga divisione￿ Trasformata ZConsente di calcolare i valori della sequenza{x(kT)}Ricordando cheX(z)=1Xk=0x(kT)z k=x(0)+x(1)z+x(2)z2+...ec h eX(z)=N(z)D(z)=c0+c1z+c2z2+...si o￿ene chec0=x(0)c2=x(2)c1=x(1)...￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#23,23,"Metodo computazionale￿ Trasformata ZConsente di calcolare i valori della sequenza{x(kT)}Ricordando cheX(z)=X(z)U(z)=N(z 1)D(z 1)doveU(z)=Z[ 0(kT)]si o￿eneX(z)D(z 1)=U(z)N(z 1)da cui (trasl. in avan￿)xk+a1xk 1+···+anxk n=b0uk (n m)+b1uk (n m+1)+···+bmuk nxk= a1xk 1 ··· anxk nb0uk (n m)+b1uk (n m+1)+···+bmuk nMetodo per implementare eq. alle di￿erenze￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#24,24,"Osservazioni￿ Trasformata Z￿.Il metodo computazionale e quello della lunga divisione possono essere applica￿quando non`e di interesse calcolare una forma chiusa perx(kT),m as iv o g l i o n oconoscere solo alcuni campioni per cara￿erizzare la risposta di un sistema (metodinumerici)￿.Sianom=deg(N(z))en=deg(D(z)), allora si avr`an m=0)c06=0n m=k)c0=···=ck 1=0￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#25,25,"Scomposizione in fra￿ semplici o metodo di Heaviside￿ Trasformata ZConsente di calcolare{x(kT)}in forma chiusaSi scomponeX(z)/zin termini di cui l’an￿trasformata`en o t aG(z)=X(z)z=lXi=1riXj=1Ri,j(z pi)jsi an￿trasformano i singoli termini (prop. linearit`a) dopo aver mol￿plicato perzecalcolatoRi,jcon la formula per i residuiRi,j=1(ri j)!limz!pi⇢dri jdzri j(z pi)riX(z)z  NBLa funzione deve essere stre￿amente propria￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#26,26,"Osservazioni￿ Trasformata Z￿.Si considera la funzionaG(z)=X(z)zperch´e—Le funzioni da an￿trasformare devono essere stre￿amente proprie (m<n)—Si elimina lo zero inz=0(b0=0)—Si possono u￿lizzare con pi`u facilit`a le tabelle￿.In caso di poli a molteplicit`a singola, il residuo pu`o essere calcolato con la formulaRi=l i mz!pi(z pi)X(z)zche si o￿ene dalla formula generale￿.Ir e s i d u iRiedRi+iassocia￿ ad una coppia (pi,pi+1)d ip o l ic o m p l e s s ic o n i u g a ￿s o n oanch’essi complessi coniuga￿.￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#27,27,"Metodo dell’integrale di inversione￿ Trasformata ZConsente di calcolare{x(kT)}in forma chiusa ed`ei lm e t o d op i`u generale (valeanche con trasformateZnon razionali fra￿e)Formula matema￿cax(kT)=12⇡jICX(z)zk 1dz,k=0,1,2,...
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#28,28,"Tabella TrasformataZ(￿/￿)￿ Trasformata Z
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#29,29,"Tabella TrasformataZ(￿/￿)￿ Trasformata Z
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#3,3,"Indice￿ Trasformata ZIEquazioni alle di￿erenzeITrasformata Z
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#30,30,"Tabella TrasformataZ(￿/￿)￿ Trasformata Z
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#31,31,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#32,32,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#33,33,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#34,34,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#35,35,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#36,36,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#37,37,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#38,38,
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#39,39,Strumen￿ matema￿ci per l’analisi deisistemi tempo discreto – LT Cap.￿Thanks for sharing your thoughtsTo The TOP￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#4,4,"TrasformataZ￿ Trasformata Z
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#5,5,"De￿nizione￿ Trasformata ZSia data una sequenza di valori{xk}2R,d e ￿ n i t ap e rk=0,1,2,...en u l l ap e rk<0.LaZ-trasformata (unilatera) della sequenza{xk}`e la funzione di variabile complessazde￿nita come segueX(z)=Z[xk]==x0+x1z 1+x2z 2+···+xkz k+···==1Xk=0xkz kSe la sequenzaxk`e o￿enuta campionando uniformemente con periodoTil segnalex(t)allora vale la notazioneX(z)=Z[x(t)] =Z[x(kT)]￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#6,6,"Osservazioni￿ Trasformata Z￿.Dominio di convergenza: zona esterna ad un cerchio di raggioR(raggio diconvergenza) centrato nell’origine￿.Z[x(t)]implica un tempo di campionamentoTX(z)=Z[X(s)]=Z[L 1[X(s)]t=kT]￿.Le funzioni considerate qui saranno del ￿po razionale fra￿oX(z)=b0zm+b1zm 1+···+bmzn+a1zn 1+···+an==b0z (n m)+b1z (n m+1)+···+bmz n1+a1z 1+...anz n￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#7,7,Propriet`ad e l l aZ-trasformata￿ Trasformata Z•Linearit`a•Traslazione nel tempo•Teorema del valor iniziale•Teorema del valor ￿nale￿/￿￿
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#8,8,"Linearit`a￿ Trasformata ZSiano date due sequenzef(kT),g(kT),c o nZ-trasformataF(z),G(z)rispe￿vamente, e due costan￿a,b2C, allora la sequenzax(kT)o￿enuta comex(kT)=af(kT)+bg(kT)haZ-trasformata pari aX(z)=aF(z)+bG(z)Dim.X(z),P1k=0x(kT)z k==P1k=0[af(kT)z k+bg(kT)z k]==aP1k=0f(kT)z k+bP1k=0g(kT)z k==aF(z)+bG(z)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\01StrumentiMatematici.pdf#9,9,"Traslazione nel tempo￿ Trasformata ZSia data la funzionex(t),n u l l ap e rt<0,es i aX(z)laZ-trasformata della sequenzax(kT), che si o￿ene campionandox(t)con periodoT, allora•Ritardo temporaleZ[x(t nT)] =z nX(z)•An￿cipo temporaleZ[x(t+nT)] =znX(z) n 1Xk=0x(kT)z k conn=1,2,...￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#0,0,"Ricostruzione dei segnaliLT Cap.￿Controllo DigitaleCorso di Laurea in Ingegneria Informa￿caProf. Federica PascucciMarch ￿￿, ￿￿￿￿
￿/￿￿ "
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#1,1,Indice￿ Ricostru￿ori realiIRicostru￿ori realiIRicostru￿ore di ordine ￿ (ZOH)IRicostru￿ore di ordine ￿ (FOH)ICon￿nua￿/￿￿
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#10,10,"Ricostru￿ore di ordine uno (FOH)￿ Ricostru￿ore di ordine ￿ (FOH)Segnale ricostruitox1(t)=x(kT)+x(kT) x((k 1)T)T(t KT)kTt<(k+1)TRisposta impulsivag1(t)=  1(t)+  2(t)T 2  1(t T)+ 2  2(t T)T+  1(t 2T)+  2(t 2T)T
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#11,11,
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#12,12,"Ricostru￿ore di ordine ￿ (FOH)￿ Ricostru￿ore di ordine ￿ (FOH)L-trasformataH1(s)=1s+1Ts2 2e sTs 2e sTTs2+e 2sTs+e 2sTTs2==✓1s+1Ts2◆(1 2e sT+e 2sT)==1+TsT✓1 e sTs◆2
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#13,13,"Analisi frequenziale￿ Ricostru￿ore di ordine ￿ (FOH)Risposta armonicaH1(j!)=1+j!TT✓1 e j!Tj!◆2==T✓sin(!T/2)!T/2◆2(1+j!T)e j!TModulo|H1(j!)|=T    sin(!T/2)!T/2    2p1+!2T2Fase\H1(j!)=ArgT✓sin(!T/2)!T/2◆2(1+j!T)e j!T == arctan(!T) !T￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#14,14,"Analisi frequenziale￿ Ricostru￿ore di ordine ￿ (FOH)
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#15,15,Indice￿C o n ￿ n u aIRicostru￿ori realiIRicostru￿ore di ordine ￿ (ZOH)IRicostru￿ore di ordine ￿ (FOH)ICon￿nua￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#16,16,"Ricostru￿ore a uscita con￿nua￿C o n ￿ n u aSegnale ricostruitox1(t)=x((k 1)T)+x(kT) x((k 1)T)T)(t KT)kTt<(k+1)TRisposta impulsivagc(t)=  2(t)T 2  2(t T)T+  2(t 2T)TL-trasformataHc(s)=1 2e sT+e 2sTTs2=1T✓1 e sTs◆2
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#17,17,Ricostruzione dei segnaliLT Cap.￿Thanks for sharing your thoughtsTo The TOP￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#2,2,"Ricostru￿ori reali￿ Ricostru￿ori realiEspansione in serie di Taylorx(t)=x(kT)+dx(t)dt    t=kT(t kT)+d2x(t)dt2    t=kT(t kT)22!+...Derivata=rapp. incrementaledx(t)dt    t=kT'x(kT) x((k 1)T)Td2x(t)dt2    t=kT'dx(t)dt  t=kT dx(t)dt  t=(k 1)TT''x(kT) 2x((k 1)T)+x((k 2)T)T2￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#3,3,Studio dei ricostru￿ori reali￿ Ricostru￿ori reali￿.Segnale ricostruito￿.Risposta impulsiva￿.L-trasformata (Trasformata di Laplace)￿.Analisi in frequenza—Calcolo della funzione in!—Tracciamento della risposta armonica—Considerazioni sul tempo di campionamento￿/￿￿
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#4,4,Indice￿ Ricostru￿ore di ordine ￿ (ZOH)IRicostru￿ori realiIRicostru￿ore di ordine ￿ (ZOH)IRicostru￿ore di ordine ￿ (FOH)ICon￿nua￿/￿￿
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#5,5,"Ricostru￿ore di ordine zero (ZOH)￿ Ricostru￿ore di ordine ￿ (ZOH)Segnale ricostruitox0(t)=x(kT)kTt<(k+1)TRisposta impulsivag0(t)=  1(t)   1(t T)L-trasformataH0(s)=L[g0(t)] =1s e sTs=1 e sTs
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#6,6,"Analisi in frequenza (￿/￿)￿ Ricostru￿ore di ordine ￿ (ZOH)Risposta armonicaH0(j!)=1 e j!Tj!=2e j!T/2!ej!T/2 e j!T/22j==2e j!T/2!sin(!T/2)=Tsin(!T/2)!T/2e j!T/2Modulo|H0(j!)|=T    sin(!T/2)!T/2    Fase\H0(j!)=ArgTsin(!T/2)!T/2e j!T/2 =Argsin!T2  !T2ApprossimazioneH0(j!)'Te j!T/2￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#7,7,"Analisi in frequenza (￿/￿)￿ Ricostru￿ore di ordine ￿ (ZOH)
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#8,8,
data_test\rootfolder\università\ControlloDigitale\03Ricostruzione.pdf#9,9,Indice￿ Ricostru￿ore di ordine ￿ (FOH)IRicostru￿ori realiIRicostru￿ore di ordine ￿ (ZOH)IRicostru￿ore di ordine ￿ (FOH)ICon￿nua￿/￿￿
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#0,0,"Sistemi tempo discreto – LT Cap.￿Controllo DigitaleCorso di Laurea in Ingegneria Informa￿caProf. Federica PascucciMarch ￿￿, ￿￿￿￿
￿/￿￿ "
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#1,1,"Indice￿ Funzione di trasferimento tempo discretoIFunzione di trasferimento tempo discretoISchemi a blocchi
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#10,10,"Blocchi in cascata￿S c h e m i a b l o c c h i
Nel dominio di LaplaceY⇤(s)=G⇤(s)H⇤(s)X⇤(s)Z-trasformataY(z)=G(z)H(z)X(z)FdTY(z)X(z)=G(z)H(z)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#11,11,"Blocchi in cascata￿S c h e m i a b l o c c h i
Nel dominio di LaplaceY⇤(s)=[G(s)H(s)]⇤X⇤(s)Z-trasformataY(z)=GH(z)X(z)FdTY(z)X(z)=GH(z)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#12,12,"Esempio: confronto blocchi in cascata￿S c h e m i a b l o c c h i
Y(z)X(z)=H0(z)G(z)=G(z)=Z[G(s)]
Y(z)X(z)=H0G(z)=Z[H0(s)G(s)] = (1 z 1)ZG(s)s ￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#13,13,"Controllo a retroazione (￿/￿)￿S c h e m i a b l o c c h i
E(s)=R(s) H(s)Y(s)Y(s)=G(s)E⇤(s)sos￿tuendo si o￿eneE(s)=R(s) H(s)G(s)E⇤(s)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#14,14,"Controllo a retroazione (￿/￿)￿S c h e m i a b l o c c h icampionando le relazioni preceden￿ si o￿eneE(s)=R⇤(s) GH⇤(s)E⇤(s)Y(s)=G⇤(s)E⇤(s)La FdT del sistema campionato nel dominio di Laplace risultaY⇤(s)=G⇤(s)R⇤(s)1+GH⇤(s)nel dominio dellaZ-trasformataY(z)=G(z)R(z)1+GH(z)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#15,15,Sistemi tempo discreto – LT Cap.￿Thanks for sharing your thoughtsTo The TOP￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#2,2,"Integrale vs sommatoria di convoluzione￿ Funzione di trasferimento tempo discreto
c(t)=Zt0g(⌧)x(t ⌧)d⌧==Zt0x(⌧)g(t ⌧)d⌧C(s)=X(s)G(s)
mk=kXi=0diek i=kXi=0eidk iM(z)=D(z)E(z)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#3,3,"Dai sistemi tempo con￿nuo ai sistemi tempo discreto (￿/￿)￿ Funzione di trasferimento tempo discreto
y(t)=8>>>>><>>>>>:g(t)x(0)0t<Tg(t)x(0)+g(t T)x(T)Tt<2Tg(t)x(0)+g(t T)x(T)+g(t 2T)x(2T)2Tt<3T......g(t)x(0)+g(t T)x(T)+···+g(t kT)x(kT)kTt<(k+1)T￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#4,4,
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#5,5,"Dai sistemi tempo con￿nuo ai sistemi tempo discreto (￿/￿)￿ Funzione di trasferimento tempo discreto
In forma compa￿ay(t)=g(t)x(0)+g(t T)x(T)+···+g(t kT)x(kT)=kXh=0g(t hT)x(hT)0t<(k+1)Tcampionando la sequenza o￿enutay(kT)=kXh=0g(kT hT)x(hT)=kXh=0x(kT hT)g(hT)ricordando chex(t)=g(t)=0,p e rt<0y(kT)=1Xh=0g(kT hT)x(hT)=1Xh=0x(kT hT)g(hT)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#6,6,"Funzione di trasferimento discreta￿ Funzione di trasferimento tempo discretoA par￿re dalla relazione trovatay(kT)=1Xh=0g(kT hT)x(hT)si arriva alla relazione di funzione di trasferimento discretaY(z)=G(z)X(z)Y(z)=1Xk=0y(kT)z k=1Xk=01Xh=0g(kT hT)x(hT)z k=Y(z)=1Xm=01Xh=0g(mT)x(hT)z m h=1Xm=0g(mT)z m1Xh=0x(hT)z h==G(z)X(z)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#7,7,"Indice￿S c h e m i a b l o c c h iIFunzione di trasferimento tempo discretoISchemi a blocchi
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#8,8,"Ingresso/uscita campiona￿￿S c h e m i a b l o c c h i
Nel caso di ingresso pari ax⇤(t), nel dominio di Laplace in uscita si avr`aY(s)=G(s)X⇤(s)Campionando l’uscita si o￿eneY⇤(s)=[G(s)X⇤(s)]⇤=G⇤(s)X⇤(s)Passando nel dominio dellaZ-trasformataY(z)=G(z)X(z)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\04SistemiTempoDiscreto 2.pdf#9,9,"Ingresso con￿nuo￿S c h e m i a b l o c c h i
Nel caso di ingresso pari ax(t), nel dominio di Laplace in uscita si avr`aY(s)=G(s)X(s)Campionando l’uscita si o￿eneY⇤(s)=[G(s)X(s)]⇤6=G⇤(s)X⇤(s)Passando nel dominio dellaZ-trasformataY(z)=GX(z)6=G(z)X(z)￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#0,0,"Mappings!zer i s p o s t aa r m o n i c aLT Cap.￿ – Cap.￿Stabilit`ad e is i s t e m iat e m p od i s c r e t oLT Cap.￿Controllo DigitaleCorso di Laurea in Ingegneria Informa￿caProf. Federica PascucciMarch ￿￿, ￿￿￿￿
￿/￿￿ "
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#1,1,"Indice￿ Mappings!zIMappings!zIRisposta armonicaIStabilit`a
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#10,10,"Risposta armonica discreta￿ Risposta armonicaLarisposta armonicadiG(z)`ed e ￿ n i t ac o m eG(ej!T)0!<⇡T￿.La funzione`ed e ￿ n i t as o l oi0!<⇡Tin quanto`ep e r i o d i c ai n!sG(ej(!+!s)T)=G(ej(!T+2⇡TT))=G(ej!T)￿.per! 0assume valori complessi coniuga￿ rispe￿o al caso!0G(ej( !)T)=G⇤(ej!T)￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#11,11,"Diagrammi di Bode￿ Risposta armonica•Ha senso considerare solo il range di frequenze!2⇥0,⇡T⇤•La funzioneG(ej!T)`e trascendente e non valgono le regole per il tracciamento deidiagrammi di Bode asinto￿ci•I diagrammi di Bode vanno traccia￿ per pun￿ (cio`e con l’ausilio del calcolatore) opassando nel dominiow￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#12,12,"Indice￿ Stabilit`aIMappings!zIRisposta armonicaIStabilit`a
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#13,13,"De￿nizione di stabilit`a￿ Stabilit`aG(z)=N(z)D(z)•Il sistema`easinto￿camente stabilese e solo se tu￿e le radici del polinomio D(z), cio`ei poli del sistema, si trovano all’interno della circonferenza di raggio unitario centratanell’origine del piano Z•Il sistema`estabile semplicementese i poli del sistema si trovano all’interno dellacirconferenza di raggio unitario centrata nell’origine del piano Z tranne al pi`uu n oc o nmodulo pari ad ￿NBDal momento che si tra￿a di sistemi lineari, tempo invarian￿ stabilit`a asinto￿ca estabilit`a BIBO coincidono.￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#14,14,Criteri per determinare la stabilit`a￿ Stabilit`a•Calcolo delle radici diD(z)•Analisi dei coe￿cien￿⇧Passare nel dominiowCriterio di Routh-Hurwitz⇧Analizzare i coe￿cien￿ diD(z)Criterio di Jury￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#15,15,"Criterio di Routh-Hurwitz￿ Stabilit`a￿.Si trasformaD(z)sos￿tuendoz=1+w1 w￿.Si analizzaD(w)costruendo la tabella di Routh
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#16,16,"Trasformazione bilineare￿ Stabilit`aPer la stabilit`as ih a|z|<1|z|=    1+w1 w    =    1+ +j!1   j!    =(1+ )2+!2(1  )2+!2<1￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#17,17,"Criterio di Jury￿ Stabilit`a•Si consideraD(z)=a0zn+a1zn 1+a2zn 2+···+an 1z+ancona0>0•Si veri￿cano le seguen￿ condizioni:￿.|an|<a0￿.D(z)|z=1>0￿.D(z)|z= 1⇢>0npari<0ndispari￿.|bn 1|>|b0||cn 2|>|c0|...|q2|>|q0|￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#18,18,"Tabella di Jury￿ Stabilit`a|z0z1z2...zn 1zn +            1|anan 1...a2a1a02|a0a1a2...an 1an3|bn 1...b2b1b04|b0b1b2...bn 15|cn 2...c1c06|c0c1...cn 2...|2n 5|p3p2p1p02n 4|p0p1p2p32n 3|q2q1q0￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#19,19,"Coe￿cien￿ di Jury￿ Stabilit`abk=    anan k 1a0ak+1    k=0,1,...,n 1ck=    bn 1bn k 2b0bk+1    k=0,1,...,n 2...qk=    p3p2 kp0pk+1    k=0,1,2￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#2,2,"Legames!z￿ Mappings!zData una funzionex(t)campionataX⇤(s)=X(z)    z=esTda cui si deduce i legames!zz=esTs`e una variabile complessas= +j!da cuiz=esT=eT( +j!)=eT ejT(!+2k⇡T)8k2Z+￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#20,20,Mappings!ze risposta armonicaLT Cap.￿ – Cap.￿Stabilit`ad e is i s t e m iat e m p od i s c r e t oLT Cap.￿Thanks for sharing your thoughtsTo The TOP￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#3,3,"Suddivisione pianoS￿ Mappings!z
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#4,4,"Poli stabili￿ Mappings!z
Asse immaginarioz=e0Tej!TModulo|z|=eT <1￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#5,5,"Polo nell’origine (￿-￿)￿ Mappings!z
Modulo|z|=e0T=1Fase\z=\ej0 ·T=\ej0+·T=0￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#6,6,"Poli sull’asse immaginario (￿-￿)￿ Mappings!z
Modulo|z|=e0T=1Fase\z=\ej!sT4=\ej2⇡T4T=⇡2￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#7,7,"Poli al con￿ne della striscia primaria (￿-￿)￿ Mappings!z
Modulo|z|=e0T=1Fase\z=\ej!sT2=\ej2⇡T2T=⇡￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#8,8,"Poli al con￿ne della striscia primaria (￿-￿)￿ Mappings!z
Modulo|z|=e 1T=0Fase\z=\ej!sT2=\ej2⇡T2T=⇡￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\05MappingSZStabilita 2.pdf#9,9,"Indice￿ Risposta armonicaIMappings!zIRisposta armonicaIStabilit`a
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#0,0,"Intro to Digital Control SystemsDigital Control SystemsComputer Science EngineeringProf. Federica PascucciMarch ￿, ￿￿￿￿
￿/￿￿ "
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#1,1,Table of Contents￿C o u r s e i n f oICourse infoITeaching sta￿IResourcesIExamICourse outline￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#10,10,"Moodle Website￿R e s o u r c e s•Outcomes•Textbooks•Syllabus•Slides and notes•Links•Exams
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#11,11,"Teams Group￿R e s o u r c e s•Old recordings•Slides and notes•Forms!The course will be in presence only
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#12,12,Table of Contents￿ ExamICourse infoITeaching sta￿IResourcesIExamICourse outline￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#13,13,"Exam￿ Exam•￿ Mid term tests or wri￿en exam (Aula Campus)•Oral exam•Homeworks
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#14,14,Table of Contents￿ Course outlineICourse infoITeaching sta￿IResourcesIExamICourse outline￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#15,15,Outline￿ Course outline•Digital Control Systems (￿￿%)-Analysis of digital control systems-Design of digital control systems•Microcontroller (￿￿%)-Arduino pla￿orm-Arduino programming•Training: Matlab (￿￿%)￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#16,16,"Prerequisites￿ Course outline•Con￿nuous ￿me linear systems•Computer architectures•Signal sampling and reconstruc￿on
￿￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#17,17,
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#18,18,
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#19,19,
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#2,2,"Digital Control Systems￿C o u r s e i n f oCourse name:Controllo DigitaleSSD:Ing–Inf/￿￿Instructor:Prof. Federica PascucciLectures:Mon-Wed-ThuTimetable:￿￿:￿￿-￿￿:￿￿Room:N￿Textbook:Bonivento, Melchiorri, ZanasiSistemi di controllo digitaleProge￿o LeonardoResources:Moodle, Teams￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#20,20,Intro to Digital Control SystemsThanks for sharing your thoughtsTo The TOP￿￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#3,3,Table of Contents￿ Teaching sta￿ICourse infoITeaching sta￿IResourcesIExamICourse outline￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#4,4,"Who am I?￿ Teaching sta￿Federica PascucciAssociate Professor in Automa￿c ControlRobo￿cs and Automa￿on Group (GRA)Chair for Technical Ac￿vi￿es - I-RIM
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#5,5,"My research interests￿ Teaching sta￿•Cybersecurity for Industry ￿.￿•Wearable Robo￿cs•Autonomous Naviga￿on•Localiza￿on
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#6,6,"How to contact me￿ Teaching sta￿•Online mee￿ng (Teams)•In presence mee￿ng (DIA ￿.￿￿)•Email: federica.pascucci@uniroma￿.it•Phone: ￿￿ ￿￿￿￿ ￿￿￿￿
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#7,7,Tutor￿ Teaching sta￿•Valeria BonaguraEmail: valeria.bonagura@uniroma￿.it•Laura FilardoEmail: laura.￿lardo@uniroma￿.it•Jacopo PisaniEmail: jacopo.pisani@uniroma￿.it￿/￿￿
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#8,8,"Email rules￿ Teaching sta￿•Subject: [CD]•Insert yournameesurnamein the email text!Please no￿ce that email without [CD] in the subject will not beread
￿/￿￿"
data_test\rootfolder\università\ControlloDigitale\IntroCorsoCD-4.pdf#9,9,Table of Contents￿R e s o u r c e sICourse infoITeaching sta￿IResourcesIExamICourse outline￿￿/￿￿
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#0,0,"Machine Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning: Introduzione
1"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#1,1,"Sommario
Informazioni sul corso  
Programma, testi consigliati, precondizioni  
Software tools  
Cos'è il deep learning  
Representation learning  
Autoencoders  
Factors of variation  
Approcci di IA ed evoluzione delle architetture  
Curse dimensionality  
Local constancy & smoothness regularization  
Libreria D2L"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#10,10,"Google Colaboratory (o Colab)  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#11,11,"Google Colaboratory (o Colab)  
GPUs includes Tesla 
 P100
  (used in Colab), Tesla 
 V100
  (equipped in 
Amazon EC2 P3 instance), and Tesla 
 T4
 (equipped in Amazon EC2 
G4 instance). 
 TPUs
  are tensor processing units developed by Google 
to accelerate operations on a Tensor
 ﬂ
ow Graph. Each TPU packs up 
to 180 tera
 ﬂ
ops of 
 ﬂ
oating-point performance and 64 GB of high-
bandwidth memory onto a single board.
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#12,12,"Cos'è il Deep Learning
Il 
machine learning
  riguarda tecnologie capaci di acquisire conoscenza 
relativamente all'ambiente di interesse allo scopo di risolvere problemi in 
modo automatizzato, cioè senza l'intervento dell'utente.  
Per problemi complessi occorre rappresentare la conoscenza come 
concetti su vari livelli di astrazione, creando dipendenze tra gli stessi, in 
modo simile a come avviene nella mente umana.  
Da queste strutture deriva il termine 
 deep learning
 . 
Storicamente i computer sono stati impiegati per rappresentare conoscenza 
formale (es. regole per giocare a scacchi) su cui implementare meccanismi 
di 
reasoning
  (es. regole logiche) mentre è stato più dif
 ﬁ
cile rappresentare la 
conoscenza informale.  
Esempio: Cyc inference engine e ""Fred shaving in the morning""
13"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#13,13,"Representation learning (1)
Successivamente sono state introdotte tecniche di machine learning per 
acquisire la conoscenza (
 know-how
 ) estraendo 
 patterns
  dai dati in modo 
automatico, es. logistic regression e naive Bayes.  
Le prestazioni di tali approcci dipendono dalla scelta con cui i dati sono 
rappresentati. È importanti scegliere le informazioni più rilevanti (
 features
 ) 
per il task che si intende risolvere (approccio 
 hand-designed
 ). 
LXI + XCIX = ?  
Per alcuni task de
 ﬁ
nire una rappresentazione dei task è arduo.  
Es. identi
 ﬁ
care un auto potrebbe ridursi al task di riconoscere le ruote; 
come puoi farlo a partire da una rappresentazione a pixel?  
A differenza del hand-designed, il 
 representation learning
  introduce un 
sotto-task nel processo di ML che mira a riconoscere le feature più rilevanti 
in modo automatico. 
14"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#14,14,"Representation learning (2)
Identi
 ﬁ
care le features in modo automatico garantisce vantaggi:  
L'approccio hand-designed è lungo e richiede risorse  
Si può facilmente adattare l'addestramento a nuovi tasks
15"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#15,15,"Autoencoders
Gli 
autoencoders
  sono composti da un 
 encoder
  e un 
 decoder
 . Il primo 
converte l'input in una rappresentazione compatta, cioè con 
dimensionalità ridotta,, il decoder mira a ricostruire l'input originale da tale 
rappresentazione.  
L'addestramento degli autoencoders crea uno 
 spazio 
 che mira a 
rappresentare solo le features salienti necessarie per identi
 ﬁ
care una certa 
istanza, tralasciando informazioni non utili.  
Nel corso vedremo diversi tipi di autoencoders. Le 
 Generative Adversarial 
Network (GAN)
  impiegano tali tecnologie.
16"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#16,16,"Factors of variation
Le features identi
 ﬁ
cate con un approccio hand-designed, oppure 
riconosciute in modo automatico durante il learning, devono saper 
distinguere i 
 fattori di variazione
 . 
Sono spesso considerati degli elementi astratti (non misurabili) che 
in
ﬂ
uenzano il modo in cui le istanze vengono viste dagli approcci di ML. 
Se identi
 ﬁ
cati ci permettono di capire meglio la grande variabilità di 
istanze in certi domini.  
Ad esempio, età, sesso, un certo accento possono in
 ﬂ
uenzare le parole 
pronunciate da una certa persona in un task di speech-recognition. 
Osservando un automobile, la posizione, il colore, l'angolo di incidenza 
dei raggi solari sono altri tipici fattori per l'analisi di una immagine.  
Se riusciamo a riconoscerli e ignorarli durante il processamento saremmo 
in grado di sempli
 ﬁ
care molti task di ML.
17"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#17,17,"Esercizio
Prova a identi
 ﬁ
care un ulteriore task adatto ad un approccio di ML, ed 
elenca qualche fattore di variazione. 
18"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#18,18,"Deep Learning
Il Deep learning segue un approccio di 
 representation learning
 , dove certe 
rappresentazioni sono espresse mediante altre più semplici, es., l'immagine 
di un uomo viene composta da angoli e contorni, che a sua volta sono 
rappresentati con piccoli segmenti.  
Un esempio di una architettura Deep, il 
 multilayer perception:
19
Immagine tratta da Zeiler and Fergus (2014)."
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#19,19,"Schema sempli
 ﬁ
cato approcci di IA
I box scuri includono fasi esplicite di apprendimento.
20
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#2,2,"Il corso
L'obiettivo del 
 corso di Deep Learning (DL)
  di 6 CFU è fornire competenze 
avanzate e speci
 ﬁ
che nell'ambito delle architetture di reti neurali Deep.  
Il corso è strutturato in una parte teorica e 
 metodologica
  sui concetti 
fondamentali, e da una 
 attività di programmazione 
 in cui tali concetti sono 
applicati nella risoluzione di problemi mediante recenti framework di 
sviluppo (Keras & PyTorch).  
Al termine del corso lo studente sarà in grado di:  
addestrare e ottimizzare in maniera adeguata reti neurali Deep;  
saper distinguere tra diverse soluzioni, e saper selezionare e 
personalizzare le architetture di reti più ef
 ﬁ
caci da utilizzare in ambiti 
applicativi reali, supervised, unsupervised o seguendo un approccio 
basato su un apprendimento per rinforzo.  
Il corso prevede lo svolgimento di progetti.
3"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#20,20,"Evoluzione delle architetture
Ogni 2,4 anni il numero di neuroni nascosti è all'incirca raddoppiato.
21
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#21,21,"I.A. & Big Data: il contesto attuale
2222
 
  Large amount of 
Human -generated content
Posizione GPS, “mi piace”, precedenti 
acquisiti, immagini sui social.
Infrastructures
Cloud computing, GPU -enabled 
infrastructure
EU GDPR 
personal information as 
economic assetAI-enabled frameworks
Recommender systems, Speech and Text 
processing, Video and Image analysis
Oligopoly on data
Poche imprese possiedono 
grandi quantità di dati sull’utente.
AI-based interpretation of content
by natural language processing, personality 
traits, object recognition, etc.AI & Big Data
La distribuzione traintelligenza artificiale , e-commerce e abitudini di consumo -12 aprile 2018 Fabio Gasparetti"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#22,22,"Curse of dimensionality
Nei corsi di I.A. e M.L. sono stati descritti numerosi algoritmi che si 
adattano facilmente i vari task. Ma solo pochi riescono ad affrontare 
problemi centrali come riconoscere il parlato od oggetti arbitrari.  
Tali task causano il cosiddetto 
 curse of dimensionality
 : il numero di 
potenziali con
 ﬁ
gurazioni di variabili di ingresso cresce in modo 
esponenziali col numero di variabili considerate.  
Ne segue: istanze di training << # potenziali con
 ﬁ
gurazioni 
23
Incrementando il numero di dimensioni (da 1d a 3d) il 
numero di regioni di interesse (box colorati) incrementa, 
e abbiamo necessità di un numero elevato di istanze per 
caratterizzarne ognuna."
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#23,23,"Local constancy & Smoothness regularization
Imponiamo che la distribuzione di probabilità a priori, che in
 ﬂ
uenza i 
parametri ma anche la funzione che stiamo cercando di stimare, sia 
smoothness prior
  o 
local constancy prior
 . 
Sotto questa assunzione, se l'output di una funzione è OK per una certa 
istanza 
 x
, allora l'output è buono anche per istanze vicine ad 
 x
: 
Esempio
 : algoritmo di 
 k
-nearest neighbors.  
Per dimensionalità elevate, una funzione smooth potrebbe cambiare (in 
modo smooth) in modo diverso a seconda della dimensione. Occorrono 
molte istanze di training per caratterizzarle.  
Il deep learning introduce dipendenze tra le regioni di interesse (cioè nelle 
distribuzioni dei dati) per ridurre il numero di istanze necessarie. 
24
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#24,24,"La libreria D2L
Durante il corso faremo uso di una libreria Python di supporto chiamata 
D2L.ai  
La libreria d2l mette a disposizione alcune funzionalità per rendere il 
codice più interpretabile e compatto.  
Vediamone alcuni esempi di impiego:  
01-d2l_3.2.ipynb  
02-d2l_regressione_3.3.ipynb
25"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#3,3,"Il programma
4
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#4,4,"Testi consigliati e altri riferimenti
• I. Goodfellow, Y. Bengio, and A. Courville, ""Deep Learning"", MIT Press, 
2016.  
• A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola, ""Dive into Deep Learning"", 
2020 (free online).  
• A. Geron, “Hands-on Machine Learning with Scikit-Learn, Keras, and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems”, 
O'Reilly Media, Inc, USA, 2019.  
• M. Nielsen, ""Neural Networks and Deep Learning"", 2019 (free online).  
Altri riferimenti a codice, tutorial, e altre fonti saranno dati durante il corso.
5"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#5,5,"Precondizioni
Le seguenti lezioni del corso di Machine Learning sono requisiti per il 
corso di DL:  
Introduzione alla Regressione  
La Valutazione nella Regressione  
Over
 ﬁ
tting, Cross Validation  
Introduzione alle Reti Neurali Arti
 ﬁ
ciali (es. algoritmo di 
backpropagation)  
Sebbene alcuni dei concetti saranno ripresi per introdurre i formalismi 
necessari al resto del corso.
6"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#6,6,"Software Tools
Docker  
https://www.docker.com/community-edition#/download  
Jupyter Notebook Scienti
 ﬁ
c Python Stack + Tensor
 ﬂ
ow + Tensorboard  
https://github.com/lspvic/jupyter_tensorboard  
docker pull lspvic/tensorboard-noteboo
 k
docker run -it --rm -p 8888:8888 lspvic/tensorboard-noteboo
 k
Docker Engine Utility for NVIDIA GPUs  
https://github.com/NVIDIA/nvidia-docker   
Anaconda + Tensor
 ﬂ
ow 
https://docs.anaconda.com/anaconda/user-guide/tasks/tensor
 ﬂ
ow/ 
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#7,7,"Jupiter
https://jupyter.readthedocs.io/en/latest/  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#8,8,"Google Colaboratory (o Colab)  
Servizio di calcolo online basato su Nvidia Tesla T4 GPUs  
12 GB of RAM  
ﬁ
no a 12 ore di seguito  
Supporto multi-ambiente: TensorFlow, Keras, PyTorch, e OpenCV.  
Molti dataset disponibili nell'ambiente  
https://www.tensor
 ﬂ
ow.org/datasets/catalog/overview   
Interfaccia Jupyter ben nota.  
Default: Runtime Python 3 e nessun acceleratore hardware.  
Menu Runtime -> Change runtime type  
Possibilità di trasferire l’esecuzione in locale (per elaborazioni molto 
lunghe)  
https://research.google.com/colaboratory/local-runtimes.html  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#9,9,"Google Colaboratory (o Colab)  
Acceleratore: GPU
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Multilayer Perceptrons, One-hot encoding e Softmax
1"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#1,1,"Sommario
Monotonicità  
MLP e Hidden layers  
Non linearità  
Funzioni di attivazione  
Datasets  
MLP e Tensor
 ﬂ
ow 
Da regressione lineare a classi
 ﬁ
cazione  
Funziona softmax  
One-hot encoding e misure di distanza"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#10,10,"Alcuni toy datasets 
Elenchiamo alcuni dataset che vengono spesso impiegati negli approcci di 
ML e DL:  
MNIST  
notMNIST  
fashion-MNIST  
Dataset più complessi saranno introdotti più avanti. 
11"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#11,11,"Dataset MNIST
Composto da cifre numeriche, usato per addestrare sistemi OCR.  
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others.""  
Contiene 60K immagini di addestramento e 10K di training.  
1998: un linear classi
 ﬁ
er ha ottenuto 7.6% di errore rate.  
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%.  
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono 
centrate in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare 
una cifra.  
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#12,12,"Dataset MNIST: train.csv e test.csv
Il 
ﬁ
le train.csv contiene una matrice con 785 colonne. La prima colonna è il 
label
 della cifra (es. 3) e le restanti colonne sono la rappresentazione 
sequenziale dell’immagine:  
Il 
ﬁ
le test.csv ha la stessa rappresentazione senza la prima colonna.  
Esempio di immagini:
13
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#13,13,"Dataset MNIST - svantaggi
Troppo semplice: algoritmi classici di ML raggiungono i 97% di precisione, 
architetture DL il 99.7%  
Si rischia di ideare nuove architetture adatte solo per questo dataset e 
dif
ﬁ
cilmente adattabili in altri contesti.  
Molto diverso dai task studiati attualmente nell’ambito del DL.
14"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#14,14,"Dataset notMNIST
Simile a MNIST: contiene 10 labels (lettere da A a J), ma ogni lettera nel 
dataset ha un font molto diverso dalle altre, es.:  
http://yaroslavvb.blogspot.
 ﬁ
/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione  
notMNIST_small.tar.gz -> test 
15
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#15,15,"Dataset fashion-MNIST
Fornito da Zalando: 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc).  
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST:  
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
16
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#16,16,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes.  
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su WordNet. In 
media 1K immagini per concetto.  
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi.  
Open Image
 : 9 milioni di URLs di immagini annotate con bounding boxes e 
migliaia di classi.  
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 questions 
per immagini con 10 ground truth answers per question.  
The Street View House Numbers
 : 600K immagini di numeri civici.  
Risultati sperimentali ottenuti per varie architetture  
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
17"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#17,17,"MLP e Tensor
 ﬂ
ow
Proviamo a costruire una MLP con Tensor
 ﬂ
ow (Keras).  
Coalb 04-mlp_5.2.1.ipynb
18"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#18,18,"Da regressione lineare a classi
 ﬁ
cazione
Nei problemi di regressione rispondiamo a domande del tipo ""
 Quale 
quantità o valore?
 "". Ma molti problemi mirano a trovare una classe di 
appartenenza,  
es. è una email di spam? è più probabile che un utente si iscriva ad un 
abbonamento oppure no?  
Ci può interessare la classe più verosimile (
 hard assignements
 ), oppure la 
distribuzione di probabilità sulle classi possibili (
 soft assignements
 ), o siamo 
in presenza di più classi di appartenenza (
 multi-label classi
 ﬁ
cation
 ). 
In caso di più valori in output (es. un layer di output con più nodi), ogni 
valore può essere interpretato come 
 il grado di appartenenza dell'istanza in 
ingresso ad una certa classe
 . La loss misura il discostamento tra classe attesa 
e valori prodotti dal modello. 
19"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#19,19,"Classi
 ﬁ
cazione binaria
Si ha interesse ad associare una istanza in input ad un valore in y
 ∈
{0,1} 
Se usiamo un modello di regressione, estraiamo dall'istanza x features 
numeriche e le combinano linearmente. Il risultato dipende dalle somme 
dei valori di input e dei parametri del modello.  
Al risultato del modello applichiamo la funzione 
 logistic
 , che restituisce un 
valore in [0,1]. La funzione è facilmente differenziabile.  
Interpretiamo tale valore come la probabilità di appartenenza ad una delle 
due classi.  
Si ottiene una 
 logistic regression
 . 
Vogliamo generallizzare la logistic regression al caso K classi, con K>2
20!""=	argmax!*(!|-)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#2,2,"Motivazioni
Tale dispensa richiama in modo sommario molti concetti trattati nel corso di 
ML con particolare attenzione ai concetti che interessano maggiormente lo 
sviluppo di architetture DL (architetture MLP).  
Si rimanda al materiale del corso di ML per i dettagli
3"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#20,20,"Esempio  
Supponiamo di avere 3 classi e l’output della combinazione lineare sia:  
Sebbene la classe più probabile sia associata all’indice 1, i valori non sono 
direttamente interpretabili come distribuzioni di probabilità, infatti:  
I valori non sono in in [0,1]  
La somma non è pari 1
21y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#21,21,"La funzione Softmax
La funzione 
 softmax
  prende in input un vettore in 
 ℝ
T
 e dà in output un 
vettore 
 ℝ
T  
nell'intervallo (0,1] la cui somma è pari a 1. È de
 ﬁ
nita: 
L'output può essere interpretato come distribuzione di probabilità su K 
classi, a differenza di altri modelli (es. classi
 ﬁ
catore SVM).
22S(yi)=eyi
eyj
jK
∑"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#22,22,"Layer softmax nelle reti neurali
La funzione softmax è tipicamente applicata all’output di un layer fully-
connected, creando un nuovo layer chiamato 
 softmax
 . 
Il seguente esempio rappresenta un singolo layer, con funzione di attivazione 
softmax su T classi.  
Nota
 : la funzione softmax introduce non linearità.
23
y s(y)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#23,23,"Softmax in Keras
In Keras è semplice implementare il modello precedente con il parametro 
activation
  di layer Dense:  
24
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#24,24,"One-hot encoding
Nel ML le rappresentazioni dell’input e output sono sottoinsiemi dei 
domini 
 ℕ
 e 
ℝ
. Tali insieme introducono implicitamente ordinamenti.  
Es. se abbiamo 3 categorie (es. rosso=1, bianco=2 e nero=3) e gli 
assegniamo 3 numeri, introduciamo una relazione di ordinamento che 
non esiste nei dati.  
Durante l’addestramento tali relazioni possono essere considerate 
potenziali features, e di conseguenza apprese dall'algoritmo  
Es. Le due istanze Rosso-Nero possono considerarsi più distanti rispetto 
a Rosso-Bianco  
La rappresentazione 
 one-hot
  caratterizza ogni istanza con una 
con
ﬁ
gurazione univoca, costituita da una sequenza binaria di zero, tranne 
un solo elemento pari a 1.
25"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#25,25,"One-hot encoding in Python
Colab 05_onehot.ipynb
26"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#26,26,"Loss e one-hot encoding
Se la 
 softmax
  genera una distribuzione di probabilità su K possibili, la 
codi
ﬁ
ca one-hot genera una distribuzione che ""concentra"" tutta la densità di 
probabilità sulle classi corrette, es.:  
[0, …, 0, 1, 0 …, 0].  
Per addestrare il modello occorre de
 ﬁ
nire una misura di loss che tenga conto 
della distanza tra le due distribuzioni.
27"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#27,27,"Misura di Distanza: cross entropy
Per confrontare due generici vettori 
 p
 e 
q
 che rappresentano distribuzioni di 
probabilità si impiega la misura 
 cross entropy
 : 
Dove 
 x
 si estende su tutte i valori potenziali della variabile causale su cui 
sono de
 ﬁ
nite le probabilità, cioè le classi in output.  
Attenzione: la funzione H non è simmetrica:  
Se uno dei parametri (
 p
 o 
q
) è codi
 ﬁ
cato one-hot, in che posizione conviene 
averlo?
28H(p,q)≠H(q,p)H(p,q)=−p
x∑ (x)⋅log	q(x)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#28,28,"Misura di Distanza: cross entropy
Nella fase di addestramento un parametro della cross entropy è l’output 
della funzione softmax s(y), mentre il secondo è la codi
 ﬁ
ca one-hot che 
indica una o più classi di appartenenza.  
Supponiamo di usare la codi
 ﬁ
ca one-hot per il calcolo dei logaritmi:  
Anche il layer softmax può generare valori 0, ma è un problema raro e 
facilmente risolvibile (es. aggiungendo un 
 ε
).
29D(s(y),ˆy)=−s(y1)⋅log	1.0+s(y2)⋅log	0+s(y3)⋅log	0 ( ) ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#29,29,"Multinomial logistic classi
 ﬁ
cation
30x=2.0
0.7
1.5
...
8.0⎡
⎣⎢
⎢
⎢
⎢
⎢
⎢⎤
⎦⎥
⎥
⎥
⎥
⎥
⎥S(y)=0.659
0.242
0.099⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥D(ˆy,S(y))Input
Linear model Softmax Onehot rep.
Cross entropy distanceLabels"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#3,3,"Monotonicità
Le architetture lineare impongono l'assunzione di 
 monotonicità
 : 
l'incremento di una feature generare un incremento/decremento nel valore 
in output del modello, a seconda del valore dei pesi (o parametri).  
Per certi task è verosimile, sebbene non sempre vero, ad esempio:  
Task: ""
 un individuo sarà regolare con le rate del mutuo?
 "". Se il salario 
passa da 0K a 50K la probabilità che ripaghi il mutuo sarà molto diversa; 
mentre se il salario passa da 1M a 1,05M la probabilità non cambierà 
molto.  
Task: ""
 predire se un individuo è malato in base alla temperatura
 "".  
T << 37 o T >> 37 indica una possibile patologia.  
Come pensi si può risolvere il problema impiegando un algoritmo di 
regressione lineare?
4"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#30,30,"Esercizio
Supponiamo di avere 3 istanze di addestramento che consistono in varie 
features (es. sex, age, etc) e vogliamo predire se un elettore voterà 
democratico o repubblicano con una rete neurale.  
Avendo due reti che producono in output i seguenti valori:  
Calcola l’errore impiegando: (1) cross entropy, (2) mean squared error, (3) 
accuratezza (binaria).
31
#1
#2"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#31,31,"Confronto tra misure di loss
Cross entropy  
#1: -(ln(0.4) + ln(0.4) + ln(0.1)) / 3 = 1.38  
#2: -(ln(0.7) + ln(0.7) + ln(0.3)) / 3 = 0.64 (smaller)  
Mean squared error  
#1: [(0.3 - 0)^2 + (0.3 - 0)^2 + (0.4 - 1)^2 + …] / 3  
(0.54 + 0.54 + 1.34) / 3 = 0.81  
#2: (0.14 + 0.14 + 0.74) / 3 = 0.34 (smaller)  
Accuratezza (binaria)  
Entrambi: classi
 ﬁ
cation error 1/3 = 0.33, accuracy 2/3 = 0.67  
Nota
 : le implementazione delle misure discusse sono in 
 sklearn.metrics  
32"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#32,32,"Confronto tra misure di loss
Cross entropy  
#1: 1.38  
#2: 0.64 (migliore)  
Mean squared error  
#1: 0.81  
#2: 0.34 (migliore)  
Accuratezza (binaria)  
Entrambi: 0.67  
Rispetto alla cross entropy, MSE da molta importanza agli output sbagliati, 
ma allo stesso tempo, se la rete si avvicina ai risultati corretti, i gradienti 
diventano assai bassi, rallentando notevolmente la convergenza.
33
#1
#2"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#4,4,"Monotonicità
Per un task ""
 l'immagine contiene un cane
 ?"", come possiamo creare una 
relazione tra un certo pixel è una classe in output?  
L'assunzione di linearità ci impone un vincolo tra:  
luminosità del pixel <-> classe di appartenenza;  
ignorando però il contesto (altri pixel) e la complesse relazioni tra essi che 
portano a rappresentare visivamente un oggetto.  
Invece di de
 ﬁ
nire una rappresentazione adeguata, impieghiamo reti neurali 
multistrato
 , dove gli 
 hidden layer
  si occupano di riconoscere una 
rappresentazione adeguata dei dati in input, che viene impiegata da un 
predittore lineare per generare l'output. 
5"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#5,5,"Hidden layers e MLP
L'approccio più semplice per aggiungere strati nascosti è 
 impilarli
  (stack) uno 
dopo l'altro, ottenendo L layers.  
Interpretiamo gli L layer, tranne l'ultimo, come l'insieme di nodi impiegati 
per la rappresentazione, e l'ultimo come predittore lineare.  
Otteniamo una architettura 
 Multilayer perceptron (MLP)
  fully connected.
6
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#6,6,"Da lineare a non lineare
Indichiamo con 
  un 
minibatch
  (una sottoinsieme del dataset di 
training) di 
 n
 istanze dove ogni istanza ha 
 d
 features.  
Per un hidden layer con 
 h
 unità, indichiamo con 
  il relativo 
output. Avendo layer fully connected, abbiamo come parametri:  
i pesi 
   e i  bias 
  . 
Il layer di output avrà parametri:   
    e    
L'output è ricavato nel seguente modo:  
 
 
Secondo te, combinando più funzioni af
 ﬁ
ni, siamo riusciti a introdurre non 
linearità nel modello?
X
∈
ℝ
n
×
d
H
∈
ℝ
n
×
h
W
(
1
)
∈
ℝ
d
×
h
b
(
1
)
∈
ℝ
1
×
h
W
(
2
)
∈
ℝ
h
×
q
b
(
2
)
∈
ℝ
1
×
q
H
=
X
W
(
1
)
+
b
(
1
)
O
=
H
W
(
2
)
+
b
(
2
)
7"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#7,7,"Da lineare a non lineare
Combinando le equazioni viste in precedenza otteniamo un modello 
equivalente ad un singolo layer:  
 
La non linearità viene espressa mediante funzioni di attivazione 
  non 
lineari (es. ReLU) impiegate all'interno delle unità nascoste, a valle della 
trasformazione af
 ﬁ
ne. 
Facendo 
 stacking
  di più hidden layer con funzioni non lineari, es:  
 
 
si ottengono architetture 
 deep
 , che approssimano funzioni più complesse.
O
=
(
X
W
(
1
)
+
b
(
1
)
)
W
(
2
)
+
b
(
2
)
=
X
W
(
1
)
W
(
2
)
+
b
(
1
)
W
(
2
)
+
b
(
2
)
=
X
W
+
b
σ
H
(
1
)
=
σ
1
(
X
W
(
1
)
+
b
(
1
)
)
H
(
2
)
=
σ
2
(
H
(
1
)
W
(
2
)
+
b
(
2
)
)
8"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#8,8,"Universal approximators
Ci si può chiedere quanta capacità rappresentativa (i.e. quanto è 
 potente
 ) è 
espressa da una rete neurale.  
Alcuni risultati suggeriscono che 
 per
ﬁ
no con un solo hidden layer
  è possibile 
approssimare qualsiasi funzione con un numero adeguato di unità.  
Una rete neurale deep può essere pensata come un programma in C,  
cioè puoi risolvere qualsiasi problema software, ma i programmi possono 
raggiungere complessità molto elevate.  
Vedremo architetture di reti deep possono risolvere gli stessi task in modo 
molto più ef
 ﬁ
ciente. 
9"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#9,9,"Funzioni di attivazione
Ne esistono molte, ad esempio:  
Funzione Sigmoide  
Tangente iperbolica (tanh)  
Relu 
Leaky Relu  
Swish  
Relu parametrizzato  
ELU 
Softplus e Softsign  
Selu 
Gelu  
Durante il corso discuteremo pro e contro delle principali.  
Colab 03-funzioni_di_attivazione_5.1.2
10"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Kayers e moduli in Keras
1"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#1,1,"Sommario
Moduli e Keras  
Sequential  
Moduli custom  
Gestione dei parametri: lettura, condivisione, inizializzazione  
Inizializzazione lazy  
Layer custom  
I/O 
GPU e Keras"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#10,10,"Gestione dei parametri: accesso
Il loop di addestramento mira a trovare i parametri che minimizzano la funzione di 
loss. Le architetture più classiche hanno implementazioni che si occupano 
interamente della gestione dei parametri. In altri casi è necessario accedervi 
durante l'esecuzione (es. debugging, riuso dei parametri in parti diverse del 
modello).  
Vediamo come accedere ai parametri. Costruiamo un semplice modello:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
I layer nel modello sono memorizzati mediante liste. I parametri sono facilmente 
accedibili:  
net.layers[
 2
].weights       # secondo layer: 4 pesi e 1 bias  
[<tf.Variable 
 'dense_1/kernel:0'
  shape=(
 4
, 
1
) dtype=float32, numpy=  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32)>,  
 <tf.Variable 
 'dense_1/bias:0'
  shape=(
 1
,) dtype=float32, numpy=array([
 0.
], dtype=float32)>]  
11"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#11,11,"Gestione dei parametri: lettura
In Keras i parametri sono salvati in particolari classi. Per ottenere il valore 
bisogna convertire le classi in tensori, ad esempio, per ottenere il bias dal 
secondo layer della rete:  
type
(net.layers[
 2
].weights[
 1
]), tf.convert_to_tensor(net.layers[
 2
].weights[
 1
]) 
(tensorflow.python.ops.resource_variable_ops.ResourceVariable,  
 <tf.Tensor: shape=(
 1
,), dtype=float32, numpy=array([
 0.
], dtype=float32)>)  
Mentre per ottenere tutti i parametri:  
net.get_weights()  
[array([[-
 0.20149094
 ,  
0.69364685
 , -
0.12403131
 ,  
0.81778544
 ], 
        [ 
 0.3347332
  ,  
0.43645364
 ,  
0.18376476
 , -
0.5020199
  ], 
        [-
 0.7681664
  , -
0.14477473
 , -
0.6313741
  ,  
0.8246415
  ], 
        [-
 0.8074637
  , -
0.20050609
 ,  
0.4308104
  ,  
0.69257575
 ]], 
       dtype=float32),  
 array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32),  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32),  
 array([
 0.
], dtype=float32)]  
12"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#12,12,"Condivisione dei parametri
In alcune architetture è conveniente condividere i parametri in layer distinti, 
in modo che la modi
 ﬁ
ca dei parametri di un layer si ri
 ﬂ
etta sull'altro.  
shared = tf.keras.layers.Dense(
 4
, activation=tf.nn.relu)  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    shared,  
    shared,  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
In questo caso, i gradienti del secondo e terzo layer sono sommati.
13"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#13,13,"Inizializzazione dei parametri
All'interno del modulo Python 
 keras.initializers
  sono contenute le 
implementazioni di vari tipi di inizializzazione dei parametri. Tali approcci 
dipendono solitamente dall'input e dell'output e i valori dei bias sono 
impostati a zero.  
Per default, l'inizializziazione dei parametri è basata su una distribuzione 
uniforme (
 glorot initializer
 ) nell'intervallo [-k,k], dove k = sqrt(6/(
 ﬁ
n_in + 
fan_out)).  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
Vedi: 
 https://keras.io/api/layers/initializers/  
14"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#14,14,"Inizializzazione dei parametri
Nell'esempio si impiega una inizializzazione basata su una distribuzione 
gaussiana con deviazione standard 0.01.  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.random_normal_initializer(mean=
 0
, stddev=
 0.01
), 
        bias_initializer=tf.zeros_initializer()),  
    tf.keras.layers.Dense(
 1
)]) 
net(X) 
net.weights[
 0
], net.weights[
 1
] 
(<tf.Variable 
 'dense_2/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
 array([[-
 0.00021173
 ,  
0.00316905
 , -
0.00598176
 ,  
0.00144992
 ], 
        [-
 0.00882782
 ,  
0.01484077
 , -
0.00652608
 , -
0.00581241
 ], 
        [ 
 0.00398763
 , -
0.01069997
 , -
0.01145216
 , -
0.00430671
 ], 
        [ 
 0.00342147
 , -
0.01215916
 ,  
0.01345742
 ,  
0.01632656
 ]], 
       dtype=float32)>,  
 <tf.Variable 
 'dense_2/bias:0'
  shape=(
 4
,) dtype=float32, numpy=array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32)>)  
Invece per una inizializzazione con valori costanti:  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.keras.initializers.Constant(
 1
), 
        bias_initializer=tf.zeros_initializer()),  
Nota
 : è possibile impiegare inizializzazioni distinte per ogni layer.
15"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#15,15,"Inizializzazione dei parametri - custom
Per una inizializzazione custom dei parametri bisogna creare una classe a 
partire dalla classe Initializer, e de
 ﬁ
nire la funzione __call__() che restituisce 
il tensore in base alle dimensioni passate come parametro, es:  
class 
MyInit
(tf.keras.initializers.Initializer):  
    
 def 
__call__
 (
self
, shape, dtype=
 None
): 
        data=tf.random.uniform(shape, -
 10
, 
10
, dtype=dtype)  
        factor=(tf.abs(data) >= 
 5
) 
        factor=tf.cast(factor, tf.float32)  
        
 return
 data * factor  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, 
        activation=tf.nn.relu,  
        kernel_initializer=MyInit()),  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
print
(net.layers[
 1
].weights[
 0
]) 
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[-
 0.
       , -
 6.526873
  ,  
8.615063
  ,  
5.7617836
 ], 
       [ 
 0.
       ,  
 0.
       ,  
 6.0559807
 , -
0.
       ],  
       [-
 6.7486644
 ,  
8.665197
  ,  
0.
       , -
 7.035637
  ], 
       [-
 0.
       , -
 0.
       , -
 7.608464
  ,  
0.
       ]], dtype=float32)>  
16"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#16,16,"Inizializzazione dei parametri - custom (2)
In alternativa si possono impostare i parametri direttamente:  
net.layers[
 1
].weights[
 0
][:].assign(net.layers[
 1
].weights[
 0
] + 
1
) 
net.layers[
 1
].weights[
 0
][
0
, 
0
].assign(
 42
) 
net.layers[
 1
].weights[
 0
] # stampa  
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[
 42.
       , -
 5.526873
  ,  
9.615063
  ,  
6.7617836
 ], 
       [ 
 1.
       ,  
 1.
       ,  
 7.0559807
 ,  
1.
       ],  
       [-
 5.7486644
 ,  
9.665197
  ,  
1.
       , -
 6.035637
  ], 
       [ 
 1.
       ,  
 1.
       , -
 6.608464
  ,  
1.
       ]], dtype=float32)>  
Nell'esempio aggiorno i pesi del primo layer (+1) e imposto uno speci
 ﬁ
co 
peso al valore 42.
17"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#17,17,"Inizializzazione lazy
Nel codice visto, il risultato di alcune istruzioni dipende da iperparametri 
quali la dimensione dei layer (es. inizializzazione dei parametri, inserire un 
layer senza indicarne il numero di nodi), sebbene tali iperparametri non 
sono esplicitamente indicati.  
Con la inizializzazione differita (o lazy) è possibile de
 ﬁ
nire una architettura 
in modo più possibile parametrico, in modo da speci
 ﬁ
care solo gli 
iperparametri essenziali e derivare gli altri in modo automatico.  
In questo esempio manca la dimensione del layer di input, perciò Keras non 
può de
 ﬁ
nire completamente gli iperparametri:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
[net.layers[i].get_weights() 
 for
 i 
in 
range
(
len
(net.layers))]  
[[], []]  
...
18"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#18,18,"Inizializzazione lazy (2)
Se proviamo a de
 ﬁ
nire le dimensioni di un certo input, Keras può 
completare l'inizializzazione, ad esempio:  
X = tf.random.uniform((
 2
, 
20
)) 
net(X) 
[w.shape 
 for
 w 
in
 net.get_weights()]  
[(
20
, 
256
), (
256
,), (
256
, 
10
), (
10
,)]
19"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#19,19,"Layer custom
Possiamo de
 ﬁ
nire layer anche senza parametri da sottoporre ad 
addestramento. Nell'esempio implementiamo una sorta di normalizzazione 
sottraendo la media dai valori in input. Tale operazioni vanno inserite nella 
funzione call().  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
class 
CenteredLayer
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
call
(
self
, inputs):  
        
 return
 inputs - tf.reduce_mean(inputs)  
layer = CenteredLayer()  
layer(tf.constant([
 1.0
, 
2
, 
3
, 
4
, 
5
])) 
<tf.Tensor: shape=(
 5
,), dtype=float32, numpy=array([-
 2.
, -
1.
,  
0.
,  
1.
,  
2.
], dtype=float32)>  
Impieghiamo il layer custom nel nostro modello, e veri
 ﬁ
chiamo che con dait 
random otteniamo un valore medio in output quasi 0:  
net = tf.keras.Sequential([tf.keras.layers.Dense(
 128
), CenteredLayer()])  
Y = net(tf.random.uniform((
 4
, 
8
))) 
tf.reduce_mean(Y)  
<tf.Tensor: shape=(), dtype=float32, numpy=
 9.313226e-10
 >
20"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#2,2,"Deep networks e moduli
Abbiamo visto come una MLP sia composta da uno o più layer, ognuno 
composto da uno o più nodi che costituiscono l'unità elementare di 
elaborazione.  
Alcuni risultati ci suggeriscono che questo sia un modello suf
 ﬁ
cientemente 
generale per simulare un dominio molto vasto funzioni. Ma risultati 
sperimentali hanno dimostrato che modelli intermedi, più grandi del singolo 
neurone, ma più piccoli dell'intero modello computazionale siano più adatti 
per costruire architetture deep.  
Esempio
 : l'architettura 
 ResNet-152
  (Residual NN) sviluppata nell'ambito 
della computer vision è una delle prime architetture con 100ia di layers. 
La rete è costituita da schemi di nodi e connessioni (
 moduli
 ) che si 
ripetono. Particolari tecniche (
 skip connections
 ) sono impiegate per 
risolvere il vanishing problem.  
Un modulo può essere un layer, più layers, o l'intero modello; e generalizza 
un elemento computazionale che può essere ripetuto, o riutilizzato in diverse 
architetture.
3"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#20,20,"Layer custom con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
21"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#21,21,"Layer con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
22"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#22,22,"I/O su 
 ﬁ
le - tensori
Gli addestramenti di reti deep possono essere molto lunghe. È necessario 
salvare i risultati parziale e 
 ﬁ
nali su 
 ﬁ
le in modo da poterli recuperare 
facilmente.  
Ad esempio, per salvare e recuperare i tensori:  
import 
numpy 
as 
np 
import 
tensorflow  
as 
tf 
# salvataggio  
x = tf.range(
 4
) 
np.save(
 'x-file.npy'
 , x) 
# recupero  
x2 = np.load(
 'x-file.npy'
 , allow_pickle=
 True
) 
# salvataggio di più sensori  
y = tf.zeros(
 4
) 
np.save(
 'xy-files.npy'
 , [x, y])  
x2, y2 = np.load(
 'xy-files.npy'
 , allow_pickle=
 True
) 
# o salvare dizionari stringa-tensore  
mydict = {
 'x'
: x, 
'y'
: y} 
np.save(
 'mydict.npy'
 , mydict)  
mydict2 = np.load(
 'mydict.npy'
 , allow_pickle=
 True
) 
23"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#23,23,"I/O su 
 ﬁ
le - modelli
Per i modelli, occorre distinguere architettura e parametri. Per la prima, ci si 
basa sul codice che si usa per crearla, perciò senza salvataggio su 
 ﬁ
le. 
Mentre per i parametri si sfruttano le funzionalità di Keras.  
Ad esempio, de
 ﬁ
niamo una architettura, salviamo i parametri e ricostruiamo 
la rete con il recupero dei parametri:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
 def 
call
(
self
, inputs):  
        x = 
 self
.flatten(inputs)  
        x = 
 self
.hidden(x)  
        
 return 
self
.out(x) 
net = MLP()  
X = tf.random.uniform((
 2
, 
20
)) 
Y = net(X)  
net.save_weights(
 'mlp.params'
 ) 
...  
clone = MLP()  
clone.load_weights(
 'mlp.params'
 )
24"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#24,24,"GPU e Keras
Per default i tensori sono creati in memoria e le computazioni sono sulla 
CPU. Ma possiamo comunque controllare l'elaborazione:  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
cpu
():   
    
 return
 tf.device(
 '/CPU:0'
 ) 
def 
gpu
(i=
0
):   
    
 return
 tf.device(
 f'/GPU:
{
i
}
'
) 
cpu(), gpu(), gpu(
 1
) 
(<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa2b271c0
 >, 
 <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa257a100
 >, 
 [<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ad00
 >, 
  <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ab40
 >]) 
def 
num_gpus
 ():   
    
 return 
len
(tf.config.experimental.list_physical_devices(
 'GPU'
)) 
def 
try_gpu
(i=
0
):   
    
# restituisce gpu(i) se esiste, altrimenti cpu()  
    
 if
 num_gpus() >= i + 
 1
: 
        
 return
 gpu(i) 
    
 return
 cpu() 
def 
try_all_gpus
 ():   
    # 
Numero di GPU disponibili, o CPU se le GPU non ci sono  
    
 return
 [gpu(i) 
 for
 i 
in 
range
(num_gpus())]  
try_gpu(), try_gpu(
 10
), try_all_gpus()
25"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#25,25,"GPU e Keras (2)
# su quale device è allocato il tensore  
# Nota: è fondamentale avere tutti i parametri di una operazione sullo stesso device  
x = tf.constant([
 1
, 
2
, 
3
]) 
x.device  
'/job:localhost/replica:0/task:0/device:GPU:0'  
# alloca un tensore su una GPU  
with
 try_gpu():  
    X = tf.ones((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
1.
]], dtype=float32)>  
# alloca un tensore sulla seconda GPU  
with
 try_gpu(
 1
): 
    Y = tf.random.uniform((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 0.44844735
 , 
0.7493162
  , 
0.5692874
  ], 
       [
 0.10097635
 , 
0.81023645
 , 
0.5274769
  ]], dtype=float32)>  
# per calcolare X + Y, dobbiamo averli sullo stesso device  
# spostiamo X sulla stessa GPU di Y  
with
 try_gpu(
 1
): 
    Z = X  
print
(X) 
print
(Z) 
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
# ora possiamo calcolarlo  
Y + Z
26"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#26,26,"GPU e Keras (3)
È possibile indicare a Keras di impiegare le GPU disponibili per 
l'elaborazione di un certo modello:  
strategy = tf.distribute.MirroredStrategy()  
with
 strategy.scope():  
    net = tf.keras.models.Sequential([  
        tf.keras.layers.Dense(
 1
)]) 
INFO:tensorflow:Using MirroredStrategy 
 with
 devices (
 '/job:localhost/replica:0/task:0/device:GPU:0'
 , 
'/
job:localhost/replica:0/task:0/device:GPU:1'
 ) 
net(X) 
<tf.Tensor: shape=(
 2
, 
1
), dtype=float32, numpy=  
array([[-
 1.1522729
 ], 
       [-
 1.1522729
 ]], dtype=float32)>  
# vediamo la conferma cheanche i parametri sono memorizzati nello stesso device  
net.layers[
 0
].weights[
 0
].device, net.layers[
 0
].weights[
 1
].device  
(
'/job:localhost/replica:0/task:0/device:GPU:0'
 , 
 
'/job:localhost/replica:0/task:0/device:GPU:0')
27"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#3,3,"Moduli in Keras
Un modulo è rappresentato da una classe Python che implementa la forward 
propagation, memorizza i parametri, e fornisca la backpropagation. 
Quest'ultimo aspetto può essere delegato alla tecnica autodiff, senza perciò 
de
ﬁ
nire manualmente i singoli gradienti.  
Ad esempio il seguente codice genera due layer: il primo con 256 nodi 
 fully 
connected
  (o 
denso
 ) ed uno di output con 10 nodi.  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
X = tf.random.uniform((
 2
, 
20
)) 
net(X).shape  
Il modello è costruito istanziando la classe 
 Sequential
  e passandogli i singoli 
layer come parametri. Sia 
 Sequential
  che 
 Dense
  sono istanze di 
 keras.Model
 .  
4"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#4,4,"Sequential in Keras
Sequential crea una lista ordinata di layer.  
La procedura di forward propagation è de
 ﬁ
nita implicitamente: l'output di 
un layer corrisponde all'input del secondo.  
Nell'esempio si invoca net(X), che corrisponde alla funzione net.call(X), per 
ottenere l'output dal modello appena creato.
5"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#5,5,"Moduli custom
Per creare nuovi moduli occorre tener presente come vengono impiegati 
durante l'esecuzione:  
1.
I dati di input vengono mandati in input alla forward propagation  
2.
La funzione di propagazione restituisce i valori in output  
3.
Si calcolano i gradienti dell'output rispetto agli input per mezzo del 
metodo di backpropagation. Uno step solitamente gestito in automatico  
4.
Memorizzare i parametri ottenuti necessari per la successiva forward 
propagation
6"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#6,6,"Moduli custom
Ad esempio, la rete precedente (un layer da 256 nodi seguito da un layer di 
10 nodi) si codi
 ﬁ
ca nel seguente modo:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 # Sempre necessario richiamare il costruttore della superclass  
        
 super
().
__init__
 () 
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
# forward propagation  
    
 def 
call
(
self
, X): 
        
 return 
self
.out(
self
.hidden((X)))  
de
ﬁ
nendo il costruttore e la funzione che si occupa della forward 
propagation.  
Il metodo call permette di creare layer che richiedono particolari 
elaborazioni (es. controllare il 
 ﬂ
usso di esecuzione durante la forward 
propagation) che non corrispondono a quelle prede
 ﬁ
nite in Keras.
7"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#7,7,"Moduli custom - esempio
Durante l'elaborazione possiamo aver bisogno di accedere a costanti, cioè valori 
che non sono associati a parametri da stimare durante l'apprendimento, perciò 
non soggetti a back propagation.  
Nell'esempio, istanziamo i parametri in modo casuale, e rimarranno costanti 
durante il training. Restituiamo la somma dei valori in output.  
L'esempio è di scarsa utilità ma dimostra le potenzialità dei moduli custom.  
class 
FixedHiddenMLP
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
       
self
.rand_weight = tf.constant(tf.random.uniform((
 20
, 
20
))) 
        
 self
.dense = tf.keras.layers.Dense(
 20
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        X = 
 self
.flatten(inputs)  
        
 # Usiamo i parametri costanti per generare l'output  
        X = tf.nn.relu(tf.matmul(X, 
 self
.rand_weight) + 
 1
)        
        X = 
 self
.dense(X)  
        
 # Control flow: simil l1 regularization  
        
 while
 tf.reduce_sum(tf.math.abs(X)) > 
 1
: 
            X /= 
 2 
        
 # reduce_sum() calcola la somma dei valori per una certa dimensione del tensore  
        
 # senza secondo parametro la somma è operata su tutte le dimensioni del tensore  
        
 return
 tf.reduce_sum(X)  
net = FixedHiddenMLP()  
net(X) 
<tf.Tensor: shape=(), dtype=float32, numpy=
 0.88945085
 >
8"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#8,8,"Moduli custom - esempio
Nell'esempio de
 ﬁ
nisco un altro modello (NestMLP) e successivamente un 
nuovo modello che include il primo come layer:  
class 
NestMLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.net = tf.keras.Sequential()  
        
 self
.net.add(tf.keras.layers.Dense(
 64
, activation=tf.nn.relu))  
        
 self
.net.add(tf.keras.layers.Dense(
 32
, activation=tf.nn.relu))  
        
 self
.dense = tf.keras.layers.Dense(
 16
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        
 return 
self
.dense(
self
.net(inputs))  
chimera = tf.keras.Sequential()  
chimera.add(NestMLP())  
chimera.add(tf.keras.layers.Dense(
 20
)) 
chimera.add(FixedHiddenMLP())  
chimera(X)
9"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#9,9,"Esercizio
Implementare un modulo che prende l'output di due moduli (es. 
 net1
 e 
net2
) e restituisce un output concatenato durante la forward propagation.
10"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN) - parte 1
1"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#1,1,"Sommario
Introduzione  
Architettura Visual cortex  
MLP fully connected e limiti  
Invarianza (spaziale) e principio di località  
Convolutional layer e canali"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#10,10,"MLP - fully connected
Le reti MLP sono comunque ef
 ﬁ
caci in molti contesti, ad esempio:  
In presenza di dati in formato 
 tebellare
 , dove non assumiamo a priori 
una struttura che mette in correlazione le features per ogni istanza, 
sebbene possano esserci potenziali correlazioni e dipendenze.  
Dati da cui si possono estrarre un numero di features non elevatissimo 
(<<1000), che perciò necessitano di un numero di parametri da stimare 
limitato.
11"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#11,11,"Invarianza (spaziale) #1
12
Nella identi
 ﬁ
cazione delle targhe, per addestrare una MLP dobbiamo 
costruire un training set con molte istanze, in modo da :  
avere lo stesso oggetto che compare in varie posizioni, angolazioni e 
dimensioni.  
oggetto visualizzato parzialmente (es. sul bordo).  
casi di overlap tra oggetti etc."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#12,12,"Invarianza (spaziale) #2
Nel task ""Where's Waldo?"" non siamo interessati alla posizione, ma solo 
alla presenza o meno di una certa istanza.  
Il modello dovrebbe tentare di analizzare piccole zone dell'immagine e 
confrontarle con il pattern ""Waldo"".
13
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#13,13,"Proprietà locali
14Per riconoscere certe caratteristiche speci ﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata . Non c'è bisogno di considerare l'intera immagine iniziale.  
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  "
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#14,14,"MLP: Proprietà desiderate
15
Nei primi layer la rete dovrebbe comportarsi in modo simile 
indipendentemente dalla posizione di una certa regione di interesse 
(
translation invariance
  o 
translation equivariance
 ). 
Nei primi layer l'analisi deve essere limitata a piccole regioni 
dell'immagine in input, e non sull'intera immagine (
 principio di località
 ).  
Nei successivi layer, tali analisi considerano regioni più vaste, combinando 
l'output delle analisi precedenti, 
 ﬁ
no ad arrivare all'intera immagine."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#15,15,"Esempio MLP e immagini
16
Supponiamo di avere una MLP con uno strato nascosto 
 H
. L'input 
 X
 è 2d, ed è 
rappresentato da un tensore, anch'esso 2d. Supponiamo per ora che 
 H
 abbia la 
stessa struttura di 
 X
. 
Indichiamo con [
 X
]
i,j
 e [
H
]
i,j
 il pixel nella posizione <i,j> e il corrispettivo nodo nel 
layer nascosto.  
Indichiamo con 
 W
 e 
U
 pesi e bias della rete. Poiché ogni nodo di 
 H
 riceve input 
da tutti i pixel in input, usiamo matrici-tensori di ordine 4.  
Dove [
 V
]
i,j,a,b
 := [
H
]
i,j,i+a,j+b 
 , 
perciò introduciamo un semplice cambio notazione. 
Gli indici 
 a
 e 
b
 sono offset rispetto a <i,j> e scorrono l'intera immagine in input, 
perciò possono assumere valori negativi.  
Numero di parametri: per immagini 1000x1000 abbiamo 10
12
 parametri, infatti 
ogni nodo in 
 H
 deve essere connesso con tutti i nodi del layer precedente.
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#16,16,"Invarianza spaziale nella pratica
17
Tale proprietà impone che, se abbiamo uno 
 shift
 nell'input 
 X
, anche la 
rappresentazione 
 H
 deve subire lo stesso 
 shift
, in modo da mantenere lo 
stesso output. Ma questo è possibile solo se 
 U 
e 
V
 non dipendono da 
 <i,j>
, 
cioè [
 V
]
i,j,a,b
 := [
V
]
a,b  
e 
U
 è una costante.  
Rappresenta l'operatore di 
 convoluzione
 . Il pixel <i+a,j+b>, vicino alla 
location <i,j>, è pesato con il coef
 ﬁ
ciente [
 V
]
a,b
 per ottenere l'output [
 H
]
i,j
. 
[
V
]
a,b  
richiede meno coef
 ﬁ
cienti poiché è indipendente dalla location. I 
parametri passano da 10
12
 a 4·10
6
, con 
 a
 e 
b
 in (-1000,1000).
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#17,17,"Principio di località nella pratica
18
Limitiamo l'analisi per determinare [
 H
]
i,j
 a una zona 
 Δ
×
Δ
, con 
Δ
<<1000 
(es. 
Δ
=10), perciò evitando di considerare l'intera immagine:  
I parametri si riducono ulteriormente da 4·10
6
 a 4·
Δ
2
, sebbene il layer 
nascosto mantenga la dimensione iniziale, e perciò la quantità di 
informazione originale.  
La regione 
 Δ
×
Δ
 che genera le attivazioni nel successivo strato è chiamata 
Local receptive 
 ﬁ
eld (LRF)
 .
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#18,18,"CNN - Convolutional layer e LRF
19
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input:  
immagine 25x25 pixe l
in bianco e neroOutput dopo il primo  
layer convolutivo .local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato  
da una certa posizione del 
LRF  che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#19,19,"Convolutional neural networks
20
Il layer 
 H
 che abbiamo introdotto prende il nome di 
 convolutional layer,
  e 
le rete basate su tale layer 
 Convolutional neural networks
  (CNNs).  
V
 è comunemente chiamato 
 convolution kernel
  o 
ﬁ
ltro
. 
Per rappresentare features più complesse e ad alto livello, si impiegano più 
layer convolutivi alternati a non linearità."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#2,2,"Introduzione
Alcune so
 ﬁ
sticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come:  
•
Riconoscere un giocattolo in una immagine  
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speci
 ﬁ
che.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture.  
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identi
 ﬁ
carlo.  
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
3"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#20,20,"Channels (canali)
21
Le immagini a colori hanno 3 canali RGB, perciò, ai due assi principali che 
identi
 ﬁ
cano le relazioni spaziali, ne aggiungiamo un terzo ottenendo 
tensori 3d [
 X
]
i,j,k
 con 
 ﬁ
ltri del tipo [
 V
]
a,b,c
 . 
Muovendoci in profondità, possiamo creare una terza dimensione per ogni 
strato hidden. In pratica si ha uno 
 stack
  di griglie, chiamato 
 feature maps
 , 
dove ogni griglia è creata con un 
 ﬁ
ltro distinto. Il numero di griglie 
corrisponde ai canali per quello strato.  
Generalizzando, supponendo di avere più canali in input (
 c
) e più canali 
nell'hidden layer (
 d
), si ha:  
Il successivo layer userà i 
 d
 canali dell'hidden layer che diverranno i 
 c 
canali di input.
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#21,21,"Esercizio
22
Impiega il dataset di cifre MNIST e crea una rete convolutiva per la 
classi
 ﬁ
cazione.  
Colab 
 07-lenet.ipynb 
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#3,3,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive 
 ﬁ
eld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale.  
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
con
ﬁ
gurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"".  
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi.  
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
4"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#4,4,"L'architettura della Visual cortex
5
Secondo te è una MLP?Ad ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#5,5,"L'architettura della Visual cortex
6
È simile a una MLP ,  
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#6,6,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
7"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#7,7,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
8"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#8,8,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare.  
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo 
task
, es. riconoscere linee orizzontali.  
•
I neuroni specializzati sono attivati se il pattern da identi
 ﬁ
care è 
localizzato in una certa zona.  
•
Ma vorremmo poter identi
 ﬁ
care lo stesso pattern indipendentemente da 
dove compare.
9"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#9,9,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
3. Le reti 
 MLP 
non riescono a codi
 ﬁ
care esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identi
 ﬁ
cano 
features analizzando piccole aree dell'immagine.  
•
I neuroni ""ad alto livello"" combinano tali features per identi
 ﬁ
care features 
spazialmente più estese.
10"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
2a parte
1"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#1,1,"Sommario
Convolutional Neural network  
•
Convolutional layer  
•
Local receptive 
 ﬁ
eld 
•
Stride e Padding  
•
Filters e Feature Maps  
•
Pooling Layer  
Architettura LeNet-5"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#10,10,"CNN - Stride
11•La distanza s tra due LRF  adiacenti è chiamata stride . 
•Finora abbiamo visto stride di 1 pixel, ma la LRF  può scorrere di più pixel . 
•Le CNN spesso impiegano kernels di dimensione 1,3,5 o 7. Questo rende più facile mantenere 
la dimensionalità con padding (vedi di seguito) che consistono nello stesso numero di righe in 
cima e in fondo, e colonne a sinistra e a destra dell'immagine. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3  
Stride = 2"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#11,11,"CNN: Padding
12•Supponendo stride > 1 , può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF ) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input.  
•Il padding  aggiunge dimensioni  ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding ). Si hanno i seguenti vantaggi :
•Permettere alla LRF  di scorrere per intero l'immagine in input senza ignorarne delle parti .
•Un LRF potrebbe ""imparare"" a riconosce una certa feature  quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo , senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#12,12,"CNN: Riduzione dimensionalità e Stride
13Output layer precedente•La presenza di stride > 1  altera gli indici iniziali e ﬁnali che identi ﬁcato il LRF associato ad 
un certo nodo.  
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista .
•Stride > 1 riducono la dimensione  del layer convoluzionale a scapito della precisione .
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3  
Stride = 2"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#13,13,"CNN: Filters
14Filters•Supponiamo di poter rappresentare gra ﬁcamente i pesi associati a un certo nodo , usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters  o convolution kernels  
(o kernels )
•Ad esempio, una LRF  77 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#14,14,"Esempi di 
 ﬁ
ltri e attivazioni (1)
15Esempio di input  
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo .
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#15,15,"Esempi di 
 ﬁ
ltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#16,16,"CNN: Feature Maps
17Filters•Le LRF  scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione . Tale approccio prende il nome di shared weights . 
•L'insieme delle attivazioni ottenute (output) con lo stesso ﬁltro viene chiamato feature map 
poiché rappresenta le features apprese nella dimensione spaziale. Esse possono essere 
visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map  dove le zone dell'input simili a una 
linea verticale  sono più evidenziate  (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate . Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#17,17,"CNN: Stacking feature maps
In 
ogni layer
  possiamo avere 
 più 
ﬁ
ltri con le medesime dimensioni
 . Ogni 
ﬁ
ltro produrrà una diversa feature map. Ogni layer sarà così costituito da 
una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i 
 ﬁ
ltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di:  
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP.  
•
Durante la backpropagation, adattare ogni 
 ﬁ
ltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso 
 ﬁ
ltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
18"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#18,18,"Canali multipli in input
Abbiamo già visto l'operatore di convoluzione in presenza di più canali.  
Se in ingresso abbiamo più canali, es. RGB, 
 c
i
 > 1, allora il 
 ﬁ
ltro 
rappresentato dal tensore 
 k
h
 × 
k
w
 dovrà essere ripetuto per ogni canale. Se 
concateniamo i tensori abbiamo un tensore 
 c
i 
× k
h
 × 
k
w
. 
Il risultato sarà un tensore 2d poiché il risultato delle singole convoluzioni 
sarà sommato nella dimensione dei canali.  
Ad esempio, considerando 2 canali in input:
19
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#19,19,"Canali multipli in output
Nelle CNN tradizionalmente il numero di canali aumentano con il numero 
di layer processati, generalmente riducendo allo stesso tempo la risoluzione 
spaziale degli input.  
Idealmente ogni canale rappresenterà un different set di features, ma in 
realtà le features possono essere 
 sparse
  su più canali.  
Per avere un output multicanale, creiamo più tensori 
 c
i 
× k
h
 × 
k
w 
, ognuno 
per singolo canale in output. Se li concateniamo otteniamo un kernel  
c
o 
× c
i 
× k
h
 × 
k
w
 .
20"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#2,2,"CNN - Struttura gerarchica
3Input layer:  
È un layer costituito da unità  
a cui viene associato il valore  
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerData una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota : Nelle tradizionali MLP , input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori , ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN  tale ridimensionamento è controproducente  poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell' input layer  le features  
corrispondono ai singoli pixel"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#20,20,"CNN: Feature Maps e Canali
21...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB, cioè 3 
canali.Possiamo de ﬁnire un certo numero di 
ﬁltri (es. 12) per riconoscere diverse 
caratteristiche salienti dell'immagine 
iniziale. I ﬁltri analizzano 
contemporaneamente 3 canali RGB, 
perciò i ﬁltri saranno de ﬁniti con 
matrici a 3 dimensioni. Un ﬁltro 
applicato all'immagine in input 
produce un singolo convolutional layer.I successivi layer convoluzionali 
analizzato le attivazioni di più ﬁltri 
contemporaneamente. I ﬁltri di questo 
layer riconosceranno caratteristiche 
più astratte.depth = 3 depth = 12 depth = 7"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#21,21,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori:  
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
2201234567891011121300 12345678910111213
senza padding ('VALID' ) con padding ('SAME' )ignorati
stride=5padding P=+3"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#22,22,"Stride, padding e Keras
Le dimensioni del kernel e i restanti iperparametri sono de
 ﬁ
niti via 
costruttore del modello Conv2D:  
# numero di kernels pari a 1  
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=
 3
, padding=
 'same'
, strides=
 2
) 
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=(
 3
,
5
), padding=
 'valid'
, strides=(
 3
, 
4
)) "
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#23,23,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di 
 ﬁ
ltri per layer (o 
 depth
 ) 
Dimensione del LRF  
Stride e padding  
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una con
 ﬁ
gurazione 
verosimilmente già ottimizzata.
24"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#24,24,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con 
ﬁ
ltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200  
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile.  
•
Con 
ﬂ
oat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
25"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#25,25,"Pooling layer
Ripetendo i layer convolutivi, ad ogni layer il 
 receptive 
 ﬁ
eld
 sarà 
 sensibile  
ad una parte sempre maggiore in riferimento all'immagine iniziale. Perciò 
gli ultimi nodi della rete saranno attivati in base all'intera informazione 
presente nell'immagine iniziale.  
Spesso l'informazione spaziale esatta delle features riconosciute non è 
importante, soprattutto se ci interessa l'invarianza ad eventuali translazione 
dell'input.  
I pooling layer sono utili per:  
mitigare la sensitività
  dei layer convolutivi rispetto alle posizioni delle 
features  
ridurre la dimensionalità dell'input da elaborare
 .
26"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#26,26,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti:  
•
Meno complessità computazione  
•
Meno risorse di memoria  
•
Meno parametri (e ridurre l'over
 ﬁ
tting come effetto collaterale)  
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF.  
•
Occorre de
 ﬁ
nire dimensione, stride e padding  
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
27"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#27,27,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁ
eld (
pooling size
 ), il 
pooling stride
 , e tipo di aggregazione.  
•
Spesso pooling size e stride corrispondono.  
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identi
 ﬁ
cata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche.  
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta.  
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel 
ﬁ
eld considerato.  
•
average pooling:
  considero il valor medio nel 
 ﬁ
eld.
28"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#28,28,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max.  
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
29
A causa del padding VALID  
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  fpo è il pooling size , spo il pooling stride ,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#29,29,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri.  
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente:  
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#3,3,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la 
 ﬁ
nestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della 
 ﬁ
nestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#30,30,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classi
 ﬁ
cazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden:  
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID  
•Numero ﬁltri (o depth) = 96  
•L’output per ogni ﬁltro avrà dimensione di lato 
(227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 
=290.400 nodi.  
•L'attivazione di un nodo si ricava considerando 
11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri.  
•Per la proprietà degli shared weights, nella CNN il 
numero di parametri sarà 11x11x3x96 + 96 = 
34.944.  × ×
×
×
feature mapscomputazione"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#31,31,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST.  
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identi
 ﬁ
cate dalle CNN 
per fare classi
 ﬁ
cazione per mezzo della MLP.  
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni."
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#32,32,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/  "
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#33,33,"Architettura LeNet-5
convolutional layer#1 conv. laye r
feature maps:  
28x28, depth 6#3 conv. layer  
feature maps:  
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling laye r
feature maps:  
14x14, depth 6#4 pooling laye r
feature maps:  
5x5, depth 16
conv. layer#6 fully connected layer  
nodi 84#5 conv. layer  
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer  
nodi 10
La con ﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding."
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#34,34,"LeNet-5: esempio di 
 ﬁ
ltri
Nel caso del dataset MNIST di caratteri numerici (immagini 28x28), 
otteniamo 
 ﬁ
ltri di questo tipo:  
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#4,4,"CNN - LRF
5Output layer precedente•In un certo layer convoluzionale , un nodo con indice (i, j) prende in input  gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF  va dalla riga  i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e fw corrispondono all'altezza e larghezza del LRF . 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni .forward propagation
Esempio con LRF 3x3  
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding  
(discusso più avanti)
•Notazioni: rispetto alle slide precedenti 2Δ=fh=fw"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#5,5,"Cross-correlazione
Supponendo 
 K
 il kernel e 
 X
 l'input 2d, possiamo de
 ﬁ
nire la funzione 
 corr2d
 () che 
restituisce un output di dimensioni pari all'input, meno la dimensione del kernel 
 + 
1
: 
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
corr2d
(X, K):  
    h, w = K.shape  
    Y = tf.Variable(tf.zeros((X.shape[
 0
] - h + 
 1
, X.shape[
 1
] - w + 
 1
))) 
    
 for
 i 
in 
range
(Y.shape[
 0
]): 
        
 for
 j 
in 
range
(Y.shape[
 1
]):         
            # estraggo la parte di X che mi interessa  
            # calcolo una moltiplicazione element-wise tra le matrici  
            # ricavo infine la somma  
            Y[i, j].assign(tf.reduce_sum(  
                X[i: i + h, j: j + w] * K))  
    
 return
 Y 
X = tf.constant([[
 0.0
, 
1.0
, 
2.0
], [
3.0
, 
4.0
, 
5.0
], [
6.0
, 
7.0
, 
8.0
]]) 
K = tf.constant([[
 0.0
, 
1.0
], [
2.0
, 
3.0
]]) 
corr2d(X, K)  
<tf.Variable 
 'Variable:0'
  shape=(
 2
, 
2
) dtype=float32, numpy=  
array([[
 19.
, 
25.
], 
       [
 37.
, 
43.
]], dtype=float32)>  
Nota
 : l'operatore di 
 convoluzione
  è simile all'operatore 
 cross-correlazione
 , ma nel 
primo il kernel è ""
 capovolto"" 
 durante il calcolo. Nelle CNN si impiega usualmente 
la cross-correlazione. Non c'è differenza poiché i pesi ricavati durante 
l'addestramento sono i medesimi, ma con ordine invertito. Spesso nei testi e nel 
codice i due termini assumono lo stesso signi
 ﬁ
cato.
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#6,6,"Esempio di modello Conv2D
class 
Conv2D
(tf.keras.layers.Layer):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
build
(
self
, kernel_size):  
        initializer = tf.random_normal_initializer()  
        
 self
.weight = 
 self
.add_weight(name=
 'w'
, shape=kernel_size,  
                                      initializer=initializer)  
        
 self
.bias = 
 self
.add_weight(name=
 'b'
, shape=(
 1
, ), 
                                    initializer=initializer)  
    
 def 
call
(
self
, inputs):  
        
 return
 corr2d(inputs, 
 self
.weight) + 
 self
.bias"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#7,7,"Esempio: riconoscimento bordi
Supponiamo che vogliamo riconoscere il bordoe in una immagine 
monitorando il cambio del valore dei pixel.  
Costruiamo una immagine 6x8 nel seguente modo:  
X = tf.Variable(tf.ones((
 6
, 
8
))) 
X[:, 
2
:
6
].assign(tf.zeros(X[:, 
 2
:
6
].shape))  
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
8
) dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
]], dtype=float32)>  
Costruiamo un kernel 1x2  
K = tf.constant([[
 1.0
, -
1.0
]]) 
Con la crosscorrelazione, l'output è 0 quando due elementi adiacenti 
dell'input sono uguali, altrimenti un valore diverso da 0.  
Nota
 : la crosscorrelazione corrisponde ad una approssimazione 
discreta della derivata del primo ordine.
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#8,8,"Esempio: riconoscimento bordi
Si nota il risultato +1 nei bordi da bianco a nero, -1 da nero a bianco:  
Y = corr2d(X, K)  
Y 
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
7
) dtype=float32, numpy=  
array([[ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
]], dtype=float32)>  
Trasponendo l'immagine, il kernel non individua più i bordi:  
corr2d(tf.transpose(X), K)  
<tf.Variable 
 'Variable:0'
  shape=(
 8
, 
5
) dtype=float32, numpy=  
array([[
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
]], dtype=float32)>"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#9,9,"Kernel: training
Al principio non abbiamo kernel precostituiti, dobbiamo ottenerli 
durante l'addestramento, soprattutto se abbiamo molti layer convolutivi 
in cascata. Il procedimento è simile al caso MLP, es:  
# Un layer convolutivo, 2d con 1 canale in output, un kernel 1x2  
# Per semplicità ignoriamo i bias ora  
conv2d = tf.keras.layers.Conv2D(
 1
, (
1
, 
2
), use_bias=
 False
) 
# L'input è nella forma (batch_size, height, width, channel),  
# dove batch size e canali sono entrambi 1  
X = tf.reshape(X, (
 1
, 
6
, 
8
, 
1
)) 
Y = tf.reshape(Y, (
 1
, 
6
, 
7
, 
1
)) 
lr = 
3e-2  
# Learning rate  
Y_hat = conv2d(X)  
for
 i 
in 
range
(
10
): 
    
 with
 tf.GradientTape(watch_accessed_variables=
 False
) 
as
 g: 
        
 # indichiamo noi le variabili su cui operare il gradiente  
        g.watch(conv2d.weights[
 0
]) 
        Y_hat = conv2d(X)  
        l = (
 abs
(Y_hat - Y)) ** 
 2 
        
 # aggiornamento kernel  
        update = tf.multiply(lr, g.gradient(l, conv2d.weights[
 0
])) 
        weights = conv2d.get_weights()  
        weights[
 0
] = conv2d.weights[
 0
] - update  
        conv2d.set_weights(weights)  
        
 if
 (i + 
1
) % 
2
 == 
0
: 
            
 print
(
f'epoch 
 {
i + 
1
}
, loss 
{
tf.reduce_sum(l)
 :
.3f
}
'
) 
epoch 
2
, loss 
17.533 
epoch 
4
, loss 
3.607 
epoch 
6
, loss 
0.878 
epoch 
8
, loss 
0.259 
epoch 
10
, loss 
0.089 
# monitoriamo i tensori ottenuti  
tf.reshape(conv2d.get_weights()[
 0
], (
1
, 
2
))"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
3a parte
1"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#1,1,"Sommario
Calcolo del numero dei parametri  
LeNet-5 e calcolo dei parametri  
Architettura AlexNet  
1x1 convolution"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#10,10,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
11"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#11,11,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 .
12"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#12,12,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
13"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#13,13,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
14"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#14,14,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.
15"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#15,15,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.  
5.
Distribuire la computazione
  su più elaboratori.
16"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#16,16,"Architettura CNN più recenti
Ne sono state proposte molte. Anche se sviluppate in un particolare task di 
computer vision, esse sono state impiegate in modo pro
 ﬁ
cuo in altri domini, es. 
tracking, segmentation, object detection, style transformation.  
La challenge ImageNet (dal 2010) è favorito lo sviluppo di molte architetture.  
Le CNN sono relativamente semplici, ma creare una architettura ef
 ﬁ
ciente 
richiede intuizione, una base algebrica, e molti tentativi.  
Speso nuove architetture sfruttano elementi di architetture precedenti."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#17,17,"Architettura CNN più recenti #1
Sebbene LeNet sia ef
 ﬁ
ciente per il problema OCR, non si adatta facilmente a 
dataset più grandi ed eterogenei. Effettivamente dal 1995 (LeNet) al 2012 (AlexNet) 
sono state proposte tecniche ML alternative (es. kernels, ensemble, structured 
estimation) ef
 ﬁ
cienti in molti tasks.  
Perché abbiamo atteso così a lungo per avere una rete più versatile e capace di 
competere con le altre architetture ML?  
Nel anni '90 una scheda GPU come la NVIDIA GeForce 256 era capace di 480 
MFLOP, senza la disponibilità di framework software per sempli
 ﬁ
care la 
programmazione. Oggi la NVIDIA Ampere A100 raggiunge i 300 TFLOPS . Un 
dataset di cifre a bassa risoluzione (28x28) era considerato molto arduo da trattare.  
In pratica, era molto complesso testare architetture GPU-based anche su 
dataset semplici.  
I 
dati disponibili
  adatti all'addestramento sono aumentati sensibilmente, e questo 
ha garantito la sperimentazione di un numero maggiore di architetture.  
ImageNet è stato costruito mediante Google Image e per mezzo di Amazon 
Mechanical Turk per la classi
 ﬁ
cazione manuale."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#18,18,"LeNet vs AlexNet
AlexNet ha 8 layers: 5 convolutivi, 2 FC nascosti, 1 FC output.  
Usa la ReLU invece delle sigmoid o tanh.
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#19,19,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%) sviluppata da Alex Krizhevsky e 
Ilya Sutskever.  
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.  
E' molto simile a 
 LeNet-5
  ma con più profondità.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer.  
Impiega ReLI, SGD e 
momentum.  
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 NVIDIA 
GTX 580s con 3Gb)."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#2,2,"Calcolo del numero di parametri di una rete neurale
Il calcolo del numero di parametri è
  fondamentale per 
comprendere la complessità 
 della rete e apportare miglioramenti 
all'architettura (es. introducendo pooling layer per ridurre i 
parametri).  
Il calcolo dipende dal tipo di layer che stiamo considerando e dai 
valori ricevuti dal layer precedente.  
Consideriamo il calcolo del numero di parametri per le seguenti 
con
ﬁ
gurazioni:  
Un 
Convolutional layer 
 seguito da un 
 FC layer
   (
CONV
 FC
) 
Un
 Input layer 
 seguito da un 
 Convolutional layer
  (
I
FC
) 
Un 
FC layer 
 seguito da un 
 FC layer 
 (
FC
 FC
)
→
→
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#20,20,"Architettura AlexNet (2)
Le immagini di ImageNet sono 8x più grandi rispetto a MNIST.  
I LRF del primo strato sono 11x11, 5x5 nel secondo e 3x3 nel terzo.  
Dopo il primo, il secondo e 5o strato convolutivo, c'è un 
 max-pooling layers
  con 
ﬁ
nestra 3x3 e uno stride pari a 2.  
AlexNet ha 10 volte i canali di LeNet.  
La rete FC multi-layer ha 1Gb di parametri. La doppia pipeline di elaborazione 
permetteva di suddividere l'occupazione.  
Il numero elevato di parametri rende AlexNet poco ef
 ﬁ
ciente rispetto ad 
architetture più recenti.  
La ReLU rende la computazione dei gradienti più rapida. Inoltre se 
l'inizializzazione dei parametri porta a valori di attivazione vicini ad 1 o 0 
(estremi dell'intervallo) la derivata è vicina allo 0, e questo rallenta 
l'aggiornamento dei pesi. Il gradiente della ReLU è sempre 1 per valori positivi.  "
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#21,21,"Architettura AlexNet (3)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signi
 ﬁ
cativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
Il dropout nei layer FC prende il posto del weight decay della LeNet. Questo 
garantisce una sorta di regolarizzazione dei parametri  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#22,22,"Esempio: Filtri di AlexNet
Esempi di 
 ﬁ
ltri dei primi layer di Alex Net dopo l'addestramento:
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#23,23,"AlexNet e Keras
08-AlexNet.ipynb"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#24,24,"La 
1
1 convolution
  è un 
 ﬁ
ltro di dimensione 
 1
1
C
 e (ovviamente) si 
applica a input con profondità 
 C
. 
•
Può essere vista come una 
 rete neurale con un layer,
  che prende in input 
un vettore di 
 C
 elementi.  
•
Per 
C
 pari a 
 1 
non viene impiegato  
•
Un 
ﬁ
ltro 1
 1
1 corrisponde ad una moltiplicazione per uno scalare, operazione 
inutile in una rete neurale.  
A cosa può servire?
×
 ×
×
×
×
CNN: 1
 1 convolution
×
output layer precedente :
supponi una profondità C > 1feature map  
avrà la stessa 
dimensione dell'input 
ma profondità pari a 1
dimensione LRF : 
11C××"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#25,25,"CNN: 1x1 convolution (2)
Effettua un 
 feature pooling
  cioè combina linearmente più features legate tra 
loro da un certa legame spaziale (es. i 3 valori dei canali RGB di un pixel).  
•
Utile quando si hanno feature maps con grande profondità e si vuole ridurre 
il numero di paremetri nei layer successivi.  
•
Mentre il 
 pooling
  tradizionale aggrega più feature vicine all'interno della 
stessa feature map.  
Se in input abbiamo una feature maps con profondità 
 C
, ogni mappa 
rappresenterà l'importanza di una diversa feature in una certa posizione. La  
1
1 convolution
  raccoglie le informazioni di 
 C
 features diverse valutate nella 
stessa posizione per determinare un singolo output.
×
1x1 conv
La profondità è passata da 32 a 1.  
Impiegano n ﬁltri 1x1 conv, 
otteniamo una profondità n della 
feature maps in output."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#26,26,"CNN: 1x1 convolution (3)
Oltre a ridurre il numero di parametri nei layer successivi in presenza di 
feature maps con grande profondità, la 
 1
1 convolution
  viene usata 
anche per creare nuove 
 proiezioni  
lineari
  a partire dalle feature map 
correnti.  
•
Le proiezioni creazioni 
 nuove features
  determinate dalla combinazioni 
di più feature maps nei layer precedenti. 
×
+verso i layer successivi..."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#3,3,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  nel layer convoluzionale, che 
produrranno i valori delle attivazioni nelle feature maps.  
•
Il layer di input non ha pesi associati.  
Se indichiamo con:  
•
#
W
c
 e #
B
c 
il numero di pesi e bias del layer convoluzionale  
•
f
 la dimensione del LRF  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
C
 profondità delle istanze in input (es. 3 per immagine a colori RGB)  
allora si ha:  
#
W
c
 = f
2 
 C 
 N
c 
    e    #
 B
c
 = N
 c 
Lo stesso risultato si ottiene per con
 ﬁ
gurazioni 
 CONV
 CONV
 , considerando come 
profondità 
 C
 la profondità delle feature maps nel layer precedente.  
Si nota come il numero di parametri è indipendente dalla dimensione X,Y dell'input.
×
×
→
Calcolo del numero dei parametri: 
 I
FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#4,4,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso alle 
feature maps prodotte dal convolutional layer precedente.  
Se indichiamo con:  
•
#
W
cf
 e #
B
cf  
il numero di pesi e bias del layer FC  
•
O
 dimensione delle feature maps nel convolutional layer, supponendo larghezza e 
altezza coincidenti.  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
F
 numero dei nodi nel layer FC  
allora si ha:  
#
W
cf
 = O
2 
 N
c 
 F 
   e   
 #B
cf
 = F  
Spesso si opera una ""
 linearizzazione
 "" dell'output del convolutional layer. Se 
abbiamo 
 N
c 
ﬁ
ltri e una dimensione delle feature maps pari a OxO, introduciamo 
una rappresentazione 1-dimensionale con un vettore di 
 O
2
• N
 c
 elementi, passato in 
input al layer fully-connected.
×
×
Calcolo del numero dei parametri: 
 CONV
 FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#5,5,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso al FC 
precedente.  
Se indichiamo con:  
•
#
W
ff
 e #
B
ff 
 il numero pesi e bias del layer FC  
•
F
 il numero di nodi nel layer FC  
•
F
-1
 il numero di nodi nel layer FC precedente  
allora si ha:  
#W
 ff
 = F
 -1 
 F
    e   
 #B
ff
 = F
 ×
Calcolo del numero dei parametri: 
 FC
 FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#6,6,"LeNet-5: numero di parametri
Indichiamo con 
 f
, 
s
 e 
p
 rispettivamente la dimensione del 
 ﬁ
ltro, stride e 
pooling (dove 0 corrisponde al pooling VALID).
Non è un vero layer ,
ma una linearizzazione dei 
dati: rendiamo ﬂat la 
rappresentazion e
5x5x16 -> 40028x28x6  
feature maps di 6 ﬁltri 
di dimensione 28x28 l'uno
14x14x6  
un pooling layer con f e s pari 
a 2 dimezza le dimensioni ,
ma mantiene uguale la dept h
della feature maps."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#7,7,"LeNet-5: numero di parametri (2)
Dopo la convoluzione 
abbiamo 6 ﬁltri 28x28. Dopo il pooling abbiamo  
6 ﬁltri 14x14
Invece di avere 240000 
parametri ne abbiamo 
151600 (vedi commento 
dopo).Stesso procedimento di S2 
ma ora abbiamo 16 ﬁltriPooling
Poolingncl-1 è la profondità  
del  layer precedente. 
supponiamo input depth = 1  
cioè scala di grigiil pooling layer non  
altera la profondità
ognuno dei 28x28 in output 
ha 5x5x6 connessioni col 
layer precedente, cioè 
l’immagine in input.Connections =  
28x28 x 5x5x1x6 = 117600
Connections =  
10x10x5x5x6x10 = 150000"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#8,8,"LeNet-5: peculiarità
Nel #3 hidden layer, con lo scopo di ridurre potenziali simmetrie e il numero di 
connessioni, gli autori hanno deciso che
  solo 10 delle 16 features maps sono connesse 
con le 6 features maps del layer precedente
 .  
La tecnica 
 dropout
  introdotta solo successivamente ha automatizzato questo step, 
perciò non si riscontra in architetture più recenti.
Schema di interconnessione tra feature maps impiegato.
Connections =  
10x10x5x5x6x10 = 150000"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#9,9,"LeNet-5: numero di parametri (3)
Rendiamo “ ﬂat” l’output 
precedente.  Abbiamo 400 
(5x5x16) nodi dal layer S4. 
Il primo strato fully 
connected layer ha 120 nodi. 
Ogni nodo del layer è 
connesso con i 400 nodi 
dello strato precedente.Fully connected layer con 
84 neuroni.softmax"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
4a parte - Architetture
1"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#1,1,"Sommario
Architetture avanzate CNN  
VGG  
NiN 
GoogleNet"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#10,10,"Poiché le risorse di calcolo necessarie alla VGG sono molto 
maggiori di AlexNet, costruiamo una rete con un numero minore di 
canali, suf
 ﬁ
cienti per il dataset Fashion-MNIST.  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
with
 d2l.try_gpu():  
    model = VGG(arch=((
 1
, 
16
), (
1
, 
32
), (
2
, 
64
), (
2
, 
128
), (
2
, 
128
)), lr=
0.01
) 
    trainer.fit(model, data)  
C'è una similarità tra val_loss e train_loss, con un discostamento 
minimale che può rappresentare un piccolo over
 ﬁ
tting.
Training VGG Network e Keras
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#11,11,"L'upsampling di Fashion-MNIST di un fattore 8 (da 28x28 a 
224x224) è molto inef
 ﬁ
ciente. Prova a modi
 ﬁ
care l'architettura per 
trattare immagini 28x28.
VGG - Esercizio"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#12,12,"Rispetto a LeNet, AlexNet e VGG intervengono principalmente 
creando strutture (conv_layer + pooling) più ""profonde"" e più 
""ampie"".  
Ma i layer FC 
 ﬁ
nali richiedono ancora molti parametri.  
Una semplice VGG-11 richiede matrici 25088x4096, con una 
occupazione di 400Mb di RAM (FP32). Non adatti a sistemi 
embedded e mobile.  
L'architettura Network in network (NiN) blocks consiste in un 1x1 
conv layer che aggiunge non-linearità tra le attivazioni dei canali, e 
un 
global average pooling
  nell'ultimo layer.
Network in Network (NiN)"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#13,13,"Rimpiazza i layer FC di una rete CNN tradizionale con un pooling.  
Prende in input un tensore 3d (height,width,channels) e ricava 
l'avg rispetto al dimensione channels.  
L'idea è generare una feature map per ogni categoria di interesse nel 
task nei layer 
 ﬂ
attening, inviando l'output direttamente alla softmax.  
Introduce una sorta di codi
 ﬁ
ca più diretta tra feature maps e 
categorie di interesse. Le feature maps possono essere interpretate 
come 
 mappe di con
 ﬁ
denze con le categorie
 . 
Non ci sono i parametri tradizionali, e si evitano fenomeni di 
over
ﬁ
tting.  
È più robusto a traslazioni spaziali poiché l'operazione considera 
tutte le informazioni spaziali disponibili.
Global average pooling
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#14,14,"Ricordiamo che l'input e output dei conv layers sono tensori 4d: 
istanze, channel, height e width.  
L'input e output di un layer FC sono tensori 2d (istanze, features).  
L'idea è applicare un FC layer a ogni posizione di pixel (per ogni 
height e width). La rete risultante 1x1 conv può essere interpretata 
come un layer FC indipendente per ogni pixel.  
Il blocco NiN è costituito da un conv layer seguito da convoluzioni 
1x1. 
In questo modo non c'è necessità di una grossa rete FC al termine 
dell'architettura.
Blocchi NiN"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#15,15,"La rete NiN usa le stesse dimensioni dei 
 ﬁ
ltri di AlexNet: 11x11, 5x5 
e 3x3; e le stesse dimensioni dei canali di output.  
Le conv net sono seguite da pooling layer 3x3 con stride 2.  
NiN non include FC layer. Il numero dei canali di output dei blocchi 
NiN corrispondono al numero di classi del task, seguite da un 
global average pooling
 , ottenendo un vettore di logits.  
L'architettura riduce il numero di parametri a scapito del tempo di 
training, più lungo.
Architettura NiN"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#16,16,"Architettura NiN
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#17,17,"NiN in codice Keras:  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
def 
nin_block
 (out_channels, kernel_size, strides, padding):  
    
 return
 tf.keras.models.Sequential([  
    tf.keras.layers.Conv2D(out_channels, kernel_size, strides=strides,  
                           padding=padding),  
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
)])
Blocco NiN in Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#18,18,"class 
NiN
(d2l.Classifier):  
    
 def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            nin_block(
 96
, kernel_size=
 11
, strides=
 4
, padding=
 'valid'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 256
, kernel_size=
 5
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 384
, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            tf.keras.layers.Dropout(
 0.5
), 
            nin_block(num_classes, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.GlobalAvgPool2D(),  
            tf.keras.layers.Flatten()])  
model = NiN()  
X = tf.random.normal((
 1
, 
224
, 
224
, 
1
)) 
for
 layer 
 in
 model.net.layers:  
    X = layer(X)  
    
print
(layer.
__class__
 .
__name__
 ,
'output shape:
 \t
'
, X.shape)  
Sequential output shape:     (
 1
, 
54
, 
54
, 
96
) 
MaxPooling2D output shape:   (
 1
, 
26
, 
26
, 
96
) 
Sequential output shape:     (
 1
, 
26
, 
26
, 
256
) 
MaxPooling2D output shape:   (
 1
, 
12
, 
12
, 
256
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
384
) 
MaxPooling2D output shape:   (
 1
, 
5
, 
5
, 
384
) 
Dropout output shape:        (
 1
, 
5
, 
5
, 
384
) 
Sequential output shape:     (
 1
, 
5
, 
5
, 
10
) 
GlobalAveragePooling2D output shape:         (
 1
, 
10
) 
Flatten output shape:        (
 1
, 
10
)
Architettura NiN in Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#19,19,"model = NiN(lr=
 0.05
) 
trainer = d2l.Trainer(max_epochs=
 10
, num_gpus=
 1
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
model.apply_init([
 next
(
iter
(data.get_dataloader(
 True
)))[
0
]], d2l.init_cnn)  
trainer.fit(model, data)  
Training NiN in Keras
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#2,2,"Networks Using Blocks (VGG)
Sebbene 
 AlexNet
  abbia permesso di ottenere buone performance in 
diversi task, non fornisce dei 
 template
  per la realizzazione di nuove 
architetture.  
Il Visual Geometry Group Oxford University ha de
 ﬁ
nito 
l'architettura VGG che consiste in strutture ripetute de
 ﬁ
nite per 
mezzo di istruzioni di loop e subroutines.  
Il 
blocco
  fondamentale della CNN è una sequenza di (i) 
convolutional layer con padding (ii) nonlinearità come la ReLU, (iii) 
pooling layer per ridurre la risoluzione.  
Il problema di questo approccio è che la risoluzione spaziale si 
riduce abbastanza rapidamente. Introduce il limite rigido di 
 log
2
d 
layer convolutivi prima che tutte le dimensioni (
 d
) si esauriscano.  
Per esempio per 
 ImageNet
  non si possono avere più di 8 layer."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#20,20,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁ
ltri negli strati iniziali.  
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#21,21,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identi
 ﬁ
cate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei 
 ﬁ
ltri
. Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo.  
•
Si impiegano 
 ﬁ
ltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function.  
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 ."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#22,22,"CNN: Inception module (GoogleNet)
GoogleNet ha vinto la challenge ImageNet 2015 con una struttura 
che combina le caratteristiche di NiN, blocchi ripetuti, e un mix di 
kernel convolutivi.  
Crea una distinzione tra:  
stem
 (data ingest), primi 2-3 conv layers per estrarre feature a 
basso livello  
body
  (data processing), serie di blocchi convolutivi  
head
  (prediction), per problemi di classi
 ﬁ
cation, segmentation, 
detection, o tracking.  
L'idea è combinare l'output di più conv layer con diverse 
dimensioni in un unico output "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#23,23,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempli
 ﬁ
care i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali.  
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5.  
•
Sperimentalmente si nota come gli inception module sono più 
ef
ﬁ
cienti se usati negli layer più a valle.
Inception module
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#24,24,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri.  
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#25,25,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classi
 ﬁ
cazione 
 per mezzo di una softmax.  
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer.  
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati.  
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più ef
 ﬁ
ciente il training e migliorare l’accuracy.
auxiliary classi ﬁerauxiliary classi ﬁer"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#26,26,"GoogLeNet: esempio di 
 ﬁ
ltri
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#27,27,"Inception e Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
Inception
 (tf.keras.Model):  
    
# `c1`--`c4` sono il numero di canali in output per ogni ramo  
    
 def 
__init__
 (
self
, c1, c2, c3, c4):  
        
 super
().
__init__
 () 
        
 self
.b1_1 = tf.keras.layers.Conv2D(c1, 
 1
, activation=
 'relu'
) 
        
 self
.b2_1 = tf.keras.layers.Conv2D(c2[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b2_2 = tf.keras.layers.Conv2D(c2[
 1
], 
3
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b3_1 = tf.keras.layers.Conv2D(c3[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b3_2 = tf.keras.layers.Conv2D(c3[
 1
], 
5
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b4_1 = tf.keras.layers.MaxPool2D(
 3
, 
1
, padding=
 'same'
) 
        
 self
.b4_2 = tf.keras.layers.Conv2D(c4, 
 1
, activation=
 'relu'
) 
    
 def 
call
(
self
, x): 
        b1 = 
 self
.b1_1(x)  
        b2 = 
 self
.b2_2(
self
.b2_1(x))  
        b3 = 
 self
.b3_2(
self
.b3_1(x))  
        b4 = 
 self
.b4_2(
self
.b4_1(x))  
        
 return
 tf.keras.layers.Concatenate()([b1, b2, b3, b4])"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#28,28,"GoogleNet e Keras
Uno stack di 9 blocchi 
 inception, 
 organizzati in 3 gruppi 
intramezzati da max-pooling per ridurre le dimensioni, e un global 
average pooling per generare l'ultimo output prima del FC layer.
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#29,29,"GoogleNet e Keras
class 
GoogleNet
 (d2l.Classifier):  
    
 def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, 
7
, strides=
 2
, padding=
 'same'
, 
                                   activation=
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b2
(
self
): 
    
 return
 tf.keras.Sequential([  
        tf.keras.layers.Conv2D(
 64
, 
1
, activation=
 'relu'
), 
        tf.keras.layers.Conv2D(
 192
, 
3
, padding=
 'same'
, activation=
 'relu'
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b3
(
self
): 
    
 return
 tf.keras.models.Sequential([  
        Inception(
 64
, (
96
, 
128
), (
16
, 
32
), 
32
), 
        Inception(
 128
, (
128
, 
192
), (
32
, 
96
), 
64
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#3,3,"VGG Blocks
L'idea è di impiegare convoluzioni multiple e distinte tra periodici 
downsampling (eg. max-pooling) sotto forma di unico blocco 
funzionale.  
L'ipotesi che 
 diverse dimensioni di convoluzioni (deep e wide) 
possono meglio rappresentare le features signi
 ﬁ
cative
 .  
Per esempio 3x3 convolutions interessa gli stessi pixel della 5x5 
convolutions. Ma l'ultima usa un numero di parametri (
 25•c
2
) come 
tre 3x3 convolutions (
 3•9•c
2
), cioè uno 
 stacking
  di convoluzioni 
3x3. Dimostrano che tali con
 ﬁ
gurazioni (deep & narrow) ottengono 
prestazioni migliori.  
La dimensione della rete con stacking 3x3 può oltrepassare i 100 
layers, un approccio molto comune nelle moderne architetture."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#30,30,"GoogleNet e Keras
@d2l
.add_to_class(GoogleNet)  
def 
b4
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 192
, (
96
, 
208
), (
16
, 
48
), 
64
), 
        Inception(
 160
, (
112
, 
224
), (
24
, 
64
), 
64
), 
        Inception(
 128
, (
128
, 
256
), (
24
, 
64
), 
64
), 
        Inception(
 112
, (
144
, 
288
), (
32
, 
64
), 
64
), 
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b5
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        Inception(
 384
, (
192
, 
384
), (
48
, 
128
), 
128
), 
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Flatten()])  
@d2l
.add_to_class(GoogleNet)  
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
    
super
(GoogleNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.Sequential([  
        
 self
.b1(), 
self
.b2(), 
self
.b3(), 
self
.b4(), 
self
.b5(), 
        tf.keras.layers.Dense(num_classes)])  "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#31,31,"GoogleNet e Keras
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = GoogleNet(lr=
 0.01
) 
    trainer.fit(model, data)  
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#32,32,"GoogleNet - vantaggi
GoogleNet richiede meno potenza di calcolo rispetto alle 
architetture precedenti mantenendo una precisione più elevata.  
L'approccio è basato sulla approssimazione dell'architettura senza 
andare a scapito delle prestazioni.  
Introduce un 
 design by block
 , con iperparametri più ""ad alto livello""."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#33,33,"Architetture AlexNet, VGG, NiN, GoogleNet
Esercizio
 : valuta la differenza di prestazioni e i tempi di 
addestramento su medesimi dataset (FashionMNIST) o subset di 
dataset più complessi (ImageNet)."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#34,34,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza.  
35
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#35,35,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Scarica alcune immagini di animali, ad esempio usando la funzion 
matplotlib.image.mpimg.imread(). Ridimensionali e fai crop 299x299 pixel, 
con 3 canali RGB.  
•
Scarica i modelli pre-addestrati di Inception v3  
•
https://github.com/tensor
 ﬂ
ow/models/tree/master/research/slim  
•
Crea il modello Inception v3 usando la funzione inception_v3() con 
is_training=False, num_classes=1001 nel seguente modo:  
from 
 tensor
 ﬂ
ow.contrib.slim.nets 
 import 
 inceptio
 n
import 
 tensor
 ﬂ
ow.contrib.slim 
 as 
sli
m
X 
= 
tf
.
placeholder
 (
tf
.
ﬂ
oat32
 , 
shape
 =[
None
 , 
299
, 
299
, 
3
]
)
with 
slim
.
arg_scope
 (
inception
 .
inception_v3_arg_scope
 ())
:
logits
 , 
end_points 
 = 
inception
 .
inception_v3
 (
X
, 
num_classes
 =
1001
 , 
is_training
 =
False
 )
predictions 
 = 
end_points
 [
""Predictions""
 ]
saver 
 = 
tf
.
train
.
Saver
 (
)
•
...
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#36,36,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
... Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Crea una sessione e usa Saver per recuperare il modello pre-addestrato.  
•
Lancia il modello per addestrare le immagini che hai scaricato visualizzando 
le top-5 predictions e la relativa probabilità.  
•
I nomi delle categorie le trovi qui: 
 https://github.com/ageron/handson-ml/
blob/master/datasets/inception/imagenet_class_names.txt  
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#4,4,"VGG Blocks in Keras
Un funzione che prende come parametri il numero di layer 
convolutivi e il numero di channel di output  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2l
def 
vgg_block
 (num_convs, num_channels):  
    blk = tf.keras.models.Sequential()  
    
 for
 _ 
in 
range
(num_convs):  
        blk.add(  
            tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                   padding=
 'same'
, activation=
 'relu'
)) 
    blk.add(tf.keras.layers.MaxPool2D(pool_size=
 2
, strides=
 2
)) 
    
 return
 blk"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#5,5,"L'architettura VGG e AlexNet a confronto, con i blocchi funzionali 
che si ripetono:
VGG Network e AlexNet
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#6,6,"L'aspetto distintivo sono i layer convolutivi,raggruppati in 
trasformazioni non lineari che medesima dimensione per gruppo.  
Si impiegano 
 ﬁ
ltri 
3x3
 con zero padding in modo da scorrere 
l'intera l'immagine.  
Successivamente c'è lo step di riduzione della risoluzione (2x2 
pooling)  
Al termine ci sono layer FC  
Nota: 100M di parametri nei FC in confronto dei 40M degli strati 
convolutivi
VGG Network"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#7,7,"VGG Network - Dettaglio parametri
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#8,8,"La prima parte della rete VGG è una successione di blocchi VGG.  
La conv_arch consiste in una lista di tuple (una per blocco), ognuna 
che contiene 2 valori: il numero di conv layers e il numero di 
canali.  
class 
VGG
(d2l.Classifier):  
    
 def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential()  
        
 for
 (num_convs, num_channels) 
 in
 arch: 
            
 self
.net.add(vgg_block(num_convs, num_channels))  
        
 self
.net.add(  
            tf.keras.models.Sequential([  
            tf.keras.layers.Flatten(),  
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(num_classes)]))  
VGG Network e Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#9,9,"La VGG originale chiamata 
 VGG-11
  ha 5 blocchi: i primi 2 con un 
conv layer ognuno, e gli 3 con 2 conv layer ognuno. Il 1o blocco ha 
64 canali, e i successivi raddoppiato i canali, 
 ﬁ
no a 512.  
VGG(arch=((
 1
, 
64
), (
1
, 
128
), (
2
, 
256
), (
2
, 
512
), (
2
, 
512
))).layer_summary(  
    (
1
, 
224
, 
224
, 
1
)) 
Sequential output shape:     (
 1
, 
112
, 
112
, 
64
) 
Sequential output shape:     (
 1
, 
56
, 
56
, 
128
) 
Sequential output shape:     (
 1
, 
28
, 
28
, 
256
) 
Sequential output shape:     (
 1
, 
14
, 
14
, 
512
) 
Sequential output shape:     (
 1
, 
7
, 
7
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
La dimensione 
 ﬁ
nale dopo la sequenza dei blocchi è 7x7, seguita 
dal 
ﬂ
attening e il successivo processamento FC.
VGG Network e Keras"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
5a parte - Batch Normalization e ResNet
1"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#1,1,"Sommario
Internal covariate shift  
Batch normalization  
Architettura Residual Network (ResNet)"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#10,10,"Batch Normalization layer
Poiché la BN dipende dalla dimensione del mini batch, e perciò dai dati di 
training, non possiamo ignorarla quando de
 ﬁ
niamo la nostra architettura.  
Per reti FC si può applicare la BN tra la trasformazione lineare e il calcolo 
della funzione di attivazione.  
Per conv layers l'approccio è simile, ma consideriamo la BN per ogni 
singolo canale, valutandola sui i dati sparsi spazialmente. Perciò ogni canale 
avrà una stima diversa di media e deviazione standard.  
Questo è in linea col principio di 
 invarianza spaziale
 , cioè nel calcolo 
possiamo ignorare l'informazione relativa alla posizione.
11"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#11,11,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci:
12"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#12,12,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).
13"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#13,13,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 .
14"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#14,14,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 . 
•
Richiamo: Introduce una certa 
 regolarizzazione 
 dei parametri, sebbene non 
sostituisce le tecniche più ef
 ﬁ
caci (es. dropout)  
•
Richiamo: Permette l'uso di 
 learning rate più elevati
 , riducendo i tempi di 
apprendimento.  
•
Es. Per un tipico task di image classi
 ﬁ
cation, si ottengono incrementi x14.
15"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#15,15,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?
16"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#16,16,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?  
Se impieghiamo funzioni di attivazioni logistiche, 
 forziamo al rete a 
lavorare in regime di quasi-linearità
 , riducendo la capacità di costruire 
relazioni input-output non lineari.
17"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#17,17,"Batch Normalization e LeNet - Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
BNLeNet
(d2l.Classifier):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(filters=
 6
, kernel_size=
 5
, 
                                   input_shape=(
 28
, 
28
, 
1
)), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Conv2D(filters=
 16
, kernel_size=
 5
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Flatten(), tf.keras.layers.Dense(
 120
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(
 84
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(num_classes)])  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
) 
with
 d2l.try_gpu():  
    model = BNLeNet(lr=
 0.5
) 
    trainer.fit(model, data)
18
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#18,18,"Architettura Residual Network - Motivazioni
In generale, architetture di reti complesse (es. più profonde) possono stimare 
una classe più ampia di funzioni. Ma se aggiungiamo layer, nessuno ci 
garantisce che l'apprendimento ci permette di trovarle, anzi in taluni casi 
possiamo allontanarci dall'ottimo.  
Inoltre reti profonde potrebbero soffrire del vanishing gradient problem.  
Ma se aggiungiamo layer che mirano a stimare una funzione identità, i.e., 
f(x)=x, sicuramente manteniamo la stessa ef
 ﬁ
cacia della rete iniziale.  
L'ipotesi è che, i layer che aggiungiamo alla rete dovrebbero avere più 
probabilità nel rappresentare funzioni identità per garantire prestazioni ottimali."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#19,19,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers.  
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice e veloce propagare segnali 
 su varie parti 
della rete.  
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#2,2,"Motivazioni
L'addestramento delle architetture Deep mostra alcune problematiche 
aggiuntive oltre quelle già discusse per le MLP. Una signi
 ﬁ
cativa è il tempo 
necessario per addestrarle.  
Spesso si operano 
 standardizzazioni
  nei valori delle features in ingresso con 
forme di pre-processamento, es:  
imporre µ=0 (zero mean) o la unit-variance (cioè dividere per la stddev)  
zero mean
  sul valore delle features, considerando la singola istanza; spesso 
utile per dati con informazioni spaziali.  
Ci garantisce che durante l'addestramento i valori dei parametri rimangano in 
intervalli ottimali, sia considerando i layer per l'intera profondità della rete, sia 
tra i nodi di un singolo layer, sia tra i valori di ogni parametro per la durata 
dell'addestramento."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#20,20,"ResNet: Residual learning e residual block
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning o mapping
 . 
Dal punto di vista operativo, è suf
 ﬁ
ciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#21,21,"Architettura ResNet
L'architettura ResNet impiega conv layer 3x3 (simili a VGG).  
Ogni blocco ResNet ha due 3x3 conv layer seguite dalla batch normalization e 
attivazione ReLU. Prima dell'ultima ReLU sommiamo l'input dalla skip 
connection.  
La 1x1 conv layer è necessaria per adattare i canali dell'input con quelli 
ottenuti a valle del blocco.
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#22,22,"Blocco ResNet e Keras
class 
Residual
 (tf.keras.Model):  
    
def 
__init__
 (
self
, num_channels, use_1x1conv=
 False
, strides=
 1
): 
        
 super
().
__init__
 () 
        
 self
.conv1 = tf.keras.layers.Conv2D(num_channels, padding=
 'same'
, 
                                            kernel_size=
 3
, strides=strides)  
        
 self
.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                            padding=
 'same'
) 
        
 self
.conv3 = 
 None 
# dipende se vogliamo usare o meno il 1x1 conv layer  
        
 if
 use_1x1conv:  
            
 self
.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 1
, 
                                                strides=strides)  
        
 self
.bn1 = tf.keras.layers.BatchNormalization()  
        
 self
.bn2 = tf.keras.layers.BatchNormalization()  
    
def 
call
(
self
, X): 
        Y = tf.keras.activations.relu(
 self
.bn1(
self
.conv1(X)))  
        Y = 
 self
.bn2(
self
.conv2(Y))  
        
 if 
self
.conv3 
is 
not 
None
: 
            X = 
 self
.conv3(X)  
        Y += X  
        
 return
 tf.keras.activations.relu(Y)  
blk = Residual(
 3
) 
X = tf.random.normal((
 4
, 
6
, 
6
, 
3
)) 
Y = blk(X)  
Y.shape 
TensorShape([
 4
, 
6
, 
6
, 
3
]) "
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#23,23,"Architettura ResNet-18
I primi layer di ResNet sono simili a GoogleNet, ma in ResNet si usa la Batch 
normalization.  
Seguono vari moduli ripetuti ResNet. La ResNet-18 include 18 layer totali, ma 
si hanno modelli addestrati con molti più layer, es. ResNet-152.
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#24,24,"Architettura ResNet e Keras
class 
ResNet
(d2l.Classifier):  
    
def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, kernel_size=
 7
, strides=
 2
, 
                                   padding=
 'same'
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(ResNet)  
def 
block
(
self
, num_residuals, num_channels, first_block=
 False
): 
    blk = tf.keras.models.Sequential()  
    
for
 i 
in 
range
(num_residuals):  
        
 if
 i == 
0 
and 
not
 first_block:  
            blk.add(Residual(num_channels, use_1x1conv=
 True
, strides=
 2
)) 
        
 else
: 
            blk.add(Residual(num_channels))  
    
return
 blk 
@d2l
.add_to_class(ResNet)  
def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
    
super
(ResNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.models.Sequential(
 self
.b1()) 
    
for
 i, b 
in 
enumerate
 (arch): 
        
 self
.net.add(
 self
.block(*b, first_block=(i==
 0
))) 
    
self
.net.add(tf.keras.models.Sequential([  
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Dense(units=num_classes)]))  "
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#25,25,"Architettura ResNet e Keras
class 
ResNet18
 (ResNet):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 (((
2
, 
64
), (
2
, 
128
), (
2
, 
256
), (
2
, 
512
)), 
                       lr, num_classes)  
ResNet18().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
128
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
256
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = ResNet18(lr=
 0.01
) 
    trainer.fit(model, data)  
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#26,26,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?
27"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#27,27,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.
28"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#28,28,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.
29"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#29,29,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.  
•
ResNet
  introduce le skip connections, che permettono un numero di layer 
oltre i 100. Anche la relativa semplicità la contraddistingue. 
30"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#3,3,"Motivazioni
Inoltre un layer che produce valori di attivazione molto elevati rispetto agli altri 
(es. x100) richiede aggiustamenti (es. modi
 ﬁ
cando il learning rate in modo 
adattivo per produrre variazioni più ef
 ﬁ
caci durante il training).  
In
ﬁ
ne, per affrontare l'over
 ﬁ
tting è spesso utile introdurre 
 regolarizzazioni
  sul 
valore dei parametri (es. aggiungendo del rumore)."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#30,30,"Esercizio su CNN e MNIST
Prova costruire una tua architettura CNN (cioè con uno o più convolution 
layers, pooling layers, etc) per raggiungere la migliore accuratezza per i 
dataset MNIST.  
•
MNIST dataset: 
 http://yann.lecun.com/exdb/mnist/   
•
MNIST e Tensor
 ﬂ
ow: 
https://www.tensor
 ﬂ
ow.org/quantum/tutorials/mnist  
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#4,4,"Internal covariate shift
Con 
Internal covariate shift
  si indica la circostanza in cui 
 la distribuzione 
dei valori di attivazione nella rete cambia a causa della variazione dei 
parametri durante il training
 .  
•
Fenomeno fondamentale nelle architetture deep (con molti layers).  
•
E' chiaro che i parametri in
 ﬂ
uenzano le attivazioni, ma 
 la distribuzione 
dei valori 
 non dovrebbe alterarsi a causa dei parametri.  
•
Il vanishing/exploding gradient ricade in questa circostanza.  
•
ReLU, e le sue varianti, riducono il fenomeno ma non lo escludono.  
L'obiettivo è ridurre il 
 covariance shift
  all'interno della reti.
5"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#5,5,"Batch Normalization
La 
batch normalization
  (
BN
) è una tecnica per affrontare tale problema. 
Prima della funzione di attivazione di ogni layer:  
•
Normalizza gli input
 , centrandoli in 0 e dividendoli per la deviazione 
standard 
 σ
. 
•
Introduce 
 2 parametri
 , uno per determinare la 
 scalatura
  e uno per lo 
 shift
. 
Tali parametri saranno soggetti ad addestramento.  
Dopo la normalizzazione 
 la rete apprende il valore medio e la scala più 
giusta degli input per ogni layer
 . 
•
La normalizzazione è frequente nei dati in ingresso degli approcci basati su 
ML. La tecnica proposta estende tale tecnica ad ogni layer della rete.  
Per normalizzare bisogna prima conoscere valor medio e varianza dei dati. 
Si stimano entrambi 
 impiegando 
 mini-batch,  
cioè un piccolo sottoinsieme 
del training set. Da questo il termine 
 batch normalization
 .
6"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#6,6,"Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
7
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#7,7,"Batch Normalization - Considerazioni
La tecnica BN può essere impiegata sui singoli layer, soprattutto sugli 
hidden, oppure all'intera rete.  
La stima di media e deviazione standard sono ricavate sul mini batch 
corrente.  
Possiamo interpretare i parametri 
 scale
  e 
offset
  stimati durante 
l'apprendimento come un mezzo per ""recuperare"" i gradi di libertà persi a 
causa della normalizzazione e limitarsi a considerare mini-batch invece 
dell'intero dataset.  
Con mini-batch di dimensione adeguata (un iperparametro da de
 ﬁ
nire) si 
raggiungono buoni incrementi di prestazioni e una 
 stabilità
  nell'andamento. 
Ma richiede un tuning che dipende dai dati impiegati.  
La tecnica non permette al valore dei parametri di divergere. Inoltre permette 
di incrementare il 
 learning rate
 . 
8"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#8,8,"Batch Normalization - Considerazioni (2)
Può sembrare illogico introdurre approssimazioni nei valori di media e 
deviazione standard, ma nella pratica rappresentano una sorta di rumore 
introdotto arti
 ﬁ
cialmente che garantisce tempi più rapidi e minor effetto 
over
ﬁ
tting.  
Valori spesso ottimali della dimensione del mini batch sono 50-100 istanze, 
che garantiscono la giusta 
 quantità di rumore
  introdotto durante 
l'apprendimento.
9"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#9,9,"Batch Normalization - Considerazioni (3)
In casi particolari 
 γ
 e 
β
 possono assumere valori tali da ""invertire"" il processo 
di normalizzazione degli input del processo di 
 batch normalization
 , se 
questo garantisce l'ottimalità durante il training.  
La BN può essere vista come una 
 trasformazione lineare
 , perciò facilmente 
differenziabile
  durante il calcolo dei gradienti.  
La normalizzazione basata su mini-batch è essenziale per garantire 
l'ef
ﬁ
cienza di tale tecnica, ma è inutile nel test e in produzione.  
In 
produzione
  vogliamo una rete che renda l'output dipendente 
unicamente e deterministicamente dall'input
 , perciò non in
 ﬂ
uenzata 
dallo speci
 ﬁ
co mini-batch.  
Per tale motivo la normalizzazione sarà calcolata sull'intera popolazione 
 {x} 
con valori di media e varianza costanti durante l'elaborazione:
10
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep
1"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#1,1,"Sommario
Motivazioni dell'apprendimento speci
 ﬁ
co per reti Deep  
Vanishing/Exploding gradients  
La funzione di attivazione softmax  
Inizializzazione dei parametri  
Funzione di attivazione ReLU e variazioni  
Batch normalization  
Gradient clipping  
Reusing Pretrained layers - Transfer learning  
Unsupervised Pretraining  
Pretraining su Auxiliary tasks"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#10,10,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
11"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#11,11,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
12"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#12,12,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
13"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#13,13,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
14"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#14,14,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
15"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#15,15,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
16"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#16,16,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
17"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#17,17,"Altre inizializzazioni
Ricerche più recenti adattano la suddetta inizializzazione considerando 
diversi scenari di funzione attivazione
 , dove si distinguono per ogni layer il 
numero di connessioni in input (
 n
inputs
) e in output (
 n
outputs
 ). 
Riferimenti:  
•
He et al. 
 Delving Deep into Recti
 ﬁ
ers: Surpassing Human-Level Performance on ImageNet Classi
 ﬁ
cation
  2015
18
Hu initialization →"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#18,18,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?
19"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#19,19,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.
20"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo visto architetture di Reti neurali (
 NN
) con più strati (
 layer
 ), ognuno 
composto da molti nodi completamente connessi con i layer precedenti e 
successivi (
 fully connected
 ). 
L'addestramento (training) di tali architetture mostra le seguenti 
problematiche:  
•
Vanishing gradients
  o 
Exploding gradients
 : che rendono la ricerca dei 
parametri molto dif
 ﬁ
cile 
•
Lentezza
 : la stima di molti parametri richiede molto tempo  
•
Over
 ﬁ
tting
: la presenza di molti parametri aumenta la possibilità di 
over
ﬁ
tting (cioè mancanza di generalizzazione).  
Per tale motivo introduciamo
  tecniche di addestramento speci
 ﬁ
che
 per 
affrontarle, che permettono di de
 ﬁ
nire architetture NN più complesse e 
deep
 .
3"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#20,20,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.  
2.
Per 
valori prossimi allo 0 la logistic function si comporta in modo 
lineare
 .  
•
Tale comportamento ci preclude l'addestramento di funzioni complesse e non 
lineari, anche in presenza di più layer.
21"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#21,21,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?
22"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#22,22,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?  
1.
Avere 
 una rete inizializzata con gli stessi valori implica avere stessi 
gradienti e stessi aggiornamenti per ogni nodo di un layer
 .  
•
Uno degli obiettivi della inizializzazione dei parametri è 
 rompere eventuali 
simmetrie
  nel comportamento della rete.  
•
La simmetria 
 non permette di specializzare diversi neuroni su diversi scopi
 .  
•
Un layer con tutti nodi con lo stesso peso è equivalente ad un layer con un 
singolo nodo.  
•
La 
backpropagation  
non è in grado di risolvere in modo adeguato questo tipo 
di simmetrie
 .
23"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#23,23,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?
24"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#24,24,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?  
•
È possibile inizializzare i 
 bias
 a 0, oppure seguire il procedimento di 
inizializzazione usato per i pesi 
 w
.
25"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#25,25,"Inizializzazione dei pesi e softmax
La 
softmax
  è spesso usata nella classi
 ﬁ
cazione multi label.  
Tende a dare 
 molta più probabilità
  alle classi associate ai nodi che hanno in 
output 
 attivazione superiori agli altri,
  soprattutto se l'intervallo dei valori 
delle attivazioni è esteso.  
Si cerca di ridurre questo intervallo (ad esempio con vincoli sulla varianza) 
per alleviare questo comportamento ""
 opinionated
 "", soprattutto nelle prime 
fasi di training.  
•
L'inizializzazione dei pesi è fondamentale.  
•
Si garantisce una esplorazione più ampia dello spazio di ricerca.
26
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#26,26,"Nonsaturing activation functions
La 
logistic function
  è molto popolare, ed è in parte ispirata al 
comportamento di un neurone 
 ﬁ
sico.  
Ma nelle architetture 
 deep
  è più conosciuta la:  
Recti
 ﬁ
ed Linear Function  
ReLU :  
f(x)=max(0,x)  
Fino a pochi anni fa la più popolare nelle architetture deep.
27
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#27,27,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:
28"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#28,28,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
 .
29"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#29,29,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 .
30"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#3,3,"Vanishing/Exploding gradients
L'
algoritmo di backpropagation
  usato per addestrare una NN segue questi passi:  
•
Per ogni coppia input-output si valuta l'errore tra output ottenuto dalla NN e 
output atteso mediante la 
 loss function 
 (o 
cost function
 ). 
•
Si calcola il 
 gradiente
 , cioè l'insieme delle derivate parziali dell'errore rispetto 
ai parametri (pesi), mediante la 
 chain rule
 . 
•
In base a tali valori si aggiornano i pesi in modo da ridurre l'errore, ad esempio 
mediante il 
 gradient descent.  
Impiegando i gradienti per addestrare la rete può capitare di ottenere valori 
molto piccoli (
 vanishing gradients
 ), soprattutto per i layer vicini all'input.  
•
Il gradiente nei primi strati si ottiene come 
 prodotto
  dei gradienti degli strati più 
lontani.  
•
Questo implica che nei primi layer i pesi non vengono pressoché alterati 
durante il training 
 e dif
ﬁ
cilmente si converge ad una soluzione
 .
4"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#30,30,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.
31"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#31,31,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 :
32"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#32,32,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
33"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#33,33,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
34"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#34,34,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
•
L'intervallo dell'output è 
 [
0,
∞
]
35"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#35,35,"Leaky ReLU
Per risolvere il problema
  dying ReLUs
  si introduce la 
 Leaky ReLU 
 o 
LReLU:  
                               
dove 
 α
 è un 
 iperparametro
  (es. 
0.01
) che garantisce un valore diverso da 
 0 
per 
x < 0
 . 
f
(
x
)
=
m
a
x
(
α
⋅
x
,
x
)
36
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#36,36,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU):  
α
 viene impostato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
37"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#37,37,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
38"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#38,38,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU)
 :     
•
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 Producendo valori <0, la media 
degli output di un layer è più vicina allo 0 rispetto a quella della ReLU, e si riduce il 
vanishing problem.  
•
Non ha singolarità nello 0
 , cioè è sempre derivabile.  
•
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un 
 tasso di 
convergenza più veloce 
 della ReLU.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
39
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#39,39,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?
40"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#4,4,"Vanishing/Exploding gradients
In modo simile i 
 gradienti possono aumentare 
 e in alcuni layer il valore può 
eccedere gli intervalli rappresentabili nei framework di NN (
 exploding 
gradients
 ). 
•
Fenomeno che capita spesso nelle 
 Recurrent NN
  che studieremo più avanti  
Più in generale, 
 strati diversi della rete possono aggiornarsi con 
""velocità"" 
 (cioè valori di gradienti)
  molto diverse
 . 
Tali problemi sono ancora più evidenti 
 con funzioni di attivazione con 
valore medio <> 0
 , e 
inizializzazione dei pesi casuale 
 con distribuzione 
gaussiana
 . 
•
Ad esempio, nel caso della 
 logistic 
 (o
 sigmoid
 )
 function
 , per valori in input 
grandi in modulo, la funzioni 
 satura a 0 o 1
 , con 
 derivate
  tendenti allo 
 0
. 
Si ha perciò 
 vanishing gradients
 . 
5"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#40,40,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
41"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#41,41,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
42"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#42,42,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
43"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#43,43,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
44"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#44,44,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
45"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#45,45,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
46"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#46,46,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
7.
La 
softmax
  è adatta per ottenere distribuzioni di probabilità su classi 
mutuamente esclusive.
47"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#47,47,"Gradient clipping
Una tecnica molto facile per ridurre il fenomeno del 
 exploding gradients
  è 
introdurre 
 una soglia per limitare il valore dei gradienti
  durante il 
backpropagation, chiamata 
 gradient clipping
 . 
Chiaramente ponendo valori soglia rischiamo di ridurre l'informazione che 
tali parametri possono propagare.  
La rivedremo tra poco ma nel dominio della regolarizzazione dei parametri 
W
.
48"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#48,48,"Reusing pretrained layers
Addestrare un rete deep complessa 
 richiede molte risorse
 , a volte 
impossibili da avere, ad eccezione di pochi laboratori al mondo.  
Il 
transfer learning
  è l'approccio che ha l'obiettivo di
  ri-utilizzare parametri 
ottenuti da architetture già addestrate 
 su obiettivi simili.  
Ha il duplice vantaggio di ridurre:  
•
il 
tempo di addestramento,  
•
la 
dimensione del training set
  relativo all'obiettivo di interesse.  
Ad esempio, una rete è addestrata a riconoscere animali, piante, automobili, 
etc., mentre siamo interessati a distinguere il modello di certe auto.  
•
Conviene riutilizzare i parametri che permettono di rappresentare speci
 ﬁ
che 
features della classe auto (es. forme di fanali e paraurti) e sfruttarli per 
adattare la rete alle nuove classi.
49"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#49,49,"Esempio di complessità della architettura GPT-3
Generative Pre-trained Transformer 3
  (
GPT-3
 ) è un architettura deep creata 
da 
OpenAI
  per ottenere modelli (transformer) di linguaggio naturale.  
Apparsa nel 2020 come evoluzione delle versioni v2 e v1, è popolare 
per la capacità di redigere testo (es. news) simili a quelle scritte da 
persone umane. E' suf
 ﬁ
ciente dare poche parole per farla partire.  
Contiene 175 miliardi di parametri.  
Addestrata su quasi 500 miliardi di parole estratte da varie fonti 
(CommonCrawl, WebText2, Books, Wikipedia)  
Con una GPU cloud Tesla V100 richiederebbe $4.6M e 355 anni per 
l'addestramento.  
Esempi di applicazione: 
 https://beta.openai.com/examples/  
50"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#5,5,"Logistic (sigmoid) function
6
Saturazione  
(risposta max)  
gradiente basso
Saturazione  
(risposta max )
gradiente basso Quasi-lineare 
derivata costante 
cioè indipendente dagli input
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#50,50,"Reusing pretrained layers
Nelle architetture deep i 
 layer rappresentano features 
 rilevanti per la 
classi
 ﬁ
cazione 
 con diversi livelli di 
 astrazione
 . Ad esempio nel task della 
classi
 ﬁ
cazione delle immagini:  
•
I 
primi layer
  (vicini all'input) si specializzano su  
features di base
 , come 
line, angoli, variazioni cromatiche  
•
I 
layer più vicini all'output
  legano le feature precedenti per rappresentare 
oggetti complessi e relative 
 caratteristiche salienti
  (es. il muso e le orecchie 
di un animale).  
Il transfer learning 
 mira a riutilizzare i parametri (e il tipo di feature) più 
importanti.  
•
I pesi che si riusano si possono 
 congelare, 
 e focalizzare l'addestramento 
solo sui nuovi parametri che dipendono dal nuovo task.  
•
Si sempli
 ﬁ
ca l'addestramento poiché alcuni parametri non si alterano. 
51"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#51,51,"Transfer learning - procedimento
Gli output layers della rete iniziale spesso si scartano perché tipicamente 
non riadattabili al nuovo task, cioè non rappresentano le feature signi
 ﬁ
cative 
per il nuovo task e ai nuovi output di interesse.  
Il 
procedimento
  generale del 
 transfer learning
  è il seguente:  
1.
Si tenta di 
 riutilizzare tutti i parametri della vecchia rete
  e si valutano le 
performance.  
2.
Si 
""scongelano"" gli ultimi 1 o 2 layer
  e si permette il loro addestramento, 
valutando miglioramenti.  
3.
In caso il training set sia limitato, 
 si scartano gli ultimi layer,
  e si 
congelano i restanti. Si valutano le performance.  
4.
Se si hanno suf
 ﬁ
cienti dati, i
  layer scartati si rimpiazzano con nuovi 
layer
 , eventualmente aumentano la profondità della rete rispetto a quella 
di partenza.
52"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#52,52,"Reusing pretrained layers
Nota: 
 Il transfer learning è adatto quando le istanze in input hanno feature a basso livello  
(es. numero di pixel di una immagine) simili a quelle delle istanze in input alla nuova rete.
53
Parametri da addestrare,  
parzialmente riutilizzati
Parametri ﬁssi ottenuti  
dalla rete già addestrata.
Rete già addestrata  
per un certo task.Rete da addestrare  
per un task simile.CongelatiNon congelati
}}"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#53,53,"Transfer learning
Dove posso trovare parametri già addestrati?
54"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#54,54,"Transfer learning
Dove posso trovare parametri già addestrati?  
Sui repository dei framework di DL, o su blog specializzati, si trovano 
elenchi aggiornati di modelli per diversi task, es:  
•
https://github.com/tensor
 ﬂ
ow/models  
•
https://pytorch.org/docs/stable/torchvision/models.html   
I modelli fanno riferimento ad architetture DL conosciute in letteratura  
•
Es. AlexNet, VGG, ResNet, SqueezeNet, DenseNet, Inception v3, GoogLeNet, 
Shuf
ﬂ
eNet v2, MobileNet v2, ResNeXt, Wide ResNet, MNASNet
55"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#55,55,"Unsupervised Pretraining
Può capitare di lavorare su un task dove abbiamo 
 un training set di istanze 
labelled
  ridotto
 , e non esistono modelli pre-addestrati da impiegare.  
Nel 
unsupervised pretraining
  la rete viene addestrata 
 uno strato alla volta
 , 
partendo da quello più vicino agli input.  
•
Ogni layer è addestrato impiegando l'output del layer precedente, quindi in 
modo 
 unsupervised
 . 
•
Tutti i layer sono congelati, tranne quello sotto addestramento.  
•
Quando tutti i layer sono stati addestrati, la rete può essere addestrata con 
un approccio 
 ﬁ
ne-tuned 
 supervised
 .  
•
Tipicamente (1) si aggiunge un ultimo layer, (2) si congelano i pesi dei 
layer precedenti, e (3) si considera il training set disponibile.
56"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#56,56,"Unsupervised Pretraining
La fase di unsupervised permette di creare 
 una approssimazione dei 
parametri (o inizializzazione) 
 utile per la fase di addestramento reale.  
Ipotesi sostengono che tale fase individua il sottoinsieme di 
 minimi
  più 
probabili nello spazio di ricerca.  
È un approccio piuttosto lungo da completare, ma è stato impiegato di 
frequente 
 ﬁ
no alla comparsa delle prime tecniche che hanno affrontato il 
vanishing gradients
  problem. 
57"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#57,57,"Unsupervised Pretraining - considerazioni
Ricordiamoci che in una architettura deep è facile ricavare valori di errore 
sugli strati 
 ﬁ
nali, vicini all'output atteso. Ma a causa del vanishing problem, 
 i 
primi strati potrebbero non avere suf
 ﬁ
ciente informazione per il relativo 
addestramento
 . 
L'approccio iterativo del 
 unsupervised pretraining  
addestra 
 uno strato alla 
volta
 , mantenendo costanti gli altri parametri, perciò senza la possibilità che 
possano in
 ﬂ
uenzare il training in modo sub-ottimale.  
•
L'addestramento è suddiviso in più fasi, e in ogni fase abbiamo pochi 
parametri da determinare.  
•
L'
output atteso 
 di un layer sotto addestramento 
 corrisponde all'output dello 
strato precedente
  (approccio unsupervised)  
•
In ogni fase si tenta di identi
 ﬁ
care 
 minimi locali 
 utili per la fase 
 ﬁ
nale.  
Con 
pretraining
  si indica in generale 
 il procedimento di addestrare modelli 
sempli
 ﬁ
cati su dati sempli
 ﬁ
cati 
prima di arrivare al modello 
 ﬁ
nale su dati 
complessi.
58"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#58,58,"Unsupervised Pretraining
59
Layer addestratoLayer addestratoLayer addestratoRete addestrata"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#59,59,"Pretraining su auxiliary task
Un modo alternativo per addestrare una rete con scarsi dati di training e 
trovare un 
 auxiliary task
 , cioè un task simile che condivide un insieme di 
feature detectors
  salienti con il task di nostro interesse.  
Ipotesi
 : se riusciamo ad addestrare la rete sul task alternativo, potremmo 
riutilizzare i primi layer dato che si sono specializzati sulle features di 
comune interesse.  
Esempio: 
 face detection  
Tipicamente ci sono
  poche istanze 
 per ogni viso da riconoscere.  
Possiamo andare su Google e collezionare facilmente molti visi di 
celebrity. La rete imparerà a riconoscere le 
 feature salienti
  che potranno 
essere impiegate sul nostro training set.  
Un approccio alternativo è ""corrompere"" un sottoinsieme di istanze 
disponibili di una certa classe per associarle ad una classe negativa.
60"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#6,6,"Vanishing/Exploding gradients
Una possibilità sarebbe 
 comprimere
  i valori delle attivazioni in un intervallo 
ristretto, ma intorno allo 0 la logistic mostra comportamenti prettamente 
lineari, che non permettono di rappresentare funzioni complesse.
7"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#7,7,"Vanishing/Exploding gradients
8
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#8,8,"Vanishing/Exploding gradients problem:  
Cosa succede durante l'addestramento?
Comportamenti tipici in presenza di vanishing gradients problem sono:  
•
Le performance migliorano 
 troppo lentamente
 , o 
non migliorano  
•
Prematura convergenza
  (ma non a valori ottimi)  
•
Analizzando i parametri appresi si notano 
 variazioni più signi
 ﬁ
cative negli 
ultimi strati
 , vicini all'output, 
 rispetto ai primi strati
 .
9"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#9,9,"Inizializzazione di Xavier e He 
L'obiettivo è garantire la propagazione delle attivazioni (forward) e dei 
gradienti (backward) in modo corretto, cioè senza 
 exploding
  e 
vanishing
 . 
Xavier e He
  propongono di mantenere uguali:  
•
i valori della varianza degli output di ogni layer con la varianza degli input 
del layer successivo
  (forward propagation).  
•
le varianze dei gradienti ottenuti prima e dopo un certo layer
  (backward 
propagation)  
Tali condizioni possono essere veri
 ﬁ
cate solo se ogni layer ha lo 
 stesso 
numero di connessioni in entrata e in uscita
 .  
Introducendo una approssimazione de
 ﬁ
niamo la 
 Xavier initialization
  così:
10I pesi della rete sono inizializzati per ogni layer in modo casuale  
con distribuzione gaussiana  con media 0  e varianza pari a n-1, 
dove n il numero di nodi del layer precedente."
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 2: Optimizers, learning rates adattivi
1"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#1,1,"Sommario
Faster Optimizer  
Momentum optimization  
Nesterov Accelerated Gradient  
AdaGrad Algorithm  
RMSProp algorithm  
Adam Optimization  
Learning rate schedule   
Adaptive learning rate algorithms"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#10,10,"Richiami: Gradient descent
•
Alterazioni troppo piccole allungano i tempi di esplorazioni.  
•
Alterazioni troppo grandi (es. learning rate elevati) generare comportamenti 
che possono allontanarci dall'ottimo.
11
Ricerca lenta Ricerca imprecisa"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#11,11,"Gradient descent vs Stochastic vs Minibatch
•
Gradient descent
 : iteriamo sull'intero training set, cioè su tutte le istanze, 
prima di aggiornare i pesi.  
•
Sebbene la stima dell'errore sia molto precisa, per training set grandi 
dobbiamo attendere molto prima di aggiornare i parametri. Gli output 
sono ricavati con i parametri ricavati nel ciclo precedente, senza poterli 
aggiornare durante l'epoca.  
•
Stochastic Gradient descent (SGD)
 : ad ogni istanza estratta dal training set 
(in modo random) aggiorniamo i parametri.  
•
La stima dei gradienti è approssimata su una singola istanza, perciò poco 
precisa. Ma aggiorniamo i parametri istantaneamente. Convergenza più 
rapida, ma meno probabilità di raggiungere l'ottimo.  
•
Minibatch SGD
 : dopo un minibatch di istanze aggiorniamo i pesi.  
•
Si suppone che il minibatch stimi meglio le variazioni dei parametri 
simulando la stima sull'training set. In altre parole, riduce la varianza sui 
valori stimati. Combina i vantaggi di entrambi.
12"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#12,12,"Richiami: (Mini)Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
13
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#13,13,"Gradient vs Stochastic Gradient descent
In condizioni ideali (es. convex function) un gradient descent tradizionale è 
l'approccio ottimale per raggiungere il minimo in poche iterazioni.  
L'approccio stocastico introduce rumore che può rallentare il 
raggiungimento del minimo (es. a dx dopo 50 iterazioni non si hanno ancora 
valori ottimali, a sx dopo 20 iterazioni possiamo fermarci).  
Ma generalmente nel DL non abbiamo 
 convex functions
 .
14
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#14,14,"Gradient descent e learning rate
•
Per rendere la ricerca 
 più ef
 ﬁ
ciente 
 potremmo pensare di 
 variare il learning 
rate 
  durante l'esplorazione:  
•
Aumentandolo ulteriormente al principio
 , per rendere la ricerca più rapida,  
e riducendolo alla 
 ﬁ
ne
, soprattutto nel caso del SGD e minibatch SGD, per 
ridurre gli effetti che il rumore possa avere sulla ricerca dell'ottimo.  
•
Nell'esempio, aumentiamo la velocità durante la discesa della curva, e la 
riduciamo quando la curva riduce la pendenza.
η
15
Costo
Θ"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#15,15,"Momentum optimization
La 
momentum optimization 
 introduce il concetto di 
 accelerazione
  e 
velocità  
durante l'esplorazione.  
Introduco il 
 vettore momentum  
m
, usato per aggiornare i pesi 
 . Il suo compito è 
interpretare il gradiente 
  come una 
 accelerazione,
  che altera la 
 velocità 
corrente
  rappresentata da 
 . 
 
 
 è chiamato 
 parametro momentum
 , o semplicemente 
 momentum
 , e ha lo scopo 
di evitare che la velocità cresca eccessivamente.  
•
=0 resistenza massima (corrisponde al gradient descent), 
 =1 nessuna resistenza.  
Si veri
 ﬁ
ca facilmente che, se il il valore del gradiente rimane costante, la variazione 
massima dei pesi è 
 . 
•
Per 
 =0.9 e 
 =1
, si ottiene 10 volte il valore del gradiente.
Θ
η
∇
Θ
J
(
Θ
)
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
m
β
β
 β
η
1
1
−
β
β
 η
16"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#16,16,"Momentum optimization (2)
Analogia con una biglia su una super
 ﬁ
cie. La direzione non corrisponde più 
a quella determinata dal gradiente calcolato attualmente, ma in base alle 
media pesata di tutti i gradienti precedenti.  
L'approccio rientra nella classi dei 
 accelerated gradient methods
 . 
Ha molteplici 
 vantaggi
 : 
•
Rende più stabile la ricerca quando qualche gradiente risulta scarsamente 
accurato (es. scelta sbagliata della istanza/minibatch), mediando su una serie 
di valori.  
•
Si 
accelera l'esplorazione
  quando stiamo esplorando spazi dei parametri 
ampi, e dove le super
 ﬁ
ci de
 ﬁ
nite dalla funzione di costo variano lentamente.  
•
L'accelerazione permette più facilmente di 
 evitare (o uscire) minimi locali 
rispetto al gradient descent tradizionale
 . 
Il momentum 
  è un 
 iperparametro da stimare
  caso per caso, ma valori 
intorno allo 
 0.9
 sono molto comuni.
β
17"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#17,17,"Momentum optimization
18apprendimento lento
apprendimento veloce
Discesa del gradiente  
con Momentum optimizationDiscesa del gradiente  
tradizionale"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#18,18,"Momentum optimization: esempio
10-momentum.ipynb
19"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#19,19,"Nesterov Accelerated Gradient
Il 
Nesterov Accelerated Gradient
  (
NAG
 ) è una variazione del momentum 
optimization dove il 
 gradiente
  viene valutato non nella posizione corrente 
ma nella direzione del momentum  
 : 
 
 
In genere il vettore momentum indica la direzione verso l'ottimo, perciò 
sembra più logico misurare il gradiente verso quella direzione.  
Queste piccole variazioni si sommano e il NAG si dimostra essere 
 più 
rapido rispetto al momentum optimization
 .
Θ
+
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
+
β
⋅
m
)
Θ
←
Θ
−
m
20"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#2,2,"Gli optimizer
Un 
optimizer
  è un algoritmo usato per alterare i parametri della rete, ed 
eventualmente alcuni iperparametri quali il learning rate, in modo da 
minimizzare la misura di loss.  
Per tale motivo la funzione di loss è anche chiamata 
 objective function
 . 
Nelle architetture deep si impiegano spesso 
 optimizer
  alternativi alla discesa 
del gradiente.  
Concettualmente, l'apprendimento delle architetture DL è ricavare un 
modello adatto al task in base ai dati disponibili, mentre l'optimizer si 
focalizza sulla objective function.  
L'ottimizzazione si focalizza sulla loss è sui dati disponibili, perciò ul 
training error
 . 
Altrettanto fondamentale nel DL è minimizzare l'
 over
ﬁ
tting
, cioè 
massimizzare le capacità di 
 generalizzazione
 . Per questo durante 
l'ottimizzazione dobbiamo includere ulteriori analisi. 
3"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#20,20,"Nesterov Accelerated Gradient
Nello scenario classico di una discesa verso l'ottimo il NAG 
 riduce eventuali 
oscillazioni 
 causate dall'accelerazione puntuale del momentum 
optimization.
21
βm"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#21,21,"AdaGrad Algorithm: Motivazioni
In presenza di 
 dati sparsi
 , i parametri 
  associati alle
  features poco 
frequenti riceveranno update signi
 ﬁ
cativi molto raramente
 .  
•
Se decrementiamo il learning rate durante l'esplorazione, nel caso tali 
features non compaiono al principio del training, 
 è probabile che i relativi 
pesi non verranno aggiornati adeguatamente prima di raggiungere la 
condizione di ottimo.  
Facciamo l'ipotesi  
che il 
 learning rate  
 è legato 
 al numero di volte  
s(i,t)
 che 
abbiamo 
 ""notato"" una certa features 
 i
 durante il training 
 ﬁ
no al tempo 
 t
. 
•
Features frequenti vedranno il learning rate associato ai relativi parametri 
diminuire più velocemente:  
 
Ma se contiamo solo le occorrenze 
 non teniamo in considerazione il valore 
del gradiente
 , a volte molto grande, a volte irrilevante.
Θ
η
η
=
η
0
s
(
i
,
t
)
+
ϵ
22"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#22,22,"AdaGrad Algorithm
Il 
AdaGrad algorithm
  rende il 
 learning rate adattivo
 , dove 
 ogni parametro 
ha un proprio rate
 . 
Per tale motivo si considera un 
 vettore  
s
 che 
 memorizza gli update per ogni 
parametro
  calcolato nel seguente modo:  
 
 
si assume 
 s
0
 = 0. 
La prima espressione accumula nel vettore 
 s
 i quadrati dei gradienti rispetto 
ai parametri  
ﬁ
no all'istante attuale.  
•
Se 
la funzione di costo è ripida
  rispetto ad una direzione 
 i
, la sequenza dei 
gradienti assumeranno un valore elevato
  in modulo, e la componente  
aumenterà ad ogni iterazione.
s
←
s
+
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
Θ
s
i
23...cont"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#23,23,"AdaGrad Algorithm (
 cont.
 )
La seconda è simile alla discesa del gradiente, ma 
 il vettore dei gradienti è 
scalato del fattore  
 , dove 
  è il solito parametro di smoothing per 
evitare divisioni per 0.  
•
Le coordinate che mostreranno spesso gradienti elevati saranno 
maggiormente 
 ridimensionate
 , al contrario, gradienti signi
 ﬁ
cativi sporadici 
o in valore ridotto corrisponderanno a learning rate più importanti.  
I principali vantaggi di 
 AdaGrad
  sono i seguenti:  
•
Adatto a training data sparsi e addestramenti molto lunghi.  
•
Il
 tuning del learning rate super
 ﬂ
uo
. Si imposta a un valore comune,  
es. 
=0.01, evitandolo di considerare come iperparametro da ottimizzare.  
•
La 
complessità computazione è paragonabile alla discesa del gradiente 
tradizionale.
s
+
ϵ
 ϵ
η
24"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#24,24,"AdaGrad Algorithm
25
parametro soggetto a gradienti 
elevati e legati a features frequenti
parametro soggetto a gradienti  
ridotti e legati a features sparse"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#25,25,"RMSProp algorithm
AdaGrad può rallentare la discesa del gradiente interrompendo 
anticipatamente il training.  
L'
algoritmo RMSProp
  è una variazione di AdaGrad dove 
 il vettore 
accumulatore 
 s
 considera maggiormente gli ultimi gradienti calcolati
 .  
•
Si introduce un 
 fattore di decay  
. 
 
 
•
Sebbene 
  sia un iperparametro, valori intorno allo 0.9 mostrano un buon 
comportamento.  
RMSProp
  si dimostra
  spesso migliore di AdaGrad
  e di altre ottimizzazioni 
(es. Momentum optimization e NAG).
β
s
←
β
s
+
(
1
−
β
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
β
26"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#26,26,"Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
β
1
27Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#27,27,"Adam Optimization
Riguardo il 
 tuning
  dell'Adam Optimization:  
•
Valori tipici per 
  e 
 sono 0.9 e 0.999, rispettivamente.  
•
Come per gli altri 
 algoritmi di adaptive learning rate
 , il valore iniziale di  
può essere impostato ad un valore tipico di 0.001 senza ulteriore tuning.
β
1
β
2
η
28"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#28,28,"Tecniche di ottimizzazione e complessità
Gli approcci 
 ﬁ
nora trattati si basano su 
 derivate parziali del primo ordine  
(Jacobians). Il numero di output per ogni dimensione in input è 
 n
,
 con 
 n 
numero di parametri.  
Esistono molti approcci del 
 secondo ordine (
 Hessians), ma richiedono 
 n
2 
Hessians per output.  
•
Recenti architetture Deep contengono oltre 10
8
 parametri.  
•
Limiti sulla memoria di calcolo non permettono di usare tali approcci.
29"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#29,29,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?
30"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#3,3,"Gli optimizer (2)
Nel DL le funzioni di 
 loss
 sono complesse e non hanno una 
 soluzione 
analitica
 , cioè non possono essere formalizzati in modo da poter ricavare la 
soluzione ottima con le risorse (tempo e hardware) disponibili in una serie di 
step. Per questo si impiegano 
 soluzioni numeriche
  che seguono un 
procedimento di trail & error su un insieme di soluzioni candidate.  
Es.
 i coef
 ﬁ
cienti di una regressione lineare possono essere ricavati 
analiticamente via algebra lineare (es. 
 matrix factorization
 ), oppure 
numericamente (es. 
 gradient descent
 ) quando i dati non sono 
interamente memorizzabili.
4"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#30,30,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepasserà il momentum. 
31"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#31,31,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.
32"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#32,32,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.  
3.
Potrà oscillare molte volte prima di arrivare al minimo.
33"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#33,33,"Keras e optimizer
Si può de
 ﬁ
nire facilmente via compile()  
from
 tensorflow 
 import
 keras
from
 tensorflow.keras 
 import
 layers
model = keras.Sequential()
model.add(layers.Dense(
 64
, kernel_initializer=
 'uniform'
 , input_shape=(
 10
,)))
model.add(layers.Activation(
 'softmax'
 ))
opt = keras.optimizers.Adam(learning_rate=
 0.01
)
model.
compile
(loss=
'categorical_crossentropy'
 , optimizer=opt
 )
# oppur
e
model.compile(loss='categorical_crossentropy', 
 optimizer='adam'
 )
Oppure all'interno del training loop:  
optimizer = tf.keras.optimizers.Adam()
# Iterate over the batches of a dataset.
for
 x, y 
in
 dataset:
   
with
 tf.GradientTape() 
 as
 tape:
        
 # Forward pass.
        logits = model(x)
        
 # Loss value for this batch.
        loss_value = loss_fn(y, logits)
    
# Get gradients of loss wrt the weights.
    gradients = tape.gradient(loss_value, model.trainable_weights)
    
# Update the weights of the model.
    
optimizer.apply_gradients
 (
zip
(gradients, model.trainable_weights))
34
Optimizer disponibili:  
•
SGD,  
•
RMSprop,  
•
Adam,  
•
Adadelta,  
•
Adagrad,  
•
Adamax,  
•
Nadam,  
•
Ftrl"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#34,34,"Richiami: Learning rate
Impostare un 
 learning rate troppo alto
  può far 
 divergere
  l'apprendimento 
dall'ottimo.  
Valori 
 troppo bassi 
 provocano 
 tempi di addestramento lunghi
 .  
Valori 
 elevati
  rendono il processo più rapido avvicinandosi all'ottimo ma 
senza convergere realmente
 .  
•
Tecniche quali
  AdaGrad, RMSProp
  e 
Adam
  affrontano questo problema ma 
richiedono comunque tempo, perciò 
 risorse di calcolo
 . 
Avviando il training più volte 
 su un training set ridotto e con diversi learning 
rate ci permette di 
 stimare
  quello più adatto.
35
EpocheLoss"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#35,35,"Richiami: Learning rate
36
Minimo cost function
learning rate elevato
learning rate basso
learning rate ideale"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#36,36,"Learning rate schedule
Le strategie di 
 learning schedules
  mirano ad 
 adattare il valore del learning rate  
durane il training.  
I più popolari algoritmi di 
 adaptive learning rate
  sono:  
•
Predetermined piecewise constant learning rate
 : 
•
Ogni 
 n
 epoche decrementa il rate di un valore predeterminato.  
•
Performance scheduling
 : 
•
Misura le perfomance (es. validation error) ogni 
 n
 steps e riduce il rate di un 
fattore prede
 ﬁ
nito quando le performance non migliorano.  
•
Exponential scheduling
 : 
•
Il rate si riduce di 
  dopo 
 r
 steps:  
•
Power scheduling
 : 
•
Simile al precedente ma il rate decresce più lentamente: 
1
10
η
(
t
)
=
η
0
⋅
10
−
t
r
η
(
t
)
=
η
0
(
1
+
t
r
)
−
c
37"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#37,37,"Learning rate schedule: considerazioni
Nel dominio dello 
 speech recognition
  e impiegando il Momentum 
optimization, il 
 performance scheduling
  e 
exponential scheduling  
dimostrano 
 migliori performance
 . 
•
L'
exponential scheduling 
 è da preferire perché 
 più facile nel tuning
 . 
Se si impiegano i seguenti optimizer 
 AdaGrad, RMSProp
  e 
Adam 
 non è 
necessario implementare il learning rate schedule.
38"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#38,38,"Keras e learning rate
Nell'esempio si de
 ﬁ
nisce un learning rate adattivo basato su exponential 
decay:  
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=
 1e-2
,
    decay_steps=
 10000
,
    decay_rate=
 0.9
)
optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)
39"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#4,4,"Local vs Global minimum
Un approccio numerico tradizionale che porta lo stato vicino ad un minimo 
locale restituirà una soluzione sub-ottima. Introducendo un certo grado di 
rumore abbiamo possibilità di continuare la ricerca altrove  
Nel 
minibatch stoachastic gradient descent
 , si introducono variazioni 
dovute ai gradienti calcolati sui minibatch e non sull'intero batch. 
5
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#5,5,"Saddle points
I punti di sella generano vanishing gradients, e creano problemi se non 
siamo in minimi locali o globali.  
Nell'esempio 
 f(x)=x
3
6
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#6,6,"Saddle points (2)
Nell'esempio sotto abbiamo 
 f(x,y)=x
2
-y
2 
con punto di sella in (0,0), massimo 
per y e minimo per x. Se assumiamo l'input di f un vettore k-dimensionale e 
l'output scalare, abbiamo  
Derivate parziali  
La 
matrice di Hessian
  (H) consiste nelle derivate parziali del secondo 
ordine. Essa rappresenta proprietà geometriche della super
 ﬁ
cie, 
soprattutto quando i gradienti sono pari a 0.
7
∇f(x)=[∂f(x)
∂x1,∂f(x)
∂x2,⋯,∂f(x)
∂xk]
Hf=∂2f
∂x1∂x1∂2f
∂x1∂x2⋯∂2f
∂x1∂xk
∂2f
∂x2∂x1∂2f
∂2x2⋯∂2f
∂x2∂xk
⋯
∂2f
∂x1∂xk∂2f
∂x2∂xk⋯∂2f
∂2xk"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#7,7,"Punti critici
In particolare gli autovalori e il determinante di H ci danno indicazioni sui punti 
critici e sulla funzione di costo.  
Una 
 convex function
  (cioè con un unico minimo) ha sempre autovalori non negativi.  
Ma il calcolo di H è oneroso di risorse (spazio e calcolo). Inoltre i task su cui si 
applicano architetture di DL non sono tipicamente associati a convex functions.
8
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#8,8,"Formalismo
Nei lucidi seguenti useremo il formalismo:  
•
:   i pesi attuali 
 w
 e 
b
 della RN (in passato 
 W
) 
•
 :  
funzione di costo
  (in passato 
 E 
o 
f
) 
•
 : 
gradiente
  della funzione di costo  
•
:   
 learning rate 
 o step size (in passato 
 ) 
•
, 
:  
moltiplicazione
  e 
divisione element-wise
 , 
   cioè posizione 
  posizione  
Θ
J
(
Θ
)
∇
Θ
J
(
Θ
)
η
 α
⊗
⊘
×
9"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#9,9,"Richiami: Gradient descent
Il processo di ottimizzazione 
 Gradient descent
  opera una 
 sequenza di step 
regolari
  per ogni punto verso la direzione di massima discesa che 
corrisponde a quella determinata dall'opposto del suo gradiente in quel 
punto.  
 
In questo modo si ha che:  
•
L'
aggiornamento dipende solo dal gradiente calcolato localmente
 , e non 
da quelli precedenti.  
•
Se il 
 gradiente locale è piccolo
 , l'aggiornamento sarà 
 poco signi
 ﬁ
cativo
 .
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
10"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 3: Over
 ﬁ
tting 
1"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#1,1,"Sommario
Affrontare l'Over
 ﬁ
tting 
Richiami  
Early stopping  
1 e 
 2 regularization  
Dropout  
Max-Norm regularization  
Data Augumentation  
Esercizi
ℓ
 ℓ"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#10,10,"Early stopping - ipotesi
Alcuni studi mostrano che le reti DL hanno la capacità di fare 
 ﬁ
tting di label 
arbitrarie, per
 ﬁ
no generate casualmente, ma solo dopo un numero elevato 
di iterazioni. In presenza di label ben de
 ﬁ
nite nel training set, la rete tende a 
rappresentarle per prime, e poi interpolare i dati associati a label ""rumore"".  
Ci garantisce la capacità di generalizzazione: è suf
 ﬁ
ciente riuscire ad 
addestrare il modello sui dati con label ben de
 ﬁ
nite, ed evitare di 
continuare su dati mal addestrati.
11"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#11,11,"Early stopping
Invece di introdurre vincoli sui parametri (l1 e l2 regularization), il vincolo 
può essere sul numero di epoche del training.   
Nella tecnica di regolarizzazione 
 early stopping
  interrompiamo il training 
quando le prestazioni della rete non migliorano, ad esempio:  
•
Alla 
ﬁ
ne di ogni epoca possiamo valutare le prestazioni sul 
 validation set
 .  
•
Teniamo traccia dell'ultima volta in cui il modello ha migliorato le 
prestazioni.  
•
Se dopo un certo numero di epoche non ci sono stati miglioramenti 
signi
ﬁ
cativi (> 
 ε
), spesso chiamata 
 patience criteria
 , interrompiamo e 
scegliamo lo snapshot del modello che in passato si è dimostrato migliore.  
Il vantaggio è aumentare il potere di generalizzazione evitando di 
considerare label noisy. Inoltre riduce il tempo di training.  
È spesso utile combinarlo ad altre tecniche di regolarizzazione.
12"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#12,12,"1
 e 
 2
 regularization
 ℓ
ℓ
1
 e 
 2 
regularization
  introducono limiti sul valore dei parametri e possono 
prevenire l'over
 ﬁ
tting.  
•
Corrispondono rispettivamente alle tecniche di 
 Lasso
  e 
Ridge 
 nella 
regressione e 
 1
 e 
 2
-penalty nella classi
 ﬁ
cazione.  
•
In pratica, oltre alla corrispondenza tra output attesi e output prodotti dalla 
rete, aggiungiamo un ulteriore vincolo da soddisfare durante il training.  
Modelli complessi tendono a rappresentare anche 
 ﬂ
uttuazioni causate dal 
rumore.  
Le due regolarizzazioni spingono i parametri del modello ad assumere valori 
vicini allo 0 e, come effetto collaterale, a ridurre gli effetti dei layer nascosti 
della rete, perciò rendendo il modello meno complesso.
ℓ
ℓ
ℓ
ℓ
13"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#13,13,"1
 regularization
ℓ
Nella 
 1
  si 
aggiunge la magnitudo sui pesi 
 (valore assoluto) come 
coef
ﬁ
ciente di penalità
  (o 
termine di regolarizzazione
 ) alla funzione di loss.  
1
 riduce signi
 ﬁ
cativamente il valore dei pesi associati alle feature meno 
importanti, operando una sorta di 
 feature selection
 , che
  riduce complessità 
e signi
 ﬁ
catività di alcune feature
 .  
Alfa è l'iperparametro 
 regularization rate
 . Valori 
 troppo elevati 
 comportano 
modelli semplici e potenziali 
 under
 ﬁ
tting, valori molto bassi 
 annullano la 
regolarizzazione.
ℓ
ℓ
14
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#14,14,"2
 regularization
ℓ
Nella 
 2
  si 
aggiunge la magnitudo al quadrato sui pesi 
 (o norma Ecluidea)  
come coef
 ﬁ
ciente di penalità.
ℓ
15
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#15,15,"Dropout - motivazioni
Abbiamo visto come modelli semplici possono garantire la generalizzazione. 
Possiamo intervenire (1) riducendo il numero delle dimensioni, o (2) 
riducendone l'importanza 
 (
2
 regularization), oppure (3) imponendo che la 
funzione stimata sia 
 smooth
  cioè poco sensibile a piccoli cambiamenti 
dell'input.  
Alcune teorie mettono in correlazione la smoothness con la capacità di 
essere resilienti alle perturbazioni nell'input. In base ad esse è stata proposta 
la tecnica di 
 iniettare
  rumore durante la forward propagation negli strati 
intermedi. L'obiettivo è minimizzare la situazione in cui un layer si 
specializza solo su un sottoinsieme di pattern di attivazione del layer 
precedente (
 co-adaptation
 ). 
Nella pratica, si disabilitano una frazione di nodi del layer precedente così 
da contribuire con un valore pari a 0 nell'input del layer attuale
ℓ
16"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#16,16,"Dropout (1)
Nel 
dropout
  si assegna ad ogni nodo una probabilità 
 p
 di essere disattivato 
(ignorato) in un certo step durante la fase di forward e backward propagation, 
ad eccezione dell'output layer.  
•
p
 è un iperparametro chiamato 
 dropout rate
  (es. p=0.5).  
•
Ogni attivazione di un layer intermedia è sostituita con:  
•
Nel caso fosse 0 i gradienti svaniscono durante il backpropagation.  
Dopo la fase di training (es. in produzione) tutti i nodi saranno attivati.  
Ad ogni step abbiamo una diversa con
 ﬁ
gurazione di rete. 
 Con N nodi 
possiamo avere 2
N
 con
ﬁ
gurazioni diverse, tutte addestrate per lo stesso scopo.
17
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#17,17,"Dropout (2)
Una impresa funziona meglio senza un dipendente?  
•
Sì, se i lavoratori sanno adattarsi, cioè: ognuno si occupa di più cose, 
maggiore cooperazione, e non contare solo sui vicini.  
Garantisce reti più 
 robuste 
 e con capacità di 
 generalizzazione
 . 
Si ottiene un incremento delle prestazioni del 
 1-2% 
 per
ﬁ
no nelle architetture 
più ottimizzate.
18"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#18,18,"Dropout - esempio
19
senza Dropout con Dropout"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#19,19,"Dropout: altre considerazioni
Una 
 rete complessa
  con molti parametri facilmente incorpora 
dipendenze che rappresentano feature dei dati di ingresso di scarso 
interesse (
 over
ﬁ
tting
).  
•
Se ad ogni step proponiamo dati a diverse con
 ﬁ
gurazioni di layer è 
meno probabile che un certo peso si focalizzi su una feature poco 
signi
ﬁ
cativa.  
La tecnica dropout 
 raddoppia circa il numero di iterazioni per 
raggiungere la convergenza
 , ma il 
 tempo di addestramento per una 
epoca è più breve 
 dato che ho meno nodi funzionanti.  
Per avere aggiornamenti più lenti si può considerare un singolo mini-
batch per ogni con
 ﬁ
gurazione considerata.
20"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#2,2,"Richiami: Over
 ﬁ
tting
Le reti deep contengono molti parametri che mirano a modellare un insieme 
vasto di funzioni, anche complesse.  
L'obiettivo dell'
 addestramento
  è ottenere una rete che mostra 
 buone 
prestazioni sia sul training set, sia in produzione 
 (cioè su dati mai visti).  
•
In queste condizioni si ha 
 generalizzazione
 . 
Il 
test set  
permette di 
 valutare l'over
 ﬁ
tting
 del modello 
 ﬁ
nale testandolo su 
dati mai visti in precedenza durante il training, ma con distribuzione di 
probabilità simile.  
•
Se un modello 
 ﬁ
tta
 i dati di training e di test contemporaneamente, si ha 
minimo over
 ﬁ
tting.  
Il 
validation set
  è usato più raramente per 
 valutare la combinazione migliore 
degli iperparametri
  durante lo sviluppo della rete. Non è impiegato durante il 
training né Nonostante ciò, le sue caratteristiche possono essere parzialmente 
rappresentate all'interno della rete, 
 rendendo la valutazione meno oggettiva
 .
3"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#20,20,"Dropout e analogia col boosting
Supponiamo di avere un problema di 
 classi
 ﬁ
cazione
 . Il 
dropout  
interpreta la rete come un insieme (molto grande) di classi
 ﬁ
catori 
“
weak
 ”.  
•
Durante l’addestramento 
 disattivo una parte della rete per 
sfruttare solo un sotto-modello alla volta
 . 
•
L'
accuratezza dei singoli sotto-modelli è minore di quella che 
potrei ottenere addestrando l'intera rete 
 su tutto il training set.  
•
Ma alla 
 ﬁ
ne considero la 
 rete nella sua interezza
 , cioè con tutti i 
sotto-modelli attivati, 
 ottenendo un aumento delle prestazioni
 . 
•
Nel 
boosting si suppongono modelli indipendenti
  mentre nel 
dropout c’è inevitabilmente dipendenza
  dovuta alla condivisione 
dei parametri tra sotto-modelli.
21"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#21,21,"Dropout nella pratica
Dal punto di vista operativo, con 
 p=0.5,
  durante il test ogni nodo di 
un qualsiasi hidden layer riceve il doppio degli input rispetto alla 
fase di training.  
•
Dopo il training è importante moltiplicare il valore degli input per  
1-p
 o avremmo dei segnali di ingresso con magnitudine troppo 
elevata. In alternativa, si può scalare l'output di ogni neurone.  
Durante lo sviluppo della rete, se notiamo che il modello mostra 
over
ﬁ
tting possiamo introdurre il dropout, ovvero incrementare 
 p
. 
Se mostra unde
 ﬁ
tting lo decrementiamo.  
Dropconnect
  è una variazione del dropout, dove sono gli archi ad 
essere disattivati.
22"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#22,22,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#23,23,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#24,24,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe. "
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#25,25,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe.  
Lo possiamo usare nel 
 input layer 
 perché permette di addestrare 
il modello ignorando alcune feature in ingresso che possono 
in
ﬂ
uenzare negativamente l'addestramento (es. p=0.8)  
E simile ad una feature selection."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#26,26,"Dropout
10-dropout
  (python)
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#27,27,"Max-Norm regularization
La 
Max-norm regularization
  introduce il 
 vincolo sul modulo dei 
pesi
 con un iperparametro 
 r
: 
 ,            dove
  indica la 
 2
-norm  
Ad ogni training step normalizziamo i pesi:  
 
Riducendo 
 r
, oltre a regolarizzare i pesi, si affronta anche il 
vanishing/exploding problem.  
w
2
≤
r
 ⋅
2
ℓ
w
←
w
r
w
2"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#28,28,"Data Augumentation
La 
data augumentation
  genera nuove istanze da dare in input
 , 
aumentando la dimensione del training set.  
Nel caso delle immagini (
 image augumentation
 ), si automatizza 
il processo con tecniche tradizionali quali:  
•
Ruotare, spostare, ridimensionare, aggiungere un rumore, copie 
speculari, variazioni di luce e contrasto, etc.  
•
Es. fare crop dell'immagine in modo che il soggetto compaia in 
diverse posizioni, modi
 ﬁ
care l'intensità dei colori per ridurre la 
relativa sensitività del modello.  
Lo scopo e (1) rendere la rete meno dipendente da queste 
variazioni e (2) incrementare il set di training nel caso ci fossero 
un numero insuf
 ﬁ
ciente di istanze."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#29,29,"Data Augumentation in Keras
11-data_augmentation.ipynb
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#3,3,"Richiami: Over
 ﬁ
tting
Per ridurre l'over
 ﬁ
tting si può intervenire:  
•
Cambiando la struttura della rete
  (es. riducendo il numero di nodi/pesi/
layer).  
•
Alterando i valori del parametri
  durante l'addestramento.
4"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#30,30,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Con 
modello sparso
  indichiamo una versione ""sempli
 ﬁ
cata"" di 
modello tipicamente più complesso, utile per elaboratori con 
meno risorse computazionali.  
Ad esempio: mini computers e smartphones."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#31,31,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#32,32,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0  
La 
 1
 regularization incrementa il numero di parametri vicino 
allo 0 che possono essere azzerati  
Il 
FTRLOptimizer
  è una altro algoritmo adatto per questo scopo.
ℓ"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#33,33,"Tool: Gradient Descent Visualization
θ1
θ2loss"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#34,34,"Richiami 
 
 
 
 
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
35Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ
 s←s+∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵAdaGradAdam"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#35,35,"Qualche indicazione pratica
Per problemi di classi
 ﬁ
cazione, inizia da una con
 ﬁ
gurazione di default,  
come la seguente:  
Oppure cerca modelli pre-addestrati per compiti uguali o simili.  
Modi
 ﬁ
ca la con
 ﬁ
gurazione intervenendo:  
•
Se 
converge troppo lentamente incrementa il learning rate  
•
Se converge ma 
 con performance non adeguate
 , prova un 
 learning schedule
 , es. 
exponential decay.  
•
Se 
il training set è troppo piccolo, fai data augumentation
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#36,36,"Kaggle: piattaforma per competizioni ML-based
Ogni competizione consiste in un dataset di training e uno di test.  
Il partecipante suddivide il training set in due, una parte per la 
validazione, oppure opera una cross-fold validation.  
Il test set completo rimane privato 
 ﬁ
no alla 
 ﬁ
ne della competizione.
37
https://www.kaggle.com/c/digit-recognizer/data"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#37,37,"Over
 ﬁ
tting: un caso reale
Il ranking 
 ﬁ
nale viene calcolato sul 
 test set
 .
38
Differenza rispetto al training (e validation) set pubblico
Scendendo si hanno di solito valori negativi: approcci che 
si comportano molto bene nel training ma non nel test set."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#38,38,"La regola del 30
La 
regola del 30  
è un semplice procedimento empirico adatto per 
classi bilanciate
  (cioè con lo stesso numero di istanze per ogni label).  
Fornisce una idea 
 se un incremento di prestazioni è signi
 ﬁ
cativo o 
meno
  (es. dovuto solo al caso).  
Se dopo aver aggiornato il classi
 ﬁ
catore ottengo un incremento 
(o decremento) di accuratezza che riguarda almeno 30 istanze, 
allora il miglioramento (peggioramento) è signi
 ﬁ
cativo.  
39"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#39,39,"La regola del 30
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima 
percentuale per dire che l’incremento di accuratezza è signi
 ﬁ
cativo? 
40"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#4,4,"Richiami: Over
 ﬁ
tting
5Training/Validation
 Produzione/
Test
label:A
label:J
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#40,40,"La regola del 30: soluzione
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima percentuale per 
dire che l’incremento di accuratezza è signi
 ﬁ
cativo?  
L’incremento percentuale si calcola:  
Esempio:  
Se N = 1000 -> 3%  
Se N = 3000 -> 1%  
Se N = 30.000 -> 0.1%  
Seguendo la regola, è meglio usare un validation set ampio, così anche 
incrementi (es. 0.1%) possono essere tenuti in considerazione.  
Indicazioni più accurate sono ottenute con 
 test di signi
 ﬁ
catività
 .
41(N+30)−N
N⋅100"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#41,41,"Esercizio su Deep NN
Costruisci una rete Deep, con 5 layer hidden da 100 nodi l'uno, 
inizializzazione Xavier e He, e funzione di attivazione ELU  
Usa la Adam optimization con early stopping.  
Impiega il dataset di cifre MNIST, ma solo da 0 a 4. Usa come output 
un layer softmax da 5 neuroni.  
Ricordati di salvare periodicamente i checkpoints, e il modello 
 ﬁ
nale.  
Fai tuning sugli iperparametri usando la cross-validation, e vedi se 
puoi incrementare la precisione.  
Prova ad aggiungere la Batch normalization e confronta le curve di 
learning. Converge prima? Produce un modello migliore?  
Secondo te c'è over
 ﬁ
tting sul training set? Prova ad aggiungere il 
dropout ad ogni layer e valuta miglioramenti.
42"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#42,42,"Esercizio sul Transfer Learning
Crea una nuova Deep NN e riusa i parametri degli hidden layer della 
rete precedente. Congelali e rimpiazza il layer softmax con uno 
nuovo.  
Addestra la rete sulle cifre 5-9, usando solo 100 immagini per cifra, e 
vedi quanto impiega. Nonostante le poche immagini riesci ad avere 
una buona precisione?  
Prova a fare caching dei layer congelati, e addestra di nuovo il 
modello. Quanto è veloce ora?  
Prova di nuovo usando solo 4 hidden layer. La precisione aumenta?  
Ora scongela i primi 2 layer e continua il training. Ottieni maggiori 
performance?
43"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#43,43,"Esercizio sul Pretraining su auxiliary task
Costruiamo una Deep NN che confronta due cifre MNIST per veri
 ﬁ
care se sono le 
stesse. Dopodiché impieghiamo gli stessi layer 
 ﬁ
nali della rete per addestrare un 
classi
 ﬁ
catore MNIST su pochissimi dati di training.  
Inizia da 2 Deep NN (A e B), simili a quanto costruito nel esercizio su Deep NN. 
Aggiungi un singolo layer di output che connette l'output di ambedue le reti. Usa la 
funzione concat() di Tensor
 ﬂ
ow con axis=1. Usa quanto ottieni come input al nuovo 
output layer. L'output layer contiene un singolo nodo e usa la logistic come funzione 
di attivazione.  
Suddividi MNIST in 2 sets: primo split da 55,000 immagini, secondo split da 5,000. 
Crea una funzione che genera un batch dove ogni istanza è una coppia di immagini 
prese dallo split #1. Metà devono appartenere alla classe ""stessa classe"" (label 0), 
l'altra metà ""classi diverse"" (label 1).  
Addestra la rete sul training set. Per ogni coppia manda in input in simultanea 
l'immagina da A e l'immagine da B.  
Ora crea una nuova rete riutilizzando e congelando i pesi degli hidden layers di A e 
aggiungendo una softmax layer di 10 nodi. Addestra la rete sullo split #2 e vedi se 
ottieni prestazioni elevate avendo solo 500 immagini per classe.
44"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#5,5,"Affrontare l'Over
 ﬁ
tting
Valori dei pesi limitati in modulo signi
 ﬁ
cano spesso modelli meno complessi, e meno 
in
ﬂ
uenzati da 
 ﬂ
uttuazioni statistiche dei dati in input.  
•
Valori elevati nei pesi implicano attivazioni molto diverse per leggere variazioni in input.  
Tranne nei casi di training set molto grandi, si impiegano sempre 
 tecniche di 
regolarizzazione
 , tra le quali:  
•
Early stopping
 : 
•
terminare l'addestramento quando le performance degradano  
•
 1
 e 
 2
 regularization (o weight regularization)
 :  
•
penalizzare il modello in base alla magnitudo dei pesi  
•
Dropout
 : 
•
per ogni layer ignorare alcuni input durante l'addestramento  
•
Max-Norm regularization (o weight constraint)
 :  
•
introdurre un range di ammissibilità per il valore dei pesi  
•
Data Augumentation (non regolarizza i pesi, ma aumenta la dimensione del training set)
 : 
•
modi
 ﬁ
care il training set, es. aggiungendo del rumore
ℓ
ℓ
6"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#6,6,"Richiami: Over
 ﬁ
tting
7
Complessità del modello"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#7,7,"Richiami: bias e varianza 
High Validation error
High Test errorSi
SiNo
No
Done! •Bigger mode l
•Train longer  
•New model architecture 
•More data  
•Regularization  
•New model architecture Bias 
(unde ﬁt)
Varianc e
(over ﬁt)
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#8,8,"Over
 ﬁ
tting e regolarizzazione
Il procedimento di training 
 ﬁ
nora seguito è:  
•
addestrare
  il modello su un training set, e valutare l'
 errore di 
generalizzazione
  su holdout data (test set).  
La differenza di performance tra i due set si chiama 
 generalization gap
 . Se 
la differenza è elevata si ha 
 over
ﬁ
tting
 sul training data.  
Nello scenario del DL, prendendo l'esempio del task della classi
 ﬁ
cazione, 
si hanno tipicamente modelli complessi a suf
 ﬁ
cienza per 
 ﬁ
ttare
 ogni istanza 
di training, anche per training set molto grandi. Farebbe pensare che per 
ridurre il generalization error siamo costretti a introdurre regolarizzazioni 
(es. riducendo la complessità, vincoli sul valore dei parametri).  
In realtà si nota come nel DL si raggiungano spesso 0 training error, perciò 
l'unico aspetto da ottimizzare è il generalization error. Inoltre, contrario alla 
logica, l'errore si può ridurre anche rendendo l'architettura più complessa 
(es. più layer e nodi). I progettisti hanno più possibilità di affrontare 
l'over
 ﬁ
tting rispetto alle architetture NN tradizionali.
9"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#9,9,"Ispirazione ai modelli non parametrici
Gli approcci parametrici possono essere de
 ﬁ
niti in vari modi, es. sono 
basati su modelli statistici che rappresentano i parametri con distribuzioni 
standard. Nei modelli nonparametrici la variabilità dei parametri è più 
ampia e ci sono meno vincoli da rispettare (es. su media, varianza).  
Spesso i modelli nonparametrici confrontano le istanze e si basano 
sull'ipotesi che istanze simili in input producono output simili (es. k-NN).  
Un altro modo per caratterizzare i modelli nonparametrici è sulla 
complessità che tende a crescere al crescere del numero di dati disponibili 
di training.  
Le reti NN sono spesso viste come modelli non parametrici
 . Si hanno un 
numero molto abbondate di parametri che tendono a interpolare i training 
data.
10"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #1
1"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#1,1,"Sommario
Nodi e layers ricorrenti  
•
Calcolo degli output  
Predizione  
Architetture RNN  
•
Sequence-to-sequence  
•
Sequence-to-vector  
•
Vector-to-sequence  
•
Encoder-decoder  
Memory cells  
•
LSTM  
•
GRU"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#10,10,"Architetture RNN (1) 
Ci sono vari tipi di architetture RNN, che dipendono dal task che si vuole 
affrontare.  
La rete 
 sequence-to-sequence
  è utile per task di 
 predizione
 .  
•
Supponiamo di avere la quotazione di chiusura di un titolo in borsa, misurata 
negli ultimi N giorni. La rete deve produrre in output le stesse quotazioni 
traslate di un giorno nel futuro.  
La rete 
 sequence-to-vector
  è simile alla precedente ma 
 scarta tutti i valori in 
output tranne l'ultimo
 . 
•
Se in input abbiamo una sequenza di 
 id
 di parole, l'ultimo output può 
corrispondere al 
 sentiment
  (es. -1 [hate], +1 [love).
11
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#11,11,"Architetture RNN (2) 
La rete 
 vector-to-sequence
  prende in input ripetutamente lo stesso vettore per 
una successione di steps e produce una sequenza in output.  
•
Se il vettore in input corrisponde ad una immagine, possiamo addestrare la 
rete per produrre una descrizione testuale associata (sequenza di parole).
12
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#12,12,"Architetture RNN (3) 
In
ﬁ
ne si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
vector-to-sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio.  
•
Una rete 
 sequence-to-sequence
  non è adatta poiché l'intera frase. Le ultime 
parole dell'input potrebbero in
 ﬂ
uenza l'inizio dell'output, mentre la rete 
traduce ogni parola via via che l'input è reso disponibile. Inoltre le lunghezze 
dell'input e output potrebbero non corrispondere.
13
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#13,13,"RNN: Addestramento 
L'addestramento di una RNN richiede l'
 unrolling through time
  e l'uso della 
tecnica 
 backpropagation through time
  (
BPTT
 ). 
•
La prima passata corrisponde alla 
 forward
  pass tradizionale (frecce 
tratteggiate).  
•
L'output è valutato con una 
 funzione di costo  
 . Per talune 
architetture la funzione può ignorare alcuni output.  
•
Il gradiente della funzione di costo è propagato 
 backward
  (frecce continue) e 
i parametri aggiornati di conseguenza.
C
(
Y
(
0
)
,
Y
(
1
)
,
⋯
,
Y
(
T
)
)
14
In questo esempio la funzione  
è valutata con gli ultimi 3 
output, e perciò i gradienti non 
transitano per Y (0) e Y (1).
Da notare che i medesimi 
parametri W,b sono impiegati 
ad ogni step. La 
backpropagation considera 
tutti gli steps per fare 
l'aggiornamento."
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#14,14,"Time series: Predizione (forecasting)
Analizziamo le seguenti 
 time series
 :  
•
numero orario di utenti attivi su un sito web,  
•
temperatura giornaliera in un certo luogo  
•
situazione 
 ﬁ
nanziare di una società misurata trimestralmente con metriche 
multiple (es. reddito, debito, etc).  
Le prime due sono 
 univariate  
time series
  perché valutiamo temporalmente 
una singola metrica, l'ultima è una 
 multivariate  
time series
 . 
La predizione di un valore in un tempo futuro è chiamato 
 forecasting
 . 
Con 
imputation
  si intende stimare un valore mancante all'interno della time 
series.  
Le RNN si usano spesso per fare 
 forecasting
  e 
imputation
 .
15"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#15,15,"RNN e Keras (1)
Generiamo 
 time series
  in modo random:  
def 
generate_time_series
 (
batch_size
 , 
n_steps
)
:
    
# valori random in [0,1); il parametro di rand è lo shape
    freq1, freq2, offsets1, offsets2 = np.random.rand(
 4
, batch_size, 
 1
)
    
# n_steps valori nell'intervallo 0, 1 equamente spaziati
    time = np.linspace(
 0
, 
1
, n_steps)
    series = 
 0.5
 * np.sin((time - offsets1) * (freq1 * 
 10
 + 
10
))  
#   wave 1
    series += 
 0.2
 * np.sin((time - offsets2) * (freq2 * 
 20
 + 
20
)) 
# + wave 2
    series += 
 0.1
 * (np.random.rand(batch_size, n_steps) - 
 0.5
)   
# + noise
    
return
 series[..., np.newaxis].astype(np.float32)
Dove 
batch_size
  sono il numero di 
 time series
  da generare con lunghezza 
n_steps
 . Le serie sono 
 univariate
 . La funzione restituisce un array NumPy di 
dimensioni [
 batch_size
 , 
n_steps
 , 1].  
Ogni serie è generata come somma di due funzioni 
 seno
 di ampiezza 
 ﬁ
ssa ma 
frequenza e fase random, e con aggiunta di rumore.  
16"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#16,16,"RNN e Keras (2)
Creiamo training set, validation set e test set:  
n_steps = 
 50
series = generate_time_series(
 10000
, n_steps + 
 1
)
X_train, y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-1
]
X_valid, y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-1
]
X_test, y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-1
]
X_train
  contiene 7000 time series di lunghezza 50 steps, e ha dimensioni 
[7000,50,1]  
X_valid
  contiene 2000 time series  
X_test
  contiene 1000 time series  
Poiché vogliamo un 
 forecast
  di un singolo valore per time series, il vettore 
colonna target ha dimensioni [7000,1]  
17"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#17,17,"RNN e Keras (3)
Per valutare il modello introduciamo degli approcci 
 baseline
 , con cui 
confrontarci.  
Un semplice modello stima il valore futuro facendolo coincidere con l'ultimo 
valore nella time series (
 naive forecoasting
 ). 
>>> y_pred = X_valid[:, 
 -1
]
>>> np.mean(keras.losses.mean_squared_error(y_valid, y_pred))
0.020211367
•
Sebbene banale, ottiene buone prestazioni: 
 Mean squared error (MSE) di 0.02  
Un altro approccio è impiegare una rete 
 fully connected
 . Ad esempio con un 
singolo layer, perciò si riduce ad una combinazione lineare dei valori della 
time series in ingresso.  
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 50
, 
1
]),
    keras.layers.Dense(
 1
)
]
)
•
Con la con
 ﬁ
gurazione: MSE loss, Adam optimizer, 20 epoche di training; si 
ottiene un MSE di 0.004.
18"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#18,18,"RNN e Keras (4)
Implementiamo una semplice RNN, con un layer con un singolo nodo con la 
funzione Keras 
 SimpleRNN
 .  
model = keras.models.Sequential(
 [
  keras.layers.SimpleRNN(1, input_shape=[None, 1]
 )
]
)
Come dimensione dell'input impostiamo 
 None
  poiché una RNN elabora 
 time 
series
  di qualsiasi lunghezza e non occorre speci
 ﬁ
carla anticipatamente.  
Di default la 
 SimpleRNN
  usa la attivazione 
 tangente iperbolica
 .  
Il primo output viene elaborato con 
 h
(init)
=0
 e 
x
(0)
 pari al valore in input al 
primo step. Il nodo calcola la somma pesata dei 2 contributi e valuta la 
tangente iperbolica al risultato, ottenendo il primo valore in output 
 y
0
. Nella 
SimpleRNN
  tale valore corrisponde al valore per lo stato 
 h
(0)
.  
Al successivo step, lo stesso nodo prende in input il successivo input 
 x
(0) 
e lo 
stato 
 h
(0)
 e ripete l'elaborazione.  
L'unico valore in output corrisponde 
 y
49
. Se si vogliono ottenere tutti i valori in 
output impostare 
 return_sequences=True
 .
19"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#19,19,"RNN e Keras (5)
Una volta compilato e sottoposto a 
 ﬁ
t (con
 ﬁ
gurazione: 20 epoche, Adam op.), 
tale modello raggiunge un MSE di 0.014, perciò al di sotto del modello 
lineare.  
•
Il modello lineare ha un totale di 51 parametri, cioè un parametro per ogni 
input e il bias. Nella SimpleRNN abbiamo un singolo parametro per input, 
uno per l'hidden state e per il bias, cioè 3 parametri in totale.  
•
Un SimpleRNN è una rete troppo semplice per avere questo task.
20"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo assunto input per i nostri modelli di tipo vettoriale, dove ogni 
elemento 
 x
j
 corrisponde ad un attributo (o feature). Perciò possiamo 
raggruppare facilmente i dati in formato tabellari 
 istanze 
 x
 attributi
 . 
Successivamente abbiamo considerato immagini, dove per ogni coordinata 
abbiamo il valore del pixel. In questo scenario abbiamo introdotto le CNN, 
capaci di implementare logiche gerarchiche e gestire proprietà di 
invarianza.  
Come possiamo trattare input sotto forma di sequenze, come time series 
prediction, video analysis, etc?  
Oppure affrontare task che producono in output sequenze come l'
 image 
captioning, speech synthesis, 
 e
 music generation.
3"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#20,20,"Trend e stagionalità (seasonality)
Ci sono molti altri modelli per il forecast di time series, come il 
 weighted 
moving average
  e l'
autoregressive integrated moving average 
 (
ARIMA
 ). 
Alcune modelli richiedono di 
 rimuovere preliminarmente trend e stagionalità 
nei dati, ad esempio:  
•
Se i visitatori di un sito web crescono stabilmente 10% al mese, occorre 
rimuovere questa variazione dai dati in input. Una volta ottenuta la 
predizione si può reintegrare al valore 
 ﬁ
nale.  
•
Per predire la vendita di creme solari, occorre preliminarmente rimuovere la 
stagionalità annuale associata ai mesi estivi. Per esempio, rimuovendo al 
valore attuale il valore nell'anno precedente (
 differencing
 ). Si può reintegrare 
al valore 
 ﬁ
nale ottenuto.  
Le RNN non richiedono generalmente questi preprocessamenti, anche se 
possono aumentare le prestazioni, poiché la rete non è costretta ad 
apprenderli.
21"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#21,21,"Deep RNN: considerazioni
Una DeepRNN raggiunge un MSE di 0.003.  
Una architettura più adatta avrebbe un ultimo layer con un singolo valore in 
output per time step. Ma in questo caso avremmo un 
 hidden state  
rappresentato con un solo valore, che non avrebbe molta utilità. Una 
DeepRNN sfrutta tutti gli hidden states dei layer precedente per ""trasportare"" 
l'informazione necessaria per produrre l'ultimo output, e il contributo 
dell'hidden dell'ultimo layer risulta assai limitato.  
Possiamo sostituire il layer in output con un layer fully connected (o Dense). 
L'accuratezza non è alterata, il tempo di addestramento si riduce leggermente 
e possiamo scegliere qualsiasi funzione di attivazione.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 1
)
])
22"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#22,22,"Predizione di più dati
Possiamo tentare di stimare più valori temporalmente futuri, impi  
Elenchiamo alcuni approcci:  
•
Usare l'output come input nello step successivo ottenendo un valore alla 
volta  
•
Simile al precedente ma in output prediciamo contemporaneamente più 
valori ma considerando una unica loss (
 sequence-to-vector
 ) 
•
Simile al precedente ma con una loss per ogni valore predetto (
 sequence-to-
sequence
 )
23"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#23,23,"Predizione di più dati - uno dato alla volta
Possiamo tentare di stimare più valori temporalmente futuri.  
Una possibilità è impiegare il modello attuale, ottenere l'output e 
concatenarlo al predente input, ottenendo un secondo input e così via.  
•
Ad esempio, per predire 10 dati:  
series = generate_time_series(
 1
, n_steps + 
 10
)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for
 step_ahead 
 in 
range
(
10
):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=
 1
)
Y_pred = X[:, n_steps:]
Otteniamo un MSE=0.029. L'approccio 
 naive
  ottiene 0.223, ma il modello 
lineare 0.0188, ed è più accurato e veloce da addestrare.  
La Deep RNN rimane valida se limitiamo il numero di valori da predire.
24"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#24,24,"Predizione di più dati - sequence-to-vector
Una seconda opzione è addestrare la RNN per predire 10 valori 
contemporaneamente.  
•
Usiamo la 
 sequence-to-vector
 , ma con 10 valori in output invece di 1.  
Intanto cambiamo i valori target:  
series = generate_time_series(
 10000
, n_steps + 
 10
)
X_train, Y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-10
:, 
0
]
X_valid, Y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-10
:, 
0
]
X_test, Y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-10
:, 
0
]
L'output layer consisterà di 10 nodi:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 10
)
]
)
E si potranno predire 10 valori in modo simile:  
Y_pred = model.predict(X_new)
Ora l'MSE è di 0.008, migliore del modello lineare.
25"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#25,25,"Predizione di più dati - sequence-to-sequence
Un ulteriore modello da impiegare è il 
 sequence-to-sequence
 , dove le 10 
predizioni sono comunque ottenute sequenzialmente step-by-step.  
•
Il vantaggio è avere una 
 loss
 ad ogni step, perciò più gradienti che saranno 
usati per aggiornare il modello, non solo seguendo un approccio 
 through-time,  
ma direttamente dagli output generati, come avviene nelle reti non ricorrenti.  
Al primo step il modello produrrà in output la predizione per gli step da 1 a 10, 
allo step successivo le predizioni da 2 a 11, e così via. Il target avrà la stessa 
lunghezza dell'input.  
•
Sebbene in output otteniamo una parte dei valori usati in input, l'input 
corrente consiste sempre in valori apparsi nel passato. Sarebbe scorretto 
impiegare valori del dataset che temporalmente sono da considerarsi futuri.  
Creiamo le sequenze target di 10 elementi:  
Y = np.empty((
 10000
, n_steps, 
 10
)) 
# each target is a sequence of 10D vectors
for
 step_ahead 
 in 
range
(
1
, 
10
 + 
1
):
    Y[:, :, step_ahead - 
 1
] = series[:, step_ahead:step_ahead + n_steps, 
 0
]
Y_train = Y[:
 7000
]
Y_valid = Y[
 7000
:
9000
]
Y_test = Y[
 9000
:]
26"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#26,26,"Predizione di più dati - sequence-to-sequence
Per avere un modello 
 sequence-to-sequence
  impostiamo 
return_sequences=True
  per ogni layer, compreso l'ultimo. Ad ogni step 
valutiamo l'output del layer FC.  
•
Keras fornisce il 
 TimeDistributed
  layer, adatto ad essere valutato ad ogni step. 
I valori in input vengono automaticamente ridimensionati cosicché ogni step 
è trattato come una istanza separata  
•
[
batch size, time steps, input dim.
 ] 
 [
batch size × time steps, input dim.
 ] 
•
Nell'esempio abbiamo 20 nodi nel layer 
 SimpleRNN
 . L'output sarà una 
sequenza e non un singolo vettore. Il layer Dense viene applicato in modo 
indipendente ad ogni step.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
→
27"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#27,27,"Predizione di più dati - sequence-to-sequence
L'output nell'ultimo step è impiegato per la predizione e valutazione.  
Sebbene usiamo la MSE su tutti gli output, per la valutazione ci limitiamo a 
usare una metrica 
 custom
  che elabora l'MSE sull'ultimo step.  
def 
last_time_step_mse
 (
Y_true
, 
Y_pred
):
    
return
 keras.metrics.mean_squared_error(Y_true[:, 
 -1
], Y_pred[:, 
 -1
])
optimizer = keras.optimizers.Adam(lr=
 0.01
)
model.
compile
(loss=
""mse""
, optimizer=optimizer, metrics=[last_time_step_mse])
Si ottiene MSE di 0.006, 25% meglio del modello precedente.  
È possibile combinare i due approcci: predire 10 valori, concatenarli ai dati in 
input e predire i successivi 10, ottenendo sequenze di lunghezza arbitraria.  
Nota: Il 
 Montecarlo Dropout
  (
MC Dropout
 ) è spesso inclusa in ogni cella per 
omettere in modo random parte degli input e degli hidden state.  
28"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#28,28,"Predizione di più dati: limiti (1)
Per addestrare una RNN su sequenze molto lunghe occorre creare 
 reti molto 
deep
 , coi noti problemi di 
 instabilità dei gradienti
  (es. tempo di 
apprendimento troppo lungo, o instabile).  
Inoltre la rete fa più fatica a ricordare le informazioni iniziali della sequenza.  
Alcune tecniche viste possono essere nuovamente applicate (es. dropout, 
optimizers più adatti alla architettura deep).  
Le 
ReLU  
non sono adatte
  per le 
 RNN
 . 
•
Supponiamo che la discesa del gradiente aggiorni i parametri in modo da 
incrementare leggermente l'output. Siccome ad ogni step sono usati gli stessi 
parametri, anche l'output al successivo step può essere leggermente 
incrementato, e così via, 
 ﬁ
no a valori troppo elevati o instabili. 
 Una funzione 
che non satura non può prevenire questo
 .  
•
Anche i gradienti possono assumere valori troppo elevati, perciò sono utili 
tecniche quali il 
 Gradient clipping.
29"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#29,29,"Predizione di più dati: limiti (2)
La 
Batch normalization
  non mostra sperimentalmente la stessa ef
 ﬁ
cacia 
rispetto alle reti deep tradizionali e non ottiene bene
 ﬁ
ci. 
•
Teoricamente un layer BN può essere aggiunto ad ogni memory cell, e 
interverrà dopo ogni step, sia sugli input correnti sia sull'hidden state (dello 
step precedente).  
•
Ma il layer BN sarà usato ad ogni step, con gli stessi parametri, senza 
considerare la scala di valori e l'offset degli input e dell'hidden state attuali.  
Nota: un tecnica simile ma più adatta è la 
 Layer normalization
 , ma invece di 
normalizzare rispetto al batch, normalizza rispetto alla dimensione delle 
features.
30"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#3,3,"Introduzione
Una 
 time series
  consiste in una serie di misurazioni indicizzate con un 
ordine temporale.  
•
Es. ultima quotazione giornaliera di un titolo 
 ﬁ
nanziario, situazione oraria del 
meteo, traiettoria di una automobile  
Le 
Recurrent Neural Networks
  (
RNN
 ) sono architetture di reti neurali 
adatte ad analizzare time series e stimare misure mancanti o future.  
Rispetto alle 
 CNN
  possono elaborare dati in ingresso con lunghezza 
arbitraria non pre
 ﬁ
ssata, più adatte in certi contesti.  
•
Es. analisi di una frase per fare una traduzione automatica o speech-to-text  
Ciononostante non sono le uniche architetture per 
 time series
 . 
•
Reti
 fully-connected 
 sono sempre adatte per sequenze di lunghezza 
limitata, mentre sequenze molto lunghe possono essere elaborate da 
ﬁ
ltri convoluzionali.
4"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#30,30,"RNN più recenti
Le celle introdotte 
 ﬁ
nora soffrono del problema del 
 vanishing
  (e exploding) 
gradient. Il gradient clipping o altre tecniche, sebbene risolvano il problema, 
non permettono alle RNN di analizzare sequenze lunghe.  
Per tale motivo sono state introdotte le 
 memory cells
 , cioè unità di 
elaborazione che mantengono lo stato memorizzato e lo propagano alle celle 
successive evitando che ""svanisca"" a causa dei gradienti troppo bassi.  
Le 
Long Short-Term Memory (LSTM)
  sono le prime memory cell introdotte in 
letteratura, le 
 Gated Recurrent Unit (GRU)
  ne sono una versione sempli
 ﬁ
cata. 
Nelle 
 Bidirectional Recurrent Neural Networks
  si sfruttano le informazioni 
raccolte negli step precedenti e successivi per determinare l'output nello step 
corrente.
31"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#31,31,"Celle LSTM - motivazioni
Le 
LSTM
  sono memory cells introdotte per dotare la cella di memoria 
 a lungo 
termine 
 utile per riconoscere pattern di segnale più estesi.  
Oltre alla rappresentazione 
 long-term
 , determinata dai pesi che sono appresi 
durante il training, le celle hanno una memoria
  short-term
  capace di 
rappresentare le attivazioni ef
 ﬁ
mere. Tale memoria viene condivisa da una 
cella alla successiva.  
All'interno delle memory cells, oltre allo stato, esistono una serie di 
 gate 
controllers
  che determinano quali input in
 ﬂ
uenzano lo stato, se lo stato deve 
essere azzerato (o dimenticato) e come lo stato in
 ﬂ
uenza l'output della cella.  
•
Perciò nella LSTM esistono meccanismi dedicati sia per aggiornare lo stato, 
sia per azzerarlo.  
I gate sono governati da parametri che sono stimati durante l'apprendimento.
32"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#32,32,"Celle LSTM e Keras
Keras ne sempli
 ﬁ
ca l'uso con la funzione 
 LSTM
 : 
model = keras.models.Sequential([
    keras.layers.LSTM(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.LSTM(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
O impiegando la cella general purpose 
 RNN
  che può assumere come 
argomento 
 LSTMCell
 , utile per creare celle 
 custom
 , con lo svantaggio di 
perdere parte delle ottimizzazioni GPU:  
model = keras.models.Sequential([
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
,
                     input_shape=[
 None
, 
1
]),
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
Successivamente vedremo una implementazione con le funzionalità
  d2l
.
33"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#33,33,"Celle LSTM: Architettura (1)
L'architettura di una cella 
 LSTM
  è la seguente:  
Esistono 4 gates (
 FC
) i cui input sono: l'
 hidden state
  dello step precedente 
 h
(t-1) 
e l'input corrente 
 x
(t)
.  
I gate sono: 
 forget gate
 , 
input gate
 , 
output gate
 , e 
input node
 . I relativi output, 
f(t)
, 
i(t)
, 
o(t)
 e 
g(t)
; sono determinati da una rete fully connected (FC). Hanno 
tutti funzione di attivazione 
 logistic
 , tranne l'
 input node
  che impiega la 
 tanh
.
34
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#34,34,"Celle LSTM: Architettura (2)
Possiamo interpretare i gate nel seguente modo:  
•
L'
input gate
  determina quanto dell'input corrente deve essere aggiunto ad 
 c
(t) 
che assume il ruolo di stato corrente.  
•
Il 
forget gate 
 in
ﬂ
uenza quanto tenere e quanto dimenticare dello stato interno 
precedente 
 c
(t-1)
.  
•
L'
output gate
  quanto la cella corrente in
 ﬂ
uenzerà l'output 
 y
(t)
. 
•
L'
input node
  rappresenta la computazione di una cella ricorrente tradizionale.
35
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#35,35,"Celle LSTM: Architettura (3)
Per esempio, se il 
 forget gate
  fosse sempre 1 e l'
 input gate
  fosse 0, lo stato 
 c
(t-1) 
rimarrebbe imperturbato negli step futuri. Nella realtà, i gate saranno addestrati 
in modo da perturbare lo stato in funzione degli input analizzati dalla cella.  
•
Questa tecnica basata su gate affronta il 
 vanishing gradient problem  
garantendo che gli stati possano propagarsi temporalmente per molti step.  
L'
input node
  produce 
 g
(t)
 e si comporta come una cella ""base"", ma nella LSTM 
una parte rilevante del output del cella base è memorizzato nello stato interno 
c(t)
, e il resto scartato. La suddivisione tra output e stato è più netta. 
36
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#36,36,"Celle LSTM: Architettura (4)
L'output della cella 
 h(t), 
 corrispondente al valore y di una cella tradizionale, è 
generato prendendo il valore 
 tanh
 dello stato interno corrente 
 c(t)
 e calcolando 
una moltiplicazione element-wise con il valore ottenuto dall'
 output gate
 . 
•
Se l'
output gate
  è 1 lo stato interno in
 ﬂ
uenzerà i layer successivi (in una 
architettura multilayer) nello step corrente. Se è 0 lo stato non li in
 ﬂ
uenzerà.  
•
È sempre possibile che lo stato interno si propaghi per molti step, e che non 
in
ﬂ
uenzi l'output a causa dell'
 output gate 
 che lo inibisce, 
 ﬁ
no ad un certo 
step in cui il gate potrà invertire il valore. Per tale motivo 
 h(t)
 è visto come 
stato 
 short-term,
  mentre 
 c(t) 
long-term
 .
37
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#37,37,"Celle LSTM: Architettura (5)
In sintesi, la 
 LSTM
  è in grado di riconoscere sequenze lunghe, per mezzo dell'
 input 
gate
, memorizzarlo in uno stato long-term, e preservarlo 
 ﬁ
nché è giudicato 
importante, per mezzo del
  forget gate
 , e ripescarlo quando necessario.  
•
Per tale motivo le LSTM hanno ottenuto buoni risultati nell'analisi di pattern, anche molto estesi, in 
time series, testi, audio, etc.  
In termini analitici, per una singola istanza in input si ha:  
•
dove 
 W
xi
, 
W
xf
, 
W
xo
,
W
xg
 sono le matrici dei pesi dei 4 layer per le connessioni con 
l'input vector 
 x
(t)
. 
•
W
hi
, 
W
hf
, 
W
ho
,
W
hg
 sono le matrici dei pesi dei 4 layer per le connessioni con lo stato 
short-term precedente 
 h
(t-1)
. 
•
b
i
, 
b
f
, 
b
o
,
b
g
 sono i bias, inizializzati a 1 invece di 0 per evitare di ""dimenticare"" tutto 
all'inizio del training.
38
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#38,38,"Celle LSTM, Keras e d2l
11-memory_cells.ipynb
39"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#39,39,"Celle LSTM: Peephole connections
In una cella LSTM tradizionale i gate controllers analizzano 
 x
(t)
 e 
h
(t-1)
. Può 
essere utile dargli la possibilità di usare le informazioni nello stato long-term.  
Le 
peephole connections
  aggiungono il precedente stato long-term 
 c
(t-1) 
all'input dei controllers del 
 forget
  e 
input
  gate. Lo stato long-term corrente 
 c
(t)
 è 
aggiunto all'input controller dell'output gate.  
Non sempre ci sono miglioramenti,  
perciò si può tentare di usarli e valutare.  
In Keras non c'è supporto uf
 ﬁ
ciale alla cella con 
 peephole connections
 , ma si 
può creare un layer RNN generico e passargli 
 PeepholeLSTMCell
  al suo 
costruttore.
40
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#4,4,"Alcuni task con dati temporali
Speech recognition  
Music generation  
Sentiment classi
 ﬁ
cation  
DNA sequence analysis  
Machine translation  
(Video) Activity recognition
“It was a bright cold day in 
April, and the clocks were 
striking thirteen
“I loved this so much. I crap out 
on books about 40 pages in about 
90% of the time.”
Ø  
o few inputs
ACAAGATGCCATTGTCCCCCGGCCTCCTGCTGC ACAAGATG CCATTGTCCCCCGGCCTCCT GCTGC
“Ho corso per arrivare in orario.” “I ran to get on time.”
Alzarsi -> In piedi -> Camminare"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#40,40,"Celle GRU - motivazioni
Dopo le LSTM sono state studiate altre architetture che potessero mantenere i 
vantaggi ma con meno risorse di calcolo necessarie.  
Le celle 
 Gated Recurrent Unit (GRU)
 , con un numero minore di gate, sono 
state proposte per tale scopo, 
41"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#41,41,"Celle GRU
Le celle 
 Gated Recurrent Unit
  (
GRU
 ) sono una versione sempli
 ﬁ
cata, e con 
meno parametri, delle LSTM. In molti task mostrano prestazioni simili con 
tempi di addestramento ridotti.  
Le sempli
 ﬁ
cazioni sono le seguenti:  
•
Entrambi i vettori di stato sono fusi in un singolo vettore 
 h
(t)
. 
•
Un singolo 
 update gate  
z
(t)
 rappresenta una fusione del 
 forget
  e 
input gate
 . 
La funzione 
 keras.layers.GRU
  è impiegata in modo simile a SimpleRNN e 
LSTM.
42
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#42,42,"Celle GRU (2)
Intuitivamente il 
 reset gate
  r(t)
 controlla quanto dello stato precedente 
vogliamo mantenere nelle successive elaborazioni.  
L'
update gate  
z(t)
 controlla quanto il nuovo stato sia copia dello stato 
precedente.  
Entrambi i gate sono implementati con una FC e funzione di attivazione 
sigmoid
 , perciò con output in (0,1).
43
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#43,43,"Celle GRU (3)
Il 
hidden state candidato h(t) 
 (candidato poiché dobbiamo ancora sommare la 
componente del 
 update gate
 ) sarà generato combinando insieme 
 x(t)
 e 
l'output del reset gate 
 r(t)
, e impiegando una funzione di attivazione 
 tanh
. 
Quando il  
reset gate  
ha output pari a 1, otteniamo una RNN tradizionale. Se il 
gate
 genera 0, l'hidden state candidato coincide con l'output della FC con 
 x(t) 
come input. Perciò l'hidden state sarà resettato. 
44
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#44,44,"Celle GRU (4)
Il 
hidden state h(t)  
dipende dal 
 update gate
 , che determina quanto il nuovo 
stato corrisponde al vecchio oppure al nuovo stato candidato.  
Quando l'
 update gate
  è 1, manteniamo lo stato così com'è, e l'informazione 
x(t) non sarà considerata per alterarlo. Perciò ignoriamo lo step corrente nella 
catena di correlazioni che stiamo rappresentando con lo stato. Se l'output del 
gate è 0, lo stato corrisponde al candidato che abbiamo appena creato.
45
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#5,5,"Nodi Ricorrenti
Finora abbiamo considerato reti neurali 
 feedforward
 , dove le attivazioni si 
propagano
  dall'input all'output layer.   
Le 
RNN
  sono simili alle reti feedforward, ma hanno connessioni anche 
 verso i 
layer precedenti
 , creando una specie di ciclo.  
La più semplice 
 RNN
  consiste in un 
 nodo ricorrente 
 (o
 recurrent neuron
 ) 
che 
riceve l'input 
 x
, produce in output 
 y,
 e lo stesso output viene 
 riproposto
  in input.  
•
Ad ogni 
 iterazione  
t
, (o 
step
, o 
frame
 ), il nodo ricorrente riceve l'input 
 x
(t)
 e 
l'output precedente 
 y
(t-1)
. Il valore 
 y
(t)
 alla prima iterazione si considera pari a 0.  
La RNN si può rappresentare esplicitando l'asse temporale (
 unrolling the 
network through time
 ).
6
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#6,6,"Nodi Ricorrenti e Layers
Se 
x
(t) 
e 
y
(t-1)
 sono vettori, i parametri che de
 ﬁ
niscono il comportamento di un 
nodo ricorrente consistono in due vettori di pesi: 
 w
x
 e 
w
y
.  
L'
output  
di un singolo nodo
  si ricava nel modo usuale:  
 
Un
 layer di nodi ricorrenti 
 comprende più nodi, ed i parametri saranno 
perciò rappresentati da due matrici 
  e 
 .
y
(
t
)
=
σ
(
w
T
x
x
(
t
)
+
w
T
y
y
(
t
−
1
)
+
b
)
W
x
W
y
layer di nodi ricorrenti"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#7,7,"Nodi ricorrenti: calcolo degli output
Nel caso più generale di
  un layer di nodi ricorrenti 
 con un input costituito da 
vettori
 , cioè istanze rappresentate con più features:  
  dove:  
•
  è una matrice 
 m
n
nodi
, che contiene gli output del layer di 
 n
nodi
 nodi 
ricorrenti, per ognuna delle 
 m
 istanze all'interno del mini-batch,  
•
  è una matrice 
 m
n
inputs
, dove 
 n
inputs
 sono il numero di features in input,  
•
  è la matrice 
 n
inputs
 n
nodi
 dei pesi delle connessioni per le istanze in input,  
•
  è la matrice 
 n
nodi
n
nodi
 dei pesi delle connessioni per i valori in output 
ottenuti nello step precedente.  
•
Si può dire che una RNN è una feedforward NN dove i parametri di ogni 
layer sono condivisi (cioè sono gli stessi) per tutti i time steps.
Y
(
t
)
=
σ
(
x
(
t
)
W
x
+
y
(
t
−
1
)
W
y
+
b
)
y
(
t
)
×
x
(
t
)
×
W
x
×
W
y
×
8"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#8,8,"Nodi ricorrenti: forma compatta
Le matrici dei pesi 
  e 
   sono spesso 
 concatenate
  verticalmente in una 
singola matrice (
 n
inputs
+n
nodi
)
n
nodi 
La notazione 
  rappresenta la concatenazione delle matrici 
  
In questo modo si ottiene la seguente 
 forma compatta
 : 
   con    
È chiaro che 
  è funzione di 
  e 
 , quest'ultimo è funzione di 
  e 
, che è funzione di 
  e 
 , e così via.  
Di conseguenza  
dipende da tutti i valori in input 
 ﬁ
no a 
t=0
. 
Si può dire che il nodo contiene memoria di tutti gli input precedenti. In realtà 
i pattern che può riconoscere non sono lunghi tipicamente più di 10 steps.
W
x
W
y
×
[
X
(
t
)
Y
(
t
−
1
)
]
X
(
t
)
 e 
Y
(
t
−
1
)
σ
(
[
X
(
t
)
Y
(
t
−
1
)
]
W
+
b
)
 W
=
[
W
x
W
y
]
Y
(
t
)
 X
(
t
)
Y
(
t
−
1
)
 X
(
t
−
1
)
Y
(
t
−
2
)
 X
(
t
−
2
)
Y
(
t
−
3
)
Y
(
t
)
9"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#9,9,"Memory Cells
Una rete neurale in grado di tenere traccia degli stati in cui si è trovata nelle 
passate iterazioni si chiama 
 memory cell
  (o 
cell
). 
•
Un singolo
  recurrent node,
  o un layer di tali nodi, è una 
 cella
 elementare, in 
grado di riconoscere piccoli patterns, tipicamente non più lunghi di 10 steps.  
Indichiamo 
 stato
  di una cella all'istante 
 t
 con la notazione 
 , dove 
 h
 sta per 
hidden
 . Lo stato dipende dall'input corrente e dallo stato precedente:  
 
•
Anche l'
 output  
 dipende dalle stesse quantità.  
Nelle celle elementari 
 output
  e 
stato  
coincidono
 , ma nelle celle più 
complesse non sempre accade, come nel seguente esempio:
h
(
t
)
h
(
t
)
=
f
(
h
(
t
−
1
)
,
x
(
t
)
)
y
(
t
)
10
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #2
1"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#1,1,"Sommario
1d convolution per sequenze  
WaveNet  
Deep RNN  
Bidirectional RNN  
Encoder-decoder e Keras  
Esercizi"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#10,10,"Bidirectional RNN - motivazioni
Finora abbiamo visto scenari di predizione dove un valore in output dipende 
dai valori precedenti (es. predizione di una parola data una frase iniziale).  
In altri task è utile considerare il contesto di un valore in entrambe le 
direzioni, es. Part-of-speech tagging.  
•
Ad esempio, nel seguente task tentiamo di predire il token mancante dal 
testo dato come input:
11
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#11,11,"Bidirectional RNN
Nelle Bidirectional RNN abbiamo 2 layer unidirezionali con direzioni opposte, 
che operano sul medesimo input. Nel primo layer, il primo input è 
 x
1
 e l'ultimo 
x
T
, nel secondo il primo input è 
 x
T
 e l'ultimo 
 x
1
. 
L'output è generato concatenando l'output dei 2 layers.  
•
Nel caso multilayer, l'output diverrà l'input dei successivi 2 layers 
bidirezionali, e così via 
 ﬁ
no al layer di output.  
In Keras sono implementate con il parametro 
 bidirectional=
 True
.
12
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#12,12,"Architettura Encoder-decoder - Keras
14-encoder_decoder_interfaces.ipynb
13
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#13,13,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?
14"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#14,14,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?  
Sequence-to-sequence: previsioni meteo, machine translation (con Encoder-
decoder), video captioning, speech to text, music generation, identi
 ﬁ
care 
accordi nella musica.  
Sequence-to-vector: classi
 ﬁ
care brani musicali in base al genere, analizzare il 
sentimento di una recensione di un libro, predire quale parola sta pensando un 
paziente afasico in base ai segnali di impianti cerebrali, stimare la probabilità 
di vedere un certo 
 ﬁ
lm in base ai 
 ﬁ
lm visti in passato.  
Vector-to-sequence: image captioning, creare una playlist di musica in base agli 
embedding dell'artista corrente, generare una melodia in base a dei parametri, 
identi
 ﬁ
care pedoni in una foto.
15"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#15,15,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?
16"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#16,16,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?  
Un layer RNN deve avere input 3 dimensionali: la prima dimensione è la 
dimensione del batch (cioè il numero di time series), la seconda rappresenta il 
dimensione temporale, e la terza indica il numero di features per step.  
L'output sarà ancora 3 dimensionale, con le stesse 2 dimensioni dell'input, ma 
con l'ultima dimensione uguale al numero di nodi. 
17"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#17,17,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?
18"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#18,18,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?  
Per una sequence-to-sequence, il parametro è True per tutti i layer.  
Per una sequence-to-vector, il parametro è True per tutti gli RNN layers eccetto 
l'ultimo layer, impostato a False.
19"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#19,19,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?
20"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#2,2,"1d convolution per le sequenze
Sebbene popolari, 
 LSTM
  e 
GRU
  non sono adatte a sequenze che contengono 
pattern signi
 ﬁ
cativi che si estendo per molti steps (es. 100). Una alternativa è 
ridurre
  la lunghezza delle sequenze in input.  
Impieghiamo le 
 1d convolution
  sulle sequenze in input considerando come 
profondità la dimensione temporale piuttosto che spaziale. Fissiamo segmenti 
di dimensioni prede
 ﬁ
nita sulle sequenze in input per creare tali sequenze che 
corrispondono alle dimensioni del kernel.  
Estendiamo l'approccio considerando più 
 ﬁ
ltri 1d convolution.  Ogni 
 ﬁ
ltro 
riconoscerà determinati pattern.  
•
Ad esempio, con 10 kernels, l'output complessivo del layer consisterà in 10 
sequenze 1-dimensionali, tutte della stessa lunghezza, o una singola 
sequenza 10-dimensionale.  
Possiamo avere reti che alternano layer 1d convolution e layer ricorrenti, ed 
eventualmente layer di pooling. In questo modo le celle analizzeranno dati 
temporali più 
 compatti
 . Oppure possiamo avere reti costituite interamente da 
moduli convolutivi (es. WaveNet).
3"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#20,20,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?  
L'architettura più semplice è una sequence-to-vector, cioè uno stack di RNN 
layers (tutti con return_sequences=True eccetto il primo), con 7 nodi nel layer 
di output. Si addestra il modello con 
 ﬁ
nestre random dalle time series (es. 
sequence di 30 giorni consecutivi e un vettore contenente i valori dei successivi 
7 giorni come target).  
In alternativa si imposta return_sequences=True per tutti i layer creando una 
sequence-to-sequence. Per l'addestramento si usano random windows con la 
stessa lunghezza del target. 
21"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#21,21,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?
22"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#22,22,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?  
Le due maggiori problematiche sono l'instabilità dei gradienti e la short-term 
memory limitata. I problemi peggiorano in presenza di sequenze molto lunghe.  
Per affrontarli si usano learning rate più bassi, funzioni di attivazioni che 
saturano ed eventualmente gradient clipping, layer normalization o dropout ad 
ogni step. Per la short-term memory, si impiegano celle LSTM o GRU.
23"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#23,23,"RNN - LSTM
Rappresenta l'architettura LSTM gra
 ﬁ
camente.
24"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#24,24,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?
25"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#25,25,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?  
Una RNN opera sequenzialmente: per calcolare l'output al tempo t, deve prima 
calcolare gli output degli step precedenti. Questo rende impossibile 
parallelizzare l'elaborazione.  
La 1d conv non mantiene uno stato tra elaborazioni successive perciò e 
facilmente parallelizzabile. Non essendo ricorrente, è meno affetta da gradienti 
instabili.  
Più 1d conv possono processare l'input riducendo la risoluzione temporale 
(downsampling) permettendo di analizzare time series molto lunghe.  
Infatti la WaveNet analizza time series impiegando solo 1d conv.
26"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#26,26,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video? 
27"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#27,27,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video?  
Prendiamo un frame per secondo e lo diamo in input a una rete 
convoluzionale. L'output della CNN è passato in input a una sequence-to-
vector RNN, il cui output è passato a una layer softmax, ottenendo una 
distribuzione di probabilità sulle classi.  
La funzione di costo può essere una cross entropy.  
Per usare l'audio si possono impiegare layer 1d conv, per ridurre la risoluzione 
da migliaia di audio frames per secondo a 1 solo per secondo, così da 
sincronizzarsi rispetto ai frame, e concatenare l'output con l'input alla 
sequence-to-vector.
28"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#28,28,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow.
29
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#29,29,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow. 
DOWNLOAD_ROOT = 
 ""http://download.tensorflow.org/data/""
FILENAME = 
 ""quickdraw_tutorial_dataset_v1.tar.gz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/quickdraw""
 ,
                                extract=
 True
)
quickdraw_dir = Path(filepath).parent
train_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""training.tfrecord-*""
 )])
eval_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""eval.tfrecord-*""
 )])
with 
open
(quickdraw_dir / 
 ""eval.tfrecord.classes""
 ) 
as
 test_classes_file:
    test_classes = test_classes_file.readlines()
    
with 
open
(quickdraw_dir / 
 ""training.tfrecord.classes""
 ) 
as
 train_classes_file:
    train_classes = train_classes_file.readlines()
assert
 train_classes == test_classes
class_names = [name.strip().lower() 
 for
 name 
in
 train_classes]
sorted
(class_names)
30"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#3,3,"1d convolution per le sequenze: esempio
Il modello include una 
 1d conv 
 che opera una sorta di 
 downsampling
  delle 
sequenze in input di un fattore 2 impiegano uno stride 2. Il kernel è più grande 
dello stride perciò tutta l'informazione verrà considerata.  
Riducendo la lunghezza in input sarà più facile per la GRU riconoscere pattern 
più lunghi.  
model = keras.models.Sequential([
    keras.layers.Conv1D(filters=
 20
, kernel_size=
 4
, strides=
 2
, 
padding=
 ""valid""
,
                        input_shape=[
 None
, 
1
]),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, 
metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train[:, 
 3
::
2
], epochs=
 20
,
                    validation_data=(X_valid, Y_valid[:, 
 3
::
2
]))
•
Nota: Avendo kernel di dimensione 4, è opportuno ignorare i primi 3 step nei valori target, e 
fare dowsampling dei target di un fattore 2.
4"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#30,30,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
def 
parse
(
data_batch
 ):
    feature_descriptions = {
        
 ""ink""
: tf.io.VarLenFeature(dtype=tf.float32),
        
 ""shape""
: tf.io.FixedLenFeature([
 2
], dtype=tf.int64),
        
 ""class_index""
 : tf.io.FixedLenFeature([
 1
], dtype=tf.int64)
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[
 ""ink""
])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), 
 -1
, 
3
])
    lengths = examples[
 ""shape""
][:, 
0
]
    labels = examples[
 ""class_index""
 ][:, 
0
]
    
return
 sketches, lengths, label
 s
def 
quickdraw_dataset
 (
filepaths
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                      
 n_parse_threads
 =
5
, 
n_read_threads
 =
5
, 
cache
=
False
)
:
    dataset = tf.data.TFRecordDataset(filepaths
 ,
                                      num_parallel_reads=n_read_threads
 )
    
if
 cache
:
        dataset = dataset.cache(
 )
    
if
 shuffle_buffer_size
 :
        dataset = dataset.shuffle(shuffle_buffer_size
 )
    dataset = dataset.batch(batch_size
 )
    dataset = dataset.
 map
(parse, num_parallel_calls=n_parse_threads
 )
    
return
 dataset.prefetch(
 1
)
31"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#31,31,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
train_set = quickdraw_dataset(train_files, shuffle_buffer_size=
 10000
)
valid_set = quickdraw_dataset(eval_files[:
 5
]
)
test_set = quickdraw_dataset(eval_files[
 5
:]
)
def 
draw_sketch
 (
sketch
, 
label
=
None
)
:
    origin = np.array([[
 0
., 
0
., 
0
.]]
)
    sketch = np.r_[origin, sketch
 ]
    stroke_end_indices = np.argwhere(sketch[:, 
 -1
]==
1
.)[:, 
0
]
    coordinates = np.cumsum(sketch[:, :
 2
], axis=
 0
)
    strokes = np.split(coordinates, stroke_end_indices + 
 1
)
    title = class_names[label.numpy()] 
 if
 label 
is 
not 
None 
else 
""Try to guess""
    plt.title(title
 )
    plt.plot(coordinates[:, 
 0
], -coordinates[:, 
 1
], 
""y:""
)
    
for
 stroke 
 in
 strokes
 :
        plt.plot(stroke[:, 
 0
], -stroke[:, 
 1
], 
"".-""
)
    plt.axis(
 ""off""
)
def 
draw_sketches
 (
sketches
 , 
lengths
, 
labels
)
:
    n_sketches = 
 len
(sketches
 )
    n_cols = 
 4
    n_rows = (n_sketches - 
 1
) // n_cols + 
 1
    plt.figure(figsize=(n_cols * 
 3
, n_rows * 
 3.5
)
)
    
for
 index, sketch, length, label 
 in 
zip
(
range
(n_sketches), sketches, lengths, labels)
 :
        plt.subplot(n_rows, n_cols, index + 
 1
)
        draw_sketch(sketch[:length], label
 )
    plt.show()
32"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#32,32,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
for
 sketches, lengths, labels 
 in
 train_set.take(
 1
)
:
    draw_sketches(sketches, lengths, labels
 )
lengths = np.concatenate([lengths 
 for
 _, lengths, _ 
 in 
train_set.take(
 1000
)]
)
plt.hist(lengths, bins=
 150
, density=
 True
)
plt.axis([
 0
, 
200
, 
0
, 
0.03
]
)
plt.xlabel(
 ""length""
 )
plt.ylabel(
 ""density""
 )
plt.show(
 )
def 
crop_long_sketches
 (
dataset
, 
max_length
 =
100
)
:
    
return
 dataset.
 map
(
lambda
 inks, lengths, labels: 
(inks[:, :max_length], labels)
 )
cropped_train_set = crop_long_sketches(train_set
 )
cropped_valid_set = crop_long_sketches(valid_set
 )
cropped_test_set = crop_long_sketches(test_set
 )
33"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#33,33,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
model = keras.models.Sequential(
 [
    keras.layers.Conv1D(
 32
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 64
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 128
, kernel_size=
 3
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.LSTM(
 128
, return_sequences=
 True
)
,
    keras.layers.LSTM(
 128
)
,
    keras.layers.Dense(
 len
(class_names), activation=
 ""softmax""
 )
]
)
optimizer = keras.optimizers.SGD(lr=
 1e-2
, clipnorm=
 1
.
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 ,
              optimizer=optimizer
 ,
              metrics=[
 ""accuracy""
 , 
""sparse_top_k_categorical_accuracy""
 ]
)
history = model.fit(cropped_train_set, epochs=
 2
,
                    validation_data=cropped_valid_set
 )
y_test = np.concatenate([labels 
 for
 _, _, labels 
 in
 test_set]
 )
y_probas = model.predict(test_set)
34"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#34,34,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas)
 )
n_new = 
 10
Y_probas = model.predict(sketches
 )
top_k = tf.nn.top_k(Y_probas, k=
 5
)
for
 index 
in 
range
(n_new)
:
    plt.figure(figsize=(
 3
, 
3.5
)
)
    draw_sketch(sketches[index]
 )
    plt.show(
 )
    
print
(
""Top-5 predictions:""
 .
format
(index + 
 1
)
)
    
for
 k 
in 
range
(
5
)
:
        class_name = class_names[top_k.indices[index, k]
 ]
        proba = 
 100
 * top_k.values[index, k
 ]
        
 print
(
""  {}. {} {:.3f}%""
 .
format
(k + 
1
, class_name, proba)
 )
    
print
(
""Answer: {}""
 .
format
(class_names[labels[index].numpy()])
 )
model.save(
 ""my_sketchrnn""
 )
35"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#35,35,"RNN - Generazione di musica
Scarica il dataset Bach chorales e scompattalo. Consiste in 382 corali composti 
da Johann Sebastian Bach. Ogni corale è lungo da 100 a 640 time steps, e ogni 
step contiene 4 interi, dove ogni interno corrisponde alla nota su un piano. Lo 0 
indica che che non si suona alcuna nota.  
Addestra un modello ricorrente o convoluzionale, o entrambi, che può predire 
il successivo step (4 note), data una sequenza del corale. Usa quello modello 
per generare musica in stile Bach, ad esempio dando in input l'inizio di un 
corale e ottenendo la predizione che userai come successivo input.  
In
ﬁ
ne dai un'occhiata al Google Coconet model.  
36"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#36,36,"RNN - Generazione di musica
DOWNLOAD_ROOT = 
 ""https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/""
FILENAME = 
 ""jsb_chorales.tgz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/jsb_chorales""
 ,
                                extract=
 True
)
jsb_chorales_dir = Path(filepath).parent
train_files = 
 sorted
(jsb_chorales_dir.glob(
 ""train/chorale_*.csv""
 ))
valid_files = 
 sorted
(jsb_chorales_dir.glob(
 ""valid/chorale_*.csv""
 ))
test_files = 
 sorted
(jsb_chorales_dir.glob(
 ""test/chorale_*.csv""
 ))
import
 pandas 
 as
 pd
def 
load_chorales
 (
filepaths
 ):
    
return
 [pd.read_csv(filepath).values.tolist() 
 for
 filepath 
 in
 filepaths]
train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)
train_chorales[
 0
]
notes = set()
for
 chorales 
 in
 (train_chorales, valid_chorales, test_chorales):
    
for
 chorale 
 in
 chorales:
        
 for
 chord 
in
 chorale:
            notes |= set(chord)
n_notes = 
 len
(notes)
min_note = 
 min
(notes - {
 0
})
max_note = 
 max
(notes)
37"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#37,37,"RNN - Generazione di musica
assert
 min_note == 
 36
assert
 max_note == 
 81
from
 IPython.display 
 import
 Audio
def 
notes_to_frequencies
 (
notes
):
    
# Frequency doubles when you go up one octave; there are 12 semi-tones
    
# per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    
return 
2
 ** ((np.array(notes) - 
 69
) / 
12
) * 
440
def 
frequencies_to_samples
 (
frequencies
 , 
tempo
, 
sample_rate
 ):
    note_duration = 
 60
 / tempo 
 # the tempo is measured in beats per minutes
    
# To reduce click sound at every beat, we round the frequencies to try to
    
# get the samples close to zero at the end of each note.
    frequencies = np.
 round
(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(
 0
, note_duration, n_samples)
    sine_waves = np.sin(
 2
 * np.pi * frequencies.reshape(
 -1
, 
1
) * time)
    
# Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 
 9
.).reshape(
 -1
, 
1
)
    
return
 sine_waves.reshape(
 -1
)
def 
chords_to_samples
 (
chords
, 
tempo
, 
sample_rate
 ):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[
 -1
:]] 
# make last note a bit longer
    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)
                     
 for
 melody 
 in
 freqs.T], axis=
 0
)
    n_fade_out_samples = sample_rate * 
 60
 // tempo 
 # fade out last note
    fade_out = np.linspace(
 1
., 
0
., n_fade_out_samples)**
 2
    merged[-n_fade_out_samples:] *= fade_out
    
return
 merged
38"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#38,38,"RNN - Generazione di musica
def 
play_chords
 (
chords
, 
tempo
=
160
, 
amplitude
 =
0.1
, 
sample_rate
 =
44100
, 
filepath
 =
None
):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    
if
 filepath:
        
 from
 scipy.io 
 import
 wavfile
        samples = (
 2
**
15
 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        
 return
 display(Audio(filepath))
    
else
:
        
 return
 display(Audio(samples, rate=sample_rate))
for
 index 
in 
range
(
3
):
    play_chords(train_chorales[index])
def 
create_target
 (
batch
):
    X = batch[:, :
 -1
]
    Y = batch[:, 
 1
:] 
# predict next note in each arpegio, at each step
    
return
 X, Y
def 
preprocess
 (
window
):
    window = tf.where(window == 
 0
, window, window - min_note + 
 1
) 
# shift values
    
return
 tf.reshape(window, [
 -1
]) 
# convert to arpegio
def 
bach_dataset
 (
chorales
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                 
 window_size
 =
32
, 
window_shift
 =
16
, 
cache
=
True
):
    
def 
batch_window
 (
window
):
        
 return
 window.batch(window_size + 
 1
)
    
def 
to_windows
 (
chorale
):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 
 1
, window_shift, drop_remainder=
 True
)
        
 return
 dataset.flat_map(batch_window)
    chorales = tf.ragged.constant(chorales, ragged_rank=
 1
)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).
 map
(preprocess)
    
if
 cache:
        dataset = dataset.cache()
    
if
 shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.
 map
(create_target)
    
return
 dataset.prefetch(
 1
)
39"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#39,39,"RNN - Generazione di musica
train_set = bach_dataset(train_chorales, shuffle_buffer_size=
 1000
)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)
n_embedding_dims = 
 5
model = keras.models.Sequential([
    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,
                           input_shape=[
 None
]),
    keras.layers.Conv1D(
 32
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 48
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 2
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 64
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 4
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 96
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 8
),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(
 256
, return_sequences=
 True
),
    keras.layers.Dense(n_notes, activation=
 ""softmax""
 )
])
model.summary()
optimizer = keras.optimizers.Nadam(lr=
 1e-3
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 , optimizer=optimizer,
              metrics=[
 ""accuracy""
 ])
model.fit(train_set, epochs=
 20
, validation_data=valid_set)
model.save(
 ""my_bach_model.h5""
 )
model.evaluate(test_set)
40"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#4,4,"Architettura WaveNet
Le rete convolutiva 
 WaveNet
  impiega più layer 1d conv, dove ad ogni layer si 
raddoppia la lunghezza della LRF, chiamato anche 
 dilatation rate.
  In questo 
modo ogni layer raddoppia i dati analizzati rispetto al layer precedente.  
•
I primi layer riconoscono pattern 
 short-term
 , gli ultimi i pattern estesi.  
•
Per dilatation >1, i layer ignoreranno alcuni campioni all'interno del LRF che 
però saranno considerati nei layer precedenti.  
Il training è più rapido rispetto alle RNN non essendoci collegamenti ricorrenti.  
L'output può essere accodato all'input successivo per fare predizione (es. 
generazione voce umana).
5
stack of conv layers"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#40,40,"RNN - Generazione di musica
def 
generate_chorale
 (
model
, 
seed_chords
 , 
length
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note = model.predict_classes(arpegio)[:
 1
, 
-1
:]
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
seed_chords = test_chorales[
 2
][:
8
]
play_chords(seed_chords, amplitude=
 0.2
)
new_chorale = generate_chorale(model, seed_chords, 
 56
)
play_chords(new_chorale)
def 
generate_chorale_v2
 (
model
, 
seed_chords
 , 
length
, 
temperature
 =
1
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note_probas = model.predict(arpegio)[
 0
, 
-1
:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=
 1
)
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
41"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#41,41,"RNN - Generazione di musica
new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 0.8
)
play_chords(new_chorale_v2_cold, filepath=
 ""bach_cold.wav""
 )
new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.0
)
play_chords(new_chorale_v2_medium, filepath=
 ""bach_medium.wav""
 )
new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.5
)
play_chords(new_chorale_v2_hot, filepath=
 ""bach_hot.wav""
 )
play_chords(test_chorales[
 2
][:
64
], filepath=
 ""bach_test_4.wav""
 )
42"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#5,5,"6
1
2
3
4
https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio
Nella 
 WaveNet
  l'output layer ha la 
stessa dimensionalità temporale 
dell'input.  
Il singolo valore in output è prodotto 
da una 
 softmax
 , perciò con 
distribuzione sulle categorie 
disponibili.  
Le 
dilated convolution
  sono simili ai 
layer convolutivi con pooling e 
stride, ma in questo caso l'output ha 
la stessa dimensione dell'input.  
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#6,6,"WaveNet: esempio
Impostando il 
 padding  
causal
  si garantisce che l'input non conterrà dati oltre a 
quello attuale.  
Il parametro 
 dilatation_rate
  de
ﬁ
nisce l'architettura WaveNet.  
L'ultimo layer è convolutivo con 10 
 ﬁ
ltri di dimensione 1 senza funzione di 
attivazione. Ogni conv layer produce una sequenza della stessa lunghezza 
dell'input, cosicché possiamo usare i target senza ridimensionarli.  
Nell'esempio manca il layer softmax impiegato nell'esempio precedente.  
model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[
 None
, 
1
]))
for
 rate 
in
 (
1
, 
2
, 
4
, 
8
) * 
2
:
    model.add(keras.layers.Conv1D(filters=
 20
, kernel_size=
 2
, padding=
 ""causal""
 ,
                                  activation=
 ""relu""
, dilation_rate=rate))
model.add(keras.layers.Conv1D(filters=
 10
, kernel_size=
 1
))
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=
 20
,
                    validation_data=(X_valid, Y_valid))
7"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#7,7,"Deep RNN
Finora abbiamo visto RNN con un singolo hidden layer ricorrente, uno strato 
di input e uno di output. Le memory cell permettono di creare correlazioni 
che in
 ﬂ
uenza step anche distanti tra loro (direzione temporale).  
Nelle Deep RNN si vogliono identi
 ﬁ
care correlazioni anche tra input e output 
nello stesso step (direzione input-output). Per questo si considerano più layer 
stacked 
 sequence-to-sequence.  
•
Il primo layer produce una sequenza in output di lunghezza T, che sarà 
l'input del successivo layer.  
•
Ogni cella perciò dipenderà dai valori  
del layer negli step precedente, e dai  
valori generati dai layer precedenti nello  
stesso step.  
Architetture comuni di RNN hanno  
lunghezza (
 numero di step
 ) nel range  
64-2056 e profondità in 1-8.
8
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#8,8,"Deep RNN - Keras (1)
12-deep_rnn.ipynb
9"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#9,9,"Deep RNN - Keras (2)
In alternativa alla classe GRU possiamo operare uno stacking impiegando 
Sequential:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.SimpleRNN(
 1
)
])”
Nota
 : ricordati di impostare return_sequences=
 True
 per ogni layer (tranne 
l'ultimo se ci interessa in output solo l'ultimo valore), altrimenti l'output del 
layer sarà 2D (solo l'ultimo valore) e si crea un mismatch con l'input atteso in 
3D dal successivo layer.
10"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Attention mechanisms e Transformers
1"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#1,1,"Sommario
Beam search  
Attention mechanism  
Multi-head attention  
Self-attention  
Transformers  
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#10,10,"Beam search (2)
La complessità è pari a 
 O
(
k·
|
Y
|·
T'
)
, dove 
 T'
 è il numero massimo di token 
della sequenza in output, e 
 Y
 è il vocabolario.  
Al contrario dell'approccio greedy, la beam search permette di scegliere alcuni 
token meno probabili, sebbene la frase nel suo complesso generi accuracy 
migliori.  
Una ricerca esaustiva di tutte le possibili combinazioni richiederebbe 
complessità 
 O
(|
Y
|
T'
).
11"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#11,11,"Attention cues
Il meccanismo si ispira a studi di neuroscienze cognitive, dove si tenta di dare 
attenzione solo ad una parte degli stimoli generati dal sistema di visione.  
•
le 
nonvolitional cues
  (
keys
) sono legate alla visibilità dell'oggetto 
nell'ambiente (es. tazza di caffè rossa su un tavolino grigio),  
•
le 
volitional cue
  (o 
query
 ) dipendono dal task che stiamo seguendo (es. 
leggere un libro su un tavolo).  
Se abbiamo dei 
 sensory inputs
  da analizzare, la 
 query
  interagisce con le 
 keys 
per selezionare gli input più corretti.  
L'
attention pooling
  aggrega gli input per generare l'output.
12
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#12,12,"Attention pooling e Keras
Ci sono vari modi di implementare l'attention pooling. Qui diamo un esempio 
basato sul modello di regressione Nadaraya-Watson kernel.  
Generiamo un dataset arti
 ﬁ
ciale con questo modello:  
con epsilon generato con distribuzione normale media 0 e varianza 0.5, e 50 
istanze di training e test.  
class 
NonlinearData
 (
d2l
.
DataModule
 ):
    
def 
__init__
 (
self
, 
n
, 
batch_size
 ):
        
 self
.save_hyperparameters()
        f = 
 lambda
 x: 
2
 * tf.sin(x) + x**
 0.8
        
 self
.x_train = tf.sort(tf.random.uniform((n,
 1
)) * 
5
, 
0
)
        
 self
.y_train = f(
 self
.x_train) + tf.random.normal((n,
 1
))
        
 self
.x_val = tf.
 range
(
0
, 
5
, 
5.0
/n)
        
 self
.y_val = f(
 self
.x_val)
    
def 
get_dataloader
 (
self
, 
train
):
        arrays = (
 self
.x_train, 
 self
.y_train) 
 if
 train 
else
 (
self
.x_val, 
 self
.y_val)
        
 return 
self
.get_tensorloader(arrays, train)
n = 
50
data = NonlinearData(n, batch_size=
 10
)
13
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#13,13,"Attention pooling e Keras (2)
Gra
ﬁ
chiamo gli esempi di training (cerchi), il ground truth senza rumore 
(curva blu) la funzione generata per la prediction (tratteggiata rossa).  
Proviamo con l'estimator più facile: 
 average pooling
  sui dati di input:  
y_hat = tf.repeat(tf.reduce_mean(data.y_train), n)
plot_kernel_reg(y_hat)
def 
plot_kernel_reg
 (
y_hat
):
    d2l.plot(data.x_val, [data.y_val, y_hat.numpy()], 
 'x'
, 
'y'
, legend=[
 'Truth'
, 
'Pred'
],
             xlim=[
 0
, 
5
], ylim=[
 -1
, 
5
])
    d2l.plt.plot(data.x_train, data.y_train, 
 'o'
, alpha=
 0.5
);
14"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#14,14,"Attention pooling e Keras (3)
Nel seguente nonparametric attention pooling chiamato 
 Nadaraya-Watson 
kernel regression 
 pesiamo gli output in base alla posizione degli input.  
dove K è il kernel. Generalizzandolo (non serve ora studiare i dettagli del 
regressore) possiamo de
 ﬁ
nire un qualsiasi 
 attention pooling
  nel seguente 
modo:  
dove 
 x
 è la 
 query
 , e (
x
i
,y
i
) e la coppia 
 chiave-valore
 . Perciò ogni valore 
 y
i
 è 
pesato e si può pensare come una distribuzione di probabilità sull'insieme 
chiavi-valore.  
15
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#15,15,"Attention pooling e Keras (4)
Gra
ﬁ
cando l'output del nuovo modello otteniamo:  
def 
diff
(
queries
, 
keys
):
    
return
 tf.reshape(queries, (
 -1
, 
1
)) - tf.reshape(keys, (
 1
, 
-1
))
def 
attention_pool
 (
query_key_diffs
 , 
values
):
    attention_weights = tf.nn.softmax(- query_key_diffs**
 2
/
2
, axis=
1
)
    
return
 tf.matmul(attention_weights, values), attention_weights
y_hat, attention_weights = attention_pool(
    diff(data.x_val, data.x_train), data.y_train)
plot_kernel_reg(y_hat)
16
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#16,16,"Attention pooling e Keras (5)
Analizzando i pesi generati dell'attention pooling, con le 
 query
  come 
validation inputs
  e 
keys
 come 
 training inputs
 , notiamo come all'avvicinarsi dei 
valori tra 
 query
  e 
chiave
 , i pesi sono più signi
 ﬁ
cativi:  
d2l.show_heatmaps([[attention_weights]],
                  xlabel=
 'Sorted training inputs'
 ,
                  ylabel=
 'Sorted validation inputs'
 )
17
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#17,17,"Attention Scoring functions
L'output dell'
 attention mechanism
  possiamo valutarlo con una 
 softmax
  e 
interpretarlo come distribuzione di probabilità sui valori che sono in paio con 
le chiavi.  
18
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#18,18,"Multi-head attention
L'attention mechanism potrebbe richiedere di analizzare dipendenze su vari 
intervalli (short e long-range) all'interno delle sequenze. Invece di un singolo 
pooling, possiamo generare 
 h
 proiezioni lineari indipendenti. Gli 
 h
 output 
sono concatenati e passati ad una combinazione lineare 
 ﬁ
nale per produrre 
l'output. Ognuna delle 
 h 
attention pooling
  è chiamato 
 head
 .
19
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#19,19,"Self-attention e positional encoding
Supponiamo che in input all'attention mechanism diamo una sequenza di 
tokens. I tokens rappresentano perciò sia le query, le chiavi e i valori. Ogni 
query è relativa e tutte le coppie chiave-valore e genera un output. Per tale 
motivo si parla di 
 self-attention
 . 
Si può dimostrare facilmente che le CNN e i self-attention possono essere 
implementati con computazioni parallele, sebbene sequenze molto lunghe 
penalizzano molto i self-attention.  
Possiamo aggiungere informazioni aggiuntive, come quelle associate alla 
posizione, alla rappresentazione in input del self-attention, poiché durante i 
calcoli queste informazioni vengono ignorate, a differenza delle RNN.
20"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#2,2,"Introduzione
In una architettura 
 encoder-decoder,
  durante la traduzione di un testo notiamo 
come alcune parole generate dal decoder dipendano da poche parole in input 
al encoder. Se le frasi sono molte lunghe, una RNN fa fatica a identi
 ﬁ
care tali 
dipendenze.  
Gli 
attention mechanism 
 introdotti nel 2014 da Bahdanau et al.
(1)
 risolvono in 
parte le limitazioni della memoria delle RNN, arrivando a processare frasi di 
30 parole circa.  
Gli attention mechanism sono alla base dell'architettura 
 Transformers
 , che è 
lo stato dell'arte nel campo dell'NLP in molti task, es. machine language 
translation, conversational chatbots, e per migliorare le performance dei 
search engines.  
L'obiettivo degli 
 attention mechanism 
 è assegnare un livello di importanza alle 
features e sfruttarlo per agevolare il raggiungimento di un certo task. 
3 (1) https://arxiv.org/abs/1409.0473"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#20,20,"Attention mechanism e Encoder-decoder (1)
Nell'architettura 
 encoder-decoder con 
 attention mechanism
 , oltre all'ultimo 
hidden state propagato dal encoder al decoder (non visibile nel disegno), 
inviamo al decoder tutti i valori generati in output dal encoder
 . 
•
Ad ogni step, il 
 decoder
  calcola una combinazione lineare dei valori ottenuti 
in output dal encoder così da determinare su quale parola porre l'attenzione 
al successivo step.  
•
Il peso 
  è riferito al 
 i
-esimo output, allo step 
 t
-esimo...
 α
(
t
,
i
)
21
Nell'esempio, se  è 
maggiore di  e , 
allora il decoder 
assegnerà maggiore 
attenzione al termine 
""milk"" nello step corrente .
La restante elaborazione 
coincide l'architettura 
originale.α(3,2)
α(3,0)α(3,1)Questa con ﬁgurazione 
speci ﬁca di attention 
mechanism è anche 
chiamata:  
Bahdanau attention .  
 
Dato che concatena gli 
output del encoder con gli 
hidden state, si chiama 
anche: concatenative 
attention , o additive 
attention ."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#21,21,"Attention mechanism e Encoder-decoder (2)
I valori 
  sono generati da una rete neurale chiamata 
 alignment model  
(o 
attention layer)
  addestrata con il resto del encoder-decoder.  
•
Consiste in una 
 time-distributed Dense layer
  con un singolo nodo, che 
riceve tutti gli output dal encoder, concatenati con l'hidden state del decoder 
estratti dallo step precedente.  
•
Il layer produce una serie di valori e
 (3,0)
, e
(3,1)
, etc; che indicano 
 quanto ogni 
output è allineato con l'hidden state precedente
 . La 
softmax
  normalizza tali 
valori.
α
(
t
,
i
)
22
 rappresenta l'hidden 
state del decoder .
La rete densa richiede il 
calcolo di n2 parametri, 
supponendo n la 
lunghezza delle frasi in 
input e output. Ma se non 
abbiamo frasi lunghissime 
la complessità è ancora 
praticabile. h(2)"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#22,22,"Image captioning
In questo task occorre generare un testo signi
 ﬁ
cativo in linguaggio naturale 
che descrive una immagine. In altre parole dobbiamo dotare l'algoritmo di 
capacità di ""
 comprensione""
 . 
Usiamo un 
 encoder-decoder
 , dove il 
 decoder
  sfrutta l'
 attention mechanism
 . 
L'
encoder
  è una CNN, e le features sono estratte dal layer convolutivo. 
L'
attention mechanism
  avrà perciò informazione posizionale codi
 ﬁ
cata 
nell'input. Il 
 decoder
  usa lo stato precedente, il token generato in precedenza 
e un context vector per generare il nuovo token.
23 ...
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#23,23,"Image caption e Visual Attention
Il 
context vector
  è generato dall'
 attention mechanism 
 a partire dalle features 
della CNN nell'encoder. Esso rappresenta i pesi per ogni location spaziale 
dell'output dell'encoder (
 visual attention
 ).  
Ad ogni step il decoder usa l'attention model per identi
 ﬁ
care le giusta 
porzione dell'immagine da analizzare per poi per generare la frase.
24
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#24,24,"Explainability
Nel ML con 
 explainability
  si intende la capacità del modello di descrivere il 
suo comportamento in termini comprensibili all'uomo.  
•
Interpretability
  è un concetto simile, ma legato alle relazioni causa-effetto 
del modello, e perciò sulla capacità di stimare un certo output in base a una 
certa con
 ﬁ
gurazione di input. Si può avere interpretability senza 
explainability.  
Utile quando si vuole comprendere un certo output, eventualmente errato.  
•
Es. l'output ""un lupo che si muove sulla neve"" prodotto quando c'è un cane 
come input può dipendere dal fatto che il modello si focalizza sulla presenza 
della neve per classi
 ﬁ
care l'animale.  
I 
modelli DL 
 sono molto complessi e spesso 
 dif
ﬁ
cilmente esplorabili
 . 
Un tentativo è creare modelli interpretabili (es. alberi di decisione) a partire 
dagli output di un modello non interpretabile
(3)
, e usarli per costruire le 
motivazioni di un certo output.
25 (3) https://arxiv.org/abs/1602.04938"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#25,25,"Architettura Transformer - motivazioni
Computazionalmente, i modelli di attention e le 
CNN sono più veloci rispetto all RNN. I Transformer 
sono unicamente basati su tali modelli.  
In ""Attention is all you need""
(4)
, un team di Google 
propose l'architettura 
 Transformer
 , dove il task della 
traduzione dei testi si affronta senza RNN, ma 
principalmente con 
 layer embedding
 , 
dense layers
  e 
di 
normalization
 .  
Inizialmente proposti nel task 
 seq2seq
  sul testo, 
sono stati poi usati in svariati altri domini, es. 
visione, speech, reinforcement learning.  
L'encoder
  mappa le sequenze in input in una 
rappresentazione continua latente che incapsula 
tutte le informazioni rilevanti della sequenza.  
I multi-head attention creano associazioni tra una 
parola e le altre con un sistema di pesi.
26
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#26,26,"Architettura Transformer - (1)
Ad alto livello possiamo notare uno stack di layer 
multipli che si ripetono (
 N
 volte). Ognuno di questi 
macro-layer ha sotto layer.  
Nell'encoder si ha un 
 multi-head self-attention
  e un 
positionwise feed-forward network
 .  
Nell'
 encoder self-attention
 , queries, keys a values 
sono ottenuti dall'output del layer precedente. In 
modo simile alla ResNet, abbiamo connessioni 
residue.  
Lo stack del decoder oltre layer simili all'encoder 
abbiamo un ulteriore layer 
 encoder-decoder 
attention
  nel mezzo, che prende in input l'output 
del layer precedente nel decoder, e keys e values 
ottenuti dall'encoder. 
27
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#27,27,"Architettura Transformer - (2)
Nel decoder self-attention, queries, keys e values 
sono ottenuti dal layer precedente.  
Ogni posizione nel decoder interessa tutte le 
posizioni viste 
 ﬁ
no alla posizione corrente. Infatti 
nel training i dati sono noti, ma in produzione 
possiamo generare token che dipendono solo dai 
token già generati.  
La 
positionwise feed-forward network
  è composta 
da 2 layer FC e prende in input (batch size, number 
of time steps/sequence length in tokens, number of 
hidden units/feature dimension) e produce in output 
(batch size, number of time steps, ffn_num_outputs).  
I transfomer mantengono la proprietà 
 auto-
regressive
 , cioè l'output dipende linearmente dai 
valori prodotti in precedenza e da un termine 
stocastico.
28
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#28,28,"Architettura Transformer e NLP: dettagli (1)
29 (4) https://arxiv.org/abs/1706.03762
L'input si pre-processa come prima, ottenendo 
una
 rappresentazione in uno spazio a 512 
dimensioni
  (cioè uno shape [batch size, max 
input sentence length, 512]) mediante 
 word 
embeddings
 . 
L'output del decoder ha sempre forma di 
distribuzione di probabilità ([batch size, max 
output sentence length, vocabulary length])  
Il 
decoder
  prende in input la frase target 
traslata di 1 posizione.  
Ad ognuno dei 
 N
 livelli, l'output del 
 encoder  
è inviato in input al 
 encoder-decoder attention  
nel corrispondete livello del 
 decoder
 .EncoderDecoder"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#29,29,"Architettura Transformer e NLP: dettagli (2)
In produzione ancora una volta l'output del decoder (una nuova parola) verrà 
accodata all'input del decoder allo step successivo.
30 (4) https://arxiv.org/abs/1706.03762
Sia encoder sia decoder, oltre agli layer 
embedding, hanno 
 5
N skip connections
 , 
ognuna seguita da una layer di 
normalizzazione
 . 
Le 
positionwise feed-forward
  network sono 
reti MLP
  tradizionali con 2 Dense layer 
ciascuna, il primo layer con attivazione 
ReLU, il secondo senza attivazione. Il 
 layer 
di output
  è una layer denso con softmax.  
Tutti i layer sono 
 time-distributed
 , cosicché 
ogni parola è trattata indipendentemente 
dalle altre.
×
EncoderDecoder"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#3,3,"Introduzione
Nell'esempio sono evidenziate features ricavate dall'
 attention mechanism 
 che 
mettono in correlazione features anche molto distanti tra loro.
4
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#30,30,"Architettura Transformer e NLP: dettagli (3)
Ma se la generazione delle parole è indipendente una dall'altra, e non 
abbiamo RNN, come può funzionare?
31 (4) https://arxiv.org/abs/1706.03762
Il modulo 
 multi-head attention
  codi
 ﬁ
ca ogni 
relazione di una parola con tutte le altre nella 
stessa frase, in modo da evidenziale le 
relazioni più importanti (
 self-attention
 ). 
•
Es. In “They welcomed the Queen of the 
United Kingdom”, il termine queen sarà più 
legato cone 
 united
  e 
kingdom
  rispetto a 
 they 
e 
welcomed
 . 
Il modulo 
 masked multi-head attention
  si 
comporta in modo simile, ma si limita a 
considerare la parola precedente.  
Il 
multi-head attention
  del decoder analizza le 
parole nella frase in input e si focalizza sui 
termini più importanti per la traduzione (es. 
""Queen"")."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#31,31,"Architettura Transformer e NLP: dettagli (5)
Ma se la generazione delle parole è indipendente una dall'altra, come può 
funzionare?
32 (4) https://arxiv.org/abs/1706.03762
I 
positional embeddings
 , che sono dati in 
input al 
 encoder
  e 
decoder
  insieme agli 
embedding tradizionali, 
 rappresentano la 
posizione di un termine rispetto agli altri in 
una certa frase
 .  
Sono aggiunti ai 
 word embedding
  poiché il 
multi-head attention laye
 r ignora posizione 
e ordine delle parole nella frase, come pure 
gli altri layer  essendo tutti 
 layer time-
distributed
 . 
 "
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#32,32,"Keras: Transformer
In Keras una versione di Attention basata su 
 scaled dot-product
  è 
implementata in keras.layers.Attention.  
encoder_outputs = Z
Z = decoder_in
for
 N 
in 
range
(
6
):
    Z = keras.layers.Attention(use_scale=
 True
, causal=
 True
)([Z, Z])
    Z = keras.layers.Attention(use_scale=
 True
)([Z, encoder_outputs])
outputs = keras.layers.TimeDistributed(
    keras.layers.Dense(vocab_size, activation=
 ""softmax""
 ))(Z)
33 ..."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#33,33,"Demo Transformers e NLP
https://transformer.huggingface.co/  
34 ..."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#4,4,"Richiamo: Architetture encoder-decoder
Si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
 vector-to-
sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio. 
5
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#5,5,"Encoder/Decoder in Keras (1)
L'interfaccia 
 encoder
  può prendere in input una sequenza di lunghezza 
variabile X.  
class 
Encoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
call
(
self
, 
X
, *
args
):
        
 raise
 NotImplementedErro
 r
Il 
decoder
  prende l'output dei decoder per tramutarlo nello stato.  
class 
Decoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
init_state
 (
self
, 
enc_outputs
 , *
args
):
        
 raise
 NotImplementedError
    
def 
call
(
self
, 
X
, 
state
):
        
 raise
 NotImplementedError
6"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#6,6,"Encoder/Decoder in Keras (2)
L'architettura completa:  
class 
EncoderDecoder
 (
d2l
.
Classifier
 ):
   
def 
__init__
 (
self
, 
encoder
, 
decoder
):
        super().
 __init__
 ()
        
 self
.encoder = encoder
        
 self
.decoder = decoder
    
def 
call
(
self
, 
enc_X
, 
dec_X
, *
args
):
        enc_outputs = 
 self
.encoder(enc_X, *args, training=
 True
)
        dec_state = 
 self
.decoder.init_state(enc_outputs, *args
 )
        
 # Return decoder output only
        
 return 
self
.decoder(dec_X, dec_state, training=
 True
)[
0
]
7"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#7,7,"Esempio: Machine Translation (1)
In questo caso input e output sono sequenze di lunghezza variabile. La 
sequenza in input è tradotta in una rappresentazione nascosta/latente 
 ﬁ
xed-
shape.  
La sequenza in output è generata 
 token-by-token
 : data l'attuale sequenza in 
input, e i token precedenti generati in output. Durante l'addestramento il 
token da generare sarà estratto dai dati ground-truth. L'
 hidden state 
dell'
encoder
  viene dato in input ad ogni step di decoding. L'output generato 
sarà il nuovo input del decoder nello step successivo.  
Nota: se ignoriamo 
 l'encoder
 , il 
decoder
  corrisponde ad un 
 language model
 . 
Nell'esempio abbiamo frasi tokenizzate, dove <eos> corrisponde a end-of-
sequence. Ad ogni istanze iniziale, si impiega un tag <bos> per indicare 
l'inizio della sequenza
8
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#8,8,"Esempio: Machine Translation (2)
L'encoder
  può essere implementato con una RNN (es. GRU) uni o bi-
direzionale.  
L'output layer del 
 decoder
  sarà una FC che genera la distribuzione di 
probabilità sui token in output.  
La 
loss
 sarà una basata sulla 
 cross-entropy
 . 
Usualmente si usano sequenze di padding per frasi di lunghezza variabile, in 
input e output. Tali padding non intervengono nel calcolo della loss.
9
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#9,9,"Beam search (1)
Nell'architettura precedente il token generato è quello con più alta 
probabilità, 
 ﬁ
no a quando non è generato il token <eos>. Seguiamo una 
strategia 
 greedy
 , 
basata sui passati token generati e la variabile di contesto 
 c
, 
che rappresenta la frase in input:  
Nella 
 beam search
  scegliamo i 
 k
 token candidati più probabili. 
Successivamente teniamo in considerazioni i 
 k
 token per la generazione del 
nuovo token, e così via.
10
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Autoencoders
1"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#1,1,"Sommario
Language models: recenti sviluppi  
Autoencoders  
Stacked Autoencoders  
Fashion MNIST dataset  
Visualizzazione con t-SNE  
Unsupervised training con Stacked autoencoders  
Convolutional Autoencoders  
Recurrent Autoencoders  
Denoising Autoencoders  
Sparse Autoencoders  
Variational Autoencoders  
Semantic interpolation"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#10,10,"Rappresentazioni latenti
Latent representation learning
  (LRL), o 
 Latent variable modeling 
 (LVM), è una 
tecnica di apprendimento automatico che tenta di inferire le variabili latenti 
da misurazioni empiriche da variabili osservabili. Tali variabili latenti non 
possono essere misurate direttamente e quindi devono essere dedotte.  
Una o più variabili latenti costituiscono congiuntamente uno 
 spazio latente
  o 
una
 rappresentazione latente
 . Questa rappresentazione è solitamente una 
forma 
 compatta
  dello spazio impiegato per rappresentare le misurazioni 
empiriche, cioè consiste in un numero di variabili latenti inferiore alla 
dimensionalità delle misurazioni.
11 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#11,11,"Autoencoders
Gli 
autoencoders
  apprendono 
 rappresentazioni latenti
  dei dati senza 
l'impiego di approcci supervisionati.  
Inoltre possono essere impiegati per il 
 unsupervised pretraining
 , e per 
generare casualmente nuovi dati 
 che risultano simili a dati già visti in 
precedenza (es. visi di persone), sebbene non sempre realistici.  
•
Con le più recenti 
 Generative adversarial networks
  (
GANs
 ), che spesso 
includono anche moduli di autoencoders, suddividono il processo in 2 parti: 
generazione e discrimazione. In questi casi il realismo è maggiore.  
•
https://thispersondoesnotexist.com/  
https://thisrentaldoesnotexist.com/  
https://github.com/jantic/DeOldify    
Inoltre le GAN possono incrementare la risoluzione delle immagini, 
aggiungere colore alle immagini b/w, photo editing come rimpiazzare oggetti, 
convertire un disegno in una foto realistica, predire il successo frame in un 
video, creare/incrementare dataset per l'addestramento, etc.
12 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#12,12,"Rappresentazione dei dati ef
 ﬁ
ciente
Un 
autoencoder
  può avere una architettura piuttosto comune, es. MLP, dove 
input e output hanno hanno medesima dimensione.  
•
Nel seguente esempio l'
 hidden layer
  consiste in 2 soli nodi, mentre l'
 output 
e
 l'input layer 
 di 3 nodi. Lo scopo del 
 decoder
  (
output layer
 ) è ricostruire 
l'input a partire dalla rappresentazione creata dall'
 encoder
 .  
•
Se la rappresentazione dell'encoder ha meno dimensioni rispetto all'input, 
l'
autoencoder
  si chiama 
 undercomplete
 . 
•
La
 loss di ricostruzione
  valuta la differenza dell'output generato rispetto 
all'input.
13 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#13,13,"Autoencoders
Se l'
autoencoder 
 usa 
attivazioni lineari
  e la 
 MSE
 come funzione di costo, 
allora otteniamo un modello simile alla 
 Principal Component Analysis 
 (
PCA
). 
Nel seguente esempio proiettiamo istanze da un dataset 3d in 2d.  
from
 tensorflow 
 import
 keras
encoder = keras.models.Sequential([keras.layers.Dense(
 2
, input_shape=[
 3
])])
decoder = keras.models.Sequential([keras.layers.Dense(
 3
, input_shape=[
 2
])])
autoencoder = keras.models.Sequential([encoder, decoder])
autoencoder.
 compile
(loss=
""mse""
, optimizer=keras.optimizers.SGD(lr=
 0.1
))
Possiamo addestrarlo e impiegarlo per ottenere le rappresentazioni latenti:  
history = autoencoder.fit(X_train, X_train, epochs=
 20
)
codings = encoder.predict(X_train)
14 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#14,14,"Stacked Autoencoders
Gli 
stacked autoencoders
  (o 
deep autoencoders
 ) sono autoencoders 
organizzati su più layer, spesso in modo speculare.  
•
Non è mai consigliato creare autoencoders troppo complessi per non 
penalizzare il grado di generalizzazione su istanze in input non presenti nel 
dataset di training, su cui il modello non è capace di determinare attivazioni 
signi
ﬁ
cative.  
Nel caso 
 MNIST
  possiamo creare una architettura con 784 inputs, 100 nodi 
nel primo hidden layer, 30 nodi in quello centrale, un altro da 100 e l'output 
layer.
15 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#15,15,"Scaled Exponential Linear Units
La funzione di attivazione 
 Scaled Exponential Linear Units
  (
SELU
 ) 
è simile alla 
ELU ed è de
 ﬁ
nita nel seguente modo:  
 
 
La SELU non si annulla per valore < 0, a differenza della ReLU.  
Si può ipotizzare che la SELU implementi un ulteriore tipo di normalizzazione 
""interna"" che supporti l'invarianza tra media e varianza tra i layer, oltre alle 
due normalizzazioni già note:  
•
Input normalization (
 es. quando scaliamo i dati in ingresso)  
•
Batch normalization
f
(
x
)
=
λ
x
,
if 
x
>
0
f
(
x
)
=
λ
α
(
e
x
−
1
)
 altrimenti
16
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#16,16,"Keras: Stacked Autoencoders
L'implementazione è simile a una MLP. Nell'esempio usiamo una funzione di 
attivazione SELU, e invece delle MSE impieghiamo la 
 binary cross-entropy
  loss  
per accelerare la convergenza.  
stacked_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
),
])
stacked_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])
stacked_ae.
 compile
(loss=
""binary_crossentropy""
 ,
                   optimizer=keras.optimizers.SGD(lr=
 1.5
))
history = stacked_ae.fit(X_train, X_train, epochs=
 10
,
                         validation_data=[X_valid, X_valid])
17 (13) https://arxiv.org/pdf/1706.02515.pdf"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#17,17,"`
Per comprendere se l'output è corretto è utile visualizzarlo. Nel caso del 
dataset Fashion MNIST si ha:  
def 
plot_image
 (
image
):
    plt.imshow(image, cmap=
 ""binary""
 )
    plt.axis(
 ""off""
)
def 
show_reconstructions
 (
model
, 
n_images
 =
5
):
    reconstructions = model.predict(X_valid[:n_images])
    fig = plt.figure(figsize=(n_images * 
 1.5
, 
3
))
    
for
 image_index 
 in 
range
(n_images):
        plt.subplot(
 2
, n_images, 
 1
 + image_index)
        plot_image(X_valid[image_index])
        plt.subplot(
 2
, n_images, 
 1
 + n_images + image_index)
        plot_image(reconstructions[image_index])
show_reconstructions(stacked_ae)
18 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#18,18,"t-Distributed Stochastic Neighbourh 
t-Distributed Stochastic Neighbourh Embedding (t-SNE)
  è un algoritmo non 
supervisionato usato per la visualizzazione dei dati.  
Basato su una tecnica di riduzione della dimensionalità non lineare che punta 
a raggruppare punti simili tra loro in spazi con poche dimensioni preservando 
la struttura dei dati originali.  
Sfrutta la distribuzione t-Student per il calcolo della similarità tra 2 punti nello 
spazio ridotto e sulla Kullback–Leibler divergence.  
È poco affetto dagli outliers.
19 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#19,19,"Visualizzare un dataset con Autoencoders
Sebbene esistano tecniche avanzate di riduzione della dimensionalità e la 
visualizzazione dei dati, gli 
 autoencoders
  sono capaci di ridurre notevolmente 
le dimensioni di un dataset con molti istanze e molte features. Perciò 
possiamo sfruttarlo per generare input verso approcci più tradizionali, anche 
di visualizzazione.  
Sfruttiamo 
 t-distributed stochastic neighbor embedding
  (
t
-
SNE
) implementato 
in Scikit-Learn per la visualizzazione 2d.  
from
 sklearn.manifold 
 import
 TSNE
X_valid_compressed = stacked_encoder.predict(X_valid)
tsne = TSNE()
X_valid_2D = tsne.fit_transform(X_valid_compressed)
plt.scatter(X_valid_2D[:, 
 0
], X_valid_2D[:, 
 1
], c=y_valid, s=
 10
, cmap=
""tab10""
)
20 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#2,2,"Language Models: recenti sviluppi (1)
ELMo
(6)
 Embeddings from Language Models: rappresentazioni contestuali 
ottenute da un approccio 
 Deep bidirectional language model (biLM) 
addestrato su larghi dataset testuali. Gli stati generati dalla rete sono associati 
ai testi in modo da creare rappresentazioni latenti.   
ULMFiT
(7)
 Universal Language Model Fine-tuning: basato su 
 self-supervised 
learning
  con una architettura 
 LSTM
  a 3 layer dove sono richiesti meno dati (es. 
100 istanze) per l'addestramento sfruttando il transfer learning. State-of-the-art 
per la classi
 ﬁ
cazione NLP.
3(6) https://arxiv.org/abs/1802.05365  
(7) https://arxiv.org/abs/1801.06146  
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#20,20,"Fashion MNIST: Autoencoders e t-SNE
Fashion MNIST sottoposto a 
 autoencoders
  e 
t-SNE
 :
21 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#21,21,"Unsupervised training con Stacked autoencoders
Seguendo la 
 ﬁ
loso
ﬁ
a del 
 transfer learning
 , possiamo addestrare un 
autoencoder
  su un grande dataset di dati 
 unlabeled
 , e 
riutilizzare i parametri 
ottenuti nei primi layer 
 con un dataset più limitato di dati 
 labeled
  nel task 
principale di interesse.  
•
Dati 
 unlabeled
  si trovano facilmente sul web, es. immagini, testi, mentre i 
dati labeled sono molto preziosi poiché richiedono molte ore-uomo per 
creare valori target.
22 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#22,22,"Autoencoders: Tying weights (1)
Per 
autoencoders
  simmetrici è possibile creare 
 vincoli
  tra i valori dei parametri 
nei layer speculari (
 tying weights
 ) in modo da dimezzare i parametri da 
stimare durante l'apprendimento.  
In Keras costruiamo un Dense layer per impiegare i pesi di un layer 
precedente; attenzione: occorre trasporli prima di impiegarli nella decodi
 ﬁ
ca. 
class 
DenseTranspose
 (
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
dense
, 
activation
 =
None
, **
kwargs
):
        
 self
.dense = dense
        
 self
.activation = keras.activations.get(activation)
        super().
 __init__
 (**kwargs
 )
    
def 
build
(
self
, 
batch_input_shape
 ):
        
 self
.biases = 
 self
.add_weight(name=
 ""bias""
, initializer=
 ""zeros""
,
                                      shape=[
 self
.dense.input_shape[
 -1
]])
        super().build(batch_input_shape
 )
    
def 
call
(
self
, 
inputs
):
        z = tf.matmul(inputs, 
 self
.dense.weights[
 0
], 
transpose_b
 =
True
)
        
 return 
self
.activation(z + 
 self
.biases)
23 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#23,23,"Autoencoders: Tying weights (2)
La costruzione della rete impiega i nuovi layer per legarli con i precedenti:  
dense_1 = keras.layers.Dense(
 100
, activation=
 ""selu""
)
dense_2 = keras.layers.Dense(
 30
, activation=
 ""selu""
)
tied_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    dense_1,
    dense_2
])
tied_decoder = keras.models.Sequential([
    DenseTranspose(dense_2, activation=
 ""selu""
),
    DenseTranspose(dense_1, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])
24 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#24,24,"Greedy layerwise training
Invece di addestrare tutti i layer contemporaneamente possiamo farlo uno step 
alla volta, aggiungendo un layer dopo aver addestrato il precedente (
 greedy 
layerwise training
 ). 
Dopo il primo step codi
 ﬁ
co tutto il dataset per mezzo del primo autoencoder 
(
phase 1
 ). Uso il nuovo dataset per addestrare un secondo autoencoder (
 phase 
2
). In
ﬁ
ne metto tutti i layer insieme (
 phase 3
 ) 
•
Tale tecnica è attualmente poco popolare a causa di tecniche più recenti.
25 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#25,25,"Convolutional Autoencoders
Le architetture di 
 autoencoders
  viste non sono adatte per le immagini, cioè 
input con grandi dimensionalità.  
Le 
convolutional autoencoders
  impieghiamo dei 
 layer convoluzionali 
 per 
ridurre la dimensionalità
  incrementando la profondità del modello durante la 
codi
ﬁ
ca. 
Il 
decoder
  deve fare l'inverso: ridurre la profondità ed aumentare la risoluzione 
(
upsampling
 ). Si impiegano 
 transpose convolutional layers
  che operano in 
modo inverso alle convolution layer tradizionali.  
Ecco un esempio per Fashion MNIST:  
conv_encoder = keras.models.Sequential([
    keras.layers.Reshape([
 28
, 
28
, 
1
], input_shape=[
 28
, 
28
]),
    keras.layers.Conv2D(
 16
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 32
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 64
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
)
]
)
...
26 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#26,26,"Convolutional Autoencoders
conv_decoder = keras.models.Sequential([
    keras.layers.Conv2DTranspose(
 32
, kernel_size=
 3
, strides=
 2
, padding=
 ""valid""
,
                                 activation=
 ""selu""
,
                                 input_shape=[
 3
, 
3
, 
64
]),
    keras.layers.Conv2DTranspose(
 16
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""selu""
),
    keras.layers.Conv2DTranspose(
 1
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])
27 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#27,27,"Recurrent Autoencoders
Per dati 
 time series
  abbiamo visto come le RNN sono una valida alternativa alle 
FC. 
I 
recurrent autoencoder 
 hanno un 
 encoder
  tipicamente 
 sequence-to-vector 
 che 
""comprime"" l'input in una rappresentazione vettoriale, mentre il decoder è 
vector-to-sequence
 . 
Il seguente 
 autoencoder
  processa sequenze di qualsiasi lunghezza, con 28 
dimensioni considerate per singolo step. L'input possono essere immagini 
Fashion MNIST che saranno processate una riga di pixel alla volta.  
•
Il
 RepeatVector layer 
 del decoder garantisce che l'input vector al decoder sarà 
inviato per intero ad ogni step.  
recurrent_encoder = keras.models.Sequential([
    keras.layers.LSTM(
 100
, return_sequences=
 True
, input_shape=[
 None
, 
28
]),
    keras.layers.LSTM(
 30
)
])
recurrent_decoder = keras.models.Sequential([
    keras.layers.RepeatVector(
 28
, input_shape=[
 30
]),
    keras.layers.LSTM(
 100
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 28
, activation=
 ""sigmoid""
 ))
])
recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])
28 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#28,28,"Denoising Autoencoders (1)
Nelle 
 denoising autoencoders
(14)
 in input abbiamo immagini a cui 
aggiungiamo del rumore, e in output ci sono le versioni originali: stiamo 
addestrando la rete a 
 rimuovere il rumore
 .  
•
Il rumore può essere gaussiano, oppure con un random switch-off degli input 
(es. tramite tecniche simili al Dropout).
29 (14) https://jmlr.csail.mit.edu/papers/v11/vincent10a
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#29,29,"Denoising Autoencoders (2)
Codi
ﬁ
ca e output con Fashion MNIST  
dropout_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    
keras.layers.Dropout(
 0.5
),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activ
                       “    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
)
])
dropout_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])
30 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#3,3,"Self-supervised learning
Con 
self-supervised learning  
si intende l'addestramento di una modello in assenza di 
un dataset suf
 ﬁ
cientemente grande in termini di valori target riguardo il task di 
interesse principale.  
In tali casi si sfruttano le stessi istanze presentate in input per creare dei nuovi target 
secondari, distinti da quello iniziale, ma comunque af
 ﬁ
ni. In tal modo la rete può 
identi
 ﬁ
care alcune features salienti impiegabili nel task principale (
 knowledge transfer 
process
 ).  
•
Esempi di task secondari sono
 : identi
 ﬁ
care relazioni sostantivo-verbo o frase-
aggettivo (dominio NLP); due immagini, una ruotata, ed aspettarsi l'angolo di 
rotazione in output alla rete (dominio immagini).  
Sebbene i dataset secondari siano più facili da costruire, non sono suf
 ﬁ
cienti per 
risolvere il problema principale. ma riducono il tempo totale necessario per la fase di 
training del task principale. Una ulteriore fase di addestramento su un dataset ridotto 
(es. quello disponibile inizialmente) rendono la rete ef
 ﬁ
cace anche sul task di interesse 
primario.  
È fondamentale scegliere un task secondario che, durante l'addestramento, generi un 
sottoinsieme di features utili anche per il task principale.  
Attenzione: è un approccio distinto dal 
 unsupervised pretraining
 .
4"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#30,30,"Sparse Autoencoders (1)
Negli 
 sparse autoencoders 
 introduciamo un termine nella funzione di costo che 
favorisce un numero limitato di nodi ""attivi"" nel layer di coding
 , cioè quello che 
è associato allo spazio che stiamo costruendo.  
•
In altre parole, forziamo la rete a rappresentare ogni input con poche attivazioni, 
e perciò 
 ogni nodo attivo rappresenterà un numero limitato di feature molto 
signi
ﬁ
cative
 . 
Con la funzione di attivazione 
 sigmoid
 , che pone una sorta di vincolo sulle 
codi
ﬁ
che in [0,1], e con la 
 ℓ
1
 regularization
  al layer di coding, otteniamo il 
seguente codice Keras:  
sparse_l1_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ),
    
keras.layers.ActivityRegularization(l1=
 1e-3
)
  # vedi lucido seguente
])
sparse_l1_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])
31 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#31,31,"Sparse Autoencoders (2)
Il layer 
 ActivityRegularization
  restituisce gli stessi input, ma ha l'effetto 
collaterale di aggiungere una
  training loss che coincide con la somma dei valori 
assoluti dei suoi input
 . In questo modo forziamo la rete, sia a produrre 
codi
ﬁ
che vicine allo 0
 , sia a ricostruire l'output corretto; perciò avremo 
codi
ﬁ
che con pochi valori, ma molto signi
 ﬁ
cativi, diversi da 0.  
Un modo alternativo è 
 misurare una sorta di ""sparsity"" calcolata durante 
l'apprendimento
  e, se si discosta da un valore target, 
 penalizziamo la rete
 . La 
ricaviamo con l'
 attivazione media
  per ogni nodo nel coding layer nell'intero 
training batch, che avrà una dimensione suf
 ﬁ
ciente per stimare correttamente 
tali valori.  
Successivamente introduciamo la 
 sparsity loss
  che penalizza i nodi troppo 
attivi, o i nodi non suf
 ﬁ
cientemente attivi.  
•
Es. Se l'average per un nodo è 0.3, e la target sparsity è 0.1, penalizziamo in 
modo da ridurre l'attivazione aggiungendo ad esempio l'
 errore quadratico  
(0.3-0.1)2  alla funzione di cost.  
•
Una alternativa migliore è usare 
 Kullback–Leibler (KL)
 , che deriva dei gradienti 
più signi
 ﬁ
cativi interpretando le 2 attivazioni come distribuzioni di probabilità.
32 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#32,32,"Sparsity loss
Sparsity loss
  ricavata con diverse metriche:
33 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#33,33,"Keras: Sparse Autoencoders
Sparse autoencoders con la KL-divergence:  
K = keras.backend
kl_divergence = keras.losses.kullback_leibler_divergence
class 
KLDivergenceRegularizer
 (
keras
.
regularizers
 .
Regularizer
 ):
    
def 
__init__
 (
self
, 
weight
, 
target
=
0.1
):
        
 self
.weight = weight
        
 self
.target = target
    
def 
__call__
 (
self
, 
inputs
):
        mean_activities = K.mean(inputs, axis=
 0
)
        
 return 
self
.weight * (
            kl_divergence(
 self
.target, mean_activities) +
            kl_divergence(
 1
. - 
self
.target, 
 1
. - mean_activities))
        
..
.
kld_reg = KLDivergenceRegularizer(weight=
 0.05
, target=
 0.1
)
sparse_kl_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ,”
                       activity_regularizer=kld_reg)
])
sparse_kl_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])
34 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#34,34,"Sparse Autoencoders e attivazioni
Dopo la fase di training su Fashion MNIST notiamo come circa il 70% delle 
attivazioni è prossima a 0, e che gran parte dei neuroni (90%) ha attivazione 
media tra 0.1 e 0.2.
35 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#35,35,"Variational Autoencoders (1)
I 
variational autoencoders 
 sono molto diffusi. Sono distinti dai precedenti 
poiché sono in parte 
 probabilistici
 , cioè una parte dell'output è generato in 
modo random, e 
 generativi
 , cioè possono generare nuove istanze che 
sembrano campionate dal training set. 
36 (15) https://arxiv.org/abs/1312.6114
Hanno una architettura simile agli altri 
autoencoders, ma all'interno 
l'encoder produce un vettore 
 codi
ﬁ
ca 
media  
 e un vettore 
 deviazione 
standard  
.  
L'
effettiva codi
 ﬁ
ca
 della istanza in 
input sarà generata per mezzo di una 
distribuzione gaussiana con tali 
parametri.  
Durante il training la loss tende a 
raggruppare le codi
 ﬁ
che in modo da 
generare una ""nuvola gaussiana"" di 
punti.
μ
σ"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#36,36,"Variational Autoencoders (2)
La 
funzione di costo
  consiste in due loss: la 
 reconstruction loss 
 che impone 
che l'output sia fedele all'input, e una 
 latent loss 
 che spinge ad avere 
codi
ﬁ
che come se fossero campionate da una distribuzione gaussiana, de
 ﬁ
nita 
per mezzo della KL-divergence.  
37 (15) https://arxiv.org/abs/1312.6114
La forma analitica contiene dettagli 
per limitare l'informazione trasmessa 
al coding layer, ma sempli
 ﬁ
cando si 
ottiene la seguente 
 latent loss
 : 
K 
è la dimensione delle codi
 ﬁ
che e 
 i 
indica l'i-esima componente della 
codi
ﬁ
ca.  
•
Impiegando la log(
 ) invece di 
  si 
ottiene 
 più stabilità
 .
σ
 σ
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#37,37,"Keras: Variational Autoencoders (1)
In Keras creiamo un 
 Sampling
  layer che campiona una istanza dalla distribuzione 
gaussiana  
class 
Sampling
 (
keras
.
layers
.
Layer
):
    
def 
call
(
self
, 
inputs
):
        mean, log_var = inputs
        
 return
 K.random_normal(tf.shape(log_var)) * K.exp(log_var / 
 2
) + mean
Non avendo un modello strettamente sequenziale usiamo le 
 Functional API
  di Keras, 
adatte per architetture particolari, ad esempio con topologie non lineari, pesi condivisi 
tra layer, o input e output multipli.  
Nel codice del 
 encoder
  con Functional API notiamo la rappresentazione esplicita dei 
dati ricavati dalla rete (es. 
 z, codings_mean, codings_log_var
  etc):  
codings_size = 1
 0
inputs = keras.layers.Input(shape=[
 28
, 
28
])
z = keras.layers.Flatten()(inputs)
z = keras.layers.Dense(
 150
, activation=
 ""selu""
)(z)
z = keras.layers.Dense(
 100
, activation=
 ""selu""
)(z)
codings_mean = keras.layers.Dense(codings_size)(z)  
 # 
μ
codings_log_var = keras.layers.Dense(codings_size)(z)  
 # 
γ
codings = Sampling()([codings_mean, codings_log_var])
variational_encoder = keras.Model(
    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])
38 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#38,38,"Keras: Variational Autoencoders (2)
Creiamo il 
 decoder
 , in questo caso potevamo usare anche l'approccio Keras 
Sequential.  
decoder_inputs = keras.layers.Input(shape=[codings_size])
x = keras.layers.Dense(
 100
, activation=
 ""selu""
)(decoder_inputs)
x = keras.layers.Dense(
 150
, activation=
 ""selu""
)(x)
x = keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 )(x)
outputs = keras.layers.Reshape([
 28
, 
28
])(x)
variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])
Creiamo il modello e de
 ﬁ
niamo la 
 latent_loss
  e 
reconstruction_loss
 , e 
addestriamo con 
 RMSprop
  optimizer, adatto in questa con
 ﬁ
gurazione:  
_, _, codings = variational_encoder(inputs)
reconstructions = variational_decoder(codings)
variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])
latent_loss = 
 -0.5
 * K.
sum
(
    
1
 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),
    axis=
 -1
)
variational_ae.add_loss(K.mean(latent_loss) / 
 784
.)
variational_ae.
 compile
(loss=
""binary_crossentropy""
 , optimizer=
 ""rmsprop""
 )
history = variational_ae.fit(X_train, X_train, epochs=
 50
, batch_size=
 128
,
                             validation_data=[X_valid, X_valid])
39 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#39,39,"Generare immagini stile Fashion MNIST
Generiamo nuove istanze campionando in modo causale dalla distribuzione 
gaussiana:  
codings = tf.random.normal(shape=[
 12
, codings_size])
images = variational_decoder(codings).numpy(
 )
Le istanze in output, un po' fuzzy, sono abbastanza verosimili:
40 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#4,4,"Self-supervised learning - esempio
Nel dominio delle immagini possiamo considerare come task secondari quelli 
il cui obiettivo è ricostruire una immagine manipolata, es. distorta, ruotata.  
Nel task 
 patches
 , estraiamo più segmenti dall'immagine e cerchiamo di 
determinare la relazione tra essi (es. posizione relativa tra 2 segmenti).  
•
Es
. prendiamo una patch 
 X
 a caso dall'immagine, ed otteniamo le 8 patches 
che la circondano 
 Y
i
. Usiamo coppie di patches (
 X,Y
i
) come input per 
determinare la posizione della patch 
 Y
i
. Oppure diamo in input tutte le 9 
patches in ordine random e chiediamo alla rete di ""risolvere il puzzle"".
5
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#40,40,"Variational Autoencoders e semantic interpolation
Invece di interpolare due immagini nel ""dominio dei pixel"", possiamo 
interpolare nel dominio latente 
 costruito dall'
 autoencoder
 . 
•
Deriviamo la rappresentazione dal coding layer di due immagini in input, 
interpoliamole e decodi
 ﬁ
chiamole.  
codings_grid = tf.reshape(codings, [
 1
, 
3
, 
4
, codings_size])
larger_grid = tf.image.resize(codings_grid, size=[
 5
, 
7
])
interpolated_codings = tf.reshape(larger_grid, [
 -1
, codings_size])
images = variational_decoder(interpolated_codings).numpy()
41 ...
Le immagini nel box sono 
quelle originali, quelle 
senza sono l'interpolazione 
di quelle adiacenti."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#5,5,"Language Models: recenti sviluppi (2)
GPT
(8)
 sfrutta il 
 unsupervised pretraining
  con una  architettura 
 Transform
  con 
stack di 12 moduli, addestrata su un dataset esteso con tecniche 
 self-
supervised
 .  
•
Necessita di un 
 ﬁ
ne-tuned training per impiegarla su task speci
 ﬁ
ci (es. 
classi
 ﬁ
cazione, misura di similarità, question answering).  
•
GPT-2
(9)
 è una versione estesa con 1.5 miliardi di parametri, con modelli 
disponibili online.  
•
GPT-3
  è estesa a 175 miliardi di parametri. Le APIs sono disponibili ma 
l'accesso è previa veri
 ﬁ
ca.
6(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#6,6,"Language Models: recenti sviluppi (3)
GPT-2 output
7(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#7,7,"Language Models: recenti sviluppi (4)
BERT
(10)
 Bidirectional Encoder Representations from Transformers: sviluppata 
da Google, simile alla GPT, impiega 
 self-supervised pretraining
  con approccio 
bidirezionale. È stata pre-addestrata su due task:  
•
Ogni parola in una frase ha il 15% di probabilità di essere 
 mascherata
 . Il 
compito della rete è di indovinarla.  
•
Date due frasi, predire se sono consecutive.  
Altri approcci recenti usano CNN con 
 masked 2d-conv
  per il task di 
trasformazione sequence-to-sequence
(11)
, o RNN dove ogni nodo risulta 
indipendente dall'altro, garantendo apprendimenti su sequenze molto più 
lunghe
(12)
.
8(10) https://arxiv.org/abs/1810.04805  
(11) https://arxiv.org/abs/1808.03867(12) https://arxiv.org/abs/1803.04831  "
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#8,8,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14
9 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#9,9,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14  
Se riconosci il pattern ""tutti i numeri pari dal 50 al 14"" ti sarà più facile 
ricordare la seconda.
10 ..."
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Generative Adversarial Networks
1"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#1,1,"Sommario
Apprendimento discriminativo e generativo  
Generatie adversarial networks (GANs)  
Deep Convolutional Generative Adversarial Networks"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#10,10,"GAN e Keras: Generatore e Discriminatore
   
for
 epoch 
in 
range
(num_epochs):
        timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
)  
# loss_D, loss_G, num_examples
        
 for
 (X,) 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(
                mean=
 0
, stddev=
 1
, shape=(batch_size, latent_dim))
            metric.add(update_D(X, Z, net_D, net_G, loss, optimizer_D),
                       update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
        
 # Visualizzazione dei dati generati
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, shape=(
 100
, latent_dim))
        fake_X = net_G(Z)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].scatter(data[:, 
 0
], data[:, 
 1
])
        animator.axes[
 1
].scatter(fake_X[:, 
 0
], fake_X[:, 
 1
])
        animator.axes[
 1
].legend([
 ""real""
, 
""generated""
 ])
        
 # Visualizzazione delle loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch + 
 1
, (loss_D, loss_G))
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec'
 )
11"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#11,11,"GAN e Keras: Generatore e Discriminatore
Speci
 ﬁ
chiamo gli iperparametri per fare 
 ﬁ
tting di una distribuzione gaussiana:  
lr_D, lr_G, latent_dim, num_epochs = 
 0.05
, 
0.005
, 
2
, 
20
train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G,
      latent_dim, data[:
 100
].numpy())
> 
loss_D 
0.693
, loss_G 
 0.693
, 
333.2
 examples/sec
12
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#12,12," Deep Convolutional Generative Adversarial 
Nelle GAN abbiamo visto come i campioni generati provengano perloppiù da 
distribuzioni uniformi o normali, che sono poi trasformati in istanze che 
corrispondono alle distribuzioni di un certo dataset di dati reali.  
Per generare campioni più complessi (es. immagini fotorealistiche) sono 
necessarie architetture più complesse come le 
 Deep Convolutional GANs 
(DCGAN)
 . 
13"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#13,13,"DCGAN - Keras (1)
Il dataset è la collezione di Pokemon sprites, ottenuto da pokemondb.  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
d2l.DATA_HUB[
 'pokemon'
 ] = (d2l.DATA_URL + 
 'pokemon.zip'
 ,
                           
 'c065c0e2593b8b161a2d7873e42418bf6a21106c'
 )
data_dir = d2l.download_extract(
 'pokemon'
 )
batch_size = 
 256
pokemon = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir, batch_size=batch_size, image_size=(
 64
, 
64
)
)
Ridimensiono ogni immagini in 64x64. I valori sono in [0,1], mentre il generatore usa la 
 tanh
 e 
genera campioni con pixel in [-1,1]. Normalizziamo i dati con media e deviazione standard pari 
a 0.5.  
def 
transform_func
 (
X
):
    X = X / 
 255
.
    X = (X - 
 0.5
) / (
0.5
)
    
return
 X
data_iter = pokemon.
 map
(
lambda
 x, y: (transform_func(x), y),
                        num_parallel_calls=tf.data.experimental.AUTOTUNE)
data_iter = data_iter.cache().shuffle(buffer_size=
 1000
).prefetch(
    buffer_size=tf.data.experimental.AUTOTUNE)
14"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#14,14,"DCGAN - Keras (2)
d2l.set_figsize(figsize=(
 4
, 
4
))
for
 X, y 
in
 data_iter.take(
 1
):
    imgs = X[:
 20
, :, :, :] / 
 2
 + 
0.5
    d2l.show_images(imgs, num_rows=
 4
, num_cols=
 5
)
Il generatore deve mappare una 
 noise variabile  
 e un vettore di dimensione 
 d
 ad una  
immagine 64x64.  
Usiamo la 
 Conv2DTranspose
  per incrementare  
la risoluzione in input, seguita da una 
 batch normalization  
e attivazione ReLU.  
class 
G_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
strides
=
2
, 
padding
=
""same""
,
                 **
 kwargs
):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d_trans = tf.keras.layers.Conv2DTranspose(
            out_channels, kernel_size, strides, padding, use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.ReLU()
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d_trans(X)))
z
∈
ℝ
d
15
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#15,15,"DCGAN - Keras (3)
Di default abbiamo
  kernel 4x4, stride 2x2 e same padding.  
Con un input 16x16, il generatore raddoppia larghezza e altezza dell'input.  
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))  
# creiamo un dato sintetico
g_blk = G_block(
 20
)
g_blk(x).shape
> TensorShape([2, 32, 32, 20]
 )
Se usiamo un kernel 4x4, stride 1x1 e zero padding, con un input 1x1, l'output avrà 
larghezza e altezza incrementati di 3.  
x = tf.zeros((2, 1, 1, 3)
 )
# padding=""valid"" corresponds to no padding
g_blk = G_block(
 20
, strides=
 1
, padding=
 ""valid""
)
g_blk(x).shape
> TensorShape([2, 4, 4, 20])
16
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#16,16,"DCGAN - Keras (4)
Il 
generatore
  consiste in 4 blocchi base che incrementano ampiezza e altezza 
da 1 a 32. Inizialmente mappa le variabili latenti in 64x8 canali, e poi 
dimezza i canali ogni volta. In
 ﬁ
ne, un
  transposed convolution layer 
 genera 
l'output raddoppiando la dimensione a 64x64 e riducendo i canali a 3 per 
rispettare l'output desiderato. La funzione di attivazione 
 tanh
 è usata per 
generare output in (-1,1).  
n_G = 
64
net_G = tf.keras.Sequential([
    
# Output: (4, 4, 64 * 8)
    G_block(out_channels=n_G*
 8
, strides=
 1
, padding=
 ""valid""
),
    G_block(out_channels=n_G*
 4
), 
# Output: (8, 8, 64 * 4)
    G_block(out_channels=n_G*
 2
), 
# Output: (16, 16, 64 * 2)
    G_block(out_channels=n_G), 
 # Output: (32, 32, 64)
    
# Output: (64, 64, 3)
    tf.keras.layers.Conv2DTranspose(
        
 3
, kernel_size=
 4
, strides=
 2
, padding=
 ""same""
, use_bias=
 False
,
        activation=
 ""tanh""
)
])
17"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#17,17,"Richiami: Leaky ReLU
La leaky ReLU è  utile per affrontare il dying ReLU.  
alphas = [
 0
, 
.2
, 
.4
, 
.6
, 
.8
, 
1
]
x = tf.
range
(
-2
, 
1
, 
0.1
)
Y = [tf.keras.layers.LeakyReLU(alpha)(x).numpy() 
 for
 alpha 
in
 alphas]
d2l.plot(x.numpy(), Y, 
 'x'
, 
'y'
, alphas)
18
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#18,18,"DCGAN - Keras (5)
Il blocco base del discriminatore è un convolution layer seguito da 
 batch 
normalization
  (tranne per l'input layer) e leaky ReLU activation. Gli 
iperparametri sono simili a quelli impiegati al blocco generatore.  
class 
D_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
                 
 strides
=
2
, 
padding
=
""same""
, 
alpha=
0.2
, **kwargs):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d = tf.keras.layers.Conv2D(out_channels, kernel_size,
                                             strides, padding,  
                                      use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.LeakyReLU(alpha)
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d(X))
 )
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))
d_blk = D_block(
 20
)
d_blk(x).shape
> TensorShape([2, 8, 8, 20])
19"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#19,19,"DCGAN - Keras (6)
Per un input shape 16x16 e un kernel 4x4 e stride 2 e same padding:  
n_D = 
64
net_D = tf.keras.Sequential([
    D_block(n_D), 
 # Output: (32, 32, 64)
    D_block(out_channels=n_D*
 2
), 
# Output: (16, 16, 64 * 2)
    D_block(out_channels=n_D*
 4
), 
# Output: (8, 8, 64 * 4)
    D_block(out_channels=n_D*
 8
), 
# Outupt: (4, 4, 64 * 64)
    
# Output: (1, 1, 1)
    tf.keras.layers.Conv2D(
 1
, kernel_size=
 4
, use_bias=
 False
)
]
)
x = tf.zeros((
 1
, 
64
, 
64
, 
3
))
net_D(x).shape
> TensorShape([1, 1, 1, 1]) # Predizione: Singolo valore
20
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#2,2,"Apprendimento discriminativo e generativo
Finora abbiamo trattato il 
 discriminative learning
 , cioè un apprendimento 
capace di distinguere le differenti istanze, cioè le relative caratteristiche, e 
classi
 ﬁ
carle, o fare predizione. In molti task arriviamo a livelli di accuratezza 
comparabili a quelli umani.  
Ci sono altri casi in cui vogliamo analizzare grossi dataset senza labels per 
creare un modello che ne descrive le caratteristiche. Con tale modello 
possiamo creare esempi di dato 
 sintetici
  che assomigliano a quelli reali. Tale 
approccio si chiama 
 generative learning
 . 
•
Es. le reti ricorrenti sono un esempio di un modello discriminativo che può 
essere impiegato anche per generare nuove istanze.
3"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#20,20,"Richiami: Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
s
+
ϵ
β
1
21Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘s+ϵ"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#21,21,"DCGAN - Keras (7)
Rispetto alle GAN usiamo lo stesso 
 learning rate
  per il generatore e 
discriminatore essendo architetture simili. Portiamo 
  in Adam da 0.9 (spesso 
usato come default) a 0.5.  
Decrementiamo lo 
 smooth
  del momentum, la weighted moving average 
esponenziale dei passati gradienti, per tenere traccia più puntuale delle 
variazioni rapide dei gradienti a causa dell'instabilità creata dal discriminatore-
generatore.  
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr
, 
latent_dim
 ,
          
 device
=d2l.try_gpu()):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_hp = {
 ""lr""
: lr, 
""beta_1""
 : 
0.5
, 
""beta_2""
 : 
0.999
}
    optimizer_D = tf.keras.optimizers.Adam(**optimizer_hp)
    optimizer_G = tf.keras.optimizers.Adam(**optimizer_hp)
β
1
22"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#22,22,"DCGAN - Keras (8)
    animator = d2l.Animator(xlabel=
 'epoch'
, ylabel=
 'loss'
,
                          xlim=[
 1
, num_epochs], nrows=
 2
, figsize=(
 5
, 
5
),
                          legend=[
 'discriminator'
 , 
'generator'
 ]
)
    animator.fig.subplots_adjust(hspace=
 0.3
)
    
for
 epoch 
in 
range
(
1
, num_epochs + 
 1
):
 
       timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
) 
# loss_D, loss_G, num_examples
        
 for
 X, _ 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(mean=
 0
, stddev=
 1
,
                                 shape=(batch_size, 
 1
, 
1
, latent_dim))
            metric.add(d2l.update_D(X, Z, net_D, net_G, loss,  
                                                           optimizer_D),
                       d2l.update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
23"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#23,23,"DCGAN - Keras (9)
        
 # Visualizziamo i dati generti
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, 
                                        shape=(
 21
, 
1
, 
1
, latent_dim))
        
 # Normalizziamo i dati generati in (0,1)
        fake_x = net_G(Z) / 
 2
 + 
0.5
        imgs = tf.concat([tf.concat([fake_x[i*
 7
+j] 
for
 j 
in 
range
(
7
)],
                                    axis=
 1
)
                          
 for
 i 
in 
range
(
len
(fake_x) // 
 7
)], axis=
 0
)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].imshow(imgs)
        
 # Visualizziamo le loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch, (loss_D, loss_G)
 )
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec on  
                                      
 {
str
(device._device_name)}
 '
)
24"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#24,24,"DCGAN - Keras (10)
latent_dim, lr, num_epochs = 
 100
, 
0.0005
, 
40
train(net_D, net_G, data_iter, num_epochs, lr, latent_dim)
> loss_D 0.217, loss_G 3.687, 2310.5 examples/sec on /GPU:
 0
25
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#3,3,"Generative adversarial networks
Nel 2014 sono state introdotte le 
 Generative adversarial networks (GAN)
 , un 
modello che sfrutta un approccio 
 discriminativo
  per generare modelli 
generativi:  
•
L'idea è che un modello generativo è buono se non riusciamo a distinguere i 
dati generati da quelli reali.  
Dal punto di vista statistico corrisponde ad un 
 2-sample test
 : misurare se due 
sequenze di istanze 
 X
= {
x
1
, ..., 
x
n
} e 
X'
= {
x'
1
, ..., 
x'
n
} sono ottenute dalla stessa 
distribuzione.  
Nelle GAN tale test è usato dal modello generativo per adattarsi a creare 
istanze sempre più simili ai casi reali.  
•
In pratica, cerchiamo di ""bidonare"" il classi
 ﬁ
catore reale/fake. 
4"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#4,4,"Generative adversarial networks (GANs)
L'architettura include un 
 generative network
 , nel nostro caso una deep 
network, che ha lo scopo di generare istanze simili a quelle reali (es. segnale 
di voce umana, immagini di visi). Il 
 discriminative network
  cerca di 
distinguere dati reali da quelli generate (o fake).  
Il 
discriminator
  è implementato come un classi
 ﬁ
catore binario che produce 
uno scalare per ogni input 
 x 
(es. una FC con 1 layer e funzione di attivazione 
sigmoid
  per convertire lo scalare in probabilità). Assumiamo che la label 
corrispondente sia 1 per una istanza da dati reali, 0 per una fake creata dal 
generatore.  
Il generatore mira a generare una immagine più  
vicina possibile alle immagini reali, e per ottenere  
dal discriminatore il relativo output corrispondente  
a ""il dato e' real"".
5
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#5,5,"Generative adversarial networks (GANs)
Il 
discriminatore
  mira a distinguere immagini generate da immagini reali minimizzando 
la 
cross-entropy loss:  
 
dove 
 D
(x) = 1/(1 + 
 e
-o
) è la probabilità ottenuta con la 
 sigmoid
  a partire dallo scalare 
 o.  
Collezionando in modo casuale 
  (es. con distribuzione normale), dove 
  riveste il 
compito di 
 variabile latente,
  il compito del 
 generatore
  è di bidonare il discriminatore per 
classi
 ﬁ
care 
 x'=G(z)
  come ""dato reale"", cioè vogliano D(G(z)) ≈ 1.  
In altre parole, dato un discriminatore D, aggiorniamo i parametri del generatore per 
massimizzare la 
 cross-entropy loss 
 quando y=0, cioè 
 dato fake
 : 
 
Se il generatore si comporta in modo ottimale, D(x') è circa 1, cosicché la loss è vicina 
allo 0, e perciò i gradienti sono assai ridotti per generare progressi per il discriminatore. 
Minimizzeremo perciò la seguente loss:  
 
che è il feed x'=G(z) nel discriminatore dando il label 1.  
min
 D
{
−
y
 log 
D
(
x
)
−
(
1
−
y
)
 log
(
1
−
D
(
x
)
)
}
z
∈
ℝ
D
z
max
 G
{
−
(
1
−
y
)
 log 
(
1
−
D
(
G
(
z
)
)
)
}
=
max
 G
{
−
 log 
(
1
−
D
(
G
(
z
)
)
)
}
min
 G
{
−
y
 log 
(
D
(
G
(
z
)
)
)
}
=
min
 G
{
−
 log 
(
D
(
G
(
z
)
)
)
}
6"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#6,6,"GAN e Keras (1)
Generiamo dati con un modello gaussiano:  
X = tf.random.normal((1000, 2), 0.0, 1
 )
A = tf.constant([[1, 2], [-0.1, 0.5]]
 )
b = tf.constant([1, 2], tf.float32
 )
data = tf.matmul(X, A) + 
 b
Otteniamo una gaussiana traslata in modo arbitrario con media 
 b
 e covarianza 
A
T
A
. 
d2l.set_figsize(
 )
d2l.plt.scatter(data[:100, 0].numpy(), data[:100, 1].numpy())
 ;
print(f'The covariance matrix is\n{tf.matmul(A, A, transpose_a=True)}'
 )
> The covariance matrix i
 s
> [[1.01 1.95
 ]
> [1.95 4.25]
 ]
batch_size = 
 8
data_iter = d2l.load_array((data,), batch_size)
7
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#7,7,"GAN e Keras: Generatore e Discriminatore
Il generatore è un semplice layer lineare.  
net_G = tf.keras.layers.Dense(2
 )
Per il discriminatore usiamo una MLP a 3 layer:  
net_D = tf.keras.models.Sequential(
 [
    tf.keras.layers.Dense(5, activation=""tanh"", input_shape=(2,))
 ,
    tf.keras.layers.Dense(3, activation=""tanh"")
 ,
    tf.keras.layers.Dense(1
 )
]
)
De
ﬁ
niamo una funzione per aggiornare il 
 discriminatore
 : 
def 
update_D
 (
X
, 
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_D
 ):
    batch_size = X.shape[
 0
]
    ones = tf.ones((batch_size,)) 
 # Labels corrispondenti ai dati reali
    zeros = tf.zeros((batch_size,)) 
 # Labels corrispondenti ai dati fake
    
# Ignoriamo i gradienti per `net_G` all'interno di GradientTape
    fake_X = net_G(Z)
    
with
 tf.GradientTape() 
 as
 tape:
        real_Y = net_D(X)
        fake_Y = net_D(fake_X)
        loss_D = (loss(ones, tf.squeeze(real_Y)) + loss(
            zeros, tf.squeeze(fake_Y))) * batch_size / 
 2
    grads_D = tape.gradient(loss_D, net_D.trainable_variables)
    optimizer_D.apply_gradients(
 zip
(grads_D, net_D.trainable_variables))
    
return
 loss_D
8"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#8,8,"GAN e Keras: Generatore e Discriminatore
Il generatore sarà aggiornato in modo simile. Riutilizziamo la cross-entropy 
loss ma cambiamo la label dei dati fake da 0 a 1  
def 
update_G
 (
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_G
 ):
    batch_size = Z.shape[
 0
]
    ones = tf.ones((batch_size,))
    
with
 tf.GradientTape() 
 as
 tape:
        fake_X = net_G(Z)
 
       fake_Y = net_D(fake_X)
       loss_G = loss(ones, tf.squeeze(fake_Y)) * batch_size
    grads_G = tape.gradient(loss_G, net_G.trainable_variables)
    optimizer_G.apply_gradients(
 zip
(grads_G, net_G.trainable_variables))
    
return
 loss_G
Sia il discriminatore sia il generatore operano una
  logistic regression binaria 
con cross-entropy loss. Usiamo 
 Adam
  per rendere smooth il processo di 
training. Ad ogni iterazione, prima aggiorniamo il discriminatore e poi il 
generatore. 
9"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#9,9,"GAN e Keras: Generatore e Discriminatore
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr_D
, 
lr_G
, 
latent_dim
 , 
data
):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_D = tf.keras.optimizers.Adam(learning_rate=lr_D)
    optimizer_G = tf.keras.optimizers.Adam(learning_rate=lr_G)
    animator = d2l.Animator(
        xlabel=
 ""epoch""
, ylabel=
 ""loss""
, xlim=[
 1
, num_epochs], nrows=
 2
,
        figsize=(
 5
, 
5
), legend=[
 ""discriminator""
 , 
""generator""
 ])
    animator.fig.subplots_adjust(hspace=
 0.3
)
   ...
10"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recommender Systems
1"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#1,1,"Sommario
MovieLens dataset  
AutoRec  
Implicit feedback (richiami)ù  
Neural Collaborative Filtering (NCF)  
Caser e Sequence-aware Recsys  
Factorization Machines e Deep FM"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#10,10,"Neural Collaborative Filtering for Personalized Ranking
L'output del penultimo layer di entrambe le reti è concatenato è dato in input 
al NeuMF layer:
11
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#11,11,"Sequence-aware recommender systems
Spesso gli utenti operano una sequenza di azioni nei servizi online il cui 
ordine temporale può essere signi
 ﬁ
cativo nel processo di raccomandazione.  
Il modello 
 Caser 
 (Convolutional sequence embedding recommendation 
model) sfrutta le CNN, in particolare 
 horizontal
  e 
vertical
  convolutional 
networks, per identi
 ﬁ
care rispettivamente pattern sequenziali 
 union-level
  e 
point-level
  di tipo short-term.  
I pattern 
 point-level
  identi
 ﬁ
cano l'in
 ﬂ
uenza di un item all'interno di una 
sequenza verso un certo item target. L'union-level analizza l'in
 ﬂ
uenza di varie 
azioni fatte sul valore target (es. l'acquisto di latte e burro può implicare 
l'acquisto di farina).  
I bisogni di lungo termine sono rappresentati nei layer FC 
 ﬁ
nali.
12"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#12,12,"Sequence-aware recommender systems
Supponiamo che ogni utente u sia associato ad una sequenza di items 
. Se prendiamo i passati 
 L
 items, possiamo costruire una 
matrice che rappresenta le interazioni passati con tali items rispetto al time 
step 
t
. 
Dove 
  rappresenta sempre lo spazio di embedding e 
 q
i
 indica la 
 i
-
ma riga. 
  è usata per ottenere i bisogni transienti dell'utente 
 u
 per 
il time step 
 t
, ed è l'input per i successivi convolutional layers:  
•
L'horizontal layer ha 
 d 
ﬁ
ltri orizzontali 
 . 
•
Il vertical layer ha d' 
 ﬁ
ltri verticali  
Dopo una serie di operatori convoluzionali e di pooling otteniamo gli output 
 e 
 :
S
u
=
(
S
u
1
,
⋯
,
S
u
|
S
u
|
)
Q
∈
ℝ
n
×
k
E
(
u
,
t
)
∈
ℝ
L
×
k
F
j
∈
ℝ
h
×
k
,
i
≤
j
≤
d
,
h
=
{
1,
⋯
,
L
}
G
j
∈
ℝ
L
×
1
,
i
≤
j
≤
d
′ 
o
∈
ℝ
d
o
′ 
∈
ℝ
d
′ 
13
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#13,13,"Sequence-aware recommender systems
Gli output sono concatenati e dati in input ad una MLP per ricavarne 
rappresentazioni ad alto livello:  
L'output 
  indica i bisogni a breve termine dell'utente.  
I bisogni a lungo termine dell'utente sono ricavati:  
dove 
  è una ulteriore embedding matrix, e  
  è la 
 user 
embedding matrix
  per i bisogni a lungo termine. 
  e 
  sono la 
u
-ma riga e 
 i
-ma riga rispettivamente di 
 P
 e 
V
.
z
∈
ℝ
k
V
∈
ℝ
n
×
2
k
P
∈
ℝ
m
×
k
p
u
∈
ℝ
k
v
i
∈
ℝ
2
k
14
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#14,14,"Sequence-aware recommender systems
L'architettura generale di Caser è così rappresentata:
15
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#15,15,"Addestramento e architetture sequenziali
In modo simile all'addestramento RNN, in presenza di dati con timestamp che 
rappresentano azioni tra utenti e items (es. l'utente ha lasciato un rating su un 
ﬁ
lm), possiamo costruire un dataset di addestramento creando sequenze di 
dimensione prede
 ﬁ
nita, ad esempio:
16
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#16,16,"Factorization Machines
Le FM sono algoritmi supervisionati che possono essere impiegati in contesti 
di classi
 ﬁ
cazione, regressione e ranking. Si ispirano a modelli di regressione 
lineare, modelli di MF e Support vector machines con kernel polinomiali.  
Mostrano vantaggi in caso di dataset sparsi riducendo notevolmente il tempo 
di addestramento. Inoltre individuano più facilmente correlazioni signi
 ﬁ
cative 
tra i dati.  
Se indichiamo con 
  il vettore delle feature per una certa istanza, e con 
y la label numerica associata (es. 4.5 oppure click/no-click), formalizziamo il 
modello in questo modo:  
dove 
  è il bias globale, 
  sono i pesi per la i-ma variabile, 
 sono i feature embeddings, e 
 v
i
 è la i-ma riga di 
 V
, <v
 i
,v
j
> è il 
prodotto vettoriale tra i 2 vettori è modella l'interazione tra la 
 i
-ma e 
 j
-ma 
feature.
x
∈
ℝ
d
w
0
∈
ℝ
 w
∈
ℝ
d
V
∈
ℝ
d
×
k
17
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#17,17,"Factorization Machines
Nell'espressione precedente si può notare una prima componente che 
rappresenta il modello di regressione lineare, mentre il secondo estende un 
modello di MF:  
Se la feature 
 i
 rappresenta un item, e la feature 
 j
 un utente, il terzo termine è il 
prodotto scalare tra i due embedding, uno dell'utente ed uno dell'item. 
18
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#18,18,"Deep Factorization Machines
In alcuni scenari l'approccio lineare delle FM non è suf
 ﬁ
ciente per 
rappresentare correlazioni e patterns complessi. Ma è possibile integrare 
approcci ""deep"" nel FM per rappresentare interazioni tra features nei dati.  
Nel 
DeepFM
  la componente FM e deep sono combinate in modo 
 parallelo
 . La 
FM è simile all'architettura originale. La deep è implementata con una MLP. 
L'input/embeddings delle 2 componenti è il medesimo, l'output è 
 sommato  
per creare la predizione 
 ﬁ
nale.  
La DeepFM si ispira allearchitetture RecSys chiamate 
 wide & deep
 . In tali 
architetture la predizione combina due pipeline:  
•
la 
memorizzazione
  mira a rappresentare co-occorrenze frequenti tra items o 
features nei dati storici. Si implementa con un modello lineare (es. logistic 
regression)  
•
la 
generalizzazione
  punta a implementare la ""transitività"" delle correlazioni, 
cioè esplorare combinazioni signi
 ﬁ
cative tra features che non sono state mai 
incontrate nel passato. La pipeline è generalmente basata su una MLP.
19"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#19,19,"Deep Factorization Machines
Supponiamo che l'output della FM sia 
 . Indichiamo con 
  il vettore 
delle feature latenti del campo 
 i
-mo.  
L'input della componente deep è la concatenazione degli embeddings di tutti 
i campi associati alle 
 f
 feature categoriche date in input:  
La rete neurale è cosi de
 ﬁ
nita: 
L'output 
  è combinato con il precedente per generare l'output 
 ﬁ
nale:  
 
̂
y
(
F
M
)
e
i
∈
ℝ
k
̂
y
(
D
N
N
)
̂
y
=
σ
(
h
a
t
y
(
D
N
N
)
+
̂
y
(
D
N
N
)
)
20
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#2,2,"Motivazioni
I 
sistemi di raccomandazione
  sono strumenti chiave in molti scenari: e-
commerce, siti per la fruizione di musica e video (es. Spotify, Net
 ﬂ
ix), app 
stores, pubblicità, etc.  
•
Alcune conferenze internazionali speci
 ﬁ
che nel settore (es. RecSys) 
attraggono i maggiori players che fanno a gara per aggiudicarsi i migliori 
ricercatori.  
Supponiamo nel resto dei lucidi che alcuni argomenti sia già noti dai 
precedenti corsi:  
•
Collaborative 
 ﬁ
ltering  
•
Explicit e Implicit feedback  
•
Recommendation tasks (es. rating vs top-n vs sequence aware 
recommendation
3"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#20,20,"Deep Factorization Machines
L'architettura DeepFM è la seguente:
21
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#3,3,"MovieLens dataset
Il dataset più popolare nel mondo accademico 
 RecSys
 . Ne esistono diverse 
versioni in base alla quantità di dati contenuti.  
•
In 
MovieLens 100K
  sono contenuti 100.000 ratings espressi in una scala da 1 
a 5, da 943 utenti su 1682 
 ﬁ
lm. Ogni utente ha espresso rating su almeno 20 
ﬁ
lm. Il formato del dataset è 
 csv
. 
•
http://
 ﬁ
les.grouplens.org/datasets/movielens/ml-100k.zip  
Tecniche quali 
 Matrix Factorization
  sono state in in grado di individuare 
patterns chiave per ottenere migliori risultati rispetto ad approcci più 
tradizionali. Ma si limitano a catturare patterns e correlazioni di tipo lineare. 
4"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#4,4,"MovieLens dataset
MovieLens
  100K
  vs 
1M
5
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#5,5,"AutoRec
In 
AutoRec
  si impiega un paradigma di Collaborative Filtering basato su 
autoencoders. Invece di rappresentare la matrice user-ratings in un spazio 
latente, o di impiegare le stesse istanze di input anche per l'output come nel 
caso degli autoencoders visti in precedenza, si segue un approccio alternativo:  
•
in 
input
  si hanno un le interazioni utente-item osservate  
•
in 
output
  ci si aspetta l'intera matrice delle interazioni utente-item  
Esistono architetture AutoRec 
 user-based 
 e 
item-based
 . Qui vedremo le 
seconde ma è facile immaginare le prime per analogia.
6"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#6,6,"(Item-based) AutoRec
Indichiamo con 
  la i-ma colonna della matrice dei ratings. I valori di rating 
sconosciuti saranno 0.  
La rete AutoRec la possiamo de
 ﬁ
nire formalmente:  
 
dove f e g sono funzioni di attivazione, W e V matrici di pesi, 
  e 
b
 sono 
biases, 
  la ricostruzione della i-ma colonna.  
La funzione da ottimizzare è la seguente:  
 
dove il primo modulo considera solo i 
 ratings
  noti.
R
*
i
h
(
R
*
i
)
=
f
(
W
⋅
g
(
V
⋅
R
*
i
+
μ
)
+
b
)
μ
h
(
R
*
i
)
argmin
W
,
V
,
μ
,
b
M
∑
i
=
1
|
|
R
*
i
−
h
(
R
*
i
)
|
|
2
+
λ
(
|
|
W
|
|
2
F
+
|
|
V
|
|
2
F
)
)
7"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#7,7,"Richiami: Implicit Feedback
I 
rating espliciti
  (es. valutazioni da 1 a 5) sono generalmente scarsi nei servizi 
di raccomandazione. Inoltre valori mancanti di rating possono essere 
erroneamente interpretati, es.: forme di feedback negativi invece di rating che 
devono essere ancora speci
 ﬁ
cati. 
Si tendono a sfruttare altre fonti che possono essere interpretate come forme di 
implicit feedback
 . 
•
Es. clicks, acquisti, visite, wish lists.
8"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#8,8,"Neural Collaborative Filtering for Personalized Ranking
Il 
Neural Collaborative Filtering (NCF)  
framework con implicit feedback 
sfrutta la capacità di 
 non-linearità 
 delle reti neurali.  
È composto da 2 reti, una basata su Generalized Matrix Factorization, l'altra 
consiste in una MLP.  
L'output delle 2 reti è concatenato per generale la predizione 
 ﬁ
nale. Se in 
AutoRec puntavamo a predire i rating, NCF produce una lista di 
raccomandazioni con score associato ad ogni item della lista.
9"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#9,9,"Neural Collaborative Filtering for Personalized Ranking
La 
GMF
  è un approccio di MF implementato con reti neurali. L'input è il 
prodotto element-wise (Hadamard product) tra le rappresentazioni latenti degli 
utenti e degli item:  
Dove 
 p
u
 e 
q
i
 sono rispettivamente la u-ma riga di 
 P
 e q-ma riga di 
 Q
, dove 
 e 
 . L'output è la previsione di score dell'utente 
 u
 per 
l'item 
 i
. 
La 
MLP
 prende in input le rappresentazioni degli utenti e item, ignorando lo 
spazio latente della GMF. Lo scopo è individuare correlazioni aggiuntive con 
operazioni non lineari.
P
∈
ℝ
m
×
k
Q
∈
ℝ
n
×
k
10
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning e Natural Language Processing
1"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#1,1,"Sommario
DL e NLP: motivazioni  
word2vec  
skip-gram  
CBOW  
GloVe  
fastText  
BERT"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#10,10,"word2vec: skip-gram (training)
Ci poniamo l'obiettivo di massimizzare la probabilità, cioè minimizzare la 
funzione:  
Se impieghiamo lo SGD, usiamo sequenze brevi per stimare il gradiente 
stocastico e aggiornare il modello. La stima è basta sul gradiente del logaritmo 
della probabilità condizionata data una coppia 
 w
o
 e 
w
c
. 
Una volta terminato l'apprendimento, i vettori 
 v
i
 sono tipicamente impiegati 
come 
 embedding
  associati ad un termine.
11
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#11,11,"word2vec: Continuous Bag of Words (CBOW)
Simile allo skip-gram ma assume che le parole contestuali generico la parola 
centrale.  
Essendoci più parole contestuali, i vettori sono mediati. La probabilità 
condizionata di generare un termine 
  dati i termini contestuali 
  è 
la seguente:  
Se consideriamo una sequenza di lunghezza T abbiamo:
w
c
 w
o
1
,
⋯
,
w
o
2
m
12
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#12,12,"word2vec: recap
Diagramma riassuntivo dei 2 modelli:
13
CBOW model Skip-gram model
t-word embedding t-word embeddingmatrix  
Vxdmatrix
dxV"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#13,13,"Word Embedding with Global Vectors (GloVe)
Le co-occorrenze tra termini rappresentano informazioni importanti per 
costruire gli embeddings. Indichiamo con 
 q
ij
 la probabilità condizionata 
 P(w
 j
|
w
i
)
 nel modello 
 skip-gram
 : 
La parola 
 w
i
 può presentarsi molte volte in un corpus. Tutte le parole 
contestuali che co-occorrono con 
 w
i
 creano un multiset, dove 
 x
ij
 indica il 
numero di volte che la parola 
 w
j 
co-occorre con 
 w
i
. La loss function è:  
Indichiamo con 
 x
i
 il numero di parole contestuali dove compare wi come 
parola centrale, e avendo 
 p
ij
=x
ij
/x
i
, otteniamo:
14
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#14,14,"Word Embedding with Global Vectors (GloVe)
La sommatoria interna è la cross-entropy tra la probabilità condizionata 
 q
ij 
relativa alla predizione generata dal modello, e 
 p
ij
 ottenuta analizzando le 
statistica dell'intero corpus.  
Per ridurre la complessità computazionale (soprattutto per generare 
 q
ij
) e per 
mitigare gli effetti generate dai termini che compaiono di rado nel corpus ma 
che possono assumere importanza elevata dalla cross entropy, il modello 
GloVe introduce alcune varianti.  
La nuova 
 loss function
  è la seguente:  
dove si introducono ad ogni parola sono associati 2 bias, 
 b
i
 per le parole 
centrali e 
 c
i
 per le parole impiegate nel contesto; il primo e ultimo termine nel 
termine a quadrato sono il termine di loss, e 
 h(x
ij
)
 genera un peso associato al 
termine di loss.
15
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#15,15,"fastText model
Ci sono relazioni morfologiche comuni tra molti vocaboli, es., tra 
 help
 e 
helps, 
helped, helping
 ; tra 
dog
 e 
dogs
 e tra 
 cat
 e 
cats
; tra 
boy
 e 
boyfriend
  e tra 
 girl
 e 
girlfriend
 . Modelli come skip-gram ignorano queste relazioni, poiché ognuno 
di questi termini è rappresentato da un vettore distinto.  
Il modello 
 fastText
  usa 
subword embeddings
 , dove ogni 
 subword
  è un 
 n-gram 
di caratteri. Ad ogni subword è associato un vettore.  
•
Per esempio, la parola ""where"" genera le subwords “<wh”, “whe”, “her”, 
“ere”, “re>” impiegando una 
 ﬁ
nestra di lunghezza 3.  
La rappresentazione di un termine 
 v
w
 sarà la somma delle sue subwords 
 z
g
: 
Il resto del modello è basato su skip-gram.
16
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#16,16,"Modelli context-indipendent e context-sensitive
Nei modelli precedenti, data una parola, il vettore generato non dipende dal 
contesto attuale (approccio 
 context-independent
 ). Termini polisemici o 
relazioni semantiche del linguaggio naturale saranno perciò ignorate.  
Modelli come 
 ELMo
  combinano le rappresentazioni intermedie ottenute da 
LSTM bidirezionali per ottenere una rappresentazione che dipende dalla 
sequenza in input (approccio 
 context-sensitive
 ).  
•
La rappresentazione così ottenuta è solitamente combinata con quella 
ottenuta in modo context-independent (es. tramite GloVe) nei task successivi. 
Il modello impiegato da ELMo deve essere speci
 ﬁ
co per il task che si andrà 
ad affrontare, e perciò rimarrà costante.  
Per evitare di avere diversi modelli per ogni task, GPT pre-addestra un 
language model che sarà usato per rappresentare sequenze testuali. I 
parametri saranno poi 
 ﬁ
ne-tuned
  in base all'ouput del task successivo. GPT è 
basato su Transformers. Il contesto analizzato da GPT sarà limitato alla parte 
antecedente al termine attuale, perciò non si analizza il contesto a destra del 
termine. 
17"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#17,17,"Bidirectional Encoder Representations from Transformers (BERT)
BERT combina i due approcci appena descritti, rappresentando l'intero 
contesto mediante un approccio bidirezionale.  
È basato su Transformer encoders pre-addestrati. Un output layer speci
 ﬁ
co per 
il task da affrontare sarà di volta in volta addestrato da zero. 
18
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#18,18,"Bidirectional Encoder Representations from Transformers (BERT)
L'input di BERT può essere una singolo testo o coppie di testi.  
Oltre agli 
 positional
  embedding, si impiegano anche 
 segment
  e 
token  
embeddings. Infatti, a differenza delle RNN, i Transformer richiedono tecniche 
speci
 ﬁ
che per rappresentare internamente l'ordine relativo in cui i termini 
compaiono tra loro. Tali embedding sono ricavati durante la fase di training.
19
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#19,19,"Bidirectional Encoder Representations from Transformers (BERT)
Come pretraining (auxiliary) task si impiega il 
 Masked Language modeling
 . 
Dato un corpus testuale, il 15% dei tokens saranno selezionati in modo 
random per il task di predizione. Al loro posto sarà presente un tag <mask>, 
es: 
•
“this movie is great” becomes “this movie is <mask>”  
Un ulteriore auxiliary task speci
 ﬁ
co nello scenario in cui si hanno 2 testi in 
input è il 
 Next sentence prediction
 . Dal corpus si estraggono coppie di frasi 
consecutive, e altrettante coppie di frasi che non sono consecutive. Il task è di 
classi
 ﬁ
cazione binaria.
20"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#2,2,"DL e NLP 
Durante l'apprendimento di tecniche ML abbiamo spesso bisogno di grosse 
moli di dati 
 labelled
  per implementare approcci supervisionati.  
Alcune architetture DL hanno la capacità di riconoscere pattern e 
caratteristiche anche complesse in tali dati, ma dataset adeguati per 
l'addestramento non sono disponibili.  
Per tale motivo sono stati proposti vari approcci come il 
 self-supervised 
learning
 , per analizzare dati un modo non supervisionato (
 auxiliary task, es. 
predire una parte mancante del testo) e costruire rappresentazioni utili per 
supportare l'apprendimento (tipicamente supervisionato) in task più speci
 ﬁ
ci.  
Avendo un dataset di testo, l'input può essere costruito impiegando singole 
parole o n-grams formati da lettere, utili per catturare informazioni 
morfologiche delle parole. L'output è tipicamente una rappresentazione 
vettoriale associata ad ogni parola (
 embedding
 ), indipendente dal contesto in 
cui sarà presente in seguito.
3"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#20,20,"Bidirectional Encoder Representations from Transformers (BERT)
BERT raggiunge prestazioni elevate su numero categorie di tasks, es.:  
•
single text classi
 ﬁ
cation 
 (e.g., sentiment analysis),  
•
text pair classi
 ﬁ
cation
  (e.g., date due domande di Quora determinare se sono 
simili o no),  
•
question answering
 ,  
•
text tagging
  (e.g., named entity recognition)
21"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#3,3,"Esempio di auxiliary task
4
inputsliding-window
output (training set)
  "
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#4,4,"Esempio di embeddings
Embeddings relativi a termini che identi
 ﬁ
cano 115 nazioni estratti da un 
corpus testuale, rappresentati su un piano 2d.
5   
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#5,5,"Esempio di operazioni su embeddings
Essendo vettori, possiamo fare operazioni sugli embeddings, es:  
•
vector(“paris”)−vector(“france”)+vector(""germany"")  
Impiegando il modello di embeddings 
 GloVe
  addestrato sul testa estatto da 
Wikipedia otteniamo:  
•
berlin: 0.8015347  
•
paris: 0.7623165     
•
munich: 0.7013252     
•
leipzig: 0.6616945    
•
germany: 0.6540700 
6   "
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#6,6,"DL e NLP 
Le rappresentazioni pretrained ottenute con approcci non supervisionati sono 
successivamente impiegate su architetture di DL in base al task da risolvere.
7
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#7,7,"word2vec
Il modello impiega 2 reti: 
 skip-gram
  e 
continuos bag of words
  (CBOW).  
Il training è basato sulla stima delle probabilità condizionate di predire una 
certa parola in base a termini che occorrono nel suo intorno. Si segue sempre 
un approccio non supervisionato.
8"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#8,8,"word2vec: skip-gram
Assume che un termine può generare il testo circostante in una sequenza.  
Supponiamo di considerare la sequenza 
 “the”, “man”, “loves”, “his”, “son”
 ; e 
considerare il termine 
 loves
  con parola centrale, e una 
 ﬁ
nestra di 2 termini 
intorno al termine centrale.  
Il modello skip-gram valuta la seguente probabilità condizionata:  
Se assumiamo che i termini siano generati in modo indipendente tra loro, 
possiamo riscriverla:
9
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#9,9,"word2vec: skip-gram
Ogni parola con indice 
 i
 ha associati 2 vettori d-dimensionali, 
  e 
. Il primo impiegato quando la parola è usata centralmente, l'altro 
quando la parola appare nel contesto.  
La probabilità di generare un certo termine contestuale con indice 
 o
 dato il 
termine centrale con indice 
 c
 è de
 ﬁ
nita mediante una operazione softmax nel 
seguente modo:  
Data una sequenza di testo lunga 
 T
, dove 
  indica la parola posizionata allo 
step 
t
, e assumendo che le parole contestuali siano generate in modo 
indipendente tra loro, per una 
 ﬁ
nestra di lunghezza 
 m
, la probabilità di 
generare tutti i termini contestuali è de
 ﬁ
nita nel seguente modo:
v
i
∈
ℝ
d
u
i
∈
ℝ
d
w
(
t
)
10
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#0,0,!1Introduzione
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#1,1,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!2
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#10,10,"Misura delle grandezze fisicheEsempio: per misura della larghezza L di una lavagna occorre confrontare la larghezza della lavagna con uno standard di misura delle lunghezze: 
!11L{}=LL⎡⎣⎤⎦Risultato del confrontoGrandezza fisica da misurareLunghezza standard• Se [L]=metro            → {L} = 3,5    [L]=m   →   L = 3,5 m • Se [L]=centimetro    → {L} = 350     [L]=cm   →   L = 350 cm • Se [L]=piede             → {L} = 11,5    [L]=ft     →   L = 11,5 ft • Se [L]=pollice           → {L} = 138    [L]=in     →  L = 138 in La grandezza è sempre la stessa, ma cambiano sia la parte numerica che quella relativa allo standard di misura utilizzato"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#11,11,"Misura delle grandezze fisicheLa misura è identificata da due elementi: • La parte numerica (numero)  {L} • Lo standard usato (l’unità di misura) [L] 
!12L={L}[L]Devono essere specificati entrambi!!!"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#12,12,"Dimensioni delle grandezze fisicheGrandezze principali (che useremo nel corso) • Lunghezza L, Tempo T, Massa M, Intensità di corrente I
!13e ( alcune) grandezze derivate: • Superficie S=[L2], V olume V=[L3] • Frequenza F=[1/T]=[T-1]  • Velocità V=[L/T]=[LT-1], accelerazione A=[L/T2]=[LT-2] • Tensione elettrica V=[ML2I-1T-3]• Grandezza generica  [X]=[MαLβTγI𝛿] 𝛼,𝛽,𝛾,𝛿 sono dette dimensioni della grandezza fisica"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#13,13,"Dimensioni nelle formuleOgni formula ﬁsica è una relazione tra grandezze ﬁsiche → sono due relazioni, una sui numeri e una sulle unità di misura
!14"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#14,14,"Unità di misura (standard di misura)Gli standard devono soddisfare i criteri: • Essere stabili nel tempo • Essere precisi • Essere “facilmente” riproducibili in ogni parte del mondo (universo)
!15Dal 20 maggio 2019 si utilizzano nuove definizioni"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#15,15,"Unità di tempo: il secondoScelta di un fenomeno periodico:  •Giorno solare medio. Diviso in  - 24 ore, 60 minuti primi, 60 minuti secondo - 1 giorno = 86400 secondi  (minuti secondi) • 1967: un secondo corrisponde a 9.192.631.770 oscillazioni dell’isotopo di Cesio 133 tra lo stato fondamentale e il suo primo stato eccitato (invariato al 20/5/2019)!16
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#16,16,"Unità di lunghezza: il metroProdotto della rivoluzione francese (1795)•Deﬁnizione originale– 1 metro = 1/10 000 000 della distanza tra polo nord ed equatore •Deﬁnizione successiva (1889): distanza tra due tacche di una sbarra di platino-iridio (campione di Sèvres)•1983: Lo standard di tempo è ben deﬁnito; la velocità della luce è una costante universale:– 1 metro = distanza percorsa dalla luce in 1/299 792 458 secondi(invariato al 20/5/2019)!17
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#17,17,"Unità di corrente: l’ampereFino al 20/5/2019 L’intensità di corrente che, se mantenuta in due conduttori lineari paralleli di lunghezza infinita e sezione trascurabile, posti a un metro di distanza l’uno dall’altro nel vuoto, produce tra questi una forza pari a 2×10-7 newton per ogni metro di lunghezza. Oggi:  L’ampere sarà definito dal valore numerico della carica elementare fissato a 1,602176634×10-19 coulomb e sarà realizzato attraverso speciali circuiti che contano gli elettroni.!18
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#18,18,"Unità di massa: il kilogrammoProdotto della rivoluzione francese (1795) Intenzione: 1 kg = massa di 1 dm3 di acqua a 4 gradi centigradi Fino al 20/5/2019 Definizione: 1kg =  massa di un cilindro campione di platino iridio di 39 mm di altezza e 39 mm di diametro!19
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#19,19,"Unità di massa: il kilogrammoOggi:  Sarà ridefinito in termini della costante di Planck, sarà realizzato attraverso una speciale bilancia elettromagnetica (detta bilancia di Kibble) e non sarà più necessario riferirsi al campione di Sèvres. il chilogrammo diventa la massa controbilanciata da un certa quantità di corrente, dove entra in gioco la costante di Planck.
!20
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#2,2,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!3Fino al XVII secolo la Fisica era considerata come filosofia della natura (spinta più da considerazioni filosofiche)Il senso moderno del termine è stato introdotto da Galileo Galilei, partendo dalla definizione di Metodo Scientifico"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#20,20,"Sistema Metrico DecimaleUn insieme di unità di misura costituisce un sistema: Sistema MKS: metro, kilogrammo, secondo (rinominato in SI nel 1970: Sistema Internazionale) Sistema cgs: centimetro, grammo, secondo Sistema metrico decimale: i multipli ed i sottomultipli sono potenze di 10: Multipli prefisso  sottomultipli prefisso 10 deca (da)  10-1 deci   (d) 102 etto (h)  10-2 centi  (c) 103 kilo  (k)                 10-3 milli  (m) 106 mega (M)  10-6 micro  (µ) 109 giga (G)  10-9 nano (n) Esempi: 1 mm, 2 µm, 5 ns, 20 km, 4 hg!21"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#21,21,"Esempio
!22Una macchina percorre una curva semicircolare di raggio R=50 m con una velocità di v = 20 m/s. Calcolare l’accelerazione della macchina.
Risultato: l’accelerazione vale: Analisi dimensionale: [a]=[LT-2]Suggerimento: l’accelerazione (a) si misura in m/s2. La formula da usare è una delle seguenti:"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#22,22,"Esercizio
!23Determinare quanti secondi ci sono in un anno solare;Quanto pesa un metro cubo di acqua?Enrico Fermi amava dire che faceva lezioni che duravano tipicamente un microsecolo. A quanti minuti corrisponde un microsecolo?365.25×24×60×60=31,556,7361dm3→1kg1m3=1000dm3→1000kg100×365.25×24×60=52,594,560 minuti in un secoloUn microsecolo corrisponde a 52.59456 minuti "
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#23,23,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.ithttps://www.unibo.it/sitoweb/lorenzo.rinaldi/
!24"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#3,3,"Il Metodo Scientifico-SperimentaleAlla base del metodo Scientifico c’è l’Esperimento: i processi della Natura sono schematizzati in Modelli da verificare sperimentalmente
!4
...tra le sicure maniere di conseguire la verità è l’anteporre l’esperienza a qualsivoglia discorso, non sendo possibile che una sensata esperienza sia contraria al vero... "
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#4,4,"Il Metodo Scientifico-SperimentaleNessun modello teorico risulta essere valido universalmente Le teorie risultano essere valide entro ben determinati limiti esempio:  •piccole distanze: serve la “teoria dei quanti” •elevate velocità: serve la “teoria della relatività” 
!5"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#5,5,"Il Metodo Scientifico-SperimentaleLe teorie fisiche sono validate tramite osservazioni sperimentali Gli esperimenti devono essere realizzati per determinare con precisione (MISURARE) in maniera RIPRODUCIBILE le grandezze fisiche.
!6Le grandezze Fisiche sono quantità che servono per descrivere i fenomeni naturali in maniera oggettiva (esempio: tempo, spazio, massa,…) 
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#6,6,"Grandezze Fisiche
!7Grandezza fisica: proprietà o caratteristica di un oggetto o di un fenomeno che può essere quantificata (→ misurata)
Esempi: 
lunghezze, durate, velocità, forza, temperatura, pressioneodori, intelligenza, bello, brutto…
Controesempi: 
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#7,7,"Grandezze principali e derivate Lunghezza e V olume • Il volume V di un cubo di lato L: V=L3
!8
L In un viaggio di T=1 h, ho percorso L=100 km spostandomi ad una velocità v=100 km/h • 3 grandezze: durata, distanza, velocità •1 relazione tra le grandezze v=L/Tlunghezza e tempo sono grandezze principali V olume e velocità sono grandezze derivate"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#8,8,"Grandezze principali e derivate
!9In Fisica ci sono 7 grandezze principali, tutte le altre sono derivabili da esselunghezza tempo massa temperatura intensità di corrente elettrica intensità luminosa quantità di sostanzaMECCANICAELETTROMAGNETISMO"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#9,9,"Misura delle grandezze fisicheMisura: processo di determinazione di una grandezza fisica Operativamente: misura=confronto della grandezza che ci interessa con uno standard (una misura campione di quel tipo di grandezza)Le grandezze Fisiche sono definite in Modo Operativo: il modo di misurare la grandezza ne fissa la definizione Le grandezze Fisiche sono definite da tutte le possibili operazioni di misurazione
!10"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#0,0,VETTORI  CdS Ingegneria Informatica A.A. 2019/20
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#1,1,"!2Grandezze fisiche•Grandezze scalari: completamente definite da un numero ed una unità di misura –Esempi: distanza, lunghezza, periodo, pressione, temperatura •Grandezze vettoriali: completamente definite da 3 numeri e da una unità di misura o da un numero, una unità di misura, una direzione ed un verso –Esempi: spostamenti, forze, velocità, accelerazione, campi elettrici e magnetici, … •Grandezze tensoriali: definite da più di 3 numeri ed una unità di misura –Esempi: momento d’inerzia, matrice di rotazione, …"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#10,10,"!11Proprietà associativa della somma
⃗a+⃗c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#11,11,"!12Differenza tra vettori•Definizione:OABOAB−⃗bvettore opposto (stesso modulo e direzione, ma con verso opposto)⃗d=⃗a−⃗b=⃗a+(−⃗b)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#12,12,"Somma e differenza
!13⃗a⃗d=⃗a−⃗b⃗b⃗c=⃗a+⃗b"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#13,13,"!14Moltiplicazione per uno scalare•Si può definire come moltiplicazione tra un numero naturale n ed un vettore     come una somma ripetuta:•Generalizzando, si può definire come  moltiplicazione tra un numero reale λ ed un vettore      come vettore di direzione pari ad      modulo pari a            e verso concorde con     se             , verso opposto se    È un vettore!"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#14,14,"!15Moltiplicazione per scalare: proprietà•La moltiplicazione per uno scalare gode delle proprietà commutative, associative e distributive sia rispetto agli scalari che ai vettori:•Inoltre:"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#15,15,"!16Prodotto scalareAssocia a due vettori arbitrari uno scalare:θa⋅b=abcosϑ
a⋅b=abb
a⋅b=aba"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#16,16,!17                   : casi notevoli•Vettori in direzione opposta:a⋅b=abcosϑ•Vettori paralleli:a⋅b=ab>0•Vettori ortogonali:a⋅b=0•La componente: –Sia      un versorea⋅ˆu=aˆucosϑ==acosϑ=au
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#17,17,"!18Prodotto scalare: proprietà•Il prodotto scalare gode della proprietà commutativa, distributiva sulla somma:•Quadrato di un vettore:DEFINIZIONE  DI MODULO!  a⋅b=b⋅aa⋅b+c()=a⋅b+a⋅cλa⋅b()=λa()⋅b=a⋅λb()   a⋅a=a2=a2=a2  ⇒a=a⋅a"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#18,18,"!19Moduli di somme e di differenze
   a+b=a+b()2=a+b()⋅a+b()=  =a⋅a+a⋅b+b⋅a+b⋅b   a+b=a2+b2+2abcosϑ   a−b=a−b()2=a−b()⋅a−b()=  =a⋅a−a⋅b−b⋅a+b⋅b   a−b=a2+b2−2abcosϑ"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#19,19,"!20Prodotto vettore•Associa a due vettori un terzo vettore:
Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destraModulo: area del parallelogrammaVerso convenzionale"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#2,2,!3Stazione: 2.2 km in direzione nord-est
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#20,20,"!21Prodotto vettore•Associa a due vettori un terzo vettore:Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destra
"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#21,21,!22Prodotto vettore: proprietà•Il prodotto vettore (o vettoriale) gode della proprietà anticommutativa e distributiva sulla somma: •Il prodotto vettore non gode della proprietà associativa: •Caso notevole:
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#22,22,"!23Doppio prodotto misto
Proprietà:V=a∧b⋅c=a∧b()⋅ch=c⋅versa∧b() a∧b⋅c=b∧c⋅a=c∧a⋅b a∧b⋅c=a⋅b∧c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#23,23,"!24Sistemi di riferimento•I vettori sono entità astratte, indipendenti da come sono rappresentate.AB•Per convenienza pratica i vettori si descrivono bene utilizzando il concetto di SISTEMA DI RIFERIMENTO, costituito in estrema sintesi da un punto privilegiato detto origine e da un insieme di vettori campione (vettori di base)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#24,24,!25Spazio unidimensionale•Ogni vettore può essere scritto come:O In uno spazio unidimensionale ogni vettore può essere espresso come uno scalare (la componente) moltiplicato il versore dell’asse (sempre lo stesso).a+b=auˆu+buˆu=au+bu()ˆua=a⋅a=auˆu⋅auˆu=au2(ˆu⋅ˆu)=au
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#25,25,"!26Spazio bidimensionale: vettori nel piano•Scelgo 2 assi ortogonali x,y: 
OXYˆi⋅ˆj=0"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#26,26,"Esempio di spazio bi-dimensionale
!27
(C; 4)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#27,27,"!28Spazio tridimensionale
•Scelgo 3 assi ortogonali x,y,z: "
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#28,28,"!29Vettori di base nello spazio
1ˆˆˆˆˆˆ=⋅=⋅=⋅kkjjii0ˆˆˆˆˆˆ=⋅=⋅=⋅ikkjjiˆi∧ˆi=ˆj∧ˆj=ˆk∧ˆk=0"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#29,29,"!30Operazioni nella rappresentazione cartesiana
a⋅b=ca⋅b=(axˆi+ayˆj+azˆk)⋅(bxˆi+byˆj+bzˆk)==axbxˆi⋅ˆi+axbyˆi⋅ˆj+axbzˆi⋅ˆk+aybxˆj⋅ˆi+aybyˆj⋅ˆj+aybzˆj⋅ˆk++azbxˆk⋅ˆi+azbyˆk⋅ˆj+azbzˆk⋅ˆk==axbx+ayby+azbz=c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#3,3,"!4Vettore nel piano
ABModuloDirezioneVersoVettore libero 1 direzione nello spazio 1 verso 1 modulo (intensità)Prototipo: vettore spostamento"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#30,30,"!31Prodotto vettoriale
"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#31,31,"Esercizio A•Sianoˆˆˆˆˆˆ21322aijkbijk=−+=−+−!!1.Trovare i moduli 2.Trovare il vettore somma ed il vettore differenza 3.Calcolare  4.Calcolare  5.Trovare l’angolo compreso!3232,23cabdab=+=−!!!!!!abλ=⋅!!"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#32,32,"Esercizio Nel piano XY, la componente x di un vettore v vale -25, quella y +40. Quanto vale il modulo del vettore? Quanto vale l’angolo compreso fra v e l’asse delle ascisse? 
!33"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#33,33,!34Esercizio 1•Sia1.Trovare i moduli 2.Trovare l’angolo compreso 3.Trovare il vettore somma ed il vettore differenza 4.Trovare un vettore perpendicolare ad entrambi
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#34,34,"!35Esercizio 3•Una barca naviga in direzione Nord-Est per 15 km, successivamente vira in direzione Sud e prosegue per 10 km, quindi vira nuovamente in direzione Ovest e percorre altri 5 km. Trovare la distanza percorsa e la distanza dal punto di partenza.NESO"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#35,35,"Esercizio Nella somma a+b = c il vettore a ha modulo 12 e forma un angolo di 40° rispetto al semiasse positivo delle ascisse, mentre il vettore c ha modulo 15 ed è diretto con un angolo di 20° in senso antiorario rispetto al semiasse negativo delle ascisse. Calcolare il modulo e la direzione (rispetto al semiasse positivo delle ascisse) di b. 
!36"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#36,36,"Esercizio Dati nel piano cartesiano i punti A = (1, 1), B = (3, 4) e  C = (5, 2), determinare il valore dell’angolo formato dai segmenti CA e CB e l’area del triangolo ABC. 
!37"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#37,37,"EsercizioDeterminare il volume del parallelepipedo individuato dai vettori   ˆˆˆˆˆˆˆ2,3,32ajkbjcjkιι=−+=−=−+−!!!
!38"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#38,38,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it www.unibo.it/docenti/lorenzo.rinaldi
!39"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#4,4,"!5Versore•Versore: vettore di modulo unitario, adimensionaleUn versore individua un asse orientatoAB"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#5,5,"I versori dove non te li aspetti
!6"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#6,6,"!7LA componente ed IL componente
vu = v cosθla componente
(vu = v cosθ u) il componenteLA componente è una grandezza scalare!IL componente è un vettore (il vettore componente lungo una direzione)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#7,7,!8Algebra dei vettori•I vettori liberi costituiscono un’algebra –È definita l’operazione somma tra due vettori –È definita l’operazione di moltiplicazione tra un vettore ed uno scalare •Inoltre: sono definiti un prodotto esterno ed uno interno –Prodotto scalare: –Prodotto vettoriale:
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#8,8,"!9Somma tra due vettori•Prototipo: somma tra due vettori spostamentoABCD
Regola del parallelogramma: Il vettore somma è dato dalla diagonale (C-A) del  Parallelogramma costruito  con i vettori (B-A) e (C-B)B≡C⃗c=⃗a+⃗b=(D−A)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#9,9,"!10Proprietà commutativa della somma•La somma gode della proprietà commutativa: 
•È un risultato sperimentale, non teorico, valido nel nostro ambiente. Ci sta dicendo che lo spazio fisico in cui viviamo è in buona approssimazione uno spazio euclideo."
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#0,0,CINEMATICA CdS Ingegneria InformaticaA.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#1,1," 2Modello base•Punto materiale: –Punto geometrico –Dotato di una proprietà chiamata massa •Valido per la descrizione del moto di ogni oggetto, quando le dimensioni dello stesso non sono importanti e possono essere trascurate"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#10,10," 11Velocità scalare, vettoriale, versore tangente
Nella rappresentazione intrinseca: v(t)=limΔt→0P(t+Δt)−P(t)Δt=dPdt v(t)=s(t)=limΔt→0s(t+Δt)−s(t)Δt⎯⎯→⎯→Δ0t)()()()(lim0tvtsttsttst==Δ−Δ+=→Δ"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#11,11," 12Velocità: derivata del vettore posizione
xyzP(t)
Nella rappresentazione cartesiana:"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#12,12," 13Derivata di un vettore⃗a=⃗a(t)=B(t)−A(t)d⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δtd⃗adt è un vettored⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δt⃗a(t)⃗a(t+Δt)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#13,13," 14Regole di derivazione
Dimostrabili tramite la rappresentazione cartesiana dei vettori"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#14,14,"se a(t)=λ costante   ⇒da2dt=0 per ipotesida2dt=da⋅a()dt=dadt⋅a+a⋅dadt=2a⋅dadt≡0⇒a⊥dadt
 15Esempi e dimostrazioni•Tutte le relazioni si dimostrano facilmente nella rappresentazione cartesiana:•Caso notevole: vettore di modulo costante.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#15,15," 16Cinematica: Riassunto•Il moto è sempre un fenomeno relativo
Moto di un punto (P) rispetto ad un sistema di riferimento (SR)TraiettoriaDescrizione cartesianaEquazioni  parametricheVettore posizionexyz"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#16,16," 17Velocità e descrizione intrinseca
xyzOΩss: ascissa/coordinata curvilinea
Velocità scalare istantanea
Velocità vettoriale  istantanea
Rappresentazione cartesianaRappresentazione intrinsecaversore tangente alla traiettoria"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#17,17," 18Accelerazione scalare media ed istantanea•Analogamente a quanto fatto per la variazione della posizione, si introduce il concetto di accelerazione per descrivere le variazioni di velocità •Data la velocità scalare istantanea   Accelerazione scalare mediaAccelerazione istantanea   a(t)=limΔt→0am(t,t+Δt)=limΔt→0v(t+Δt)−v(t)Δt=dvdt=!v   a(t)=dvdt=!v=d2sdt2=!!s  am⎡⎣⎤⎦=a⎡⎣⎤⎦=ΔvΔt⎡⎣⎢⎤⎦⎥=LT−1/T⎡⎣⎤⎦=LT−2⎡⎣⎤⎦→(m/s2)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#18,18," 19Accelerazione vettorialeAccelerazione mediaAcc. Istantanea !a=limΔt→0!am=limΔt→0!v(t+Δt)−!v(t)Δt"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#19,19," 20Esercizio 1•Il movimento di un punto dello spazio è descritto dal vettore posizione: •Trovare la velocità vettoriale e scalare •Trovare l’accelerazione vettoriale •Calcolare l’angolo tra il vettore velocità e quello accelerazione e spiegare il risultato ottenuto.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#2,2,"•La terra non ruota solo su se stessa: ruota intorno al Sole a una velocità superiore a 110.000 km/h.
Qual è la nostra VELOCITÀ?Vi sembra di essere seduti immobili mentre ascoltate la lezione?
 3•Il pianeta ruota su se stesso, il che significa che in realtà viaggiamo verso est a una velocità che può raggiungere i 1600 km/h .
•Il Sole e il Sistema Solare viaggiano nello spazio alla folle velocità di 2 milioni di km/hQual è la nostra vera VELOCITÀ? "
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#20,20," 21Esercizio 2•In un piano xy, un punto materiale si muove seguendo le leggi: •Trovare il vettore posizione •Trovare la velocità scalare al tempo t=10s •Mostrare che l’accelerazione è costante
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#21,21," 22Rapp. Intrinseca: versore normale
Traiettoria circolare
Δ̂utΔs⟶α,Δs→0d̂utds=d̂utdŝun"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#22,22," 23Componenti intrinseche dell’accelerazione
Circonferenza osculatrice (nel piano osculatore)ρ = raggio di curvatura (funzione di s)Espressione intrinseca"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#23,23," 24Rappresentazione intrinseca del moto•Traiettoria:•Legge oraria:•Versore tangente: •Versore normale: •Versore binormale: Terna intrinseca  di versori  Ortonormali  •Raggio di curvatura: •Velocità: •Accelerazione: •Legge oraria:   →!v=""s=vx2+vy2+vz2"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#24,24," 25Classificazione dei moti - I1. Moto a velocità costante:
xyzOMoto rettilineo  uniforme"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#25,25," 26Classificazione dei moti - II2. Velocità costante in direzione
xyzOEsempio: Moto uniformemente  accelerato"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#26,26," 27Classificazione dei moti - III3. Moto a modulo di velocità costanteEsempio: Moto circolare uniformeMoto uniformemente curvo
xyzOΩs"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#27,27," 28Classificazione dei moti - IV4. Moto senza vincoli sulla velocitàMoto curvo varioxyzOΩs"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#28,28," 29Osserviamo la realtà che ci circonda …Perché le curve in autostrada sono sempre molto dolci (→ hanno un raggio di curvatura di centinaia di metri), mentre in campagna mi trovo anche curve molto secche (a 90° in pochi metri)?Perché NON ESISTONO curve in autostrada con raggio inferiore a diverse centinaia di metri, ad eccezione dei raccordi per i caselli, dove, se non si rallenta opportunamente, è facile finire fuori strada?Perché i progettisti delle tratte ferroviarie dell’alta velocità considerano sempre traiettorie con raggi di curvatura di qualche km, quando in stazione ci sono curve con raggi di curvatura di qualche decina di metri?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#29,29," 30Espressioni cartesiane
 an=!s2ρ→ρ=!s2an"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#3,3," 4Cos’è il moto?•Il moto è sempre un fenomeno relativo•Moto di una macchina rispetto ad una strada•Moto di un aereo rispetto alle nuvole, al terreno•Moto di un pianeta rispetto alle stelle ﬁsse•Moto di un sistema osservato rispetto all’osservatoreESEMPIMoto di un punto (P) rispetto "
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#30,30," 31Problemi di cinematica•Problema DIRETTO della cinematica: dato il vettore posizione, trovare velocità ed accelerazione: •Problema INVERSO della cinematica: data l’accelerazione (o la velocità), trovare velocità e vettore posizione !at() noto ⇒ !vt()=?!rt()=?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#31,31," 32Problema inverso•Tipico problema: nota la velocità:
L’analisi illustra che esistono ∞3 soluzioni (moti diversi)La richiesta che il sistema di equazioni abbia  una sola soluzione richiede l’introduzione di altri dati:  le condizioni iniziali"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#32,32," 33Esempio di problema inversoCostanti arbitrarieCondizioni iniziali: Soluzioneunivoca"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#33,33," 34Esempio: problema inverso unidimensionale•ES:Sia                  , trovare il moto x(t).Soluzione: txk=-2k=0k=-1k=+1Moltitudine di moti diversi!Condizioni iniziali:  x(0)=0Un moto particolareSoluzione: k=0"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#34,34," 35Esempio•Un punto materiale si muove lungo l’asse x con una accelerazione data da •Sapendo che le condizioni iniziali sono •Trovare velocità e posizione ad ogni istante di tempo"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#35,35," 36Soluzione•Velocità:• Posizione:dv adt→=→dv∫=adt∫"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#36,36," 37Esercizio 1 La posizione di un punto materiale è individuata dal vettore posizione con t  espresso in secondi ed r in metri. Determinare la velocità e l’accelerazione ad ogni istante di tempo, la terna di versori intrinseca ed il raggio di curvatura della traiettoria per t=0 s.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#37,37," 38Esercizio 2In un certo istante, un punto materiale è in moto lungo un arco di circonferenza. Sapendo che rispetto ad un certo SR, la velocità e l’accelerazione valgono  e determinare la velocità scalare, l’accelerazione tangenziale, il raggio di curvatura della traiettoria e la normale al piano in cui avviene il moto. 
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#38,38," 39Moti nel piano
XYP1y(t)Ox(t)Equazioni parametriche
Equazione della traiettoria"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#39,39," 40Moto rettilineo uniforme
XYP1y(t)Ox(t)Equazioni parametricheVelocità ed accelerazioneda x=x0+v0xt→t=x−x0v0xintercettapendenza"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#4,4," 5Scelta del sistema di riferimento•Lo stesso oggetto può essere descritto in modo diverso a seconda del SR:Moto della lavagna (e di tutti noi):•Ferma rispetto a noi (SR della stanza)•Moto circolare per chi ci osserva dalla luna (SR lunare; velocità circa 1200 km/h)•Moto + complesso per chi ci osserva dal Sole (SR eliocentrico; velocità circa 108000 km/h)•Moto ancora più complesso per chi ci osserva dal centro della Galassia!Scegliamo un SR a seconda di cosa si muove e di come vogliamo descrivere il moto"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#40,40," 41Moto dei gravi•Caduta di un corpo sulla superficie terrestre
XYy(t)Ox(t)costantealtoAsse orizzontaleCondizioni iniziali"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#41,41," 42Moto dei gravi: soluzione
•Traiettoria:→y=ax2+bx+c"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#42,42," 43Caduta dei graviOggetto che cade da fermo da un’altezza hCaso particolare con condizioni iniziali (con t0=0): {⃗r0=ĥ𝚥⃗v0=⃗0{x0=0y0=hv0x=0v0y=0{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2traiettoria: linea retta (asse y)XYO"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#43,43," 44Caduta dei gravi{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2
XYOTempo di caduta (da altezza h):y(tc)=0h−g2t2c=0tc=2hgVelocità d’impatto al suolo⃗v(tc)=−gtĉ𝚥⃗v(tc)=−g2hĝ𝚥=−2gĥ𝚥"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#44,44," 45Moto dei gravi:  generale•La traiettoria è una parabolaXYy(t)Ox(t)altoAsse orizzontaleCoordinate del punto di massimo della parabola?In quale punto dell’asse x atterra ? (y=0)A che istante e con che velocità ci arriva?Rappresentazione intrinseca:velocità e accelerazione?terna di versori intrinseca?raggio di curvatura?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#45,45," 46Coordinate Polari piane
xyPvettore posizione del punto Pin coordinate cartesiane⃗r=x̂ı+ŷ𝚥
{x=rcosφy=rsinφpotremmo usare un’altra coppia di scalari: + distanza r dall’origine e angolo 𝜑 rispetto ad asse x̂ı̂𝚥φrtrasformazioni delle coordinater=x2+y2φ=arctanyx"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#46,46," 47Coordinate Polari piane
xyP{x=rcosφy=rsinφ̂ı̂𝚥φrr=x2+y2φ=arctanyxversori in coordinate polari pianêur=(̂ur⋅̂ı)̂ı+(̂ur⋅̂𝚥)̂𝚥=cosφ̂ı+sinφ̂𝚥⃗r=x̂ı+ŷ𝚥̂uφ=(̂uφ⋅̂ı)̂ı+(̂uφ⋅̂𝚥)̂𝚥=−sinφ̂ı+cosφ̂𝚥̂ur̂uφsi veriﬁca facilmented̂urdφ=̂uφd̂uφdφ=−̂urcambiano durante il moto!α=φ+π2cosα=−sinφsinα=cosφ"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#47,47," 48Coordinate polari cilindriche
xyzPϕzrP’̂ur̂uφ̂uz
̂ur̂uz{x=rcosφy=rsinφz=zr=x2+y2φ=arctanyxz=ẑur=cosφ̂ı+sinφ̂𝚥uφ=−sinφ̂ı+cosφ̂𝚥̂uz=̂k̂uφterna ortogonalêur=̂uφ∧̂k"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#48,48," 49Moto circolare
xyP(t)ascissa curvilinea s (con origine sull’asse x)s=RφTraiettoria circolare di raggio R centrata nell’origine di un SdR cartesianoRarco di circonferenzaφΩs[0≤s≤2πR]{x(φ)=Rcosφy(φ)=RsinφNel SdR cartesiano⃗r(φ)=Rcosφ̂ı+Rsinφ̂𝚥⃗r(s)=Rcos(sR)̂ı+Rsin(sR)̂𝚥|⃗r|=R
la posizione dipende solo dall’angolo 𝜑⃗r(φ)=R̂urs(t)=Rφ(t)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#49,49," 50Cinematica del moto circolare⃗r(φ(t))=Rcosφ(t)̂ı+Rsinφ(t)̂𝚥=R̂ur⃗v(φ(t))=d⃗rdt=−R·φsinφ̂ı+R·φcosφ̂𝚥=R·φ̂uφ⃗a(φ(t))=d⃗vdt==(−R··φsinφ−R·φ2cosφ)̂ı+(R··φcosφ−R·φ2sinφ)̂𝚥==R··φ(−sinφ̂ı+cosφ̂𝚥)−R·φ2(cosφ̂ı+sinφ̂𝚥)==R··φ̂uφ+R·φ2(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#5,5," 6Sistema di riferimento cartesianoTraiettoria Luogo dei punti dello spazio per cui passa un corpo P=P(t)
xyz
= Descrizione cartesianaEquazioni  parametricheOVettore posizione
r⎡⎣⎤⎦=x⎡⎣⎤⎦=y⎡⎣⎤⎦=z⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#50,50," 51Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φaccelerazione angolareα=·ω=··φ⃗v=R·φ̂uφ=Rω̂uφ=Rω̂k∧̂ur=(ω̂k)∧(R̂ur)=⃗ω∧⃗rvettore velocità angolarêuφ=̂k∧̂ur⃗v=⃗ω∧⃗r⃗ω=ω̂k⃗a=Rα̂uφ+Rω2(−̂ur)=⃗α∧⃗r−ω2⃗rvettore accelerazione angolare⃗α=α̂k⃗a=ddt(⃗ω∧⃗r)=d⃗ωdt∧⃗r+⃗ω∧d⃗rdt=ur=̂uφ∧̂k
⃗at=⃗α∧⃗r⃗an=⃗ω∧⃗v=⃗ω∧(⃗ω∧⃗r)=⃗α∧⃗r+⃗ω∧⃗v=⃗α∧⃗r+⃗ω∧(⃗ω∧⃗r)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#51,51," 52Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φ=ddt(sR)=·sR=vRaccelerazione angolareα=·ω=ddt(·sR)=··sRangoloφ=sR⃗v=Rω̂uφ=·ŝuφ⃗a=Rα̂uφ+Rω2(−̂ur)=··suφ+·s2R(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#52,52," 53Cinematica del moto circolare⃗r=R̂ur⃗v=R·φ̂uφ=Rω̂uφ⃗a=R··φ̂uφ+R·φ2(−̂ur)=xyφR̂ur̂uφ=Rα̂uφ+Rω2(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#53,53," 54Moto circolare uniforme⃗r=R̂ur⃗v=Rω̂uφ=⃗ω∧⃗rx̂uryφR̂uφ⃗a=−Rω2(̂ur)=−ω2⃗r=⃗ω∧(⃗ω∧⃗r)velocità costante in modulo ma varia continuamente in direzioneω=·φ=costanteα=·ω=0
accelerazione (centripeta) costante in modulo ma varia continuamente in direzione"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#54,54,"Moti periodici•Un fenomeno è detto periodico se, a partire da un istante qualsiasi t, le sue caratteristiche si ripresentano inalterate dopo un certo intervallo di tempo T, detto periodo. •Quantità caratteristiche: –       ,  periodo fondamentale; –         , frequenza (numero di T contenuti nell’unità di tempo); –          , pulsazione (numero di giri compiuti nell’unità di tempo sulla traiettoria chiusa) υ=1Tω0=2πTTmin
 55 !r(t+nT)=!r(t)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#55,55,"Esempio di moto periodicoMoto circolare uniforme:→v=costantexy !r•In coordinate cartesiane:Tutte le equazioni:hanno la stessa famiglia di soluzioni: 56
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#56,56," 57Soluzione generale•Problema di base:Ipotesi di soluzione:f+ω2f=0→"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#57,57," 58Moto oscillatorio armonicoTraiettoria Equazione oraria 
x+l-l"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#58,58," 59Moto armonico: condizioni inizialiSia dato un moto armonico di pulsazione ω e condizioni iniziali x(0)=x0 e v(0)=v0. Trovare la legge oraria.Soluzione:  Equazione del moto armonico:Soluzione generale:Velocità:Accelerazione:Impongo le condizioni iniziali:x(0)=Acos(φ0)=x0x(0)=−ωAsin(φ0)=v0→⎧⎨⎪⎩⎪"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#59,59," 60Esercizio•Dati due moti armonici di pulsazione ω nel piano con condizioni iniziali:
Trovare leggi orarie e traiettoriaMoto A xA0()=x0!xA0()=0⎧⎨⎪⎩⎪yA0()=y0!yA0()=0⎧⎨⎪⎩⎪Moto B xB0()=x0!xB0()=0⎧⎨⎪⎩⎪yB0()=0!yB0()=ωx0⎧⎨⎪⎩⎪"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#6,6," 7TraiettoriaLuogo dei punti dello spazio per cui passa un corpo (entità unidimensionale)P=P(t)xyzOP1=P(t1)P2=P(t2)Equazione parametrica della traiettoria:ParametriVettore spostamentor⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#60,60,"Moti relativi
 61
P(')(')POOOPO−=−+−
()rrOOʹʹ=+−!!Posizioner!rʹ!
''PPOrrr=+!!""'Or!‘‘‘‘‘‘‘
SS’S: sistema di riferimento fermoS’: sistema di riferimento mobile
SS’"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#61,61,"Trasformazione della velocità (opz)
 62Velocità''Orrr=+!!!ˆˆˆˆˆˆ(')(')''''''(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!ˆˆˆ'(')''''''ˆˆˆ()(')(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!
Pr!rʹ!
'Or!’’’’’’’ˆˆˆ'''''''xiyjzk=++v!""""""ˆˆˆxiyjzk=++v!""""""ˆˆˆˆˆˆ'('''''')'''ˆˆˆ'''''''''drdxiyjzkddjdkxiyjzkxyzdtdtdtdtdtι++==+++++!""""""ˆˆˆ'''ddjdkdtdtdtιQuanto valgono                          ?
!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#62,62,"Formule di Poisson (opz)•Quindi:
 63ˆ'ddtιDerivata di un vettore di modulo costanteˆˆ''ˆˆˆ'''ddajbkdtdtιιι⊥=+drrdtω==×v!!!!Vista nel moto circolare uniforme. E’ generalizzabile !Formule di Poisson: esiste un unico       per cui:ˆ'ˆ'ˆ'ˆ'ˆ'ˆ'ddtdjjdtdkkdtιωιωω⎧=×⎪⎪⎪=×⎨⎪⎪=×⎪⎩!!!ω!ˆˆˆ''''''ˆˆˆ'(')'(')'(')ˆˆˆ('''''')'ddjdkxyzdtdtdtxyjzkxyjzkrιωιωωωιω++==×+×+×==×++=×!!!!!!ω!Descrive la rotazione di S’ rispetto ad S: asse + velocità angolare"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#63,63,"Trasformazione della velocità (opz)•Posizione:
 64''Orrr=+!!!ˆˆˆ'''''''xiyjzk=++v!""""""ˆˆˆxiyjzk=++v!""""""•Velocità:•Trasformazione:•Velocità di trascinamento:•Un punto fermo in S’ si muove di velocità     in STv!Addizione delle velocità!v=!v'+!ω×!r'+!vO'!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'=!v'+!ω×!r'+!vO'!vT=!ω×!r'+!vO'!v=!v'+!vT"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#64,64,"Trasformazione dell’accelerazione (opz)
 65Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!""""""""""""""""""""""""'ˆˆˆˆˆˆˆˆˆˆˆˆ('''''''''''')('''''''''''')Oxiyjzkxiyjzkxiyjzkxiyjzka=++++++++++++=!""""""""""""""""""""""""""""""""""""""""""""""""ˆˆˆˆˆˆˆˆˆ('''''')'(')''''('''''')'xiyjzkxiyjzkxiyjzkωωωωω++=×+×+×=×++=×v!!!!!!""""""""""""""""""""""""NB:()ˆˆˆ'(')'ˆˆˆˆ''''diddiidtdtdtωιωιωωιωωι×===×+×=×+××!""!!!!!""""""""
!v=""xˆi+""yˆj+""zˆk=""x'ˆi'+""y'ˆj'+""z'ˆk'+x'ˆ""i'+y'ˆ""j'+z'ˆ""k'+!vO'!v'=""x'ˆi'+""y'ˆj'+""z'ˆk'!a=d!vdt=ddt(""x'ˆi'+""y'ˆj'+""z'ˆk'+x'ˆ""i'+y'ˆ""j'+z'ˆ""k'+!vO')=
x'ˆ!!i'+y'ˆ!!j'+z'ˆ!!k'==x'(!""ω×ˆι'+!ω×!ω×ˆι'())+y'(!""ω×ˆj'+!ω×!ω×ˆj'())+z'(!""ω×ˆk'+!ω×!ω×ˆk'())==!""ω×(x'ˆi'+y'ˆj'+z'ˆk')+!ω×!ω×(x'ˆi'+y'ˆj'+z'ˆk')()=!""ω×!r'+!ω×!ω×!r'()"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#65,65,"Trasformazione dell’accelerazione
 66Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!""""""""""""""""""""""""()''2'''odaarradtωωωω==+×+×+××+vv!!!!!!!!!!!""()'''Toarraωωω=×+××+!!!!!!!""Accelerazione di trascinamento:Un punto fermo in S’ si muove di accelerazione     in STa!'2''TCOTaaaaaaω=+×+=++v!!!!!!!!2'COaω=×v!!!Accelerazione di Coriolis:"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#66,66,"SR in moto rettilineo uniforme
 67
''Orrr=+!!!
xyzx’y’z’'Ov!
'aa=!!P(t)O’O00COTaa==!!!!
()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!""
Trasformazioni di Galileo!vO'=costante,!ω=!0x(t)=x'(t)+vO'ty(t)=y'(t)z(t)=z'(t)!v(t)=!v'(t)+!vO'=vx(t)=vx'(t)+vO'vy(t)=vy'(t)vz(t)=vz'(t)⎧⎨⎪⎩⎪!vT=!vO'
!v=!v'+!vT!vT=!vO'+!ω×!r'"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#67,67,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.itwww.unibo.it/docenti/lorenzo.rinaldi
 68"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#68,68,"Argomenti opzionali
 69"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#69,69," 70Velocità areolare
A(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#7,7," 8Rappresentazione intrinseca
xyzOΩss: ascissa curvilineaDescrizione intrinseca: -Geometria della traiettoria -Origine Ω, verso della traiettoria  -Coordinata curvilinea s(t)s(t)⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)origine della traiettoriaverso"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#70,70," 71Accelerazione Areolare•Velocità areolare•Accelerazione areolare   costante in direzione à il moto si svolge su un piano   costante à                    MOTO CENTRALE à                    MOTO RETTILINEOClassiﬁcazione dei moti"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#71,71,"SR in rotazione uniforme
 72
xy  x’y’O=O’Pr
'Trrωω=×=×v!!!!!
'rr=!!
()'2'COTCOTaaaaaarωωω=++=×=××v!!!!!!!!!!!Un punto fermo in S’ ha accelerazione                                  in S()Tarωω=××!!!!
''Orrr=+!!!
()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!""
!v=!v'+!vT!vT=!vO'+!ω×!r'
!v=!v'+!ω×!r!rO'=!0,!ω=costante"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#72,72,"Esercizio•Nei pressi di un incrocio a 90° tra due strade si urtano due macchine che viaggiavano rispettivamente a 40 km/h e 50 km/h. Determinare la velocità relativa dell’urto (velocità di una macchina come misurata da un osservatore solidale con l’altra) quando: –L’urto è frontale –L’urto è un tamponamento –L’urto avviene tra due macchine che viaggiavano su due strade a 90° tra loro.
 73"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#73,73,"Caso 1: tamponamento
 74
150/kmh=v
240/kmh=vx’y’z’xyz!v2=!v'2+!vO'=40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−10km/hˆι"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#74,74,"Caso 2: urto frontale
 75
150/vkmh=
240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=−40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−90km/hˆι"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#75,75,"Caso 3: urto a 90 gradi
 76
150/vkmh=
240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=40km/h ˆk!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−50ˆι+40ˆk()km/h!v'2=502+402=64km/h"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#76,76,"Esercizio•Su una giostra costituita da una piattaforma rotante si trova un bambino con in mano una pallina. La giostra ruota con una velocità angolare pari a 0.5 s-1 quando, il bambino, che si trova a 4 m dall’asse di rotazione, lancia la pallina con una velocità iniziale pari a 3 m/s. Calcolare la velocità che ha la pallina per un osservatore solidale con il terreno quando il bambino lancia la pallina: –Verso l’asse di rotazione della giostra –In direzione radiale –In orizzontale a 90° dalla direzione radiale. 77"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#77,77,"Impostazione della soluzione
 78
xy  x’y’O=O’r
vʹ!
'vvrω=+×!!!!
Caso 2:Caso 3:5(/)vms=!!rO'=!0,!ω=costante=0.5ˆk!r=!ʹr=4ˆι(m)
!v=−3ˆι+0.5⋅4ˆk∧ˆι=−3ˆι+2ˆjCaso 1:!ʹv=3ˆk(m/s)
!v=3ˆk+0.5⋅4ˆk∧ˆι=3ˆk+2ˆj!ʹv=−3ˆι(m/s)
!ʹv=3ˆj(m/s)
!v=3ˆj+0.5⋅4ˆk∧ˆι=5ˆj!v=13 (m/s)!v=13 (m/s)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#78,78,"Esercizio •Calcolare i moduli delle velocità e dell’accelerazione di un corpo fermo sulla superficie terreste a 45° di latitudine rispetto ad un SR con origine nel centro della terra e assi rivolti verso le stelle fisse.
 79"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#8,8," 9Velocità scalare media ed istantanea
Velocità scalare istantanea
Velocità scalare mediavm⎡⎣⎤⎦=v⎡⎣⎤⎦=ΔsΔt⎡⎣⎢⎤⎦⎥=L/T⎡⎣⎤⎦=LT−1⎡⎣⎤⎦→(m/s)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#9,9," 10Velocità vettoriale media ed istantanea
Velocità vettoriale media Velocità vettoriale Istantanea"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#0,0,Moti in SR NON INERZIALI CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#1,1,"LAURA FABBRI  -
Moti in SR in moto relativo: cinematica
!7Cinematica: movimento è un concetto relativo, legato al SR scelto.ES: oggetto lasciato cadere sul vagone di un treno in moto:  - Cade lungo la verticale per un osservatore sul treno,  - Compie una traiettoria parabolica per osservatore a terra.Entrambi i moti sono veri rispetto al loro SR.  Cambia la descrizione di posizione, velocità…. Un SR può essere solo più “conveniente” computazionalmente
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#10,10,"LAURA FABBRI  -
Cosa misura una bilancia  in ascensore?
!50
Ascensore fermo:Ascensore in salita con      costante. Se l’ascensore sale, un corpo fermo in esso sentirà una forza fittizia diretta come  Ascensore in discesa con      costante. Se l’ascensore scende, un corpo fermo in esso sentirà una forza fittizia diretta come  Caso limite: caduta libera→P→/u1D445/u1D463’’"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#2,2,"LAURA FABBRI  -
Moti in SR in moto relativo: dinamica
!11Due principi fondamentali:•Tutti i sistemi di riferimento inerziali sono equivalenti;•Nei SRI le leggi della fisica sono le stesse e per il secondo principioCosa succede se studio il moto in un SR NON INERZIALE?"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#3,3,"LAURA FABBRI  -
Moti in SR Non inerziali
!14
Es: treno in moto con velocità costante. Ragazzo seduto sul treno con un cubetto di ghiaccio sul vassoio. Due SR: S solidale a un osservatore a terra    S’ solidale con l’osservatore sul trenoIn S: sul cubetto non agisce nessuna forza -> si muove con la stessa velocità del SRIn S’: sul cubetto non agisce nessuna forza -> è fermo nel SR "
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#4,4,"LAURA FABBRI  -
Moti in SR Non inerziali
!19
Se treno in moto decelera improvvisamente….In S’ il cubetto vola fuori dal vassoio come se fosse sottoposto a una forza in avanti. È reale?Forza reale: attrito esercitato tra treno e binari, che ha coinvolto tutti gli oggetti solidali al treno in moto. Forza non ha agito sugli oggetti sul treno non solidali ad esso. Moto improvviso non dovuto a forze sull’oggetto ma a forze sul SR che non è più inerziale"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#5,5,"LAURA FABBRI  -
Sistemi di riferimento non inerziali
!23•Esiste una classe di sistemi di riferimento in cui NON vale il secondo principio della dinamica: sistemi di riferimento non inerziali •I SR non inerziali sono tutti quelli in moto accelerato rispetto ad un SRI. Es: veicolo in partenza, veicolo in frenata, piattaforma rotante….•Nel SR non inerziale compaiono forze dette fittizie dovute all’accelerazione del nuovo SR.•In un SR non inerziale possiamo scrivere il secondo principio a patto di usare come risultante delle forze sia quelle reali che quelle fittizie"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#6,6,"LAURA FABBRI  -
Forze fittizie
!30
‘‘‘‘‘‘‘SS’
Forza di CoriolisForza centrifuga→/u1D439′ =/u1D45A→/u1D44E′ (/u1D461)=/u1D45A(→/u1D44E−→/u1D44E/u1D450/u1D45C−→/u1D44E/u1D461)S’: sistema di riferimento mobileS: sistema di riferimento fermoUn osservatore in S’ direbbe che sul corpo agisce una forza        tale che:Corpo in S sente una forza reale 
Forza fittizia"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#7,7,"LAURA FABBRI  -
Forza centrifuga
!35
-In S (SRI) solidale alla strada agisce una forza reale: forza centripeta;-Oggetti dentro la macchina non sentono l’azione dell’attrito fra ruote e strade e tendono a mantenere il moto rettilineo per il primo principio.  -In S’ (SR NON I) solidale alla macchina: osservatore dentro la macchina si sente spinto verso l’esterno dalla forza centrifuga: •Forza fittizia; •Stesso modulo e direzione della forza centripeta ma verso oppostoForza a cui è soggetto un corpo in moto curvilineo: es macchina in curva"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#8,8,"LAURA FABBRI  -
Forza di Coriolis
!40Piattaforma che ruota con velocità angolare costante e corpo lanciato radialmente con velocità iniziale non nulla.In S SRI solidale al terreno moto della pallina rettilineo uniforme poichè non agiscono forze (primo principio).In S’ SR non I solidale alla piattaforma: pallina risente della forza fittizia di CoriolisyxˆjˆiForza a cui è soggetto un corpo in moto in un sistema di riferimento in rotazione
Traiettoria circolare verso destra rispetto osservatore in S’→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ 
→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ =−2/u1D45A(/u1D714^/u1D458)×(/u1D463^/u1D456)=−2/u1D45A/u1D714/u1D463^/u1D457"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#9,9,"LAURA FABBRI  -
Forza di Coriolis
!45
•Le masse d’aria si spostano dall’alta pressione H alla bassa pressione L: vento di ciclone; •H e L separate di 1000 km; •Emisfero settentrionale: correnti d’aria tendono verso L deviando a destra; •Vortice ciclonico che ruota in senso antiorario nell’emisfero nord e in senso orario nell’emisfero sudResponsabile di molti fenomeni visibili: •Sbilanciata usura dei binari dei treni orientati secondo i meridiani: treno da nord a sud usura maggiormente il binario di destra; •Moto dei gravi su lunghe distanze (missili…); •Circolazione dei venti→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ "
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#0,0,"Forza: dinamometro•Definizione operativa della forza. •Dinamometro: strumento graduato contente una molla ideale, elastica, deformabile.
!1
0
01
02
03Calibrazione del dinamometro tramite peso campione: unità kg-forza"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#1,1,"Modello del filo inestensibile•Filo ideale senza massa, in grado di trasportare una forza (TENSIONE) senza allungarsi.
!2
01
01
01
01
Il filo è in grado di trasportare una tensione.  Il dinamometro si allinea al filo.Ciò che misura un dinamometro è un vettore: -Direzione (del filo) -Verso (il filo tira) -Intensità (scala graduata)La forza è un vettore"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#10,10,"Esercizio 2•Un acrobata, stando nel punto di mezzo di una fune lunga 18 m, esercita una forza di 700 N e fa abbassare la fune di 1.5 m rispetto alle estremità. Determinare la tensione T della fune.
!11
P!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#11,11,"Esercizio 3•Una sfera di peso 4 kg-f si ferma tra due piani inclinati di 30° e 60°. Determinare le reazioni vincolari delle superfici.
!12
P!
P!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#2,2,"03
Come funziona un dinamometro?•Il dinamometro misura una forza       esterna generando una forza         tale che
!3
03
F!F−!dinFkl=−Δ!!""""Legge di HookeestF!dinF!
0estdinFF+=!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#3,3,"Natura vettoriale delle forze
!4
02
03
021F!2F!3F!23FF+!!1230FFF++=!!!!In condizioni statiche! (Macchina di Atwood)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#4,4,"Quiete, equilibrio e statica
!5Equilibrio: se un sistema (insieme di punti o di corpi) inizialmente quiete in un dato SdR, pur soggetto a forze rimane in quiete, allora esso si trova in uno stato di equilibrio.Quiete: un punto (o un corpo) è in quiete in un dato SdR, se il punto (o ogni punto del corpo) ha una velocità nulla in ogni istante di tempo (è e rimane fermo). Assenza di velocità!
Statica: studio delle forze nei sistemi in stato di equilibrioEquilibrio stabile: piccole variazioni nel sistema portano a piccoli spostamenti dalla posizione di equilibrio Equilibrio instabile: piccole variazioni nel sistema portano a grandi spostamenti
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#5,5,"Statica del punto materiale•Risultato sperimentale: il punto è in quiete se:
!61F!2F!
3F!1234RFFFF=+++!!!!!
4F!
12340RFFFF=+++=!!!!!!Risultante delle forze applicate al puntoCondizione necessaria per l’equilibrio di un punto materiale è che si annulli la risultante        di tutte le forze ad esso applicate.R!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#6,6,"Studio statico delle forzeFORZA PESO
!7
01!P!FdinIdea: applicare ad un corpo una forza tramite il dinamometro, adattando verso, direzione e modulo fino a raggiungere l’equilibrio!Fdin+ EQ ⇒!R=0!R=!Fdin+ ?
Ad ogni punto materiale posto in prossimità della superficie terrestre risulta applicata una forza diretta lungo la verticale, verso il basso, con intensità dipendente dal corpo materiale.!P=−!Fdin"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#7,7,"REAZIONE VINCOLARE
!8
!P!RV!P+ EQ ⇒!R=!P+!RV!RV=−!P
!F
Quando la superficie di un corpo materiale C, giungendo a contatto con la superficie di un corpo materiale V (vincolo) esercita su tale superficie una forza perpendicolare F, determina una deformazione di V che esercita a sua volta su C una forza RV uguale e contraria ad F   㱺  RV: normale alla superficie, uscente e di modulo dipendente dalla forza applicata F  CV!RV"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#8,8,"!9Un vincolo impedisce alcuni movimenti del corpo considerato e ne consente altri (es.: rotaia treno, cardine porta, piano su cui è appoggiato un oggetto, ecc.). Per impedire i movimenti vietati dei corpi, i vincoli debbono esercitare sui corpi delle forze, dette forze vincolari o reazioni vincolari.Le forze vincolari sono a priori sconosciute, in quanto debbono adeguarsi alle circostanze per neutralizzare le forze attive che potrebbero causare movimenti vietati.
Vincolo"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#9,9,"Vincoli ideali o lisci•Vincolo ideale o liscio: vincoli che non offrono resistenza apprezzabile quando le forze tendono a produrre degli spostamenti tangenziali rispetto alla loro superficie
!10
PF!VR!
PF!VR!•In caso contrario, se c’è resistenza ai movimenti tangenziali, parleremo di vincolo scabro (forze d’attrito)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#0,0,DINAMICA CdS Ingegneria InformaticaA.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#1,1,"Concetto di forza
 2Grandezza ﬁsica vettoriale (intensità, direzione, verso e punto di applicazione): vettore applicatoLe forze possono produrre variazioni dello stato di moto degli oggetti su cui agisconoLe forze possono deformare i corpi su cui agisconoLe forze possono compensarsi, determinando situazioni di equilibrioLe forze si presentano sempre in coppia: derivano sempre da interazioni tre i corpi, che esercitano forze l’uno sull’altro"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#10,10,"Formulazione esplicita del 2° principioNewton: “La forza è uguale alla massa per l’accelerazione."" 
 11
In un sistema di riferimento inerziale, la forza complessiva (totale, risultante) che agisce su un corpo materiale di massa m è tale che:Fma=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#11,11,"Unità di misura della forza
 122o Principio Unità di misura della massa nel sistema internazionale: chilogrammo (kg) Prototipo: cilindro di platino-iridio c/o Bureau International des Poids et Mèsures a Sèvres dal 22/5/2019 nuova definizione basata sulla costante di PlankUnità di misura della forza nel sistema internazionale: Newton (N) Corrisponde alla forza che, agendo su una massa di 1 kg le imprime un’accelerazione di 1 m/s2Unità di misura della forza nel sistema tecnico: chilogrammo-forza (kgf) È il peso del cilindro di cui sopra,nei luoghi in cui g=9,80665 m/s2, detto valore “standard”Per convenzione
Derivata per definizione
1kgf9.80665N;1N0.101972kgf==Per convenzione
!F=m!a
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#12,12,"Forza peso: misura della massa inerzialeN corpi con pesi
 13
a!!P29,8 m/sag==!12,,,NPPP!!!…12Naaag====!!!…12,,,Naaa!!!…cadono con accelerazionig=!Pmg=!!Osservazione sperimentale valida (con opportune approssimazioni) in ogni punto della Terra.Approssimazioni: ignoro gli attriti, la forma non sferica della terra, considero di essere in un SRI"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#13,13,"Misura della massa inerziale
 14Presa una massa campione      ho anche un peso campionecmccPmg=!!
Pmg=!!cP!cRPλ=!!ccPRPPλ==!!!!cccPmgmmgmPλ===!!!!Condizione di equilibrio:cPRPλ==!!!
ccPmmP=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#14,14,"Principi fondamentali•Il secondo principio NON è una definizione di forza
 15•SdR: Inerziale•La forza è ciò che indica il dinamometro•La massa è una proprietà dei corpi•L’accelerazione è una caratteristica cinematicaFma=!!•In ogni SRI vale:Fma=!!
''SSaa=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#15,15,"Indipendenza delle azioni simultanee
 16
TTFma=!!11Fma=!!22Fma=!!12FF=+=!!()12Tmaama=+=!!!2a!1a!
Ogni forza produce un effetto indipendentemente dalla presenza di altre forze.L’effetto complessivo è dato dalla risultante di tutte le forze applicate."
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#16,16,"Relazione tra moto e cause•Tutti i problemi di determinazione del moto di un corpo a partire dalle forze che agiscono sono problemi inversi di cinematica
 17Fma=!!Fam=!!nototrovare (),  ()atrt=v!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#17,17,"Moto circolare uniforme
nF!Rappresentazione intrinseca della forza
Moto rettilineo
 18
ˆtuˆnuF!tF!
ˆˆtnttnnFFFfufu=+=+!!!ˆˆ()ttnnFmamauau==+!!2forza tangenteforza centripetattnnfmafmamR===v00tnffR≠=→=+∞200/tnnffRmf=≠→=vˆˆttnnaauau=+!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#18,18,"Moto circolare uniforme
 19
F!r!v!drrdtω==×v!!!!costanterRωω===v!!!22costanteaRRωω====vv!!!??2nnFmafmamRω===!!
v!T!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#19,19,"Caduta dei graviGrave: punto materiale o oggetto in moto a causa del suo peso
 20
z
hPmg=!!ˆkProblema: studiare la caduta di un grave di massa m che parte da fermo da una quota hˆˆPmgmgkmzk==−=!!""""zg→=−!!0()(0)()tztzgdtʹ→=+−∫!!()ztgt→=−!200()(0)(')'''2ttgztzztdthgtdtht→=+=−=−∫∫!Legge oraria:2()2gztht=−Velocità:()ztgt=−!Tempo di caduta:2()0hhhzttg=→=vmax=v(th)=2gh"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#2,2,"Concetto di forza
 3Forze di contattomacroscopicamente sono associate ad un contatto tra corpi interagenti (es. spinta di un oggetto, forze elastiche)Forze a distanzaLe interazioni avvengono senza contatto (forza peso, forze elettriche e magnetiche)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#20,20,"Tutti i corpi cadono nello stesso modo
 21Tempo di caduta:2()0hhhzttg=→=
11Pmg=!!22Pmg=!!33Pmg=!!1ag=!!2ag=!!3ag=!!vmax=v(th)=2gh"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#21,21,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
 22()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#22,22,"Piano Inclinato liscio
 23
P!
VR!tP!nP!sintPPα=!
αcosnPPα=!hcosVnNRPPα===!!
 23|⃗PT|=Psinα=mgsinα=maa=gsinαcostante:moto unif. accel.Lunghezza del pianoL=hsinαs(t)=s0+vot+12at2L=hsinα=12gsinαt2v(t)=v0+att=2Lgsinα=2hgsin2αv(t)=gsinα2hgsin2α=2ghs0=0v0=0"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#23,23,"Forza elastica / Legge di Hooke•k costante elastica della molla. [k]=[MT-2]
 24
03
0
XF!
F!0F=!!ˆ()Ffxι=!(0)0f=0,()0xfx><0,()0xfx<>ˆFkxι=−!()fxx
Fkr=−!!0()Fkrr=−−!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#24,24,"Oscillatore armonico unidimensionale
 25
0
mˆFkxι=−!ˆaxι=!""""Fmakxmx=→−=!!""""0mxkx→+=!!0kxxm+=!!2pongo  0kmω=>20xxω+=!!
x+l-l
0(0)cos()xlφ=
0()cos()xtltωφ=+kmω=
000arctanxφω=−v()0220lxω=+v22mTkππω==SRIEquazione oraria "
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#25,25,"Regime delle piccole oscillazioni•Osservazione: ogni sistema in prossimità di un punto di equilibrio stabile si comporta come un oscillatore armonico
 26ˆ()Ffxι=!()fxx
()0fx=Punti di equilibrioAB()0Bfxʹ>xB punto instabile
()0Afxʹ<xA punto stabile
()2()()()()()AAAAfxfxfxxxOxxʹ+−+−!()()AAxxfxkxx→⎯⎯⎯→−−Moto oscillatorio attorno al punto di equilibrio stabile xA2():;2()AAkfxmTmmfxωπʹ−===ʹ−"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#26,26,"Pendolo sempliceGalileo: osservazione del moto del lampadario nel Duomo di Pisa
 271.Ampiezza max a DX = SX2.Il periodo del pendolo (T) è  indipendente dall’ampiezza massima3.Il periodo non dipende dalla massa ma solo dalla lunghezza del ﬁlo
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#27,27,"Pendolo semplice
 28
Metodo: 1.“Inquadrare” il problema 2.Scrivere la F = ma  3.Individuare il SdR migliore  4.Scrivere le equazioni parametriche 5.Integrare 6.Calcolare le costanti arbitrarie
0v!Ol
C
θslθ=
gmP!!=VR!RgmF!!!+=
ˆtuˆnu21ˆˆtnasusuρ=+!""""""
0(0)(0)0(0)(0)lslslρθθ=====v!!ˆˆsinttmsumguθ=−!!sin0glθθ+=!!()2ˆˆcosnVnsmumgRulθ=−+!2cosVmlmgRθθ+=!
am!=
Piccole oscillazioni (sinθ ≅ θ )0glθθ+=!!
()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#28,28,"Pendolo semplice II
 292cosVRmlmgθθ=+!()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v()2221122()cos,cos11sintttθαωωθθαω=−=−!""()()222222223122cos1sin1sinVRmltmgtmgtαωωαωααω=+−=+−Durante il moto, la reazione vincolare cambia. "
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#29,29,"Nota storica•Le oscillazioni di un pendolo hanno costituito un primo sistema meccanico per misurare il tempo
 30Esercizio pratico per casa:Costruire un pendolo e misurare l’accelerazione di gravitàElementi: punto ﬁsso, ﬁlo, massa, cronometro, metro
L22/TLgππω==
224LgTπ→=22/TLgππω==
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#3,3,"Forze fondamentali
 4
La maggior parte delle forze sono riconducibili alla forza elettromagnetica •Forze di contatto (attrito, viscosità, reazioni vincolari) •Forze elastiche •Forze chimiche (molecolari e biologiche) Ad oggi sappiamo che esistono 4 forze fondamentali della natura"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#30,30,"Forza di attrito statico
 31
P!VR!
03
F!Se il corpo NON si sposta nonostante la forza orizzontale introduciamo una nuova forza di attrito: l’attrito staticoASF!Caratteristiche: E’ una forza di contatto; di entità NON nota a priori.E’ una caratteristica delle superﬁci (secche, non lubriﬁcate) Ma non dipende all’area di contatto !Dipende da tutte le forze agenti sui corpi.Quando esiste in condizioni statiche, annulla sempre la risultante.Per ogni situazione esiste un valore massimo della forza. 
Vincolo ruvido!vincoli o superﬁciNON ideali"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#31,31,"Forza di attrito statico
 32
P!VR!
03
F!ASF!0ASFF+=!!!maxmax:ASASASFFF∃≤!maxASSFNµ=N: forza perpendicolare alle superfici      forza di carico µS: coefficiente di attrito staticoVNRP==!!Tipicamente:0.011Sµ<<"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#32,32,"Piano inclinato ruvidoProblema: sapendo che                , qual è il valore massimo di α per cui il corpo NON si muove?
 33
P!
VR!tP!nP!sintPPα=!
αcosnPPα=!hSe il corpo non si muove nonostante la presenzadi una forza non bilanciata                     allora esiste una forza di attrito staticosintPPα=!ASF!0tASPF+=!!!cosVnNRPPα===!!maxcosASSSFNPµµα==maxtASASPFF==!!maxsincosASASSPFFPαµα→===!sintancosSαµαα→==0,5Sµ=arctan0,463646...0,46Sradαµα→==→=26,565...27α→==°
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#33,33,"Importanza dell’attrito statico
 34
ASF!,av!!
PF!ASF!
ASF!VR!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#34,34,"Importanza dell’attrito statico
(/)(/)1SSrocciametallogommaasfaltoµµ≈≪Indipendente dall’area di contattoASF!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#35,35,"EsercizioUn mattone è appoggiato su una scanalatura rettilinea ruvida inclinata di un angolo α=35° rispetto ad un piano orizzontale e raccordato nel punto B con un pavimento orizzontale. Le due superfici hanno lo stesso coefficiente di attrito cinetico µc = 0,4. All’istante t = 0 il mattone viene lasciato in quiete da una altezza h = 3 m (punto A). Studiare il moto del mattone calcolando la velocità massima e la lunghezza totale del percorso.
 36
αhABC
max?vLABBC=+
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#36,36,"Esercizio – Passo 1
 37
αhAB
P!
VR!tP!nP!ADF!ˆιa!iADtFFPma=+=∑!!!!ˆsintPmgαι=!ˆˆcosADCCFNmgµιµαι=−=−!ˆaxι=!""""(sincos)ADtCFPmamxmgmgαµα+=→→=−!!!""""2(sincos)2,41 m/sCxgaαµα=−==!!()(0)(')'xtxxtdtat=+=∫!!!!2()(0)(')'2txtxxtdta=+=∫!x0,/sinABxxhα==
222:()2,08 s 2sinsinBBBBthxhtxtataaαα==→===max2:()25,02 m/sBBBBxxtataaxa====v!/sin5,23 mBxhα=="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#37,37,"Esercizio – Passo 2
Distanza percorsa:  38C
ˆιADF!
P!VR!v!BiADtFFPma=+=∑!!!!0tP=!!ˆˆADCCFNmgµιµι=−=−!ADtCFPmamxmgµ+=→→=−!!!""""23,92 m/sCxgaµ=−=−=−!!()(0)(')'Bxtxxtdtat=+=−∫v!!!!2()(0)(')'2Btxtxxtdtta=+=−∫v!()0Cxt=→!/1,28 sCBta==v8,45 mBCDxx=+=xxC=vBtC−atC22=vB22a=3,22 m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#38,38,"Esercizio•  Una pallina di massa M=0,2 kg è ferma tra una superficie verticale ed un piano inclinato di un angolo α=15°, come mostrato in figura. Determinare le reazioni vincolari della superficie verticale e del piano inclinato.
 39
α2VR!1VR!1tan0,52550,526VRmgNNα===…2/cos2,03..2,03VRmgNNα==="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#39,39,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
 40()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#4,4,"Galileo Galilei (1564-1642)Qual è il moto di un corpo non soggetto ad alcuna forza?
 5
!P!RV!v=costSe riusciamo ad eliminare tutti gli attriti PRINCIPIO DI INERZIA"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#40,40,"EsercizioUn proiettile di massa M viene sparato orizzontalmente da un cannone fermo posto su una altura che si eleva di h=50 m rispetto alla pianura circostante. Determinare: 1)il modulo v  della velocità con cui si deve sparare il proiettile affinché colpisca un bersaglio nella pianura e che dista orizzontalmente dal cannone di D=250 m; 2)l’angolo con cui il proiettile colpisce il bersaglio;  3)la velocità scalare del proiettile quando colpisce il bersaglio.
 41vf=D2g2h+2gh=84m/stanα=vyvx=2hD=0,4⇒α=21,8°v0=Dg2h=78,3m/s"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#41,41,"EsercizioUna molla ideale, di costante elastica k, è sospesa in verticale tramite un aggancio in alto. Ad un certo istante (t=0) si applica una massa m all’altro estremo della molla, che viene quindi lasciata libera. Trovare il moto del punto nella direzione verticale. In presenza di un piccolo attrito, dove si fermerà il punto?
 42
xzBOPbz
eF!
PF!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#42,42,"EsercizioIl sistema meccanico in ﬁgura è costituito da tre corpi uguali di massa m, un ﬁlo inestensibile ed una superﬁcie ruvida con coefﬁciente di attrito statico 0.6 e coefﬁciente di attrito cinetico 0.4. Determinare: 1) se il sistema è in condizioni di staticità; 2) la tensione nel ﬁlo; 3) cosa succede se il corpo 3 è eliminato dal sistema.
 43
3
2
1
ˆTmgι=!ˆPmgj=−!ASF!max2ASASSSFFNmgµµ<==!Statica ?0ASTF+=!!!maxASASTFF=<!!?21.2cmgmgmgµ→<=1. Si, il sistema è in equilibrio statico. max1.2ASASFmgFmg=<=!ˆTmgι=!3. maxASASTFF=<!!?0.6cmgmgmgµ→<=No: il sistema non è statico e si muove"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#5,5,"Primo Principio della Dinamica
➡criterio cinematico per stabilire quando su di un punto materiale non agiscono forze. 
 6
Se in un dato sistema di riferimento la risultante delle forze applicate ad un punto materiale è nulla allora il punto materiale o rimane in quiete o si muove di moto rettilineo uniforme.Il moto è relativo:Si muove rispetto a cosa? 
Sistema di riferimento inerziale 
Formulazione moderna Esiste almeno un sistema di riferimento, detto “inerziale” (SRI), rispetto al quale un qualunque punto materiale che sia sufficientemente lontano da tutti gli altri corpi, o rimane in quiete o si muove di moto rettilineo uniforme.“Principia”  di Newton:
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#6,6,"Classe di Sistemi di Riferimento Inerziali
 7Sia dato un punto su cui non agiscono forze in un SRI   S:  il punto si muove di moto rettilineo uniforme in S:      = costante
xyzx’y’z’
''aaSS=!!P(t)O’Ov!v!SdR S’ in moto rettilineo uniforme
S’ è un sistema di riferimento inerzialeTrasformazioni di Galileo!vO'=costante,!ω=!0!vO'x(t)=x'(t)+vO'xty(t)=y'(t)+vO'ytz(t)=z'(t)+vO'zt!v(t)=!v'(t)+!vO'vx(t)=vx'(t)+vO'xvy(t)=vy'(t)+vO'yvz(t)=vz'(t)+vO'z⎧⎨⎪⎩⎪!v'=!v−!vO'=costante"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#7,7,"Esiste un SRI privilegiato?S ed S’ sono due SRI: come posso distinguerli sperimentalmente operando solo all’interno di un SRI ?
 8
''aaSS=!!
R: No, non esiste un SRI privilegiato
Principio di relatività galileiano Tutte le leggi della fisica si scrivono nello stesso modo in ogni sistema di riferimento inerziale.
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#8,8,"Approssimazioni di SRI1.Sistema solidale alla terra (SR principale in statica) 2.Sistema con origine nel centro della terra e assi rivolti verso le “stelle fisse”  3.Sistema con origine nel centro del Sole e assi rivolti verso le stelle fisse 4.Sistema con origine nel centro della nostra galassia e assi rivolti verso le galassie più lontane  9()'2oCOTaarraaaaωωωωʹʹʹʹʹ=+×+×+××+=++v!!!!!!!!!!!!!""22221 d,6370 km,0,035 m/sTTRarRTπω⎛⎞=====⎜⎟⎝⎠622356 d1 y,15010 km,0,0059 m/sTTRarω=====i22200 Ma,26000 al,0,00000000025 m/sTTRarω====
29.8 m/sg="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#9,9,"Principi fondamentali
 10
2o Principio Un qualunque punto materiale che sia sottoposto ad una o più forze ha un’accelerazione vettorialmente proporzionale alla risultante di tali forze.
amF!!=CausaEffettoRisulta essere: -Positiva -Indipendente da posizione e velocità -Proprietà additiva dei corpi12Tmmm=+Massa inerziale "
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#0,0,"LAVORO ed ENERGIA CdS Ingegneria Informatica A.A. 2019/20
1"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#1,1,Lavoro ed Energia: definizioni intuitive•Lavoro: caratteristica di una forza di operare uno spostamento •L’energia è la capacità di produrre lavoro •Il lavoro è il processo attraverso il quale una certa quantità di energia si trasferisce da un corpo a un altro. •Ingredienti per una definizione più rigorosa di Lavoro: forza e movimento
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#10,10,"Lavoro di una forza elastica
11
Esempio: lavoro compiuto da una molla compressa da l1 fino all’ espansione l2δℒ=⃗F⋅d⃗l=(−kx̂ı)⋅(̂ıdx)=−kxdx(̂ı⋅̂ı)=−kxdxℒ1,2=∫x2x1⃗F⋅d⃗l=−k∫x2x1xdx−k[x22]x2x1=−k2x22+k2x21=−k2(l2−l0)2+k2(l1−l0)2ℒ1,2=−k2(x22−x21)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#11,11,"Lavoro della forza peso
12
SARA VALENTINETTI  -
Stessa conclusione se al posto del piano inclinato abbiamo un profilo curvo.Lavoro infinitesimoLavoro totale
𝑧1𝑧2 ℒ1,2=mghh = differenza di quota a cui si porta il punto
𝑑𝑙𝑧1𝑧2Esempio: punto materiale di massa m scivola su un piano liscio inclinato di un angolo  da un punto P1 a un punto P2 a differenza di quota hδℒ=⃗F⋅d⃗l=(−mĝk)⋅(̂ıdx+̂kdz)==−mg(̂k⋅̂ı)−mg(̂k⋅̂k)=−mgdzℒ1,2=∫P2P1⃗F⋅d⃗l=−mg∫z2z1dz=−mg(z2−z1)=mgh>0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#12,12,"Proprietà additiva dei lavori
13Punto materiale soggetto a N forze, equivale a un punto soggetto alla risultante delle forzeLavoro infinitesimo di ciascuna forza:Lavoro infinitesimo totale:Date n forze Fi , applicate allo stesso punto P, che si muove lungo una propria curva  dal punto A al punto B,  il lavoro complessivo è dato da….ℓLo spostamento è lo stesso per ogni forza perché agiscono tutte sulla stessa particella che compie un tratto di traiettoria.
Somma dei lavori delle singole forze.δℒ=⃗F⋅d⃗lδℒtot=δℒ1+δℒ2+...=⃗F1⋅d⃗l+⃗F2⋅d⃗l+...=(⃗F1+⃗F2+...)⋅d⃗l=(∑i⃗Fi)⋅d⃗l=⃗R⋅d⃗lℒℓtot=∫BAℓ⃗R⋅d⃗l=∫BAℓ(∑i⃗Fi)⋅d⃗l=∫BAℓ(∑i⃗Fi⋅d⃗l)=∑i∫BAℓ⃗Fi⋅d⃗l=∑iℒℓi"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#13,13,"Potenza di una forzaDef: capacità di produrre lavoro per unità di tempo
14•Per un punto materiale:Nuova definizione di lavoroLavoro compiuto da una forza per unità di tempo durante un intervallo di tempo infinitesimo P=δℒdtP=δℒdt=⃗F⋅d⃗ldt=⃗F⋅d⃗ldt=⃗F⋅⃗vP=⃗F⋅⃗vδℒ=Pdt⟹ℒ=∫Pdt"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#14,14,"Analisi dimensionale
15LavoroL⎡⎣⎤⎦=F⋅ds⎡⎣⎤⎦=N⋅m⎡⎣⎤⎦=kg⋅ms2⋅m⎡⎣⎢⎤⎦⎥=MLT−2L⎡⎣⎤⎦⇒L⎡⎣⎤⎦=ML2T−2⎡⎣⎤⎦Unitá di misura: SI-MKS  Joule(J)=N⋅mPotenzaP⎡⎣⎤⎦=LΔt⎡⎣⎢⎤⎦⎥=F⋅dsΔt⎡⎣⎢⎤⎦⎥=N⋅ms⎡⎣⎢⎤⎦⎥=kg⋅ms2⋅m⋅1s⎡⎣⎢⎤⎦⎥=MLT−2LT−1⎡⎣⎤⎦⇒P⎡⎣⎤⎦=ML2T−3⎡⎣⎤⎦Unitá di misura: SI-MKS  Watt(W)=Joule/s"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#15,15,"Esercizio
16Determinare la potenza istantanea sviluppata durante la caduta su un piano inclinato di un angolo  alto h da un punto A in cima al piano ad un punto B in fondo al piano da un punto materiale di massa m.α"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#16,16,"Teorema delle Forze Vive
17
Es: Corpo in moto con velocità  su piano orizzontale liscio contro molla. Corpo comprime molla perdendo velocità. Molla esercita forza tale che  e  opposti e       v⃗Fdxℒ<0•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro."
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#17,17,"Teorema delle Forze Vive
18•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.
Alla fine del moto il corpo è fermo e molla compressa esercita forza che tende a ridistenderla, in grado di rimettere in moto il corpo. In questo caso  e  hanno stesso verso e     ⃗Fdxℒ>0Relazione fra velocità e lavoroSperimentalmente  ⃗vfinale=−⃗viniziale"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#18,18,"Teorema delle Forze Vive
19Descrive il lavoro compiuto da un sistema di forze qualunque (attive, vincolari, interne, esterne, di interazione o apparenti), su un sistema meccanico qualunque (puntiforme, esteso, rigido, non rigido, vincolato, ecc.). Teorema delle forze vive per il punto materiale:Lavoro compiuto da tutte le forze per spostare corpo da A a B lungo un tratto di traiettoriaSostituisco la definizione di d⃗lProprietà delle derivate principio: risultante di tutte le forzeℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅d⃗ld⃗l=⃗vdt⟹ℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdtℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdt=∫BAm12dv2dtdt=12m∫BAdv2=12m[v2]BA=12mv2B−12mv2A"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#19,19,"Teorema delle Forze Vive
20Il lavoro compiuto dalla risultante delle forze che agiscono su un sistema meccanico qualunque, nel passaggio da una configurazione A ad un’altra B, è uguale alla corrispondente variazione dell’energia cinetica di tale sistema.Se  forza ha accelerato il corpo compiendo un lavoro positivoℒ>0⟹vB>vA→Se forza ha decelerato il corpo compiendo un lavoro negativoℒ<0⟹vB<vA→Energia Cinetica: 1. Ha le dimensioni del lavoro       2. Non è  mai negativa  (T>=0)[𝑇]=[12𝑚𝑣2]=[𝑀𝐿2𝑇−2]→JouleT=12mv2ℒA,B=12mv2B−12mv2A=TB−TA"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#2,2,"Lavoro ed Energia: MacchineUna macchina è un dispositivo vincolato capace di spostare il punto di applicazione di una forza, chiamata “resistente”, sfruttando un’altra forza chiamata “motrice”.
Una macchina “vantaggiosa” sposta il punto di applicazione di una forza resistente utilizzando una forza motrice di modulo più piccolo.carrucolapiano inclinatoleva"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#20,20,"Energia Potenziale
21
Lavoro sul corpo (teorema delle forze vive):Corpo in moto su un piano orizzontale liscio contro una molla ideale •velocità iniziale del carrello v0,  •velocità finale nulla poiché comprime una molla che esercita una forza opposta allo spostamento del corpo provocandone l’arresto.ℒcorpo=Tfin−Tin=12mv2fin−12mv2in=0−12mv20<0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#21,21,"Energia Potenziale
22•Molla inizialmente in quiete si comprime per effetto di una forza premente.  •Chi produce la forza compressiva è il carrello e l’entità della compressione è una misura della forza agente.  •Forza reagente della molla è uguale e opposta alla forza premente.Lavoro sulla molla (teorema delle forze vive):   
Dal punto di vista della molla…
ℒmolla=Tfin−Tin=12mv2fin−12mv2in=12mv20−0=−ℒcorpo>0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#22,22,"Energia Potenziale
23•Corpo in ragione della velocità compie un lavoro positivo sulla molla comprimendola; •Energia di un corpo: possibilità di un corpo di compiere un lavoro positivo; •Energia del carrello in moto si trasferisce gradualmente alla molla; •Quando il carrello si ferma, tutta la sua energia cinetica iniziale è trasferita alla molla compiendo un lavoro positivo su di essa; •Molla immagazzina l‘energia del corpo comprimendosi; •Molla poi rilascia gradualmente l’energia immagazzinata distendensosi e imprimendo al corpo una velocità uguale e contraria: restituisce energia cinetica al carrello; •energia totale immagazzinata dalla molla ridiventa interamente energia cinetica"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#23,23,"Energia Potenziale
24
0Lavoro forza elastica:Molla compressa di una certa quantità a ad un certo tempo t>0Teorema forze vive:Uguagliando:Energia iniziale: cineticaEnergia totale istantanea durante la compressioneLavoro che sarebbe in grado di fornire la molla ridistendendosi -> misura dell’energia propria immagazzinata dalla molla: Energia potenzialeLa somma dell’energia cinetica e di quella potenziale si conserva IN QUESTO moto.ℒel=Tfin−Tin=12mv2−12mv20ℒel=∫finin⃗Fel⋅d⃗l=∫finin(−kx̂ı)⋅(̂ıdx)=∫finin−kxdx=−k[x22]finin=−kx2212mv2−12mv20=−kx22⟹12mv2+kx22=12mv20kx22"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#24,24,"Esercizio
25Un blocco di ghiaccio è in moto su una salita inclinata di  Sapendo che all’inizio la sua velocità è pari a v = 9 m/s e che il coefficiente di attrito dinamico è pari a , di quanto si sposta lungo il piano inclinato il blocco di ghiaccio prima di fermarsi?α=6∘μc=0.07"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#25,25,"Esercizio
26Un blocco P di massa m = 3 kg si muove di moto rettilineo su un piano orizzontale scabro nella direzione dell’asse di una molla non deformata, di cui va a colpire uno degli estremi, mentre l’altro è bloccato a un supporto verticale fisso. La molla, di costante elastica k = 300 N/m, viene compressa di  Sapendo che il coefficiente di attrito dinamico fra P e il piano è , determinare: 1) I lavori compiuti durante tale compressione dalla forza elastica e dalla forza di attrito; 2) Il modulo della velocità di P nel momento in cui colpisce la molla. δ=8cmμc=0.25"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#26,26,"Esercizio
27Un cubetto P di massa m scivola lungo il segmento AB disposto lungo un piano inclinato di un angolo  rispetto alla direzione orizzontale. Il coefficiente di attrito dinamico passa dal valore massimo di ½ alla sommità A al valore 0 alla base B secondo una legge del tipo  dove e k sono costanti positive e s è la distanza da A di un generico punto di AB. Sapendo che  e che P è partito da fermo in A, calcolare il modulo v della sua velocità all’istante in cui arriva in B in termini di  e della variazione di quota h fra A e B.Ah𝛼B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#27,27,"Alcuni concetti matematici
28•Derivate parziali: primo e secondo ordine, miste… •Differenziali; •Campi: scalari, vettoriali…"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#28,28,"Derivate parziali
29Se una funzione esiste per ogni valore della variabile nel dominio, derivate parziali al primo ordine:Se le derivate parziale al primo ordine esistono per ogni valore della variabile nel dominio, derivate parziali al secondo ordine:
Derivate parziali miste (l’ordine non influenza)𝜕𝑧2Es: ∂f(x,y,z)∂xx0,y0,z0=limΔx→0f(x0+Δx,y0,z0)Δx∂f(x,y,z)∂yx0,y0,z0=limΔy→0f(x0,y0+Δy,z0)Δy∂f(x,y,z)∂zx0,y0,z0=limΔy→0f(x0,y0,z0+Δz)Δz∂2f(x,y,z)∂x∂y,∂2f(x,y,z)∂y∂z,∂2f(x,y,z)∂x∂zf(x,y,z)=x3−y2+3z"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#29,29,"DifferenzialiSia  una funzione a 3 variabili. Quanto varia il valore della funzione se ci spostiamo da un punto  a un punto infinitamente vicino  ?f(x0+dx,y0+dy,z0+dz)=f(x0,y0,z0)+∂f∂xP0dx+∂f∂yP0dy+∂f∂zP0dzDifferenzialedF=f(x0+dx,y0+dy,z0+dz)−f(x0,y0,z0)=∂f∂xdx+∂f∂ydy+∂f∂zdzPiù ordini successivi
30"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#3,3,"Definizione di lavoro infinitesimo
4
P1P2
xyzOLavoro infinitesimo compiuto da  durante uno spostamento infinitesimo   la quantità scalare:⃗Fd⃗lPer definire lavoro infinitesimo compiuto da una forza:In un intervallo di tempo   i, punto si sposta da P1 a P2 :    ΔtΔ⃗r=⃗r2−⃗r1-Regione di spazio in cui agisce  -Punto P si muove lungo linea curva   ⃗FℓSe  piccolo,             tangente ΔtΔ⃗r→d⃗l=̂utdlLavoro infinitesimo  perché non è un differenziale esatto (in generale non dipende solo dagli estremi in cui si integra).δLδℒ=⃗F⋅d⃗lΔ⃗rℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#30,30,"CampiCampo scalare: una grandezza scalare funzione delle coordinate spaziali U(x,y,z) definita ovunque dentro una certa regione di spazio. Superficie di livello: luogo geometrico dei punti dove la funzione scalare assume un valore costante prefissato  U(x,y,z) = costante -> infinite superficiCampo vettoriale: un vettore applicato funzione delle coordinate spaziali               definito ovunque dentro una certa regione di spazioLinee di forza: una o più linee sempre tangenti al vettore del campo. Le linee di forza sono più fitte dove il modulo del vettore è maggiore.31"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#31,31,"Campi di forze conservativi
32In generale il lavoro di una forza per spostare un punto materiale su un tratto AB di traiettoria dipende dalla traiettoriayzx0AB..12Per il teorema delle forze vive:Le velocità agli estremi sono diverse a seconda che si percorra la curva 1 o la 2.ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗l⟹ℒ1(A,B)≠ℒ2(A,B)ℒ1(A,B)=12m(vB)2−12m(vA)2ℒ2(A,B)=12m(v′ B)2−12m(v′ A)2⟹vB≠v′ B⟹vA≠v′ A"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#32,32,"Campi di forze conservativi
33Campo di forza conservativo: forza posizionale che, spostando il suo punto di applicazione da A a B, punti qualunque del dominio di esistenza, compie un lavoro che è indipendente dalla particolare traiettoria seguita, ma dipendente soltanto dagli estremi A e B. 
ℒA,B=∫BA⃗F⋅d⃗lℒ1(A,B)=ℒ2(A,B)=ℒ3(A,B)=...=ℒA,B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#33,33,"Campi di forze conservativi: 1a proprietà
34
AB12Campo conservativo:
1a Proprietà
Lavoro su una curva chiusa di una forza conservativa (circuitazione) è nulloCondizione necessaria (se il campo è conservative allora la circuitazione è nulla) e sufficiente (se la circuitazione è nulla allora il campo è conservativo)ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗lℒA,B=∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹∫BA1⃗F⋅d⃗l−∫BA2⃗F⋅d⃗l=0∫BA1⃗F⋅d⃗l+∫AB2⃗F⋅d⃗l=0⟹ℒ=∮⃗F⋅d⃗l
ℒ=∮⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#34,34,"Campi di forze conservativi: 2a proprietà 
35 funzione scalare definita in ogni punto dello spazio legata al valore della forza in quell punto. Fissata a meno di una costante additiva arbitraria: se  soddisfa la relazione anche  lo faU=U(x,y,z)U(x,y,z)U′ =U(x,y,z)+kDifferenziale esatto di una funzione scalare  è un campo scalare Analisi: integrale fra A e B di un differenziale esatto è la differenza della primitiva fra B e A.Scelgo arbitrariamente un punto in cui   (origine)U=0yzx0PU funzione solo del punto non della traiettoria∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹ℒA,B=∫BA⃗F⋅d⃗lℒA,B=∫BA⃗F⋅d⃗l=∫BAdU=U(B)−U(A)ℒA,B=U(B)−U(A)=[U′ (B)−k]−[U′ (A)−k]=U′ (B)−U′ (A)U(x,y,z)=∫P(x,y,z)0⃗F⋅d⃗l=U(P)−U(0)=U(P)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#35,35,"Campi di forze conservativi: 2a proprietà 
Esiste una  funzione scalare U(P), dipendente solo dalla posizione e dalla forza, detta potenziale tale che2a Proprietàyzx0BA..123Percorso AB: A->O->B
ℒA,B=∫BA1⃗F⋅d⃗l=∫0A2⃗F⋅d⃗l+∫03B⃗F⋅d⃗l=−∫A02⃗F⋅d⃗l+∫03B⃗F⋅d⃗l==−[U(A)−U(0)]+[U(B)−U(0)]=U(B)−U(A)ℒA,B=U(B)−U(A)36"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#36,36,"Energia potenzialeAl posto di U(P) si preferisce introdurre V(P)=−U(P)
37•V(P) misura la capacità che ha il punto P di produrre lavoro quando il punto materiale ritorna all’origine.2a ProprietàEsiste una funzione scalare V(P), dipendente solo dalla posizione e dalla forza, detta energia potenziale tale cheLe prime due proprietà devono essere mutualmente dimostrabili.ℒA,B=U(B)−U(A)=V(A)−V(B)V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#37,37,"Forze conservative 3a proprietà
38Campo conservativo è un differenziale esattoPer definizioneFxdx+Fydy+Fzdz=−∂V∂xdx−∂V∂ydy−∂V∂zdzdV=∂V∂xdx+∂V∂ydy+∂V∂zdzUguagliandoδℒ=⃗F⋅d⃗l=Fxdx+Fydy+Fzdz=dU=−dV"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#38,38,"Forze conservative 3a proprietà
39Operatore vettoriale (operatore simbolico)  nabla
3a ProprietàLa forza è col segno meno il gradiente dell’energia potenziale NB: l’operatore nabla non è un vettore, è un operatore che agisce sulle funzioni, come la derivata o l’integrale. Il risultato dell’operazione dipende al tipo di funzione a cui è applicato. "
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#39,39,"Operatore Nabla
40
Nabla:Gradiente di una funzione scalare
Divergenza di un campo vettoriale
Rotore di un campo vettoriale
È un vettoreÈ uno scalareÈ un vettoreÈ un operatore"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#4,4,"Se chiamo   la componente della forza lungo la tangente allo spostamento allora  Ft=Fcosθ
Definizione di lavoro infinitesimo
5Lavoro infinitesimo compiuto da una forza:Il lavoro infinitesimo è il prodotto dello spostamento per la componente della forza lungo lo spostamentoSe la forza è  allo spostamento:        ⊥δℒ=0Es:
NB:definizioni valgono per qualsiasi forza, non è detto sia quella che causa il moto!δℒ=⃗F⋅d⃗l=|⃗F||d⃗l|cosθ=Fdlcosθδℒ=Ftdlδℒpeso=0δℒforza⃗F≠0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#40,40,"Significato dell’operatore gradienteL’operatore gradiente restituisce un vettore diretto lungo la direzione in cui aumenta più velocemente la funzione scalare.
41Campo scalare
xy
Superfici (linee) di livello
Vettore applicato!
Diretto dove f(x,y) aumenta e       alle superfici di livello⊥"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#41,41,"Forze conservative 4a proprietà
423a proprietàRotoreSostituisco la prima nella seconda:Proprietà delle derivate parziali seconde per funzioni continue e derivabili:∂2V∂x∂y=∂2V∂y∂x∂2V∂x∂z=∂2V∂z∂x∂2V∂y∂z=∂2V∂z∂y𝜕𝑧"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#42,42,"Forze conservative 4a proprietà
4a pr oprietà:  se il campo è conservativo il suo rotore é nulloCondizione necessaria e sufficiente affinché un campo di forze sia conservativo è che il rotore si annulli in tutti i punti del campo.Modo facile e pratico per verificare se un campo è conservativo:𝜕𝑧
43"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#43,43,"ℒ=∮⃗F⋅d⃗lRiepilogo: Forze conservative
44
1a Proprietà
2a ProprietàEsiste una funzione scalare V(P) (=-U(P)), detta energia potenziale, tale che
ℒA,B=V(A)−V(B)
3a Proprietà
4a Proprietà
Tutte le proprietà sono simultaneamente necessarie e sufficienti (la verifica di una implica tutte le altre)Forze posizionali il cui lavoro non dipende mai dal percorso ma solo dal punto di partenza e dal punto di arrivo."
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#44,44,"Calcoli di energia potenziale
45yz
xP(t)O1Data una forza conservativa, trovare l’energia potenziale
2AB
V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗lℒ0,P=ℒ1(0,P)=ℒ2(0,P)=ℒ(0,A,B,P)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#45,45,"Calcoli di energia potenziale
46
1. Scelgo un percorso arbitrario su una spezzata2. Applico la definizione di energia potenziale sul percorso sceltoIn coordinate cartesiane:V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#46,46,"47Esercizio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)= 2xˆı z2ˆ| ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı zˆ| ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R: =4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵""0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10 6C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale 2sulla superﬁcie interna del guscio sferico (R: 2 Q14⇡r22= 8·10 6C/m);b) la di↵erenza di potenziale tra i due conduttori. (R: V=Q4⇡""0r2 r1r1r2= 15kV)V"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#47,47,"Esercizio   Sia dato un punto materiale di massa M su cui agisce una forza conservativa di energia potenziale:                                Sapendo che le costanti α e β sono positive, determinare:   1) l’espressione della forza;   2) le dimensioni e le unità di misura delle costanti α e β;    3) l’accelerazione del corpo quando passa per il punto P(0,L,L).
48
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#48,48,"Conservazione dell’energia meccanica
49Sistema meccanico con: -Vincoli ideali -Forze attive conservativeTeo. forze viveCampi conservativiUguagliando:Energia meccanica:E=T+VTeorema della conservazione dell’energia meccanica: Per un sistema meccanico sottoposto a vincoli tutti ideali ed a forze non vincolari tutte conservative, l’energia meccanica E si conserva, ossia la somma fra l’energia cinetica T e  l’energia potenziale totale V, rimane costante durante il moto. 
Dimensionalmente:                    JouleE⎡⎣⎤⎦=T⎡⎣⎤⎦=V⎡⎣⎤⎦NB: A e B sono punti sulla traiettoria, l’energia si conserva lungo la traiettoria
ℒA,B=V(A)−V(B)
ℒA,B=T(B)−T(A)ℒA,B=T(B)−T(A)=V(A)−V(B)⟹T(A)+V(A)=T(B)+V(B)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#49,49,"Conservazione dell’energia meccanica
50
x
x
E1E2Corpo 1: Stato liberox1x≥x1x2x3Corpo 2: Stato legatox2≤x≤x3Curva nera:  V(x) energia potenzialeIn una certa regione di spazio E è costante Se V aumenta  T diminuisce  e viceversaMoto possibile solo nelle regioni di spazio in cui                        per def di TE≥V"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#5,5,"Definizione di lavoro
6
AB
xyzOIl lavoro totale compiuto dalla forza su un punto materiale in un intervallo di tempo in cui il punto si sposta da A a B è la somma di tutti i lavori infinitesimi:d⃗l1d⃗l2d⃗l3
Il lavoro compiuto da una generica forza, il cui punto di applicazione P si sposta da A a B lungo una linea , è l’integrale esteso a tale linea del prodotto scalare fra la forza  e lo spostamento infinitesimo :⃗Fℓ⃗Fd⃗lℓℒ=∑iδℒ=∑i⃗Fi⋅d⃗liℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#50,50,"Esempi: forza elastica
51Verifichiamo se è conservativa:  ?⃗∇∧⃗F=0
Forza elastica:
La forza elastica è conservativa⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(∂(ky)∂z−∂(kz)∂y)+̂𝚥(∂(kz)∂x−∂(kx)∂z)+̂k(∂(kx)∂y−∂(ky)∂x)=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#51,51,"Potenziale elastico
52yzxP(t)OABV(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,0,0)0kxdx+∫(x,y,0)(x,0,0)kydy+∫(x,y,z)(x,y,0)kzdz==kx22+ky22+kz22=k2(x2+y2+z2)=k|⃗r2|2V(P)=k2(x2+y2+z2)=k|⃗r2|2"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#52,52,"Esempi: forza pesoForza peso:
53
La forza peso è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(−∂(−mg)∂y)+̂𝚥(∂(−mg)∂x)+0̂k=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#53,53,"Potenziale gravitazionale
54yzxP(t)OAB𝑉(𝑃)=𝑚𝑔𝑧
V(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,y,z)(x,y,0)mgdz=mgz"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#54,54,"Esempi: forza costanteForza costante:
55
Una forza costante è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂fy∂z−∂fz∂y)+̂𝚥(∂fz∂x−∂fx∂z)+̂k(∂fx∂y−∂fy∂x)=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#55,55,"Potenziale di una forza costante
56yzxP(t)OAB𝑉(𝑃)=−𝑓𝑥𝑥−𝑓𝑦𝑦−𝑓𝑧𝑧
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0fxdx−∫(x,y,0)(x,0,0)fydy−∫(x,y,z)(x,y,0)fzdz==−fx∫(x,0,0)0dx−fy∫(x,y,0)(x,0,0)dy−fz∫(x,y,z)(x,y,0)dz=−fxx−fyy−fzz"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#56,56,"Esempi: campo centrale  a simmetria sfericaForza centrale a simmetria sferica:
57Verifichiamo se è conservativa:
Tutti i campi centrali a simmetria sferica sono conservativixyz
O funzione scalare della sola posizione   è un’energia potenziale se è possibile trovare una funzione scalare t.c  (forza è conservativa).F(r)drF(r)dr=−dVF(r)dr=−dV⟹F(r)=−dV/drd⃗l=̂u⊥(dl⊥)+̂ur(dr)δℒ=⃗F⋅d⃗l=F̂ur⋅(̂u⊥dl⊥+̂urdr)=F(ur⋅̂u⊥dl⊥+ur⋅̂urdr)=Fdrd⃗l=(dl⊥)̂u⊥+(dlr)̂ur=0=1⃗F(⃗r)=F(r)̂ur
ℒA,B=∫BAF(r)dr=−∫BAdV=V(rB)−V(rA)AB"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#57,57,"•sono arrivato qua •(mancano le animazioni)
58"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#58,58,"Lavoro di una forza di attrito dinamico
59Lavoro lungo la traiettoria 2:
BLavoro lungo la traiettoria 1:Lavoro da A a B della forza di attrito dinamico:1
ATutte le forze di attrito (dinamico, viscoso) NON sono mai conservative⃗F=−μcN̂ut=−μcN⃗vvℒ1(A,B)=∫BA1⃗F⋅d⃗l=∫BA1(−μcN̂ut)⋅(̂utdl)2=−μcN∫BA1dl=−μcNLA1B<0ℒ2(A,B)=∫BA2⃗F⋅d⃗l=∫BA2(−μcN̂ut)⋅(̂utdl)=−μcN∫BA2dl=−μcNLA2B<0LA1B≠LA2B⟹ℒ1(A,B)≠ℒ2(A,B)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#59,59,"Lavoro di forze conservative e non
60
Teo. Forze vive ℒtot=T(B)−T(A)Lavoro totale ℒtot=ℒcons+ℒncCampi conservativi ℒcons=V(A)−V(B)Il lavoro delle forze non conservative è dato dalla variazione dell’energia meccanica totaleIn presenza di forze d’attrito, generalmente, si ha ℒnc<0⟹E(B)<E(A)Forze dissipativePunto materiale soggetto ad una forza totale: somma di 2 contributi ℒA,B=∫BA⃗F⋅d⃗l=∫BA(⃗Fcons+⃗Fnc)⋅d⃗l=∫BA⃗Fcons⋅d⃗l+∫BA⃗Fnc⋅d⃗lT(B)−T(A)=V(A)−V(B)+ℒncℒnc=[T(B)+V(B)]−[T(A)+V(A)]=E(B)−E(A)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#6,6,"Graficamente
7
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsBIl lavoro infinitesimo in un tratto di s è pari all’area tratteggiatadlδℒ=Ftdlℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#60,60,"Esercizio•Un carrello viene lanciato con una velocità iniziale v lungo un binario orizzontale che poi presenta un avvolgimento circolare verticale di raggio R = 4 m. Calcolare, nell’ipotesi di assenza di attriti,  il minimo valore vmin che deve essere dato alla velocità v affinché il carrello compia il “giro della morte” senza staccarsi dai binari.
61
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#61,61,"EsercizioUn punto materiale di massa m=30 g è inizialmente fermo su di un profilo circolare liscio di raggio R=20 cm ad una altezza H=R/2 rispetto al piano orizzontale. Scendendo lungo il profilo il punto incontra in A un piano orizzontale liscio su cui è vincolata in B una molla di costante elastica  k =0,1 kg/s2, inizialmente a riposo. Determinare: a)le componenti tangenziale (aT) e centripeta (aN)  dell’accelerazione del punto nel punto iniziale; b)la reazione vincolare nel punto A; c)la compressione massima della molla. 
62
mRKA
R
B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#62,62,"EsercizioUna cassa, di massa M=7 kg è  inizialmente in moto su un piano orizzontale liscio con una velocità di v =8 m/s ad una distanza D =6 m da un piano ruvido inclinato di  α=15° rispetto alla direzione orizzontale. Sapendo che la cassa si ferma dopo aver percorso L = 8 m sul piano inclinato, determinare  a)il coefficiente di attrito dinamico del piano inclinato,  b)il lavoro fatto dalla forza di attrito sul piano inclinato,  c)indicare (motivando la risposta) se, raggiunta la quota massima la cassa ridiscende il piano o si ferma.
63
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#63,63,"EsercizioUn corpo di massa M = 12 kg scende da un piano inclinato di α=30° rispetto ad una direzione orizzontale. Sapendo che il corpo parte da fermo, che si abbassa di una quota h = 2 m, che il piano è ruvido e con un coefficiente di attrito dinamico µd=0,2, determinare la sua velocità finale.
64"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#7,7,"Graficamente
8
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsB
Il lavoro totale è pari all’area sotto la curva compresa fra i due estremi fra cui si sposta il punto materialeℒ=∫BAFtdlℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#8,8,"Esempi
91.
AB
costante in modulo, direzione e verso ℓℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFtdl=Ft∫BAℓdl=Ftℓ2. costante in moduloFt=|⃗F|cosθ=Fcosθℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFcosθdl=Fcosθ∫BAℓdl=FℓcosθIn generale in coordinate cartesiane: forza posizionale⃗F(x,y,z)=Fx(x,y,z)̂ı+Fy(x,y,z)̂𝚥+Fz(x,y,z)̂kd⃗l=dx̂ı+dŷ𝚥+dẑkIntegrale generalmente non scomponibile!
AB
𝜗𝜗𝜗𝜗ℓℒ=∫BAℓ⃗F(x,y,z)⋅d⃗l=∫BAℓ[Fx(x,y,z)dx+Fy(x,y,z)dy+Fz(x,y,z)dz]"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#9,9,"Esercizio
10Calcolare il lavoro della forzacon k e h costanti che agisce sul piano (x,y) sulle traiettorie: 1)Lungo un segmento rettilineo che congiunge l’origine con un punto A=(a,b); 2)Lungo l’arco di parabola OA avente vertice nell’origine e per asse l’asse x.xyOA"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#0,0,Terzo Principio della Dinamica CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#1,1,"Sviluppo1)Modello del punto materiale troppo povero per descrivere tutta la realtà; 2)Dinamica dei sistemi di punti materiali; 3)Riscrittura  della  in modo opportuno; 4)Terzo principio della dinamica⃗F=m⃗a
2"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#10,10,"Derivate rispetto al tempo
Rappresenta TUTTE le forze REALI che agiscono sul punto i-esimoPossiamo distinguere tra le forze dovute agli altri punti del sistema  (forze INTERNE al sistema) e forze dovute a tutto ciò che non è il sistema (forze ESTERNE al sistema, dovute all’ambiente). Analogamente per i momenti→𝑄=𝑁∑𝑖=1→𝑞𝑖=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1𝑑→𝑞𝑖𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖→𝑃𝑜=𝑁∑𝑖=1→𝑝𝑖=𝑁∑𝑖=1𝑚𝑖→𝑟𝑖∧→𝑣𝑖𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1𝑑→𝑝𝑖𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑟𝑖∧→𝐹𝑖
11"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#11,11,"Forze interne ed esterneTipiche forze interne: vincoli tra punti materiali, fili, sbarre interne al sistema, molle o sistemi di attrazione/repulsione tra punti del sistema Tipiche forze esterne: forze peso, vincoli tra il sistema e l’esterno, tensioni tra il sistema e l’esterno
Piano verticaleInterneEsterne
Piano orizzontale
Piano verticale
12"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#12,12,"Separazione tra forze interne ed esterne
Per un sistema isolato si ha:Attenzione:  risultato parziale→𝐹𝐸𝑆𝑇=0, →𝑀𝐸𝑆𝑇=0𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1(→𝐹𝐼𝑁𝑇𝑖+→𝐹𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1(→𝑀𝐼𝑁𝑇𝑖+→𝑀𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇
13"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#13,13,"Verifiche sperimentaliQuanto valgono nei sistemi isolati?Studio il sistema Terra-Luna o Giove-suoi satelliti o altri sistemi:
Risultato sperimentale nuovo: nei sistemi isolati si osserva sempre: Nei sistemi isolati la quantità di moto e il momento angolare del sistema sono costanti nel tempo.𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇
𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=014"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#14,14,"Sistema isolato semplice
Le due forze interne agiscono su una retta d’azione che passa per i due punti materiali
 e : forze interne al sistema di due punti⃗F1⃗F2
O
→𝐹𝐼𝑁𝑇=→0→→𝐹1+→𝐹2=→0⟹→𝑀𝐼𝑁𝑇=→𝑟1∧→𝐹1+→𝑟2∧→𝐹2=→0→→𝑟1∧→𝐹1+→𝑟2∧(−→𝐹1)=→0→→𝑟1∧→𝐹1−→𝑟2∧→𝐹1=(→𝑟1−→𝑟2)∧→𝐹1=→0(→𝑟1−→𝑟2)∥→𝐹115→𝐹2=−→𝐹1⃗F1⃗F2"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#15,15,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storica
16"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#16,16,Terzo principio della dinamica•Col secondo principio prevediamo il moto di un punto materiale sulla base della forza agente su di esso:  •Per avere una forza  occorre almeno un altro corpo che agisca sul punto materiale •Il secondo principio dice come si muove il punto materiale soggetto ad una forza ma non cosa succede al corpo che tale forza la provoca  serve il terzo principio→𝐹=𝑚→𝑎⃗F→17
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#17,17,"Terzo principio della dinamica  per sistemi di punti materiali•Per ogni punto si suppone di poter distinguere fra le forze agenti sul punto i-esimo quella dovuta al punto j-esimo •Si soppone valere sempre la sovrapposizione degli effetti cioè se  è la forza che 2 esercita su 1 e  è la forza che 3 esercita su 1 allora  •Se valgono queste condizioni allora il terzo principio è estendibile a N corpi applicandolo ad ogni possibile coppia di punti→𝐹1,2→𝐹1,3→𝐹1=→𝐹1,2+→𝐹1,3→𝐹𝑖=𝑁−1∑𝑗=1→𝐹𝐼𝑁𝑇𝑖,𝑗+→𝐹𝐸𝑆𝑇𝑖Sul punto i-esimo agiscono tutte le forze interne dovute agli altri N-1 punti e le forze esterneSe agiscono solo forze interne: il sistema è isolato  →𝐹𝐸𝑆𝑇𝑖=→0⟹𝑑→𝑄𝑑𝑡=018"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#18,18,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storicaFormulazione alternativaSe in un SRI, osserviamo che su un corpo (A) si esercita una forza allora esisterà almeno un altro corpo (B) responsabile di tale forza. Su questo corpo B agirà una forza vettorialmente opposta a quella su A e con la stessa retta d’azione.NB: le due forze sono applicate in due punti di applicazione diversi ovvero I due corpi!19"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#19,19,"Terzo principio, formulazione modernaSemplice, diretto, modernoSu sistemi isolati
Nulli per il terzo principio (sperimentale)Nulli in un sistema isolatoQuantità di moto e momento angolare si conservano per sistemi isolati.In un Sistema di Riferimento Inerziale,  e calcolato rispetto ad un polo O qualunque si conservano per sistemi isolati.→𝑄→𝑃0 𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=0
20"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#2,2,"Quantità di moto di un punto materialeSi definisce la quantità di moto di un punto come:Se la massa è costante:Secondo principio:Se la massa è variabile: quale delle due è corretta?oppure[→𝑞]=[𝑚→𝑣]=[𝑀𝐿𝑇−1]→𝑘𝑔∙𝑚𝑠→𝐹=𝑚→𝑎=𝑚𝑑→𝑣𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡
→𝐹=𝑑→𝑞𝑑𝑡→𝐹=𝑑→𝑞𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡=𝑑𝑚𝑑𝑡→𝑣+𝑚𝑑→𝑣𝑑𝑡3"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#20,20,"Conseguenze del terzo principio2 corpi su un piano orizzontale tenuti insieme da una molla compressa tramite un filo ideale
21
Terzo principio: poiché il sistema è isolatoIn diverse circostanze è possibile ottenere dei risultati di dinamica SENZA conoscere le forze in gioco
→𝑄𝑖𝑛𝑖𝑧=→0Tagliando il filo i corpi si muovono per effetto della di moto rettilineo uniforme in direzione opposta→𝐹=𝑚→𝑎 →𝑄𝑓𝑖𝑛=𝑚1→𝑣1+𝑚2→𝑣2→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛→→0=𝑚1→𝑣1+𝑚2→𝑣2→→𝑣2=−𝑚1𝑚2→𝑣1"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#21,21,Urti CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#22,22,"UrtiSi ha un urto quando due corpi, che si muovono a velocità diverse, interagiscono (p.es. vengono a contatto) e, in un intervallo di tempo molto breve (rispetto al contesto), modificano sostanzialmente le proprie velocità.
23
"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#23,23,"Forze d’urto – forze impulsive
24
Forze impulsive"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#24,24,"Urti collineari di punti materiali
25
e = 0 : urto perfettamente anelastico e = 1 : urto perfettamente elasticoEmpiricamente Prima dell’urtoDopo l’urto
NB.: Trattasi di relazioni tra le componenti dei vettori lungo l’asse x, le quali includono il segno.v0,1x−v0,2x>0→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛𝑣1,𝑥−𝑣2,𝑥=−𝑒(𝑣01,𝑥−𝑣02,𝑥)0≤𝑒≤1"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#25,25,"Urti collineari di punti materiali
26
Conservazione della quantità di moto (e del momento angolare).
Relazione fra le velocità
m1 = m2
e = 0
Urto anelastico
m1 = m2
e = 1
Urto elastico"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#26,26,"Energia cineticaFacendo un po’ di conti … :
e = 1
E = costante T=12m1v1x2+12m2v2x2T0=12m1v01x2+12m2v02x2
In un urto perfettamente elastico l’energia cinetica si conserva
e = 0
ΔE ≤  0 In un urto perfettamente anelastico l’energia cinetica diminuisce27"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#27,27,"Urti in sistemi non isolatiSe gli urti avvengono in sistemi non isolati a causa della presenza di forze esterne o vincoli esterni, il terzo principio (formulazione conservativa) non è sempre applicabileSe l’urto è quasi istantaneo, sono molto più importanti le forze impulsive e si può trascurare l’effetto della forza peso. Si ha una quasi conservazione di quantità di moto e momento angolare tra prima e dopo l’urto. Vale in generale per forze esterne LIMITATE.Se le forze esterne hanno una direzione definita, si ha la conservazione della quantità di moto nelle direzioni perpendicolari.
Esempio: urto di due palloni che si scontrano in aria. E’ presente una forza esterna: quella peso.
28"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#28,28,"Urti: riassunto
29"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#29,29,"EsercizioUn corpo di massa m=1 kg è in moto rettilineo uniforme ad una velocità v=10 m/s, su un piano liscio, quando entra in una regione permanendovi per t=0.1 s in cui perde velocità scalare. All’uscita della regione il corpo ha una velocità di v=9 m/s. Determinare:  1)la forza media che ha frenato il corpo,  2)il lavoro della forza frenante e  3)il coefficiente di attrito se si tratta di una forza di attrito cinetico. 
30"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#3,3,"Situazioni di massa variabile•Moto di una goccia d’acqua che cade in presenza di vapor d’acqua saturo  à la massa aumenta •Moto di un aereo in condizioni di tempo brutto con formazione di ghiaccio sulle ali à la massa aumenta •Moto di un razzo che si muove bruciando carburante à la massa diminuisce •Relatività: la massa dipende dalla velocità: •Dato sperimentale: la forza varia con la massa!È più generale della 
m(v)=m01−vc()2→𝐹=𝑑→𝑞𝑑𝑡4"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#30,30,"EsercizioDue punti materiali di massa m1=1 kg e m2=3 kg sono uniti da un filo inestensibile che risulta sempre in tensione. Sapendo che i due punti si muovono su un piano ideale senza attrito, che costituiscono un sistema isolato e che il punto 1 ha equazioni del moto date da :    (nelle unità del SI) trovare la tensione del filo e l’accelerazione del punto 2. 
31"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#31,31,"EsercizioDa una pistola con canna lunga L=15 cm esce un proiettile di massa m=5 g con velocità v=180 m/s. Trovare la forza media che ha spinto il proiettile dentro la canna e il tempo che impiega il proiettile a percorrere la canna della pistola dal momento dello sparo.
32"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#32,32,"EsercizioDue corpi A e B di massa 2 kg si scontrano fra loro. Le velocità prima dell’urto sono   Dopo l’urto Tutte le velocità sono date in metri al secondo. Qual è la velocità finale di B? Quanta energia cinetica guadagna o perde nell’urto il corpo B? L’urto è elastico? →𝑣𝐴,𝑖=15^𝑖+30^𝑗→𝑣𝐵,𝑖=−10^𝑖+5^𝑗→𝑣𝐴,𝑓=−5^𝑖+20^𝑗
33"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#33,33,"EsercizioUna palla di stucco con una massa di 5 g ed una velocità v1 = 4 m/s compie una collisione diretta e perfettamente anelastica con una palla da biliardo inizialmente ferma e che ha una massa di 500 g. Determinare la velocità comune delle due palle dopo l’urto e le energie cinetiche prima e dopo l’urto dei diversi corpi.  - trascurare gli effetti di rotolamento -
34"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#34,34,"EsercizioUna pallina di gomma, di massa m=20 g, viene lasciata cadere in verticale da una altezza h=100 cm misurata rispetto ad un pavimento orizzontale. La pallina rimbalza esattamente in verticale e raggiunge una altezza di h' = 90 cm.  Qual è il coefficiente di restituzione del pavimento? A che altezza arriverà il successivo rimbalzo?
35"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#35,35,"EsercizioDue carrelli, di massa rispettivamente M=50 kg e 2M si muovono uniti su un binario orizzontale rettilineo ad una velocità costante v=10 m/s. Tra i due carrelli, tenuti uniti da un gancio, vi è un respingente (molla) compresso di 25 cm e di costante elastica k=80000 N/m. Se ad un certo punto il gancio si rompe, trovare le velocità finali dei due carrelli.
36"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#36,36,"EsercizioUn proiettile di massa mP = 4 kg viene sparato in orizzontale da un cannone posto su un carrello e avente una massa complessiva di MC = 3 000 kg. Sapendo che la velocità di uscita del proiettile è di vP = 350 m/s, determinare la velocità iniziale di rinculo del cannone.
37"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#37,37,"Esercizio (pendolo balistico)Un proiettile, di massa m e velocità v diretta in orizzontale, colpisce in modo totalmente anelastico un peso di massa M appeso al soffitto tramite un filo inestensibile. A seguito dell’urto il peso inizia una oscillazione. Trovare la relazione tra la velocità del proiettile e la massima altezza del peso rispetto alla sua posizione di riposo.
38"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#38,38,"Esercizio Un corpo di 2 kg viene spinto contro una molla di costante elastica pari a 200 N/m fino a comprimerla di 15 cm. Lasciato andare, la molla lo spinge su una superficie orizzontale fino a che non si arresta dopo un percorso di 75 cm. Qual e’ il coefficiente di attrito dinamico tra blocco e superficie?
3939"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#39,39,"EsercizioDue sferette di masse m1 e m2, vincolate a muoversi su un piano verticale, sono collegate ad uno stesso punto fisso O attraverso due fili flessibili inestensibili, entrambi di lunghezza l e massa trascurabile (vincoli ideali). Inizialmente la sferetta m2 è in posizione di equilibrio stabile, mentre la sferetta m1 con il filo teso è trattenuta ad una quota h rispetto alla posizione di m2. In seguito, m1 viene lasciata libera di muoversi e va a urtare m2. Nell’ipotesi che l’urto sia istantaneo e completamente anelastico, calcolare:   1) il modulo v1 della velocità con cui m1 urta m2;   2) la quota massima h’ raggiunta dal sistema    dopo l’urto e   3) la perdita di energia cinetica.
40
"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#4,4,"ImpulsoL’azione di una forza in un intervallo di tempo dt provoca una variazione infinitesima della quantità di moto
Impulso:Viceversa: da una variazione infinitesima della quantità di moto si può risalire alla forza agente.⃗ℐ=∫t2t1⃗Fdt=∫t2t1d⃗q=⃗q(t2)−⃗q(t2)=Δ⃗q[⃗ℐ]=[Δ⃗q]=[MLT−1]5"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#40,40,"EsercizioUn sistema meccanico, che si trova inizialmente fermo ad una altezza h = 1,2 m dal pavimento, è costituito da una pallina di massa m1 = 10 g collocata in equilibrio (instabile) sopra una pallina di massa m2 = 5m1. A un certo istante, il sistema viene lasciato libero di cadere. Assumendo che ogni urto sia perfettamente elastico e trascurando le dimensioni delle palline, determinare:  1)l’altezza a cui rimbalza la pallina più leggera;  2)la velocità con cui arriva a terra la seconda pallina dopo l’urto.
41"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#41,41,"EsercizioUna pallina di massa 2m viene lanciata verso l’alto da una quota z=0 ad una velocità v=10 m/s esattamente nello stesso istante in cui un’altra pallina di massa m, posta ad una quota h=5 m viene lasciata cadere sulla verticale della prima pallina.  1) Se l’urto tra le palline e’ elastico, quanto tempo impiega la prima pallina ad arrivare a terra? 2) Se l’urto e’ completamente anelastico, quanto tempo ci mettono le palline ad arrivare a terra?    (considerare g=10 m/s2)
42"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#5,5,"Teorema dell’impulsoForze impulsive: forze che agiscono per un periodo di tempo limitato
Primo principio  con la quantità di motoSe m è costante    costante    Se m costante e     costante    Teorema dell’impulso: l’impulso di una forza applicata ad un punto materiale provoca la variazione della sua quantità di moto.Forma integrale del secondo principio della dinamica:  nota la forza anche la variazione della quantità di moto è nota; nota la variazione della quantità di moto è nota la forza media che ha agito nell’intervallo di tempo dt.⃗ℐ=∫t2t1⃗Fdt=Δ⃗q
⃗ℐ=∫t2t1⃗Fdt=Δ⃗q=m(⃗v2−⃗v1)6"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#6,6,"⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)Momento angolare
xyz
O
P
Punto materiale di massa m con velocità  ⃗vMomento angolare o  momento della quantità di moto rispetto al polo O: 
Rispetto al polo F: P
F
Osservazione: il vettore quantità di moto è un vettore applicato nel punto P
7⃗pF=(⃗r−⃗rF)∧⃗q"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#7,7,"Momento angolare nel piano
Y
O
Velocità: componente radiale più tangenziale
Il momento angolare: - Dipende dalla velocità trasversa, non da quella radiale - È un vettore  al piano definito da  e  - È diverso da zero solo quando c’è una rotazione - È costante in un moto circolare uniforme⊥→𝑟→𝑣velocità angolare
8⃗v=⃗vr+⃗vt=vr̂ur+vt̂ut=·r̂ur+r·φ̂ut̂ur̂utφ⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)⃗p0=⃗r∧⃗q=m(r̂ur)∧(·r̂ur+r·φ̂ut)=mr2·φ(̂ur∧̂ut)=mr2·φ̂k·φ=dφdt=ω"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#8,8,"d⃗p0dt=⃗r∧⃗F=⃗M0Derivata del momento angolareDerivando:La derivata del momento angolare é uguale al momento della forza agente sul punto materiale rispetto allo stesso polo.Il momento delle forze è nullo se: -La forza agente è nulla (punto isolato da altri corpi) -Vettore posizione e forza sono paralleli  Se il momento delle forze è nullo, il momento angolare è costante in modulo direzione e verso: la traiettoria giace su un piano. 9⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)d⃗p0dt=d(⃗r∧⃗q)dt=d⃗rdt∧⃗q+⃗r∧d⃗qdt=⃗v∧⃗q+⃗r∧⃗F"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#9,9,"Sistemi di punti materialiUn insieme di N punti materiali di masse mi costituisce un sistema di punti materiali 
xyz
OSRI
12iDef: massa del sistema di punti materiali:
NM=mii=1N∑Def: Quantità di moto del sistema di punti materiali: 
Def: Momento della quantità di moto (o momento angolare): (momento risultante del sistema)10⃗P0=N∑i=1⃗pi=N∑i=1⃗ri∧⃗qi=N∑i=1mi⃗ri∧⃗vi"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#0,0,Dinamica dei Sistemi CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#1,1,"Equazioni cardinali 
2Dal principio di indipendenza delle azioni simultanee: le forze ed i momenti interni rimangono nulli anche in presenza di forze e momenti delle forze esterni.6 equazioni scalari! Descrivono esattamente: 1.Il moto di un punto 2.Il moto di 2 punti 3.Il moto di un corpo rigido𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇Equazioni cardinali della dinamica dei sistemiChe cosa descrivono per un sistema generico di N punti materiali?"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#10,10,"Teorema del momento angolare
11A cosa sono dovute le variazioni del momento angolare totale di un sistema di punti?Consideriamo un polo O’ mobile (non necessariamente il CM)
O
O’
Derivando:=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−𝑁∑𝑖=1𝑚𝑖→𝑣𝑂′ ∧→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′ )∧→𝑎𝑖==𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−→𝑣𝑂′ ∧𝑁∑𝑖=1𝑚𝑖→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′ )∧→𝑎𝑖Quantità di moto totale del sistemaMomento delle forze agenti sul sistema rispetto polo O’Nullo perché prodotto vettoriale fra vettori paralleli⃗PO′ =N∑i=1⃗pi=N∑i=1mi⃗r′ i∧⃗vi=N∑i=1mi(⃗ri−⃗rO′ )∧⃗vid⃗PO′ dt=N∑i=1mid[(⃗ri−⃗rO′ )∧⃗vi]dt==N∑i=1mi(⃗vi−⃗vO′ )∧⃗vi+N∑i=1mi(⃗ri−⃗rO′ )∧⃗ai=−→𝑣𝑂′ ∧→𝑄+→𝑀𝑂′ "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#11,11,"Teorema del momento angolare
12O
O’
Estensione della seconda equazione cardinale al caso di un polo mobile:  seconda equazione cardinale generalizzataUsando il primo teorema del centro di massa−→𝑣𝑂′ ×𝑀→𝑣𝐶𝑀+→𝑀𝑂′ =−𝑀→𝑣𝑂′ ×→𝑣𝐶𝑀+→𝑀𝑂′ 𝑑→𝑃𝑂′ 𝑑𝑡=−→𝑣𝑂′ ×→𝑄+→𝑀𝑂′ ="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#12,12,"Teorema del momento angolare: se il polo O’ è fisso nel SRI o coincide con il CM, l’evoluzione nel tempo del momento angolare è determinata dal momento risultante delle forze esterne.Teorema del momento angolare
13Il secondo termine è nullo quando: 1- O’ è fermo nel SRI 2- il CM è fermo nel SRI 3- il polo O’ coincide con il CM 4- 
Sempre, anche  quando il CM si muove!
In uno di questi casi𝑑→𝑃𝑂′ 𝑑𝑡=→𝑀𝑂′ −𝑀→𝑣𝑂′ ×→𝑣𝐶𝑀
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#13,13,"Equazioni cardinali
14
Descrivono il moto di un sistema di N punti materiali attraverso il suo CMSistema di equazioni non completo: non si può descrivere il moto di N punti con sole 2 equazioni vettoriali, ma queste forniscono una indicazione globale su come si muove il CM e l’evoluzione del momento angolare calcolato rispetto al CM.Per un sistema di punti materialiEquazioni cardinali:  moto di 1 punto, 2 punti, corpo rigido"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#14,14,"Energie di un sistema di punti
15Osservazione: la forza ed il lavoro sono grandezze additive Anche l’energia (cinetica, potenziale, meccanica) è una grandezza additiva.Definiamo energia cinetica di un sistema:
Definiamo energia potenziale di un sistema soggetto solo a forze conservative interne o esterne:
Analogamente definiremo Energia Meccanica di un sistema:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#15,15,"Teorema di König
16
Usiamo coordinate intrinseche: 
Energia cinetica come calcolata nel SR del CM (SR intrinseco)Energia cinetica nel SRI di un punto di massa M  con velocità pari a quella del CM
TCM=
⃗Q′ =0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#16,16,"T=T′ +TCMTeorema di König
17Energia cinetica nel SR del CM (SR intrinseco)Energia cinetica di un punto di massa M con velocità pari a quella del CM
Teorema di König: l’energia cinetica di un sistema di punti materiali in moto rispetto ad un punto O è, istante per istante, uguale alla somma dell’energia cinetica del sistema rispetto al CM (T’) più l’energia che possiederebbe in quell’istante rispetto ad O il CM se in esso fosse concentrata tutta la massa (TCM).
()T′ =0TCM=12Mv2CMT′ =N∑i=112miv′ 2i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#17,17,"Sistema di punti soggetti a forza peso
18O
CM
Ricordando la definizione di CM:
⟹𝑀→𝑟𝐶𝑀=∑𝑁𝑖=1𝑚𝑖→𝑟𝑖"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#18,18,"Sistema di punti soggetti a forza peso
19O
CM
Un sistema di punti soggetto alla forza peso si comporta come un unico punto materiale coincidente con il CM avente massa M
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#19,19,"Esercizio
20
Un proiettile è lanciato con una velocità di 20 m/s ad un angolo di 30° rispetto l’orizzontale. Nel corso della sua traiettoria esplode suddividendosi in due frammenti, uno dei quali ha massa doppia rispetto quell’altro. I due frammenti colpiscono il suolo nello stesso istante. Il frammento di massa minore colpisce il suolo a 20 m dal punto di lancio. In quale punto colpisce il suolo il secondo frammento?"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#2,2,Equazioni cardinali -Per N punti materiali servono N equazioni vettoriali del tipo  quindi 3N equazioni scalari; -Le equazioni cardinali sono al massimo 6 equazioni scalari  mancano 3N-6 equazioni scalari che diano informazioni mancanti (es: vincoli che legano fra loro i punti come nel caso dei corpi rigidi)→𝐹=𝑚→𝑎⟹Per N punti materiali le equazioni cardinali forniscono solo informazioni parziali:  non forniscono informazioni sul singolo punto ma danno informazioni collettive.  Che cosa descrivono le equazioni cardinali per un sistema di N punti materiali?  È possibile trovare un elemento del sistema che sia descritto dalle equazioni cardinali? 3
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#20,20,"Sistemi continui
21Sistemi non puntiformi: insiemi “densi” di punti àsistemi continui (estesi). Per tali sistemi la grandezza (dimensione lineare) è importante.  Possiamo caratterizzarli attraverso una nuova quantità geometrica:      Volume V     [L3] àm3Anche un sistema continuo è dotato della proprietà Massa del Sistema:          Massa M     [M] àkg
M=∫dm=∫Vρ(⃗r)dτDef: densità volumetrica puntuale (locale) di massa: 
dm,dτρ(⃗r)=dmdτdm=ρ(⃗r)dτDef: densità volumetrica media di massa: 
M,τ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#21,21,"Legame tra sistemi di punti e sistemi estesi
22
Sistema di punti
Sistema esteso
Un sistema continuo può essere pensato come un sistema di N punti materiali, con Nà+∞ 
M=∫dm=∫Vρ(⃗r)dτρ(⃗r)=dmdτ
M=∫dm=∫Vρ(⃗r)dτ∫f(⃗r,⃗v)dm=∫Vf(⃗r,⃗v)ρ(⃗r)dτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#22,22,"Esempio: centro di massa
23
Sistema di punti
Sistema continuo
Esempio: cubo omogeneo di lato L
xzy⃗rCM=∫V⃗rρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫V⃗rρ(⃗r)dτMxCM=∫Vxρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vxρ(⃗r)dτMyCM=∫Vyρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vyρ(⃗r)dτMzCM=∫Vzρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vzρ(⃗r)dτM"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#23,23,"SISTEMI PIANI
24Se un sistema continuo volumetrico ha una dimensione sempre costante allora può essere trattato come un sistema continuo pianoEsempi: foglio di carta, lastra metallica, tavola di legno, muro
Def: densità superficiale media di massa: 
Def: densità superficiale puntuale (locale): 
Dimensionalmente:
Se il sistema esteso ha uno spessore costante pari a D:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#24,24,"¯λ=MLSistemi lineari
25Se un sistema continuo volumetrico ha due dimensioni sempre costanti allora può essere trattato come un sistema continuo lineareEsempi: corda, filo, sbarra, palo, colonna, pilastroDef: densità lineare media: 
Def: densità lineare puntuale (locale): 
[¯λ]=[ML−1]kg/m"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#25,25,"Esercizio
26Una sbarra di lunghezza L è collocata lungo l’asse x con un estremo nell’origine (0<x<L). Determinare la coordinata x del CM sapendo che la sbarra ha una densità lineare pari a:
xL0Caso 1:
Caso 2:
Caso 3:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#26,26,"Esercizio
27Trovare le coordinate del CM di un triangolo rettangolo isoscele di lato L e densità superficiale σ costante.
yxO
dx
Verificare che 
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#27,27,"Corpi rigidi
28
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#28,28,"Moto del corpo rigido
29Sistema di N=1 punto 
3 variabili dinamicheSistema rigido di N=2 punti 
6 variabili dinamiche dei punti - 1 vincolo = 5 variabili dinamiche indipendenti
Sistema rigido di N=3 punti 3x3=9 variabili dei punti - 3 vincoli = 6 variabili indipendenti
Sistema rigido di N>3 punti Ogni punto in più introduce 3 variabili dinamiche del punto e 3 vincoli
Nel caso del corpo rigido il moto è descrivibile da sole 6 equazioni.
6 variabili dinamiche indipendenti"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#29,29,"Quali variabili dinamiche?
30La descrizione completa ne richiede 6. Ho la libertà di scegliere quali.
ABCon le 6 variabili così definite posso descrivere la posizione del corpo rigido nello spazio. Sono convenienti dal punto di vista della dinamica?
Suggerimento: 3 coordinate del CM + 3 variabili angolari6 eq. in 6 incogniteEsempio:  •3 coordinate del punto A + 3 coordinate del punto B – 1 vincolo sulla distanza AB = 5 variabili. •1 angolo di rotazione attorno all’asse AB
Equazioni  cardinali per sistema di punti"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#3,3,"Centro di Massa
4O
CM
Sia dato un sistema di N punti materiali descritti in un sistema di riferimento inerziale, si definisceCentro di massa:
3mmL
L/43L/4CM
Punto geometrico definito dal vettore posizione   “interno al sistema”, ma non necessariamente appartenente al sistema. E’ una caratteristica del sistema di punti e non del sistema di riferimento usato.→𝒓𝑪𝑴"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#30,30,"Moto generico di un corpo rigido
31Due possibili moti indipendenti:
2.Moto rotatorio puro attorno ad un asse passante per il CM che è fisso    Tutti i punti compiono un moto circolare attorno all’asse istantaneo di rotazione
Vale ancora:Due possibili moti indipendenti:1.Moto traslatorio puro.   - Tutti i punti hanno la stessa velocità (del CM)  - Traiettorie dei punti sono tutte parallele  - Moto descritto dalla prima equazione cardinale
CM
 Il moto più generico possibile è un moto roto-traslatorio, dove il CM si muove seguendo la prima equazione cardinale ed il corpo fa un moto rotatorio attorno ad un asse istantaneo di rotazione e solo se l’asse di rotazione passa per il CM il moto è descritto dalla seconda equazione cardinale. "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#31,31,"Moto di un corpo rigido
32
Equazioni cardinali per i sistemi sono separate per il moto del CM e per l’evoluzione del momento angolare.Prima equazione cardinale analoga a  per il punto materiale. Ben nota.→𝐹=𝑚→𝑎Seconda equazione cardinale è la vera novità per il moto dei corpi estesi. La studiamo in dettaglio nel caso più semplice: il CM non ha moto traslatorio e utilizzo il sistema di riferimento intrinseco (moto rotatorio puro)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#32,32,"Moto rotatorio puro
33
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare  ⃗ωIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Legge di trasformazione delle velocità tra due sistemi di riferimento in moto relativo⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#33,33,"Moto rotatorio puro
34
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Nulli perché i due sistemi di riferimento si muovono reciprocamente di solo moto rotatorio.⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#34,34,"Moto rotatorio puro
35
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’ perché  per la scelta del sistema S’ →𝑟𝑖=→𝑟′ 𝑖→𝑟𝑂′ =→𝑟𝐶𝑀=0⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i=ω∧⃗ri"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#35,35,"Moto rotatorio puro
36
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Momento angolare per sistemi di punti materiali.Momento angolare per sistemi estesi.⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i=ω∧⃗ri⃗PCM=∫V⃗r∧⃗vρdτ=∫V⃗r∧(⃗ω∧⃗r)ρdτ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#36,36,"Momento angolare di un sistema rigido
37
Proprietà del doppio prodotto vettoriale:2)  ⃗ri(⃗ω⋅⃗ri)=(xîı+yî𝚥+zîk)⋅(xiωx+yiωy+ziωz)=1) ⃗ωr2i=ωxr2îı+ωyr2î𝚥+ωzr2îk⃗ri=(xîı+yî𝚥+zîk)
=̂ı(ωxx2i+ωyxiyi+ωzxizi)+̂𝚥(ωxxiyi+ωyy2i+ωzyizi)+̂k(ωxxizi+ωyyizi+ωzz2i)⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)⃗PCM=N∑i=1mi⃗ri∧(ω∧⃗ri)=N∑i=1mi⃗ωr2i−N∑i=1mi⃗ri(⃗ω⋅⃗ri)⃗a∧⃗b∧⃗c=⃗b(⃗a⋅⃗c)−⃗c(⃗a⋅⃗b)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#37,37,"Momento angolare di un sistema rigido
38Sostituisco le espressioni trovate in precedenza=N∑i=1mi(ωxr2îı+ωyr2î𝚥+ωzr2îk)+−N∑i=1mi[̂ı(ωxx2i+ωyxiyi+ωzxizi)++̂𝚥(ωxxiyi+ωyy2i+ωzyizi)++̂k(ωxxizi+ωyyizi+ωzz2i)]⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#38,38,"Momento angolare di un sistema rigido
39            =̂ı𝑁∑𝑖=1𝑚𝑖[(𝜔𝑥𝑟2𝑖−𝜔𝑥𝑥2𝑖−𝜔𝑦𝑥𝑖𝑦𝑖−𝜔𝑧𝑥𝑖𝑧𝑖)]++̂𝚥𝑁∑𝑖=1𝑚𝑖[(𝜔𝑦𝑟2𝑖−𝜔𝑥𝑥𝑖𝑦𝑖−𝜔𝑦𝑦2𝑖−𝜔𝑧𝑦𝑖𝑧𝑖)]+̂k𝑁∑𝑖=1𝑚𝑖[(𝜔𝑧𝑟2𝑖−𝜔𝑥𝑥𝑖𝑧𝑖−𝜔𝑦𝑦𝑖𝑧𝑖−𝜔𝑧𝑧2𝑖)]Raccolgo tutti i termini diretti lungo lo stesso versore⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#39,39,"Momento angolare di un sistema rigido
40
Si è sostituito: 𝑟2𝑖−𝑥2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑥2𝑖=𝑦2𝑖+𝑧2𝑖𝑟2𝑖−𝑦2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑦2𝑖=𝑥2𝑖+𝑧2𝑖𝑟2𝑖−𝑧2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑧2𝑖=𝑥2𝑖+𝑦2𝑖E ordino secondo le componenti di →𝜔⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#4,4,"Centro di Massa
5Centro di massa:
Equazione vettoriale  corrisponde a 3 equazioni scalari⇒𝑥𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑥𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑥𝑖𝑦𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑦𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑦𝑖𝑧𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑧𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑧𝑖"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#40,40,"Momento angolare di un sistema rigido
41
Compaiono dei termini uguali nelle posizioni simmetriche. ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#41,41,"Momento angolare di un sistema rigido
42
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎I: tensore d’inerzia Matrice 3x3 simmetrica
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#42,42,"Momento d’inerzia
43
in generale non sono paralleli.
problema agli autovalori/autovettoriI=I0100010001⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟In casi particolari il tensore d’inerzia è diagonale e proporzionale al tensore unitario
Indipendentemente dalla sua forma, per un corpo rigido generico esistono tre direzioni (detti assi principali d’inerzia) per cui  : →𝑷∥→𝝎→𝑷=𝝀→𝝎Esempi: - Sfera di raggio R e massa M:    
              - Cubo di lato L e massa M:    
⃗P=I⃗ω=λ⃗ω(I−1λ)⃗ω=0→(I−1λ)=0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#43,43,"Momento d’inerzia
44problema agli autovalori/autovettoriè la matrice d’inerzia simmetrica  esistono sempre 3 autovalori e 3 autovettori che diagonalizzano la matrice𝐼 →𝐼=𝐼𝑥𝑥000𝐼𝑦𝑦000𝐼𝑧𝑧,= momenti principali d’inerzia Per tale matrice  sono gli assi principali d’inerzia.Ixx,Iyy,Izẑı,̂𝚥,̂k(I−1λ)⃗ω=0→(I−1λ)=0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#44,44,"Momento d’inerzia
45Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z (velocità angolare solo lungo l’asse z) si ha:
Per sistemi di punti materialiPer sistemi estesi⃗P=I⃗ω=Ixx000Izz000Izz(00ω)=Izzω̂k⃗P=Izzω̂kIzz=∫V(x2+y2)ρdτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#45,45,"Rotazioni attorno all’asse z:⃗P=Iω̂k
46z
xy
Prendo un sistema di N punti materiali simmetrico rispetto all’asse z in moto rotatorio con velocità  attorno ad un asse coincidente con l’asse di simmetria. →𝜔Sistemi simmetrici rispetto ad un asse hanno nell’asse di simmetria un asse principale
Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z si ha con →𝑃=𝐼𝑧𝑧→𝜔=𝐼𝑧𝑧𝜔^𝑘 𝐼𝑧𝑧=∑𝑁𝑖=1𝑚𝑖(𝑥2𝑖+𝑦2𝑖)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#46,46,"Rotazioni attorno all’asse ⃗P=Iω̂k
47Per un sistema di N punti materiali simmetrico rispetto all’asse z
I    (cvd)→𝑃=𝐼→𝜔=𝐼𝑥𝑥𝐼𝑥𝑦0𝐼𝑥𝑦𝐼𝑦𝑦000𝐼𝑧𝑧00𝜔^𝑘=𝐼𝑧𝑧𝜔^𝑘z
xy
Per un sistema di N puntiPer un sistema esteso
Izz=∫V(x2+y2)ρdτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#47,47,"Dinamica rotazionale
48Dinamica rotazionale:
Analoga a :
Stessa struttura, stesse soluzioni. in generale è una variabile dinamica vettoriale descritta da 3 variabili scalari di tipo angolare che possono essere:  •2 variabili per indicare la direzione del vettore •1 variabile per l’intensità della velocità angolare.→𝜔𝑑→𝑃𝐶𝑀𝑑𝑡=→𝑀𝐸𝑆𝑇𝐶𝑀→𝑃=𝐼→𝜔𝑑→𝑣𝐶𝑀𝑑𝑡=→𝐹𝐸𝑆𝑇𝑀⟹𝑑→𝑣𝐶𝑀=→𝐹𝐸𝑆𝑇𝑀𝑑𝑡⇒→𝑣𝐶𝑀=𝑡∫0→𝐹𝐸𝑆𝑇𝑀𝑑𝑡+→𝑣0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#48,48,"Dinamica rotazionale
49
Caso più semplice: moti con asse di rotazione fisso (z): →𝜔=𝜔^𝑘
 diretto lungo l’asse z→𝑀𝐸𝑆𝑇𝐶𝑀=𝑀𝐸𝑆𝑇𝐶𝑀^𝑘𝐼𝑧𝑧𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀→𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧⟹𝑑𝜔=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡⇒Il momento d’inerzia rappresenta per la dinamica rotazionale ciò che la massa rappresenta nel moto traslatorio: fornisce l’inerzia del corpo rigido ad essere messo in moto rotatorio.𝜗(𝑡)=𝑡∫0𝜔(𝑡)𝑑𝑡+𝜗0𝜔(𝑡)=𝑡∫0𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡+𝜔0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#49,49,"Esempio
50Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx =2𝑚(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)=⃗v1=d⃗r1dt=−·θRsinθ̂ı+·θRcosθ̂𝚥⃗v2=d⃗r2dt=−d⃗r1dt=−⃗v1⃗PCM=m⃗r1∧⃗v1+m⃗r2∧⃗v2=m⃗r1∧⃗v1+m(−⃗r1)∧⃗(−v1)=2m⃗r1∧⃗v1=2m⃗r1∧⃗v1=2m(Rcosθ̂ı+Rsinθ̂𝚥)∧(−R·θsinθ̂ı+R·θcosθ̂𝚥)==2𝑚˙𝜃𝑅2(𝑐𝑜𝑠2𝜃+𝑠𝑒𝑛2𝜃)^𝑘=2𝑚˙𝜃𝑅2^𝑘"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#5,5,"Primo teorema del Centro di Massa
6Velocità del Centro di massa:
Centro di massa:
Derivando:
Ricordando:⟹⟹"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#50,50,"Esempio
51Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx→𝑃𝐶𝑀=𝐼→𝜔⟹2𝑚˙𝜃𝑅2^𝑘=𝐼→𝜔⟹{𝐼=2𝑚𝑅2→𝜔=˙𝜃^𝑘Caso  MEST =0  ⟹
𝑑𝑃𝐶𝑀𝑑𝑡=𝑀𝐸𝑆𝑇→𝑃𝐶𝑀=2𝑚˙𝜃𝑅2^𝑘Seconda equazione cardinaleCaso  MEST=cost  ⟹
  ˙𝜃(𝑡)=˙𝜃0+𝛼𝑡𝜃(𝑡)=𝜃0+˙𝜃0𝑡+12𝛼𝑡2"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#51,51,"Momenti d’inerzia di solidi
52Sbarra omogenea di massa M e lunghezza L: 
I=λx2dx−L2L2∫=λx33⎡⎣⎢⎤⎦⎥−L2L2=λ2L33⋅8=MLL33⋅4=ML212Disco omogeneo di raggio R e massa M: 
σ=MS=MπR2,dS=2πrdrI=σr22πrdr0R∫=2πσr44⎡⎣⎢⎤⎦⎥0R=2πMπR2R44=MR22Piastra rettangolare omogenea di lati a e b:
σ=MS=Mab,dS=dxdy
-a/2a/2b/2-b/2-L/2L/2"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#52,52,"Teorema di Huygens-Steiner
53Calcoliamo il momento d’inerzia rispetto ad un asse passante a distanza D                            dal CM (asse lungo z) per un sistema rigido di N punti materiali.
CMxyy’x’z’z
Per definizioneIntroduco il SR intrinseco
Il momento d’inerzia rispetto ad un asse qualunque è sempre pari al momento d’inerzia calcolato rispetto ad un asse parallelo a quello dato ma passante per il CM aumentato della quantità MD2 con D distanza tra i due assi.
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#53,53,"Teorema di König per corpi rigidi
54Energia cinetica di un sistema di punti materialiVelocità dei punti nel sistema del CM
αd
T=T'+TCM=12mivi'2i∑+12MvCM2
Energia cinetica di rotazioneEnergia cinetica di traslazioneCome si calcola l’energia cinetica totale di un corpo rigido?Ipotesi semplificata: corpo in rotazione istantanea attorno a un asse passante per il CM diretto lungo z."
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#54,54,"Statica dei corpi rigidi•Quando un corpo rigido è in condizioni statiche? (ànon si muove)
55
Equazioni cardinali della Dinamica dei sistemiR: Quando ogni punto del corpo è e rimane fermo!                      il corpo non trasla e non ruota!
Controllo forze e momenti esterni e questo garantisce che il corpo resti fermo per il 1°, 2° e 3° principio!"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#55,55,"Macchina di AtwoodDiscutere il moto dei due oggetti 1 e 2 appesi tra loro su una carrucola tramite un filo ideale nel caso: 1) la carrucola sia ideale; 2) la carrucola sia reale. 
56
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#56,56,"EsercizioUn’asta omogenea di sezione trascurabile, di massa m e lunghezza l giace su un piano orizzontale liscio inizialmente ferma ed incernierata in uno degli estremi. Ad un certo istante un punto materiale di massa 2m che si muove con velocità v0 urta in modo totalmente anelastico e perpendicolarmente l’asta nel suo centro. Calcolare le espressioni:  1)Della velocità angolare del sistema dopo l’urto; 2)Della reazione vincolare che agisce sul sistema dopo l’urto.57"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#57,57,"EsercizioUna forza costante di 1960 N applicata tangenzialmente al bordo di un disco di raggio R=100 cm ne fa variare la velocità angolare da 4 s-1 a 2 s-1 in 30 s. Determinare: -il momento d’inerzia della ruota attorno al suo asse;  -il modulo della variazione del momento angolare nei 30 sec considerati;  -l’angolo descritto dalla ruota in questo intervallo di tempo -l’energia cinetica persa.
58"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#58,58,"EsercizioUn disco omogeneo di massa M = 0.4 kg e raggio R = 10 cm viene appoggiato in verticale su un piano inclinato di 30° rispetto l’orizzontale. Sapendo che il disco scende rotolando senza strisciare, determinare la velocità di traslazione del disco dopo aver compiuto 2 m sul piano inclinato.
59"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#59,59,"EsercizioDue volani assimilabili a due dischi aventi massa e raggio rispettivamente di M1 = 187,5 kg, R1 = 80 cm, M2 = 120 kg e R2 = 50 cm ruotano attorno allo stesso asse fisso orizzontale coincidente con il loro asse di simmetria con velocità angolari di  e . Ad un certo istante I due volani vengono messi a contatto. Calcolare la velocità angolare finale trascurando gli effetti transienti.𝜔1=33 𝑟𝑎𝑑/𝑠𝜔2=2𝜔1
60"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#6,6,"Secondo teorema del Centro di Massa
7Accelerazione del Centro di massa:
Prima equazione cardinale→𝑎𝐶𝑀=𝑑→𝑣𝐶𝑀𝑑𝑡=𝑑(→𝑄𝑀)𝑑𝑡=1𝑀𝑑→𝑄𝑑𝑡=1𝑀→𝐹𝐸𝑆𝑇
Analogia formale  (e sostanziale) con: 
La 1a equazione cardinale descrive il moto di un punto fittizio che è il CM. Se il sistema non è soggetto a forze esterne, il CM si muove con velocità costante. "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#60,60,"EsercizioUna Colonna di marmo di massa M = 600 kg ha la forma di un parallelepipedo a base quadrata di lato L = 30 cm e altezza h = 2.5 m ed è appoggiata in vertical su un piano ruvido inclinato di un angolo  rispetto l’orizzontale. Schematizzando la colonna come una figura piana che appoggia sul piano inclinator nei punti A e B distanti L determinare: 1)Il valore Massimo dell’angolo che permette la stabilità 2)La forza di attrito statica necessaria alla stabilità 3)Il minimo valore del coefficiente di attrito statico necessario per tenere ferma la colonna se 𝛼𝛼=5°
61
AB"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#61,61,"EsercizioDue punti materiali di massa M ruotano nel piano (x,y) attorno all’origine seguendo le equazioni del moto: Determinare le forze esterne ed i momenti delle forze esterne che agiscono sul sistema al tempo t=0.  
62θ(t)=α2t2+ϖ0t"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#62,62,"EsercizioUn disco di massa M = 0.5 kg, raggio R = 0.2 m e spessore trascurabile ha densità superficiale . Supponendo che il disco sia disposto orizzontalmente e ruoti attorno ad un asse verticale passante per il suo centro con velocità angolare  = 4 rad/s, calcolare l’energia cinetica del sistema.σ=kr⃗ω
63"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#63,63,"Esercizio
64Una sbarra omogenea di massa M e lunghezza L è appesa al soffitto tramite un filo collegato al suo centro di massa. La sbarra si muove in un piano orizzontale (x,y) e il filo esercita un debole momento delle forze dato da                          .       Calcolare il periodo del movimento.
xy
θ
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#7,7,"Sistema di riferimento del CM
8
Posizione del CM rispetto al CMVelocità del CM rispetto al CM
Calcoliamo la posizione del CM nel sistema intrinsecoIl CM definisce un punto importante per capire la dinamica del sistema. La prima equazione cardinale riguarda il moto di questo punto.  Che cosa descrive la seconda equazione cardinale?E’ conveniente introdurre un nuovo sistema di riferimento S’ (in generale NON inerziale) che esalti il ruolo del CM: SR Intrinseco con origine coincidente col CM.
O
CM=O’
→𝑟𝑖
→𝑟𝐶𝑀"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#8,8,"Terzo teorema del centro di massa
9Riscriviamo il momento angolare nel SRI usando il sistema intrinseco:
=𝑁∑𝑖=1𝑚𝑖(→𝑟′ 𝑖+→𝑟𝐶𝑀)∧(→𝑣′ 𝑖+→𝑣𝐶𝑀)Sostituendo:=𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣′ 𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣𝐶𝑀+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣′ 𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣𝐶𝑀=𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣′ 𝑖+(𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖)∧→𝑣𝐶𝑀+→𝑟𝐶𝑀∧(𝑁∑𝑖=1𝑚𝑖→𝑣′ 𝑖)+(𝑁∑𝑖=1𝑚𝑖)→𝑟𝐶𝑀∧→𝑣𝐶𝑀=momento angolare del sistema calcolato rispetto al SR intrinseco⃗P′ CM=𝑀⟹𝑀→𝑟𝐶𝑀∧→𝑣𝐶𝑀Momento angolare di un punto di massa M situato nel CM Nulli per dimostrazione precedente⃗P0=N∑i=1⃗pi=N∑i=1mi⃗ri∧⃗vi"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#9,9,"Terzo teorema del centro di massa
10
Spin o momento angolare intrinseco
Terzo teorema del centro di massa: il momento angolare rispetto ad un polo O di un sistema di punti materiali è in ogni istante uguale alla somma del momento angolare del sistema calcolato nel sistema di riferimento del centro di massa e del momento angolare rispetto allo stesso polo O di un punto materiale di massa pari alla massa totale M del sistema collocato nel CM.⃗P0=⃗P′ CM+M⃗rCM∧⃗vCM=⃗P′ CM+⃗rCM∧⃗Q"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#0,0,Campo Gravitazionale CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#1,1,"Moto dei pianeti
2Meccanica diventa disciplina coerente dopo un’accurata e attendibile descrizione del moto dei pianeti: moto in assenza di attriti studiabile per lungo tempo -> metodo scientifico facilmente applicabile: Comprensione del moto -> previsione del moto -> verifica sperimentale.Principali risultati grazie a : -Tycho Brahe (1546-1601): misura di precisione delle posizioni dei pianeti -Johannes Kepler (1571-1630): formulazione leggi empiriche sui moti dei pianeti a partire dai dati di Brahe
"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#2,2,"Leggi di Keplero1.I pianeti descrivono orbite piane, ellittiche, di cui il Sole occupa uno dei due fuochi. 2.Il raggio vettore che unisce il centro del Sole con il centro del pianeta descrive aree uguali in tempi uguali. 3.I quadrati dei tempi che i pianeti impiegano a percorrere le loro orbite sono proporzionali al cubo del semiasse maggiore dell’orbita.3
a2T3=costante"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#3,3,"Gravitazione universale
4•Cosa fa girare i pianeti? •Moto può avvenire anche in assenza di forza (principio di inerzia), ma serve una “spinta” centripeta per mantenere il corpo in traiettoria curva. •Newton: pianeti si muovono sottoposti alla forza di gravità che è la stessa che fa cadere i corpi a Terra. •Che forma ha questa forza?"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#4,4,"5Velocità areolare
A(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#5,5,"Gravitazione universale
61a legge di Keplero: il moto avviene su un piano.Velocità areolare2a legge di Keplero: la velocità areolare è costante in modulo.
2o principio dinamica ⃗A=12(P−O)∧⃗v=12⃗r∧⃗vd⃗Adt=12ddt(⃗r∧⃗v)=12(d⃗rdt∧⃗v+⃗r∧d⃗vdt)=12(⃗v∧⃗v+⃗r∧⃗a)=12⃗r∧⃗a=⃗0Campo centrale a simmetria sferica"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#6,6,"Gravitazione universale
73a legge di Keplero:Moto dei pianeti può essere schematizzato come moto circolare uniforme 
Stessa struttura di quanto ipotizzato dalla 2a leggeDallo studio dei moti celesti:  con M=massa attorno a cui ruota m     GM=4π2kCostante di gravitazione universaleG=6,672⋅10−11N⋅m2kg2a2T3=costanteT=2πω→ω=2πT⃗a(t)=⃗at+⃗an=··ŝut+v2ρ̂un=v2ρ̂unT2=kR3⃗Fcentripeta=m⃗ac=mv2R̂un=mω2R̂un=m4π2T2R̂un⟹⃗Fcentripeta=m4π2T2R̂un=m4π2kR3R̂un=−m4π2kR2̂ur"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#7,7,"Legge di gravitazione universale
8
Un qualsiasi punto materiale P1 di massa m1 esercita su un qualunque altro punto materiale P2 di massa m2 una forza gravitazionale F12 diretta secondo la congiungente di P1 con P2, sempre attrattiva, in modulo direttamente proporzionale al prodotto delle due masse e inversamente proporzionale al quadrato della distanza fra P1 e P2. •Per il terzo principio della dinamica se P1 esercita una forza su P2 allora P2 esercita una forza  su P1 uguale e contraria •Sul sistema agiscono due forze di risultante nulla ma applicate in punti di applicazione diversi -> il moto è uno solo •La forza gravitazionale è conservativa poiché è un campo centrale a simmetria sferica -> esiste un potenziale gravitazionale ⃗F12⃗F21conˆr=P2−P1"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#8,8,"Energia potenziale gravitazionale
9Campo conservativo
Costante arbitrariaScelgo r0→∞⇒V(∞)=−Gm1m2r0=0V(A)=−Gm1m2rAEnergia potenziale gravitazionale"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#9,9,"Velocità di fuga
10
Velocità di fuga: velocità minima che occorre imprimere ad un corpo per far si che si allontani da un altro corpo senza ricadervi.Corpo in R si allontana in modo che arrivi all’infinito con velocità nullaConservazione dell’energia meccanica
12mvfuga2−GmMR=0⇒vfuga=2GMRG"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#0,0,1 Elettrostatica CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#1,1,"2Fenomeni elettriciFenomeni elettrici (e magnetici) noti dall’antichità
Teoria completa dei fenomeni elettrici (e magnetici) nella seconda metà XIX secolo: Volta, Ampère, Faraday, Maxwell, Ørsted 
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#10,10,"11Elettrizzazione per contatto
AC++++++++12Q+AB++++++++12Q+12Q+++++++++Fino a che punto possiamo suddividere (separare) la carica elettrica?
Limite della Natura la più piccola carica elettrica osservata fino ad ora in natura è quella dell’elettrone (-) e del protone (+)Cariche elettriche frazionar ie della carica elementari sono s tate ipotizzate  (quark confinati all’interno di protoni e neutroni) ma MAI osservate fino ad ora"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#11,11,"12La carica elettricaUnità di misura della carica elettrica nel Sistema Internazionale:  C  (Coulomb) Carica dell’elettrone:   qe= −1.6 × 10-19 C   Carica del protone:      qp= +1.6 × 10-19 C Limite sperimentale:                                                                   |qe| |qp||qp|    <⇡10 21"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#12,12,13La carica elettrica - esempiCarica degli elettroni in una goccia d’acqua (1g)  Ne=(Np)=3×1023     |Qe|=(|Qp|)=5×104 C  Forza tra due cariche da 1C ad 1m di distanza 9×109 N (equivalente a 100 Titanic!!)Carica in processi triboelettrici  |Q|=10-7C (1011 elettroni)1m1C1C×100
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#13,13,"14Proprietà carica elettricaEsistono due tipi di cariche elettriche  •convenzionalmente positive e negative La carica elettrica è quantizzata •in natura le cariche sono multiple della carica elettrica elementare  |qe|= 1.6 × 10-19−19 C In un sistema isolato, la carica elettrica si conserva •il numero totale di cariche (negative e positive) rimane invariato "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#14,14,15Interazioni tra cariche elettriche~F=m~aIpotesi iniziali (per il momento…) •Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra le cariche che interagiscono •Consideriamo solo cariche ferme (ELETTROSTATICA)
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#15,15,"16Forza elettrostaticaBilancia di torsione (Coulomb, fine XVIII sec)
𝜃Avvicinando la cariche q2 e q1, si arriva ad una situazione di equilibrio in cui la forza elettrica è bilanciata dalla forza di torsione del pendolo Felettrica=Ftorsione∝𝜃  Dalla misura dell’angolo 𝜃 si ricava l'intensità della forza elettrica.q1, q2 cariche  r distanza tra le cariche 𝜃 angolo di torsione|Fel|/|q1||q2|r2Sperimentalmente si osserva: ricordiamoci che la forza è un vettore…"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#16,16,"17Legge di Coulomb
z
y
x
q1q2SdR cartesiano ortogonaleForza esercitata dalla carica q1 sulla carica q2
Costante dielettrica del vuoto:q1 e q2  puntiformi~F12=14⇡""0q1q2r3~r~F12ha stessa direzione di~re verso che dipende dal segno delle cariche⃗F12=14πε0q1q2r2̂ur
(Farad verrà introdotto in seguito)ε0=8.85×10−12C2Nm2=8.85×10−12Fm14πε0=8.99×109Nm2C2⃗r=⃗r2−⃗r1⃗r1⃗r2⃗F12=q1q24πε0⃗r2−⃗r1|⃗r2−⃗r1|3⃗F12=14πε0q1q2r3⃗r"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#17,17,"18Legge di Coulomb~F21= ~F12III principio della dinamica (sistema isolato)Il vettore forza è applicato sulla caricaStesso segnoq1q2~r=~r2 ~r1~F12=14⇡""0q1q2r3~r~F21q1q2~r=~r2 ~r1~F12=14⇡""0q1q2r3~r~F21Segni opposti"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#18,18,"19Esercizio
𝜃 l m,q m,q l Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡""0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2 12p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema.(R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡""0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2 12p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema.(R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#19,19,"20Forza elettrica vs forza gravitazionaleForza ElettrostaticaForza GravitazionaleHanno stessa forma (entrambe dipendono dall’inverso del quadrato), ma… A. la forza elettrica è molto più intensa della forza gravitazionale B.la massa è sempre positiva (forza gravitazionale sempre attrattiva)14πε0=8.99×109 Nm2C−2G=6.67×10−11kg−1m3s−2⃗FCoulomb=14πε0q1q2r2̂ur⃗FGravitazionale=−Gm1m2r2̂ur"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#2,2,"3Fenomeni elettriciOsservazioni sperimentali (note da VI secolo A.C): oggetti di diversi materiali (es. vetro, plastica, ambra), dopo strofinio su panno di lana, se posti in vicinanza: •oggetti della medesima sostanza, si respingono •oggetti di sostanze diverse possono respingersi o attrarsi 
plastica
vetro
ambra
vetro
plastica
ambra
evidenza sperimentale esistenza di una forza"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#20,20,21EsempioCalcolare il rapporto tra le intensità della forza elettrica e di quella gravitazionale fra un elettrone ed un protone qe= −1.6 × 10-19 C       me= 1.9 × 10-31 kg  qp= +1.6 × 10-19 C       mp= 1.7 × 10-27 kg  G= 6.77 × 10-11 Nm-2kg-2 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#21,21,"22Forza elettrostatica e principio di sovrapposizione
q3q2q1Sistema di N=3 cariche puntiformiForza totale sulla carica q1 è la somma vettoriale della forza        che la carica q2  eserciterebbe su q1 se q3 fosse assente e della forza          che la carica q3  eserciterebbe su q1 se q2 fosse assente⃗F1=⃗F21+⃗F31⃗F21⃗F31⃗F31⃗F1⃗F21"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#22,22,"23Forza elettrostatica e principio di sovrapposizione
q
sistema di N cariche puntiformiForza totale sulla carica q è la somma vettoriale delle forze che le cariche qi eserciterebbero singolarmente su q se qj≠i fossero assentiqi⃗F=N∑i=1⃗Fi⃗ri⃗rivettore posizione da qi a qqj=N∑i=114πε0qqir3i⃗ri"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#23,23,"24Il campo elettrostaticoLa forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza •una carica Q altera le proprietà dello spazio, introducendo un campo elettrico    di cui Q è la sorgente •una seconda carica q (carica esploratrice) sentirà una forza dovuta alla presenza della carica Q⃗E⃗F
  !=lim""V#0""q""V=dqdVDistribuzioni Continue di Carica (II) •!Infine se la carica è distribuita in un volume conviene descrivere la distribuzione della carica utilizzando la densità volumetrica di carica (misurata in C/m3): •!Vogliamo ora calcolare la forza esercitata da una distribuzione di carica descritta dalla densità volumetrica & su di una carica puntiforme q posta a una certa distanza. •!Un volumetto elementare dV situato nel punto P) di vettore posizionale    conterrà la carica elettrica: !r!!r!r!!""r  dVVqr!!   dq=!!""r()dV25!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Distribuzioni Continue di Carica (III) •!Il volumetto dV può essere considerato come una carica puntiforme e dunque possiamo applicare a esso la legge di Coulomb: •!Per il principio di sovrapposizione, la forza totale prodotta su q dalla carica contenuta nel volume V sarà la somma dei contribuiti di tutti i volumetti infinitesimi dV: d!F=14!""0#!$r()dVdq""#$%$q!r%!$r3!r%!$r()!F=14!""0q#!$r()!r%!$r3!r%!$r()dVV&'((&'((&'((26!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!r!!r!r!!""r  dVVq!F12=14!""0q1q2r3!r
Campo Elettrico •!La forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza. •!Possiamo pensare che la presenza di una carica elettrica q1 posta nel punto P1 alteri le proprietà dello spazio, introducendo in esso un campo elettrico. •!Poniamo una carica puntiforme Q nell’origine di una terna cartesiana di riferimento e una seconda carica puntiforme q a una certa distanza r. La forza agente su q si può scrivere: !rqQ!F!r()=14!""0Qqr2ˆr=q14!""0Qr2ˆr#$%&'(!E!r()""#$%$=q!E!r()27!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!F12=14!""0q1q2r2ˆr
Campo Elettrico (II) •!Possiamo allora definire campo elettrico di una carica puntiforme Q il campo vettoriale: e scrivere la forza agente su di una carica q situata nel punto di raggio vettore    come:   !F!r()=q!E!r()   !E!r()=14!""0Qr2ˆrr!
28!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!rqQQ⃗Eq⃗E=limq→0⃗Fq⃗F=q⃗Elimite va inteso in senso “fisico”: • q è quantizzata  •possiamo trascurare i fenomeni di induzione dovuti a q"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#24,24,"25Campo elettrostatico di una carica puntiforme
z
y
xQq⃗rIn un SdR cartesiano poniamo: •carica sorgente Q nell’origine •carica esploratrice q in posizione  •q≪Q (trascuriamo il campo elettrico generato da q)⃗r⃗F(⃗r)=14πε0qQr2̂ur⃗E(⃗r)=14πε0Qr2̂ur
campo elettrostatico di una carica puntiforme Qla carica q è soggetta alla forza:⃗E=q14πε0Qr2̂ur=q⃗E(⃗r)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#25,25,"26Campo elettrostatico di una carica puntiformeL’azione della carica Q sulla carica q viene separata in due fasi distinte: • La creazione, da parte della carica Q, di un campo elettrico          in ogni punto dello spazio; •L’accoppiamento nel punto     del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico.  Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (V olt/metro)⃗E(⃗r)⃗E(⃗r)⃗r"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#26,26,"27Campo elettrico di una carica puntiforme
Campo centrale: •diretto come versore -uscente da Q positiva -entrante in Q negativa •modulo dipende solo da r ̂rIl campo elettrico è un campo vettoriale: per ogni punto dello spazio è associato un vettore
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!⃗E(⃗r)=14πε0Qr2̂ur"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#27,27,"28Principio di sovrapposizione del campo elettricosistema di N cariche puntiformiDimostriamo cheq
qi⃗ri⃗E⃗F=q⃗E⃗F=N∑i=1⃗Fi=qN∑i=1[14πε0qir3i⃗ri]
principio di sovrapposizione del campo elettrico ⃗E=N∑i=1⃗Ei⃗Ei=14πε0qir3i⃗ri=N∑i=114πε0qqir3i⃗ri=N∑i=1q[14πε0qir3i⃗ri]==qN∑i=1⃗Ei=q⃗E"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#28,28,"29Distribuzioni continue di caricaSpesso la carica elettrica non è puntiforme ma può essere distribuita in un volume nello spazio, su di una superficie o lungo una linea⇢=l i m ⌧!0 q ⌧=dqd⌧ =l i m l!0 q x=dqdx =l i m S!0 q S=dqdSDensità volumetrica di caricaDensità superficiale di caricaDensità lineare di carica
dS
dl
d𝜏dq=ρdτcarica contenuta nel volumetto d𝜏  dq=σdS(C/m3)(C/m2)(C/m)
qτ=∭τρdτcarica contenuta nel volume 𝜏  carica contenuta sulla sup. dS  carica contenuta sulla sup S  carica contenuta sulla linea dl  carica contenuta sulla linea l   qS=∬SσdSql=∫lλdldq=λdl"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#29,29,"30Campo elettrostatico da distribuzioni continue
z
y
x
P⃗r−⃗r′ ⃗r⃗r′ Campo elettrico nel punto P generato da una carica infinitesima dq (contenuta in d𝜏):dq=ρ(⃗r′ )dτPer il principio di sovrapposizione  (e sostituendo al limite la somma con l’integrale)volume 𝜏d⃗E(⃗r)=dq4πε0(⃗r−⃗r′ )|⃗r−⃗r′ |3=ρ(⃗r′ )dτ4πε0(⃗r−⃗r′ )|⃗r−⃗r′ |3⃗E(⃗r)=14πε0∭τρ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dτ"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#3,3,"4Elettrizzazione per strofinio (triboelettricità)In natura esistono due tipi di elettrizzazione a cui possiamo associare due tipologie di cariche elettriche Convenzionalmente: •elettrizzazione vetrosa     à carica elettrica positiva •elettrizzazione resinosa   à carica elettrica negativa • cariche dello stesso segno: forza repulsiva • cariche di segno opposto: forza attrattiva
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#30,30,"31Campo elettrostatico da distribuzioni continue
dl
dS
d𝜏Carica distribuita  in volume 𝜏Carica distribuita  su superficie SCarica distribuita  su linea l
Warning! formule generali da usare con attenzione: il calcolo degli integrali può risultare complesso, non fare confusione tra r (posizione del punto in cui si vuole calcolare il campo) e r’ (variabile di integrazione, relativa alla posizione delle cariche)⃗E(⃗r)=14πε0∫lλ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dl⃗E(⃗r)=14πε0∭τρ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dτ⃗E(⃗r)=14πε0∬Sσ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dS"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#31,31,32Il campo elettrico è un campo conservativo?
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#32,32,33PremessaFino ad ora ci siamo posti in condizioni statiche: le cariche sono ferme → ELETTROSTATICA Non abbiamo ancora studiato gli effetti delle cariche in moto   (esistono forze associate ai movimenti delle cariche?) Per il momento continuiamo la trattazione statica: il campo elettrostatico è conservativo?Andiamo a verificare una delle condizioni di conservatività dei campi 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#33,33,"34Circuitazione del campo elettrostaticoCalcoliamo la circuitazione del campo lungo la linea chiusa 𝛤 : circonferenza di raggio R centrata in Q 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!Qd⃗l=̂utdl
∮Γ⃗E⋅d⃗l=∮ΓQ4πε0r2̂ur⋅̂utdl`=0
Il campo elettrico (elettrostatico) generato da una carica puntiforme ferma è conservativo𝛤Circuitazione nullâr"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#34,34,"35Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi∮Γ⃗E⋅d⃗l=0⃗∇∧⃗E=⃗0Il campo elettrostatico ha sempre circuitazione nullaIl campo elettrostatico è  irrotazionale  (non esistono linee di campo chiuse su loro stesse)Equazioni fondamentali dell’elettromagnetismo, applicate al caso statico (cariche ferme)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#35,35,"36Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi
∃ una funzione scalare V(x,y,z):⃗E=−⃗∇VV(x,y,z) è il potenziale elettrostatico ⃗E⋅d⃗l=−dVè un differenziale esattoV(A)−V(B)=∫BA⃗E⋅d⃗lL’integrale non dipende dal percorsometodo per calcolare  il potenziale, partendo dal campo elettrostaticometodo per calcolare  il campo elettrico, partendo dal potenziale ∃ una funzione scalare V(x,y,z):⃗E=−⃗∇V"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#36,36,"37Il potenziale elettrostaticoIl potenziale elettrostatico V(x,y,z) è una funzione scalare in ℝ3   Dato un campo elettrostatico, operativamente il potenziale si calcola integrando il differenziale esattodV=−⃗E⋅d⃗lIl potenziale è definito a meno di una costante additiva arbitraria La differenza di potenziale tra due punti è indipendente dalla costante arbitraria (è una grandezza misurabile → circuiti) integrale indefinitointegrale definitoV(A)−V(B)=∫BA⃗E⋅d⃗lV(x,y,z)=−∫⃗E⋅d⃗l+costL’unità di misura del potenziale nel S.I. è il Volt=Joule/Coulomb  (V)=(J)/(C)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#37,37,"38Il potenziale elettrostatico: carica puntiformeV(⃗r)=−∫⃗E⋅d⃗l+cost
Qd⃗l=̂rdr+̂u⊥dl⊥̂u⊥dl⊥d⃗l̂urdr⃗E=Q4πε01r2̂urV(⃗r)=[−∫Q4πε01r2̂ur⋅(̂urdr+̂u⊥dl⊥)]+cost=[−∫Q4πε01r2(̂ur⋅̂urdr+̂ur⋅̂u⊥dl⊥]+costCalcoliamo V dall’integrale indefinito lungo una generica curva 𝛤  =[−Q4πε0∫drr2]+costV(⃗r)=14πε0Qr+cost𝛤in genere si fissa il potenziale nullo all’infinito:=−Q4πε0(−1r)+cost=14πε0Qr+cost⃗r`1`0V(⃗r→∞)=0⇒14πε0Q(r→∞)+cost=0⇒cost=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#38,38,"39Il potenziale elettrostatico: carica puntiforme
QAB⃗Ecalcoliamo la differenza di potenziale tra i punti A e BΔVAB=VA−VB=∫BA⃗E⋅d⃗l=...=Q4πε0[−1r]BA=Q4πε0(1rA−1rB)=14πε0QrA−14πε0QrBrBrAVA=V(⃗rA)=14πε0QrAVB=V(⃗rB)=14πε0QrBAssumendo il potenziale nullo all’infinito (cost=0)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#39,39,40Principio di sovrapposizione del potenzialeDemo: basta usare la proprietà distributiva del prodotto vettorialeUn campo elettrostatico generato da N cariche discrete o da una distribuzione continua di carica è conservativo⃗∇∧⃗E=⃗∇∧(∑⃗Ei)=∑⃗∇∧⃗Ei=⃗0principio di sovrapposizionecampo da carica puntiforme irrotazionaleV(⃗r)=−∫⃗E⋅d⃗l=−∫(∑⃗Ei⋅d⃗l)=∑∫−⃗Ei⋅d⃗l=∑Vi(⃗r)Il potenziale elettrostatico generato da un sistema di cariche gode del principio di sovrapposizione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#4,4,"5La struttura microscopica della materiaTutti i  materiali formati da atomi (e molecole) Gli atomi sono composti da •nucleo formato da protoni (carichi positivamente) e neutroni (neutri) •attorno al nucleo orbitano gli elettroni (carichi negativamente)
La Forza Elettromagnetica nella Fisica Moderna (II) •!La forza elettromagnetica è la forza dominante nel mondo fisico che conosciamo: –!Tiene uniti gli elettroni al nucleo negli atomi. –!Tiene uniti gli atomi nelle molecole; –!È all’origine delle forze elastiche; –!È all’origine delle forze di tensione delle funi; –!È all’origine delle forze di attrito; –!È all’origine delle forze di resistenza; –!È all’origine delle forze di tensione superficiale dei liquidi; –!È all’origine delle forze di urto; –!È all’origine delle reazioni vincolari. 9!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
La Forza Elettromagnetica nella Fisica Moderna (III) 
10!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Non hanno origine elettromagnetica poche forze comunemente note, tra cui: –!La forza peso (forza gravitazionale); –!La forza che mantiene i pianeti sulle loro orbite (forza gravitazionale); –!La forza che tiene uniti i quark nei nuclei degli atomi (forza nucleare forte). 
La Composizione della Materia molecolaatomonucleoelettrone
protoneneutronequark10 cm!810 cm!12
10 cm!1310 cm!13(<10 cm)!1811!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
I Costituenti della Materia: le Particelle Elementari (Fermioni) 
12!Domenico Galli – Fisica Generale B – 1. Elettrostatica!1 MeV/c2 = 1.783 ! 10–30 kg  Q=23eQ=!13eu d e !e c s µ""!µ""t b #""!#""elettrone up down neutrino elettronico neutrino muonico neutrino tauonico muone tauone charm strange top bottom m = 0 m = 0 m = 0 m = 0.5 MeV/c2 m = 8 MeV/c2 m = 15 MeV/c2 
m = 170000 MeV/c2 m = 4500 MeV/c2 m = 106 MeV/c2 m = 1800 MeV/c2 m = 1600 MeV/c2 m = 300 MeV/c2 leptoni quark Esistite subito dopo il Big Bang. Ora presenti nei raggi cosmici e negli acceleratori Q=!eMateria ordinaria 
1 e = 1.602 ! 10–19 C  
La materia ordinaria risulta complessivamente neutra  (stesso numero di protoni ed elettroni) Perché?"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#40,40,"41Potenziale: sistema di N cariche puntiformisistema di N cariche puntiformi
qi⃗riP(x,y,z)V(x,y,z)=N∑i=1Vi(x,y,z)=N∑i=114πε0qiriIl potenziale in un punto P(x,y,z) è dato dalla somma algebrica dei singoli potenziali generati dalle cariche qi singolarmente "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#41,41,"42Potenziale: sistemi continui di cariche
z
y
x
P(x,y,z)⃗r−⃗r′ ⃗r⃗r′ dqCarica volumetricaCarica superficialeCarica lineare Warning! come per il campo elettrico, queste sono formule generali da usare con attenzioneV(x,y,z)=14πε0∫dq|⃗r−⃗r′ |V(x,y,z)=14πε0∭τρ(⃗r′ )dτ|⃗r−⃗r′ |V(x,y,z)=14πε0∬Sσ(⃗r′ )dS|⃗r−⃗r′ |V(x,y,z)=14πε0∫lλ(⃗r′ )dl|⃗r−⃗r′ |"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#42,42,"x
Exd2−d2
43EsempiSiano date due cariche uguali q+ posizionate sull’asse y di un SdR cartesiano a distanza d dall’origine. Determinare l’espressione del campo e del potenziale elettrostatico sull’asse x.
x
d
⃗E(x,0,0)=q2πε0x(x2+d2)3/2̂ı
y"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#43,43,44EsempioDeterminare il campo ed il potenziale elettrostatico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 ⃗E=λ2πε0r̂ur ortogonale al filo
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#44,44,"z
Ez45EsempioDeterminare il campo elettrostatico sull’asse di un anello di raggio R su cui è depositata uniformemente una carica Q⃗E=Q4πε0z(z2+R2)32̂k"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#45,45,46EsempioDeterminare il campo elettrostatico sull’asse di un disco di raggio R su cui è depositata uniformemente una carica Q⃗E=Qz2πε0R2[1|z|−1(z2+R2)12]̂k
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#46,46,"47EsempioDeterminare la differenza di potenziale elettrostatico tra due piani indefiniti paralleli, posti a distanza d, su cui è depositata uniformemente una densità superficiale di carica uguale ed opposta
  +𝜎-𝜎d"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#47,47,"48Esempio1.7Una sottile barra di plastica ha una densit` a lineare di carica positiva uniforme. La barra ` e curvata a formadi semicerchio di raggioR. Determinare:a) il potenziale elettrostatico nel centroOdel semicerchio (V= 4✏0);b) il campo elettrostatico nel puntoO(~E=  2⇡✏0Rˆ|)1.8Calcolare il campo elettrostatico nei punti dell’assexdi un anello di raggioRuniformemente carico concaricaQ. Descrivere il moto di una caricaq(opposta aQ) e massamche si trova inizialmente ferma inun punto dell’asse vicino al centro dell’anello. (R:~E=Q4⇡✏0x(x2+R2)32ˆı, oscillatore armonico con pulsazione!=qqQ4⇡✏0mR3)1.9Calcolare il campo elettrico lungo l’assexdi un disco di raggioRcaricato uniformemente con densit` a dicarica .( R :~E= x2✏0[1|x| (x2+R2) 12])1.10Sia dato un guscio sferico di raggioRe di spessore trascurabile su cui ` e distribuita uniformemente una caricatotaleQ. Calcolare il campo elettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardalcentro del sistema.1.11Sia data una sfera di raggioRin cui ` e distribuita uniformemente una carica totaleQ. Calcolare il campoelettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardal centro della sfera.1.12Sia data una sfera di raggioRnel cui volume presente una carica distribuita con densit` a di volume⇢(r)=kr,conkcostante. Calcolare:a) la carica totaleQdella sfera (R:Q=⇡kR4);b) il campo elettrostatico in tutto lo spazio, in funzione della distanzardal centro della sfera (R:~E(r<R)=kr24""0ˆr,~E(r>R)=kR44""0r2ˆr);c) il potenziale elettrostatico in un generico punto interno della sfera a distanzardal centro (R:V(r)=k12""0(4R3 r3)).1.13Sia data un cilindro di raggioRe altezza indeﬁnita in cui ` e distribuita uniformemente una carica con densit` avolumetrica di carica⇢. Calcolare:a) il campo elettrostatico in tutto lo spazio, in funzione della distanzardall’asse del cilindro;b) il potenziale elettrostatico in tutto lo spazio, imponendo che il potenziale sia nullo sulla superﬁcie delcilindro.1.14Si consideri un volume sferico di raggioRin cui ` e presente una caricaQdistribuita con densit` a⇢(r)dipendente dalla distanza radialerdal centro della sfera. Sapendo che il campo elettrico all’interno dellasfera ha modulo costante ed ` e diretto radialmente, determinare l’espressione della densit` a di carica⇢(r). (R:⇢=Q2⇡R2r)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#48,48,"49Il lavoro della forza elettrostaticaSe il campo elettrostatico è conservativo ⇒ la forza elettrostatica è conservativaℒel=∫BA⃗Fel⋅d⃗l=∫BAq⃗E⋅d⃗l=q∫BA⃗E⋅d⃗l=q(VA−VB)=qΔVAB⃗Fel=q⃗EIl lavoro fatto dalla forza elettrostatica per spostare una carica q dalla posizione A alla posizione BLa forza elettrostatica (di Coulomb) è proporzionale al campo elettrico
Dato che la forza elettrostatica è conservativa, il lavoro non dipende dal percorso"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#49,49,50L’energia elettrostaticaPossiamo definire l’energia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale VUE=qVLa variazione di energia potenziale corrisponde alla variazione di energia cinetica Tin+Uin=Tfin+Ufin⇒ΔT=−ΔUEU si misura in Joule (J) In Fisica delle Particelle si usa l’elettronvolt: (energia cinetica di una carica elementare accelerata da un V olt) 1eV = qe𝛥V =(1.6×10-19 C)×(1V)=1.6×10-19 J Forza elettrostatica conservativa ⇒ energia meccanica totale (cinetica+potenziale) si conserva        ℰ=T+UE
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#5,5,6Lo strofinio produce uno spostamento di elettroni da un materiale all’altro.  Sfregando tra di loro i due materiali: •il più alto nella lista si carica ⊕ (cede elettroni) •il più basso nella lista si carica ⊝ (acquista elettroni)Serie triboelettricacuoio vetro capelli lana seta alluminio carta legno ambra gomma argento oro plastica PVC silicone teflonperché sono gli elettroni a spostarsi e non i protoni?
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#50,50,"51Moto di una carica in un campo elettrostatico Un oggetto di massa m e carica q posto in un campo elettrostatico è soggetto alla forza elettrostatica⃗F=q⃗E=m⃗a⃗a=d2⃗rdt2=qm⃗ENote le condizioni iniziali possiamo determinare le equazioni del moto Dato che il campo elettrostatico è conservativo, si può utilizzare anche la conservazione dell’energiaΔT=−ΔUe"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#51,51,"52Esempio: moto carica in campo costante
+𝜎Campo piano indefinitoDeterminare la velocità di una particella di massa m e carica q(+), inizialmente ferma (vA=0) su un piano uniformemente carico positivamente, dopo che ha percorso una distanza D
ABa=qmE=qmσ2ε0costante, moto uniformemente acceleratovB=vA+atxB=xA+vAt+12at2v2B−v2A=2a(xB−xA)vB=qmσε0DTB−TA=UA−UBTB=12mv2BTA=0UA−UB=q(VA−VB)=q∫BA⃗E⋅d⃗l==q∫BAσ2ε0dx=qσ2ε0(xB−xA)=qσ2ε0D12mv2B=qσ2ε0Dv2B=2qmσ2ε0DDin alternativa (conservazione energia)⃗E=σ2ε0̂ıx"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#52,52,"53Esempio: deflessione in doppio strato-𝜎+𝜎
xy
m, q+⃗v0=v0x̂ı⃗E=σε0̂𝚥
𝛼Calcolare l’angolo di deflessione di una particella di massa m e carica q che attraversa con velocità iniziale v0x un doppio strato di lunghezza LL"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#53,53,"54EsempioTre particelle identiche, aventi massa m e carica q,  sono poste ai vertici di un triangolo equilatero di lato L. Inizialmente le cariche sono ferme. Ad un certo istante una delle tre cariche viene lasciata libera. Determinare la velocità che la carica acquista dopo aver percorso una distanza L (risolvere per m=2 kg, q=5𝜇C, L=3m)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#54,54,"55Integrale di superficie una funzione vettorialeSiano date in ℝ3 una funzione vettoriale e una superficie S ⃗F(x,y,z)
nel limite N→∞ e 𝛥Si→0 , definiamo l’integrale di superficie di una funzione vettoriale
S𝛥SîniPi⃗F(Pi)αîniSuddividiamo S in N superfici infinitesime 𝛥Si e consideriamo su di esse i punti Pi(xi,yi,zi), i corrispondenti versori      normali a 𝛥Si  N∑i=1⃗F(Pi)⋅̂niΔSi=N∑i=1F(Pi)cosαiΔSi∬S⃗F⋅̂ndSconsideriamo  la somma ⃗F(x,y,z)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#55,55,"56Flusso di un campo vettorialeIl concetto di flusso viene introdotto nello studio della dinamica dei fluidi Consideriamo un tubo (di sezione infinitesima) attraversato da un fluido incompressibile (es H20) con velocità     d⃗S=̂ndS⃗vIl flusso del fluido attraverso una sezione dS del tubo è definito:dΦ=⃗v⋅̂ndSNotazione alternativa:dΦ=⃗v⋅d⃗Srisolvendo il prodotto scalare:
̂n⃗vαdSd𝛴sezione trasversa d𝛴=dS cos𝛼dΦ=vdScosα=vdΣ"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#56,56,"57Flusso di un campo vettorialeConsiderando più tubi (di flusso) su una generica superficie S 
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso del campo vettoriale     attraverso la superficie S⃗vΦs(⃗v)=∬S⃗v⋅̂ndS"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#57,57,"58Linee di flusso di un campo vettoriale
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnConsideriamo la traiettoria 𝛾 di una particella del fluido  ➡  in ogni punto la traiettoria è tangente alla velocità vettoriale della particella La linea di flusso 𝛾 è una linea sempre tangente al vettore velocità delle particelle che si trovano nei punti della linea"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#58,58,"59Linee di flusso del campo elettricoAnche per il campo elettrico possiamo rappresentare graficamente le linee di flusso (o linee di campo) • tangenti in ogni punto al vettore campo elettrico • orientate con il verso del campo elettrico • in numero (per unità di superficie trasversale), proporzionali al modulo del campo elettrico 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#59,59,"Classificazione delle superfici • aperta: compatta e con bordo • chiusa: compatta e priva di bordo • orientabile: ha due facce
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnAperta e orientabile
Sfera: chiusa e orientabileToroide: chiusa e orientabileNastro di Möbius: aperta e non orientabileBottiglia  di Klein: chiusa e  non-orientabile60Superfici in ℝ3"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#6,6,"7Isolanti e conduttoriisolanti  •la carica elettrica resta localizzata  •vetro, plastica, gomma conduttori  •cariche libere di muoversi •metalli warning: classificazione un po’ riduttiva (liquidi, semiconduttori,…)                  nota: inizieremo con esempi di materiali isolanti, i conduttori saranno trattati in seguito"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#60,60,"61Superfici chiuse e orientabili in ℝ3Nelle superfici chiuse e orientabili, in ogni punto della superficie  possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi si utilizza la normale esterna   :  positivo il flusso uscente dal volume delimitato dalla superficie chiusa negativo il flusso entrante nel volume delimitato dalla superficie chiusân
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#61,61,"Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('62Superfici aperte e orientabili in ℝ3Nelle superfici aperte non possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi attraverso una superficie aperta si utilizza l’orientamento    indicato dalla regola della mano destra sulla base dell’orientamento della linea del bordo:̂n"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#62,62,"63L’angolo solidorl𝛼Angolo piano rapporto tra arco di circonferenza l e raggio r
r𝛺𝛴Angolo solido rapporto tra la parte di superficie sferica 𝛴 intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera α=lr∈[0,2π[L’angolo solido si misura in steradianti (sr)Ω=Σr2∈[0,4π]dα=dlrinfinitesimoinfinitesimodΩ=dΣr2"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#63,63,64Il flusso del campo elettricod𝛴̂nαdS⃗Eprendendo la superficie d𝛴 ortogonale al campo elettrico:Flusso infinitesimo del campo elettrico attraverso una superficie dSdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso del campo elettrico attraverso una superficie estesa SΦS(⃗E)=∬S⃗E⋅̂ndS=∬SEcosαdS=∬SEdΣdΣ=dScosα
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#64,64,"65Il flusso del campo elettricoConsideriamo ora una superficie chiusa contenente al suo interno una carica elettrica puntiforme q̂n
d𝛴dSqdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso attraverso l’intera superficie S  (             ):∬SdΩ=4πil flusso dipende solo dall’angolo solido perché E è radialeΦS(⃗E)=∬S⃗E⋅̂ndS=qε0Notazione per integrale su superficie chiusaFlusso infinitesimo attraverso un elemento dS:α
ΦS(⃗E)=∬SdΦS=∬S⃗E⋅̂ndS=q4πε0∬SdΩ=qε0=(q4πε0r2)(r2dΩ)=q4πε0dΩ⃗E"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#65,65,"66Il flusso del campo elettrico
d𝛴2d𝛴1
r1r2dΩ=dΣ1r21=dΣ2r22Se q è esterna alla superficie chiusa, il numero di linee di campo che entrano nella superficie è uguale al numero di linee di campo che escono dalla superficie
d𝛴2dS2q
d𝛴1dS1̂n1̂n2α1α2⃗E1⋅̂n1=cosα1<0⃗E2⋅̂n2=cosα2>0
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(−r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)=⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0Flusso attraverso l’intera superficie:Flusso infinitesimo:=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0ΦS(⃗E)=∬S⃗E⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#66,66,"67Il flusso del campo elettricoSe all’interno della superficie chiusa ci sono N cariche qi puntiformi, per il principio di sovrapposizione del campo elettrico, il flusso vale: dove QS è la carica contenuta all’interno della superficie S q3q2q5q7q6q1q8q4qN×××S𝜏(S)QS=∑iqintQS=∭τ(S)ρdτΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Cariche discrete Cariche distribuite su continuo V olume 𝜏(S) contenuto in superficie S "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#67,67,68La Legge di Gauss del campo elettricoIl flusso del campo elettrico attraverso una superficie chiusa S è uguale al rapporto tra la carica elettrica QS contenuta all’interno della superficie e la costante dielettrica ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#68,68,69EsempiDeterminare il campo elettrico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 (usando la legge di Gauss) 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#69,69,70EsempiDeterminare il campo elettrico generato da un piano indefinito su cui è depositata uniformemente una carica con densità superficiale 𝜎 (usando la legge di Gauss)
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#7,7,"8Elettrizzazione per induzione (elettrostatica)
Elettroscopio a foglieAvvicinando un corpo carico all’elettroscopio, le foglie metalliche (conduttori) si allontanano Le componenti metalliche “sentono"" la vicinanza di carica elettrica L’effetto svanisce quando si allontana la carica"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#70,70,71EsempiDeterminare il campo elettrico ed il potenziale generato da un guscio sferico di raggio R su cui è depositata uniformemente una carica Q
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#71,71,72EsempioSia data una sfera di raggio R contenente una carica Q distribuita uniformemente. a) Determinare il campo elettrostatico in tutto lo spazio b) Calcolare il potenziale in un generico punto  esterno alla sfera (assumendo nullo il potenziale all’infinito) c) Calcolare il potenziale in un generico punto  interno alla sfera (assumendo nullo il potenziale all’infinito) d) Calcolare la differenza di potenziale tra il centro e la superficie della sfera
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#72,72,"73La divergenza di un campo vettoriale
Consideriamo il flusso di un campo  vettoriale     attraverso una superficie chiusa S che delimita un volume 𝜏⃗FΦS(⃗F)=∬S⃗F⋅̂ndSDividiamo idealmente il volume 𝜏  in due volumi 𝜏1 e 𝜏2, usando una superficie di separazione D (diaframma). Siano S1 e S2 le superfici chiuse che delimitano 𝜏1 e 𝜏2 (D⊂S1,S2)𝜏SD𝜏2𝜏1S1S2Possiamo riscrivere il flussoΦS(⃗F)=∬S1⃗F⋅̂ndS1+∬S2⃗F⋅̂ndS2̂n2̂n1i contributi al flusso attraverso D si annullano⃗F⋅̂n1D=−⃗F⋅̂n2D"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#73,73,"74La divergenza di un campo vettorialeSuddividendo il volume 𝜏 in N volumi 𝜏i , limitatati da altrettante superfici SiDefinizione di divergenza di un campo vettorialediv⃗F=limτi→0ΦSi(⃗F)τiΦSi(⃗F)=∬Si⃗F⋅̂nidSiΦS(⃗F)=N∑i=1ΦSi(⃗F)La divergenza è il flusso uscente per unità di volume  • è una grandezza scalare, funzione delle coordinate • può variare da punto a punto𝜏iSi⃗FS𝜏⃗∇=(∂∂x,∂∂y,∂∂z)=∂∂x̂ı+∂∂ŷ𝚥+∂∂ẑkdiv⃗F=⃗∇⋅⃗FUtilizzando l’operatore “nabla”:"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#74,74,"75Il teorema della divergenzaIl flusso di un campo vettoriale attraverso una superficie S chiusa è pari all’integrale sul volume 𝜏 (delimitato da S !!!) della divergenza di tale campo vettoriale ∬S⃗F⋅̂ndS=∭τdiv⃗Fdτ=N∑i=1τi∬Si⃗F⋅̂nidSiτiNel limite N →∞ e 𝜏i →d𝜏, sostituiamo 𝛴→∫∫∫ ⟶∭τdiv⃗FdτΦS(⃗F)=∬S⃗F⋅̂ndS=N∑i=1∬Si⃗F⋅̂nidSiIl teorema della divergenza è una relazione tra un integrale di superficie e un integrale di volume"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#75,75,"76La legge di Gauss in forma localeCombiniamo il teorema della divergenza e la legge di Gauss, in presenza di una distribuzione continua di carica∭τ(S)div⃗Edτ=∭τ(S)ρε0dτdiv⃗E=ρε0∬S⃗E⋅̂ndS=∭τ(S)div⃗Edτ∬S⃗E⋅̂ndS=∭τ(S)ρε0dτLegge di GaussTeorema della divergenzaGli integrali sono sullo stesso volume"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#76,76,"77Significato fisico della divergenzaLa divergenza di un campo ci da un’informazione sul comportamento locale delle linee di campo le linee di campo si incontrano nei punti in cui la divergenza del campo è diversa da zero: • convergono nel punto se il valore della divergenza è negativo • divergono dal punto se il valore della divergenza è positivo In un punto in cui la divergenza è nulla, le linee di campo non si incontrano Se un campo ha divergenza sempre nulla, allora esso si definisce solenoidale"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#77,77,"78Significato fisico della divergenzadiv⃗E=ρε0Il campo elettrico ha divergenza non nulla solo nei punti in cui esiste una densità di carica Nel vuoto, la divergenza del campo elettrico è nulla 
z
y
x⃗r⃗r′ In tali punti, le linee di campo si incontranodiv⃗E(⃗r′ )=ρ(⃗r′ )ε0div⃗E(⃗r)=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#78,78,"79Potenziale e legge di GaussLegge di Gauss in forma locale⃗∇⋅⃗E=ρε0⃗E=−⃗∇V⃗∇⋅(−⃗∇V)=ρε0∇2V=−ρε0Campo elettrostaticoEquazione di Poisson
Il laplaciano del potenziale è proporzionale alla densità di carica Equazione alle derivate seconde, note le condizioni al contorno ammette un’unica soluzione∂2V∂x2+∂2V∂y2+∂2V∂z2=−ρε0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#79,79,80EsempioCalcolare la divergenza del campo e il flusso attraverso una superficie sferica di raggio R centrata nell’origine ⃗F=k⃗r
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#8,8,"9Elettrizzazione per induzione (elettrostatica)
Elettrizzazione per induzione anche su materiali isolanti
Microscopicamente, le molecole della carta “risentono” la vicinanza di cariche elettriche "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#80,80,"81Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#9,9,"10Elettrizzazione per contatto
In caso di contatto, parte della carica si trasferisce (e resta) sul conduttoreCaso particolare: due conduttori di stessa forma e dimensione; inizialmente A ha una carica Q+Dopo aver messo in contatto A e B, la carica si ridistribuisce in parti ugualiAB++++++++++++++++Q+
AB++++++++12Q+12Q+++++++++
Carica totale si conserva!"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#0,0, Elettrostatica dei conduttori CdS Ingegneria Informatica A.A. 2019/20
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#1,1,"2Materiali isolanti e conduttoriisolanti  •le carica elettrica restano localizzate, sono vincolate a muoversi all’interno delle molecole •Un campo elettrico esterno non produce movimento di cariche, se non su piccolissima scala: deformazione e orientamento delle molecole (azioni sui dipoli) conduttori  •cariche (elettroni di conduzione) libere di muoversi sul conduttore (moto su reticolo cristallino) •comportamento degli elettroni simile ad un gas •in presenza di un campo esterno o di un eccesso di carica, le cariche si redistribuiscono sul conduttore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#10,10,"11Campo elettrico in prossimità della superficie dei conduttori
In presenza di un conduttore, le linee di campo esterne vengono deviate dalla presenza di addensamenti locali di carica sulla superficie del conduttoreVicino al conduttore le linee di campo esterne saranno sempre perpendicolari alla superficie"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#11,11,12Campo elettrico in prossimità della superficie dei conduttori⃗E=ÊnCalcoliamo il flusso attraverso un cilindretto di dimensioni infinitesime • asse ortogonale a superficie conduttore • contributo al flusso solo da base esterna⃗E=0dΦ(E)=⃗E⋅̂ndS=EdSFlusso attraverso base infinitesimaCarica contenuta nel cilindro (intersezione con la superficie del conduttore)dQS=σdSapplicando la legge di GaussEdS=σε0dSE=σε0
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#12,12,"13Teorema di Coulomb⃗E=σε0̂nIl campo elettrostatico in prossimità dei conduttori è sempre ortogonale alla superficie del conduttore ed il modulo è proporzionale alla densità superficiale di carica La densità superficiale di carica 𝜎=𝜎(x,y,z) può variare sulla superficie, di conseguenza varierà anche l’intensità del campo elettrico Il campo elettrico subisce una discontinuità nel passaggio dall’esterno all’interno del conduttore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#13,13,"14Conduttori caviSulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
S⃗E=0ΦS(⃗E)=QSε0=0La prima affermazione si dimostra applicando la legge di Gauss, utilizzando la condizione che il campo elettrico interno al conduttore è nullo"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#14,14,"15Conduttori cavi
-+++++----⃗E≠0⃗E=0𝛤Ipotesi (per assurdo): distribuzioni locali di carica sulla superficie interna⇒ campo all’interno della cavità non nullo ⇒ circuitazione lungo linea chiusa 𝛤 non-nulla⇒ violazione della conservatività del campo elettrostatico Sulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#15,15,"16Schermo elettrostatico
  Se un conduttore dotato di cavità viene esposto a un campo elettrico esterno, il campo elettrico all’interno della cavità è comunque nullo e non vi sono cariche elettriche indotte sulla superficie della cavità stessa.    In altre parole il conduttore scherma l’interno della cavità dai campi elettrici all’esterno (gabbia di Faraday)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#16,16,"17Induzione completa
+QQ’’=+Q+++
++++
+Q’=-Q--------⃗E≠0Poniamo una carica puntiforme all’interno della cavità di un conduttore neutroLa carica genera un campo con linee radiali che poi curvano per diventare perpendicolari alla superficie interna induzione completa: tutte le linee di forza si chiudono sul conduttore Sulla superficie interna si induce una carica Q’ complessivamente uguale e opposta a +QSGauss è salvo: Q+Q’=0Conduttore neutro ⇒ carica Q’’=+Q indotta sulla superficie esterna⃗E=0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#17,17,"18Induzione completa
+QQ’’=+QQ’=-Q+++++++++++
++++
+--------⃗E≠0Poniamo all’interno della cavità una generica carica (anche su un conduttore)  Un conduttore cavo trasferisce sulla propria superficie esterna una carica uguale al valore complessivo delle cariche contenute all’interno della cavità.  "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#18,18,"BB
19Potenziale elettrostatico nei conduttoriADifferenza di potenziale tra due punti del conduttoreVA−VB=∫BA⃗E⋅d⃗l=0⃗E=0A⃗E⊥d⃗l⇒VA=VB∀A,B
Tutti i punti del conduttore sono equipotenziali  (la differenza di potenziale tra due qualsiasi punti del conduttore è sempre nulla)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#19,19,"20Potenziale di un conduttore sfericoUn conduttore carico (con carica Q), di forma sferica di raggio R è equivalente ad un guscio sferico uniformemente caricoCampo elettrico (calcolato con legge di Gauss):⃗E(r<R)=0⃗E(r>R)=14πε0Qr2̂urPer simmetria, la densità superficiale di carica deve essere uniforme (altrimenti avrei campi elettrici tangenti)
RQ"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#2,2,3Premesse~F=m~a•Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra i conduttori e le eventuali cariche esterne •Lavoriamo con conduttori solidi (es. metalli) •Poniamoci in condizioni di ELETTROSTATICA
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#20,20,21Potenziale di un conduttore sfericoCalcolo del potenziale in un generico punto a distanza r dal centro della sfera (assumendo V∞=0)V(r)=V(r)−V(∞)=∫∞r⃗E⋅d⃗rEsternamente (come carica puntiforme)V(r>R)=∫∞r⃗E⋅d⃗r=∫∞r14πε0Qr2dr=Q4πε0[−1r]∞r=14πε0QrV(r<R)=∫∞r⃗E⋅d⃗r=∫Rr⃗E(r<R)⋅d⃗l+∫∞R⃗E(r≥R)⋅d⃗l=InternamenteE(r)rRV(r)rRDiscontinuità del campo⃗E(r>R)=14πε0Qr2̂urCostante!=0+∫∞RQ4πε01r2dr=Q4πε0[−1r]∞R=Q4πε01R
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#21,21,"22Esempio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)= 2xˆı z2ˆ| ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı zˆ| ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R: =4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵""0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10 6C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale 2sulla superﬁcie interna del guscio sferico (R: 2 Q14⇡r22= 8·10 6C/m);b) la di↵erenza di potenziale tra i due conduttori. (R: V=Q14⇡""0r2 r1r1r2= 15kV)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#22,22,"23Esempio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1=Q2=12µC, Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ)."
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#23,23,"24Ridistribuzione delle caricheQ0
R1Siano date due sfere conduttrici di raggi R1 e R2 con R1 > R2 Inizialmente sulla prima sfera c’è una carica Q0, la seconda sfera è scarica Le sfere sono poste a distanza tale da poter trascurare effetti di induzione elettrostatica
Successivamente le sfere vengono connesse con un sottile cavo conduttore. Come si ridistribuisce la carica? 
R2"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#24,24,"25Ridistribuzione delle cariche
R1
R2Dobbiamo calcolare le cariche finali sulle due sfere: Q1 e Q2Per la conservazione della carica (il sistema è isolato): Q1 + Q2 =Q0Le due sfere unite formano un unico conduttore  ⇒ equipotenziale V1 = V2 Q1Q2V1=14πε0Q1R1V2=14πε0Q2R214πε0Q1R1=14πε0Q2R2Q1R2=Q2R1Q1R1=Q2R2"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#25,25,"26Ridistribuzione delle cariche
R1
R2Q1Q2Risolvendo il sistema: {Q1+Q2=Q0Q1R2=Q2R1{Q2=Q0−Q1Q1R2=(Q0−Q1)R1{Q2=Q0−Q1Q1(R1+R2)=Q0R1Q1=R1R1+R2Q0Q2=R2R1+R2Q0La carica si redistribuisce proporzionalmente al raggioCaso particolare R1 = R2 Q1=Q2=Q02"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#26,26,"27Potere delle punte
R1
R2Q1Q2Cosa succede alle densità di carica (e ai campi elettrici delle sfere?)σ1=Q14πR21σ2=Q24πR22Q1=σ14πR21Q2=σ24πR22V1 = V2  ⇒Q1R1=Q2R2σ14πε0R21R1=σ14πε0R22R2σ1R1=σ2R2La densità superficiale di carica è maggiore sulla sfera più piccolaσ1=(R2R1)σ2⟶R1>R2σ2>σ1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#27,27,"28Potere delle punteConsideriamo un conduttore di una forma generica, con raggio di curvatura che varia da punto a punto della superficie.⃗E=σε0̂nIn vicinanza delle punte il campo elettrico                 può essere molto intenso La densità di cariche è inversamente proporzionale al raggio di curvatura 
maggiore addensamento di carica sulle punte
+ + + + + + + + + + + + + + ++++++++++++++++"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#28,28,"29Potere delle punte
In vicinanza delle punte dei conduttori le densità di carica elettrostatica ed i campi elettrostatici possono essere molto intensi Campi molto intensi possono causare l’espulsione di cariche dal conduttoreLe cariche espulse subiscono forti accelerazioni, guadagnando energia cineticaInteragendo con l’aria, provocano un riscaldamento del mezzo per cui si osservano “scintille”"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#29,29,"30Collegamento a terra
R1
R2Q0Poniamoci nella condizione limite: R1 ≫ R2 Inizialmente carica Q0 sul conduttore piccolo.Q1=R1R1+R2Q0⟶R1≫R2Q0Q2=R2R1+R2Q0⟶R1≫R20La carica fluisce interamente sul conduttore più grandeLa Terra può essere considerata come un enorme conduttore, da cui si capisce il significato di collegamento a terra (o messa a terra, ground)VT=Q4πε0RT⟶RT≈6400km0Collegando i due conduttori:In elettrotecnica si utilizza il potenziale di terra come valore di riferimento del potenzialeSimbolo  messa a terra"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#3,3,"4Conduttori in presenza di carica esterna
+++++++
+++++++
Conduttorebacchetta caricaoscilloscopio a foglieL’oscilloscopio misura la presenza di caricaL’oscilloscopio misura una maggiore presenza di caricaInduzione elettrostatica (spostamento di cariche sul conduttore)+++++++-------"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#30,30,"31Massa e messa a terra
TerraIn elettrotecnica la massa (chassis) è la scatola metallica di un’apparecchiatura elettrica Si comporta come una gabbia di Faraday La massa è utilizzata per assegnare il potenziale di riferimento comune delle componenti elettriche
massaguasto delle componenti elettriche ⇒ eccesso di cariche sulla massa (pericolo!)Collegando la massa a terra, si scaricano pericolosi eccessi di caricacomponenti  elettrici/elettronici"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#31,31,"32Capacità di un conduttoreIl potenziale di un conduttore isolato è proporzionale alla carica presente sul conduttoreC=QVDefiniamo la capacità di un conduttoreNel S.I. la capacità si misura in Farad (F):  1F=1C/1VLa capacità quantifica l’attitudine di un conduttore ad accumulare carica ad un dato potenziale  La capacità dipende solo dalla forma e dalle dimensioni del conduttore e dal mezzo che lo circonda (nel nostro caso il vuoto, per ora)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#32,32,"33Capacità di un conduttore sferico
RQConsideriamo una sfera conduttrice di raggio R con carica QC=QV=QQ4πε0R=4πε0RLa capacità dipende solamente da fattori geometriciEsempiCapacità di una sfera di raggio R=1m nel vuoto: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++Capacità della Terra R=6400 km: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#33,33,"34CondensatoriIl condensatore è un sistema formato da due conduttori carichi per i quali si verifica induzione completa (tutte le linee di forza uscenti da un conduttore incontrano l’altro conduttore) I due conduttori sono le armature del condensatore Lo spazio interposto tra le armature è l’intercapedineLa capacità del condensatore è definita come rapporto tra la carica (presente con segno opposto sui due conduttori) e la differenza di potenziale tra i due conduttoriC=QΔV
+Q-Q++++++++++++____________La capacità di un condensatore dipende solo dalla geometria, dalla forma e dal materiale interposto tra i conduttoriSimbolo  condensatore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#34,34,"35Capacità di un condensatore pianoIl condensatore piano (condensatore a facce piane e parallele) è costituito da due armature piane di superficie S poste parallelamente a piccola distanza d (d≪S, trascuriamo effetti di bordo)
SdSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QIl sistema è equivalente al doppio strato⃗E={σε0̂n=QS1ε0interno0esternoCapacità:C=QΔV=QQdε0S=ε0Sd• proporzionale alla superficie delle armature • inversamente proporzionale alla distanza tra le armatureΔV=∫d0Edz=Ed=QdSε0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#35,35,"36Capacità di un condensatore sferico
R1+Q-QR2Un condensatore sferico è costituito da una sfera conduttrice di raggio R1 racchiusa all’interno di una cavità sferica di raggio R2 di un conduttore sfericoΔV=V1−V2=∫R2R1⃗E⋅d⃗r=Q4πε0∫R2R1drr2=Q4πε0[−1r]R2R1=Q4πε0(1R1−1R2)Differenza di potenziale tra le armatureCapacità del condensatore sfericoC=QΔV=QQ4πε0(1R1−1R2)=4πε0(R1R2R2−R1)Nel limite R1→ R2, definendo d=R2-R1 C=4πε0(R1R2R2−R1)⟶R1→R24πε0R2d=ε0Sdcapacità del condensatore piano"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#36,36,"37Capacità di un condensatore cilindricoUn condensatore cilindrico è costituito da un cilindro conduttore di raggio R1 racchiuso all’interno di una cavità cilindrica di raggio R2 di un conduttore cilindrico (nell’approssimazione R1,R2≪h , trascurando eff. bordo)⃗E=Q2πε0hr̂rCampo elettrico internoR2R1hΔV=∫R2R1Edr=∫R2R1Qdr2πε0hr=Q2πε0hlnR2R1Differenza di potenziale tra le armatureC=QQ2πε0hlnR2R1=2πε0hlnR2R1CapacitàNel limite R1→ R2, definendo d=R2-R1 lnR2R1=lnR1+R2−R1R1=ln(1+R2−R1R1)=ln(1+dR1)≅dRC=2πε0hdR=ε02πRhd=ε0Sdcapacità del condensatore piano"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#37,37,"38Sistemi di condensatori in paralleloI condensatori sono dispositivi dipolari  (hanno due capi di connessione)Connessione in parallelo (gli elementi circuitali sono alla stessa differenza di potenziale 𝛥V1=𝛥V2=VA-VB=𝛥VAB): Q1=C1𝛥V1=C1𝛥VAB Q2=C2𝛥V2=C2𝛥VABQTOT=Q1+Q2=(C1+C2)𝛥VAB=CTOT𝛥VABCTOT=C1+C2   
la capacità del sistema formato da due (o più) condensatori collegati in parallelo è uguale alla somma delle singole capacitàCTOT=∑CiC1C2+Q2-Q1VAVB-Q2+Q1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#38,38,"39Sistemi di condensatori in serieConnessione in serie (gli elementi circuitali sono collegati con un solo polo in comune)Conduttore isolato e neutro -Q1+Q2=0 ⇒  Q1=Q2 I condensatori in serie hanno la stessa caricaC1C2+Q2+Q1VAVB-Q1-Q2VM=QC1+QC2=Q(1C1+1C2)=QCTOTVA−VB=(VA−VM)+(VM−VB)=1CTOT=1C1+1C2CTOT=C1C2C1+C21CTOT=∑1Ci
L’inverso della capacità del sistema formato da due o più condensatori collegati in serie è uguale alla somma degli inversi delle singole capacità "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#39,39,"40Esempio
serie o parallelo?"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#4,4,"5Conduttori in presenza di carica esterna
+++++++In presenza di un campo elettrostatico esterno le cariche del conduttore si spostano fino a raggiungere una nuova condizione di equilibrio (𝛥t∼10-9 s)Equilibrio ⇒ cariche ferme ⇒ forza nulla ⇒ campo elettrico complessivamente nulloLe cariche del  conduttore si dispongono in maniera tale da generare un campo interno      (indotto) che annulla il campo esterno⃗E⃗E⃗E′ Il campo elettrico interno ai conduttori è sempre nullo
+++++++-------⃗E′ ⃗E⃗Econd=⃗E+⃗E′ =0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#40,40,"41Esercizio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0a3(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ).2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0a3(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ)."
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#41,41,"42Energia elettrostatica di un sistema di caricheEnergia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale V:  U=qV  Rappresenta il lavoro che bisogna fare sulla carica q per portarla dall’infinito al punto in cui il potenziale vale Vq1Per portare la prima carica nella posizione finale, non occorre fare lavoroPer portare la seconda carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q2⃗E1⋅d⃗l⃗r12q2=q2∫⃗E1⋅d⃗l=q2V1(r12)=q2q14πε0r12U12=q1q24πε0r12=U21Energia del sistema di due cariche:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#42,42,"43Energia elettrostatica di un sistema di caricheq1Per portare una terza carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q3⃗Etot⋅d⃗l=q3∫(⃗E1+⃗E2)⋅d⃗l⃗r12q2=q3[∫⃗E1⋅d⃗l+∫⃗E2⋅d⃗l]=q3[V1(r13)+V2(r23)]=⃗r13⃗r23q3=q3V1(r13)+q3V2(r23)=q3q14πε0r13+q3q24πε0r23U13=U31=q1q34πε0r13U23=U32=q2q34πε0r23UE=U12+U13+U23Energia elettrostatica del sistema di 3 cariche:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#43,43,44Energia elettrostatica di un sistema di caricheUij=qiqj4πε0rijUE=12(U12+U21+U13+U31+U23+U32)Energia elettrostatica del sistema di 3 cariche:Utilizzando una notazione compatta:Vi=3∑j=1j≠iqj4πε0rijUE=123∑i=1qiVi=123∑i=1qi3∑j=1j≠iqj4πε0rij
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#44,44,45Energia elettrostatica di un sistema di caricheL’energia elettrostatica totale di un sistema di N cariche puntiformi èqiqj⃗rijL’energia elettrostatica di un sistema è equivalente al lavoro necessario per portare le N cariche nella configurazione finale UE=12N∑i=1qiVi=12N∑i=1N∑j=1j≠iqiqj4πε0rij=N∑i=1N∑j>iqiqj4πε0rij
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#45,45,"46EsercizioEsercitazioni di Fisica Generale T2 - provvisorioLorenzo Rinaldi10/10/20171 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, determinare l’angolo✓che i due ﬁli formano con la verticale (risolvere nell’approssimazione✓⇡0 (R:✓=3qq216⇡✏0mgl2).1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏055+15p2+12p330=4.65J )1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema. (R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso. (Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1.6Sia data una sbarretta di lunghezza L e dimensioni trasversali trascurabili, disposta lungo il semiasse dellexpositive in un sistema di riferimento avente l’origine coincidente con uno degli estremi. Sulla barretta ` edepositata una carica Q con densit` a lineare =kx. Determinare in funzione diQed iL, l’espressione delpotenziale generato dalla barretta nel puntoP=( 2L,0,0). (V=Q2⇡✏0L(ln 4 1))1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#46,46,47Energia elettrostaticaNel caso in cui le cariche siano distribuite con una densità 𝜌 su un volume 𝜏UE=12∫τρVdτUtilizzando la legge di Gauss in forma locale: ρ=ε0⃗∇⋅⃗E⃗∇⋅(V⃗E)=V⃗∇⋅⃗E+⃗E⋅⃗∇VV⃗∇⋅⃗E=⃗∇⋅(V⃗E)−⃗E⋅⃗∇VUE=12∫τρVdτ=12∫τε0⃗∇⋅⃗EVdτUso le proprietà del prodotto scalareUE=ε02∫τ(⃗∇⋅(V⃗E)−⃗E⋅⃗∇V)dτUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#47,47,48Densità di energia del campo elettrico⃗∇V=−⃗EUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ∫div⃗Fdτ=∮⃗F⋅̂ndSUE=ε02∮SV⃗E⋅̂ndS+∫τ⃗E⋅⃗EdτGli integrali vanno calcolati su tutto lo spazio in  cui è presente il campo elettrico Il campo elettrico si estende e si annulla all’infinito se la carica 𝜌 è localizzataIl flusso all’infinito è nullo (E si annulla all’infinito) ⃗E⋅⃗E=E2uE=12ε0E2densità di energia del campo elettrostaticoUE=∫spazio12ε0E2dτUE=∫spaziouEdτ
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#48,48,"49Densità di energia del campo elettrico
uE=12ε0E2densità di energia del campo elettrostatico (quantità di energia per unità di volume) L’energia elettrostatica è localizzata nel campo elettrico (e non nella carica)UE=∫spazio12ε0E2dτUE=∫spaziouEdτUE=12∫τρVdτuE=dUEdτEspressioni dell’energia elettrostaticavolume in cui è contenuta la caricavolume in cui è presente il campo elettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#49,49,"50Energia di un condensatoreSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+q-qCondensatore (piano) carico con carica q+dqdℒ=dqΔVq=dqqCIl lavoro complessivo per caricare completamente il condensatore dalla carica 0 alla carica Q:ℒ=∫Q0dℒ=∫Q0dqqC=1C∫Q0qdq=12Q2CL’energia elettrostatica accumulata in un condensatore è Ue=12Q2C=12CΔV2=12QΔVIl lavoro (di una forza esterna) per portare una carica +dq dall’armatura di destra a quella di sinistra è:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#5,5,"6Elettrizzazione per contatto
++++++++++++++++In caso di contatto parte della carica sulla bacchetta si trasferisce al conduttoreLa carica resta sul conduttore dopo aver rimosso il contatto (misurabile con oscilloscopio)
+++++++++++++ConduttoreConduttore⃗Econd=0Nuova situazione di equilibrio ⇒"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#50,50,"51Energia di un condensatoreIn un condensatore piano la capacità vale: Sd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QC=ε0SdRiscriviamo l’energia: La differenza di potenziale tra le armature: ΔV=EdL’energia è pari alla densità di energia integrata su tutto lo spazio dove si estende il campo (il campo è nullo esternamente al condensatore)densità di energia elettrostaticavolume interno del condensatoreUE=12CΔV2=12ε0Sd(Ed)2=12ε0dSE2=(12ε0E2)(dS)=uEτ=∫τuEdτ"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#51,51,"52Energia del condensatore
Si può pensare di utilizzare un condensatore al posto di una batteria (chimica) ricaricabile? Svantaggi: •Ingombro. La densità di energia (energia per unità di volume) di un condensatore è enormemente minore di quella di una batteria. •Potenziale non costante. Mano mano che si scarica, la differenza di potenziale ai capi di un condensatore diminuisce (proporzionalmente alla carica).Vantaggi: •Velocità. Un condensatore si può caricare molto velocemente e può produrre intensità di corrente molto elevate scaricandosi (flash macchine fotografiche) •Durata. Una batteria si esaurisce dopo alcune migliaia di cicli di carica-scarica, mentre un condensatore ha una durata teoricamente illimitata.  •Basse temperature. Funzionano anche a -40° C, temperatura alla quale le normali batterie non sono in grado di operare. "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#52,52,"53Forza tra le armature di un condensatoreLe armature di un condensatore hanno cariche opposte: si attraggonoSx+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QUE=12Q2C=12Q2xε0Steniamo fissa un’armatura e applichiamo una forza esterna opposta a quella attrattiva, in modo tale che il lavoro della forza esterna bilanci la variazione di energia del condensatore⃗F⃗FestdUE=δℒest=FestdxdUE=12Q2dxε0S=δℒest=Festdxpossiamo definire la pressione elettrostatica:Per calcolare la forza tra le armature di un condensatore piano partiamo dall’energiaForza tra le armature ⃗F=−⃗Fest=−Q22ε0Ŝnp=FS=Q22ε0S2=σ22ε0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#53,53,"54EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p. V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21 V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3
C1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10 4J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a x=D/2. Calcolare il lavoro fatto dalla forza esterna.(R:L= 12Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=""0Sa b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e ilvuoto. Successivamente si introduce nel condensatore, parallelamente alle facce del condensatore, una lastra"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#54,54,"55EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p. V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21 V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3
C1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10 4J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a x=D/2. Calcolare il lavoro fatto dalle forze del campo elettrico.(R:L= 12Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=""0Sa b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e il"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#55,55,"56Condensatori con dielettriciCosa succede se riempiamo con un materiale isolante l’intercapedine di un condensatore?+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  ++𝜎-𝜎-𝜎P𝜎PNel dielettrico le cariche non si muovono.Però a livello microscopico le molecole (dipolari) possono orientarsiSulle superfici del dielettrico a contatto con le armature del condensatore si osserva un eccesso di carica 𝜎P (carica di polarizzazione)Le cariche di polarizzazione creano un campo elettrico opposto al campo del condensatoreIl campo elettrico totale (e di conseguenza la differenza di potenziale) diminuisce La capacità del condensatore aumenta⃗E0⃗E′ "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#56,56,"57Il dipolo elettrico
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!-+   Il dipolo elettrico è un sistema formato da 2 cariche elettriche in quiete, di uguale valore assoluto ma segno opposto (Q e –Q), poste a una distanza fissata d.  
x
z
y+Q-QdMolti materiali isolanti sono formati da molecole che hanno una struttura “dipolare”. 
Definiamo il momento di dipolo ⃗p=(Qd)̂k
"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#57,57,"58Azioni meccaniche su un dipolo elettricoCalcoliamo il momento della forza esercitato da un campo esterno su un dipolo
⃗M=⃗p∧⃗E
Dipolo Elettrico (IV) •!Si ha: 
•!Dunque il potenziale di un dipolo elettrico decresce con la distanza come 1/r2.      !pi!r=QdversP+!P!()i!r=Qdrcos!   V!r()""d#rQ4!""0dr2cos#=14!""01r2!pi!rr   V!r()""d#r14!""0!pi!rr3
9!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!
Dipolo Elettrico (V) •!Per calcolare il campo elettrico del dipolo scriviamo il potenziale in coordinate cartesiane e calcoliamo il gradiente:    Vx,y,z()!d""r14!""0xpx+ypy+zpzx2+y2+z2()32
   Exx,y,z()=!""V""x""d#r!14#$0""""xxpx+ypy+zpzx2+y2+z2()32==!14#$0pxx2+y2+z2()32!xpx+ypy+zpz()32x2+y2+z2()122xx2+y2+z2()3==14#$03xxpx+ypy+zpz()x2+y2+z2()52!pxx2+y2+z2()32%&'''()***=14#$03!pi!r()xr5!pxr3%&''()**10!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!
Dipolo Elettrico (VI) •!Ripetendo il calcolo per le componenti y e z si ottiene: •!Il campo elettrico di un dipolo elettrico decresce con la distanza come 1/r3:    !Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())
11!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!!Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())=14!""01r33!piˆr()ˆr#!p$%'(
Dipolo Elettrico (VII) •!Calcoliamo ora il momento della forza esercitato da un campo elettrico esterno su di un dipolo elettrico. •!Trattandosi di due forze di uguale modulo QE, medesima direzione e verso opposto, le cui rette di azione distano d sin !, si ha: 
Q!Qd– !pF!!F!!!Esind!+    !M=!p!!E   M=Fb=QE()dsin!()=Qd()Esin!()=pEsin!
12!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!M=FEdsinθ=(QE)dsinθ=(Qd)Esinθ=pEsinθLe due forze hanno stesso modulo QE, stessa direzione e verso opposto il momento delle forze (prendendo come polo una delle due cariche) è⃗M=⃗rd∧⃗FE"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#58,58,"59Elettrostatica dei dielettrici+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |⃗E0−  +⃗pOgni singolo atomo/molecola del dielettrico ha un momento di dipolo elettrico ⃗p(⃗p=q⃗d)Ogni dipolo sentirà un momento delle forze e tenderà ad allinearsi con il campo:⃗M=⃗p∧⃗E0Definiamo il momento di dipolo medio          (media di tutti i dipoli) ⟨⃗p⟩sia                 il numero di atomi/molecole per unità di volumen=NΔτSi definisce il vettore polarizzazione ⃗P=n⟨⃗p⟩[C/m2] come densità di carica • indica il grado di allineamento degli atomi/molecole in un dielettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#59,59,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L+𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
60Elettrostatica dei dielettrici|⃗P|=σpIl modulo del vettore polarizzazione è la densità di carica di polarizzazione⃗P=σp̂n⃗P=σp̂nIn un dielettrico isotropo e omogeneo le cariche di polarizzazione sono distribuite solo superficialmente (±𝜎P)Chiamiamo la carica libera (±𝜎L) quella sulle armature del condensatoreSi definisce il vettore spostamento elettrico⃗D=σL̂n⃗D=σL̂n"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#6,6,"7Carica interna al conduttore
SConsideriamo una generica superficie chiusa S interna al conduttore  ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Per la legge di GaussInternamente al conduttore il campo elettrico è nullo, quindi la carica interna ad S sarà sempre nullaQS=∭τ(S)ρdτ=0All’interno del conduttore non ci sono cariche in eccesso (cariche positive e negative hanno uguale densità)⃗E=0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#60,60,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
61Elettrostatica dei dielettriciIl campo all’interno del dielettrico⃗E=⃗E0+⃗EP⃗EP=−σPε0̂n⃗E0=σLε0̂n⃗D=ε0⃗E+⃗P=⃗Dε0−⃗Pε0=σL̂nε0−σP̂nε0In un dielettrico isotropo e omogeneo i vettori campo elettrico, polarizzazione e spostamento sono paralleliIn un dielettrico isotropo e omogeneo si definisco le due quantità adimensionali suscettività dielettrica 𝜒 (𝜒≥0) e la costante dielettrica relativa 𝜀R (𝜀R≥1), legati dalla relazione 𝜒=𝜀R-1Il campo elettrico ed il vettore polarizzazione sono legati dalla relazione⃗P=ε0χ⃗E=ε0(εR−1)⃗E"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#61,61,"62Elettrostatica dei dielettrici⃗P=ε0χ⃗E=ε0(εR−1)⃗E⃗D=ε0⃗E+⃗P⃗D=ε0⃗E+ε0(εR−1)⃗E=ε0εR⃗EUtilizzando il vettore spostamento elettrico, formuliamo la legge di Gauss (in forma locale e integrale) in funzione delle sole cariche libere 𝜌L e QL :⃗∇⋅⃗D=ρL∬⃗D⋅̂ndS=QLIn un dielettrico isotropo e omogeneo il vettore spostamento elettrico è proporzionale al campo elettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#62,62,"Capacità di un condensatore piano con dielettrico63Condensatori con dielettriciΔV=ΔV0εrC=QΔV=εrQΔV0=εrC0C=ε0εrSdSe riempiamo un condensatore con un dielettrico isotropo e omogeneo, il campo elettrico totale vale:
Capacità di un condensatore con dielettricoDi conseguenza, la differenza di potenziale tra le armature⃗E=⃗Dε0εR=σL̂nε01εR=⃗E0εRcampo elettrico con condensatore vuoto"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#63,63,64Costanti dielettriche relativematerialecostante dielettrica relativa 𝜀R Aria1.00059Acqua distillataca. 80Etanolo25Petrolio2.1Vetro comune5 ÷ 10Plexiglas3.40Mica8Ebanite2Paraffina2.1Glicerolo42.6Ossido di titanio90 ÷ 170Titanati di Ba-Sr1000 ÷ 10000
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#64,64,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
65"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#7,7,"8Carica superficiale di un conduttore La carica in eccesso (dovuto ad elettrizzazione per induzione o per contatto) si  dispone sulla superficie del conduttore Microscopicamente la carica occupa uno spessore di 10-10 m (dimensioni atomiche)Nei conduttori le cariche in eccesso si dispongono in superficie, in una configurazione tale che il campo elettrico interno al conduttore sia nullo
+++++++++++++++++++++++Conduttore elettrizzato
--++++++++++-----------Conduttore polarizzato per induzione elettrostatica100 pm"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#8,8,"9Campo elettrico in prossimità della superficie dei conduttoriIn equilibrio elettrostatico le cariche si dispongono in superficieIl campo generato da tali cariche non può avere componenti tangenti alla superficie, altrimenti si osserverebbero movimenti di cariche⃗EEnEt⃗F⃗E=Ên
Il campo elettrico è sempre normale alla superficie dei conduttori"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#9,9,"10Campo elettrico in prossimità della superficie dei conduttoriIl campo elettrico è sempre normale alla superficie dei conduttoriSi dimostra in maniera formale calcolando la circuitazione del campo lungo una linea chiusa 𝛤 che interseca la superficieIl campo è nullo all’interno del conduttoreConservatività del campo elettrostatico⇒∫BA⃗E⋅d⃗l=∫BA⃗E⋅̂utdl=0⟺⃗E=ÊnSABCD0=∮L⃗E⋅d⃗l=∫BA⃗E⋅d⃗lAB+∫CB⃗E⋅d⃗lBC+∫DC⃗E⋅d⃗lCD+∫AD⃗E⋅d⃗lDA∫DC⃗E⋅d⃗lCD=0∫CB⃗E⋅d⃗lBC,∫AD⃗E⋅d⃗lDA⟶BC,AD→00d⃗lAB=̂utdlABSia 𝛤 un rettangolo di vertici ABCD • lati AB e CD sufficientemente piccoli e paralleli a S • lati BC e AD infinitesimi di ordine superiore rispetto a AB e CD
"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#0,0,1 Correnti elettriche CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#1,1,"2Corrente elettricaIn condizione statiche, il campo elettrico all’interno dei conduttori è sempre nullo altrimenti gli elettroni sarebbero accelerati e addio condizione staticaCosa succede se tramite un artificio esterno (generatore) si pone una differenza di potenziale (d.d.p.) tra due punti del conduttore?Gli elettroni di conduzione si mettono in moto ed il conduttore risulta percorso da una corrente elettrica "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#10,10,11EsempioDeterminare numero di elettroni di conduzione e velocità di deriva in un filo di rame di raggio r=0.8mm percorso uniformemente da una corrente i=15A Il rame ha densità di massa 𝛿=8.96 g/cm3 e peso atomico A=6335 g/mol mediamente si avrà nC=1 elettrone di conduzione per atomon=nCδNAA=1×8.96 g cm−3×6.022×1023mol−16355 g mol−1=8.45×1022cm−3j=iS=iπr2=15Aπ×0.82×10−6 m=7.46×106 Am−2elettroni di conduzione per unità di volumedensità di correntevelocità di derivavd=jnqe=7.46×106Am−28.45×1022 cm−3×1.6×10−19As=0.55mmsquantità di carica in moto per unità di volumenqe=8.45×1022cm−3×1.6×10−19C=13.6×103 C/m3≈14 C/mm3
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#11,11,"12Conservazione della carica elettrica
Consideriamo una superficie S chiusa e orientata, interna ad un conduttoreil flusso di una corrente di densità j attraverso S è dato da⃗𝚥⃗𝚥̂ncarica che passa attraverso S nell’unità di tempo (corrente uscente) flusso positivo ⇒ carica diminuisce
Principio di conservazione della carica elettrica La carica che attraversa la superficie chiusa S è pari alla variazione di carica complessiva contenuta in SΔq=qout−qinΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=i=qin−qoutΔt=−ΔqΔt→Δt→0−dqdt=iuscente"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#12,12,13Equazione di continuitàLa carica interna alla superficie S può essere scritta in funzione della densità di carica: q=∭τSρdτ𝜏S è il volume delimitato dalla superficie S=−∂∂t∭τSρdτ=∭τS(−∂ρ∂t)dτ∬S⃗𝚥⋅̂ndS=∭τS⃗∇⋅⃗𝚥dτΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=−dqdtteorema della divergenzastesso dominio di integrazione 𝜏S⃗∇⋅⃗𝚥=−∂ρ∂tequazione di continuità 
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#13,13,14Equazione di continuità⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza del vettore densità di corrente bilancia la variazione di caricaL’equazione descrive una situazione locale (o differenziale) in ogni punto del volume in cui scorre corrente.  Una variazione di cariche corrisponde ad un moto di cariche non solenoidale  (le cariche non si muovono su linee chiuse)
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#14,14,"15Condizioni stazionarie
Si hanno condizioni stazionarie se la carica entrante è pari alla carica uscente⃗𝚥⃗𝚥̂nΔq=qout−qin=0La carica q internamente a S si mantiene costanteΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0⃗∇⋅⃗𝚥=0Il flusso della densità di corrente è nulloIl campo densità di corrente è solenoidale (linee di campo sempre chiuse)−dqdt=iuscente=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#15,15,"16Prima legge di OhmConsideriamo un conduttore filiforme ai cui estremi c’è una differenza di potenziale Internamente al filo scorre una corrente proporzionale alla differenza di potenzialeLa costante di proporzionalità tra l’intensità di corrente e la differenza di potenziale è la resistenza elettricaΔV=RiTale relazione (prima legge di Ohm) è una legge empirica, valida a temperature ordinarie costanti La resistenza si misura in Ohm (Ω)    1Ω=1V/1Asimbolo circuitale della resistenza"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#16,16,"17Seconda legge di OhmLa resistenza di un conduttore omogeneo, filiforme di lunghezza l e sezione S vale R=ρRlSR=ρRlSresistività elettrica dipende dalla natura del materiale si misura in ΩmMaterialeResistività (Ωm)Argento1,62 × 10−8Rame1,68 x 10−8Oro2,35 × 10−8Alluminio2,75 × 10−8Tungsteno5,25 × 10−8Ferro9,68 × 10−8Platino10,6 × 10−8Acqua di mare2.00 × 10−1Acqua potabiletra 2.00×101 e 2.00×103Silicio puro (non drogato)2,5 × 103Vetrotra 1010   e 1014Ariatra 1.30×1016 e 3.30×1016Quarzo fusocirca 1016"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#17,17,"18Leggi di Ohm in forma locale
dSdl⃗𝚥Nell’interno di un conduttore, consideriamo un sottile cilindro di base dS e lunghezza dl percorso da una corrente di densità ⃗𝚥VAVBsia dV=VA-VB la differenza di potenziale ai capi del cilindro (VA>VB)dV=Rdi=ρRdldSdiper le due leggi di Ohmdi=jdSdV=Edl⃗𝚥=σC⃗E⃗E=ρR⃗𝚥E=ρRjσC=1ρRConduttività  (o conducibilità) elettricail vettore densità di corrente ha stessa direzione e verso del campo elettrico"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#18,18,"19Resistenze in serieVA
VBVMDue (o più) resistenze in serie sono attraversate dalla stessa corrente i (per equazione di continuità)R1R2i{VA−VM=R1iVM−VB=R2i(VA−VM)+(VM−VB)=VA−VB=(R1+R2)isomma membro a membroRTOT=∑iRiRTOT=R1+R2
la resistenza del sistema formato da due (o più) resistenze collegate in serie è uguale alla somma delle singole resistenzeApplicando la legge di Ohm (caduta ohmica) ai capi di ciascuna resistenza"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#19,19,"20Resistenze in parallelo
VBVAR1R2i1i2Due (o più) resistenze in parallelo hanno la stessa differenza di potenziale VA-VBi1=VA−VBR1i2=VA−VBR2i=(VA−VB)(1R1+1R2)=VA−VBRTOTi=i1+i2=VA−VBR1+VA−VBR2=
L’inverso della resistenza del sistema formato da due o più resistenze collegate in parallelo è uguale alla somma degli inversi delle singole resistenze Applicando la legge di Ohm ai capi di ciascuna resistenza1RTOT=1R1+1R21RTOT=∑i1Ri"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#2,2,"3Modello di Drude-LorentzSe la d.d.p. è costante nel tempo, lo sarà anche il campo elettrico e la forza sugli elettroniCi si aspetta che il moto sia uniformemente accelerato (forza e accelerazioni costanti)Sperimentalmente, però, si trova che la velocità media degli elettroni è proporzionale al campo⟨⃗ve⟩∝⃗E⟨⃗ae⟩∝⃗EModello di Drude-Lorentz  gli elettroni si comportano come cariche libere di un gas nel reticolo cristallino, soggette al campo elettrico ed interagenti con le cariche del reticolo 
_
_
+
+
+
+
+
+
+
+
+
+
+
+⃗E=−⃗∇V"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#20,20,"Esempio
21
Esempio
22metallica quadrata di spessored/2 e latoL/2. Determinare il lavoro fatto per introdurre interamente lalastra all’interno del condensatore. (R:L= DQ210""0L2)2.12Tre condensatori di capacit` aC1=0.5µF,C2=0.8µF,C3=0.1µF, sono collegati in serie (vedi ﬁgura 4). IpuntiAeBsono collegati inizialmente ad un generatore di tensioneV0=100 V.a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccatidal generatore e il puntoBviene collegato ad un punto tra i condensatoriC1eC2.b) determinare la variazione di energia nelle↵ettuare il nuovo collegamento.   FISICA GENERALE II  -  TEST di VERIFICA     (27-10-2015)  Costanti: c = 3x108  m/s  ε0 = 8.85x10-12    F/m  G = 6.67x10-11  Nm2/kg2 e= 1.60x10-19  C me = 9.11x10-31 kg  mp = 1.67x10-27 kg   ESERCIZIO 1  Si consideri il campo F(x,y,z)=2xi-zj-ayk. Determinare: a) per quali valori di a il campo risulta conservativo; b) il potenziale generato dal campo F.  ESERCIZIO 2  Tre cariche positive puntiformi identiche q1= q2=q3=4mC sono disposte su un piano cartesiano ortogonale rispettivamente nei punti di coordinate (0,3m), (0,-1m) e (-1m,1m). Una quarta carica positiva q4=2mC  è posta nel punto di coordinate (1m,1m). Determinare: a) la forza a cui è sottoposta la carica q4; b) l’energia necessaria a spostare la carica q4 dalla posizione iniziale (1m,1m) all’origine del sistema di riferimento.  ESERCIZIO 3 Si consideri un sistema formato da un volume sferico di raggio a in cui è contenuta una carica +Q distribuita uniformemente nel volume, e da un sottile guscio di materiale conduttore di raggio b (b>a), concentrico al volume sferico, sul quale è depositata una carica –Q. Determinare: a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanza r dal centro del sistema, disegnando un grafico qualitativo dell’andamento del campo; b) l’espressione del potenziale sulla superficie del volume sferico (in r=a, considerando nullo il potenziale all’infinito).   ESERCIZIO 4  Tre condensatori di capacità C1=0.5 µF, C2=0.8 µF,  C3=0.1 µF, sono collegati in serie (vedi figura). I punti A e B sono collegati inizialmente ad un generatore di tensione V0=100 V. a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccati dal generatore e il punto B viene collegato ad un punto tra i condensatori C1 e C2. b) determinare la variazione di energia nell’effettuare il nuovo collegamento.              
Figure 4:3 Correnti elettriche3.1Un conduttore cilindrico cavo di lunghezzad=2cm ha raggia=2mm eb=5mm; esso ` e costituito da unasostanza con resistivit` a⇢=2⌦m. Una f.e.m.E=20 V pu` o essere applicata al conduttore in modo chela corrente ﬂuisca parallelamente all’asse del cilindro oppure radialmente dalla superﬁcie interna a quellaesterna. Calcolare nei due casi l’intensit` a di correnteiche percorre il conduttore, la potenza dissipata e ladensit` a di corrente sulle superﬁci terminali.3.2Un resistore di forma cilindrica di sezioneA` e composto da una parte di lunghezzal1fatta di materiale diresistivit` a⇢1=⇢e da un’altra parte di lunghezzal2fatta di materiale di resistivit` a⇢2=3⇢. Il resistore ` eattraversato da una correnteIuniformemente sulla sezioneA. Determinare:a) l’intensit` a dei campi elettriciE1eE2nelle due parti del resistore;b) la di↵erenza di potenziale ai capi del resistore;c) il valore della carica elettrica presente sulla superﬁcie di separazione tra i due materiali che formano ilresistore.3.3Nel circuito in ﬁgura 5, calcolare l’intensit` a di correntei, il potenziale nei quattro vertici e il bilancioenergetico (R= 50⌦,E1=50 V,r1= 20⌦,E2=100 V,r2= 30⌦)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#21,21,"22Effetto JouleQuando una corrente i scorre attraverso un conduttore filiforme, la carica che attraversa una sezione S in un tempo dt è: dq=i dt Il lavoro compiuto dal campo elettrico nello spostamento della carica nell’intervallo dt èδℒ=dU=ΔVdq=ΔVidt=(Ri)idt=Ri2dtLa potenza (energia per unità di tempo) spesa dal campo elettrico per sostare la carica èP=dUdt=Ri2La potenza viene persa negli urti degli elettroni di conduzione con gli atomi del conduttore, i  quali aumentano la propria energia vibrazionale (la potenza viene dissipata in calore)
Effetto Joule aumento della temperatura del conduttore attraversato da correnteP=iΔV=ΔV2R"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#22,22,"23Effetto Joule: interpretazione microscopicaLavoro compiuto dal campo sugli N elettroni contenuti in un volume d𝜏 in un tempo dt=ndτqe⃗E⋅d⃗l=⃗E⋅⃗𝚥dτdtdPdτ=δℒdτdt=⃗E⋅⃗𝚥
Effetto Joule in forma locale Relazione locale che esprime la potenza per unità di volume come prodotto scalare del campo elettrico per la densità di correnten=Ndτδℒ=NqeΔV=ndτqe⃗E⋅⃗vddt=⃗E⋅(nqe⃗vd)dτdt"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#23,23,"24Superconduttori
La resistività è funzione lineare della temperaturaρR=ρ0(1+αT)Alcuni metalli (Hg, Al, Pb, Ti, Zn, …) o altre leghe al di sotto di una temperatura critica Tc prossima allo zero assoluto (0°K=-273.15 °C) mostrano una resistività nullaIn tali condizioni di superconduttività, le correnti circolano senza dissipazione di energia e i superconduttori non si riscaldano, anche con correnti molto intense𝜌0,𝛼 costanti T temperatura in °K "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#24,24,"25Generatori di forza elettromotriceSi è  detto che per avere una corrente in un conduttore è necessario stabilire una differenza di potenziale in due punti del conduttore  Per loro natura i conduttori sono equipotenziali. Per forzare una d.d.p occorre connettere il conduttore ad un generatore di forza elettromotrice (o generatore elettrico)Consideriamo un semplice circuito formato da un generatore (pila o batteria) e da una resistenzaIn tale circuito la circuitazione del campo elettrico è diversa da zero (altrimenti non avremmo corrente)
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG∮⃗E⋅d⃗l=∮ρR⃗𝚥⋅d⃗l≠0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#25,25,"26Generatori di forza elettromotriceNel circuito il campo avrà due componenti
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG⃗E=⃗Es+⃗Em⃗Es⃗E=⃗Es+⃗EmAll’interno del generatore si deve aggiungere il campo elettromotore        (NON conservativo)⃗EmLe forze interna ai generatori sono non conservative (di natura chimica o altro). Il loro effetto è quello di trasportare e mantenere le cariche interne ad una differenza di potenziale 𝛥V=V2-V1Nei conduttori si avrà solo campo elettrostatico⃗Es"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#26,26,"27Generatori di forza elettromotrice∮⃗E⋅d⃗l=∮(⃗Es+⃗Em)⋅d⃗l=∮⃗Es⋅d⃗l+∮⃗Em⋅d⃗lV2V1⃗Es⃗Em⃗EsIl campo elettromotore è definito solo internamente al generatore, non è conservativo e la sua circuitazione è definita forza elettromotrice =ℰ
ℰ=∫21⃗Em⋅d⃗l=−∫21⃗ES⋅d⃗l=V2−V1=ΔVIn condizioni stazionarie (generatore non connesso al circuito) le cariche sono ferme, pertanto ∮(⃗Es+⃗Em)⋅d⃗l=0La forza elettromotrice è uguale alla differenza di potenziale (Tensione del generatore)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#27,27,"28Generatori di forza elettromotriceGeneratori ideali  • la tensione ai capi del generatore si mantiene costanteGeneratori reali  • la tensione ai capi del generatore presenta una caduta ohmica • occorre considerare la resistenza interna del generatore (in serie al circuito)+_
+_simbolo circuitale generatore idealesimbolo circuitale generatore reale"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#28,28,"Prima legge di Kirchhoff (dei nodi)
29+i1
S1
+i2-i3-i4-i5S
S2S5S4S3In condizioni stazionarie (fissato un intervallo 𝛥t, la carica entrante deve bilanciare la carica uscente) ΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0=∑entrantiik−∑uscentiik∬Sk⃗𝚥k⋅̂nkdSk={+ikentrantenelnodo−ikuscentedalnodo∬S⃗𝚥⋅̂ndS=∑k∬Sk⃗𝚥k⋅̂nkdSkConsideriamo N fili che si congiungono in un nodo Siano Si le superfici di intersezione tra S e le sezioni dei fili 
Prima legge di Kirchhoff (dei nodi) In qualunque nodo di un circuito la corrente totale entrante è uguale alla corrente uguale uscente∑nodoik==∑entrantiik−∑uscentiik=0i1+i2−i3−i4−i5=0i1+i2=i3+i4+i5"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#29,29,"Legge di Ohm generalizzata
30Prendiamo in considerazione un circuito aperto (ramo)iA+_+_BCDRR1R2𝓔1𝓔2Fissiamo arbitrariamente un verso di percorrenza della corrente ( es. da A verso D)In condizioni stazionare la corrente entrante in A è pari a quella uscente da DCiascun elemento del circuito è percorso dalla stessa corrente i (tutti gli elementi sono in serie)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#3,3,"4
_
_
+
+
+
+
+
+
+
+
+
+
+
+Gli elettroni subiscono urti, cedendo energia cineticaModello di Drude-Lorentz
⃗ae=qeme⃗EII principio dinamicaNell’intervallo di tempo tra due urti consecutivi l’elettrone si muove di moto uniformemente accelerato:Nell’urto sulle cariche positive, l’elettrone cede energia • l’elettrone rallenta • gli atomi del reticolo aumentano la loro energia vibrazionale (gli atomi del reticolo vibrano sempre a T>0° K)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#30,30,"Legge di Ohm generalizzata
31A+_+_BCDRR1R2𝓔1𝓔2Applichiamo la prima legge di Ohm ai capi dei vari elementiVA-VB=Ri              Caduta di potenziale ai capi di RVB-VC=R1i-𝓔1       Caduta di potenziale ai capi di R1, il generatore 𝓔1 fa salire il potenzialeVC-VD=R2i+𝓔2     Caduta di potenziale ai capi di R2, il generatore 𝓔2 fa scendere il potenzialeVA-VD=Ri+R1i+R2i+𝓔2-𝓔1 =(R+R1+R2)i+𝓔2-𝓔1  Differenza di potenziale ai capi dell’intero ramo   "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#31,31,"Legge di Ohm generalizzata
32A+_+_BCDRR1R2𝓔1𝓔2+_VA-VD+(𝓔1-𝓔2)=RTOT i “Fissato”  il verso della corrente, stabiliamo anche il verso in cui diminuisce il potenziale (le cariche positive della corrente fluisco dal potenziale maggiore a quello minore)Convenzione dei generatori in un circuito (segno della tensione) + se la corrente “entra” nel polo negativo ed “esce” dal polo positivo -  se la corrente “entra” nel polo positivo ed “esce” dal polo negativo +_+_"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#32,32,"Legge di Ohm generalizzata
33 V+XkEk=RTOTiLegge di Ohm su un ramo di un circuito apertoLa differenza di potenziale ai capi di un ramo aperto di un circuito sommata alle tensioni erogate dai generatori è uguale alla caduta di tensione sulla resistenza totale del ramoN.B. Se dai calcoli numerici:  • la corrente ha segno positivo, allora essa circola nello stesso verso che si era supposto inizialmente • la corrente ha segno negativo, allora essa circola nel verso opposto a quello che si era supposto inizialmente"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#33,33,"Seconda legge di Kirchhoff (delle maglie)
34A+_+_BCDRR1R2𝓔1𝓔2RConsideriamo un ramo chiuso (maglia)Connettendo i due capi, la differenza di potenziale si annulla: 𝛥V=0La legge di Ohm viene riformulata:XkEk=RTOTi
Seconda legge di Kirchhoff (o delle maglie) Su qualunque maglia di un circuito la caduta di potenziale è uguale  alla somma delle tensioni erogate dai generatori"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#34,34,"Circuiti ideali e reali
35+_Circuiti elettrici costituiti da fili conduttori, resistenze, generatori e altri elementi collegati tra loroIn un circuito ideale, gli elementi hanno resistenza interna nulla (escluso resistenza)filo conduttoreresistenzacondensatoregeneratore+_In un circuito reale, gli elementi sono schematizzati introducendo elementi resistivi"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#35,35,"Circuiti RC in regime transitorio
36+_T𝓔CRConsideriamo il circuito (ideale) formato da una resistenza, un condensatore a da un generatore di forza elettromotriceInizialmente l’interruttore T è aperto, il condensatore è scaricoAd un dato istante iniziale t=0 l’interruttore viene chiuso. Cosa succede nel circuito? Circola corrente? Potenziale ai capi di resistenza e condensatore? Carica sul condensatore?"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#36,36,"Circuiti RC in regime transitorio
37𝛥VC𝛥VR+_T𝓔CRLe differenze di potenziale ai capi di R e C varieranno al passare del tempo:ΔVR(t)=Ri(t)ΔVC(t)=Q(t)Ci(t) corrente che circola nel circuitoQ(t) carica sul condensatore all’istante t=0 il condensatore è scarico Q(0)=0Applicando la legge delle maglie: ℰ=ΔVR(t)+ΔVC(t)ℰ=Ri(t)+Q(t)C"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#37,37,"Circuiti RC in regime transitorio
38𝛥VC𝛥VR+_T𝓔CRℰ=Ri(t)+Q(t)CLa carica Q(t) che dal generatore fluisce verso il condensatore è legata alla corrente che circola nel circuito dalla relazionei(t)=dQ(t)dtQ(t)=∫t0i(t′ )dt′ L’equazione delle maglie è a tutti gli effetti un’equazione integro-differenziale0=Rdidt+1CdQdt=Rdidt+iCderivando tutto rispetto a t"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#38,38,"390=Rdidt+1CdQdt=Rdidt+iCCircuiti RC in regime transitorio𝛥VC𝛥VR+_T𝓔CRdidt=−iRCRisolviamo per separazione delle variabiliEquazione omogenea in i(t)dii=−dtRC∫i(t)i(0)di′ i′ =−1RC∫t0dt′ lni(t)i(0)=−tRCi(t)i(0)=e−tRCi(t)=i(0)e−tRCAll’instante iniziale si haℰ=Ri(0)+Q(0)Ci(0)=ℰRi(t)=ℰRe−tRCQ(0)=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#39,39,"Carica di un condensatore
40i(t)=ℰRe−tRC𝛥VC𝛥VR+_T𝓔CRCorrente che circola nel circuito in funzione del tempo=ℰR[−RCexp(−t′ RC)]t0=−ℰC(e−tRC−1)=ℰC(1−e−tRC)Q(t)=∫t0i(t′ )dt′ =∫t0ℰRexp(−t′ RC)dt′ Q(t)=ℰC(1−e−tRC)ΔVR(t)=ℰe−tRCDifferenza di potenziale ai capi della resistenzaCarica sul condensatore in funzione del tempoΔVC(t)=ℰ(1−e−tRC)Differenza di potenziale ai capi del condensatoreτ=RCCostante di tempo del circuito RC"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#4,4,"5Modello di Drude-LorentzSupponiamo che l’elettrone abbia un urto all’istante t. Sia  p(t)dt la probabilità di avere un urto in un intervallo [t, t+dt]. ⟨t⟩=∫∞0tp(t)dtIl tempo medio che intercorre tra due urti:nel tempo tra due urti consecutivi, la velocità aumenterà linearmente con l’accelerazione⃗ve=qeme⃗Etla velocità media di un elettrone sara:⟨⃗ve⟩=∫∞0⃗ve(t)p(t)dt=∫∞0qeme⃗Etp(t)dt=qeme⃗E⟨t⟩"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#40,40,"41Carica di un condensatore
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰRi(t)=ℰRe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ΔVR(t)=ℰe−tRCΔVR(t)=ℰe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰΔVC(t)=ℰ(1−e−tRC)
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0Q(t)=ℰC(1−e−tRC)ℰC"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#41,41,"42Scarica di un condensatoreTCRSia dato un circuito formato da un condensatore e una resistenza Q(0)=Q0Inizialmente l’interruttore T è aperto, il condensatore è carico con Q(0)=Q0Calcoliamo quanto vale l’energia dissipata sulla resistenza i(t)=dQ(t)dtL’equazione della maglia alla chiusura dell’interruttore èΔVR(t)+ΔVC(t)=0Ri(t)+Q(t)C=0RdQdt+QC=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#42,42,43Scarica di un condensatoreTCRQ(0)=Q0RdQdt+QC=0dQdt=−QRCdQQ=−dtRCPer separazione delle variabiliEq differenziale omogeneaQ(t)=Q0e−tRCCarica sul condensatorei(t)=−Q0RCe−tRC=−VcRe−tRCCorrente che circola nel circuitolnQ(t)Q(0)=−tRC
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#43,43,"44Scarica di un condensatore
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
i(t)=−VcRe−tRC
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
Q0Q(t)=Q0e−tRC
−Q0RC=−VcR"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#44,44,45Scarica di un condensatoreTCRQ(0)=Q0UR=∫∞0PRdt=∫∞0Ri2dt=∫∞0R[−VCRe−tRC]2dtL’energia dissipata è pari all’integrale della potenza nel tempo=12CV2C[−e−∞RC+e−0RC]=V2CR∫∞0e−2tRCdt=V2CR[−RC2e−2tRC]∞0UR=12CV2C=UCL’energia che era inizialmente accumulata nel condensatore viene interamente dissipata sulla resistenza
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#45,45,"DRAM 
46
Il condensatore può essere utilizzato come cella di memoria in alternativa al flip-flop Cella di memoria formata da condensatore + transistor Lo stato di carica del condensatore determina lo stato logico Il transistor è usato per pilotare la lettura/scrittura (funziona come un interruttore) Ad ogni lettura/scrittura, tutti i C di un array vengono ri-caricati/scaricatiLinea indirizziLinea dati"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#46,46,"DRAM 
47
PRO economicità, alta densità, velocità di accesso ~10 ns (un po’ più lente delle SRAM)
CONS carica sui C diminuisce nel tempo (effetti dissipativi) necessario un circuito di “refresh” che faccia delle letture/scritture “fittizie” (con frequenza del kHz)  Problemi in ambienti ad elevata radiazione (centrali nucleari, detector, spazio): particelle cariche da raggi cosmici o da decadimenti radioattivi possono alterare gli stati  logici"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#47,47,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
48"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#5,5,"6Modello di Drude-LorentzVelocità media o velocità di deriva proporzionale al campo: stessa direzione e verso opposto gli elettroni possiedono anche una velocità dovuta all’agitazione termica, ma si può dimostrare che essa ha valore medio nullo (perché casuale in ogni direzione) Valori tipici: velocità di termica a temperatura ambiente ~100 km/s velocità di deriva: qualche mm/s⃗vd=⟨⃗ve⟩=qeme⃗E⟨t⟩"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#6,6,"7Intensità di correnteConsideriamo un conduttore all’interno del quale è mantenuta una differenza di potenziale VA-VB
Nel S.I. l’unità di misura della corrente è l’Ampere (A) (grandezza fisica fondamentale) 
SdqVAVBi=limΔt→0ΔqΔt=dqdtData una sezione S, interna al conduttore, definiamo la corrente elettrica come la quantità di carica che attraversa il conduttore per unità di tempo"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#7,7,"8Intensità di correntei=dqdtLa carica che attraversa la superficie S è al netto delle cariche positive e negative Dal punto di vista sperimentale, in elettromagnetismo, il moto di una carica positiva è equivalente al moto di una carica negativa che procede in verso opposto
Sdq=dq++dq-VAVBConvenzione: verso positivo delle correnti quello in cui si muovono i portatori di carica positivi  la corrente ha verso opposto alla velocità di deriva degli elettroni"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#8,8,"9Intensità di corrente
̂nα
dSdS´VAVB⟨⃗v+⟩Consideriamo un tubo (di flusso) cilindrico di sezione infinitesimafissiamo il verso della corrente concorde alla velocità di derivain un intervallo dt, avremo una quantità di carica dq (positiva) che attraversa il volume d𝜏 delimitato dalle superfici orientate S e S´  n=Ndτnumero di portatori di carica N per unità di volumecarica elementare (positiva)d𝜏dq=Ne+=nq+edτdτ=[(⃗vd⋅̂n)dt]dS(⃗vd⋅̂n)dtaltezza del cilindretto obliquo"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#9,9,"10Densità di correnteDefiniamo il vettore densità di corrente elettricai=dqdt=∬S⃗𝚥⋅̂ndSRiscriviamo la carica che attraversa il volume d𝜏
̂nα
dSdS´VAVB⃗𝚥d𝜏
Corrente (infinitesima) che attraversa una superficie dSL’intensità di corrente è pari al flusso della densità di corrente attraverso la sezione del conduttore
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
⃗𝚥di=(dqdt)dS=⃗𝚥⋅̂ndSdq=nqe[(⃗vd⋅̂n)dt]dS=[(nqe⃗vd)⋅̂n]dSdt⃗𝚥=nqe⃗vd"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#0,0,1 Cmpi magnetici stazionari CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#1,1,"2Fenomeni magneticiI fenomeni magnetici sono noti dall’antichità  (Talete, Archimede, Cinesi…) Il minerale magnetite (FeO+Fe2O3+FeO4) ha la capacità di attrarre oggetti contenenti ferro o materiali ferrosi
Esistenza forze magnetiche
Limatura di ferro vicino ad una calamita è attratta maggiormente dagli estremi (poli magnetici) in cui sembra si concentri la forza"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#10,10,"Rotore e circuitazione del campo magnetico
11
Le linee del campo magnetico sono sempre chiuse  𝛤La circuitazione lungo una generica linea chiusa 𝛤 sarà in generale non nullaAnche il rotore del campo magnetico (thm Stokes) sarà in generale non nullo⃗∇∧⃗B≠0
Il campo magnetico NON è conservativo∮Γ⃗B⋅d⃗l≠0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#11,11,"Magneti, cariche elettriche, correnti
12Le forze a cui sono sottoposti gli aghi magnetici corrispondono a quelle dei dipoli elettrici, piuttosto che a quelle delle cariche singoleNon ci sono interazioni tra magneti e cariche elettriche fermeCosa succede se avviciniamo un magnete a delle cariche in movimento ? (filo percorso da corrente)
Consideriamo un esperimento in cui colleghiamo un filo conduttore ad un generatore  di f.e.m. Poniamo un ago magnetico vicino al tratto di filo rettilineo"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#12,12,"Esperimento di Oersted (1820)
13
A circuito aperto, l’ago non sente nessuna forza e resta fermoChiudendo il circuito, nel filo passa corrente e l’ago si orienta perpendicolarmente al filoInvertendo la polarità del generatore, l’ago ruota in senso opposto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#13,13,"Esperimento di Faraday (1821)
14
Poniamo un filo conduttore in un campo magneticoSe nel conduttore passa corrente, esso sente una forzapossiamo bilanciare (→ misurare) la forza con dei pesi"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#14,14,"Esperimento di Ampère (1820)
15
Esperimento con due fili rettilinei e paralleli percorsi da corrente
I fili si attraggono se le correnti hanno lo stesso versoI fili si respingono se le correnti hanno verso opposto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#15,15,"Cariche in movimento e campi magnetici
16Si osservano interazioni di tipo magnetico tra: •magneti •magneti e fili percorsi da corrente  •fili percorsi da correntePossiamo concludere che le correnti generano dei campi magneticiMa le correnti sono cariche in movimento
I campi magnetici sono generati da cariche in movimento sia macroscopicamente (correnti) che microscopicamente (magneti)Domanda: cariche in movimento sono l’unico modo per generare campi magnetici?I movimenti possono essere anche microscopici (elettroni che orbitano attorno ai nuclei, all’interno delle calamite)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#16,16,"Magnetostatica nel vuoto
17Consideriamo un circuito in corrente stazionaria i e consideriamo un piccolo tratto      che sia  •libero di muoversi su connessioni flessibili e mediante un dinamometro. •elettricamente neutro •orientato con il verso della corrente •immerso in un campo magnetico d⃗ld⃗FIl tratto di filo     subisce una forza     con le seguenti caratteristiche:d⃗l|d⃗F|∝i|d⃗l|d⃗F⊥d⃗ld⃗F=0Quando la corrente (    )  e il campo magnetico sono parallelid⃗l
iRdinamometro a molle𝓔(entrante nel piano)⃗Bd⃗l"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#17,17,"Seconda legge di Laplace
18d⃗F=id⃗l∧⃗BUn tratto di filo percorso da corrente ed immerso in un campo di induzione magnetica subisce una forza descritta da:
Definizione operativa del campo induzione magnetica⃗Bla direzione ed il verso di       sono determinati dalla corrente che circola nel filod⃗l
Regola della mano destra"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#18,18,19Seconda legge di Laplaced⃗F=id⃗l∧⃗BCosa succede a livello microscopico nel filo?Una sezione dS del filo sarà attraversata da una densità di corrente di modulo j=i/dSid⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτdi=⃗𝚥⋅̂ndS⃗𝚥 orientato come d⃗lForza magnetica sull’intero volume del filodτ volume infinitesimo⃗F=∫filo⃗𝚥∧⃗BdτForza magnetica su un volume infinitesimod⃗Fτ=⃗𝚥∧⃗Bdτ
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#19,19,"Forza magnetica su cariche puntiformi
20La densità di corrente era stata definita come:⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di derivaLa forza magnetica per unità di volume diventad⃗Fτ=⃗𝚥∧⃗Bdτ=nq⃗vd∧⃗Bdτ=Nq⃗vd∧⃗B⃗F=q⃗v∧⃗BIn base a questa relazione, possiamo generalizzare al caso di una singola carica puntiforme q che in moto con velocità    , in presenza di un campo di induzione magnetica    , subisce una forza  (forza di Lorentz)  ⃗B⃗v"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#2,2,"Fenomeni magnetici
3Le calamite esercitano forze tra di loro, che possono essere attrattive o repulsive In analogia con l’elettrostatica, possiamo introdurre la definizione di poli magnetici NORD e SUD La definizione deriva dal fatto che la Terra si comporta come una calamita in una calamita il polo sud si orienta verso il sud geografico e il polo nord con il nord terrestre
S
N"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#20,20,"Forza di Lorentz
21⃗F=q⃗v∧⃗BMetodo alternativo per definire il campo induzione magnetica (usando una singola carica)Tale relazione è puntuale (vale in ciascun punto dello spazio) ed è più precisa della seconda legge di Laplace (definita su un tratto     )d⃗lDall’espressione della Forza di Lorentz ricaviamo che il campo magnetico ha le dimensioni di una forza su carica e velocità. Nel S.I. il campo magnetico si misura in Tesla (T)  1T=1V 1s/1m2 "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#21,21,"Forza di Lorentz
22⃗F=q⃗v∧⃗BIn presenza di un campo di induzione magnetica: •Cariche ferme non soggette a forza di Lorentz  •Cariche in movimento soggette a forza di Lorentz 
La forza di Lorentz è sempre perpendicolare al campo induzione magnetica 
La forza di Lorentz è sempre perpendicolare alla velocità  (centripeta)  
La forza di Lorentz non compie lavoro sulla carica in moto (è conservativa???)
direzione della forza data dalla regola della mano destraF=qvBsinαModulo della forza di Lorentz𝛼"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#22,22,"Forza di Lorentz generalizzata
23⃗F=q⃗E+q⃗v∧⃗BSe sono presenti sia un campo elettrico che un campo magnetico la forza di Lorentz si scrive⃗F=q(⃗E+⃗v∧⃗B)Le cariche elettriche interagiscono con il campo elettrico ed il campo magnetico •Cariche ferme sentono solo gli effetti del campo elettrico •Cariche in moto sentono sia l’effetto del campo elettrico che del campo magneticoCosa succede che se cambiamo Sistema di Riferimento? (esempio, se scegliamo un SdR solidale con la carica in moto?)Le leggi della Fisica devono essere invarianti: non devono dipendere dal SdR.  Importante indizio del fatto che campo elettrico e campo magnetico sono strettamente legati: sono due aspetti della stessa entità fisica: il campo elettromagnetico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#23,23,"Moto di cariche in campi magnetici
24Studiamo il moto di una carica q che si muove con velocità costante, perpendicolare ad un campo magnetico uniformeLa forza di Lorentz è ortogonale a velocità e campo magnetico. Forza e velocità sono complanari. ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗F⃗FPer calcolare il raggio di curvatura R dell’orbita ricordiamo che nella cinematica di un moto curvilineo l’accelerazione è⃗a=dvdt̂ut+v2R̂n⃗vcostanteForza centripeta: moto circolare uniforme⃗v⃗vR"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#24,24,"Moto di cariche in campi magnetici
25⃗F=m⃗a=mv2R̂n⃗F=q⃗v∧⃗B=qvB̂n̂n=⃗v∧⃗Bvbsinα=1mv2R=qvBForza centripetaForza di Lorentzdirezione e verso della forza di LorentzLa forza di Lorentz è centripetaR=mvqBRaggio di curvatura⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BR⃗F⃗F⃗v⃗v"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#25,25,"Moto di cariche in campi magnetici
26Calcoliamo il periodo di rotazione⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ La velocità angolare (o frequenza angolare)ω=vR=vqBmv=qBm(T=2πω)Il periodo e la frequenza non dipendono né dal raggio né dalla velocità T=2πRv=2πvmvqB=2πmqB⃗F⃗F⃗v⃗v⃗BR"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#26,26,"Circuito in campo magnetico
27Utilizziamo la seconda legge di Laplace per determinare le azioni meccaniche cui è soggetto un circuito percorso da corrente  immerso in un campo magnetico  d⃗F=id⃗l∧⃗BSupponiamo che il circuito sia: •rigido (non cambia forma) •la corrente i sia mantenuta costante da un generatore di f.e.m. (anche se vedremo che B tende a modificare la corrente nel circuito…)La forza totale sul circuitoIl momento (delle forze) totale sul circuito⃗rDistanza tre dl e il polo⃗F=i∮d⃗l∧⃗B⃗M=∮⃗r∧d⃗F=i∮⃗r∧(d⃗l∧⃗B)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#27,27,"Spira in un campo magnetico
28Consideriamo il caso semplice di una spira rettangolare di lati a e b immersa in un campo induzione magnetica uniforme (diretto lungo l’asse z).⃗B̂n1ba234𝜃Calcoliamo la forza agente su ogni lato⃗F1=∫1id⃗l∧⃗B=∫1iBdl̂𝚥=ilB̂𝚥i⃗F1l=axy⃗F2=∫2id⃗l∧⃗B=∫2iBdl(−̂ı)=−ilB̂ıl=b⃗F3=∫3id⃗l∧⃗B=∫3iBdl(−̂𝚥)=−ilB̂𝚥=−⃗F1⃗F4l=al=b⃗Ftot=∑⃗Fi=0La forza totale sulla spira è nulla⃗F2⃗F3⃗F4=∫4id⃗l∧⃗B=∫4iBdl̂ı=ilB̂ı=−⃗F2z"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#28,28,"Spira in un campo magnetico
29zSe il sistema è visto dall’alto:⃗B̂n1ba234𝜃ixyzTuttavia il momento delle forze sarà non nulloCalcoliamo il momento rispetto al centro della spira⃗r1⃗M1=⃗r1∧⃗F1=0⃗F1⃗r1//⃗F1⃗F4⃗r2⃗B
̂n𝜃ixb/2b/2𝜃𝜃⃗M3=⃗r3∧⃗F3=0⃗r3//⃗F3⃗F2⃗M2=⃗r2∧⃗F2=(b2)(iaB)sinθ(̂𝚥)⃗M4=⃗r4∧⃗F4=(b2)(iaB)sinθ(̂𝚥)⃗r4⃗Mtot=⃗M1+⃗M2=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è diretto verso l’alto (lungo asse di rotazione)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#29,29,"Momento magnetico di una spira
30⃗M=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è proporzionale alla corrente e al prodotto vettoriale tra superficie della spira orientata e campo induzione magneticaDefiniamo il momento magnetico della spira di area S percorsa da corrente i ⃗m=iŜnS=ab superficie della spiraè il versore normale alla spira orientato in verso tale che esso vede circolare la corrente in verso antiorario (regola della mano destra)̂n
̂n⃗M=⃗m∧⃗BIl momento delle forze è uguale al prodotto vettoriale del momento magnetico della spira per il campo induzione magnetica(si dimostra che la relazione vale per spire di qualsiasi forma                     )d⃗m=îndS"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#3,3,"Interazioni tra calamite
4
Poli opposti (N-S) si attraggonoPoli stesso segno (N-N o S-S) si respingono"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#30,30,"Teorema di equivalenza di Ampère
31
Una spira percorsa da corrente immersa in un campo magnetico si comporta come un dipolo magnetico elementare (ago magnetico) di momento                , perpendicolare al piano della spira e orientato con la regola della mano destra⃗m=iŜnSulla spira agisce un momento di forze solo se il campo magnetico ed il momento della spira formano un angolo 𝜃≠0 La coppia di forze è nulla quando campo magnetico e momento magnetico sono allineati (𝜃=0)La relazione tra momento delle forze su una spira e campo induzione è analoga al dipolo elettrico immerso in un campo elettrico⃗M=⃗p∧⃗E"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#31,31,"Esempio
32v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#32,32,"Galvanometro
33Il galvanometro è uno strumento utilizzato per misurare piccole intensità di corrente
Il momento delle forze magnetiche sulla spira è bilanciato dal momento delle forze elasticheMolla a spiraleMmolla=−kαk costante elastica 𝛼 angolo di aperturaAll’equilibrio⃗Mmolla=⃗MMi=kαSBSistema fatto in modo che 𝜃≈90° 𝜃≈90° MM=−iSBsinθ≃−iSBMisura della corrente"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#33,33,"Motore elettrico
34Il motore elettrico trasforma energia elettrica in energia meccanica
La spira percorsa da corrente è messa in rotazione dall’interazione con il campo magneticoPer mantenere la rotazione sempre nello stesso senso si usano delle spazzole in contatto sul commutatore per invertire il verso della corrente nella spira"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#34,34,"Altoparlante
35
impulso elettrico modulato dalla frequenza sonoraIl filo è collegato rigidamente al cono di cartoneQuando nel filo passa corrente (variabile nel tempo, modulata sulla frequenza sonora), esso sente la forza magnetica e mette in vibrazione l’altoparlante La vibrazione del cono produce onde sonore (conversione di energia elettrica in energia meccanica delle onde sonore)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#35,35,"Prima legge di Laplace
36
Evidenze sperimentali mostrano che i fili percorsi da corrente generano campi magneticid⃗B=μ0i4πd⃗l∧̂urr2d⃗B=μ0i4πd⃗l∧⃗rr3Consideriamo un tratto di filo infinitesimo      percorso da corrente i. Sperimentalmente si osserva che il campo magnetico generato a distanza    vale: ⃗rd⃗ld⃗lentrante se     e nel piano del foglio⃗rd⃗lxyz⃗r⃗B⨂iLa costante 𝜇0 è la permeabilità magnetica del vuotoμ0=4π×10−7VsmA=4π×10−7NA2=4π×10−7HmHenry (H)  1H=1𝛺 1s"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#36,36,"Prima legge di Laplace
37d⃗lxyz⃗Bi⨂⃗r−⃗r′ ⃗r⃗r′ d⃗B=μ0i4πd⃗l∧(⃗r−⃗r′ )(⃗r−⃗r′ )3Notazione in forma più generale⃗B=μ04π∫lid⃗l∧(⃗r−⃗r′ )(⃗r−⃗r′ )3Il campo generato da un intero circuito l si ottiene integrandoVerifichiamo che il campo B è solenoidale⃗∇⋅⃗B=⃗∇⋅(μ0i4πd⃗l∧⃗rr3)=μ0i4π[(⃗∇∧d⃗l)⋅⃗rr3−d⃗l⋅(⃗∇∧⃗rr3)]=0⃗∇⋅(⃗A∧⃗B)=(⃗∇∧⃗A)⋅⃗B−⃗A⋅(⃗∇∧⃗B)=0  un vettore costante è irrotazionale=0  un vettore radiale è irrotazionale"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#37,37,"Prima legge di Laplace
38|d⃗B|=μ0i4πdlsinθr2Modulo del campo magnetico:d⃗lxyz⃗r⃗B⨂iθL’angolo 𝜃 è tra la direzione della corrente e la posizione del punto in cui calcoliamo il campo magnetico se sin𝜃=0;180°  ⇒ dB=0: lungo la direzione della corrente non viene generato campo magnetico dB∝1r2come la legge di Coulomb per le cariche puntiformidB∝idipende dall’intensità della corrente, e quindi dal numero di portatori di caricadB⊥d⃗ldB⊥d⃗rperpendicolare al piano definito da corrente e posizione"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#38,38,"Legge di Biot-Savart
39Determinare il campo induzione magnetica generato da un filo rettilineo di lunghezza indefinita, percorso da corrente i 
⃗B=μ0i2πr̂utLegge di Biot-Savart• il campo magnetico ha intensità inversamente proporzionale alla distanza dal filo • le linee di campo sono circonferenze nel piano trasverso al filo, centrate sul filo stesso • L’orientazione delle linee di campo segue la regola della mano destra "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#39,39,"Forza tra due fili percorsi da corrente
40
L’esperimento di Ampère evidenzia la forza tra due fili percorsi da correnteConsideriamo due fili rettilinei di lunghezza indefinita, paralleli, posti a distanza d, percorsi da correnti i1 e i2 (iniziamo con il caso di correnti equiverse)di1i2Il filo 1 genera a distanza d un campo magnetico ⃗B1⨂B1=μ0i12πdun tratto di filo dl2 sente una forza magneticad⃗F12=i2d⃗l2∧⃗B1d⃗l2(II Legge Laplace)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#4,4,"Campo magnetico
5In analogia con l’elettrostatica, viene naturale introdurre un campo vettoriale      detto  campo magnetico⃗Bconvenzione: le linee di forza del campo magnetico entrano nel polo sud e escono dal polo nord Le linee di campo sono tangenti alla direzione lungo la quale si allineano gli aghi magneticiL’intensità è proporzionale al momento delle forze sull’ago
S
N
S
N
S
N
S
N
S
N
S
NIl campo      può essere anche definito come campo induzione magnetica⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#40,40,"41d⨂d⃗F12=i2d⃗l2∧⃗B1Forza tra due fili percorsi da correntedF12=i2dl2B1sinθ=i2dl2μ0i12πd𝜃=90°Forza sul filo 2:Modulo della forzadF12=μ02πi1i2ddl2i1i2Direzione di dF12: perpendicolare ai fili, diretta da 2 verso 1 Analogamente, sul filo 1dF21=μ02πi1i2ddl1d⃗F21=iid⃗l1∧⃗B2=−d⃗F21La forza dF21 esercitata dal filo 2 sul filo 1 è uguale e opposta (attrattiva)d⃗F12d⃗l2⃗B1"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#41,41,"Forza tra due fili percorsi da corrente
42d𝜃=90°i1i2⨂Se le correnti correnti i1 e i2 sono dirette in verso opposto le forze tra i fili saranno anch’esse opposte e repulsivePer il terzo principio della dinamica, le forze tra i due fili interagenti devono sempre essere uguali e opposteSu un tratto di filo L finito, basta integrare su dl|⃗F|=μ02πi1i2dLForza per unità di lunghezzadFdl=μ02πi1i2dd⃗F12d⃗l2⃗B1"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#42,42,"Definizione operativa della corrente
43Un ampere è l'intensità di corrente elettrica che, se mantenuta in due conduttori lineari paralleli, di lunghezza infinita e sezione trasversale trascurabile, posti a un metro di distanza l'uno dall'altro nel vuoto, produce tra questi una forza pari a 2 × 10-7 N per ogni metro di lunghezza.Tale definizione fissa anche il valore di 𝜇0 . La definizione operativa della corrente (e quindi della carica elettrica) sono fatte attraverso la misura di una forza  "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#43,43,"Campi magnetici da cariche puntiformi in moto
44d⃗B=μ0i4πd⃗l∧̂urr2Se esprimiamo la corrente in funzione della densità di corrente:id⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτ⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di deriva=μ04π⃗𝚥∧⃗rr3dτ=Nμ04πq⃗vd∧⃗rr3La prima legge di Laplace può essere riformulataCampo magnetico generato da N portatori di caricaUna singola carica in movimento genera un campo magnetico che a distanza r dalla carica vale⃗B=μ04πq⃗v∧⃗rr3"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#44,44,"Campi magnetici da cariche puntiformi in moto
45⃗B=μ04πq⃗v∧⃗rr3Tale formula vale in un Sistema di Riferimento in cui q si muove con velocità vIn un SdR in cui la carica è ferma si ha che B=0 !!!Ricordiamo che a distanza r, la carica genera un campo elettrico⃗E=q4πε0⃗rr3Ammettendo che questa relazione sia valida anche per cariche in motoq⃗rr3=4πε0⃗E⃗B=μ04π⃗v∧q⃗rr3=⃗B=μ0ε0⃗v∧⃗E=1c2⃗v∧⃗Ec=1μ0ε0Chiara relazione tra campi elettrico e magnetico generati da una carica in motovelocità della luce nel vuoto…=3×108m/sμ04π⃗v∧⃗E4πε0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#45,45,"Campo da spira circolare
46Determinare il campo induzione magnetica sull’asse di una spira circolare di raggio R percorsa da corrente i 
Bz==μ0i2R2(R2+z2)3/2=μ02πm(R2+z2)3/2⃗m=iŜk=iπR2̂k"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#46,46,"Esempio
474.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .
Evi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#47,47,"Esempio
484.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .
Evi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni.v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#48,48,"Esempio
49v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#49,49,"Flusso del campo magnetico
50Abbiamo già dimostrato che il campo magnetico è solenoidale⃗∇⋅⃗B=0Per il teorema della divergenza, il flusso del campo magnetico attraverso una qualsiasi superficie chiusa sarà nullo: NON esistono cariche magnetiche isolateIl flusso attraverso una superficie aperta avrà un suo valore, non necessariamente nullo, ci torneremo in seguito…∬Saperta⃗B⋅̂ndS∬Schiusa⃗B⋅̂ndS=∭τ(S)⃗∇⋅⃗B=0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#5,5,"6Campo magnetico
La limatura di ferro si orienta con il campo magnetico delle calamite
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#50,50,"Circuitazione del campo magnetico
51Dal momento che le linee di forza del campo magnetico sono sempre chiuse, ci aspettiamo che la circuitazione può essere non-nullaSemplificando, calcoliamo la circuitazione del campo magnetico generato da un filo rettilineo indefinito percorso da corrente iCalcoliamo la circuitazione lungo una linea chiusa e orientata 𝛤 che concatena il filo. Su un tratto infinitesimo:îtrd𝜙=μ0i2πrrdϕ̂ut⋅d⃗l=rdϕProiezione su circonferenza (arco di circonferenza) ∮Γ⃗B⋅d⃗l=∫2π0μ0i2πdϕ=±μ0iSegno dipende da corrente (regola mano destra)𝛤d⃗l⃗B⋅d⃗l=μ0i2πr̂ut⋅d⃗l⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#51,51,"Circuitazione del campo magnetico
52Se invece la linea chiusa 𝛤  non “concatena” il filo:i𝛤⃗B⋅d⃗l1=μ0i2πr1̂ut⋅d⃗l1=μ0i2πr1r1dϕd⃗l1⃗B⋅d⃗l2=μ0i2πr2̂ut⋅d⃗l2=μ0i2πr2r2(−dϕ)per ogni angolo d𝜙 ci saranno sempre due tratti precorsi in verso oppostole due proiezioni sottendono lo stesso angolo, quindi il contributo alla circuitazione è nullo∮Γ⃗B⋅d⃗l=0d𝜙d⃗l2⃗B⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#52,52,"Legge di Ampère
53Il segno delle correnti si valuta usando la regola della mano destra, rispetto al verso di percorrenza della curva orientata 𝛤
La circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate ∮Γ⃗B⋅d⃗l=μ0conc∑kikLegge di Ampère fornisce un metodo per il calcolo del campo magnetico in particolari condizioni di simmetria"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#53,53,"54Circuitazione del campo magneticoPossiamo prendere un numero qualsiasi di correnti concatenate, su circuiti di forma arbitraria
∮Γ1⃗B⋅d⃗l=0∮Γ2⃗B⋅d⃗l=μ0(i1−i2)∮Γ3⃗B⋅d⃗l=μ0(−i1+i2−i3)∮Γ1⃗B⋅d⃗l=μ0i1∮Γ2⃗B⋅d⃗l=μ0(−i2−i3)∮Γ3⃗B⋅d⃗l=0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#54,54,"Densità di corrente concatenata
55Consideriamo N fili, ciascuno di sezione Sk, percorsi da correnti ikCiascuna corrente può essere scritta in funzione della densità di corrente:ik=∬⃗𝚥k⋅̂nkdSk
i1-i2i3𝛤SS1S2S3La somma delle correnti concatenate alla curva 𝛤 conc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSDove S è una generica superficie orientata che ha per bordo 𝛤 e  jc è la densità di corrente concatenata "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#55,55,"56Il teorema di StokesConsideriamo una superficie S aperta orientata avente come bordo una linea chiusa orientata 𝛤 
𝛤S(𝛤)̂n̂n
Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('𝛤∮Γ⃗F⋅d⃗lDefiniamo la circuitazione del campo lungo la linea chiusa orientata 𝛤 "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#56,56,57Il teorema di StokesIl flusso del rotore di un campo vettoriale attraverso una superficie S aperta e orientata è uguale alla circuitazione del campo vettoriale lungo il bordo 𝛤 di tale superficie∬S(Γ)(⃗∇∧⃗F)⋅̂ndS=∮Γ⃗F⋅d⃗lIl teorema di Stokes mette in relazione un integrale di superficie con un integrale di linea 
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#57,57,"Il rotore del campo magnetico
58Riscriviamo la legge di Ampère in funzione della densità di corrente concatenataconc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSS è una generica superficie con bordo 𝛤 Applichiamo il teorema di Stokes:∮Γ⃗B⋅d⃗l=μ0conc∑kik=μ0∬S⃗𝚥C⋅̂ndS∮Γ⃗B⋅d⃗l=∬S⃗∇∧⃗B⋅̂ndS=μ0∬S⃗𝚥C⋅̂ndSL’uguaglianza è vera per qualsiasi superficie S con bordo 𝛤 
Legge di Ampère in forma locale ⃗∇∧⃗B=μ0⃗𝚥In ogni punto dello spazio, il rotore del campo magnetico è proporzionale alla densità di corrente in quel punto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#58,58,"Esempio
59Calcolare il campo di un filo di lunghezza indefinita percorso da corrente i utilizzando la legge di Ampère"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#59,59,"Esempio
60Determinare in tutto lo spazio il campo magnetico generato da un cilindro conduttore di raggio R e lunghezza indefinita percorso uniformemente da una corrente di intensità i "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#6,6,"Campo magnetico terrestre
7
Un ago magnetico libero di ruotare si orienta  con la linea di campo che esce dal polo nord (del magnete) e entra dal polo sud (del magnete)Ciò significa che la Terra si comporta come un magnete le cui linee di campo escono dal polo sud geografico ed entrano nel polo nord geografico.Convenzionalmente il polo nord magnetico coincide con il polo sud geografico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#60,60,"Esempio
61v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.
⃗B=μonîk=μ0NLîk̂kCampo interno al solenoide (ideale)Esternamente il campo è nullo"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#61,61,"Esempio
626.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2 r2)(c2 b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=""0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0""0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2 S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e t/⌧dR⌧))
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#62,62,"Magnetismo nella materia
63Cosa succede se riempiamo la parte interna di un solenoide rettilineo ideale?Si osserverà una variazione del campo magnetico: alluminio, platino, sodio: leggero aumento   → materiali PARAMAGNETICIferro, nichel, cobalto: considerevole aumento → materiali FERROMAGNETICI
materiali organici, rame, argento: leggera diminuzione  → materiali DIAMAGNETICII materiali ferromagnetici restano magnetizzati "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#63,63,"64Momento magnetico orbitalePer spiegare il magnetismo nella materia occorre partire dalla struttura microscopicaIn un modello molto semplificato possiamo pensare gli elettroni più esterni in rotazione intorno al nucleoPartiamo dal caso più semplice: l’atomo di idrogenoEssendo la forza coulombiana centripetaricaviamo la velocità di rotazione:14πε0qeqpr2H=mev2rHRH=5.3×10−11m
RH=5.3×10−11mme=9.1×10−31kg|qe|=|qp|=1.6×10−19Cv=14πε0qeqpmerH=2.2×106m/s"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#64,64,65Momento magnetico orbitalepossiamo pensare che un elettrone che ruota intorno al nucleo genera una correnteil momento magnetico dell’elettronei=−qeTdove il periodoT=2πRHvdefinendo il momento angolare orbitale:⃗po=⃗RH∧me⃗vmo=iS=iπR2H=−qev2πRHπR2H=−qev2RHmememo=iS=iπR2H=−qev2πRHπR2H==−qev2RHmeme⃗mo=−qe2me⃗po
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#65,65,"Momento magnetico di spin
66Oltre al momento magnetico orbitale, si può osservare che gli elettroni hanno un ulteriore momento magnetico di spin (come se gli elettroni ruotassero intorno al proprio asse)⃗ms=−qeme⃗psIl momento magnetico totale (o intrinseco) è dato da una combinazione di momento orbitale e momento di spin. L’accoppiamento è descritto dalle leggi della meccanica quantisticaIn un generico atomo, il momento magnetico dipende dagli elettroni più esterniIn assenza di campi magnetici esterni, il momento magnetico totale macroscopico è nullo, perché i momenti magnetici degli atomi sono orientati casualmente e la loro somma vettoriale è nulla
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#66,66,"Materiali diamagnetici
67In presenza di campo magnetico esterno occorre fare delle distinzioniLa maggior parte dei materiali ha atomi con momento magnetico nullo. In questi materiali, l’effetto di un campo esterno è quello di deviare la traiettoria degli elettroni in moto (forza di Lorenz), inducendo una variazione di velocità (l’elettrone si allontana dal nucleo) e quindi una diminuzione della frequenza di rotazione (precessione di Larmor)L’effetto complessivo è una diminuzione del momento magnetico, che va ad opporsi leggermente al campo magnetico esternoTali materiali sono chiamati diamagnetici (in genere hanno un numero pari di elettroni e struttura simmetrica)
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#67,67,"Materiali paramagnetici
68I materiali paramagnetici hanno atomi con momento angolare intrinseco diverso da zero
I materiali paramagnetici sono caratterizzati da un numero dispari di elettroni  o da strutture atomiche asimmetricheGli atomi si comportano come dipoli magnetici che per effetto di un campo magnetico esterno tendono ad allinearsi  con il campo magnetico esterno, contribuendo ad aumentarne leggermente il valore
B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#68,68,"Vettore magnetizzazione
69Definiamo il vettore magnetizzazione come il prodotto del momento angolare intrinseco medio del materiale per il numero di atomi per unità di volume⟨⃗m⟩⃗M=n⟨⃗m⟩=Ndτ⟨⃗m⟩dipende dai momenti magnetici orbitali e di spinIl campo magnetico totale nella materia dipenderà dal vettore magnetizzazione:⃗B=⃗B0+μ0⃗MPossiamo definire la densità di corrente di magnetizzazione⃗jM=⃗∇∧⃗MDa cui ricaviamo le relazione⃗∇∧⃗B=⃗∇∧(⃗B0+μ0⃗M)==⃗∇∧⃗B0+μ0⃗∇∧⃗M=Legge di Ampère in forma locale=μ0⃗J+μ0⃗JM"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#69,69,"Il vettore H
70⃗∇∧⃗B=μ0(⃗J+⃗JM)Il campo magnetico totale B è generato dalle correnti di conduzione e dalle correnti di magnetizzazione
Partendo dalla relazione⃗∇∧⃗B=μ0⃗J+μ0⃗∇∧⃗M⃗∇∧(⃗B−μ0⃗Mμ0)=⃗JDefiniamo il vettore H che descrive il campo magnetico nella materia,  in funzione solo delle correnti di conduzione lungo i fili⃗H=⃗B−μ0⃗Mμ0=⃗Bμ0−⃗M⃗∇∧⃗H=⃗J⃗B=μ0⃗H+μ0⃗M"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#7,7,"Poprietà del campo magnetico
8La forza magnetica tra due calamite potrebbe essere descritta con una formula simile alla legge di Coulomb (fine 1700)⃗FM=kMm1m2r2̂urm1 e m2 sono le “cariche magnetiche” kM è una costante magneticaLa forza magnetica è proporzionale al prodotto delle cariche magnetiche ed inversamente proporzionale al quadrato della distanza Attrattiva per cariche magnetiche opposte, repulsiva per cariche magnetiche ugualiUnica analogia con forza elettrostatica di Coulomb!!"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#70,70,"Magnetismo nella materia
71Nei materiali diamagnetici e paramagnetici, omogenei e isotropi i campi B H e M sono paralleli, e vengono espressi dalle relazioni⃗B=μrμ0⃗HDove:μrPermeabilità magnetica relativa⃗M=(μr−1)⃗H=χm⃗Hχm=(μr−1)Suscettività magnetica   {negativa per diamagneticipositiva per paramagnetici(molto piccola 10-4 —10-6)⃗M=(1μ0−1μ0μr)⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#71,71,"Materiali ferromagnetici
72I materiali ferromagnetici microscopicamente hanno una configurazione elettronica per cui si creano forti interazioni tra momenti orbitali e momenti di spinTali interazioni comportano che momenti magnetici di atomi adiacenti si “accoppiano”, aumentando considerevolmente il loro effetto magnetico rispetto al singolo atomoAll’interno del materiale si creano regioni formate da numerosi dipoli allineati (domini di Weiss) I domini di Weiss hanno tipicamente volumi di 10-12 —10-12 m3 e contengono 1017 —1011 atomi 
Se il materiale non ha subito magnetizzazione, le direzioni dei momenti sono casuali"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#72,72,"73Materiali ferromagneticiQuando un materiale ferromagnetico viene posto in un campo magnetico esterno i momenti si allineano con il campo magnetico, generando un allargamento (una fusione) dei domini di Weiss
Ponendo campi magnetici sempre più intensi, si arriva ad una condizione di saturazioneIl materiale mantiene una magnetizzazione residua anche fuori dal campo magneticoI domini di Weiss vengono distrutti se il materiale viene riscaldato fino ad una temperatura critica (di Curie),che per il Fe vale ~1000°K"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#73,73,"Ciclo di isteresi
74Per i materiali ferromagnetici la permeabilità magnetica non è costante, può essere molto elevata e dipende dalle correnti che generano il campo esterno e dalla storia di magnetizzazione. Inseriamo un cilindro di materiale ferromagnetico in un solenoide:
La curva a è detta di prima magnetizzazionediminuendo il campo H fino ad azzerarlo (curva b) nel materiale si ha una magnetizzazione residuaInvertendo il campo H, si raggiunge un valore critico HC per cui la magnetizzazione è nulla H generato da corrente nel solenoideCampo B del ferromagneteCampo M del ferromagnete"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#74,74,"Memorie di massa magnetiche
75I supporti magnetici sono largamente utilizzati per l’archiviazione dei datiPer esempio gli hard disk sono formati da dischi di alluminio o vetro rivestiti da una pellicola di materiale ferromagneticoLa memorizzazione dell’informazione avviene associando un bit di magnetizzazione (verso di magnetizzazione) su un certo numero di domini di WeissLa densità di informazione è data dal numero di domini di Weiss che costituiscono un singolo bit, moltiplicato per la loro estensione superficiale media, rapportato alla superficie di archiviazione disponibileL’accesso ai dati avviene utilizzando testine magnetoresistive che variano la resistenza al variare del campo magnetico (in lettura) e viceversa (in scrittura)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#75,75,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
76"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#8,8,"Poli magnetici
9
Sperimentalmente, se si spezza una calamita si otterranno due nuove calamiteI poli magnetici esistono sempre a coppie di eguale valore e segno opposto: dipoli magneticiFino ad ora non è stato mai osservato un polo magnetico isolato (monopolo magnetico)Conseguenza: il campo magnetico ha proprietà molto diverse dal campo elettrostatico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#9,9,"Legge di Gauss per il campo magnetico
10
Le linee del campo magnetico sono sempre chiuse  (non possiamo isolare singoli poli magnetici)Il campo magnetico è solenoidale⃗∇⋅⃗B=0Di conseguenza (thm divergenza) scegliendo una qualunque superficie chiusa∬S⃗B⋅̂ndS=0La densità volumetrica di cariche magnetiche è sempre nulla (solo dipoli)S"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#0,0,1 Campi elettrici e magnetici variabili nel tempo CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#1,1,"Campi elettrici in condizioni stazionarie
2⃗∇⋅⃗E=ρε0Legge di Gauss per il campo elettrico Forma integrale: il flusso del campo elettrico attraverso una superficie chiusa è proporzionale alla carica elettrica contenuta nella superficie Forma differenziale: Le cariche elettriche generano il campo elettricoΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#10,10,"Legge di Ampère e equazione di continuità
11⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza della densità di corrente compare nell’equazione di continuità (si veda cap. su correnti)In condizioni stazionarie (indipendenti dal tempo), la densità di carica è costante e la sua derivata è nulla.  In tale situazione , quindi ritroviamo che la legge di Ampère continua ad essere valida in condizioni stazionarie. Cosa succede nel caso più generale, in condizioni non necessariamente stazionarie?⃗∇⋅⃗𝚥=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#11,11,"Legge di Ampère in condizioni non stazionarie
12⃗∇⋅⃗𝚥+∂ρ∂t=0Sostituiamo nell’equazione di continuità e invertiamo gli ordini di derivazioneDalla legge di Gauss in forma locale                             ricaviamo  ⃗∇⋅⃗E=ρε0ρ=ε0⃗∇⋅⃗E⃗∇⋅⃗𝚥+∂∂t(ε0⃗∇⋅⃗E)=0⃗∇⋅⃗𝚥+ε0⃗∇⋅∂⃗E∂t=0⃗∇⋅(⃗𝚥+ε0∂⃗E∂t)=0il vettore  ha sempre divergenza nulla!(⃗𝚥+ε0∂⃗E∂t)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#12,12,"tale vettore è la somma di due termini: • densità di corrente di conduzione    (dovuta a cariche in moto) • densità di corrente di spostamento              (dovuta a variazione di campo elettrico)Legge di Ampère-Maxwell
13(⃗𝚥+ε0∂⃗E∂t)⃗𝚥ε0∂⃗E∂t⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tAggiungendo il termine di densità di corrente di spostamento nell’equazione di Ampere, otteniamo la legge di Ampère-Maxwell"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#13,13,"Legge di Ampère-Maxwell
14⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tIl rotore del campo magnetico è proporzionale alla somma della densità di corrente di conduzione  e alla variazione del campo elettrico⃗∇⋅(μ0⃗𝚥+μ0ε0∂⃗E∂t)=0In altre parole, il campo magnetico può essere generato da cariche in moto e da campi elettrici variabili nel tempoLa legge di Ampère-Maxwell è valida sempre, sia in regime stazionario che non stazionario. Infatti la divergenza della somma dei termini di densità di corrente di spostamento e conduzione è sempre nulla"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#14,14,"Corrente di spostamento
15A partire dalla densità di corrente di spostamento ⃗𝚥S=ε0∂⃗E∂tDefiniamo la corrente di spostamento come il flusso della densità di corrente attraverso una superficie aperta S: La corrente di spostamento è proporzionale alla variazione del flusso del campo elettrico e non dipende da cariche in movimento.Si osserva una corrente di spostamento nelle regioni di spazio in cui c’è un campo elettrico variabile. Esempio: all’interno di un condensatore in regime transotorio (carica/scarica)is=∬S⃗𝚥s⋅̂ndS=∬Sε0∂⃗E∂t⋅̂ndS=ε0ddt∬S⃗E⋅̂ndS=ε0dΦS(⃗E)dt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#15,15,"Legge di Ampère-Maxwell in forma integrale
16In forma integrale, la circuitazione del campo magnetico lungo una linea chiusa rimane proporzionale alla somma delle correnti concatenate, considerando sia le correnti di conduzione che le correnti di spostamento∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#16,16,"Corrente di spostamento in condensatore
17Consideriamo un circuito RC in fase di scarica. Inizialmente sul condensatore si ha una carica Q0.  Alla chiusura dell’interruttore la carica sul condensatore varia con la legge:TCRQ(0)=Q0Q(t)=Q0e−tRCNel circuito si avrà una corrente di conduzione (dovuta alle cariche che fuoriescono dal condensatore):ic(t)=dQ(t)dt=−Q0RCe−tRC"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#17,17,"Corrente di spostamento in condensatore
18Q(t)Supponiamo che il condensatore sia a facce piane e parallele. Nel condensatore carico con carica Q(t) c’è un campo elettrico (normale alla superficie S delle armature):Il campo elettrico dipende dal tempo, quindi nel condensatore si ha una densità di corrente di spostamento:  ⃗E=σε0̂n=Q(t)ε0Ŝn=Q0e−tRCε0Ŝn⃗𝚥s=ε0∂⃗E∂t=ε0∂∂t(Q0e−tRCε0S)̂n=−Q0SRCe−tRĈned una corrente di spostamento:is(t)=∬S⃗𝚥s⋅̂ndS=∬S−Q0SRCe−tRĈn⋅̂ndS=−Q0SRCe−tRC∬SdS=−Q0RCe−tRC⃗E"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#18,18,"Corrente di spostamento in condensatore
19ic(t)=is(t)=−Q0RCe−tRCNell’esempio del condensatore si trova che la corrente di conduzione e la corrente di spostamento hanno lo stesso valoreTale risultato è conseguenza dell’equazione di continuità, che lega le correnti alle variazioni di carica.𝛴⃗Eic(t)is(t)
S1S2𝛤Se infine poniamo 𝛴=S1+S2, ritroviamo la validità generale della legge di Ampère (Maxwell) Considerando una qualsiasi superficie chiusa 𝛴 che “avvolge” metà condensatore∮Γ⃗B⋅d⃗l=μ0∬S1⃗𝚥c⋅̂ndS=μ0∬S2⃗𝚥s⋅̂ndS∬Σ(⃗𝚥c+⃗𝚥s)⋅̂ndS=∬Σ(⃗𝚥c⋅̂n+⃗𝚥s⋅̂n)dS=∬Σ(jc−js)dS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#19,19,"Esempio
206.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2 r2)(c2 b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=""0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0""0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2 S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e t/⌧dR⌧))"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#2,2,"Campi elettrici in condizioni stazionarie
3Conservatività del campo elettrostatico⃗∇∧⃗E=0La circuitazione del campo elettrostatico lungo qualsiasi linea chiusa è nullaIrrotazionalità del campo elettrostatico: implica che il campo è conservativo e che possiamo definire il potenziale elettrostatico V tale che ⃗E=−⃗∇V∮Γ⃗E⋅d⃗l=0Il campo elettromotore in una pila non è conservativo. Tale relazione è verificata solamente nel caso stazionario. "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#20,20,"Interazioni tra magneti e circuiti
21Abbiamo visto che le correnti generano campi magnetici (prima legge di Laplace, Biot-Savart) E’ vero anche il contrario?Se teniamo un magnete fermo vicino ad un circuito, in esso non si osserva corrente
Se muoviamo il magnete verso il circuito, allora si osserva una corrente (nell’intervallo in cui il magnete è in movimento)
Il movimento in verso opposto, “induce” nel circuito una corrente di segno opposto"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#21,21,"Interazioni tra circuiti percorsi da corrente
22
Un effetto analogo si osserva tra due circuiti posti in vicinanzaNel circuito di sinistra si osserva una corrente per un breve intervallo di tempo dopo la chiusura/apertura dell’interruttore (effetto transitorio con corrente variabile nel tempo)
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#22,22,"Correnti indotte
23
Estraendo una spira fatta di materiale conduttore da una regione in cui è presente un campo magnetico, si misura una corrente sulla spira  • si ha corrente anche se il campo magnetico è uniforme• la corrente è massima se il piano della spira è ortogonale al campo magnetico• la corrente è nulla se il piano della spira è parallelo al campo magneticoDal momento che sul conduttore ci sono cariche libere, proviamo a spiegare il fenomeno in termini di forza di Lorentz"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#23,23,"Correnti indotte
24⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BConsideriamo un sistema formato da due binari conduttori, paralleli e connessi elettricamente⃗vPoniamo una barretta conduttrice ortogonale ai binari e mettiamola in movimento con velocità costanteSe il sistema è posto in un campo magnetico (costante, uniforme, ortogonale al piano del circuito) nel circuito circola corrente, come se ci fosse un generatore di forza elettromotrice"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#24,24,"Correnti indotte
25⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗FLe cariche libere sulla barretta sentono una forza di Lorentz:⃗v⃗F=qe⃗v∧⃗BLe cariche in un tratto dl è come se fossero sottoposte agli effetti di un campo elettromotoreN.B. gli elettroni si muovono verso l’alto, quindi la corrente convenzionalmente circola in verso orariod⃗ldℰ=⃗E⋅d⃗l=⃗Fqe⋅d⃗l=⃗v∧⃗B⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#25,25,"Correnti indotte
26⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BLa velocità può essere scritta come d⃗ld⃗x⃗v=d⃗xdtIn un intervallo dt, la barretta si sarà spostata di un tratto dxdℰ=(⃗v∧⃗B)⋅d⃗l=(d⃗xdt∧⃗B)⋅d⃗lUtilizzando le proprietà del prodotto misto:dℰ=(d⃗xdt∧⃗B)⋅d⃗l=(d⃗l∧d⃗xdt)⋅⃗B=solo dx dipende dal tempo, B e  dl sono costanti=ddt[(d⃗l∧d⃗x)⋅⃗B]⃗v"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#26,26,"Induzione elettromagnetica
27⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗Bd⃗ld⃗x
d⃗l∧d⃗x=−̂n(dldx)=−̂ndSNegativo, perché “entrante” (verso opposto a B)dℰ=ddt[⃗B⋅(d⃗l∧d⃗x)]dℰ=−ddt[⃗B⋅̂ndS]⃗B⋅̂ndS=dΦS(⃗B)⃗vdSFlusso infinitesimo del campo magnetico attraverso dS"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#27,27,"Induzione elettromagnetica
28⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ 
ℰ=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtNel circuito si genera una forza elettromotrice indotta opposta (segno meno) alla variazione del flusso del campo magnetico concatenato con la spiraIntegrando su tutta l’area S spazzata dalla barretta 
Si può dimostrare che tale relazione è valida ogni volta in cui si verifica una variazione temporale del flusso concatenato del campo magnetico⃗Bd⃗ld⃗x⃗vS"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#28,28,"Legge di Faraday-Neumann-Lenz
29La variazione temporale del flusso di un campo magnetico “induce” una forza elettromotriceℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtLa forza elettromotrice indotta si oppone alla variazione del flusso che l’ha generata Tale legge rappresenta un ulteriore metodo per generare una corrente in un conduttore  (in aggiunta a forze elettrochimiche di pile e batterie)Il segno meno nell’equazione (storicamente attribuito di Lenz) è conseguenza del 3° principio della dinamica (azione-reazione) e quindi della conservazione dell’energia"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#29,29,"Induzione elettromagnetica
30ℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dt1)area della spira variabile nel tempo 2)campo magnetico variabile nel tempo 3)moto relativo di una spira rispetto ad  campo magnetico  Con aggiunta di tutte le possibili combinazioni delle situazioni elencateConsiderando un generico circuito chiuso (una spira), il flusso del campo magnetico concatenato con la spira può variare al verificarsi di tre tre principali situazioni:"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#3,3,"Campi magnetici in condizioni stazionarie
4⃗∇⋅⃗B=0Legge di Gauss per il campo magnetico Il flusso del campo magnetico attraverso una superficie chiusa è sempre nullo non possiamo isolare cariche magnetiche (monopoli)Il campo magnetico ha sempre divergenza nulla (è solenoidale). Le linee di campo sono sempre chiuse su loro stesse∬⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#30,30,"Esempio
31Si consideri un circuito rettangolare con un lato di lunghezza L in movimento con velocità v0 costante. La resistenza totale del circuito vale R. Il circuito è completamente immerso in un campo magnetico costante ed uniforme, ortogonale al piano del circuito. Calcolare: a)l’espressione della corrente indotta nel circuito b)la forza necessaria per mantenere la velocità costanteCampo magnetico costante (e uniforme) e area della spira variabile⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ V0 L L6. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza 2R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza L dal conduttore fisso e si muove con velocità V0 costante verso destra. Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   7. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza 2L dal conduttore fisso e  s i  m u o v e  c o n  v e l o c i t à  2 V0 c o s t a n t e  v e r s o  d e s t r a .  Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   8. Un circuito elettrico è costituito da due binari conduttori paralleli di resistenza trascurabile posti ad una distanza 2D, da una conduttore fisso di resistenza 2R e da un’asta metallica AB di resistenza trascurabile che può scorrere senza attrito sui due binari (vedi figura). La posizione dell’asta AB varia nel tempo secondo la r e l a z i o n e  x ( t )  =  2 x0(1 - cosωt), con x0 ed ω costanti positive note. Il circuito è immerso in un campo induzione magnetica B, diretto perpendicolarmente al piano del circuito, la cui intensità varia nel tempo secondo la relazione B(t)=2B0(1 + cosωt), con B0 costante positiva nota. Determinare: a. la forza elettromotrice indotta nel circuito; b. il valore massimo iM dell’intensità di corrente che circola nel circuito; c. la forza che agisce sull’asta AB.       2V0 2L L
V(t) 2R xB2D A⃗B"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#31,31,"Campo magnetico variabile nel tempo e spira ferma
32S2S1Figure 15:7.3Una spira quadrata conduttrice di latol=20 cm e resistenzaR=0.1⌦si trova ad una distanza ﬁssaa=80cm da un ﬁlo rettilineo indeﬁnito percorso da una correntei. Due dei lati della spira sono paralleli al ﬁlo.Calcolare:a) il ﬂusso del campo magnetico generato dal ﬁlo , supponendo che la corrente sia costantei0=3A ( =µ0li02⇡lna+la=2.68·10 8Wb);b) la f.e.m. massima indotta sulla spira supponendo che la corrente sul ﬁlo vari con secondo la leggei(t)=i0cos(!t), con!= 2 rad/s; (Emax=µ0li0!2⇡lna+la=5.36·10 8V)c) la massima potenza dissipata dalla spira, nel caso di corrente variabile nel tempo. (Pmax=E2maxR=2.9·10 14W)7.4Una bacchetta conduttrice di lunghezzaL=9.83cmer e s i s t e n z aR= 415 m⌦viene fatta muovere con velocit` acostantev=4.86 m/s su dei binari conduttori (di resistenza trascurabile) paralleli. La bacchetta si muovein un campo magnetico generato da una correntei= 110Ache scorre in un ﬁlo parallelo ai binari, a distanzaa= 10.2mm. Calcolare:a) la corrente indotta che scorre nella spira; (iind= µ0iv2⇡Rln a+La )b) la forza che bisogna applicare esternamente alla bacchetta per tenerla in moto uniforme; (Fest=µ0iiind2⇡ln a+La )c) confrontare la potenza dissipata sulla bacchetta con la potenza fornita dalla forza esterna. (P=Ri2ind=Fv)7.5Una spira quadrata di latoL=30 cm, resistenzaR=2⌦e massam= 10g, si muove senza attrito suun piano orizzontale con velocit` av0=1 m/s, perpendicolare ad un lato. Ad un certo istantet0la spiraentra in una regione in cui presente un campo magnetico uniforme e costante di moduloB=0.5 T, direttoperpendicolaremente al piano della spira (il bordo della regione con il campo magnetico ` e parallelo al latodella spira che sta entrando, come mostrato in ﬁgura 16). Calcolare:a) la velocit` a della spira nell’istantet0in cui essa ` e entrata completamente nella regione con campomagnetico; (v(t0)=v0 B2L3mR)b) la corrente che percorre la spira nell’istantet0;(i(t0)= BLv(t0)R)c) la potenza dissipata all’istantet0.(P=B2L2v(t0)2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#32,32,"33Campo magnetico costante (non uniforme) e spira in movimento F1) Un circuito rigido quadrato, di lato L=100cm, è costituito di un filo di alluminio (resistività ρ=2.56 10-8 Ωm) di sezione S=10 mm2. Esso si trova nel piano xy con i lati paralleli ai due assi, ed è immerso (nel vuoto) in un campo di induzione magnetica uniforme di modulo Bz= 0,5T diretto lungo l’asse z nel verso positivo, limitato all’area grigia di figura. Il circuito, inizialmente tutto immerso nel campo magnetico, trasla con parallelamente all’asse x con velocità che viene mantenuta costante di modulo V0= 20 cm/s. Calcolare, giustificando:  1) il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) l’intensità  di tale corrente nel circuito durante il moto; 3) l’energia totale dissipata nel circuito per effetto Joule; 4) il lavoro effettuato per portare il circuito completamente fuori del campo.              F2) Una spira rigida a forma di triangolo equilatero di lato L=2m, massa M=100g, e resistenza R=10 Ω ,  s i  m u o v e  c o n  v e l o c i t à  c o s t a n t e  V0 =  1 0  m / s  l u n g o  l ’ a s s e  x .  N e l semipiano delle x positive è presente un campo induzione magnetica uniforme di modulo B=0.5 T diretto lungo z nel verso positivo, mentre nel semipiano delle x negative B è identicamente nullo. Calcolare: 1)  il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) il flusso di B c o n c a t e n a t o  c o n  i l  c i r c u i t o ,  n e l l ’ i s t a n t e  i n  c u i  m e t à  d e l l ’ a r e a  d e l  3) la corrente massima che circola nel circuito durante il moto; 4) l’espressione vettoriale della forza che agisce sul lato BC del circuito, all’istante       ijBv0L
ijBLABCUna spira quadrata conduttrice di lato L e resistenza R si muove con velocità costante v0 in una regione dove è presente un campo magnetico uniforme, limitato ad una regione rettangolare. a)determinare la corrente indotta sulla spira  b)il lavoro per estrarre la spira fuori dalla regione in cui è presente il campo magnetico c)l’energia dissipata per effetto Joule"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#33,33,"Generatore elettrico
34
Consideriamo un sistema di N spire rotanti con velocità angolare costante in un campo magnetico uniformesia S=area delle spire, 𝜑=𝜔t angolo tra vettore normale al piano della spira e campo magneticoin ogni istante il flusso valeΦ(⃗B)=N⃗B⋅̂nS=NBScosφ=NBScosωtnelle spire ci sarà una fem indotta:ℰ=−dΦ(⃗B)dt=−NBS(−ωsinωt)=NBSωsinωt
fem alternata
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#34,34,"Correnti di Foucault
35Le correnti di Foucault (o correnti parassite) si osservano nei conduttori in presenza di campi magnetici il cui flusso varia nel tempo. Esse sono una conseguenza del fenomeno dell’induzione magnetica. Tali correnti sono dovute al moto degli elettroni causato dalle fem indotte nel conduttore
L’effetto di tali correnti è quello di creare campi magnetici che si oppongono alla variazione che le hanno generate: effetto “frenante”Per minimizzare gli effetti delle correnti parassite, occorre “tagliare” il conduttore
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#35,35,"Correnti di Foucault
36Le correnti di Foucault possono anche generare calore per effetto JouleTale meccanismo è alla base dei fornelli ad induzione
Perché non tutte le pentole funzionano sulle cucine ad induzione?"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#36,36,"Forma locale della legge di FNL
37ℰ=∮Γ⃗E⋅d⃗l=∬SΓ⃗∇∧⃗E⋅̂ndSℰ=∮Γ⃗E⋅d⃗l=−ddt∬SΓ⃗B⋅̂ndS=∬SΓ−∂⃗B∂t⋅̂ndS⃗∇∧⃗E=−∂⃗B∂tApplichiamo il teorema di StokesCombinando con la legge di Faraday-Neumann-LenzIl campo E è detto campo elettrico indotto  Un campo magnetico variabile nel tempo è una sorgente di campo elettrico "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#37,37,"Forma locale della legge di FNL
38⃗∇∧⃗E=−∂⃗B∂t• Il campo elettrico indotto dalla variazione di un campo magnetico ha rotore non-nullo: non è conservativoIn ogni punto dello spazio in cui è presente un campo magnetico variabile nel tempo, in quel punto si genera un campo elettrico• Il campo elettrico generato da cariche elettriche ha sempre rotore nullo ed è conservativo (campo elettrostatico)Il campo elettrico può essere generato da campi magnetici variabili nel tempo oppure da cariche elettriche"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#38,38,"Induzione mutua
39Per la prima legge di Laplace, il campo magnetico dipende linearmente dalla corrente che l’ha generato:d⃗B=μ0i4πd⃗l∧̂rr2Il flusso del campo magnetico sarà dunque proporzionale alla corrente:Φ(⃗B)=MiDove M è un coefficiente che dipende solamente dalla geometria (forma) del circuito percorso da correntei⃗B
Se le correnti sono variabili nel tempo:ℰind=−dΦ(⃗B)dt=−Mdidt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#39,39,"Induzione mutua
40Consideriamo due circuiti percorsi da correnti i1 e i2, che generano rispettivamente i campi magnetici B1 e B2 Il flusso di B1 attraverso il circuito 2 èΦ1(⃗B2)=M21i2Φ2(⃗B1)=M12i1Il flusso di B2 attraverso il circuito 1 èi1i2Si può dimostrare che M12=M21=MM è detto coefficiente di mutua induzioneNel sistema internazionale si misura in Henry (H)  1H=Tm2/A"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#4,4,"Campi magnetici in condizioni stazionarie
5∮Γ⃗B⋅d⃗l=μ0conc∑kik⃗∇∧⃗B=μ0⃗𝚥Legge di Ampère la circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate con la linea di circuitazioneIn forma locale, il rotore del campo magnetico è proporzionale alla densità di corrente. Il campo magnetico NON è conservativo Il campo magnetico è generato da correnti (cariche in movimento)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#40,40,"Esempio
41habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#41,41,"Autoinduzione
42i⃗BUn circuito percorso da corrente genera un campo magnetico Tale campo avrà un flusso concatenato con il circuito stessoSe la corrente varia nel temp, nel circuito si genererà una fem autoindottaΦ(⃗B)=LiL è detto coefficiente di autoinduzione (o induttanza) e si misura in Henryℰind=−dΦ(⃗B)dt=−LdidtLa fem autoindotta si oppone alla variazione di corrente che l’ha generata "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#42,42,"Esempio
43Calcolare l’induttanza di un solenoide cilindrico ideale di lunghezza l formato da N spire circolari di raggio r 
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2SlSupponiamo che il solenoide sia percorso da una corrente i(t) variabile nel tempo. Internamente al solenoide vi è un campo magnetico (dipendente dal tempo): Il flusso del campo attraverso una singola spira vale ⃗BS=πr2area di una spiraB(t)=μ0Nli(t)Φspira(⃗B(t))=B(t)S=μ0Nli(t)πr2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#43,43,"Esempio
44Il flusso attraverso l’intero solenoide sarà pari ad N volte il flusso attraverso una singola spira  
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BΦsolenoide(⃗B(t))=NΦspira(⃗B(t))=Nμ0Nli(t)πr2=μ0N2li(t)πr2L’induttanza L si calcola come il rapporto tra il flusso “autoindotto”  (autoflusso) e la corrente:L=Φsolenoide(⃗B)i(t)=μ0N2lπr2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#44,44,"Esempio
45habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#45,45,"Circuiti con induttanze
46
Un solenoide inserito all’interno di un circuito percorso da corrente variabile nel tempo si comporta come un generatore di forza elettromotrice (fem autoindotta) con polarità opposta alla variazione di corrente
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BSimbolo circuitale dell’induttanza +_𝓔(t)ℰautoindotta=−dΦsolenoide(⃗B(t))dt=−Ldi(t)dtREquazione del circuitoℰ(t)−Ldi(t)dt=Ri(t)ℰ(t)+ℰautoindotta=Ri(t)La fem autoindotta si “oppone” alla variazione di corrente che l’ha generata"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#46,46,"Induttanze in serie
47+_𝓔(t)RL1L2In serie, le due induttanze sono percorse dalla stessa correnteΔV=ΔV1+ΔV2=−L1di(t)dt−L2di(t)dt=−(L1+L2)di(t)dt=−Ltotdi(t)dtDifferenza di potenziale ai capi delle due induttanze
L’induttanza del sistema formato da due (o più) induttanze collegate in serie è uguale alla somma delle singole induttanzeLtot=∑iLitrascuriamo gli effetti di mutua induzione"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#47,47,"Induttanze in parallelo
48
+_𝓔(t)RL1L2In parallelo, le due induttanze sono alla stessa differenza di potenzialetrascuriamo gli effetti di mutua induzionedi1dt=−ΔVL1di2dt=−ΔVL2=−ΔVL1−ΔVL2=i=i1+i2Per la legge dei nodididt=di1dt+di2dt
L’inverso dell’induttanza del sistema formato da due o più induttanze collegate in parallelo è uguale alla somma degli inversi delle singole induttanza 1Ltot=1L1+1L2=−ΔV(1L1+1L2)=−ΔVLtot1Ltot=∑i1Li"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#48,48,"Energia magnetica
49
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗B+_𝓔(t)RL’induttanza percorsa da corrente variabile nel tempo si comporta come un generatore con polarità opposta alla variazione correnteInnalzare la corrente di un valore di equivale a far passare nell’induttanza una carica q in un tempo dt (dq=idt)Per spostare la carica occorre contrastare la fem autoindottaℰautoindotta=−Ldidtδℒ=−ℰautoindottadq=−(−Ldidt)(idt)Occorre fare un lavoro “contro” la forza elettromotrice autoindotta"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#49,49,"Energia magnetica
50Se inizialmente nell’induttanza non circola corrente i(0)=0, per portare il circuito a corrente i occorre compiere un lavoroℒ=∫i0Lidi=12Li2δℒ=−ℰautoindottadq=−(−Ldidt)(idt)Lavoro per aumentare la corrente di un valore di
Il lavoro accumula energia nell’induttanza.Energia magnetica accumulata in un’induttanzaUB=12Li2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#5,5,"Equazioni di Maxwell (caso stazionario)
6⃗∇⋅⃗E=ρε0⃗∇∧⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗B=μ0⃗𝚥Forma locale(differenziale)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#50,50,"Densità di energia magnetica
51
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BS=πr2Ricordando l’espressione dell’induttanza di un solenoideL=μ0N2lSIl campo magnetico vale:B=μ0Nlii=Blμ0NL’energia magnetica sarà pari aUB=12Li2=12(μ0N2lS)(Blμ0N)2=12(μ0N2lS)(B2l2μ20N2)=B22μ0(lS)volume del solenoideL’energia magnetica è il prodotto di una densità di energia per il volume del solenoide"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#51,51,"Densità di energia magnetica
52uB=B22μ0Definiamo la densità di energia del campo magnetico:L’energia magnetica è localizzata in ogni punto dello spazio in cui è presente il campo magneticoUB=∭spaziouBdτL’energia del campo magnetico si calcola come l’integrale sul volume in tutto lo spazio in cui è presente il campo magnetico"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#52,52,"Circuiti RL in regime transitorio
53Come abbiamo fatto per i condensatori, analizziamo un circuito composto da un generatore di forze elettromotrice costante, una resistenza e un’induttanza 
+_T𝓔LR
Inizialmente l’interruttore è aperto (non circola corrente i(0)=0, l’induttanza è scarica)Ad un dato istante iniziale t=0 l’interruttore viene chiuso. Scriviamo l’equazione della maglia:ℰ+ℰind=Riℰ−Ldidt=Ri"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#53,53,"Circuiti RL in regime transitorio
54ℰ−Ldidt=Rididt=−RL(i−ℰR)Separiamo le variabilidi(i−ℰR)=−RLdtIntegriamo tra i(0) e i(t) e tra t=0 e t∫i(t)i(0)di(i−ℰR)=∫t0−RLdtln(i−ℰR)i(t)i(0)=−RLtlni(t)−ℰRi(0)−ℰR=−RLti(t)−ℰRi(0)−ℰR=e−RLtImponendo la condizione iniziale i(0)=0i(t)−ℰR=−ℰRe−RLt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#54,54,"Circuiti RL in regime transitorio
55i(t)=ℰR(1−e−RLt)
Transitori in un Circuito RL. Chiusura del Circuito (IV) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!La quantità # = L/R, che ha le dimensioni di un tempo, viene detta costante di tempo del circuito. i0()=0""fR+i0e!RL0=fR+i0=0""i0=!fRit()=fR!fRe!RLt  it()=fR1!e!RLt""#$%&'
45!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
 Transitori in un Circuito RL. Chiusura del Circuito (V) •!Si ottiene inoltre: VR=Rit()=f1!e!RLt""#$%&'VL=Ldidtt()=LfR!e!RLt""#$%&'!RL""#$%&'=fe!RLtit()=fR1!e!RLt""#$%&'VRt()=f1!e!RLt""#$%&'VLt()=fe!RLt()****+****it()t!""#!##fRVRt()t!""#!##fVLt()t!""#!##046!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Chiusura del Circuito (VI) tfRi
tfRVfLVt47!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito •!Consideriamo il circuito in figura e supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con l’induttanza L percorsa da una corrente di intensità costante (i = f /R). •!Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione differenziale: •!L’integrale generale è: Ldidtt()+Rit()=0i0()=fR!""##$##  it()=i0e!RLt48!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0ℰRAndamento nella corrente in un circuito RL alla chiusura dell’interruttore L/R ha le dimensioni du un tempo (costante di tempo)inizialmente la corrente è nulla e si porta ad un valore asintoticoℰind=−Ldidt=−LℰRRLe−RLt⟶t→∞0in regime stazionario (t→∞ ) la fem autoindotta si annullal’induttanza si comporta come un filo a resistenza nullanell’induttanza vi è immagazzinata un’energia magneticaUB=12Li2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#55,55,"56Circuiti RL in regime transitorioSia dato un circuito formato da un condensatore e un’induttanza Inizialmente l’interruttore T è aperto, l’induttanza è carica con UB=UoCalcoliamo quanto vale l’energia dissipata sulla resistenza L’equazione della maglia alla chiusura dell’interruttore èTLR
ℰind=Ri−Ldidt=Rididt=−RLiRisolvendo l’eq. differenziale per separazione delle variabili:dii=−RLdti(t)=i(0)e−RLtlni(t)i(0)=−RLt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#56,56,"57Circuiti RL in regime transitorioi(t)=i(0)e−RLtUB=12Li(0)2La corrente iniziale si ricava dalla condizione iniziale di energia immagazzinata nell’induttanza
Transitori in un Circuito RL. Apertura del Circuito (II) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!Si ottiene inoltre: i0()=fR""i0e!RL0=i0=fR""i0=fR it()=fRe!RLtVR=Rit()=fe!RLtVL=Ldidtt()=LfRe!RLt!RL""#$%&'=!fe!RLt
49!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (III) •!Riassumendo: 
•!La corrente che scorre nel circuito dopo che è stato escluso il generatore di tensione prende il nome di extracorrente di apertura. it()=fRe!RLtVRt()=fe!RLtVLt()=!fe!RLt""#$$$%$$$it()t!""#!##0VRt()t!""#!##0VLt()t!""#!##0
50!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (IV) fRti
tfRVf!LVt51!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (V) •!Se dopo avere escluso il generatore il circuito rimane aperto, si osserva una scarica elettrica tra i contatti dell’interruttore. •!Il motivo è nel fatto che il flusso del campo magnetico nell’induttanza passa in un tempo estremamente breve dal valore iniziale f/R al valore finale 0. •!Segue che la derivata          è estremamente elevata, e con essa è estremamente elevata la f.e.m. autoindotta: ft()=!L""i""t=!L0!fR""t""t#0$#$$%  didt
52!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0i(0)=2UBLi(0)L’energia dissipata sulla resistenza per effetto Joule durante l’intero processo di scarica:UR=∫∞0Ri2dt=R∫∞0(i(0)e−RLt)2dt=R∫∞0i2(0)e−2RLtdt=R2UBL∫∞0e−2RLtdt=R2UBL[−L2Re−2RLt]∞0=UBTutta l’energia accumulata nell’induttanza viene dissipata per effetto Joule sulla resistenza"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#57,57,"Esempio
58habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#58,58,"Esempio
59  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:4"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#59,59,"Le equazioni di Maxwell
60⃗∇⋅⃗E=ρε0∬S⃗E⋅̂ndS=QSε0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t∮Γ⃗E⋅d⃗l=−ddt∬S⃗B⋅̂ndS∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tForma differenzialeForma integrale∬S⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#6,6,"Equazioni di Maxwell (caso stazionario)
7∮Γ⃗E⋅d⃗l=0∮Γ⃗B⋅d⃗l=μ0conc∑kikForma integrale∬S⃗E⋅̂ndS=QSε0∬S⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#60,60,"Le equazioni di Maxwell
61Le quattro equazioni di Maxwell descrivono completamente l’elettromagnetismo A partire da esse è possibile ricavare tutte le leggi dell’elettromagnetismo, dall’elettrostatica, alle correnti, alle forze elettriche e magnetiche Dalle equazioni di Maxwell si evince che i campi elettrico e magnetico sono strettamente legati tra di loro e che essi sono due modi di manifestarsi della stessa entità chiamata campo elettromagnetico Partendo dalle equazioni di Maxwell, si dimostra che il campo elettromagnetico si propaga attraverso onde elettromagnetiche, le quali hanno sempre una componente di campo elettrico e una di campo magnetico"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#61,61,"Argomenti Facoltativi
62• Equazione delle onde elettromagnetiche • Onde elettromagnetiche piane • Teorema di Poynting ed energia trasportata dalle onde elettromagnetiche"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#62,62,"Onde elettromagnetiche
63Prendiamo in considerazione le quattro equazioni di Maxwell in  assenza di cariche e di correnti di conduzione⃗∇⋅⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t⃗∇∧⃗B=μ0ε0∂⃗E∂t∇2⃗E=ε0μ0∂2⃗E∂t2Combinando le quattro relazioni e utilizzando le proprietà delle operazioni tra operatori si ricavano le due equazioni di D’Alambert per campo elettrico e magnetico∇2⃗B=ε0μ0∂2⃗B∂t2ε0μ0=1c2c=3×108 m/s velocità della luce nel vuoto"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#63,63,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
64"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#7,7,"Legge di Ampère su condensatore
8Scriviamo la legge di Ampère in funzione della densità di corrente ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSTale legge deve essere vera per qualsiasi superficie aperta S avente per bordo la linea chiusa 𝛤Applichiamo tale legge in un circuito con condensatore:
S1S2𝛤S1 interseca il filo  S2 passa nell’intercapedine del condensatore (senza intersecare il filo) Entrambe hanno come bordo la linea chiusa 𝛤"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#8,8,"Legge di Ampère su condensatore
9
S1S2𝛤In condizioni stazionarie, nei rami di circuiti con condensatori non circola corrente quindi la circuitazione è nulla: legge di Ampère è soddisfatta per entrambe le superfici Cosa succede in regime transitorio, quando si ha una corrente:                   
La legge di Ampère                                         è valida solo in condizioni stazionarie ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSi(t)=ℰRe−tRCIn tal caso il flusso attraverso S1 è diverso da zero, mentre risulta nullo attraverso S2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#9,9,"Legge di Ampère
10Oltre al caso del condensatore, la legge di Ampère presenta un altro problema formale⃗∇∧⃗B=μ0⃗𝚥⃗∇⋅(⃗∇∧⃗B)=μ0⃗∇⋅⃗𝚥⃗∇⋅(⃗∇∧⃗B)=0Si dimostra facilmente che la divergenza del rotore di un campo vettoriale è sempre nulla (qualunque sia il campo)⃗∇⋅⃗𝚥=?Non è vero invece che la divergenza della densità di corrente sia sempre nulla In quali condizioni è nulla? (il vettore densità di corrente è solenoidale?) Applicando l’operatore divergenza ad entrambi i membri dell’equazione di Ampère in forma differenziale:"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#0,0,"Brevi appunti di Fondamenti di
Automatica
prof. Stefano Panzieri
Dipartimento di Ingegneria
Universit a degli Studi \ROMA TRE""
UNIVERSI TÀ DEGLI  STUDIROMA
TRE
15 marzo 2022
1"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#1,1,"Stefano Panzieri
Indice
Indice 2
1 La Trasfomata di Laplace e la Funzione
di Trasferimento 3
1.1 Introduzione . . . . . . . . . . . . . . . . . 3
1.2 Una trasformata elementare . . . . . . . . 5
1.3 Alcune propriet a . . . . . . . . . . . . . . 8
1.4 Trasformata dell'impulso . . . . . . . . . . 15
1.5 Trasformate dei polinomi . . . . . . . . . . 17
1.6 Inversione della Trasformata di Laplace . . 19
1.7 Andamento delle antitrasformate nel tempo 23
1.8 Applicazione delle Trasformate di Laplace
alle equazioni dierenziali . . . . . . . . . 27
1.9 Un esempio: il carrello . . . . . . . . . . . 36
1.10 Esempi di funzioni di trasferimento . . . . 40
Rev. 0.3 Appunti di Automatica 2 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#10,10,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Traslazione nel tempo
Un risultato duale del precedente  e dato dalla propriet a di
traslazione nel tempo. Notiamo che  e meglio premoltipli-
care la funzione f(t) per un gradino unitario per evitare
che, traslando a destra, rientri nell'integrale della trasfor-
mata una quantit a diversa da zero. Immaginando che a
sia maggiore di zero:
L f 1(t a)f(t a)g=e asF(s) (1.11)
Dimostrazione: dalla denizione si ha
1Z
0  1(t a)f(t a)e stdt
posto=t a, ovverot=+asi ottiene:
1Z
 a  1()f()e se sad=F(s)e as
L'estremo inferiore  e ovviamente minore di zero per cui
pu o essere sostituito, vista la presenza del gradino in zero,
con 0 .z
Convoluzione
L'operatore di convoluzione  e molto utilizzato nell'ambi-
to dello studio dei sistemi lineari deniti da un'equazione
Rev. 0.3 Appunti di Automatica 11 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#11,11,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
dierenziale lineare a coecienti costanti. Abbiamo gi a
visto, infatti, che l'uscita di un sistema descritto dalla
sua risposta impulsiva h(t), e a cui venga applicato un
ingressou(t),  e data dalla convoluzione dei due segnali
y(t) =h(t)u(t): (1.12)
Nell'ambito della Trasformata di Laplace la convo-
luzione viene a semplicarsi e si riduce a un semplice
prodotto, vediamo come.
Supponiamo che la funzione g(t) sia denita come la
convoluzione di due funzioni f1(t) ef2(t):
g(t) =f1(t)f2(t) =tZ
0 f1(t )f2()d (1.13)
il risultato sar a:
L fg(t)g=L ff1(t)g L ff2(t)g (1.14)
Dimostrazione: supponiamo che f1(t) = 0 pert<0,
cosa che abbiamo gi a detto essere vera nell'ambito del-
lo studio che stiamo facendo. Di conseguenza, potremo
riscrivere l'eq. 1.13 estendendo l'estremo superiore:
g(t) =f1(t)f2(t) =1Z
0 f1(t )f2()d
Rev. 0.3 Appunti di Automatica 12 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#12,12,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
A questo punto facciamo la Trasformata di Laplace di
g(t):
G(s) =Z1
t=0 Z1
=0 f1(t )f2()d
e stdt
=Z1
=0 f2()Z1
t=0 f1(t )e stdt
d
=Z1
=0 f2()F1(s)e sd
=F1(s)Z1
=0 f2()e sd=F1(s)F2(s) (1.15)
che dimostra chiaramente l'eq. 1.14 z
Notiamo che, grazie a questa propriet a, la relazione
1.12 diventer a semplicemente:
Y(s) =H(s)G(s): (1.16)
Derivazione
Vediamo adesso cosa succede quando proviamo a trasfor-
mare una funzione derivata rispetto al tempo. Il risultato
 e il seguente:
L d
dtf(t)
=sF(s) f(0 ) (1.17)
Dimostrazione: Notiamo che
d
dt 
f(t)e st
=df(t)
dte st f(t)se st
Rev. 0.3 Appunti di Automatica 13 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#13,13,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
e quindi, integrando per parti,
L d
dtf(t)
=Z1
0 df(t)
dte stdt=
=Z1
0 d
dt 
f(t)e st
dt+Z1
0 f(t)se stdt
=
f(t)e st1
0 +sF(s)
= f(0 ) +sF(s) (1.18)
che dimostra l'eq. 1.17 z
Si possono ottenere, con un procedimento analogo,
anche le seguenti propriet a:
L d2
dt2f(t)
=s2F(s) sf(0 ) df
dt
t=0 (1.19)
L d3
dt3f(t)
=s3F(s) s2f(0 ) sdf
dt
t=0  d2f
dt2
t=0 
(1.20)
Integrazione
Questa  e, invece, la trasformata di Laplace di una fun-
zione integrata tra 0 et.
L Zt
0 f()d
=1
sF(s) (1.21)
Dimostrazione: Dalla trasformata della convoluzione
L Zt
0 f()g(t )d
=F(s)G(s)
Rev. 0.3 Appunti di Automatica 14 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#14,14,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
se poniamo g(t) = 1(t)
L Zt
0 f() 1(t )d
=F(s)1
s
L Zt
0 f()d
=F(s)1
s
z
1.4 Trasformata dell'impulso
L'impulso matematico di Dirac 0(t)  e il \limite"" di una
distribuzione ad area costante e unitaria e per questo non
pu o essere considerato una vera e propria funzione. L'im-
pulso rimane denito per lo pi u tramite le sue propriet a,
come ad esempio questa che fu data per primo proprio
da Dirac: Z1
 10(x)(x)dx=(0) (1.22)
Se volessimo denire una distribuzione (successione) di
funzioni che abbiano come \limite"" l'impulso di Dirac do-
vremmo ricorrere, ad esempio, a delle funzioni Gaussiane
come le seguenti:
0(x) = lim
k!1r
k
e kx2
Rev. 0.3 Appunti di Automatica 15 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#15,15,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Abbiamo per o usato la parola limite in maniera impro-
pria, in quanto questa denizione della 0(x) non  e pro-
priamente formale. E' invece vero il seguente limite che
generalizza l'eq. 1.22:
Zb
a0(x)f(x)dx= lim
k!1Zb
ar
k
e kx2f(x)dx (1.23)
Adesso, abbiamo gi a detto che l'uscita di un sistema
lineare si pu o scrivere come convoluzione tra la risposta
impulsiva e l'ingresso, ovvero:
y(t) =h(t)u(t) =Zt
0h(t )u()d
Se in ingresso poniamo un impulso d Dirac 0(t) avremo
come uscita:
y(t) =Zt
0h(t )0(t)d=h(t)
da cui comprendiamo anche perch e h(t) viene chiamata
risposta impulsiva.
Se ci chiediamo quale sia la trasformata di Laplace
dell'impulso unitario basta sostituirlo nella denizione
della Trasformata:
L f0(t)g=Zt
0 0()e st=
e st
t=0= 1 (1.24)
Rev. 0.3 Appunti di Automatica 16 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#16,16,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
1.5 Trasformate dei polinomi
Vediamo adesso di denire la Trasformata di Laplace di
una funzione polinomiale. A tale scopo deniamo un ter-
mine generico di grado k 1 utilizzando ancora il simbolo
:
 k(t) =(
0t<0
tk 1
(k 1)!t0(1.25)
perk= 1;2;:::  e una funzione di grado k 1 dit.
Poich e per k= 1;2;:::
d
dttk
k!=tk 1
(k 1)!
sfruttando la propriet a della trasformata dell'integrale
L tk
(k)!
=L Ztk 1
(k 1)!dt
=1
sL tk 1
(k 1)!
(1.26)
Per k=1 a destra nell'eq. 1.26 c' e la trasformata di Lapla-
ce della costante  1(t), secondo l'eq. 1.25, che abbiamo
gi a visto essere pari a 1 =s. Per cui, sempre per k= 1 la
trasformata della rampa lineare  2, pari a zero prima di
Rev. 0.3 Appunti di Automatica 17 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#17,17,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
t= 0 e poi pari a tpert>0 varr a 1=s2. Riassumendo:
L f0(t)g= 1 (impulso) (1.27)
L f 1(t)g=1
s(gradino) (1.28)
L f 2(t)g=1
s2(rampa) (1.29)
L f 3(t)g=1
s2(rampa parabolica) (1.30)
In generale
L f k(t)g=L tk 1
(k 1)!
=1
sk(1.31)
oppure
L 
tk	
=k!
sk+1
Polinomi per esponenziali
Vediamo cosa succede se moltiplichiamo un polinomio
per un esponenziale:
L t(k 1)ept
(k 1)!
=1
(s p)k(1.32)
Rev. 0.3 Appunti di Automatica 18 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#18,18,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Dimostrazione:
L t(k 1)ept
(k 1)!
=1Z
0 t(k 1)ept
(k 1)!e stdt
=1Z
0 t(k 1)
(k 1)!e (s p)tdt
postos p=
1Z
0 t(k 1)
(k 1)!e tdt=1
k=1
(s p)k
z
1.6 Inversione della Trasformata
di Laplace
L'inversione della Trasformata di Laplace  e un proble-
ma che si pone, ad esempio, nel calcolo dell'uscita di
un sistema lineare. Infatti, una volta che si sia trovata
l'espressione dell'uscita nel dominio di Laplace, normal-
mente utilizzando la relazione 1.16, possiamo voler ritor-
nare nel dominio del tempo per calcolarne e gracarne
l'andamento.
Rev. 0.3 Appunti di Automatica 19 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#19,19,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Ovviamente esiste una formulazione integrale dell'an-
titrasformata di Laplace, chiamata anche integrale di Brom-
wich o formula inversa di Mellin, che  e data da questo
integrale di linea:
L 1fF(s)g=1
2ilim
T!1Z+iT
 iTestF(s)ds (1.33)
dove l'integrazione avviene lungo la linea verticale <(s) =
nel piano complesso, con maggiore della parte reale di
tutte le singolarit a di F(S). Questo assicura che la li-
nea di contorno sia nella regione di convergenza della
Trasformata di Laplace.
Tuttavia, l'applicazione di questo integrale non risulta
necessaria nel momento in cui le funzioni da antitrasfor-
mare siano formate da un rapporto di polinomi, cosa che
succede sempre in ambito sistemi dinamici descritti da
una equazione dierenziale lineare e a coecienti costan-
ti a cui applichiamo come ingresso un qualsiasi polinomio
o una funzione sinusoidale.
In eetti, in questo caso  e pi u semplice ricondurre la
Y(s) a una somma di frazioni elementari che siano simili
alle trasformate gi a note. In particolare, sappiamo gi a
Rev. 0.3 Appunti di Automatica 20 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#2,2,"Capitolo 1
La Trasfomata di
Laplace e la Funzione
di Trasferimento
1.1 Introduzione
Lo strumento della Trasformata di Laplace, che prende
il nome da Pier-Simon Laplace il quale la utilizz o nel-
l'ambito della teoria delle probabilit a in un suo trattato
Th eorie analytique des Probabilit es (1812), fu probabil-
mente introdotta inizialmente da Eulero e divenne molto
popolare nell'ambito delle equazioni dierenziali grazie
a Oliver Heaviside. Si, quello della funzione a gradino,
3"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#20,20,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
come antitrasformare le seguenti funzioni razionali fratte:
Termine elementare  !antitrasformata
1 !0(t)
1
sk !t(k 1)
(k 1)!
1
(s p) !ept
1
(s p)k !t(k 1)ept
(k 1)!
!
s2+!2 !sinwt
s
s2+!2 !coswt
!
(s+a)2+!2 !e atsinwt
s
(s+a)2+!2 !e atcoswt
dove le ultime due sono state ricavate applicando il teore-
ma della traslazione in salle due immediatamente prece-
denti. Come si vede manca ancora qualcosa che ci dia
la possibilit a di antitrasformare una qualsiasi frazione
che a denominatore abbia un termine trinomio con ra-
dici complesse e coniugate e a numeratore un qualunque
polinomio di primo grado. Notiamo per o che combinan-
do linearmente le ultime due con due coecienti bec
Rev. 0.3 Appunti di Automatica 21 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#21,21,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
possiamo scrivere:
bs+c!
(s+a)2+!2=bs+c!
s2+ 2as+a2+!2
 !e at(bsinwt+ccoswt)
dove con una opportuna scelta di a;b;c e!siamo in grado
di rappresentare una qualsiasi frazione del tipo
b1s+b0
s2+a1s+a0
ponendo:b=b1,c!=b0, 2a=a1ea2+!2=a0.
Decomposizione in poli e residui
A questo punto vediamo come sia possibile analizzare una
Trasformata di Laplace espressa come rapporto di polino-
mi il cui grado sia tale da avere il grado del denominatore
pi u alto di quello del denominatore.
In algebra, la decomposizione poli e residui, o decom-
posizione in fratti semplici,  e la conversione di una fun-
zione razionale fratta in una somma di termini elementari
pi u semplici del tipo
R
(s p);R
(s p)n
conpreale o anche numero complesso p=+j!.
Rev. 0.3 Appunti di Automatica 22 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#22,22,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
La decomposizione in poli e residui prevede che i fratti
semplici si compongano utilizzando le radici del denomi-
natore (poli) e siano presenti nella forma
Ri
s pi
nel caso di poli semplici pi, o nella forma
Rn
1
(s pi)+Rn 1
1
(s pi)2++R1
1
(s pi)n
nel caso di poli pidi molteplicit a pari a n.
Il calcolo dei coecienti Rk
i(residui) procede secondo
questa espressione:
Rk
i=1
(k 1)!dk 1
dsk 1[(s pi)nF(s)]
s=pi(1.34)
che nel caso di poli semplici si riduce a
Ri= [(s pi)F(s)]
s=pi(1.35)
1.7 Andamento delle
antitrasformate nel tempo
Al ne di caratterizzare al meglio gli andamenti delle pos-
sibili risposte di un sistema,  e conveniente denire alcuni
Rev. 0.3 Appunti di Automatica 23 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#23,23,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
parametri che ci potranno aiutare a comprendere questi
andamenti e a confrontare in maniera ecace andamenti
dierenti. In particolare, considereremo poli reali e poli
complessi coniugati di molteplicit a pari a uno.
Parametri dei poli reali
Nel caso di trasformate contenenti poli reali semplici del
tipo
Yt(s) =Pbisi
(s p)(:::)=R
(s p)+:::
dove abbiamo supposto che Rsia il residuo del polo p, la
risposta nel tempo conterr a un termine del tipo
y(t) =Rept
che vale nell'origine y(0) =Re la cui derivata, calcolata
sempre nell'origine, vale _ y(0) =Rp. Questo signica che,
ipotizzando p < 0, ovvero una dinamica convergente a
zero, la tangente in 0, di equazione y=Rpx+Rincon-
trer a l'asse delle ascisse esattamente in x= 1
p, come si
vede dalal Fig. 1.1. La grandezza1
pviene chiamata nor-
malmente costante di tempo e indicata con . Il modo
reale convergente con costante di tempo pari a dopo 3
si  e ridotto del 95%, quindi la dinamica si  e quasi esau-
rita. Dopo 6 il valore residuo  e circa pari a 0 :0025R,
praticamente quasi del tutto estinto.
Rev. 0.3 Appunti di Automatica 24 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#24,24,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Figura 1.1: Poli reali
Parametri dei poli complessi e coniugati
Nel caso di trasformate contenente poli complessi e co-
niugati, e quindi radici del tipo p=+j!ep= j!,
avremo
Yt(s) =Pbisi
(s2+a1s+a0)(:::)=R
(s p)+R
(s p)+:::
DoveReRsono i residui, coniugati, dei due poli coniu-
gati.
E' possibile, a questo punto, esprimere i due residui
nella notazione polare modulo e fase
R=jRjej';
R=jRje j';
dove il residuo coniugato  e stato scritto come un nu-
mero che ha lo stesso modulo e fase cambiata di segno.
In questo maniera, scrivendo l'antitrasformata nel modo
Rev. 0.3 Appunti di Automatica 25 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#25,25,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
consueto:
y(t) =jRjej'e(+j!)t+jRje j'e( j!)t
=jRjet[ej(!t+')+e j(!t+')]
= 2jRjet[ej(!t+')+e j(!t+')]
2
= 2jRjetcos(!t+')
che, come gi a visto, porta a una espressione oscillante con
un modulo che pu o convergere a zero oppure divergere a
seconda del segno della parte reale dei poli.
Terminologia
(s p)(s p) =s2 2!s+ (!2+2) =s2+ 2!ns+!2
n
Dove!n e la pulsazione naturale; e  e il coeciente
di smorzamento
dove se1 i poli del sistema sono reali
poi se  e proprio uguale a 1 lo smorzamento  e massimo
e non ci sono oscillazioni
se invece <0 il sistema diverge
Se poi lo smorzamento  e proprio pari a zero ho poli
sull'asse immaginario
p1;2= !np
2!2
n !2
n
Posso poi determinare, attraverso la regola del segno
se le radici sono solo a parte reale negativa, infatti:
Rev. 0.3 Appunti di Automatica 26 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#26,26,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Figura 1.2: Poli complessi e coniugati
se c' e una permanenza del segno ho radici negative,
altrimenti nel caso in cui c' e variazione del segno ho radici
positive
1.8 Applicazione delle
Trasformate di Laplace alle
equazioni dierenziali
Trasformazione di una equazione
dierenziale lineare di ordine n
andny
dtn+::::+a1dy
dt+a0y(t) =bmdmu
dtm+::::+b0u(t)
L h
dny(t)
dtni
=snY(s) sn 1y(0) sn 2y(0) :::: y(n 1)(0) =
snY(s) Pn 1
k=0sn k 1y(k)(0) (dove il termine con la som-
matoria sono le condizioni iniziali)
quindi:ansnY(s)+::::+a1sY(s)+a0Y(s)+CI(n 1)
y(s) =
bmsmU(s) +::::+b0U(s) +CI(m 1)
u (s)
Risolvendo per Y(s) si avr a :
Rev. 0.3 Appunti di Automatica 27 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#27,27,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Y(s) =bmsm+:::+b0
ansn+::::+a0U(s) CIy(n 1)(s)
ansn+::::+a0+CI(m 1)
u (s)
ansn+::::+a0
dove il primo termine lo consideriamo come A il se-
condo come B e il terzo come C
Inoltre notiamo come al denominatore compaiano in
tutti gli addendi, questo  e il polinomio dell'equazione
omogenea.
Denizione dell'evoluzione libera e della
risposta forzata
U(s)Pbisi
Paisi !A
CIyPaisi !B
CIuPaisi !C
I terminiAeCsono nulli se u(t) = 0 quindi B rap-
presenta l'evoluzione libera del sistema; in particolare C
 e nullo seu(t) = 0 pert0.
Visto che il denominatore di Ce diB e lo stesso se
converge l'evoluzione libera converge anche C
Il denominatore di Acontiene i poli di Bpi u quelli
della trasformata dell'ingresso quindi:
I modi presenti nell'uscita sono quelli propri del
sistema pi u quelli dell'ingresso
Rev. 0.3 Appunti di Automatica 28 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#28,28,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Se i modi del sistema convergono a zero nel lungo
periodo rimangono solo quelli dell'ingresso e quindi
il sistema  e stabile
Quindi intuitivamente possiamo dire che un sistema  e
stabile se basta azzerare l'ingresso per riportare il sistema
a riposo.
Denizione della funzione di
trasferimento e di sistema nel senso di
Laplace
La funzione di trasferimento del sistema descritto dall'e-
quazione dierenziale  e:
G(s) =Pbisi
Paisi
Un sistema  e descritto quasi completamente (salvo
cancellazioni) dalla sua funzione di trasferimento
L'analisi della G(s) ci permette di determinare facil-
mente:
La stabilit a asintotica: Re[pi]<0
Velocit a di convergenza: maggiore se Re[pi] minore
Comportamento oscillatorio pi=p
jcomplessi
Rev. 0.3 Appunti di Automatica 29 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#29,29,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Valore pert !1 dell'uscita (regime): lim
s!0sG(s)U(s)
spessou(t) = 1 !U(s) =1
s
Trasfomata di Laplace della
convoluzione e legame tra la trasformata
di Fourier e quella di Laplace
Data:
g(t) =f1(t)
f2(t) =tZ
0 f1(t )f2()d
allora:
L fg(t)g=L ff1(t)g L ff2(t)g
Dimostrazione:
G(s) =Z1
0 Z1
0 f1(t )f2()d
e stdt=Z1
0 f2()Z1
0 f1(t )e stdt
d=
=Z1
0 f2()F1(s)e sd=F1(s)Z1
0 f2()e sd=F1(s)F2(s)
Il valore di g(t) int0dipende dal passato
Serie di Fourier:
f(t) =F(tKT) periodica di periodo T
f(t) =A0
2+P1
R=1
Akcos2k
Tt+Bksin2k
Tt
Rev. 0.3 Appunti di Automatica 30 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#3,3,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
che invent o per calcolare cosa succedesse a un circuito
elettrico quando veniva improvvisamente alimentato.
Comunque sia andata, oggi la Trasformata di Laplace
la studiamo perch e ancora introduce notevoli semplica-
zioni nell'analisi e la ricerca di soluzione delle equazioni
dierenziali lineari e ci consente, inoltre, di fare un po'
di analisi armonica, ovvero analizzare il comportamento
di un sistema quando applichiamo un segnale sinusoi-
dale. Inoltre, nello studio della stabilit a di un sistema
a controreazione porta a dei risultati molto semplici da
utilizzare.
Il presente Capitolo  e dedicato alla denizione del-
la Trasformata di Laplace, la presentazione di alcune sue
propriet a, e la sua applicazione alle equazioni dierenziali
lineari. Immaginando che un sistema possa essere descrit-
to con una equazione dierenziale lineare vedremo come,
utilizzando Laplace, lo stesso possa essere espresso come
funzione di trasferimento , ovvero un oggetto matematico
ottenuto da una particolare trasformata di Laplace.
Denizione
La trasformata di Laplace unilatera, associata a una fun-
zione di variabile reale, come pu o essere nel nostro caso
Rev. 0.3 Appunti di Automatica 4 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#30,30,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
A0
2=1
TT
2R
 T
2f(t)dt[valore medio]
Ak=2
TT
2R
 T
2f(t)cos2k
Ttdt;
Bk=2
TT
2R
 T
2f(t)sin2k
Ttdt
Utilizzando i numeri complessi:
f(t) =
21X
k= 1F(k
)ejk
t
dove:
F(k
) =1
TT
2Z
 T
2f(t)e jk
tdt
con 
 =2
T
La serie  e per i segnali periodici, un segnale qualsiasi
pu o essere visto come periodico con periodo innito
SeT !1 , 
 !0 ,k !!
Allora:
F(!) =1Z
 1f(t)e j!tdt
Rev. 0.3 Appunti di Automatica 31 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#31,31,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
F(t) =1Z
 1F(!)ej!td!
Ma proprio i casi pi u interessanti creano problemi
Invece di trasformare f(t) trasformiamo:
 1(t)f(t)e t
Pongos=+j!
e avr a :
F(+j!) =1Z
0f(t)e te j!tdt
Quindi:
F(s) =1Z
0f(t)e stdt
LAPLACE
Vediamo quindi che esiste una diretta corrispondenza
tra la serie di Fourier e la tra trasformata di Laplace.
Rev. 0.3 Appunti di Automatica 32 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#32,32,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Denizione della risposta impulsiva
come antitrasformata della funzione di
trasferimento
Data:
Y(s) =G(s)U(s)
Assumiamo U(s) = 1 !u(t) =(t) Impulso
y(t) =g(t) RISPOSTA IMPULSIVA
Possiamo dire che l'impulso ha area unitaria quindi:
1Z
 10(t)dt= 1
Ma anche con la convoluzione : y(t) =tR
0u()g(t 
)d=tR
0(t)g(t )d=g(t)
Inoltre seu(t) = 1(t)U(s) =1
sGradino
Y(s) =G(s)
s
y(t) =tZ
0g()d=g 1(t)
Questa  e la risposta indiciale cio e l'integrale della
risposta impulsiva
Rev. 0.3 Appunti di Automatica 33 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#33,33,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Modi propri di un sistema
L'antitrasformata di:
G(s) =Pbisi
Paisi
 e composta, o meglio,  e combinazione lineare di:
Esponenziali: eat,eatsin (!t+')
Polinomi del tempo: t0(che  e una costante), t,t2
2,
t3
3!
Polinomi(t) per esponenziali: teat
Eventualmente impulsi nell'origine al limite della
causalit a : 0(t)
Questi sono i modi naturali del sistema, dove il lo-
ro numero  e pari all'ordine dell'equazione dierenziale(le
sinusoidi contano 2)
Le caratteristiche del sistema si riettono sulla posi-
zione dei poli sul piano s ( Re[s];Im[s]), infatti la con-
vergenza dipende dalla loro parte reale che dovr a essere
minore di 0.
Rev. 0.3 Appunti di Automatica 34 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#34,34,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Denizione di stabilit a asintotica
Si pu o parlare di stabilit a asintotica se Re[pi]<0
Nel caso del polo semplice  ! lim
t!1epit !0;
nel caso del polo doppio  ! lim
t!1tepit !0 comun-
que
Ma cosa succede se Re[pi] = 0 ?
Se semplice, l'evoluzione libera contiene una costante
quindi il sistema  e stabile ma non asintoticamente. Se in-
vece  e multiplo, contiene una rampa, una parabola quin-
di instabile. Per poli immaginari puri, si hanno sinusoidi
nel caso di poli semplici o divergenti polinomialmente nel
caso di poli multipli.
Denizione di regime transitorio e di
regime permanente
Dato un sistema stabile la risposta forzata pu o essere
composta dal periodo di tempo prima dell'estinzione dei
modi naturali del sistema dove l'uscita si assesta det-
to REGIME TRANSITORIO , mentre il periodo di tem-
po che lo segue dove rimane solo la parte con i poli
dell'ingresso  e detto REGIME PERMANENTE .
Rev. 0.3 Appunti di Automatica 35 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#35,35,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Risposta al permanente di un sistema
asintoticamente stabile
1.9 Un esempio: il carrello
Facciamo un esempio meccanico e proviamo a scrivere
un modello matematico (il sistema) immaginando un in-
gresso da applicare e calcolando l'andamento nel tempo
dell'uscita.
Come modello prendiamo un carrellino di massa M
che si muova su un piano orizzontale con un attrito vi-
scoso pari a Dspinto da una forza fe(t). Immaginiamo
pure che la grandezza di uscita, quella a cui questa volta
siamo interessati, sia la sua velocit a v(t).
Come forza scegliamo una forza costante applicata a
partire dat= 0:
fe(t) = 1(t)L !Fe(s) =1
s:
L'equazione di equilibrio che governa il sistema  e la
seguente:
M_v(t) =fe(t) Dv(t) (1.36)
Trasformando l'equazione dierenziale 1.36, dove il pun-
tino indica la derivazione rispetto al tempo, abbiamo:
M[sV(s) v(0)] =Fe(s) DV(s)
Rev. 0.3 Appunti di Automatica 36 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#36,36,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
dove abbiamo immaginato che il carrello possa avere una
condizione iniziale, ovvero una velocit a iniziale diversa
da zero. Se poi la velocit a iniziale fosse zero, v(0) = 0, si
avrebbe pi u semplicemente:
[sM+D]V(s) =Fe(s)
da cui, ricavando V(s):
V(s) =1
Ms+DFe(s) =1
s+ 11
s: (1.37)
dove abbiamo posto anche M= 1 eD= 1.
Possiamo subito chiederci a quale valore tenda la velo-
cit a pert!1 e applicando il Teorema del valore nale
otterremo
lim
s!0s1
s+ 11
s= 1:
A questo punto possiamo applicare la decoposizione
in poli e residui per calcolare l'antitrasformata e quindi
l'andamento dell'uscita:
V(s) =R1
s+ 1+R2
s=1
s 1
s+ 1
con
R1= (s+ 1)1
(s+ 1)s
s= 1= 1
R2=s1
(s+ 1)s
s=0= 1
Rev. 0.3 Appunti di Automatica 37 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#37,37,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Figura 1.3: Evoluzione libera e forzata
quindi antitrasformando otterremo:
v(t) =L 1
 1
s 1
s+ 1
=
L 1
 1
s
+L 1
  1
s+ 1
= 1(t) +e t
In sostanza abbiamo risolto un'equazione dierenziale
tramite un'equazione algebrica.
Se poi poniamo una condizione iniziale diversa da zero
v(0) = 0:5
V(s) =1
Ms+DFe(s) +v(0)
Ms+D=1
s+ 11
s+0:5
s+ 1
e 'antitrasformata dell'evoluzione libera, indichiamola con
vl(t) varr a
vl(t)0:5e t:
In Fig. 1.3 troviamo la rappresentazione dei vari ter-
mini. Il primo termine(1
s+11
s) lo abbiamo indicato con A
e rappresenta la risposta forzata cio e l'uscita causata dal-
l'applicazione dell'ingresso; il secondo termine(0:5
s+1), indi-
chato conB e l'evoluzione libera, cio e l'uscita del sistema
Rev. 0.3 Appunti di Automatica 38 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#38,38,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Figura 1.4: Andamento della velocit a del carrellino
a partire da una condizione iniziale diversa da zero. No-
tiamo che l'unico polo della risposta libera coincide con il
polo di1
(s+1)che  e la parte della risposta forzata dovuta
solo al sistema.
Se supponessimo che dopo 5 secondi la forza appli-
cata torni a 0 potremmo studiare cosa succede in alme-
no due modi: il primo consiste nello studiare la risposta
completa all'ingresso:  1(t)  1(t 5); il secondo  e
invece quello di immaginare il sistema in una condizione
iniziale dierente, quella raggiunta con l'applicazione del
primo gradino, e da li considerare l'evoluzione libera del
sistema.
Si ottiene comunque il risultato in Fig. 1.4
Notiamo che ponendo u(t) = 0 a partire da una condi-
zione iniziale diversa da zero il sistema torna nella condi-
zione di riposo v(t) = 0. Possiamo dedurne che il sistema
sia asintoticamente stabile.
Rev. 0.3 Appunti di Automatica 39 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#39,39,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
1.10 Esempi di funzioni di
trasferimento
Risposte tipiche: impulsiva e indiciale
La risposta impulsiva  e di scarso interesse pratico
perch e gli impulsi non esistono sicamente ma  e
importante perch e consente di vedere tutti e soli i
modi del sistema.
Infatti le risposte canoniche si ricavano integrando
quella impulsiva.
La risposta al gradino, detta anche risposta indicia-
le, si ottiene integrando quella impulsiva; mentre
la risposta alla rampa si ottiene integrando quella
indiciale.
Tra l'altro  e proprio sulla risposta al gradino che si
deniscono le speciche di progetto nel dominio del
tempo.
Sistemi del primo ordine: il carrellino (FdT+C.I.)
Date le condizioni per cui il sistema si trova a riposo
My::+Dy:=f(t)y(0) = 0,y:(0) = 0
e considerando D=M= 1fa=Dx:
Y(s) [Ms2+Fs] =F(s) ;f(t) = 1(t)
Rev. 0.3 Appunti di Automatica 40 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#4,4,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
il tempo, rimane denita dal seguente integrale:
L ff(t)g:=Z1
0 f(t)e stdt:=F(s) (1.1)
cons=+j!2C(dovef (t) = 0pert< 0). Unilatera
in quanto uno degli estremi, quello inferiore,  e pari a 0 
e d'altro canto, nello studio di sistemi si suppone che la
parte interessante e diversa da zero sia presente soltanto
pert >0 essendo tutta la storia del sistema, da  1 a
0 riassunta nella condizione iniziale. Non solo, lo studio
della risposta di un sistema a un ingresso normalmente
presuppone che quest'ultimo venga applicato a partire da
t= 0 e sia completamente nullo prima.
Il codominio della Trasformata di Laplace  e il piano
dei numeri complessi e questo signica che per interpre-
tare correttamente questo operatore bisogna conoscere
bene i numeri complessi e le operazioni su di essi.
1.2 Una trasformata elementare
Visto che le soluzioni delle equazioni dierenziali lineari a
coecienti costanti omogenee sono combinazioni lineari
di esponenziali reali o complessi, a questo punto vale la
pena studiare la trasformata di Laplace della funzione
esponenziale. Sar a una delle pochissime che ci serviranno
in questo ambito.
Rev. 0.3 Appunti di Automatica 5 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#40,40,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Y(s) =1
s(Ms+D)1
s=1
s2(Ms+D)
avr a un doppio polo nell'origine quindi:
R(1)
1
s+R(2)
1
s2+R2
s+ 1
Ora vado ad eettuare il calcolo dei residui:
{R(1)
1= lim
s!0d
dsh
s2 1
(s+1)s2i
= lim
s!0 1
(s+1)2= 1
{R(2)
1= lim
s!0s2 1
s2(s+1)= 1
{R2= lim
s! 1(s+ 1)1
s2(s+1)= 1
Quindi:
Y(s) = 1
s+1
s2+1
s+ 1
e
y(t) = 1(t)
 1 +t+e t
Vediamo quindi che il sistema non  e asintoticamen-
te stabile e quindi il transitorio non si annulla!!
Sistemi del secondo ordine: massa-molla-smorzatore
Date:
f(t) =1(t) e date le stesse condizioni per cui il
sistema si trova a riposo:
Rev. 0.3 Appunti di Automatica 41 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#41,41,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
y(0) = 0 ey:(0) = 0
In questo caso invece consideriamo: M= 1 ,D= 2
,K= 101
My::(t) +Dy:(t) +Ky(t) =f(t)
Ms2Y(s) +DsY (s) +KY(s) =F(s)
Risolviamo quindi per Y(s) ottenendo cos  :
Y(s) =1
Ms2+Ds+KF(s) =1
s2+ 2s+ 1011
s=N
D
conp1= 0 ,p2= 1 10j,p3=p
2
Anche in questo caso calcoliamo i residui:
R1= lim
s!0sN
D=1
101 !1
101 1(t)
R2= lim
s! 1 10j(s+ 1 + 10j)N
D= 1
202 j
2020
R3=R
2
R2
s+1+10j+R3
s+1 10j= s+2
101(s2+2s+101)
Ora dobbiamo antitrasformare:  s+2
101(s2+2s+101)
I poli sono complessi quindi usiamo:
e tsin (!t) !!
(s+)2+!2=!
s2+2s+(2+!2)
e tcos (!t) !s+
s2+2s+(2+!2)
da cui= 1!= 10 e possiamo risolvere:
Rev. 0.3 Appunti di Automatica 42 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#42,42,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
A(s+) +B!= (s+ 2)A= 1,B= 0:1
E quindi l'antitrasformata sar a:
( e tcos 10t e t
10sin 10t)
Quindi avr o :
y(t) =1
101
 1(t) (e tcos 10t e t
10sin 10t)
dove 1(t)  e simile all'ingresso ed il termine ( e tcos 10t 
e t
10sin 10t)  e il transitorio legato all'ingresso.
Se il sistema  e asintoticamente stabile in uscita ci
ritroviamo l'ingresso
Coincidenza di poli sull'asse immaginario
Nel paragrafo 3.6.2 abbiamo parlato dei parametri
dei poli complessi e coniugati e abbiamo introdotto
il coeciente di smorzamento( ).
Dopo di che ci siamo soermati cosa succedeva al
sistema nel caso che fosse<0 oppure1; veden-
do poi che nel caso in cui fosse stato proprio pari a
0 siamo in presenza di poli sull'asse immaginario.
Rev. 0.3 Appunti di Automatica 43 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#5,5,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
L feptg=Z1
0 epte stdt=1
p s
e(p s)t1
0 =1
s p
(1.2)
dove per risolvere l'integrale abbiamo supposto che
<[s]><[p] =
eprende il nome di ascissa di convergenza. Il termi-
nee stfacilita ovviamente la convergenza dell'integrale
in quanto un esponenziale il cui argomento abbia parte
reale negativa tende a zero pi u velocemente di qualsiasi
polinomio e questo sar a importante quando tenteremo di
trasformare dei segnali di ingresso di tipo polinomiale di
grado qualsiasi.
Naturalmente il fatto che l'integrale sia sommabile
solo in una parte del piano complesso non ci preoccupa
pi u di tanto e quindi scriveremo:
L 
ept	
=1
s p(1.3)
Ad esempio consideriamo il segnale e 2t. La sua tra-
sformata  e la seguente:
e 2tL !1
s+ 2
Notiamo che a denominatore  e presente un polinomio
di grado pari a uno e che la sua radice  e proprio  2.
Rev. 0.3 Appunti di Automatica 6 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#6,6,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Potremmo quasi dedurre che, data una trasformata di
Laplace, la presenza di radici a parte reale negativa al
denominatore (che chiameremo poli),  e legata al fat-
to che il segnale di partenza, nel tempo, converge a
zero. Come vedremo pi u avanti, questa osservazione
 e generalizzabile a polinomi a denominatore di grado
qualsiasi.
Trasformate derivate da quella
elementare
Dalla trasformata appena vista se ne possono ricavare
altre come casi particolari. Ad esempio, sostituendo p=
j!otteniamo:
L 
ej!t	
=1
s j!
Altro caso particolare che possiamo subito calcola-
re  e la trasformata del gradino unitario o funzione di
Heaviside:
 1(t) =1t0
0t<0
L f 1(t)g=1
s
Ovviamente l'ascissa di convergenza del gradino risul-
ta uguale a 0.
Rev. 0.3 Appunti di Automatica 7 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#7,7,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
per quel che riguarda le funzioni sin e cos si possono
utilizzare le formule di Eulero e quindi ricondurci alla
trasformata gi a analizzata:
L fsin (!t)g=L ej!t e j!t
2j
=!
s2+!2(1.4)
L fcos (!t)g=L ej!t+e j!t
2
=s
s2+!2(1.5)
Notiamo che la parte reale delle radici del denomina-
tore, le quali valgono j!,  e nulla. Infatti i segnali in
questione non convergono ne divergono.
1.3 Alcune propriet a
Analizziamo adesso alcune semplici propriet a della Tra-
sformata di Laplace. Saranno utili nel resto del libro.
Linearit a
La trasformata di Laplace  e un operatore lineare. La
cosa si deduce dal fatto che alla base c' e un integrale la
cui linearit a  e gi a stata dimistrata nei corsi di analisi:
l'integrale della somma di due funzioni  e pari alla somam
degli integrali delle due funzioni. In questo caso possiamo
Rev. 0.3 Appunti di Automatica 8 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#8,8,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
scrivere:
L fc1f1(t) +c2f2(t)g=c1L ff1(t)g+c2L ff2(t)g
(1.6)
Coniugazione
Facile da dimostrare  e anche la propriet a di coniugazione:
baster a scrivere nell'integrale della trasformata sinvece
dis. Per cui:
F(s) =F(s) (1.7)
Teorema del valore iniziale
Questo teorema consente di determinare asintoticamente
il valore int= 0 di una funzione di classe C1e la cui tra-
sformata di Laplace abbia ascissa di convergenza minore
di zero. Quindi non pu o essere usato per funzioni che
hanno impulsi nell'origine. Nell'ipotesi che esista nito il
lim
t!0+f(t)
allora:
lim
t!0+f(t) = lim
s!1sF(s) (1.8)
Rev. 0.3 Appunti di Automatica 9 di 43"
data_test\rootfolder\università\FondamentiDiAutomatica\Trasformata_di_Laplace.pdf#9,9,"Capitolo 1. La Trasfomata di Laplace e la Funzione di
Trasferimento Stefano Panzieri
Teorema del valore nale
Allo stesso modo, solo se l'ascissa di convergenza di F(s)
 e minore o uguale a zero ed esiste
lim
t!1f(t)
allora:
lim
t!1f(t) = lim
s!0 sF(s) (1.9)
Quest'ultimo risultato  e molto utile e verr a molte vol-
te utilizzato nel prosieguo per analizzare il comportamen-
to di un sistema di controllo per t!1 .
Moltiplicazione per un esponenziale
Cosa succede se moltiplichiamo una funzione per un espo-
nenziale nel tempo eat? Questo risultato, noto anche co-
me traslazione in frequenza quando a=j! e un numero
immaginario, torner a utile studiando i segnali campiona-
ti.
L 
eatf(t)	
=1Z
0 e (s a)tf(t)dt=F(s a) (1.10)
La dimostrazione  e ovvia, basta inserire l'esponenziale
nell'integrale che denisce la trasformata e poi eettua-
re una sostituzione di variabile s0=s a. Alla ne,
tornando in ssi otterr a il risultato dell'eq. 1.10.
Rev. 0.3 Appunti di Automatica 10 di 43"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#0,0,Geometria e Combinatoria marcella.sama@uniroma3.itL10: Basi di spazi vettoriali (16-17)Argomenti lezione:•Dipendenza e indipendenza lineare•Basi•Dimensione•Una base per Sol(SO) •Dimensioni di sottospazi vettoriali •Calcolo di dimensioni e basi 
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#1,1,"Dipendenza e indipendenza lineare
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#10,10,"23/11/2011Teorema: Un singolo vettore vdi uno spazio vettoriale Vèlinearmente indipendente se e solo se v≠ 0. Teorema: Dati i vettori v1, v2, …, vr(con r> 1).                       Se uno di essi è combinazione lineare dei rimanenti,           allora i vettori v1, v2, …, vrsono linearmente dipendenti.Dimostrazione: Uno dei vettori, detto vi, è combinazione linearedei rimanenti.  Dunque esistono scalari h1, h2, …, hi–1,hi+1 , . . . , hrtali che:Dipendenzae indipendenza lineare
Abbiamo hi≠ 0. Pertanto v1, v2, …, vrsono linear. dipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#11,11,"23/11/2012Teorema: Dati i vettori v1, v2, …, vr(con r> 1). Se abbiamo ∑!""#$𝑘!𝑣!=0con ki≠ 0allora viè combinazione lineare dei rimanenti.Dipendenzae indipendenza lineare
Dimostrazione: 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#12,12,"23/11/2013Osservazione: Se v1, v2, …, vrsono linearmente dipendentiallora almeno uno è combinazione lineare dei rimanenti.Esempio: Consideriamo i seguenti polinomi: f1(x) := 1 + x,  f2(x) := x2,  f3(x) := 2 + 2x–x2e  f4(x) := 2x–x3.  Notiamo che 2 f1(x) –f2(x) –f3(x) + 0 f4(x) = 0Dunque, i polinomi sono linearmente dipendenti. Ora  f3(x) è combinazione lineare di f1(x), f2(x) e f4(x): f3(x) = 2 f1(x) –f2(x) –0 f4(x) Ma f4(x) nonè combinazione lineare di f1(x),  f2(x) e f3(x) !(le loro combinazioni lineari possono avere al più grado 2)Dipendenzae indipendenza lineare
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#13,13,"23/11/2014Osservazione: Due vettori v1e v2sono linearmente dipendenti   se e solo se uno di essi è multiplodell’altro.Esempi:v1:= (2, 1, 3) e v2:= (1, 1, 2) sono linearmente dipendenti ? No, perchè nessuno è multiplo dell’altro. Quindi: 0v1–0v2= 0 v1:= (4, 2, 6) e v2:= (6, 3, 9) sono linearmente dipendenti ? Sì, perchè (4, 2, 6) è multiplo di (6, 3, 9). Infatti: 3v1–2v2= 0 v1:= (0, 0, 0) e v2:= (1, 1, 2) sono linearmente dipendenti ?Sì, perchè (0, 0, 0) è multiplo di (1, 1, 2). Infatti: 1v1+ 0v2= 0 Dipendenzae indipendenza lineare
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#14,14,"23/11/2015Teorema: Se v1, v2, …, vrsono linearmente dipendenti allora v1,v2, …, vr,vr+1 sono linearm. dipendenti qualunque sia vr+1.Dimostrazione:Dobbiamo trovare una combinazione lineare non banale di v1, v2, …, vr, vr+1 che dia come risultato il vettore nullo. Sappiamo che esiste una combinazione lineare di v1, v2, …, vrcon coefficienti non tutti nulliche è uguale al vettore nullo: Dipendenzae indipendenza lineare
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#15,15,"23/11/2016Teorema: Se i vettori v1, v2, …, vrsono linearmente indipendenti, e vr+1è un vettore che nonè combinazione lineare di v1, v2, …, vr,allora v1, v2, …, vr, vr+1 sono linearmente indipendenti.Dimostrazione: Dobbiamo mostrare che se abbiamo una combinazione linearedi v1, v2, …, vr, vr+1 uguale al vettore nullo:allora tuttii coefficienti kisono nulli.Per ipotesi: v1, v2, …, vrsono linearmente indipendenti, da cui abbiamo che k1= k2=…= kr = 0. Anchekr+1=0, altrimenti vr+1sarebbe combinazione lineare di     v1, v2, ..., vr.Dipendenzae indipendenza lineare
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#16,16,"Basi di uno spazio vettoriale
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#17,17,"23/11/2018BasiDefinizione: I vettori v1, v2, ... , vrdi uno spazio vettoriale Vcostituiscono una basedi Vse sono verificate entrambe le proprietà:  1.V= L(v1, v2, ... , vr); 2.v1, v2, ... , vrsono linearmente indipendenti.Esempio: Verificare che f1(x) := 1,  f2(x) := 1 + x,  f3(x) := 1 + x+ x2, f4 (x) := 1 +x+ x2+ x3costituiscono una base di R4[x].
(ovvero un generico polinomio di grado <4)Il sistema è Cramerianoe, quindi, ammette un’unica soluzione (prop. 1).Nel caso a=b=c=d=0, la soluzioneè quella banale k1=k2=k3=k4=0 (prop. 2).Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#18,18,"23/11/2019BasiTeorema: Se v1, v2, ... , vrcostituiscono una basedi uno spazio V, allora ogni vettore vdi Vequivale a un’unicacombinazione linearedei vettoriv1, v2, ... , vr( ovvero 𝑣=∑!""#$𝑘!𝑣!). → k1, k2,..., krsono le rcomponentidi vrispetto alla basev1, v2,..., vrOsservazione 1:  Quando parliamo di componentidi un vettore dobbiamo sempre specificare rispetto a quale base ci riferiamo, perchèle componenti dello stesso vettore rispetto a basi diverse sono (in generale) diverse.Osservazione 2: Le componenti dell'i-esimo vettore virispetto alla base v1, v2,..., vrsono (0, ... , 0, 1, 0, ... , 0) (dove l’unico 1 compare al posto i-esimo). In particolare, il vettore 0 ha componenti (0, ..., 0). Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#19,19,"23/11/2020BasiTeorema: Se v1, v2, ... , vrcostituiscono una basedi uno spazio V, allora ogni vettore vdi Vequivale a un’unicacombinazione linearedei vettoriv1, v2, ... , vr( ovvero 𝑣=∑!""#$𝑘!𝑣!). → k1, k2,..., krsono le rcomponentidi vrispetto alla basev1, v2,..., vrDimostrazione: v1, v2, ... , vrgeneranoV, per ogni v segue: v= k1v1+ k2v2+ ... + krvrSupponiamo di scrivere vtramite due diverse combinazioni lineari:Dobbiamo dimostrare che hi = kiper ogni i. Dato chev1, v2, ... , vrsono linear. indip. si ha h1= k1 ,h2= k2 ,..., hr= kr
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#2,2,"Esempio:A2è combinazione linearedi A1e A3:Segue che                                         si può scrivere:Da cui si ha: L(A1, A2, A3) ÍL(A1, A3) Inoltre sappiamo che L(A1, A3) ÍL(A1, A2, A3)Segue che: L(A1, A3)= L(A1, A2, A3)
23/11/203Introduzione
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#20,20,"23/11/2021BasiEsempi: Base canonicaI seguenti vettori costituiscono una base per lo spazio vettoriale Rn:
Dimostriamo che e1:= (1,0) ed e2:= (0,1) formano una base di R2 :
I vettori e1ed e2generanoR2 :I vettori e1ed e2sono linear. indip. : 
Allora si ha:Da cui segue a1= 0  e  a2= 0.Quindi i vettori e1ed e2costituiscono una base (canonica) di R2.Caso n= 2:
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#21,21,"23/11/2022BasiEsempi: Base canonicaConsideriamo lo spazio vettoriale M(3, 2, R) e le seguenti matrici: Data una generica matrice di M(3, 2, R): 
Segue che le sei matrici di cui sopra sono generatoridi M(3, 2, R).Le sei matrici sono linear. indip. e formano una basedi M(3, 2, R).Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#22,22,"Basi canonicheI seguenti vettori costituiscono una base per lo spazio vettoriale Rn:
Particolarità: Le componenti del vettore ( x1, x2, ... , xn) relative a questa base sono esattamente x1, x2, ... , xn.Una base per M(p, q, R) è formata dalle pqmatrici Eij, dove Eijè la matrice i cui elementi sono tutti 0 tranne quello di posto (i, j) = 1.Particolarità: Le componenti di un vettore (cioè una matrice) relative ad esso sono gli elementi della matrice stessa.Una base per Rn[x], nnaturale,è formata dai polinomi 1, x, x2, ..., xn–1.Particolarità: Il vettore p(x) = a0+ a1x+ a2x2+ ... + an–1xn–1 ha comecomponenti relative ad essa i suoi coefficienti (a0, a1, a2, ..., an–1).23/11/2023Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#23,23,"23/11/2024BasiEsempio: Abbiamo già verificato che f1(x) := 1,  f2(x) := 1 + x,  f3(x):= 1 + x+ x2, f4 (x) := 1 +x+ x2+ x3costituiscono una base di R4[x]. Determinare le componentidi f (x) = 2x–3x2rispetto alla base data.
Da cui le componentidi f (x) rispetto alla base data sono (−2, 5, −3, 0).Si dimostra che 1, x, x2, x3formano un’altra base (canonica) per R4[x].Le componentidi f (x) relative a tale base di R4[x] sono (0, 2, −3, 0).Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#24,24,"Dimensioni di sottospazi vettoriali
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#25,25,"23/11/2026DimensioneEsempio: Abbiamo visto che dati tre punti A, Be Cdello spazio tali che O, A, Be Csiano non complanari, allora i vettori di V 3(O) v1:= OA, v2:= OBe v3:= OCdi V 3(O) sono linear. indipendenti. Ogni vettore vè uguale a una combinazione linearedi v1, v2e v3. Pertanto v1, v2e v3costituiscono una baseper V 3(O).  Dato che qualsiasi base di V 3(O) è formata da tre vettori,si dice che la dimensionedi V 3(O) è uguale a 3. In generale chiamiamo dimensionedi uno spazio vettorialeil numero di vettori che compongono una sua base. →→→
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#26,26,"23/11/2027DimensioneTeorema del completamento: Sia Vuno spazio vettoriale aventeuna base formata dai vettori e1, e2, ... , en. Siano poi assegnati rvettori linearmente indipendenti v1, v2, ... , vrdi V, con r≤n.        Si dimostra che è possibile scegliere opportunamente rvettori tra quelli della base e1, e2, ... , ene sostituirli con i vettori v1, v2, ... , vrin modo tale da ottenere una base di V.Teorema:SiaVunospazioaventeunabaseformatadanvettori.Allora assegnati comunque nvettori di Vlinearmente indipendenti,si dimostra che questi formano una base di V.Teorema: In uno spazio Vavente una base formata da nvettorinon vi possono essere più di nvettori linearmente indipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#27,27,"23/11/2028DimensioneTeorema: In uno spazio Vavente una base formata da nvettorinon vi possono essere più di nvettori linearmente indipendenti.Teorema: Sia Vuno spazio avente una base formata da nvettori. Allora ogni altra base di Vè formata da nvettori.Definizione: Se uno spazio Vha una base formata da n vettori, si dice che Vha dimensioneuguale a n : dim V = n.Definizione: Se uno spazio vettoriale Vè formato dal solo vettore nullo (dim V= 0) o ha una base formata da nvettori (dim V = n)diciamo che Vha dimensione finita.Se uno spazio vettoriale nonè dotato di una base formata da un numero finito di vettori, allora lo spazio ha dimensione infinita.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#28,28,"23/11/2029DimensioneTeorema: Si può dimostrare che:1. dim V 2(O) = 22. dimV 3(O) = 33. dimRn= n4. dimM(p, q, R) = pq5. dimRn[x] = n6. R[x] ha dimensione infinitaGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#29,29,"23/11/2030DimensioneTeorema: Se Vèuno spaziovettorialedidimensione nallora:1. non esistonopiudinvettorilinearmente indipendenti;2. daticomunquervettoriconr< n(anchese linear. indipendenti), essinon possonoesseregeneratori(tantomenouna base) diV;3. datinvettorilinear. indipendenti, essiformanouna base diV;4. daticomunquengeneratori, essiformanouna base diV.Osservazione: Datinvettoridiuno spaziovettorialedidim. n, per individuarese essiformanouna base, possiamocontrollare:•cheglinvettorisianogeneratori, oppure•cheglinvettorisianolinearmente indipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#3,3,"23/11/204IntroduzioneOsservazione: In qualunque spazio vettoriale V, se un vettore vr+1è combinazione linearedei vettori v1, v2, ... , vrallora si ha: L(v1, v2, ... , vr) = L(v1, v2, ... , vr, vr+1) Interpretazione: Se uno spazio vettoriale Vè generatodai vettori   v1, v2, ... , vr, vr+1e uno di essi è combinazione lineare degli altri, allora lo possiamo scartaree ottenere rvettori che generano V.Idea: Potremmo applicare lo stesso ragionamento agli rvettori che generano V individuando r–1 vettori generatori. Iterando ilprocesso, a una certa iterazione non possiamo più scartare vettori. Definizione: I vettori v1, v2, ... , vrsono linearmente dipendenti se esistono k1, k2, ... , krnon tutti nullitali che:∑!""#$𝑘!𝑣!=0Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#30,30,"23/11/2031DimensioneTeorema: Se Vèuno spaziovettorialedidimensione nallora:1. non esistonopiudinvettorilinearmente indipendenti;2. daticomunquervettoriconr< n(anchese linear. indipendenti), essinon possonoesseregeneratori(tantomenouna base) diV;3. datinvettorilinear. indipendenti, essiformanouna base diV;4. daticomunquengeneratori, essiformanouna base diV.Esempio: Stabilirese ivettoriv1:= (1, 2, 1), v2:= (1, 1, 1),v3:= (0, 1, 2), v4:= (1, 1, 3) diR3sono linearmente indipendenti.SappiamochedimR3= 3. Segue 4 vettoridiR3comunquesceltisono linearmente dipendenti. In particolarev1, v2, v3, v4sono linearmente dipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#31,31,"23/11/2032DimensioneTeorema: Se Vèuno spaziovettorialedidimensione nallora:1. non esistonopiudinvettorilinearmente indipendenti;2. daticomunquervettoriconr< n(anchese linear. indipendenti), essinon possonoesseregeneratori(tantomenouna base) diV;3. datinvettorilinear. indipendenti, essiformanouna base diV;4. daticomunquengeneratori, essiformanouna base diV.Esempio: Stabilirese leseguentimatricigeneranoM(2, 2, R): Sappiamo che dim M(2, 2, R) = 4. Segue per generare M(2, 2, R) sono necessari almeno 4 vettori.Dunque A1, A2, A3non generano M(2, 2, R).  Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#32,32,"Basi per le soluzioni di un sistema lineare omogeneo
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#33,33,"23/11/2034Una base per Sol(SO)Teorema: Consideriamo un sistema lineare omogeneo SO: AX= 0 di p equazioni in qincognite x1, x2, ... , xq. Sia rk A = r, allora lo spazio delle soluzioni Sol(SO) ha dimq–r.  Una base per SOpuò essere determinata nel modo seguente:•Si determinano le soluzioni del sistema con il metodo che si preferisce (Rouchè-Capelli o Gauss): sappiamo che q–rincognite scelte opportunamente fungeranno da h1, h2, ... , hq–rparametri;•Il primo vettore della base si ottiene assegnando a h1il valore 1             e agli altri parametri il valore 0;•Il secondo vettore della base si ottiene assegnando a h2il valore 1  e agli altri parametri il valore 0;•... L’ultimo vettore della base si ottiene assegnando ad hq–ril valore 1 e agli altri parametri il valore 0.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#34,34,"23/11/2035Una base per Sol(SO)Esempio: Sia dato il seguente sistema lineare omogeneo SO :
Possiamo trasformare il sistema nel seguente sistema equivalente:
Assegniamo ora a y, w,tdei valori parametrici: 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#35,35,"23/11/2036Una base per Sol(SO)Esempio: Scriviamo ora le soluzioni come matrici di M(5, 1, R):
Sol(SO) è generato dai vettori S1, S2e S3: 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#36,36,"23/11/2037Una base per Sol(SO)Esempio: Sol(SO) è generatodai vettori S1, S2e S3 : Per stabilire se S1, S2e S3formano una base per Sol(SO), verifichiamo se sono linear. indipendenti:
Questa uguaglianza si verifica soloquando h1= h2= h3= 0.S1, S2e S3sono una base di Sol(SO) che ha dimensione 3.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#37,37,"23/11/2038Una base per Sol(SO)Esempio: Determinare una base per il seguente sottospazio Edi R4
Per ottenere dei generatori di Eponiamo: h1:= 1, h2:= 0 e h3:= 0 ottenendo il vettore (0, 1, 0, 0);h1:= 0, h2:= 1 e h3:= 0 ottenendo il vettore (3/2, 0, 1, 0);h1:= 0, h2:= 0 e h3:= 1 ottenendo il vettore (–1, 0, 0, 1).h1= x2, h2= x3, h3= x4
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#38,38,"23/11/2039Dimensioni di sottospazi vettorialiTeorema: Sia Vuno spazio vettoriale di dimensione finita e sia Eun sottospazio di V. Allora Eha dimensione finita e dim E ≤dim VTeorema: Sia Vuno spazio vettoriale e dim V= n. Allora: •Esiste un sottospazio Econ dim E= 0, formato dal vettore nullo.•Esiste un sottospazio di dim. uguale a n, formato da Vstesso.Esempi: Abbiamo visto che V 2(O)ha dim. uguale a 2. Pertanto i suoi sottospazi possono avere dim. uguale a 0, 1 o 2: •L’unico sottospazio di dimensione 0 consiste nel vettore nullo;•I sottospazi di dimensione 1 sono quelli del tipo {OP| PÎr};•L’unico sottospazio di dimensione 2 è V 2(O) stesso.→Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#39,39,"23/11/2040Dimensioni di sottospazi vettorialiTeorema: Sia Vuno spazio vettoriale di dimensione finita e sia Eun sottospazio di V. Allora Eha dimensione finita e dim E ≤dim VTeorema: Sia Vuno spazio vettoriale e dim V= n. Allora: •Esiste un sottospazio Econ dim E= 0, formato dal vettore nullo.•Esiste un sottospazio di dim. uguale a n, formato da Vstesso.Esempi: Abbiamo visto che V 3(O)ha dim. uguale a 3. Pertanto i suoi sottospazi possono avere dim. uguale a 0, 1, 2 o 3: •L’unico sottospazio di dimensione 0 consiste nel vettore nullo;•I sottospazi di dimensione 1 sono quelli del tipo {OP| PÎr};•I sottospazi di dimensione 2 sono quelli del tipo {OP| PÎπ};•L’unico sottospazio di dimensione 3 è V 3(O) stesso.→→Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#4,4,"23/11/205Dipendenza lineareDefinizione: I vettori v1, v2, ... , vrsono linearmente dipendenti se esistono k1, k2, ... , krnon tutti nullitali che:∑!""#$𝑘!𝑣!=0Esempi:A2è combinazione linearedi A1e A3:
Segue che le matrici A1, A2e A3sono linearmente dipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#40,40,"23/11/2041Dimensioni di sottospazi vettorialiEsercizio(1): Sia S(2, R) il sottospazio vettoriale M(2, 2, R) formato dalle matrici simmetriche. V ogliamo determinarne una base.Consideriamo il sottospazio V1avente come base S1:= V1 ≠S(2, R), perchè c’è almeno un’altra base S2:= Consideriamo il sottospazio V2avente come basi S1e S2 :V2 ≠S(2, R) perchè c’è almeno un’altra base S3:= Consideriamo il sottospazio V3avente come basi S1 , S2e S3 .V3coincide con S(2, R), perché dimS(2, R) < dimM(2, 2, R) = 4. 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#41,41,"23/11/2042Dimensioni di sottospazi vettoriali
Dobbiamo stabilire se esistono k1, k2e k3 tali che:
Basta porre k1= b, k2= ae  k3= c. Tutte le matrici simmetriche sono combinazioni lineari di S1, S2 , S3 .Per cui S1, S2 , S3  generano S(2, R).Esercizio(1): Verifichiamo che le matrici S1, S2e S3 generano S(2, R):
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#42,42,"23/11/2043Calcolo di dimensioni e basiTeorema: Sia Vuno spazio vettoriale e v1, v2, ... , vnuna sua base.Siano u1, u2, ... , usdei vettori che generano il sottospazio Udi V.Decomponiamo u1, u2,..., usrispetto alla base formata da v1, v2,..., vn:Si dimostra che rk A = dim UInoltre il teorema e il calcolo del rango di Aci dicono anche comepossiamo estrarre una base di Uda u1, u2, ... , us.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#43,43,"23/11/2044Calcolo di dimensioni e basiVediamo come possiamo estrarre una base di Uda u1, u2, ... , us:
•Se abbiamo calcolato rk Ausando i determinanti dei minori:    Sia Mun minore di Adi ordine ravente determinante non nullo.  Gli rvettori relativi alle colonne di Mformano una basedi U.•Invece, se abbiamo calcolato rk Ariducendo la matrice a scalini:         Sia Bla matrice con rscalini ottenuta dalla matrice A.             Una basedi Usi ottiene prendendo tra i vettori u1, u2, ... , usquei vettori le cui posizioni corrispondono agli scalini di B.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#44,44,"23/11/2045Calcolo di dimensioni e basiEsercizio(2): Sia Eil sottospazio di R[x] generato da f1(x):= 1+ x –2x2,f2(x) := x+ 3 x4,  f3(x) := 1 –2 x2–3 x4. Calcolare dim Ee una base.La base canonica di R5[x] è formata dai polinomi 1, x, x2, x3, x4 .La matrice relativa ai 3 polinomi rispetto alla base canonica di R5[x]: 
rk A= 2
Concludiamo che dim E= 2 e una basedi Eè formata da f1(x) e f3(x). Un minore di ordine 2 con determinante ≠ 0 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#45,45,"23/11/2046Calcolo di dimensioni e basiEsercizio(3): Verificare che v1:= (1, 2, 1, 0), v2:= (2, 3, 0, 1) e          v3:= (1, 5/2, 2, –1/2) di R4sono linearmente dipendenti.La matrice Arelativa ai 3 vettori rispetto alla base canonica di R4:
rk A= 2
GaussDato che rk A= 2, il sottospazio generato da v1, v2, v3ha dim. 2. Segue che i vettori v1, v2, v3sono linearmente dipendenti.Gli scalini sono in prima e seconda posizionenella matrice A. Dunque una baseper L(v1, v2, v3) è formata dai vettori v1e v2 .Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#46,46,"23/11/2047Calcolo di dimensioni e basiEsercizio(4): Verificare che v1:= x+ x3e v2:= 3 + 2x+ x3 di R4[x]sono linearmente indipendenti tramite la base canonica di R4[x]. Base canonica di R4[x]: e0:= 1, e1:= x, e2:= x2, e3:= x3. Prendiamo la matrice Bavente come colonne le componenti dei vettori v1e v2relativamente alla base canonica (e0 , e1 ,e2 , e3 ).
rk B= 2v1e v2sono linearmente indipendenti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#47,47,"23/11/2048Calcolo di dimensioni e basiTeorema: Sia Auna matrice a nrighe e scolonne. Lo spazio generato dalle colonnedi Aha dimensione uguale a rk A.Lo spazio generato dalle righedi Aha dimensione uguale a rk A.(dato che rk A= rk tA)
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#48,48,"23/11/2049Calcolo di dimensioni e basiTeorema: Sia Auna matrice a nrighe e scolonne. Lo spazio generato dalle colonnedi Aha dimensione uguale a rk A.Lo spazio generato dalle righedi Aha dimensione uguale a rk A.Osservazione 1: Nonè detto che i sottospazi del teorema coincidano. Se Aha nrighe e scolonne: le sue righe generano un sottospazio di M(1, s, R), mentre le sue colonne generano un sottospazio di M(n, 1, R).Osservazione 2: Anche nel caso in cui la matrice sia Aquadrata:I sottospazi generati da righe e colonne hanno la stessa dimensione,ma nonè detto che questi due sottospazi coincidano. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#49,49,"23/11/2050EserciziEsercizio(5): Stabilire se i vettori v1:= (1, 3, 2, 1), v2:= (1, 0, 1, 0), v3:= (1, 0, 2, 0) sono linearmente dipendenti o indipendenti. Calcolare una base e la dimensione per lo spazio L(v1, v2, v3). Consideriamo la matrice Ale cui colonne corrispondono alle componenti dei vettori v1, v2e v3rispetto alla base canonica di R4 :
•rk A= 3•dimL(v1, v2, v3) = 3•v1 , v2 , v3costituiscono una base per L(v1, v2, v3) Oss.: Se poniamo k1v1+ k2v2+ k3v3= 0, il sistema lineare nelleincognite k1, k2, k3ha Acome matrice dei coefficienti.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#5,5,"23/11/206Dipendenza lineareDefinizione: I vettori v1, v2, ... , vrsono linearmente dipendenti se esistono k1, k2, ... , krnon tutti nullitali che:∑!""#$𝑘!𝑣!=0Esempi: I vettori v1:= (2, 4, 4, 2), v2:= (1, 2, 2, 1) e v3:= (1, 2, 3, 3) di R4sono linearmente dipendenti. Infatti si ha:   1v1–2v2+ 0v3= 0 Osservazione: Si noti che nella definizione di vettori linearmente dipendenti nonsi richiede che tuttii coefficienti siano diversi da 0, ma solo che qualcuno di essi (almeno uno) sia diverso da 0.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#50,50,"23/11/2051EserciziEsercizio(6): Stabilire se i vettori v1:= (1, 0, 1, 0), v2:= (2, 0, 2, 0),v3:= (2, 0, 2, 0) sono linearmente dipendenti o indipendenti. Calcolare una base e la dimensione per lo spazio L(v1, v2, v3). Consideriamo la matrice Ale cui colonne corrispondono alle componenti dei vettori v1, v2e v3rispetto alla base canonica di R4 :
Gauss
•rk A= 2 •dimL(v1, v2, v3) = 2•Una base è formatada v1e v3(vedi scalini)•Se osserviamo che v2= 2v1 , concludiamo che v1 e v2 sono linearmente dipendenti. Dunque, e.g., L(v1, v2, v3) = L(v1, v3). Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#51,51,"23/11/2052EserciziEsercizio(7): Stabilire se i vettori (1,−1, 0), (0, 1, −1), (−1, 0, 1) formano una base per R3.Consideriamo la matrice Ale cui colonne corrispondono alle componenti dei tre vettori dati rispetto alla base canonica di R3:
•det A = 0•rk A < 3•dim. del sottospazio generato < 3•sappiamo che dimR3= 3•segue i tre vettori nongeneranoR3e nonsono una sua baseGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#6,6,"23/11/207Esempio: I polinomi f1(x) := 1,  f2(x) := 1 + x,  f3(x) := 1 + x+ x2,f4 (x) := 1 +x+ x2+ x3di R[x] sono linearmente indipendenti ? Indipendenza lineareDefinizione: I vettori v1, v2, ... , vrsono linearmente indipendenti se ∑!""#$𝑘!𝑣!=0è verificata solo quando k1=k2=…= kr= 0
Scriviamo una loro combinazione lineare e poniamola = 0:Dobbiamo risolvere questo sistema:Il sistema ammette solamente la soluzione banale k1=k2=k3= k4 = 0Quindi f1(x), f2(x), f3(x) e f4(x) sono linearmente indipendenti ! Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#7,7,"23/11/208Esercizio:  v1:= (1, 2, 1, 0), v2:= (2, 3, 0, 1), v3:= (1, 5/2, 2, –1/2)di R4sono linearmente dipendenti o indipendenti ? Dipendenzae indipendenza lineareScriviamo una loro combinazione lineare e poniamola = 0:
Dobbiamo risolvere questo sistema:Pertanto v1, v2e v3sono linearmente dipendenti ! Ad esempio: 
Soluzione:
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#8,8,"23/11/209Esercizio:  v1:= (1, 2, 1, 0), v2:= (2, 3, 0, 1), v3:= (1, 5/2, 2, –1/2)di R4sono linearmente dipendenti o indipendenti ? Dipendenzae indipendenza lineareScriviamo una loro combinazione lineare e poniamola = 0:
Potevamo evitaredi risolvere il sistema:
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\10_Basi.pdf#9,9,"23/11/2010Esercizio:  v1:= (1, 2, 1, 0), v2:= (2, 3, 0, 1), v3:= (1, 5/2, 2, –1/2)di R4sono linearmente dipendenti o indipendenti ? Dipendenzae indipendenza lineareScriviamo una loro combinazione lineare e poniamola = 0:
In alternativa studiamo la matrice:Poiché il rango è 2,mentre il numero delle incognite è 3, il sistema ha soluzioni non banali.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#0,0,Geometria e Combinatoria marcella.sama@uniroma3.itL11: Intersezione e somma di sottospazi (18)Argomenti lezione:•Introduzione•Intersezione di sottospazi vettoriali •Somma di sottospazi vettoriali•Esercizi su somma e intersezione
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#1,1,"23/11/202IntroduzioneDati due sottospazi vettoriali Ee Fdi uno spazio vettoriale V,vedremo che: •L’intersezione di E e Fè un sottospazio vettoriale;•L’unione di E e Fnonè sempre un sottospazio vettoriale.Introdurremo allora la somma di due sottospazi vettoriali, ovvero “il più piccolo” sottospazio vettoriale contenente E e F. Studieremo poi la formula di Grassmannper il calcolo della dimensione dell’intersezione di E e Fo della somma di E e F.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#10,10,"23/11/2011Somma di sottospazi vettorialiTeorema: Siano Ee Fdue sottospazi vettoriali di dimensione finitadi un qualsiasi spazio vettoriale V. Segue E+Fha dimensione finita.In particolare, se e1, e2, ... , epformano una base di Ee  f1, f2, ... , fqformano una base di F, allora i vettori e1, e2, ... , ep, f1, f2, ... , fqgenerano E+ F(ma nonformano necessariamente una basedi E+F).Teorema: Sia Vuno spazio vettoriale di dimensione finita aventeuna base formata dai vettori v1, v2,..., vn. Siano Ee Fdue sottospazi vettoriali di uno spazio vettoriale Vdi dimensione finita. Siano e1, e2, ... , epuna base di E  e   f1, f2, ... , fquna base di F.Allora dim(E+ F) = rk Adove Aè la matrice avente come colonnele componenti di e1, e2,..., ep, f1, f2,..., fqrispetto alla base v1,v2,..., vn. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#11,11,"23/11/2012Somma di sottospazi vettorialiEsercizio: Determinare dim(E +F).Consideriamo in R5: Egenerato da e1:=(1,4,0,0,0), e2:=(1,0,0,1,1), e3:=(1,1,0,–1,2);Fgenerato da  f1:= (2,1,1,4,0),  f2 := (–1,1,–1,0,–2). 
e1e2    e3 f1f2rispetto alla base canonicaQuesta matrice ha rango 4. Pertanto dim(E+ F) = 4.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#12,12,"23/11/2013Somma e intersezione di sottospaziTeorema(Formula di Grassmann): Siano Ee Fdue sottospazi vettoriali di dimensione finita di un qualsiasi spazio vettoriale V.Si dimostra che: dim(E+ F) + dim(EÇF) = dim E + dim FEsempio: Consideriamo in R5: Egenerato da e1:=(1,4,0,0,0), e2:=(1,0,0,1,1), e3:=(1,1,0,–1,2);Fgenerato da  f1:= (2,1,1,4,0),  f2 := (–1,1,–1,0,–2).Abbiamo già calcolato che dim(EÇF) = 1 e che dim(E+ F) = 4Alternativamente possiamo osservare che dim E = 3 e dim F = 2Poi, ad esempio, possiamo prendere dim(EÇF) = 1 e ricavare dim(E+ F) = dim E + dim F –dim(EÇF) = 3 + 2 –1 = 4 Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#13,13,"23/11/2014Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
Sia Eil sottospazio avente come base v1e v2(che sono linear. indip.)Sia Fil sottospazio avente come base v3e v4(che sono linear. indip.)Obiettivo: Vogliamo determinare una base per E+ Fe una base per EÇFGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#14,14,"23/11/2015Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
Abbiamo che i vettori v1, v2 , v3, v4sono generatori di E+ F
v1v2 v3v4e1e2e3e4•det A= 0•Il minore di Ain rosso ha det≠ 0•E+ Fha una base formata dai vettori v1, v2 , v3•dim(E+ F) = 3Cerchiamo una base di E+ F
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#15,15,"23/11/2016Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
Un vettore vÎEse e solo se v= h1 v1+ h2v2per h1e h2ÎRUn vettore vÎFse e solo se v= k1 v3+ k2v4per k1e k2ÎRDa cuivappartiene a EÇFse e solo se  h1 v1+ h2v2= k1 v3+ k2v4h1 v1+ h2v2 –k1v3–k2v4  = 0Ponendo h3= –k1e h4= –k2, si ha:       h1 v1+ h2v2 +h3v3+ h4v4 = 0Cerchiamo una base di EÇFdim(EÇF) = 1
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#16,16,"23/11/2017Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
Un vettore vÎEse e solo se v= h1 v1+ h2v2per h1e h2ÎRUn vettore vÎFse e solo se v= k1 v3+ k2v4per k1e k2ÎRDa cuivappartiene a EÇFse e solo se  h1 v1+ h2v2= k1 v3+ k2v4Ponendo h3= –k1e h4= –k2, si ha:       h1 v1+ h2v2 +h3 v3+ h4v4 = 0Sostituendo v1, v2 , v3, v4  e riordinando per e1, e2 , e3, e4si ottiene: 
Cerchiamo una base di EÇFdim(EÇF) = 1
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#17,17,"23/11/2018Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
La combinazione lineare di e1, e2 , e3, e4 (che sono linear. indipend.) è nulla se e solo se i coefficienti sono tutti nulli, ovvero il sistema: rk A= 3
le soluzioni del sistema dipendono da unparametroCerchiamo una base di EÇFdim(EÇF) = 1
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#18,18,"23/11/2019Somma e intersezione di sottospaziEsercizio: Sia Vuno spazio vettoriale avente come base e1, e2 , e3, e4Siano dati i vettori: 
La combinazione lineare di e1, e2 , e3, e4 (che sono linear. indipend.) è nulla se e solo se i coefficienti sono tutti nulli, ovvero il sistema: 
base di EÇFCerchiamo una base di EÇFdim(EÇF) = 1
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#19,19,"23/11/2020Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi M(2, 2, R): 
La matrice Aappartiene a E+ F ? Aappartiene a E+ Fse e solo se esistono una matrice Min Ee una matrice Nin Ftali che A= M+ N.
sono in contraddizioneGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#2,2,"Intersezione di sottospazi vettoriali
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#20,20,"23/11/2021Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi M(2, 2, R): 
La matrice Aappartiene a E+ F ? Aappartiene a E+ Fse e solo se esistono una matrice Min Ee una matrice Nin Ftali che A= M+ N.
Segue che la matriceAnonappartiene a E+ F Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#21,21,"23/11/2022Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi M(2, 2, R): 
La matrice Bappartiene a E+ F ? Bappartiene a E+ Fse e solo se esistono una matrice Min Ee una matrice Nin Ftali che B= M+ N.
Il sistema (di 4 equazioni) risultante è risolubileGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#22,22,"23/11/2023Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi M(2, 2, R): 
La matrice Bappartiene a E+ F ? Bappartiene a E+ Fse e solo se esistono una matrice Min Ee una matrice Nin Ftali che B= M+ N.
Segue che la matriceBappartiene a E+ F 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#23,23,"23/11/2024Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi R4 : 
Stabilire se i vettori (1, 3, 1, 0)e (1, 0, 1, –2) appartengono a E+ F.Dato un generico vettore (x1, x2 , x3 , x4) di E, si ha x1+ x2+ x3+ x4= 0Segue possiamo riscrivere questo vettore: (x1, x2, –x1, –x2). Analogamente, si ha il generico vettore di F : (y1, –y1, y3, –y3).
Svolgendo i calcoli si ottiene che il sistema nonè risolubile. Segue (1,3,1,0) nonappartiene a E+ F.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#24,24,"23/11/2025Somma e intersezione di sottospaziEsercizio: Si considerino i seguenti sottospazi Ee Fdi R4 : 
Stabilire se i vettori (1, 3, 1, 0) e (1, 0, 1, –2)appartengono a E+ F.Dato un generico vettore (x1, x2 , x3 , x4) di E, si ha x1+ x2+ x3+ x4= 0Segue possiamo riscrivere questo vettore: (x1, x2, –x1, –x2). Analogamente, si ha il generico vettore di F : (y1, –y1, y3, –y3).
Svolgendo i calcoli si ottiene che stavolta il sistema è risolubile. Segue (1,0,1, –2) appartiene a E+ F.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#25,25,"23/11/2026Somma e intersezione di sottospaziEsercizio: Sia Uil sottospazio vettoriale di R4generato dai vettori   u1:= (2, 1, 3, 1), u2:= (1, 0, 2, 0), u3:= (4, 2, 6, 2) Sia Vil sottospazio generato da v1:= (1, 0, 2, 1), v2:= (1, 1, 1, –1),  v3:= (2, 1, 3, 0), v4:= (1, –1, 0, 0). Determinare una base per Ue la sua dimensione, una base per Ve la sua dimensione. Determinare poi una base per UÇVe U+ V.
u1u2u3
•dim U= 2rispetto alla base canonica di R4•una base di Uè data dai vettori u1e  u2Gauss
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#26,26,"23/11/2027Somma e intersezione di sottospaziEsercizio: Sia Uil sottospazio vettoriale di R4generato dai vettori   u1:= (2, 1, 3, 1), u2:= (1, 0, 2, 0), u3:= (4, 2, 6, 2) Sia Vil sottospazio generato da v1:= (1, 0, 2, 1), v2:= (1, 1, 1, –1),  v3:= (2, 1, 3, 0), v4:= (1, –1, 0, 0). Determinare una base per Ue la sua dimensione, una base per Ve la sua dimensione. Determinare poi una base per UÇVe U+ V.v1v2v3•dim V= 3rispetto alla base canonica di R4•una base di Vè data dai vettori v1, v2e  v4Gauss
v4
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#27,27,"23/11/2028Somma e intersezione di sottospaziEsercizio: Sia Uil sottospazio vettoriale di R4generato dai vettori   u1:= (2, 1, 3, 1), u2:= (1, 0, 2, 0), u3:= (4, 2, 6, 2) Sia Vil sottospazio generato da v1:= (1, 0, 2, 1), v2:= (1, 1, 1, –1),  v3:= (2, 1, 3, 0), v4:= (1, –1, 0, 0). Determinare una base per Ue la sua dimensione, una base per Ve la sua dimensione. Determinare poi una base per UÇVe U+ V.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#28,28,"23/11/2029Somma e intersezione di sottospaziEsercizio: Sia Uil sottospazio vettoriale di R4generato dai vettori   u1:= (2, 1, 3, 1), u2:= (1, 0, 2, 0), u3:= (4, 2, 6, 2) Sia Vil sottospazio generato da v1:= (1, 0, 2, 1), v2:= (1, 1, 1, –1),  v3:= (2, 1, 3, 0), v4:= (1, –1, 0, 0). Determinare una base per Ue la sua dimensione, una base per Ve la sua dimensione. Determinare poi una base per UÇVe U+ V.
(3, 1, 5, 1) costituisce una base di UÇVdim(UÇV ) = 1 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#29,29,"23/11/2030Somma e intersezione di sottospaziEsercizio: Sia Uil sottospazio vettoriale di R4generato dai vettori   u1:= (2, 1, 3, 1), u2:= (1, 0, 2, 0), u3:= (4, 2, 6, 2) Sia Vil sottospazio generato da v1:= (1, 0, 2, 1), v2:= (1, 1, 1, –1),  v3:= (2, 1, 3, 0), v4:= (1, –1, 0, 0). Determinare una base per Ue la sua dimensione, una base per Ve la sua dimensione. Determinare poi una base per UÇVe U+ V.
dim(UÇV ) = 1 dim(U+ V) = dim U+ dim V–dim (UÇV) = 2 + 3 –1 = 4Segue che U+ V= R4 Allora una base per U+ Vè, ad esempio, la base canonica di R4.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#3,3,"23/11/204Intersezione di sottospazi vettorialiTeorema: L’intersezione E ÇFdi due sottospazi Ee Fdi uno spazio vettoriale Vè un sottospazio vettoriale di V .Osservazione 1: E ÇFdi due sottospazi vettoriali Ee Fèun sottospazio vettoriale sia di Eche di F. Osservazione 2: Se Ee Fsono due sottospazi di dim. finita, allora anche E ÇFha dimensione finita. Inoltre, si ha: dim (E ÇF) ≤ dimEdim(E ÇF) ≤ dim FGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#4,4,"23/11/205Intersezione di sottospazi vettorialiEsercizio: Consideriamo i seguenti sottospazi Ee Fdi M(2, 2, R):
Determinare E ÇFSia Auna generica matrice dello spazio vettoriale M(2, 2, R):
Aappartiene a Esolo se a22= 0 e a12= a21Aappartiene a Fsolo se a22= 0 e a11= a21
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#5,5,"23/11/206Intersezione di sottospazi vettorialiEsercizio: Determinare E ÇF.Consideriamo in R5: Egenerato da e1:=(1,4,0,0,0),  e2:=(1,0,0,1,1),  e3:=(1,1,0,–1,2);Fgenerato da f1:= (2,1,1,4,0),  f2 := (–1,1,–1,0,–2). 
EÇFè l’insieme dei multipli del vettore (1, 2, 0, 4, –2).dim(EÇF) = 1Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#6,6,"Somma di sottospazi vettoriali
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#7,7,"23/11/208Somma di sottospazi vettorialiEsempio: Consideriamo i sottospazi TR(2) e TR(2) di M(n, n, R).L’insieme TR(2) ÈTR(2) sono le matrici triangolari di ordine 2.Sommando due matrici triangolari ne otteniamo una triangolare?No, ecco un contro-esempio: Abbiamo due matrici triangolari la cui somma nonè triangolare! Quindi nonè detto che l’unione di due sottospazi sia un sottospazio.Definizione: Dati due sottospazi Ee Fdi uno spazio vettoriale Vla somma E+ Fè il sottoinsieme di Vformato da tutte le somme del tipo u+ vcon uÎEe  vÎF.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#8,8,"23/11/209Somma di sottospazi vettorialiDefinizione: Dati due sottospazi Ee Fdi uno spazio vettoriale Vla somma E+ Fè il sottoinsieme di Vformato da tutte le somme del tipo u+ vcon uÎEe  vÎF.Osservazione: La somma di due sottospazi E+ Fcontiene Ee F.Dimostrazione: Ogni vettore udi Eè anche un vettore di E+ F : la somma di u(che appartiene ad E) con 0 (che appartiene a F).Teorema: La somma E+ Fdi due sottospazi vettoriali Ee Fdi uno spazio vettoriale Vè un sottospazio vettoriale di V. Se Uè un sottospazio vettoriale di Vcontenente sia Esia F, allora U contiene E+ F.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\11_Operazioni_tra_sottospazi.pdf#9,9,"23/11/2010Somma di sottospazi vettorialiEsercizio: Siano Ee Fsottospazi vettoriali di uno spazio V. Supponiamo che e1, e2 , e3formano una base di E(dimE= 3) e che i vettori f1,  f2formano una base di F(dimF= 2). Osserviamo che un vettore wdi Vappartiene a E+ Fse si può esprimere come sommadi un vettore udi Ee di un vettore vdi F. u= h1 e1+ h2e2+ h3e3per opportuni h1, h2, h3in Rv= k1 f1+ k2f2per opportuni k1, k2in Rw= u + v= h1 e1+ h2e2+ h3e3+ k1 f1+ k2f2Dunque i vettori e1, e2 , e3 ,  f1,  f2generano E+ F. Possiamo allora affermare che dim(E+ F) ≤ 5.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#0,0,Geometria e Combinatoria marcella.sama@uniroma3.itL12: Sottospazi affini (19)Argomenti lezione:•Introduzione•Le rette del piano e dello spazio •I piani dello spazio •Sottospazi affini •L’insieme delle soluzioni di un sistema
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#1,1,"23/11/202IntroduzioneNello spazio vettoriale dei vettori del piano o dello spazio applicati in un punto O:•Le rette passanti per Opossono essere viste come sottospazi vettoriali di dimensione 1. •I piani passanti per Opossono essere visti come sottospazi vettoriali di dimensione 2.Le rette del piano o dello spazio e i piani dello spazio (non necessariamente passanti per O) hanno una struttura algebricapiù generale dei sottospazi vettoriali, chiamata sottospazio affine.L’insieme delle soluzioni di un sistema(anche non omogeneo) di equazioni lineari, quando non è vuoto, è un sottospazio affine.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#10,10,"23/11/2011Sottospazi affiniTeorema: Sia v+ Eun sottospazio affine di uno spazio vettoriale V. Sia wun vettore di V. Possono sussistere due casi: 1.se wÎv+ Eallora v+ E= w+ E ;2.se wÏv+ Eallora l’intersezione di v+ Ee w+ Eè vuota.Dimostrazione: 2. Supponiamo ora che wÏv+ E . Procediamo per assurdo: Se esistesse un uappartenente all’intersezione di v+ Ee w+ E,avremmo che v+ E= u+ Ee  w+ E= u+ E . Ma allora w+ E= v+ E. Poiché w+ 0 Îw + E(in quanto 0 è un vettore di E) avremmo che wÎv+ E. Segue l’assurdo. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#11,11,"23/11/2012Sottospazi affiniTeorema: Sia v+ Eun sottospazio affine di uno spazio vettoriale V. Sia wun vettore di V. Possono sussistere due casi: 1.se wÎv+ Eallora v+ E= w+ E ;2.se wÏv+ Eallora l’intersezione di v+ Ee w+ Eè vuota.Esempio 1: Dato M(2, 2, R), si ha:Verificare che il sottospazio affine C+ S(2, R) coincidecon S(2, R). 
Ponendo t1’ := 1 + t1,  t2’ := 2 + t2,  t3’ := 4 + t3, otteniamo:
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#12,12,"23/11/2013Sottospazi affiniTeorema: Sia v+ Eun sottospazio affine di uno spazio vettoriale V. Sia wun vettore di V. Possono sussistere due casi: 1.se wÎv+ Eallora v+ E= w+ E ;2.se wÏv+ Eallora l’intersezione di v+ Ee w+ Eè vuota.Esempio 2: Dato un sottospazio affine v0+ Edi uno spazio Vdimostrare che: A.se v0ÎEallora  v0+ E=Eè un sottospazio vettoriale;B.se v0ÏE allora  v0+ Enonè un sottospazio vettoriale.A.Se v0ÎEallora v0+ E= 0 + E= E.                                              Quindi il sottospazio affine 0 + Eè un sottospazio vettoriale.B.Se v0ÏEallora v0+ Ee  0 + E= Ehanno intersezione vuota. Pertanto, v0+ Enonè un sottospazio vettoriale.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#13,13,"Soluzioni di un sistema come spazi
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#14,14,"23/11/2015L’insieme delle soluzioni di un sistemaEsempio: Prendiamo il seguente sistema risolubile: 
Eè un sottospazio vettoriale di M(4, 1, R) di dimensione 2.Segue Sol(S) è un sottospazio affine.In particolare, se h= k= 0 abbiamo la soluzione (–1, 2, 0, 0). Eal variare di he kin R
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#15,15,"23/11/2016L’insieme delle soluzioni di un sistemaProcedimento generale: Dato un sistema lineare qualsiasi S: AX= Bdi pequazioni nelle qincognite x1, x2, . . . , xq.Se rk A= r, sappiamo che q–r incognite fungeranno da parametri.sottospaziovettoriale Eal variare dei parametri reali h1, h2, ... , hq–r.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#16,16,"23/11/2017L’insieme delle soluzioni di un sistemaDefinizione: Dato un sistema lineare qualsiasi S: AX= B, chiamiamo sistema omogeneo associatoa Sil sistema SO: AX= 0.In altri termini, il sistema SO si ottiene da Ssemplicemente ponendo = 0 tutti i termini noti delle equazioni che formano S.Esempio: 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#17,17,23/11/2018L’insieme delle soluzioni di un sistemaTeorema: Sia S: AX = Bun sistema lineare risolubile. Sia X0una soluzione particolare di S. Sia SO: AX= 0 il sistema omogeneo associato a S.Sol(S) = X0+ Sol(SO) è un sottospazio affineparallelo a Sol(SO). Dimostrazione: Mostriamo che X0+ Sol(SO) ÍSol(S). Un X0+ Sol(SO) si può scrivere X0+ X ’ con X ’ soluzione di SO.X0+ X ’ è soluzione di Sse e solo se A(X0+ X ’) = B.Poiché X0è una soluzione di Sabbiamo che AX0= B. Poiché X ’è una soluzione di SOabbiamo che AX ’ = 0. Segue: A(X0+ X ’) = AX0+ AX ’ = B+ 0 = B .Abbiamo quindi dimostrato che X0+ X ’ appartiene a Sol(S).Geometria e Combinatoria marcella.sama@uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#18,18,"23/11/2019L’insieme delle soluzioni di un sistemaTeorema: Sia S: AX = Bun sistema lineare risolubile. Sia X0una soluzione particolare di S. Sia SO: AX= 0 il sistema omogeneo associato a S.Sol(S) = X0+ Sol(SO) è un sottospazio affineparallelo a Sol(SO). Dimostrazione: Mostriamo che Sol(S) ÍX0+ Sol(SO). Sia allora X1un elemento di Sol(S), dobbiamo mostrare che X1= X0+ X ’ per qualche X ’ di Sol(SO).Se X1= X0+ X ’ allora si ha X ’ = X1–X0 .Quindi dobbiamo mostrare che AX ’ = A(X1–X0) = 0 .Poiché X1e X0sono soluzioni di Sabbiamo che AX1= Be AX0= B.Segue: AX ’ = A(X1–X0) = AX1–AX0= B –B = 0 .Abbiamo quindi dimostrato che X ’ appartiene a Sol(SO).Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#19,19,"23/11/2020L’insieme delle soluzioni di un sistemaProposizione: Sia Sun sistema lineare risolubile di pequazioni nelle qincognite x1, x2, . . . , xq. Se la matrice del sistema ha rango rallora il sottospazio affine Sol(S) ha dimensione q–r.Esempio 1: L’insieme sol(S) è un sottospazio affine di R5 ? Dobbiamo verificare che  S≠ Æovvero  Sè risolubile.rk A= 2. Anche la matrice completa del sistema ha rango 2. Segue il sistema Sè risolubile, quindi è un sottospazio affine.Il sistema Sha q= 5 e r= 2  segue  dimSol(S) = 5 –2 = 3.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#2,2,"23/11/203Le rette del piano e dello spazioTeorema: Sia runa retta e sia P0un suo punto.                               Sia r’ la retta parallela a rpassante per il punto O.                                  Allora PÎrse e solo se esiste QÎr’ tale che: OP= OP0+ OQ .Equivalentemente: Sia Eil seguente sottospazio vettoriale diV 2(O) oppure di V 3(O) di dimensione 1:  E:= {OQ| QÎr’}.PÎrse e solo se il vettore v:= OPappartiene a {v0+ v’ | v’ ÎE}.→→→→→
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#20,20,"23/11/2021L’insieme delle soluzioni di un sistemaProposizione: Sia Sun sistema lineare risolubile di pequazioni nelle qincognite x1, x2, . . . , xq. Se la matrice del sistema ha rango rallora il sottospazio affine Sol(S) ha dimensione q–r.Esempio 2: L’insieme sol(S) è un sottospazio affine di R5 ? Dobbiamo verificare che  S≠ Æovvero  Sè risolubile.rk A= 2. Stavoltala matrice completa del sistema ha rango 3. Segue il sistema Snonè risolubile, e nonè un sottospazio affine.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#21,21,"23/11/2022L’insieme delle soluzioni di un sistemaEsercizio: Scrivere le soluzioni del seguente sistema lineare:come sottospazio affine v0+ Edi R4, determinando esplicitamente un vettore v0e una base per E.Risolvendo il sistema si ha:al variare di te uin RLa generica soluzione del sistema può allora essere scritta così:v0E
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#3,3,"23/11/204Le rette del piano e dello spazioOsservazione 1: Nel teorema precedente abbiamo scelto un punto P0sulla retta r : se scegliamo un differente punto Q0, posto w0:= OQ0abbiamo chePÎrse e solo se il vettore v:= OPappartiene a {w0+ v’ | v’ ÎE}.Segue gli insiemi {v0+ v’ | v’ ÎE} e {w0+ v’ | v’ ÎE} coincidono. 
→
Q0w0→
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#4,4,"23/11/205Le rette del piano e dello spazioOsservazione 2: L’uguaglianza tra gli insiemi {v0+ v’ | v’ ÎE} e {w0+ v’ | v’ ÎE} non significa che v0+ v’ = w0+ v’ per v’ ÎE , altrimenti v0= w0. Significa inveceche dato un qualunque vettore v0+ v’ con v’ ÎEesiste un vettore v’’ ÎEtale che v0+ v’ = w0+ v’’. 
Q0w0v’’Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#5,5,"23/11/206Le rette del piano e dello spazioOsservazione 2: L’uguaglianza tra gli insiemi {v0+ v’ | v’ ÎE} e {w0+ v’ | v’ ÎE} non significa che v0+ v’ = w0+ v’ per v’ ÎE , altrimenti v0= w0. Significa inveceche dato un qualunque vettore v0+ v’ con v’ ÎEesiste un vettore v’’ ÎEtale che v0+ v’ = w0+ v’’. v’ e rsi dicono parallelise QÎr’ parallela a re passante per O.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#6,6,Teorema: Sia  πun piano e sia P0un suo punto. Sia π’ il piano parallelo a  πpassante per O. Allora PÎπse e solo se esiste QÎπ’ tale che: OP= OP0+ OQ .Equivalentemente: Sia Eil sottospazio vettoriale di V 3(O)di dimensione 2:   E:= {OQ| QÎπ’}.PÎπse e solo se v:= OPappartiene a {v0+ v’ | v’ ÎE}.23/11/207I piani dello spazio→→→→→Geometria e Combinatoria marcella.sama@uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#7,7,"Sottospazi Affini
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#8,8,"23/11/209Sottospazi affiniDefinizione: In uno spazio vettoriale Vsiano dati un vettore v0e un sottospazio vettoriale E. L’insieme v0+ E:= {v0+v’ |v’ ÎE}viene chiamato sottospazio affinepassante per v0e parallelo a E. Per definizione: dim(v0+ E ) = dim(E ).Esempio: Dato lo spazio vettoriale M(2, 2, R), si ha: 1. Mostrare i vettori appartenenti al sottospazio affine A + S (2, R).2. Verificare che A + S (2, R) non è un sottospazio vettoriale.
A + S (2, R)nonè quindi un sottospazio vettoriale!
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\12_Spazi_affini.pdf#9,9,23/11/2010Sottospazi affiniTeorema: Sia v+ Eun sottospazio affine di uno spazio vettoriale V. Sia wun vettore di V. Possono sussistere due casi: 1.se wÎv+ Eallora v+ E= w+ E ;2.se wÏv+ Eallora l’intersezione di v+ Ee w+ Eè vuota.Dimostrazione: 1. Supponiamo che wÎv+ E. Allora w= v+ v’ per qualche v’ ÎE. Mostriamo ora che v+ EÊw+ E.Un vettore di w+ Esi può scrivere come w+ ucon uÎE. Ma allora w+ u= (v+ v’) + u= v+ (v’ + u) Îv+ E.Abbiamo così mostrato che v+ EÊw+ E. Per mostrare v+ EÍw+ Esi procede in maniera analoga.Geometria e Combinatoria marcella.sama@uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#0,0,15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it1L13: Omomorfismi (26)Argomenti lezione:•Introduzione•Omomorfismi tra spazi vettoriali •Matrice associata a un omomorfismo •Omomorfismo associato a una matrice•Esercizi 
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#1,1,"15/12/202Omomorfismo
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#10,10,"15/12/2011Omomorfismi tra spazi vettorialiEsercizio: Data f : M(2, 2, R) →M(2, 2, R) definitada:f (A) := A+ tAVerifichiamo se fè un omomorfismo di spazi vettoriali:1. Prese due matrici Ae Bdi M(2, 2, R), si ha:f(A+ B) = A+ B+ t(A+ B)= A+ B+ tA+ tBf(A) + f(B) = A+ tA+ B+ tBf(A+ B) =f(A) + f(B) 2. Prese una matrice Adi M(2, 2, R) e uno scalare kdi R, si ha:f(kA) = kA+ t(kA) = kA+ ktAkf(A) = k(A+ tA) = kA+ ktAf(kA) = kf(A) =>  fè un omomorfismo di spazi vettoriali su R!15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#11,11,"15/12/2012Omomorfismi tra spazi vettorialiEsercizio: Data f : R2→R2definita da: f (x,y)= (x2,x + y)Verifichiamo se fè un omomorfismo di spazi vettoriali:1. Presi due vettori u:= (x1 , y1)  e  v:= (x2 , y2) di R2, si ha:f(u + v)       =  f((x1 , y1) + (x2 , y2))=  f(x1+ x2 , y1+ y2)= ((x1+ x2)2 , x1+ x2+ y1+ y2)= (x12+ 2 x1 x2+ x22, x1+ x2+ y1+ y2)f(u) + f(v)  =  f(x1 , y1) + f (x2, y2)= (x12, x1+ y1) + (x22, x2+ y2)= (x12+ x22, x1+ x2+ y1+ y2)Notiamo che  f(u + v) =  f(u) +  f(v)  se e solo se  x1 x2= 0 Infatti tale relazione, e.g., nonè verificata se u:= (1, 0)  e  v:= (1, 0)Dunque  fnonè un omomorfismo di spazi vettoriali ! 15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#12,12,"15/12/2013Matrice associata a un omomorfismo
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#13,13,"15/12/2014Matrice associata a un omomorfismoDato un omomorfismo f: V→Wdi spazi vettoriali:Se conosciamo f(u) e f(v) allora conosciamo anche f(u+ v). Possiamo anche determinare l’immagine di vettori del tipo ku. Più in generale: Se f: V→Wè un omomorfismo di spazi vettoriali e se conosciamo l’immagine tramite fdi v1, v2, … , vndi V,di quali altri vettori di Vpossiamo determinare l’immagine? Proposizione: Sia f: V→Wun omomorfismo di spazi vettoriali. Siano v1, v2, … , vnvettori di Ve  k1, k2, . . . , knscalari. Si ha:f (k1v1+ k2v2+ … + knvn) = k1  f (v1) +k2  f (v2) + … + kn  f (vn)Dunque f (v1),  f (v2), … ,  f (vn) ci permettono di determinare l’immagine tramite fdi tutte le combinazioni linearidi v1, v2, … , vn15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#14,14,"15/12/2015Matrice associata a un omomorfismoProposizione: Siano f: V→W e  g: V→Wdue omomorfismi    di spazi vettoriali. Se v1, v2, . . . , vngenerano Ve  f (vj) = g(vj)     per 1 ≤  j≤ nallora  f= g. Dimostrazione: Bisogna mostrare che f (v) = g(v) per ogni vettore vin V .Sappiamo che vè combinazione lineare di v1, v2, . . . , vn:v= k1v1+ k2v2+…+ knvnAllora per la proposizione vista in precedenza abbiamo chef (v) = f (k1v1+ k2v2+…+ knvn) = k1  f (v1) + k2f (v2) +…+ kn  f (vn)g(v) = g(k1v1+ k2v2+…+ knvn) = k1 g(v1)  + k2 g(v2)  +…+ kn g(vn)Poiché  f (v1) = g(v1), …,  f (vn) = g(vn), abbiamo che f (v) = g(v). 15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#15,15,"15/12/2016Matrice associata a un omomorfismoSe v1, v2, . . . , vnsono dei generatori di V, un omomorfismo              f: V→Wè completamente descritto tramite f (v1), f (v2), … , f (vn).Domanda: Si trova un’applicazione lineare per ogni v1, v2, ... , vn? La risposta è negativa, vediamo un contro-esempio:Lo spazio vettoriale R2è generato dai vettori (1, 0), (0, 1), (1, 1).Non esiste alcuno omomorfismo f: R2→R3tale che                        f (1, 0) = (0, 0, 0),   f (0, 1) = (0, 0, 0),   f (1, 1) = (1, 0, 0). Infatti se un tale omomorfismo esistesse dovremmo avere:f (1, 1) =f ((1, 0) + (0, 1)) = f (1, 0) + f (0, 1) = (0, 0, 0) + (0, 0, 0) = (0, 0, 0)15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#16,16,"15/12/2017Matrice associata a un omomorfismoSe però i generatori considerati costituiscono una baseabbiamo:Teorema: Siano dati: due spazi vettoriali Ve W ; una base di Vcostituita dai vettori e1, e2, ... , en; i vettori w1, w2, ... , wndi W. Esiste un unico f: V→Wtale che:  f (ej) = wjper 1 ≤ j≤ n.Osservazione: Notiamo che non abbiamo fatto alcuna richiesta sui vettori w1, w2, ... , wndi W : ne che siano linearmente indipendenti ne che generino W.
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#17,17,"15/12/2018Matrice associata a un omomorfismoDefinizione: Sia f: V→Wun omomorfismo di spazi vettoriali didimensione finita. Fissiamo una base di Vformata dai e1, e2, … , en e una base di Wformata dai f1,  f2, … , fm . Possiamo esprimere ciascun vettore f (ej) come combinazione lineare dei f1,  f2, … ,  fm :f (e1) = a11  f1+ a21f2+…+ am1  fmf (e2) = a12  f1+ a22  f2+…+ am2  fm...f (en) = a1nf1+ a2n  f2+…+ amn  fmLa matrice Adi M (m, n, R) è detta matrice rappresentativa di frispetto alle basi e1, e2, … , ene   f1,  f2, … , fmLa j-esima colonna di Aè data dalle componenti del vettore f (ej)  rispetto alla base formata dai vettori f1,  f2, … , fm
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#18,18,"15/12/2019Matrice associata a un omomorfismoEsercizio: Sia f : R3→R2l’omomorfismo f (x, y, z) = (x+ y, y+z)e1:= (1, 0, 0), e2:= (1, 1, 0), e3:= (1, 1, 1) formano una base per R3f1:= (1, 1),  f2:= (2, 1) formano una base per R2 Determiniamo la matrice rappresentativa di  frispetto a tali basi.      f (e1) = f (1, 0, 0) = (1, 0)f (e2) = f (1, 1, 0) = (2, 1)f (e3) = f (1, 1, 1) = (2, 2) Decomponiamo le immagini rispetto alla base composta da f1  e  f2:f (e1) = (1, 0) = − (1, 1) + 1 (2, 1) = −1 f1+ 1 f2f (e2) = (2, 1) = 0 (1, 1) + 1 (2, 1) =  0f1  + 1 f2f (e3) = (2, 2) = 2 (1, 1) + 0 (2, 1) = 2f1+ 0 f2La matrice rappresentativa di  f  rispetto alle basi assegnate è A. 
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#19,19,"15/12/2020Matrice associata a un omomorfismoEsercizio: Sia f : R3→R2l’omomorfismo f (x, y, z) = (x+ y, y+z)Prendiamo due basi differenti: e'1:= (0, 1, 1), e'2:= (1, 0, 1), e'3:= (1, 1, 0) formano una base per R3f '1:= (0, 2),  f '2:= (1, 1) formano una base per R2Determiniamo la matrice A’rappresentativa di  frispetto a tali basi.
≠15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#2,2,"15/12/203FunzioniDefinizioni: Siano Ae Bdue insiemi qualsiasi. Una funzione(o applicazione) f: A→Bè una legge che associa ad ogni elemento aÎAun elemento bÎB.L’insieme Asi dice insieme di partenzao dominiodi f. L’insieme Bsi dice insieme di arrivoo codominiodi f.L’elemento bviene indicato con f (a) è chiamato immaginedi a. L’insieme f (A) delle immagini degli elementi di Aviene chiamatoimmaginedi Aattraverso la funzione f(o anche immaginedi f ):Dato bÎB:  bÎf (A) se e solo seesiste aÎAtale che f (A) = b
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#20,20,"15/12/2021Matrice associata a un omomorfismoEsercizio:  f : M(2, 2, R) →M(2, 2, R) omomorfismo f (A) := A+ tAPer rappresentare f con una matrice dobbiamo fissare una base per M(2, 2, R) «di partenza» e una base per M(2, 2, R) «di arrivo».       In questo esempio prendiamo in entrambi i casi la base canonica. 
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#21,21,"15/12/2022Matrice associata a un omomorfismoEsercizio: Sia f : R3→R2l’omomorfismo f (x, y, z) = (x+ y, y+z)Per rappresentare frispetto alle basi canoniche di R3ed R2usiamo le immagini dei vettori e1:= (1, 0, 0), e2:= (0, 1, 0), e3:= (0, 0, 1)  espresse come combinazione lineare di  f1:= (1, 0),  f2:= (0, 1).La matrice Arappresentativa di frispetto alle basi canoniche è : 
Le colonnedi Adanno f (e1),  f (e2),  f (e3)  Le righedi Acorrispondono ai coefficientidi x, y, znelle espressioni (x+ y)e (y+ z)Tutto ciò vale soloquando rappresentiamo    frispetto alle basi canoniche!15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#22,22,"15/12/2023Matrice associata a un omomorfismoEsercizio: Sia f : R3→R2l’omomorfismo f (x, y, z) = (x+ y, y+z)Per rappresentare frispetto alle basi canoniche di R3ed R2usiamo le immagini dei vettori e1:= (1, 0, 0), e2:= (0, 1, 0), e3:= (0, 0, 1)  espresse come combinazione lineare di  f1’:= (1, 1),  f2’:= (2, −1).La matrice A’rappresentativa di  frispetto alle nuove basiè : 
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#23,23,"15/12/2024Matrice associata a un omomorfismoTeorema: Sia f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Siano fissate una base per Vformata dai vettori e1, e2, ... , ene una base per Wformata dai vettori f1,  f2, … , fm.     Sia Ala matrice rappresentativa di frispetto alle basi fissate.     Dato un vettore vdi Vpossiamo determinare f (v) come segue:1. Per prima cosa esprimiamo vcome combinazione lineare dei vettori della base e1, e2, … , en   :   v= b1 e1+ b2 e2+ … + bn en2. Calcoliamo poi il prodotto matriciale:3. Per ottenere f (v) basta ora calcolare la combinazione lineare:f (v) = c1  f1+ c2  f2+ … + cm  fm
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#24,24,"15/12/2025Omomorfismo associato a una matrice
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#25,25,"15/12/2026Omomorfismo associato a una matriceTeorema: Siano Ve Wdue spazi vettoriali di dimensione finita.   Sia data una base per Vformata dai vettori e1, e2, . . . , ene  una base per Wformata dai vettori f1, f2, . . . , fm. Allora esiste un unico omomorfismof: V→W, la cui matrice rappresentativa rispetto alle basi fissate è A di tipo M (m, n, R).
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#26,26,"15/12/2027Omomorfismo associato a una matriceDefinizione: Siano Ve Wdue spazi vettoriali di dimensione finita. Sia data una base per Vformata da e1, e2, … , ene una base per Wformata dai f1, f2, … ,  fm. Sia Auna matrice di tipo M (m, n, R): Si denota “omomorfismo associato ad Arispetto alle basi fissate”l’omomorfismo  f definito da:
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#27,27,"15/12/2028Omomorfismo associato a una matriceEsercizio: Sia  f : R3→R2l’omomorfismo associato alla matrice:Determinare f(x, y, z) per ogni (x, y, z) in R3.Calcoliamo le componenti di (x, y, z) rispetto alla base data di R3 :(x, y, z) = z(1, 1, 1) + (y− z) (1, 1, 0) + (x− y) (1, 0, 0)Per ottenere le componenti di f(x, y, z) rispetto alla base data di R2basta allora calcolare il prodotto di matrici:e1:= (1, 1, 1), e2:= (1, 1, 0), e3:= (1, 0, 0)f1:= (1, 1),  f2:= (1, −1)
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#28,28,"15/12/2029Omomorfismo associato a una matriceEsercizio: Sia  f : R2→R3definita da:  f (x, y) := (xy, x− y, 0)V ogliamo stabilire se  fè lineare. Troviamo le immagini di  fper i vettori della base canonica di R2f (1, 0) = (0, 1, 0),    f (0, 1) = (0, − 1, 0). Poi consideriamo l’unica applicazione lineareg : R2→R3definita dalle medesime condizioni g(1, 0) = (0, 1, 0),   g(0, 1) = (0, − 1, 0).La matrice rappresentativa di grispetto alle basi canoniche è : 
Si vede allora facilmente che:g(x,y) = (0, x − y,0)  da cui  f≠  gPer verifica mostriamo un vettore su cui le due funzioni  fe   gassumono valori diversi: f (1, 1) = (1, 0, 0),   g (1, 1) = (0, 0, 0). Segue la confermache  f≠ g.  Pertanto,  fnonè lineare.15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#29,29,"15/12/2030Omomorfismo associato a una matriceEsercizio: Sia  f : R2→R3definita da:  f (x, y) := (x+y,x−1,2x− y)V ogliamo stabilire se  fè lineare. Troviamo le immagini di  fper i vettori della base canonica di R2f (1, 0) = (1, 0, 2),    f (0, 1) = (1, − 1, − 1). Poi consideriamo l’unica applicazione lineareg : R2→R3definita dalle medesime condizioni g(1, 0) = (1, 0, 2),  g(0, 1) = (1, −1, −1).La matrice rappresentativa di grispetto alle basi canoniche è : Si vede allora facilmente che:g(x,y) = (x + y, − y, 2x − y)  da cui  f≠  gPer verifica mostriamo un vettore su cui le due funzioni  fe   gassumono valori diversi: f (2, 0) = (2, 1, 4),   g (2, 0) = (2, 0, 4). Segue la confermache  f≠ g.  Pertanto,  fnonè lineare.
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#3,3,"15/12/204Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)   per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)           per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:1.Presi due vettori u:= (x1, y1, z1) e v:= (x2, y2, z2) di R3f (u+ v)  = f((x1, y1, z1) + (x2,y2,z2)) =per la def. di somma in R3=  f (x1+ x2, y1+ y2, z1+ z2)  =  per la def. di f                       = (x1+ x2+ y1+ y2, y1+ y2+ z1+ z2)15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#30,30,"15/12/2031Omomorfismo associato a una matriceEsercizio: Sia  f : R2→R3definita da:  f (x, y) := (0, −x,2x − y)V ogliamo stabilire se  fè lineare. Troviamo le immagini di  fper i vettori della base canonica di R2f (1, 0) = (0, −1, 2),    f (0, 1) = (0, 0, −1). Poi consideriamo l’unica applicazione lineareg : R2→R3definita dalle medesime condizioni g(1, 0) = (0, −1, 2),  g(0, 1) = (0, 0, −1).La matrice rappresentativa di grispetto alle basi canoniche è : Si vede allora facilmente che:g(x,y) = (0, −x,2x − y)  da cui  f=  gPertanto,  fè lineare.
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#31,31,"15/12/2032Omomorfismo associato a una matriceOsservazione: L’esempio precedente ha in realtà validità generale!L’unica cosa che abbiamo sfruttato è che ciascuna delle espressioni 0, − x, 2x− yè un polinomio omogeneo di primo gradoin xe yoppure il polinomio nullo. [ Ricordiamo che un polinomio omogeneo di primo grado è un polinomio in cui tutti gli addendi sono monomi di grado 1 ]Esaminando gli esempi visti:2x− y+ 1 è un polinomio di primo grado non omogeneo,perché tra i suoi addendi c’è 1.xyè un polinomio omogeneo di secondo grado.15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#32,32,"15/12/2033OmomorfismiEsercizio: Stabilire se esistono omomorfismi f: R3→R2di spazi vettoriali tali che:f(1, 2, 1) = (0, 1)f (1, 0, 2) = (0, 1)f(2, 2, 1) = (2, 1)In caso affermativo stabilire se esiste uno solo di tali omomorfismi.I tre vettori (1, 2, 1), (1, 0, 2), (2, 2, 1) formano una base per R3 :
Essendo i tre vettori una base, allora esiste esattamente un solo omomorfismo  fche soddisfa le condizioni date.15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#33,33,"15/12/2034OmomorfismiEsercizio: Stabilire se esistono omomorfismi  f: R3→R[x] di spazi vettoriali tali che:f (1, 3, 0) = xf(0, 1, 1) = x2f(1, 5, 2) = x+ x2In caso affermativo stabilire se esiste uno solo di tali omomorfismi.I vettori (1, 3, 0), (0, 1, 1) e (1, 5, 2) nonformano una base per R3 : 
Infatti: (1, 5, 2) = (1, 3, 0) + 2(0, 1, 1)f (1, 5, 2)  ≠f (1, 3, 0) + 2 f (0, 1, 1)f (1, 5, 2) = x+ x2f (1, 3, 0) + 2 f (0, 1, 1) = x+ 2x215/12/20Geometria e Combinatoria marcella.sama@uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#34,34,"15/12/2035OmomorfismiEsercizio: Sia f: R3→R2l’omomorfismo definito dalle condizioni  f (1, 0, 1) := (3, 1),   f (1, 1, 1) := (1, 2),   f (0, 0, 1) := (0, 1). Determinare la matrice rappresentativa di frispetto alle basi canoniche di R3e R2.
La matrice di frispetto alle basi canoniche è :15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#35,35,"15/12/2036OmomorfismiEsercizio: Sia f: R3→R2l’omomorfismo definito dalle condizioni  f (1, 0, 1) := (3, 1),   f (1, 1, 1) := (1, 2),   f (0, 0, 1) := (0, 1). Determinare la matrice rappresentativa di frispetto alle base di R3formata dai vettori v1:= (1, 0, 1), v2:= (1, 1, 1), v3:= (0, 0, 1)         e alla base di R2formata dai vettori w1:= (1, 1), w2:= (1, 2).
La matrice di frispetto alle basi assegnate è :
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#36,36,"15/12/2037OmomorfismiEsercizio: Stabilire se esiste un omomorfismo che verifica le seguenti condizioni e, in caso affermativo, dire se l’omomorfismo è unico.f: R3[x] → R2tale che:f (1 + x2) = (1, –2)f (2 + x+ x2) = (1, 0)I polinomi 1 + x2, 2 + x+ x2sono linearmente indipendenti. Se p3(x) è un qualsiasi vettore che insieme a 1 + x2e 2 + x+ x2forma una base di R3[x], allora per ogni vettore w3di R2esiste un unico omomorfismo f: R3[x] → R2tale che f (1 + x2) = (1, –2), f (2 + x+ x2) = (1, 0),   f(p3(x)) = w3.  Per l’arbitrarietà di w3abbiamo allora infiniti omomorfismi come quello cercato.15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it37"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#37,37,"15/12/2038OmomorfismiEsercizio: Determinare l’immagine del vettore (x, y, z, w) tramite l’omomorfismo  f: R4→ R3associato alla seguente matrice: e1:= (1, 2, 0, 0), e2:= (1, 0, 1, 0), e3:= (1, 3, 0, 0), e4:= (0, 0, 0, 1)f1:= (1, 2, 1), f2:= (1, 0, 2), f3:= (2, 2, 1)
Notiamo che in questo sistema noi conosciamo x, y, z, we dobbiamo determinare a, b, c, d.
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it38"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#38,38,"15/12/2039OmomorfismiEsercizio: Determinare l’immagine del vettore (x, y, z, w) tramite l’omomorfismo  f: R4→ R3associato alla seguente matrice: e1:= (1, 2, 0, 0), e2:= (1, 0, 1, 0), e3:= (1, 3, 0, 0), e4:= (0, 0, 0, 1)f1:= (1, 2, 1), f2:= (1, 0, 2), f3:= (2, 2, 1)
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it39"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#39,39,"15/12/2040OmomorfismiEsercizio: Determinare l’immagine del vettore (x, y, z, w) tramite l’omomorfismo  f: R4→ R3associato alla seguente matrice: e1:= (1, 2, 0, 0), e2:= (1, 0, 1, 0), e3:= (1, 3, 0, 0), e4:= (0, 0, 0, 1)f1:= (1, 2, 1), f2:= (1, 0, 2), f3:= (2, 2, 1)
15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it40"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#4,4,"15/12/205Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)   per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)           per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:1.Presi due vettori u:= (x1, y1, z1) e v:= (x2, y2, z2) di R3f (u+ v)  =  (x1+ x2+ y1+ y2, y1+ y2+ z1+ z2)f (u) + f (v) =  f (x1, y1, z1) + f (x2, y2, z2) =per la def.di f= (x1+ y1, y1+ z1) + (x2+ y2, y2+ z2) =per la def. di somma in R2 = (x1+ y1+ x2+ y2, y1+ z1+ y2+ z2)15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#5,5,"15/12/206Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)           per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:1.Presi due vettori u:= (x1, y1, z1) e v:= (x2, y2, z2) di R3f (u+ v)  =(x1+ x2+ y1+ y2, y1+ y2+ z1+ z2)OKf (u) + f (v)=  f (x1, y1, z1) + f (x2, y2, z2) =per la def.di f= (x1+ y1, y1+ z1) + (x2+ y2, y2+ z2) =per la def. di somma in R2 =(x1+ y1+ x2+ y2, y1+ z1+ y2+ z2)OK15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#6,6,"15/12/207Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)   per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)           per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:2.Presi un vettore u:= (x,y,z) di R3e uno scalare kdi Rf(k u) = f(k(x,y,z)) =per la def. di prodotto in R3                 = f(k x, k y, k z) =per la def. di f= (k x+ k y, k y+ k z)15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#7,7,"15/12/208Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)   per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)           per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:2.Presi un vettore u:= (x,y,z) di R3e uno scalare kdi Rf(k u) = (k x+ k y, k y+ k z)kf (u)  =  kf(x,y,z) =per la def. di f=  k(x+ y, y+ z) =per la def. di prodotto in R2                =  (k x+ k y, k y+ k z)15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#8,8,"15/12/209Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)   per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:2.Presi un vettore u:= (x,y,z) di R3e uno scalare kdi Rf(k u) =(k x+ k y, k y+ k z)OKkf (u)=  kf(x,y,z) =per la def. di f=  k(x+ y, y+ z) =per la def. di prodotto in R2                =(k x+ k y, k y+ k z)OK15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\13_Omomorfismo.pdf#9,9,"15/12/2010Omomorfismi tra spazi vettorialiDefinizione: Sia f: V→Wun’applicazione tra due spazi Ve W. L’applicazione fsi dice omomorfismodi spazi vettoriali o applicazione lineare se valgono entrambele proprietà:1.f (u+ v) = f (u) + f (v)per ogni uÎV, vÎV   [addizione]  2.f (k u)    = k f (u)per ognik ÎR, uÎV[moltiplicazione]Esempio: Data f : R3→R2definita da:  f (x,y,z) := (x + y, y + z)Verifichiamo se fè un omomorfismo di spazi vettoriali:1.Presi due vettori u:= (x1, y1, z1) e v:= (x2, y2, z2) di R3f (u+ v)  =f (u) + f (v)2.Presi un vettore u:= (x,y,z) di R3e uno scalare kdi Rf(k u) = kf (u)=> fè un omomorfismodi spazi vettoriali !15/12/20Geometria e Combinatoria marcella.sama@uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#0,0,Geometria e Combinatoria marcella.sama@uniroma3.itL14: Immagine (27)Argomenti lezione:•Immagine di un omomorfismo•Calcolo dell’immagine•Esercizi
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#1,1,"15/12/202Immagine di un omomorfismoRicordiamo che, data un’applicazione tra insiemi f: A→B, l’immaginedi fè il sottoinsieme f (A) dell’insieme Bformato dalle immagini degli elementi di Atramite f . Vale a dire da tutti gli elementi bdi Bper cui esiste ain Atale che f (a) = b.Esempio: Sia  f: R2→R3definita da: f (x, y) := (x+2y, x+ y, x −y).L’immagine di  fsi determina tramite i w:= (a, b, c) di R3per cui esiste v:= (x, y) tale che f (v) = w. Cioè: (x+2y, x+y, x−y) = (a, b, c).Da cui il vettore vesiste se e solo se il seguente sistema è risolubile:
metodo di Gauss
Il sistema è risolubile  se e solo se2a− 3b+ c= 0. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#10,10,"15/12/2011Calcolo dell’immagineEsercizio: Prendiamo l’omomorfismo f: R3→R4 [x] definito da:f (a, b, c) := (2a +b +8c) + (3a −b +7c) x+ (−a −3c) x2+ (b+ 2c) x3Determinare una base per f (R3).La matrice A rappresentativa di frispetto alle basi canoniche è :La matrice ha rango 2: dim  f (R3) = 2. Poichè gli scalini sono in I e II posizione, una base per f (R3) è formata dall’immagine dei primi due vettori della base canonica di R3, cioè da f (1, 0, 0) e  f (0, 1, 0).Una base per f (R3) è formata dai vettori: 2 + 3x− x2e  1 − x+ x3.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#11,11,"15/12/2012Calcolo dell’immagineEsercizio: Stabilire se i seguenti omomorfismi sono suriettivi:
Possiamo dire subito che  fnon è suriettivo (i.e. f (V) ≠W) : R3ha dimensione finita, mentre R[x] non ha dimensione finita.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#12,12,"15/12/2013Calcolo dell’immagineEsercizio: Stabilire se i seguenti omomorfismi sono suriettivi:
La matrice Arappresentativa di frispetto alle basi canoniche é:Si verifica facilmente che questa matrice ha rango 3 e, quindi, dim  f (R3) = 3. Pertanto  f  è suriettivo(i.e. f (V) = W).
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#13,13,"15/12/2014Calcolo dell’immagineEsercizio: Stabilire se i seguenti omomorfismi sono suriettivi:
Possiamo dire subito che  fnon è suriettivo(i.e. f (V) ≠W) : infatti dim R3< dim M (2, 2, R).
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#14,14,"15/12/2015Calcolo dell’immagineEsercizio:  Sia  f: M (2, 2, R) →R2l’applicazione definita da:Mostrare che  fè un omomorfismo e stabilire se  f  è suriettivo.
L’applicazione  f  è un omomorfismo visto che (a+ b)  e  (c+ d) sono polinomi omogenei di grado 1 in a, b, c, d. Nonescludiamo che fè suriettivo, perchè dim M (2, 2, R) ≥dim R2La matrice rappresentativa di  frispetto alle basi canoniche è:
Questa matrice ha rango 2.Dunque,  fè suriettivo.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#15,15,"15/12/2016Calcolo dell’immagineEsercizio: Mostrare che le seguenti condizioni definiscono un unico omomorfismo  f: R3→R2. Poi, stabilire se  f è suriettivo.
I tre vettori (1, 2, 1), (1, 0, 1), (0, 0, 1) costituiscono una base per R3, abbiamo definito un unico omomorfismo f: R3→R2.dim R3≥ dim R2e quindi nonescludiamo che  fè suriettivo. La matrice rappresentativa di  frispetto alla base data di R3e dalla base canonica di R2è la seguente:
Questa matrice ha rango 2.Dunque,  fè suriettivo.110200111≠ 0
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#2,2,"15/12/203Immagine di un omomorfismoRicordiamo che, data un’applicazione tra insiemi f: A→B, l’immaginedi fè il sottoinsieme f (A) dell’insieme Bformato dalle immagini degli elementi di Atramite f . Vale a dire da tutti gli elementi bdi Bper cui esiste ain Atale che f (a) = b.Esempio: Sia  f: R2→R3definita da: f (x, y) := (x+2y, x+ y, x −y).L’immagine di  fsi determina tramite i w:= (a, b, c) di R3per cui esiste v:= (x, y) tale che f (v) = w. Cioè: (x+2y, x+y, x−y) = (a, b, c).Da cui il vettore vesiste se e solo se il seguente sistema è risolubile:
metodo di Gauss
è un sottospazio vettorialedi R3Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#3,3,"15/12/204Immagine di un omomorfismo
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#4,4,"15/12/205Immagine di un omomorfismoDomanda: Se abbiamo un’applicazione non linearef: V→Wtra spazi vettoriali, cosa possiamo dire dell’immagine di f ?Risposta: Se abbiamo un’applicazione non lineare  f: V→Wtra spazi vett., non possiamo (a priori) dire nulla sull’immagine di  f  : •Né che sia un sottospazio vettoriale di W.•Né che non lo sia.Bisogna valutare caso per caso come è fatto il sistema risultante.Esempi: •Sia f: R2→R2l’applicazione non lineare f (x, y) := (x2, x+ y)Si può verificare che in questo caso  non è  un sottospazio di R2•Sia f: R2→R2l’applicazione non lineare f (x, y) := (xy, 2xy)Si può verificare che in questo caso  èun sottospazio di R2Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#5,5,"15/12/206Calcolo dell’immagineTeorema: Se  f: V→Wè un omomorfismo di spazi vettoriali e     se lo spazio vettoriale Vè generato dai vettori v1, v2, … , vn , allora f (V) è generato dai vettori  f (v1),  f (v2), … , f (vn).Dimostrazione: Dobbiamo mostrare che ogni wdell'immagine di fsi può esprimere come combin. lineare di  f (v1),  f (v2), ... , f (vn).Sappiamo che esiste un vettore vdi Vtale che w= f (v). Possiamo ora esprimere vcome combinazione lineare di v1, v2, … , vn :v= k1 v1+ k2 v2+ … + kn vnMa allora f (v) = k1f (v1) + k2  f (v2) + … + kn  f (vn)Poiché w= f (v) abbiamo dunque espresso wcome combinazione lineare dei vettori f (v1),  f (v2), … , f (vn), come volevamo.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#6,6,"15/12/207Calcolo dell’immagine•Abbiamo mostrato che f (v1), f (v2), … , f (vn) generano f (V), non tutto W(ciò è vero solose f (V) = W, ovvero fè suriettivo). •Notiamo poi che, anche nel caso in cui i vettori v1, v2, … , vnformano una base per V, non è detto che f (v1), f (v2), … , f (vn) formano una base per f (V). Contro-esempio: Sia dato l’omomorfismo f: R3→R[x] definito da:    f (a, b, c) := (a− b) + (b− c)x + (c− a) x2f (R3) è generato dalle immagini dei vettori di una base di R3. Presa la base canonica, f (R3) è generato dai polinomi:f (1, 0, 0) = 1 − x2,  f (0, 1, 0) = − 1 + x,  f (0, 0, 1) = − x +  x2.   Questi tre polinomi sono linearmente dipendenti:− x+ x2= − (1 − x2) − (− 1 + x)                                                                       Dunque, non formano una baseper f (R3).Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#7,7,"15/12/208Calcolo dell’immagineCorollario: Se f: V→Wè un omomorfismo di spazi vettoriali e sela dimensione di Vè finita, allora la dimensione di f (V) è finita e dim  f (V) ≤ dim V. (Invece non sappiamo nulla sulla dim W.) Dimostrazione: Se i vettori v1, v2, … , vnformano una base per V(e, dunque, dim V= n), allora f (V) è generato dagli nvettori f (v1),   f (v2), … , f (vn), e, pertanto, la sua dimensione è al più n. Osservazioni: Se f: V→Wè un omomorfismo di spazi vettoriali edim V< dim Wallora f nonpuò essere suriettivo (ovvero f (V) ≠W).Nel caso in cui dim V≥ dim Wnon possiamo dire nulla a priori: dobbiamo valutare caso per caso. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#8,8,"15/12/209Calcolo dell’immagineEsercizio: Sia Vuno spazio vettoriale con una base formata dai vettori e1, e2, e3,e4. Sia Wun altro spazio vettoriale con una base formata dai vettorif1,  f2,  f3. Siaf: V→Wl’omomorfismo:f (e1) := f1+ f2+ f3 ;               f (e2) := f1+ 2 f2+ 3 f3 ;f (e3) := 3 f1+ 4 f2+ 5 f3 ;      f (e4) := − f2− 2 f3  .V ogliamo determinare una base per l’immagine di  f. Consideriamo la matrice Ale cui colonne danno le componenti di   f (e1),  f (e2),  f (e3),  f (e4) rispetto alla base formata da  f1,  f2,  f3 :Poiché gli scalini sono in I e II posizione troviamo che una base per f (V) è data dai vettori f (e1) e  f (e2), ovvero f1+f2+f3e   f1+2f2+3f3
riduciamo  A a scalini
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\14_Immagine.pdf#9,9,"15/12/2010Calcolo dell’immagineTeorema: Sia f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Fissiamo una base per V, formata dai vettori    e1, e2, … , en , e una base per W, formata dai vettori f1,  f2, … ,  fm. Prendiamo la matrice Arappresentativa di  frispetto alle basi date.Risulta: dim f (V) = rk A. In particolare, abbiamo che fè suriettivo (i.e. f (V) = W) se e solo se rk A= dim W.Osservazioni: Per determinare una base dell’immagine di fnotiamo che le colonne della matrice Aforniscono le componenti rispetto alla base f1,  f2, … ,  fm dei vettori f (e1),  f (e2), … ,  f (en) che generano f (V). Possiamo quindi determinare una base di f (V) calcolando il rango rdella matrice Ae scegliendo opportunamente  rvettori tra  f (e1),  f (e2), … ,  f (en). Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#0,0,15/12/201L15: Nucleo (28-29)Argomenti lezione:•Nucleo di un omomorfismo •Calcolo del nucleo •Cenni su isomorfismi •EserciziIl nucleodi un omomorfismo è il sottoinsieme dello spazio di partenza la cui immagine è il vettore nullo.Geometria e Combinatoria marcella.sama@uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#1,1,"15/12/202Nucleo
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#10,10,"15/12/2011Calcolo del nucleoEsercizio: Sia l’omomorfismo f: V→Wdefinito dalle condizioni:  
riducendo a scalini la matrice ACalcoliamo il nucleo tramite il sistema equivalenteGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#11,11,"15/12/2012Calcolo del nucleoEsercizio: Sia l’omomorfismo f: V→Wdefinito dalle condizioni:  
riducendo a scalini la matrice A
soluzioni del sistemaPonendo t= 1 e u= 0 otteniamo la soluzione (−2, −1, 1, 0), ponendo invece t= 0 e u= 1 otteniamo la soluzione (−1, 1, 0, 1). Una baseper ker f : −2e1−1e2+ 1e3+ 0e4; −1e1+ 1e2+ 0e3+ 1e4Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#12,12,"15/12/2013Calcolo del nucleoEsercizio: Sia l’omomorfismo f: R3→R4[x] definito da: 
Matrice Arispettoalle basicanoniche
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#13,13,"15/12/2014Calcolo del nucleoEsercizio: Sia l’omomorfismo f: R3→R4[x] definito da: 
riducendo a scalini la matrice Asoluzioni del sistemaUna baseper  ker fè allora formata dal singolo vettore le cui componenti rispetto alla base canonica sono (−3, −2, 1). 
cerchiamo il nucleo
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#14,14,"15/12/2015Calcolo del nucleoTeorema: Sia  f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Fissiamo una base per Ve una base per W.Sia Ala matrice rappresentativa di  frispetto a tali basi. Risulta: dim ker f= dim V− rk A [dato chele soluzioni del sistema lineare omogeneo utilizzato peril calcolo del nucleo sono descritte da dim V–rk A parametri]
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#15,15,"15/12/2016Calcolo del nucleoTeorema: Sia  f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Fissiamo una base per Ve una base per W.Sia Ala matrice rappresentativa di  frispetto a tali basi. Risulta: dim ker f= dim V− rk A Teorema: Se  f: V→Wè un omomorfismo di spazi vettoriali e se V  ha dimensione finita, risulta: dim V= dim ker f+ dim f (V )[abbiamo visto in precedenza che dim f (V ) = rk A ]
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#16,16,"15/12/2017Calcolo del nucleoTeorema: Sia  f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Fissiamo una base per Ve una base per W.Sia Ala matrice rappresentativa di  frispetto a tali basi. Risulta: dim ker f= dim V− rk A Teorema: Se  f: V→Wè un omomorfismo di spazi vettoriali e se V  ha dimensione finita, risulta: dim V= dim ker f+ dim f (V )Teorema: Sia  f: V→Wun omomorfismo di spazi vettoriali. Risulta che fè iniettivose e solo se:  ker f= {0V}.[ fè iniettivoquando due vettori diversi ue v, con u≠ v, hanno immagini diverse, ovvero f (u) ≠ f (v) )Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#17,17,"15/12/2018Calcolo del nucleoTeorema: Sia  f: V→Wun omomorfismo di spazi vettoriali di dimensione finita. Fissiamo una base per Ve una base per W.Sia Ala matrice rappresentativa di  frispetto a tali basi. Risulta: dim ker f= dim V− rk A Teorema: Se  f: V→Wè un omomorfismo di spazi vettoriali e se V  ha dimensione finita, risulta: dim V= dim ker f+ dim f (V )Teorema: Sia  f: V→Wun omomorfismo di spazi vettoriali. Risulta che fè iniettivo(i.e. vettori diversi hanno immagini diverse) se e solo se:  ker f= {0V}.Notiamo che se fè iniettivo, allora dim V= dim  f (V ). Poichè  f (V ) è un sottospazio di W , abbiamo che dim V ≤ dim W.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#18,18,"15/12/2019Calcolo del nucleoNotiamo che se fè iniettivo, allora dim V= dim  f (V ). Poichè  f (V ) è un sottospazio di W , abbiamo che dim V ≤ dim W.Osservazione: Se  f: V→W èun omomorfismo di spazi vettoriali e dim V> dim Wallora l’omomorfismo  fnonpuò essere iniettivo.Nel caso in cui dim V≤ dim Wnon possiamo dire nulla a priori: dobbiamo valutare caso per caso. Criterio: Sia  f: V→ Wun omomorfismo tra spazi di dim. finita. Sia Ala matrice rappresentativa difrispetto a delle basi per Ve W. Sono allora equivalenti le seguenti condizioni:1.L’omomorfismo  fè iniettivo, 2.rk A= dim V, 3.dim f (V) = dim V.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#19,19,"15/12/2020Calcolo del nucleoEsercizio: Stabilire se i seguenti omomorfismi sono iniettivi:
Possiamo dire subito che  fnonè iniettivo: infatti R[x] non ha dimensione finita,mentre R3ha dimensione finita.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#2,2,"15/12/203Definizione del vettore nulloTeorema: Se f: V→Wè un omomorfismo allora f (0v) = 0w .Esempio: Sia f: R3→R2  l’applicazione definita da:f (x,y, z) := (x+ y+ 3z , x+ 2y+ 4z−1). fnonè lineare (nonè un omomorfismo) dal momento chef (0, 0, 0) = (0, −1) ≠ (0, 0)Esempio: Sia f: R2→R2  l’applicazione  f (x, y) := (xy, x). Vediamo che f (0, 0) = (0, 0). Attenzione però:  fnonè un omomorfismo poiché, ad esempio,  f (0, 1) + f (1, 0) = (0, 0) + (0, 1) = (0, 1) , mentre          f ((0, 1) + (1, 0)) = f (1, 1) = (1, 1) Quindi anche se f (0v ) = 0w  nonè detto che fsia un omomorfismo!Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#20,20,"15/12/2021Calcolo del nucleoEsercizio: Stabilire se i seguenti omomorfismi sono iniettivi:
Possiamo dire subito che  fnonè iniettivo: infatti dim M (2, 2, R) > dim R3.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#21,21,"15/12/2022Calcolo del nucleoEsercizio: Stabilire se i seguenti omomorfismi sono iniettivi:
Poiché dim R3≤ dim M(2, 2, R) non possiamo escludere a priori che f sia iniettivo. Dobbiamo svolgere i dovuti calcoli. La matrice rappresentativa di frispetto alle basi canoniche è :
Questa matrice ha rango 3. Essendo rk A= dim V,segue fè iniettivo.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#22,22,"15/12/2023Isomorfismo
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#23,23,"15/12/2024IsomorfismiDefinizione: Un omomorfismo f: V→Wdi spazi vettoriali è dettoisomorfismose f è biiettivo,cioè se fè sia suriettivo che iniettivo. Due spazi vettoriali Ve Wsi dicono isomorfise esiste un isomorfismo f: V→W. Teorema: Se f: V→Wè un isomorfismo di spazi vettoriali e Vha dimensione finita, allora Wha dimensione finita e dim W= dim V.[ Infatti per  f suriettivo si ha:  f (V) = W mentre per  f iniettivo si ha: dim f (V) = dim V  ]Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#24,24,"15/12/2025IsomorfismiDefinizione: Un omomorfismo f: V→Wdi spazi vettoriali è dettoisomorfismose f è biiettivo,cioè se fè sia suriettivo che iniettivo.Due spazi vettoriali Ve Wsi dicono isomorfise esiste un isomorfismo f: V→W. Teorema: Se f: V→Wè un isomorfismo di spazi vettoriali e Vha dimensione finita, allora Wha dimensione finita e dim W= dim V.Teorema: Sia  f: V→Wun omomorfismo di spazi di dim. finita. Sia dim V= dim W= n.  Sia Ala matrice rappresentativa di  frispetto a delle basi per Ve W.  Sono equivalenti le condizioni:1.  fè suriettivo;    2.  fè iniettivo;    3. fè un isomorfismo (cioè è biiettivo);    4. det A≠ 0.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#25,25,"15/12/2026Calcolo di nucleo e immagineEsercizio: Sia  f: R3→R3l’omomorfismo definito dalle condizioni:
Determinare la matrice rappresentativa di f rispetto alla base canonica:
matrice rappresentativa
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#26,26,"15/12/2027Calcolo di nucleo e immagineEsercizio: Sia  f: R3→R3l’omomorfismo definito dalle condizioni:
Determinare la matrice rappresentativa di f rispetto alla base di R3formata dai vettori v1:= (1, 1, 1), v2:= (1, 1, 0), v3:= (1, 0, 0):
matrice rappresentativaGeometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#27,27,"15/12/2028Calcolo di nucleo e immagineEsercizio: Sia  f: R3→R3l’omomorfismo definito dalle condizioni:
Determinare la matrice rappresentativa di f rispetto alla base di R3formata dai vettori w1:= (1, 2, 1), w2:= (0, 1, 0), w3:= (0, 0, 2):Per prima cosa, determiniamo  f (1, 2, 1),  f (0, 1, 0),  f (0, 0, 2).
Per trovare f (1, 2, 1), usiamo la matrice rappr. di frispetto alla base canonica.Analogamente si ha:  f (0, 1, 0) = (1, 2, 0),   f (0, 0, 2) = (0, –4, 2)Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#28,28,"15/12/2029Calcolo di nucleo e immagineEsercizio: Sia  f: R3→R3l’omomorfismo definito dalle condizioni:
Determinare la matrice rappresentativa di f rispetto alla base di R3formata dai vettori w1:= (1, 2, 1), w2:= (0, 1, 0), w3:= (0, 0, 2):Poi,decomponiamo i vettori trovati rispetto alla base data: 
matrice rappresentativa
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#29,29,"15/12/2030Calcolo di nucleo e immagineEsercizio: Sia  f: R3→R3l’omomorfismo definito dalle condizioni:
Determinare il nucleo e l’immagine di  f:Sappiamo che f (R3) è generato dalle immagini dei vettori di una base.Ad esempio, f (R3) è generato da f (1, 1, 1),  f (1, 1, 0),  f (1, 0, 0), ovvero da (1, 0, 1), (1, 2, 0), (0, 0, 0). (1, 0, 1) e (1, 2, 0) sono linear. indip., e formano una baseper  f (R3).dim f (R3) = 2. Segue dim ker f= dim R3 –dim  f (R3) = 3–2 = 1.Poichè (1, 0, 0) Îker  f, questo vettore forma una baseper ker  f.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#3,3,"15/12/204Nucleo di un omomorfismoDefinizione: Se f: V→Wè un omomorfismo di spazi vettoriali chiamiamo nucleodi  f( kerf  ) l’insieme dei vettori di Vla cui immagine è il vettore 0w.  Dunque: ker f:= {  v∊V| f (v) = 0w}Esempio: Prendiamo l’omomorfismo f: R5→R[x] definito da:f (a, b, c, d, e) := (a− b+ c) + (b− c+ d) x+ (c− d+ e) x2Un vettore (a, b, c, d, e) appartiene a  ker fse e solo se: (a− b+ c) + (b−c+ d) x+ (c− d+ e) x2= 0. Ovvero se e solo se:Una baseper ker f  è formata da (−1, 0, 1, 1, 0) e (0, −1, −1, 0, 1). 
ker fè l'insieme delle soluzioni di      un sistema omogeneo e, quindi, èun sottospazio vettorialedi R5.
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#4,4,"15/12/205Nucleo di un omomorfismoEsercizio: Sia f: M(2, 2, R) →M(2, 2, R) definito da f (A) := A+ tAPer determinare  ker  fpossiamo considerare la generica matricedi M(2, 2, R) e stabilire quando f (A) = 0.
ker fè un sottospazio vettorialedello spazio di partenza.ker fè formato dalle matrici Atali che A+ tA= 0 cioè le matrici antisimmetrichetali che tA= −A. Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#5,5,"15/12/206Nucleo di un omomorfismoTeorema: Il nucleodi un omomorfismo f: V→Wdi spazi vettoriali è un sottospazio vettorialedi V.Dimostrazione: Sappiamo che 0VÎker f ( f (0v) = 0w ). ker f≠ Ø.[ Per definizione di nucleosi ha:  ker f:= {  vin V| f (v) = 0w} ]
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#6,6,"15/12/207Nucleo di un omomorfismoTeorema: Il nucleodi un omomorfismo f: V→Wdi spazi vettoriali è un sottospazio vettorialedi V.Dimostrazione: Sappiamo che 0VÎker f ( f (0v) = 0w ). ker f≠ Ø.Sappiamo che f (v1) = 0we  f (v2) = 0we dobbiamo mostrare che      f (v1+ v2) = 0w . Dunque: f (v1+ v2) = f (v1) + f (v2) = 0w+ 0w= 0w .Ora dobbiamo mostrare che se vappartiene a ker f   ekè uno scalare, allora  k vappartiene a ker f . Sappiamo che f (v) = 0we  dobbiamo mostrare che f (k v) = 0w . Dunque f (k v) = k f (v) = k 0w= 0w. Abbiamo dimostrato che il nucleo di fè un sottospazio vett. di V.Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#7,7,"15/12/208Calcolo del nucleoProcedura: Dato un omomorfismo f: V→Wdi spazi vettoriali di dimensione finita. Data una base per V, formata dai e1, e2, . . . , en ,  e una base per W, formata dai f1,  f2, . . . ,  fm. Sia Ala matrice rappresentativa di frispetto alle basi date. Consideriamo ora un genericovettore vdi V: V ogliamo stabilire se vappartiene a ker f. 
•f1,  f2, … ,  fm sono linearm. indipend. (formano una base per W ) per cui vappartiene a  ker f  se e solo se  y1= y2= … = ym= 0.[ Per definizione di nucleosi ha:  ker f:= {  vin V| f (v) = 0w} ] 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#8,8,"15/12/209Calcolo del nucleoProcedura: Dato un omomorfismo f: V→Wdi spazi vettoriali di dimensione finita. Data una base per V, formata dai e1, e2, . . . , en ,  e una base per W, formata dai f1,  f2, . . . ,  fm. Sia Ala matrice rappresentativa di frispetto alle basi date. Consideriamo ora un genericovettore vdi V : V ogliamo stabilire se vappartiene a ker f. 
•f1,  f2, … ,  fm sono linearm. indipend. (formano una base per W ) per cui vappartiene a  ker f  se e solo se  y1= y2= … = ym= 0.•Partendo una soluzione (x1,x2, …, xn) del sistema lin. omogeneootteniamo un vettore del nucleo di  f  :  x1e1+ x2e2+ … + xnen  
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\15_Nucleo.pdf#9,9,"15/12/2010Calcolo del nucleoEsercizio: Sia l’omomorfismo f: V→Wdefinito dalle condizioni:  
Sia Vuno spazio vettor. con una base formata da e1, e2, e3,e4. Sia Wuno spazio vettor. con una base formata dai vettorif1,  f2,  f3. 
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#0,0,23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it1L16: Endomorfismi (30)Argomenti lezione:•Introduzione•Endomorfismi •Cambiamento di base•Esercizi 
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#1,1,"23/12/202IntroduzioneObiettivo lezione:Studiare particolari omomorfismi di spazi vettoriali in cui lospazio di partenza e lo spazio di arrivo coincidono.Vedremo:Come rappresentare questi omomorfismi per mezzo di matrici.  Stabiliremo come variano le matrici rappresentative al variare delle basiscelte.Definizione: Dato uno spazio vettoriale V, un endomorfismodi Vè un omomorfismo  f: V→V.Segue che possiamo utilizzare per gli endomorfismi le stesse definizionie gli stessi risultativisti per gli omomorfismi.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#10,10,"23/12/2011Cambiamento di base
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#11,11,"23/12/2012Cambiamento di baseAbbiamo visto nel precedente esercizio che, cambiando base, cambiala matrice rappresentativa dell’endomorfismo. Ci chiediamo, in generale, come cambia tale matrice.Definizione: Sia Vuno spazio vettoriale di dimensione finita n.     Si considerino due basi di V: una base formata dai vettori e1 , e2 , … , enl’altra base formata dai vettori e1’, e2’, … , en’ La matrice Min M (n, n, R) la cui j-esima colonna è data dallecomponenti del vettore  ej’  rispetto alla base formata dai vettori    e1 , e2 , … , enè detta matrice di passaggio dalla base formata da e1 , e2 , … , enalla base formata da e1’, e2’, … , en’.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#12,12,"23/12/2013Cambiamento di baseEsercizio: Consideriamo di nuovo lo spazio vettoriale R3[x],     la sua base canonica: q1(x) := 1,  q2(x) := x,  q3(x) := x2e la base formata da p1(x) := 1 + x+ x2,  p2(x) := 1 + x,  p3(x) := 1.Per trovare la matrice Mdi passaggiodalla base canonica alla seconda base dobbiamo esprimere ciascuno dei p1(x), p2(x), p3(x)come combinazione linearedei q1(x), q2(x), q3(x). Abbiamo:p1(x) = 1q1(x) + 1q2(x) + 1q3(x)p2(x) = 1q1(x) + 1q2(x) + 0q3(x)p3(x) = 1q1(x) + 0q2(x) + 0 q3(x)
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#13,13,"23/12/2014Cambiamento di baseTeorema: La matrice di passaggio Mda una base di uno spazio vettoriale Va un’altra base è invertibile.Dimostrazione: Se Mè la matrice di passaggio dalla base formatadai vettori e1, e2, … , enalla base formata dai vettori e1’, e2’, …, en’, le colonne di Mdanno le componenti di e1’, e2’, …, en’ rispetto alla base formata dai vettori e1, e2, … , en. Sappiamo che il rango di Mè uguale alla dimensione dello spazio vettoriale generato dai vettori e1’, e2’, …, en’. Poiché i vettori e1’, e2’, …, en’ formano una base per Vabbiamo cherk M= dim V, ovvero det M≠0, ovvero Mè invertibile.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#14,14,"23/12/2015Cambiamento di baseTeorema: Date due basi di uno spazio vettoriale V sia Mla matrice di passaggio dalla prima base alla seconda base. La matrice di passaggio dalla seconda base alla prima base è allora M−1.Esempio: Consideriamo di nuovo lo spazio vettoriale R3[x],            la sua base canonica: q1(x) := 1,  q2(x) := x,  q3(x) := x2e la base formata da p1(x) := 1 + x+ x2,  p2(x) := 1 + x,  p3(x) := 1.La matrice Mdi passaggio dalla base canonica alla seconda base è:Domanda: Come si determina la matrice M’di passaggio dalla seconda base alla base canonica? 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#15,15,"23/12/2016Cambiamento di baseEsempio (seguito): base canonica: q1(x) := 1,  q2(x) := x,  q3(x) := x2e base formata da p1(x) := 1 + x+ x2,  p2(x) := 1 + x,  p3(x) := 1.Domanda: Come si determina la matrice M’di passaggio dalla seconda base alla base canonica? Esprimiamo i polinomi della base canonica come combinazione lineare dei polinomi p1(x), p2(x), p3(x): •Poiché q1(x) = p3(x) allora q1(x) = 0p1(x) + 0p2(x) + 1p3(x). •Per decomporre q2(x) effettuiamo i seguenti passaggi:  x= h1(1 + x+ x2) + h2(1 + x) + h3(1) = (h1+h2+h3) + (h1+h2)x+ h1x2h1+h2+h3= 0, h1+h2= 1, h1= 0  da cui: h1= 0, h2= 1, h3= –1.•Per decomporre q3(x) effettuiamo i seguenti passaggi:  x2= h1(1 + x+ x2) + h2(1 + x) + h3(1) = (h1+h2+h3) + (h1+h2)x+ h1x2h1+h2+h3= 0, h1+h2= 0, h1= 1  da cui: h1= 1, h2= –1, h3= 0.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#16,16,"23/12/2017Cambiamento di baseEsprimiamo i polinomi della base canonica come combinazione lineare dei polinomi p1(x), p2(x), p3(x): •Poiché q1(x) = p3(x) allora q1(x) = 0p1(x) + 0p2(x) + 1p3(x). •Per decomporre q2(x) effettuiamo i seguenti passaggi:  x= h1(1 + x+ x2) + h2(1 + x) + h3(1) = (h1+h2+h3) + (h1+h2)x+ h1x2h1+h2+h3= 0, h1+h2= 1, h1= 0  da cui: h1= 0, h2= 1, h3= –1.•Per decomporre q3(x) effettuiamo i seguenti passaggi:  x2= h1(1 + x+ x2) + h2(1 + x) + h3(1) = (h1+h2+h3) + (h1+h2)x+ h1x2h1+h2+h3= 0, h1+h2= 0, h1= 1  da cui: h1= 1, h2= –1, h3= 0.
Abbiamo M M’= I,cioè M’= M −1
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#17,17,"23/12/2018Cambiamento di baseTeorema: Sia fun endomorfismo di Vdi dimensione finita.            Sia Ala matrice rappresentativa di frispetto alla base formata dai vettori e1, e2, … , en. Sia A’ la matrice rappresentativa di frispetto alla base formata dai vettori e1’, e2’, …, en’. Sia Mla matrice di passaggio dalla base formata dai vettori e1, e2, … , enalla base formata dai vettori e1’, e2’, … , en’. Allora si ha: A’ = M−1 A MEsercizio: Prendiamo di nuovo l’endomorfismo f: R3 [x] →R3 [x] :f (a+ bx+ cx2) := (3a+ c) + (a+ b)x+ cx2. Calcolare A’ = M−1 A M.
matrice rappresentativa di frispetto alla base canonica
matrice rappresentativa di f  rispetto ad un’altra base
matrice dipassaggio23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#18,18,"23/12/2019Cambiamento di baseEsercizio: Sia  f: R2→R2l’endomorfismo che rispetto alla base canonica di R2[ovvero e1:= (1, 0),  e2:= (0, 1)] si rappresenta conla matrice V ogliamo determinare la matrice rappresentativa  A’di  frispetto alla base di R2formata dai vettori e1’ := (1, 2),  e2’ := (1, –1).Calcoliamo la matrice di passaggio dalla base canonica all’altra base:
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#19,19,"23/12/2020Cambiamento di baseEsercizio: Sia  f: R2→R2l’endomorfismo che rispetto alla base canonica di R2[ovvero e1:= (1, 0),  e2:= (0, 1)] si rappresenta conla matrice V ogliamo di nuovodeterminare la matrice rappresentativa  A’di  frispetto alla base di R2formata dai vettori e1’ := (1, 2),  e2’ := (1, –1).•Stavolta usiamo la definizione di matrice rappresentativa: 
Le componenti di e1’rispetto    alla base canonica sono (1, 2)Decomponiamo f (e1’)rispetto alla base formata   dai vettori e1’  e  e2’.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#2,2,"23/12/203Endomorfismo
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#20,20,"23/12/2021Cambiamento di baseEsercizio: Sia  f: R2→R2l’endomorfismo che rispetto alla base canonica di R2[ovvero e1:= (1, 0),  e2:= (0, 1)] si rappresenta conla matrice V ogliamo di nuovodeterminare la matrice rappresentativa  A’di  frispetto alla base di R2formata dai vettori e1’ := (1, 2),  e2’ := (1, –1).•Stavolta usiamo la definizione di matrice rappresentativa: Le componenti di e2’rispetto    alla base canonica sono (1, –1)Decomponiamo f (e2’)rispetto alla base formata   dai vettori e1’  e  e2’.
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#21,21,"23/12/2022Cambiamento di baseEsercizio: Sia  f: R2→R2l’endomorfismo che rispetto alla base canonica di R2[ovvero e1:= (1, 0),  e2:= (0, 1)] si rappresenta conla matrice V ogliamo di nuovodeterminare la matrice rappresentativa  A’di  frispetto alla base di R2formata dai vettori e1’ := (1, 2),  e2’ := (1, –1).•Stavolta usiamo la definizione di matrice rappresentativa: 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#22,22,"23/12/2023Cambiamento di baseIl teorema appena visto ci dice che se due matrici Ae Brappresentanolo stesso endomorfismo rispetto a basi diverse,allora esiste una matrice invertibile  Mtale che B = M−1A M .Definizione: Siano date due matrici Ae Bappartenenti a M (n, n, R).La matrice Bsi dice similealla matrice Ase e solo se esiste unamatrice Min GL(n, R) [insieme delle matrici invertibili di M (n, n, R)]tale che B= M−1 A M .Segue che le matrici rappresentative di uno stesso endomorfismo sono tutte simili fra loro.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#23,23,"23/12/2024EndomorfismiEsercizio: Sia fl’endomorfismo di R3definito dalle condizioni: 
Determinare la matrice rappresentativa di  frispetto alla base formata da:
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#24,24,"23/12/2025EndomorfismiEsercizio: Sia fl’endomorfismo di R3definito dalle condizioni: 
Determinare la matrice rappresentativa di  frispetto alla base canonica. 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#25,25,"23/12/2026EndomorfismiEsercizio: Sia fl’endomorfismo di R3definito dalle condizioni: 
Determinare la matrice rappresentativa di  frispetto alla base canonica. 
Per evitare di calcolare M −1, possiamo (in alternativa) calcolare:
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#26,26,"23/12/2027EndomorfismiEsercizio: Sia  fl’endomorfismo di R4e Ala matrice rispetto alla base:
Determinare nucleo e immagine di  f
Gauss
L’immaginedi  fè generata da :
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#27,27,"23/12/2028EndomorfismiEsercizio: Sia  fl’endomorfismo di R4e Ala matrice rispetto alla base:
Determinare nucleo e immagine di  f
GaussIl nucleodi  fsi trova risolvendo il sistema omogeneo associato ad A :
Le soluzioni sono (–2t, –t, –t, t)Per t= 1 si ha: (–2, –1, –1, 1) Una base del nucleo è: 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#3,3,"23/12/204EndomorfismiDefinizione: Sia f: V→V un endomorfismo di uno spazio vettoriale di dimensione finita. Fissata una base di V, formata dai vettori e1, e2, … , en , possiamo esprimere ciascun vettore f (ej) come combinazione linearedei vettori della base e1, e2, … , en : f (e1 ) = a11 e1+ a21 e2+...+ an1 enf (e2 ) = a12 e1+ a22 e2+...+ an2 en …  f (en ) = a1n e1+ a2n e2+…+ ann en La matrice A di M (n, n, R) è associata all’endomorfismo(ovvero è matrice rappresentativa di) f  rispetto alla base e1, e2, … , en .La j-esima colonna di Aè data dalle componenti del vettore f (ej) rispetto alla base formata da e1, e2, … , en . 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#4,4,"23/12/205EndomorfismiDefinizione: Sia Vuno spazio vettoriale di dimensione finita.        Sia data una base per Vformata dai vettori e1, e2, … , en .                Se Aè una matrice di M (n, n, R), chiamiamo endomorfismo associatoalla matrice Arispetto alle basi fissate l’omomorfismo f:f (e1) = a11 e1+ a21 e2+...+ an1 enf (e2) = a12 e1+ a22 e2+...+ an2 en …  f (en) = a1n e1+ a2n e2+…+ ann en Vale a dire l’endomorfismo  fla cui matrice rappresentativa rispetto alle basi assegnate è esattamentela matrice A.
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#5,5,"23/12/206EndomorfismiEsercizio: Consideriamo l'endomorfismo f: R3 [x] →R3 [x] :f (a+ bx+ cx2) := (3a+ c) + (a+ b) x+ c x2Se vogliamo ora determinare la matrice rappresentativa di  frispetto alla base canonica, dobbiamo determinare le immagini dei vettori della base canonica e decomporli rispetto alla base canonica stessa.  f (1)  =  3 + x=  31 + 1x+ 0x2f (x)  =         x= 01 + 1x+ 0x2 f (x2) = 1 + x2= 11 + 0x+ 1x2 La matrice rappresentativa di  frispetto alla base canonica è allora: 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#6,6,"23/12/207EndomorfismiEsercizio: Consideriamo l'endomorfismo f: R3 [x] →R3 [x] :f (a+ bx+ cx2) := (3a+ c) + (a+ b) x+ c x2Ora vogliamo rappresentare  frispetto a un’altra base, ovvero quella formata dai polinomi p1(x) := 1 + x+ x2,  p2(x) := 1 + x,  p3(x) := 1.Calcolando le immagini di tali vettori, si ha: f (p1(x)) = 4 + 2x+ x2.[ f ( p1(x) ) =  f( 1 + x+ x2 ) da cui a = b = c = 1 segue 4 + 2x+ x2 ] 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#7,7,"23/12/208EndomorfismiEsercizio: Consideriamo l'endomorfismo f: R3 [x] →R3 [x] :f (a+ bx+ cx2) := (3a+ c) + (a+ b) x+ c x2Ora vogliamo rappresentare  frispetto a un’altra base, ovvero quella formata dai polinomi p1(x) := 1 + x+ x2,  p2(x) := 1 + x,  p3(x) := 1.Calcolando le immagini di tali vettori, si ha: f (p1(x)) = 4 + 2x+ x2.Decomponiamo f (p1(x)) rispetto alla base: p1(x), p2(x), p3(x). f (p1(x)) = 4 + 2x+ x2  = 1(1 + x+ x2) + 1(1 + x) + 21Analogamente:  f (p2(x)) = 3 + 2x= 0(1 + x+ x2) + 2(1 + x) + 11f (p3(x)) =    3 + x= 0(1 + x+ x2) + 1(1 + x) + 21Dunque la matrice rappresentativa di  f  rispetto alla base formata dai polinomi p1(x), p2(x), p3(x) è  A’: 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#8,8,"23/12/209EndomorfismiEsercizio: Sia f: M(2, 2, R) →M(2, 2, R) l’endomorfismo:f (A) := A+ tA Determinare la matrice A rappresentativa di  frispetto alla base: 
A nonè una matrice diagonale23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\16_Endomorfismi.pdf#9,9,"23/12/2010EndomorfismiEsercizio: Sia f: M(2, 2, R) →M(2, 2, R) l’endomorfismo:f (A) := A+ tA Determinare la matrice A’rappresentativa di  frispetto alla base: 
A’ è una matrice diagonale23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#0,0,23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it1L17: Autovalori e autovettori (31)Argomenti lezione:•Introduzione •Autovalori e autovettori •Polinomio caratteristico •Molteplicità di un autovalore •Autovalori e autovettori di matrici
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#1,1,23/12/202IntroduzioneObiettivo: Individuare sotto quali specifiche condizioni un endomorfismo di uno spazio vettoriale si può rappresentare per mezzo di una matrice diagonale.Concetticheintrodurremooggi:•Autovalori e autovettori •Polinomio caratteristico •Molteplicità di un autovalore •Autovalori e autovettori di matrici23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it2
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#10,10,"23/12/2011Polinomio caratteristicoEsempio: Sia f: R4[x] →R4[x] l’endomorfismo che associa al polinomio a0+ a1 x+ a2 x2 + a3 x3il polinomio (a0+ a1) + (a1–a2+ a3) x+ (a0+ 2a1–a2) x2+ a3 x3 .Consideriamo la base canonica di R4[x] formata dai polinomi p1(x) := 1,   p2(x) := x,   p3(x) := x2,   p4(x) := x3. Rispetto a tale base l’endomorfismo fsi rappresenta con la matrice:
V ogliamo ora determinare polinomi non nulli del tipo p(x) := a0+ a1 x+ a2 x2 + a3 x3tali che f (p(x)) = λp(x) per qualche λÎR.a0a1a2a323/12/20Geometria e Combinatoria marcella.sama@uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#11,11,"23/12/2012Polinomio caratteristicoEsempio (seguito): V ogliamo determinare polinomi non nulli del tipop(x) := a0+a1 x +a2 x2 +a3 x3 tali che f (p(x)) = λp(x) per qualche λÎR.=> p(x) è un autovettorese e solo se p(x) ≠0 ed esiste λÎRtale che:
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#12,12,"23/12/2013Polinomio caratteristicoEsempio (seguito): V ogliamo determinare polinomi non nulli del tipop(x) := a0+a1 x +a2 x2 +a3 x3 tali che f (p(x)) = λp(x) per qualche λÎR.=> p(x) è un autovettore se e solo se p(x) ≠0 ed esiste λÎRtale che:
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#13,13,"23/12/2014Polinomio caratteristicoEsempio (seguito): V ogliamo determinare polinomi non nulli del tipop(x) := a0+a1 x +a2 x2 +a3 x3 tali che f (p(x)) = λp(x) per qualche λÎR.=> p(x) è un autovettore se e solo se p(x) ≠0 ed esiste λÎRtale che:
λ= x23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#14,14,"23/12/2015Polinomio caratteristicoEsempio (seguito): V ogliamo determinare polinomi non nulli del tipop(x) := a0+a1 x +a2 x2 +a3 x3 tali che f (p(x)) = λp(x) per qualche λÎR.=> p(x) è un autovettore se e solo se p(x) ≠0 ed esiste λÎRtale che:
λ= xOsservazioni:•Il sistema, essendo omogeneo, è sempre risolubile.•det(A−λI) ≠ 0: il sistema (Crameriano) ha solola soluz. banale.•Stiamo cercando autovettori, ovvero vettori non nulli. Dunque ci interessano soluzioni non banalidi questo sistema omogeneo.•det(A−λI) = 0: rkAè minore del numero delle incognite e, quindi, esistono infinite soluzioni(incluse quelle non banali). 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#15,15,"23/12/2016Polinomio caratteristicoEsempio (seguito): V ogliamo determinare polinomi non nulli del tipop(x) := a0+a1 x +a2 x2 +a3 x3 tali che f (p(x)) = λp(x) per qualche λÎR.=> p(x) è un autovettore se e solo se p(x) ≠0 ed esiste λÎRtale che:
λ= xOsservazioni:•det(A−λI) = 0: rkAè minore del numero delle incognite e, quindi, esistono infinite soluzioni(incluse quelle non banali).•se λ= 1 si ha det(A−1I) = 0, il sistema ha soluzioni non banali, cioè 1 è autovaloredi  f•se λ= 2 si ha det(A−2I) ≠ 0, il sistema ha solamente la soluzione banale, cioè 2 non è autovaloredi  f23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#16,16,"23/12/2017Polinomio caratteristicoTeorema: Sia f: V→Vun endomorfismo di uno spazio vettoriale Vdi dimensione finita. Sia Ala matrice rappresentativa di  frispetto  a una base di V. Sia A’la matrice rappresentativa di  frispetto aun’altra base di V.  Allora si ha: det (A’ − xI ) = det (A− xI ). [Il teorema ci dice che gli autovalori di  fnondipendono A !cioè dalla base di Vscelta per rappresentare  f . ]
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#17,17,23/12/2018Polinomio caratteristicoTeorema: Sia f: V→Vun endomorfismo di uno spazio vettoriale Vdi dimensione finita. Sia Ala matrice rappresentativa di  frispetto  a una base di V. Sia A’la matrice rappresentativa di  frispetto aun’altra base di V.  Allora si ha: det (A’ − xI ) = det (A− xI ). Dimostrazione:Sappiamo che esiste una matrice invertibile Mtale che A’= M –1AMdet (A’ − xI) = det (M –1AM− xI)                                       [A’= M –1AM]= det(M –1AM− M –1(xI ) M)                         [I= M –1I M]= det(M –1(A− xI) M)                            [prop. delle matrici]= detM –1det (A− xI) detM               [det (A B) = detA detB]= det (A− xI )                                      [det M –1= (det M )–1]23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it18
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#18,18,"23/12/2019Polinomio caratteristicoDefinizione: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne sia Ala matrice rappresentativa di frispettoa una base di V. Chiamiamo polinomio caratteristico di fil polinomio pf (x):= det (A−xI ) di grado nnell’incognita x.Teorema: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita. Allora gli autovaloridi fsono le radicidelpolinomio caratteristicodi f. Teorema: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita n. Sia Ala matrice rappresentativa di  frispetto a una base di V.  Se λè un autovaloredi  f, allora si ha:dim E(λ) = n−rk (A−λ I )23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#19,19,"23/12/2020Polinomio caratteristicoEsempio (seguito): Determiniamo autovalori e relativi autospazi.  Il polinomio caratteristico pf (x) := det (A−xI )è: 
Ad esempio, sviluppiamo questo determinante rispetto all’ultima riga:
Calcoliamo le radici delpolinomio caratt.  pf (x)  
Calcoliamo il discriminante (∆ = b2 –4 a c) di  x2–x+ 1 : a= 1; b= –1; c= 1  segue  ∆ =1 –4 < 0  quindi  no radici realiLe radici di questo polinomio (ovvero gli autovalori di f ) sono 0 e 1. 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#2,2,"23/12/203Autovalori e Autovettori
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#20,20,"23/12/2021Polinomio caratteristicoEsempio (seguito): Determiniamo autovalori e relativi autospazi.  Il polinomio caratteristico pf (x) := det (A−xI )è: 
Le radici di pf (x) (gli autovalori di f ) sono 0 e 1. 
L’autospazio relativo all’autovalore 1 è :
Quindi  2 + x2+ x3costituisce una base di E(1)23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#21,21,"23/12/2022Polinomio caratteristicoEsempio (seguito): Determiniamo autovalori e relativi autospazi.  Il polinomio caratteristico pf (x) := det (A−xI )è: 
Le radici di pf (x) (gli autovalori di f ) sono 0e 1. L’autospazio relativo all’autovalore 0 è :Quindi  –1 + x+ x2costituisce una base di E(0)
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#22,22,"23/12/2023Polinomio caratteristicoProcedura: Per determinare l’autospazio E(λ) occorre innanzituttorisolvere il sistema lineare omogeneo associato alla matrice A− λ I.Poi, bisogna prendere i vettori che hanno queste soluzioni comecomponenti rispetto alla base considerata.Osservazioni pratiche: Per definizione, un autospazio E(λ) contiene vettori diversi dalvettore nullo. Se risolvendo il sistema omogeneo necessario alladeterminazione di E(λ) troviamo solo la soluzione banale, alloraquesto significa che abbiamo sbagliato a risolvere il sistemaoppureche il valore λnon è un autovalore(e quindi abbiamo sbagliato acalcolare il polinomio caratteristico o a determinare le sue radici). 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#23,23,"23/12/2024Molteplicità di un autovaloreTeorema: Sia p(x) un polinomio nell’incognita x. Il numero reale aè radicedel polinomio p(x)  se e solo se   x− a   dividep(x).Definizione: Sia auna radice di un polinomio p(x). Allora a è radice di p(x) con molteplicitàmse   p(x) = (x− a) m  k(x)  con k(a) ≠ 0. In altri termini, aha molteplicità mse: (x− a) mdividep(x),  mentre (x− a)m+1non dividep(x). Esempio: 
La radice 1 ha molteplicità 2.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#24,24,"23/12/2025Molteplicità di un autovaloreTeorema: Se un polinomio p(x) di grado nha le radici distinte a1, a2, …, ardi molteplicità rispettive  m1, m2, …, mr allora  m1+ m2+ … + mr≤ nEsempio (seguito): 
Cerchiamo i divisori di 2 x3+ 6 x2+ 6 x + 4 4/2 = 2 quindi i possibili divisori sono: 1, –1, 2, –2Notiamo che 2 x3+ 6 x2+ 6 x + 4si annulla per x= –22 x3+ 6 x2+ 6 x + 4      x + 2–2 x3–4 x2                              2 x2+ 2 x + 22 x2+ 6 x + 4–2 x2–4 x2 x + 4–2 x  –42     6      6       42     22       0oppure tramite Ruffini :–2          –4   –4    –42 x2+ 2 x + 223/12/20Geometria e Combinatoria marcella.sama@uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#25,25,"23/12/2026Molteplicità di un autovaloreTeorema: Se un polinomio p(x) di grado nha le radici distinte a1, a2, …, ardi molteplicità rispettive  m1, m2, …, mr allora  m1+ m2+ … + mr≤ nEsempio (seguito): 
Calcoliamo il discriminante (∆ = b2 –4 a c) di  2x2+ 2x+ 2 : a= 2; b= 2; c= 2  segue  ∆ =8 –16 < 0  quindi  no radici realip(x) ha la radice 1 di molteplicità 2 e la radice –2 di molteplicità 1La somma delle molteplicità è 3 che è inferiore al grado di p(x)
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#26,26,"23/12/2027Molteplicità di un autovaloreDefinizione: Un polinomio p(x) di grado nsi dice totalmente riducibilese si può scrivere come prodotto di polinomi di I grado.Teorema: Sia p(x) un polinomio di grado ne siano a1, a2, …, arle radici distinte di p(x) aventi molteplicità rispettive m1, m2, …, mr .Il polinomio p(x) è totalmente riducibilese e solo sem1+ m2+ … + mr= n . Definizione: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne sia λun autovalore di f. Definiamo mf(λ) = mse λha molteplicità mcome radice del polinomio caratteristico di  f.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#27,27,"23/12/2028Molteplicità di un autovaloreDefinizione: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne sia λun autovalore di f. Definiamo mf(λ) = mse λha molteplicità mcome radice del polinomio caratteristico di  f.Teorema: Se λ1, λ2, …, λrsono gli autovalori distinti di unendomorfismo fdi uno spazio vettoriale di dimensione n, si ha:  mf  (λ1) + mf(λ2) + ... + mf  (λr)  ≤ n . In particolare  fha al piùnautovalori distinti.Il polinomio caratteristico di  fè totalmente riducibile se e solo semf (λ1) + mf  (λ2) + ... + mf  (λr) = n.  23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#28,28,"23/12/2029Molteplicità di un autovaloreTeorema: Sia f un endomorfismo di uno spazio vettoriale Vdi dimensione finita ne sia λun autovalore di f. Si ha:  1  ≤  dim E(λ)  ≤  mf(λ). 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#29,29,"23/12/2030Molteplicità di un autovaloreEsempio: Consideriamo l’endomorfismo di R5la cui matrice rappresentativa rispetto alla base canonica è la matrice A: 
V ogliamo determinare gli autovalori di fe le dimensioni dei relativi autospazi.
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#3,3,"23/12/204Autovalori e autovettoriEsempio: Sia  fl’endomorfismo di R2[x] definito daf (a+ bx) := 2b+ (–a+ 3b) xRispetto alla base canonica (p1(x) := 1 e p2(x) := x) di R2[x] questoendomorfismo si rappresenta con la matrice A: Se però consideriamo la base di R2[x] formata dai due polinomi   p1(x) := 1 + xe  p2(x) := 2 + x, vediamo che si ha: f (p1(x)) =  2 + 2x= 2 p1(x) + 0 p2(x) f (p2(x)) =  2 +   x= 0 p1(x) + 1 p2(x) La matrice rappresentativa di  frispetto alla base formata da p1(x)   e p2(x) è la matrice diagonaleA’:f (p1(x)) e f (p2(x)) sono multiplidi p1(x) e p2(x)!
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#30,30,"23/12/2031Molteplicità di un autovaloreEsempio: Consideriamo l’endomorfismo di R5la cui matrice rappresentativa rispetto alla base canonica è la matrice A: 
V ogliamo determinare gli autovalori di fe le dimensioni dei relativi autospazi.
Autovalori: 3 di molteplicità 1, 0 di molteplicità 2, 2 di molteplicità 21 ≤dim E(3)  ≤  mf (3) = 1, pertanto dim E(3) = 1 ; 1≤  dim E(0)  ≤  mf(0) = 2
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#31,31,"23/12/2032Molteplicità di un autovaloreEsempio: Consideriamo l’endomorfismo di R5la cui matrice rappresentativa rispetto alla base canonica è la matrice A: 
V ogliamo determinare gli autovalori di fe le dimensioni dei relativi autospazi.
Autovalori: 3 di molteplicità 1, 0 di molteplicità 2, 2 di molteplicità 21 ≤dim E(3)  ≤  mf (3) = 1, pertanto dim E(3) = 1 ; 1 ≤  dim E(0)  ≤  mf(0) = 2  ;   1≤  dim E(2)  ≤  mf(2) = 2
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#32,32,23/12/2033Molteplicità di un autovaloreIl calcolo degli autovalori con le rispettive molteplicità può esserein alcuni casi semplificato: Teorema: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita. Supponiamo che esista una base per Vrispetto a cui  fsi rappresenta con una matrice triangolareA. Gli autovalori di  fsono gli elementi lungo la diagonale principaledi A: la molteplicità algebrica di ciascuno di essi è uguale alnumero di volteche compare sulla diagonale principale di A. [Dato che (A− xI)è una matrice triangolare: il suo determinante è dato dal prodotto degli elementi lungo la sua diagonale principale.] 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it33
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#33,33,23/12/2034Molteplicità di un autovaloreIl calcolo degli autovalori con le rispettive molteplicità può esserein alcuni casi semplificato: Teorema: Sia f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita. Supponiamo che esista una base per Vrispetto a cui  fsi rappresenta con una matrice triangolareA. Gli autovalori di  fsono gli elementi lungo la diagonale principaledi A: la molteplicità algebrica di ciascuno di essi è uguale alnumero di volteche compare sulla diagonale principale di A. Osservazione: Se λ è un autovalore di molteplicità 1 di unendomorfismo  f allora  dim E(λ) = 1. Un autovalore di molteplicità 1 viene detto semplice.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it34
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#34,34,"23/12/2035Autovalori e autovettori di matrici
Esempio: Sia  fl’endomorfismo di R2[x] definito daf (a+ bx) := 2b+ (–a + 3b) xRispetto alla base canonica di R2[x] questoendomorfismo si rappresenta con la matrice p1(x) := 1 + xe  p2(x) := 2 + xsono autovettoridi  f.  Infatti: 
=
=
Il secondo vettore è due volte il primoIl secondo vettore è una volta il primo23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#35,35,"23/12/2036Autovalori e autovettori di matrici
Esempio: Sia  fl’endomorfismo di R2[x] definito daf (a+ bx) := 2b+ (–a + 3b) xRispetto alla base canonica di R2[x] questoendomorfismo si rappresenta con la matrice p1(x) := 1 + xe  p2(x) := 2 + xsono autovettoridi  f.  Infatti: 
=
=
Ricordiamo che la matrice Aè diagonalizzabilese Aè similea una matrice diagonale (cioè se esiste Minvertibile taleche  M –1A Mè diagonale)23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#36,36,23/12/2037Autovalori e autovettori di matriciGeneralizziamo le proprietà:•Un autovettoredi Acon autovaloreλè un vettore colonna vnon nullo tale che  A v= λ v. •L’autospazioE(λ) è l’insieme dei vettori colonna vtali che Av= λv. •Il polinomio caratteristico di Aè  pA (x) := det (A− xI ). •La molteplicitàmA (λ) di un autovalore λè la sua molteplicità come radice del polinomio caratteristico di A.•Per ogni autovalore λdi una matrice Asi ha 1 ≤ dim E(λ) ≤ mA (λ).•Un autovalore λ èdetto semplicese la sua molteplicità è uguale a 1: la dimensione dell’autospazio relativo a un autovalore semplice è 1.•Gli autovalori di una matrice triangolareAsono gli elementi lungo la diagonale principale: la molteplicità algebrica di ciascuno di essi è pari al numero di volteche compare sulla diagonale principale di A.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it37
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#37,37,"23/12/2038Autovalori e autovettori di matriciEsercizio: Siano dati la matrice Ae il vettore v : 
Determinare per quali valori di kil vettore vè autovettore di A, e relativamente a quale autovalore.
Il vettore wè multiplo di vse e solo se 2 + 2k= 5, ovvero se k= 3/2.Dunque vè autovettoredi Ase e solo se k= 3/2.In tal caso vè autovettore relativamente all’autovalore5. 
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it38"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#4,4,"23/12/205Autovalori e autovettoriDefinizione: Un endomorfismo f: V→Vdi uno spazio vettoriale Vdi dimensione finita si dice diagonalizzabilese esiste (almeno) unabase di Vrispetto a cui  f  si rappresenta con una matrice diagonale.Teorema: Sia  fun endomorfismo di uno spazio vettoriale Vdidimensione finita. Data una base di Vformata da e1, e2, …, en,    la matrice rappresentativa di  frispetto a tale base è diagonalese e solo se f (ei ) è un multiplodi  eiper 1 ≤ i≤ n, ovvero se e solose esistono scalari λ1, λ2, …, λntali che  f (ei ) = λieiper 1 ≤ i≤ n. 
Matrice rappresentativadi  frispetto alla base formata dae1, e2, …, en 23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#5,5,"23/12/206Autovalori e autovettoriDefinizione: Sia f: V→Vun endomorfismo di uno spazio vett. V,v≠ 0 si dice autovettoredi fcon autovaloreλse si ha:  f (v) = λv.Quesito: Lo stesso vettore v≠ 0 può essere un autovettore di  frispetto a due autovalori diversi?No! Infatti: sia vautovettore di  fsia rispetto a due autovalori λe  μ.V ogliamo mostrare che λ= μ. Sappiamo che: f (v) = λ v;  f (v) = μv.Allora λ v= μv, cioè (λ −μ) v= 0. Poiché v≠ 0 abbiamo λ −μ= 0.Osservazione: Nella definizione abbiamo richiesto che v≠ 0. Infatti se v= 0 si ha  f (0) = 0 per qualunque numero reale λ .Dunque se nella definizione non avessimo richiesto v≠ 0,      ogni numero reale λsarebbe autovalore di  f!  23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#6,6,"23/12/207Autovalori e autovettoriEsercizio: Sia dato l’endomorfismo di R3definito daf (x, y, z) := (2x+ 2y+ z,  y,  0)Stabilire per ciascuno dei seguenti vettori se è un autovettore di f.In caso affermativo determinare l’autovalore corrispondente.v1:= (1, 0, 0)   =>  f (v1) = f (1, 0, 0) = (2, 0, 0) OK  =>  f (v1) = 2 v1v2:= (0, 1, 0)   =>  f (v2) = f (0, 1, 0) = (2, 1, 0) NO multiplo di v2v3:= (1, 0, –2) =>  f (v3) = f (1, 0, –2) = (0, 0, 0) OK => f (v3) = 0 v3v4:= (0, 0, 0)   =>  nonè un autovettore perchè, per definizione, un autovettore è diverso dal vettore nullo.23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#7,7,"23/12/208Autovalori e autovettoriTeorema: Sia f: V→Vun endomorfismo di uno spazio vettor. Ve sia λun autovalore di f.  L’insieme E(λ):= {vÎV|  f (v) = λ v}è un sottospaziovettoriale di V , detto autospaziodi  frelativo aλ. Def.: E(λ) è formato dagli autovettoridi  frelativi all’autovalore λe dal vettore nullo.  [Notiamo che, per definizione di autovettore v≠ 0, un autospaziononpuò mai essere costituito dal solo vettore nullo.]
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#8,8,"23/12/209Autovalori e autovettoriTeorema: Sia f: V→Vun endomorfismo di uno spazio vettor. Ve sia λun autovalore di f.  L’insieme E(λ):= {vÎV|  f (v) = λ v}è un sottospaziovettoriale di V , detto autospaziodi  frelativo aλ. Dimostrazione: E(λ) è non vuoto perché contiene il vettore nullo.Se v1e v2sono vettori di E(λ) allora anche la loro somma Îa E(λ)? Sappiamo che f (v1) = λv1 e  f (v2) = λv2e  dobbiamo mostrare che f (v1+ v2) = λ(v1+ v2).  Infatti:   f (v1+ v2) = f (v1) + f (v2) = λv1+ λv2 = λ(v1+ v2).Inoltre, dobbiamo mostrare che se vè un vettore di E(λ) mentre kèuno scalare, allora anche il prodotto k vappartiene a E(λ). Sappiamo che f (v) = λ v .Dobbiamo mostrare che  f (k v) = λ(k v).Infatti:   f (k v) = k f (v) = k λ v= λ (k v).   23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\17_Autovalori_Autovettori.pdf#9,9,"23/12/2010Polinomio caratteristico
23/12/20Geometria e Combinatoria marcella.sama@uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#0,0,23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it1L18: Diagonalizzazione (32)Argomenti lezione:•Introduzione •Diagonalizzazione
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#1,1,"23/12/202IntroduzioneObiettivo: Determiniamo un criterioper stabilire se unendomorfismo (o una matrice) è diagonalizzabile. In caso affermativo, descriviamo un procedimentoper trovare una base formata da autovettori dell’endomorfismo (o della matrice).Teorema: Un endomorfismo  fdi uno spazio vett. Vdi dim. finita è diagonalizzabilese e solo se esiste una base di Vformata daautovettori di  f .Osservazione: Questo teorema non ci dice come stabilire se esiste una base formata da autovettori, ne tantomeno come determinare esplicitamente una tale base (ammesso che esista).23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#10,10,"23/12/2011DiagonalizzazioneEsercizio: Consideriamo l’endomorfismo di R4definito da: 
La matrice rappresentativa di  f  rispetto alla base canonica è : 
Autovalori: 0 di molt. 2,     3+√2 di molt. 1,     3–√2 di molt. 1Verifichiamo per l’autovalore 0 se la sua molteplicità coincide con la dimensione del relativo autospazio:
fnonè diagonalizzabile !23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#11,11,"23/12/2012DiagonalizzazioneEsercizio: Sia dato l’endomorfismo  f: M(2, 2, R) →M(2, 2, R) :
La matrice rappresentativa Adi  frispetto alla base canonicaè : 
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#12,12,"23/12/2013DiagonalizzazioneEsercizio: Sia dato l’endomorfismo  f: M(2, 2, R) →M(2, 2, R) :
Calcoliamo il discriminante (∆ = b2 –4 a c) di  x2–2x–3 : a= 1; b= –2; c= –3 segue  ∆ = 4 + 12 > 0 calcoliamo le radici:x= {–b+/–[radice quadrata ∆] } / 2 a=  1 +/–2 Quindi il polinomio caratteristico di  fè totalmente riducibile.Autovalori:  0 di molt. 2,   –1 di molt. 1,    3 di molt. 1
fè diagonalizzabile ! f  si rappresenta con una matrice diagonale rispetto a una base23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#13,13,"23/12/2014DiagonalizzazioneMetodo per individuare se un endomorfismo è diagonalizzabile:Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dim. finita n.1. Scegliere e1, e2, ... , envettori che formano una basedi V. 2. Calcolare la matrice Arappresentativadi frispetto alla base scelta.3. Definire il polinomio(di grado n) caratt.di  f :pf(x) := det(A–xI ). 4. Risolvere det(A–xI ) = 0. Le soluzioni sono gli autovaloridi  f .    Se pf(x) nonè totalmente riducibile,  fnon èdiagonalizzabile, STOP.5. Per ciascun autovalore (di molteplicità > 1) verificare se la sua molteplicità e la dimensione del suo autospazio coincidono. 6. Se esiste almeno un autovalore λiper cui si ha  dim E(λi ) < m(λi ) allora fnon èdiagonalizzabile, STOP. 7. Se per tutti gli autovalori λisi ha  dim E(λi) = m(λi)                   allora  fèdiagonalizzabile, STOP. 23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#14,14,"23/12/2015DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto a una base :
Ogni autovalore è riportato lungo la diagonale principale un numero divolte uguale alla sua molteplicità.Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:[ Dobbiamo trovare una base per ciascun autospazio e unirle. ][ Tale base deve essere formata da autovettori di  f . ] 
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#15,15,"23/12/2016DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
E(0):Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:
2 equazionilin. indipendenti
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#16,16,"23/12/2017DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
Base per E(0): E(0):Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#17,17,"23/12/2018DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
E(–1):
Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:rk (A–(–1) I ) = 33 equazionilin. indipendenti23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#18,18,"23/12/2019DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
Base per E(–1):E(–1):
E(–1) = {–tE11 + tE12 | tÎR}
Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#19,19,"23/12/2020DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
E(3):Base per E(3): Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#2,2,"23/12/203IntroduzioneEsempio: Sia f: R4[x] →R4[x] l’endomorfismo che associa al polinomio a0+ a1 x+ a2 x2 + a3 x3il polinomio (a0+ a1) + (a1–a2+ a3) x+ (a0+ 2a1–a2) x2+ a3 x3 .Consideriamo la base canonica di R4[x] formata dai polinomi p1(x) := 1,   p2(x) := x,   p3(x) := x2,   p4(x) := x3. Abbiamo calcolato le radici del pol. caratteristico pf (x) := det(A−xI)ovvero gli autovalori di fsono 0 e 1. Abbiamo mostrato che entrambi gli autospazi hanno dim. pari a 1.Domanda:fè diagonalizzabile ? Cioè esiste una base di R4[x] formata di autovettori di  f? Dato che dim E(0) = 1 e dim E(1) = 1, segue che i 4 polinomi p1(x), p2(x), p3(x),p4(x) nonpossono essere tutti autovettori. Dunque,  fnonè diagonalizzabile.   23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#20,20,"23/12/2021DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
Base per E(0): 
Base per E(–1):
Base per E(3): Calcoliamo una base rispetto a cui  fsi rappresenta con la matrice D:;
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#21,21,"23/12/2022DiagonalizzazioneEsercizio(seguito):
f  si rappresenta con la matrice diagonale D rispetto ad una base
Abbiamo trovato una base  di  M(2, 2, R) formata da autovettori di  f  :
Si può verificare che: 
La matrice di passaggio Mdalla base canonica a questa base è : E(0):E(–1):E(3):
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#22,22,"23/12/2023DiagonalizzazioneEsercizio(seguito):
Attenzione:f si rappresenta anche con la matrice diagonale DAbbiamo già trovato una base  di  M(2, 2, R) formata da autovettori di  f  :Si può verificare che: 
La matrice di passaggio Ndalla base canonica a questa base è : 
E(0):E(–1):E(3):
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#23,23,"23/12/2024DiagonalizzazioneMetodo per la ricerca di una base di autovettori di un endomorfismo:Premessa: Sappiamo già che l’endomorfismo  fè diagonalizzabile. 1. Rispetto a una base opportuna di V,  fsi rappresenta con una matrice diagonaleD :  gli elementi lungo la diagonale principale sono gli autovaloridi  f, ciascuno riportato un numero di volte pari alla propria molteplicità (uguale alla dimensione dell’autospazio).2. Determinare una base per ciascun autospazioE(λi ): risolvere il sistema lineare: (A− λi I) X= 0. Il numero di vettori della base di Eideve coincidere con la dimensione del relativo autospazio. 3. Unire le basi di tutti gli autospazi per avere una base di Vformata da autovettoridi  f. 4. La matrice Mdi passaggio(da Aa D ) dalla base di partenza allabase di autovettori soddisfa la relazione:  D= M−1 A M  23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#24,24,"23/12/2025DiagonalizzazioneMetodo per la ricerca di una base di autovettori di un endomorfismo:Premessa: Sappiamo già che l’endomorfismo  fè diagonalizzabile. 4. La matrice Mdi passaggio(da Aa D ) dalla base di partenza allabase di autovettori soddisfa la relazione:  D= M−1 A M  Osservazioni sulle matrici Me D: •Mè la matrice le cui colonne danno le componenti dei vettori della base di autovettori rispetto alla base di partenza.•L’ordine in cui mettiamo gli autovalori lungo la diagonale di De l’ordine in cui scriviamo le colonne di Mdevono essere coerenti: se il k-esimo elemento lungo la diagonale di Dè un autovalore λi , allora la k-esima colonna di Mdeve dare le componenti di un autovettore relativo allo stesso autovaloreλi .23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#25,25,"23/12/2026DiagonalizzazioneEsercizio: Stabilire se la matrice se Aè diagonalizzabile :
Calcoliamo il discriminante (∆ = b2 –4 a c) di  x2–x+1/4 : a= 1; b= –1; c= 1/4  segue ∆ = 1 –1 = 0  calcoliamo le radici:x= {–b+/–[radice quadrata ∆] } / 2 a=  1/2 pA(x) è totalmente riducibile, ovvero pA(x) = –x(x –1/2)2. Autovalori di A: 0 di molteplicità 1 e 1/2 di molteplicità 2.La dimensione dell’autospazio relativo a 0 è necessariamente 1. La dimensione dell’autospazio relativo a 1/2 è : 1 oppure 2 ? 
=  –x(x2–x+1/4 )
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#26,26,"23/12/2027DiagonalizzazioneEsercizio: Stabilire se la matrice se Aè diagonalizzabile :
La dimensione dell’autospazio relativo a 0 è necessariamente 1. La dimensione dell’autospazio relativo a 1/2 è : 1 oppure 2 ? 
Segue la matrice Aè diagonalizzabile ed è simile alla matrice D :
Determiniamo ora una matrice di passaggio da  Aa  D .23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#27,27,"23/12/2028DiagonalizzazioneEsercizio: Stabilire se la matrice se Aè diagonalizzabile :
Determiniamo ora una matrice di passaggio da  Aa  D .Per determinare E(0), risolviamo il sistema ( A− 0I ) X= 0Poichè 0 è autovalore semplice, la dim. dell’autospazio è 1 .Servono quindi 3 − 1 = 2 equazioni lin. indipendenti di A− 0I . (− t, t, 0) al variare di tin RUna base per E(0) è (− 1, 1, 0)23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#28,28,"23/12/2029DiagonalizzazioneEsercizio: Stabilire se la matrice se Aè diagonalizzabile :
Determiniamo ora una matrice di passaggio da  Aa  D .Per determinare E(1/2), risolviamo il sistema ( A− 1/2 I ) X= 0Sappiamo che l’autospazio è di dim. 2.   rk ( A− 1/2 I )= 1 .Serve quindi 3 − 2 = 1 equazione lin. indipendente di  A− 1/2 I . (− 3/2t + 1/2u, t, u) al variare di te uin R
Una base per E(1/2)  è  (− 3/2, 1, 0)  e  (1/2, 0, 1) 23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#29,29,"23/12/2030DiagonalizzazioneEsercizio: Stabilire se la matrice se Aè diagonalizzabile :
Determiniamo ora una matrice di passaggio da  Aa  D .Una base per E(1/2) è  (− 3/2, 1, 0)  e  (1/2, 0, 1) Una base per E(0) è (− 1, 1, 0)Segue una base di R3formata da autovettori di Aè : 
E(0) E(1/2) 23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#3,3,"23/12/204DiagonalizzazioneTeorema: Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne siano 1, 2, …, sgli autovalori distinti di f . Se dim E(1) + dim E(2) + ... + dim E(s) < nallora  fnon è diagonalizzabile. In altre parole: affinchè  fsia diagonalizzabile è necessarioche:dim E(1) + dim E(2) + ... + dim E(s) = n Teorema: Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne siano 1, 2, …, sgli autovalori distinti di f . Prendiamo una base per ciascun autospazio: unendo tali basi siottengono dei vettori tra loro linearmente indipendenti.    Dunque, abbiamo degli autovettori linearmente indipendenti. In particolare:  dim E(1) + dim E(2) + … + dim E(s) ≤ n .23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#30,30,"23/12/2031DiagonalizzazioneEsercizio: Stabilire se il seguente  f: R3→R3è diagonalizzabile : In tal caso, trovare una base di R3formata da autovettori di  fe scrivere la matrice rappresentativa Adi  frispetto a tale base.
rispetto alla base canonica:(1,0,0), (0,1,0), (0,0,1)
Polinomio caratter. di fè totalmente riducibile. Autovaloridi f: 0 e 1.mf (0) = 2 ;  mf (1) = 1 
dim E(0) < mf (0)f  nonè diagonalizzabile !23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#31,31,"23/12/2032DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M 
sviluppo rispetto alla quarta riga
sviluppo rispetto alla seconda riga
Il polinomio caratteristico di Aè totalmente riducibile. Autovalori: 1 di molteplicità 2;  0 e 2 entrambi di molteplicità 1.23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#32,32,"23/12/2033DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M Autovalori: 1 di molteplicità 2;  0 e 2 entrambi di molteplicità 1.
Segue che Aè diagonalizzabile ed è simile alla matrice diagonale:Determiniamo una matrice di passaggio dalla matrice Aalla matrice D.23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#33,33,"23/12/2034DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M 
Determiniamo una matrice di passaggio dalla matrice Aalla matrice D.E(1):
rk(A–1I ) = 2
2 righe linear. indipendentidiA–1Ile cui soluzioni sono (0, t, 0, u) al variare di te uin Runa base per E(1) è :  v1:= (0, 1, 0, 0)  ,  v2:= (0, 0, 0, 1)23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#34,34,"23/12/2035DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M 
Determiniamo una matrice di passaggio dalla matrice Aalla matrice D.E(0):rk(A–0I ) = 33 righe linear. indip. di A–0Ile cui soluzioni sono (–t, 0, t, 0) al variare di tin Runa base per E(0) è :  v3:= (–1, 0, 1, 0)
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#35,35,"23/12/2036DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M 
Determiniamo una matrice di passaggio dalla matrice Aalla matrice D.E(2):rk(A–2I ) = 33 righe linear. indip. di A–2Ile cui soluzioni sono (t, 0, t, 0) al variare di tin Runa base per E(2) è :  v4:= (1, 0, 1, 0)
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#36,36,"23/12/2037DiagonalizzazioneEsercizio: Stabilire se la matrice Aa coeff. reali è diagonalizzabile :
In tal caso, determinare una matrice diagonale Dsimile ad Ae una matrice invertibile Mtale che D= M −1 A M 
Determiniamo una matrice di passaggio dalla matrice Aalla matrice D.una base per E(2) è :  v4:= (1, 0, 1, 0)una base per E(1) è :  v1:= (0, 1, 0, 0)  ,  v2:= (0, 0, 0, 1)una base per E(0) è :  v3:= (–1, 0, 1, 0)
v1v2v3v4
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it37"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#4,4,"23/12/205DiagonalizzazioneTeorema: Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dimensione finita ne siano 1, 2, …, sgli autovalori distinti di f . L’endomorfismo  fè diagonalizzabile se e solo se : dim E(1) + dim E(2) + ... + dim E(s) = nOsservazioni: •Sappiamo che per ciascun autovalore isi ha:  dim E(i)  ≤  mf(i)•dim E(1)+dim E(2) +...+ dim E(s) ≤ mf(1)+mf(2)+...+mf(s) ≤n•Affinchè  fsia diagonalizzabile è necessario che la somma dellemolteplicità degli autovalori sia uguale a n, ovvero il polinomiocaratteristico di  fdeve essere totalmente riducibile•Se anche per uno solo degli autovalori isi ha:  dim E(i)  <  mf(i)allorafnonè diagonalizzabile 23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#5,5,23/12/206DiagonalizzazioneTeorema: Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dim. finita n. L’endomorsmo  fè diagonalizzabile se e solo sesono verificate entrambele seguenti condizioni: 1.il polinomio caratteristico di  fè totalmente riducibile;2.per ciascun autovalore idi  fsi ha:  dim E(i)  =  mf(i). Osservazioni: •Se λè un autovalore semplice allora dim E(λ) = 1.•La seconda condizione del teorema va quindi verificata solamente per gli autovalori di molteplicità almeno 2. 23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it6
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#6,6,"23/12/207DiagonalizzazioneTeorema: Sia  f: V→Vun endomorfismo di uno spazio vett. Vdi dim. finita n. L’endomorsmo  fè diagonalizzabile se e solo sesono verificate entrambele seguenti condizioni: 1.il polinomio caratteristico di  fè totalmente riducibile;2.per ciascun autovalore idi  fsi ha:  dim E(i)  =  mf(i). Calcolo di una base particolare: In tal caso una base di  Vformata da autovettori di  fsi ottiene  prendendo una base per ciascun autospazio e unendole. Rispetto a tale base:  fsi rappresenta con una matrice diagonale i cui elementi lungo la diagonale sono gli autovalori di  f,  ciascuno ripetuto un numero di volte pari alla sua molteplicità.23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#7,7,"23/12/208DiagonalizzazioneTeorema: Sia  fun endomorfismo di uno spazio vett. di dim. n. Se  f  ha nautovalori distinti allora  f  è diagonalizzabile.Esempio: Sia data la matrice Ae il suo polinomio caratteristico:  
Calcoliamo il discriminante (∆ = b2 –4 a c) di  x2–6x+ 10 : a= 1; b= –6; c= 10 segue ∆ = 36 –40 < 0 quindi no radici reali Quindi il polinomio caratteristico di Anonè totalmente riducibile. Segue che la matrice Anonè diagonalizzabile.23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#8,8,"23/12/209DiagonalizzazioneEsercizio: Consideriamo l’endomorfismo di R4definito da: 
La matrice rappresentativa di  f  rispetto alla base canonicaè : 
2x+ y2y+ z3y+ 2w2x+ 6y+ z+ 2
23/12/20Geometria e Combinatora   marcella.sama@uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\18_Diagonalizzazione.pdf#9,9,"23/12/2010DiagonalizzazioneEsercizio: Consideriamo l’endomorfismo di R4definito da: 
La matrice rappresentativa di  f  rispetto alla base canonica è : 
Calcoliamo il discriminante (∆ = b2 –4 a c) di  x2–6x+ 7 : a= 1; b= –6; c= 7  segue  ∆ = 36 –28 > 0 calcoliamo le radici:x= {–b+/–[radice quadrata ∆] } / 2 a=     3 +/–√2Quindi il polinomio caratteristico di  fè totalmente riducibile.Autovalori: 0 di molt. 2,     3+√2 di molt. 1,     3–√2 di molt. 123/12/20Geometria e Combinatora   marcella.sama@uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#0,0,03/11/20Geometria e Combinatoriasama@ing.uniroma3.it1L1: Matrici (2-4) Argomenti lezione:•Definizione di Matrice•Matrici particolari•Operazioni tra matrici
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#1,1,"Definizione di matrice
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#10,10,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it11MatriciDefinizioni:Una matrice quadrata A= (aij) di ordine nsi dice triangolaresuperiorese tutti gli elementi che si trovano sottola diagonaleprincipale sono nulli.Una matrice quadrata A= (aij) è triangolare superiore se e solo  se aij= 0 per ogni i> jInsieme matrici triangolari superiori di ordine na coefficienti reali: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#11,11,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it12MatriciInsieme matrici triangolari superioridi ordine na coefficienti reali:Osservazione: la definizione di matrice triangolare superiore nonimplica che aij≠ 0 per ogni i≤ jEsempio:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#12,12,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it13MatriciInsieme matrici triangolari inferioridi ordine na coefficienti reali:Þtutti gli elementi che si trovano al di sopradella diagonale = 0 Esempio: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#13,13,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it14MatriciEsercizio di base (1): Determinare la matrice quadrata A:= (aij) di ordine 3 tale che aij:= max (0, i− j) 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#14,14,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it15MatriciEsercizio di base (2): Determinare la matrice quadrata A:= (aij) di ordine ntale che aij:= max (0, i− j) appartiene a Dobbiamo dimostrare che Aè una matrice triangolare inferiore, ovvero se j> i, allora aij= 0. Sia quindi j> i. Ricordiamo che  abbiamo aij= max(i− j, 0). Ma i− j< 0, perché j> i,da cui aij= 0.  
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#15,15,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it16MatriciDefinizione: Una matrice quadrata avente nulli tutti gli elementi non appartenenti alla diagonale principale si dice diagonale. Esempio: Insieme delle matrici diagonali di ordine na coefficienti reali:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#16,16,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it17MatriciDefinizione: Una matrice quadrata si dice simmetricase i suoi elementi in posizioni simmetriche rispetto alla diagonale principalesono uguali.Esempio: Insieme delle matrici simmetriche di ordine na coefficienti reali:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#17,17,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it18MatriciEsercizio di base: Dimostrare che ogni matrice diagonale è simmetrica, ovvero:Data una matrice A:=(aij)diagonale, si ha che aij= 0 se i≠ j. Dobbiamo dimostrare che aij= ajiper ogni coppia di indici ie j. Se i= j, ciò è ovvio. Se i≠ j, allora aij= 0 = aji(per la definizione di matrice diagonale). 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#18,18,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it19MatriciEsercizio di base (1): Determinare se la matrice quadrata A:= (aij)di ordine 3 tale che aij:= i+ jè simmetrica. 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#19,19,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it20MatriciEsercizio di base (2): Determinare se la matrice quadrata A:= (aij)di ordine ntale che aij:= i+ jè simmetrica. Dimostriamo che si ha  aij= ajiqualunque siano ie j . Poichè, per definizione, abbiamo  aij= i+ j , otteniamo:  aij= i+ j= j+ i= aji(proprietà commutativa della somma)Risposta: Sì!"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#2,2,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it3MatriciDef.: Una matrice a coefficienti reali a prighe e qcolonne è una tabella di numeri reali disposti su prighe e qcolonne
I numeri pe qvengono detti dimensionidella matrice di tipo (p, q), ovvero della matrice con prighe e qcolonne
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#20,20,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it21Matrice traspostaDefinizione: Data una matrice A:= (aij) a prighe e qcolonne, si dice matrice traspostadi Ala matrice a qrighe e pcolonneavente come elemento di posto (j, i) l'elemento di posto (i, j) di AEsempio:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#21,21,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it22Proprietà della matrice traspostaEsempio: Calcolare la matrice trasporta di A
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#22,22,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it23Proprietà della matrice traspostaEsercizio di base: Dimostrare la seguente affermazioneAbbiamo cheQuesto significa che se i> jallora aij= 0.Sia                                            da cuiDobbiamo dimostrare che  quindi dimostrare che, se i> jallora bji= 0.Sia allora i> j. Abbiamo bji= aij= 0,vale a dire  
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#23,23,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it24Proprietà della matrice traspostaEsercizio di base: Dimostrare la seguente affermazioneDimostriamo il viceversa, ovvero:supponendo che se                                        allora  , ovvero bji= 0 per ogni i > jabbiamo aij= bji, quindi aij= 0 per ogni i> j, vale a dire
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#24,24,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it25Proprietà della matrice traspostaEsercizio di base: Dimostrare la seguente affermazioneAnalogamente si dimostra la seguente affermazione:Inoltre si può dimostrare che: •ogni matrice simmetrica coincide con la sua traspostaEsempio: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#25,25,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it26Proprietà della matrice traspostaEsercizio di base: Dimostrare la seguente affermazioneAnalogamente si dimostra la seguente affermazione:Inoltre si può dimostrare che: •ogni matrice simmetrica coincide con la sua trasposta•una matrice quadrata è simmetrica se e solo se coincide con la propria trasposta, ovvero: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#26,26,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it27Proprietà della matrice traspostaEsempio: Calcolare la matrice trasporta di A e la trasposta di
In generale, data una qualsiasi matricesi può dimostrare che  
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#27,27,"Operazioni tra matrici
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#28,28,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it29Matrice sommaObiettivo: Date matrici  Ae Bdefiniamo una matrice  A+ BN.B. L'operazione di addizione tra matrici verifica proprietà analoghe alle usuali proprietà dell'addizione tra numeri reali.Esempio: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#29,29,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it30Matrice sommaDefinizione: Date due matrici A:= (aij)  e B:= (bij) entrambe di tipo (p, q), chiamiamo matrice somma A+ Bdi tipo (p, q) il cui elemento di posto (i, j) è dato dalla somma degli elementi di posto (i, j) delle matrici Ae B, ovvero:Osservazione: Si possono sommare solamente matrici che hanno lo stesso numero di righe e lo stesso numero di colonne, cioè matrici dello stesso tipo.
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#3,3,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it4MatriciDef.: Una matrice a coefficienti reali a prighe e qcolonne è una tabella di numeri reali disposti su prighe e qcolonne
Elemento(o coefficiente) di posto (i, j) della matrice Aè il numero reale sulla i-esima riga e sulla j-esima colonna di A
i-esima riga j-esima colonna "
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#30,30,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it31Matrice somma
-Aè chiamata la matrice opposta di A0 è chiamata la matrice nulla, in questo caso è di tipo (p, q)"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#31,31,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it32Matrice somma
-Aè chiamata la matrice opposta di AEsempio:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#32,32,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it33Matrice somma
Legge di semplicazione per l'addizione matriciale:Dimostrazione: Partiamo dal fatto che A+ C= B+ Cpoi                              A+ C+ (-C) = B+ C+ (-C)poichè si ha C+ (-C) = 0allora                         A+ 0 = B+ 0e sfruttando la proprietà della matrice nulla segue A= B"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#33,33,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it34Matrice somma
Esempio:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#34,34,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it35Moltiplicazione per uno scalareDefinizione: Data una matrice Ae un numero reale k, indichiamo con kAla matrice di tipo (p, q)avente come elementi quelli della matrice Amoltiplicati per k. Studiamo le proprietà della moltiplicazione per uno scalare.Esempio: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#35,35,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it36Moltiplicazione per uno scalare
NOTA: Nella 6, lo 0 a sinistra è un numero, lo 0 a destra è una matrice di tipo (p,q)"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#36,36,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it37Matrice prodotto
Il numero delle (q) colonne di Adeve essere uguale al numero delle (q) righe di BIl prodotto A• Bè una matrice a prighe (come A) e rcolonne (come B)"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#37,37,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it38Matrice prodotto
Esempio:
prodotto righe per colonne delle matrici  Ae  B4x22x3AB =4x3Non è possibile fare il prodotto di Be A"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#38,38,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it39Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:AB ="
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#39,39,"AB =
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it40Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#4,4,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it5MatriciEsempio: 
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#40,40,"AB =
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it41Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#41,41,"AB =
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it42Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#42,42,"AB =
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it43Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#43,43,"AB =
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it44Matrice prodotto
prodotto righe per colonne delle matrici  Ae  BEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#44,44,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it45Matrice prodotto
4 righe e 3 colonneEsempio:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#45,45,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it46Matrice prodotto
Calcolare AI = 
Esercizio di base:"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#46,46,"03/11/2047Matrice prodottoDeterminare quali dei seguenti prodotti sono definiti: AB  SI, perché il numero delle colonne di A(3) è uguale al numero delle righe di B (3).BA  NO, perché il numero delle colonne di B(3) non è uguale al numero delle righe di A (2).AA  NO, non è una matrice quadrataBB  SI, è una matrice quadrata (3, 3)  =>
Esercizio di base:2x33x3
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it47"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#47,47,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it48Proprietà della moltiplicazioneL'operazione di moltiplicazione tra matrici verifica alcuneproprietà analoghe all'operazione di moltiplicazione tra numeriVale la proprietà associativadella moltiplicazione di matrici:Attenzione: ABè una matrice di tipo (p, r) e (AB)Cè di tipo (p, s). BCè una matrice di tipo (q, s) e A(BC) è di tipo (p, s). Dunque (AB)Ce A(BC) sono matrici dello stesso tipo.
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#48,48,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it49Proprietà della moltiplicazioneL'operazione di moltiplicazione tra matrici verifica alcuneproprietà analoghe all'operazione di moltiplicazione tra numeriValgono le proprietà distributivedelle operazioni matriciali:
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#49,49,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it50Proprietà della moltiplicazioneL'operazione di moltiplicazione tra matrici verifica alcuneproprietà analoghe all'operazione di moltiplicazione tra numeri
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#5,5,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it6MatriciEsercizio di base: Determinare la matrice Adi tipo (2, 2) tale che aij:= i+ j
1+11+22+12+2"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#50,50,"03/11/2051Proprietà della moltiplicazione
Esempio:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it51"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#51,51,"03/11/2052Proprietà della moltiplicazione
Esempio:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it52"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#52,52,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it53Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Nonvale la proprietà commutativa. Per esempio, se Ae Bsono due matrici tali che sia definito il prodotto AB, allora:•il prodotto BApotrebbe non essere definito;•il prodotto BApotrebbe essere definito ma avere dimensioni diverse da AB;=> Per poter fare entrambi i prodotti ABe BAdeve essere Adi tipo (p, q) e Bdi tipo (q, p). Da cui, si ha ABdi tipo (p, p)e BAdi tipo (q, q). Ha le stesse dimensioni solo sesi ha: p= q."
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#53,53,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it54Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Nonvale la proprietà commutativa. Per esempio, se Ae Bsono due matrici tali che sia definito il prodotto AB, allora:•il prodotto BApotrebbe non essere definito;•il prodotto BApotrebbe essere definito ma avere dimensioni diverse da AB;•il prodotto BApotrebbe essere definito e avere le stesse dimensioni di AB(sono due matrici quadrate dello stesso ordine), ma non è detto che i prodotti ABe BAsono uguali."
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#54,54,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it55Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Nonvale la proprietà commutativa. Per esempio, se Ae Bsono due matrici tali che sia definito il prodotto AB, allora:•il prodotto BApotrebbe essere definito e avere le stesse dimensioni di AB(sono due matrici quadrate dello stesso ordine), ma non è detto che i prodotti ABe BAsono uguali.Contro-Esempio: "
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#55,55,"03/11/2056Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Nonvale la proprietà commutativa. Per esempio, se Ae Bsono due matrici tali che sia definito il prodotto AB, allora:•il prodotto BApotrebbe essere definito e avere le stesse dimensioni di AB(sono due matrici quadrate dello stesso ordine), ma non è detto che i prodotti ABe BAsono uguali.=> Ciò non implica che, date comunque Ae B, si ha sempreAB≠ BA.Definizione: Date due matrici quadrate Ae Bdello stesso ordine, Ae Bcommutanoo permutanose si ha AB= BA.03/11/20Geometria e Combinatoriasama@ing.uniroma3.it56"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#56,56,"03/11/2057Proprietà della moltiplicazioneDefinizione: Date due matrici quadrate Ae Bdello stesso ordine, AeBcommutanoo permutanose si ha AB= BA.Esempio: Siano Ae Bdue matrici quadrate dello stesso ordine.Stabilire se è vero o falso che qualunque siano Ae Bsi ha:
Da cui è vero se e solose AB= BA, ovvero Ae Bcommutano!03/11/20Geometria e Combinatoriasama@ing.uniroma3.it57"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#57,57,"03/11/2058Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Un'altra proprietà che nonvale è il principio di annullamento del prodotto: se Ae Bsono due matrici tali che AB= 0 non èdetto che almeno una delle matrici Ae Bsia nulla.Esempio:
AB= 003/11/20Geometria e Combinatoriasama@ing.uniroma3.it58"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#58,58,"03/11/2059Proprietà della moltiplicazioneAltre proprietà della moltiplicazione tra numeri reali nonsonovalide nel caso delle matrici. Nonvale la legge di semplificazione del prodotto: se A, Be Csono matrici tali che AC= BCe  C≠ 0, non è detto che Asia uguale alla matrice B.Esempio:
AB= 00B= 0AB= 0BA≠ 059Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#59,59,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it60Matrici e sistemiEsempio: Consideriamo il sistema S
matrice dei coefficienti di S"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#6,6,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it7MatriciDefinizioni:l'insieme delle matrici a coefficienti reali di tipo (p, q)una matrice a coefficienti reali a prighe e qcolonnel'insieme delle matrici quadratedi ordine na coefficienti realiIn una matrice quadrata A= (aij) di ordine n, gli elementi       a11,  a22, …, annsi dicono elementi della diagonale principale
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#60,60,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it61Matrici e sistemiEsempio: Consideriamo il sistema S
matrice colonna delle incognite di S"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#61,61,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it62Matrici e sistemiEsempio: Consideriamo il sistema S
matrice colonna dei termini noti di S"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#62,62,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it63Matrici e sistemiEsempio: Consideriamo il sistema S
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#63,63,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it64Matrici e sistemiEsempio: Consideriamo il sistema S
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#64,64,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it65Matrici e sistemiDato un sistema di pequazioni inq incognite:
N.B. Risolvere il sistema Sè equivalente a determinare (se esistono) tuttele matrici Xtali che A X= B.
Allora possiamo scrivere il sistema Snella forma :  A X= B"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#65,65,"Esempio (1): Data la matrice A:determinare tutte le matrici XÎM(2, 2, R) tali che AX= 0.
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it66Matrici e sistemi
AX= 0 se e solo se:
Ciò avviene se e solo se a= b= c= d= 0, cioè se e solo se Xè la matrice nulla.
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#7,7,"Matrici particolari
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#8,8,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it9MatriciEsempio:La matrice Aè una matrice quadrata di ordine 3 Gli elementi sulla diagonale principale sono 2, 3, 6Inoltre tutti gli elementi di Ache si trovano sottola diagonaleprincipale, cioè gli elementi a21, a31, a32sono nulli. Per questa ragione la matrice Asi chiama triangolare superiore
"
data_test\rootfolder\università\GeometriaECombinatoria\1_Matrici.pdf#9,9,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it10MatriciDefinizioni:Una matrice quadrata A= (aij) di ordine nsi dice triangolaresuperiorese tutti gli elementi che si trovano sottola diagonaleprincipale sono nulli.Una matrice quadrata A= (aij) è triangolare superiore se e solo  se aij= 0 per ogni i> j
"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#0,0,03/11/20Geometria e Combinatoriasama@ing.uniroma3.it1L2: Determinante (5)Argomenti lezione:•Definizione •ProprietàStudiamo il determinante di una matricequadratae le sue proprietà
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#1,1,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it2Definizione determinante
Il numero reale ad –bc è chiamato determinanteL'equazione lineare in un'incognitaax = bha un'unica soluzione se e solo se a≠ 0Il sistema di due equazioni lineari
ha un'unica soluzione se e solo se ad –bc ≠ 0.
≠ 0≠ 0"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#10,10,"03/11/2011Proprietà determinanteFormula di sviluppo del determinante secondo la j-esima colonna:
Esempio:  
1103/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#11,11,"03/11/2012Proprietà determinanteSia Auna matrice quadrata.1. Se una riga o una colonna di Aha tutti i suoi elementi uguali a 0, allora det A= 0.2. Se Aè una matrice triangolare superiore o inferiore allora det Aè uguale al prodotto degli elementi della diagonale principale di A.Dimostrazione(punto 2):Se prendiamo una matrice triangolare superiore, tutti gli elementi della prima colonna di Atranne eventualmente a11sono nulli. det A= a11det A11Il minore A11è anch'esso una matrice triangolare superiore.Proseguendo in tal modo si ha: det A= a11a22… ann1203/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#12,12,"03/11/2013Proprietà determinanteSia Auna matrice quadrata.1. Se una riga o una colonna di Aha tutti i suoi elementi uguali a 0, allora det A= 0.2. Se Aè una matrice triangolare superiore o inferiore allora det Aè uguale al prodotto degli elementi della diagonale principale di A.
1303/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#13,13,"03/11/2014Proprietà determinante
Esempio:  
1403/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#14,14,"03/11/2015Proprietà determinanteUna matrice quadrata con due righe (o due colonne) uguali hadeterminante nullo.Caso n= 2: Dimostrare che una matrice quadrata Adiordine 2con le righe uguali ha determinante nullo.
1503/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#15,15,03/11/2016Proprietà determinanteUna matrice quadrata con due righe (o due colonne) uguali hadeterminante nullo.Caso n= 3: Dimostrare che una matrice quadrata Adi ordine3con 2 righe uguali ha determinante nullo.1.La matrice Aha due righe uguali fra loro pertanto le matrici aggiunte degli elementi della riga rimanente sono matrici di ordine 2 aventi 2 righe uguali.2.Le matrici aggiunte hanno determinante nullo (vedi n = 2) . 3.Sviluppando il determinante di Arispetto alla riga rimanente troviamo quindi che il determinante è nullo. 1603/11/20Geometria e Combinatoriasama@ing.uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#16,16,03/11/2017Proprietà determinanteUna matrice quadrata con due righe (o due colonne) uguali hadeterminante nullo.Caso n= 2: Dimostrare che una matrice quadrata Adiordine 2con le righe uguali ha determinante nullo.Caso n= 3: Dimostrare che una matrice quadrata Adiordine 3con 2 righe uguali ha determinante nullo.… Ripetendo il ragionamento per matrici quadrate Adi ordine maggiore di ntroviamo quindi che det A= 0.1703/11/20Geometria e Combinatoriasama@ing.uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#17,17,"03/11/2018Proprietà determinanteUna matrice quadrata con due righe (o due colonne) uguali hadeterminante nullo.Caso n= 2: Dimostrare che una matrice quadrata Adi ordine 2 con le righe uguali ha determinante nullo.Caso n= 3: Dimostrare che una matrice quadrata Adi ordine 3 con 2 righe uguali ha determinante nullo.… Ripetendo il ragionamento per matrici quadrate Adi ordine maggiore di ntroviamo quindi che det A= 0.Se invece Aha due colonne uguali basta osservare che in tal caso la trasposta di Aha due righe uguali e, pertanto, anche il dettA è nullo. Inoltre sappiamo che detA= dettA.1803/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#18,18,"03/11/2019Proprietà determinanteLa dimostrazione vista si chiama per induzione ovvero:Passo iniziale: si dimostra direttamente il caso iniziale dellaproprietà, ovvero il caso n= 2Passo induttivo: si suppone che la proprietà sia vera per gli interi minori di ne si utilizza questa supposizione per dimostrare la proprietà per l'intero n.Per la matrice quadrata con due righe/colonne uguali abbiamo:•supposto di aver dimostrato che matrici di ordine minore di ncon due righe/colonne uguali abbiano determinante nullo;•usato questa proprietà per provare che matrici di ordine ncon due righe/colonne uguali hanno determinante nullo.1903/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#19,19,"03/11/2020Proprietà determinanteSiano Ae Bdue matrici quadrate di ordine nche si ottengonouna dall'altra scambiando fra loro due righe. Allora det A= − det B(un'analoga proprietà vale per lo scambio di colonne).Caso n= 2:
2003/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#2,2,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it3Definizione determinanteObiettivo: Definire e studiare le proprietà del determinante nel caso di sistemi di nequazioni in nincognite, aventi quindi le matrici dei coefficienti quadrate di ordine n. Tali sistemi hanno un'unica soluzione se e solo se il determinante della matrice dei coefficienti Aè diverso da 0Esempio:  
Det Aè : 
"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#20,20,03/11/2021Proprietà determinanteSiano Ae Bdue matrici quadrate di ordine nche si ottengonouna dall'altra scambiando fra loro due righe. Allora detA= − detB.Dim.: Anche in questo caso la dimostrazione è per induzione.Passo induttivo: Sia allora n> 2 e supponiamo che le righe i1-esima e i2-esima di Ae Bsiano scambiate fra loro.Sviluppiamo il determinante sia di Ache di Brispetto a una qualsiasi riga diversa da i1-esima e i2-esima:•gli elementi di questa riga sono uguali fra loro nelle due matrici; •le matrici aggiunte di questi elementi sono matrici quadrateche si ottengono scambiando fra loro due righe; •per ipotesi di induzione si ha : detA= –detB.2103/11/20Geometria e Combinatoriasama@ing.uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#21,21,"03/11/2022Proprietà determinanteTeorema (di Binet)
Esempio:  
–2322203/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#22,22,"03/11/2023Proprietà determinante
Esempio:
2303/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#23,23,"03/11/2024Proprietà determinanteData una matrice Adi ordine 2  e un numero reale ksi ha:
2403/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#24,24,"03/11/2025Proprietà determinanteDate una matrice Ae una matrice Bcosì fatte:
Osservando le due matrici, notiamo che le matrici aggiunte degli elementi della i-esima riga di Bsono uguali alle matrici aggiunte degli elementi della i-esima riga di A(Ai1= Bi1, Ai2= Bi2, etc.)  Segue che det B= k det A2503/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#25,25,"03/11/2026Proprietà determinante
Dimostrazione: •La matrice k Asi può ottenere dalla matrice Amoltiplicando la prima riga di Aper k, poi moltiplicando la seconda riga della matrice così ottenuta per ke così via per le nrighe di A. •Le matrici che via via otteniamo hanno determinante uguale al determinante della matrice precedente moltiplicato per k. •Dunque applicando nvolte il procedimento otteniamo:
2603/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#26,26,"03/11/2027Proprietà determinanteSe una matrice quadrata Aha una riga che è multipla di un'altra,allora det A= 0. Un'analoga proprietà vale per le colonne.Esempio:  
Notiamo che la quarta riga di Aè –3/2 la seconda riga(–3/2 volte la seconda riga equivale alla quarta riga). Dalla proposizione enunciata sopra abbiamo detA= 0.2703/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#27,27,"03/11/2028Proprietà determinanteEsercizio di base:
Dimostrare che nonesiste alcuna matrice quadrata Xdi ordine 3 tale che AX= I.
Si dovrebbe avere, per ipotesi, che det (AX) = det I= 1. Ma, applicando il teorema di Binet, otteniamo:
2803/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#3,3,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it4Definizione determinanteData una matrice quadrata di ordine n> 1 e un suo elemento aij, definiamo matrice aggiuntadi aijla matrice di ordine n>1 ottenuta da Acancellando la i-esima riga e la j-esima colonna. Indichiamo questa matrice con il simbolo AijEsempio:  
•••"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#4,4,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it5Definizione determinanteSia Auna matrice quadrata di ordine n, chiamiamo determinantedi Ail numero det Acalcolato come segue:
"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#5,5,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.it6Definizione determinanteSia Auna matrice quadrata di ordine n, è detto determinantedi Ail numero det Acalcolato come segue:
Esempio:  
det"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#6,6,"03/11/207Definizione determinanteSia Auna matrice quadrata di ordine n, chiamiamo determinantedi Ail numero det Acalcolato come segue:
Definizione per induzioneo ricorrenza703/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#7,7,"03/11/208Proprietà determinante
Formula di sviluppo del determinante secondo la i-esima riga:
Suggerimento: scegliere le righe con il maggior numero di zeriEsempio (1):  
803/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#8,8,"03/11/209Proprietà determinante
Formula di sviluppo del determinante secondo la i-esima riga:Esempio (2):  
Suggerimento: scegliere le righe con il maggior numero di zeri
903/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\2_Determinante.pdf#9,9,"03/11/2010Proprietà determinanteFormula di sviluppo del determinante secondo la j-esima colonna:
Esempio:  
1003/11/20Geometria e Combinatoriasama@ing.uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#0,0,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itL3: Matrice inversa (1,6)Argomenti lezione:•Matrice unità•Matrice inversa •Proprietà dell’inversa •Sistemi di equazioni lineari•Teorema di Cramer1"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#1,1,"Matrice Unità
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#10,10,"03/11/2011La matrice inversa è unicaData una matrice invertibile Asi chiama inversadi  Al’unicamatrice Btale che AB= BA= I.
Se Aè una matrice invertibile e Be Csono due matrici taliche AB= BA= Ie AC= CA= I, allora B= C.
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#11,11,"03/11/2012Matrice inversaUna matrice quadrata Aè invertibile se e solo se det A≠0. In tal caso, detto nl’ordine di A, la matrice inversa di Asi calcola nel modo seguente:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#12,12,"03/11/2013Matrice inversaUna matrice quadrata Aè invertibile se e solo se det A≠0. In tal caso, detto nl’ordine di A, la matrice inversa di Asi calcola nel modo seguente:
Attenzione:1.Consideriamo il determinante della matrice aggiunta Aji2.Lo dividiamo per il det A≠ 03.Lo moltiplichiamo per −1 elevato alla somma degli indici
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#13,13,"03/11/2014Matrice inversaEsempio (1):
det A≠ 0
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#14,14,"03/11/2015Matrice inversa
Aè invertibile !
Esempio (2):
bij= 
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#15,15,"03/11/2016Proprietà dell’inversaL'inversa di una matrice invertibile Aè una matrice invertibile.
Dimostrazione:Bisogna verificare che vale (def.): è per definizione l’inversa di A e quindi i due prodotti indicati sopra sono validi.Inoltre, dal teorema di Binet si ha:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#16,16,"03/11/2017Proprietà dell’inversaDate due matrici invertibili Ae Bdello stesso ordine, anche ilprodotto ABè invertibile e si ha:
Dimostrazione:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#17,17,"03/11/2018Proprietà dell’inversaData una matrice invertibile A, la sua trasposta è invertibile e si ha:
Dimostrazione:
Data una matrice invertibile A:Per la trasposta di un prodotto si ha:
Segue:
La trasposta della matrice identità è la matrice identità, per cui:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#18,18,"03/11/2019Proprietà dell’inversa
Dimostrazione:Moltiplicando a sinistra ambo i membri per l’inversa di Asi ha:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#19,19,"03/11/2020Proprietà dell’inversa
Si dimostra in modo analogo al precedente che: 
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#2,2,"03/11/203Matrice unitàProprietà dei numeri reali sull’inversodi un numero: dato un numero reale a≠0 esiste un numero reale btale che ab = 1. Tale numero bnon solo esiste, ma è anche unico. Studiamo la medesima proprietà per le matrici. Ci domandiamo:1.Esiste una matrice unità Icorrispondente al numero 1 ? 2.Data una matrice quadrataA, con A≠ 0, esiste una matrice quadrataB, tale che AB = I ?Risposte:1.Esiste la matrice unità I 2.Esiste la matrice quadrata Bse e solo se detA ≠ 003/11/20Geometria e Combinatoriasama@ing.uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#20,20,"Sistemi di equazioni lineari
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#21,21,"03/11/20Una equazione in una incognitaObiettivo:comedeterminareleeventualisoluzionidiunaequazionelineareinunaincognitaEsempidiequazionilineariinunaincognita:3x = 2   => SOLUZIONE  0x = 20x = 0
Geometria e Combinatoriasama@ing.uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#22,22,03/11/20Una equazione in una incognitaObiettivo:comedeterminareleeventualisoluzionidiunaequazionelineareinunaincognitaEsempidiequazionilineariinunaincognita:3x = 20x = 2 => NO SOLUZIONE0x = 0Geometria e Combinatoriasama@ing.uniroma3.it23
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#23,23,"03/11/20Una equazione in una incognitaObiettivo:comedeterminareleeventualisoluzionidiunaequazionelineareinunaincognitaEsempidiequazionilineariinunaincognita:3x = 20x = 20x = 0 => INFINITE SOLUZIONI,tale equazione si dice identicamente soddisfattaGeometria e Combinatoriasama@ing.uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#24,24,"03/11/20Una equazione in una incognitaEserciziodibase:Percheesistonoinfiniteequazionilineariinunaincognita?Ogni equazione lineare in una incognita può scriversi:ax= bEssa è determinata da due numeri qualsiasi: •il coefficiente adella x(incognita)•il termine noto bPoiché i numeri sono infiniti, le equazioni sono infinite.Geometria e Combinatoriasama@ing.uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#25,25,"03/11/20Una equazione in una incognitaOgni equazione lineare in un’incognita può scriversi:ax= bFissatiinumeriaeb,l'equazioneprecedentehasoluzioni?Quante?Procedimento: Isoliamo l’incognita x, ovvero moltiplichiamoambo i membri per l'inverso di a. Abbiamo due casi: 1.a≠ 0 =>                           => Abbiamo una sola soluzione2.a= 0 => primo membro è nullo, secondo membro? 
Geometria e Combinatoriasama@ing.uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#26,26,"03/11/20Una equazione in una incognitaOgni equazione lineare in un’incognita può scriversi:ax= b2. a= 0 => primo membro è nullo, secondo membro?•2.1Sotto caso b≠ 0 => I due membri dell'equazione sono diversi qualunque valore assuma la x. Quindi no soluzioni.•2.2Sotto caso b= 0 => I due membri dell'equazione sono uguali a 0, qualsiasi valore assuma la x. Infinite soluzioni.Geometria e Combinatoriasama@ing.uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#27,27,"03/11/20Due equazioni in due incogniteObiettivo:comedeterminareleeventualisoluzionididueequazionilineariindueincogniteEsempididueequazionilineariindueincognite:sistemaUna soluzione di un sistema Sè una coppia di numeri (h, k) che, sostituita nelle due equazioni alla coppia (x, y), da due uguaglianze 
Geometria e Combinatoriasama@ing.uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#28,28,"03/11/20Due equazioni in due incogniteLa coppia (-2, 3) è una soluzione del nostro sistema? No, ecco perché:
Geometria e Combinatoriasama@ing.uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#29,29,"03/11/20Due equazioni in due incogniteLa coppia (8/3, 2/3) è una soluzione del nostro sistema? Sì, ecco perché:Come si è potuta determinare tale soluzione? Ci sono altre soluzioni a tale sistema?  
Geometria e Combinatoriasama@ing.uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#3,3,"03/11/204Matrice unitàChiamiamo matrice unitào matrice identicadi ordine nlamatrice quadrata Inavente tutti gli elementi della diagonale principale uguali a 1 e tutti gli altri elementi uguali a 0 (la matrice identica è, quindi, una matrice diagonale).
det I= 1E’ una matrice triangolare.Il suo determinante è uguale al prodotto degli elementi della sua diagonale principale!03/11/20Geometria e Combinatoriasama@ing.uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#30,30,"03/11/20Due equazioni in due incogniteProcedimento per determinare le soluzioni al sistema S:1.Sottraendo alla seconda equazione la prima equazione, si ha:Da cui: y= 2/3 e sostituendo y= 2/3 nella prima equazione si ha x= 8/3 
sistemaequivalentead S
Geometria e Combinatoriasama@ing.uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#31,31,"03/11/20Due equazioni in due incognite
Sistema Sè equivalentea sistema S’  significa Sha le stesse soluzioni di S’ Trasformazioni possibili: •Sommare a un'equazione del sistema un'altra equazione moltiplicata per una costante (abbiamo sommato alla seconda equazione la prima equazione moltiplicata per –1)•Moltiplicare un'equazione per una costante non nulla (Per determinare yabbiamo moltiplicato la seconda equazione per 1/3 trovando y= 2/3)Geometria e Combinatoriasama@ing.uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#32,32,"03/11/20Due equazioni in due incognite
Sistema Sè equivalentea sistema S’  significa Sha le stesse soluzioni di S’ Trasformazioni possibili: •Possiamo anche scambiare tra loro due equazioni:
sistemaequivalentea S (eS’)Geometria e Combinatoriasama@ing.uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#33,33,"03/11/20Due equazioni in due incogniteEserciziodibase:Determinareleeventualisoluzionidelsistema:Sommiamo alla II equazione la I equaz. moltiplicata per –3/2Il sistema ha quindi una sola soluzione: (x = 13/4, y = –7/4)  
Geometria e Combinatoriasama@ing.uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#34,34,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itDue equazioni in due incogniteIngeneraleabbiamoilseguentesistemadiequazioni:Vedremonelcorsoche:se ae–bd≠ 0, allora il sistema ha una sola soluzione(Cramer)se ae–bd= 0, allora il sistema ha nessuna soluzioneoppure hainfinite soluzioni(Rouché -Capelli) => situazione analoga al caso una equazione e una incognita!
35"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#35,35,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itMolte equazioni in molte incogniteObiettivo:comedeterminareleeventualisoluzionidiqequazionilineariinpincognite,peqnumeriinteripositiviPer indicare qincognite si usano i seguenti simboli:Abbiamo jè un numero intero tale che 1≤ j≤ q, dunquela j-esima incognita è indicata con il simbolo xjIndichiamo con il simbolo aijil coefficiente della j-esima incognita appartenente alla i-esima equazione:  aijxj
36"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#36,36,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itMolte equazioni in molte incogniteSistemagenericodipequazioniinqincognite:
Il numero aijcon 1 ≤ i≤ p, 1 ≤ j≤ q e il coefficiente dellaj-esima incognita appartenente alla i-esima equazione.
37"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#37,37,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itMolte equazioni in molte incogniteSistemagenericodipequazioniinqincognite:
Unasoluzione del sistema S: q-upla di numeri reali (x1, x2, …, xq) che, sostituiti nelle equazioni del sistema S alle incognite (x1, x2, …, xq), danno delle identità. 
38"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#38,38,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itMolte equazioni in molte incogniteMatricedeicoefficientidelsistema:Equivaleaunataletabellaconprigheeqcolonne
39"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#39,39,"03/11/20Geometria e Combinatoriasama@ing.uniroma3.itMolte equazioni in molte incogniteConsideriamoalcunisistemiecalcoliamolematriciassociate:
Tale sistema non ha no soluzioniTale sistema ha infinitesoluzioni40"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#4,4,"03/11/205Matrice unitàChiamiamo matrice unitào matrice identicadi ordine nlamatrice quadrata Inavente tutti gli elementi della diagonale principale uguali a 1 e tutti gli altri elementi uguali a 0 (la matrice identica è, quindi, una matrice diagonale).
?
con ncolonnecon nrighe03/11/20Geometria e Combinatoriasama@ing.uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#40,40,"Teorema di Cramer
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it41"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#41,41,"03/11/2042Teorema di CramerUn sistema di nequazioni lineari a coefficienti reali in nincognite:
Se det A≠0, il sistema ammette una e una sola soluzionedata da:
Dimostrazione:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it42"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#42,42,"03/11/2043Teorema di CramerUn sistema di nequazioni lineari a coefficienti reali in nincognite:
Se det A≠0, il sistema ammette una e una sola soluzionedata da:
dove A(i) è la matrice ottenuta da Asostituendo la i-esimacolonna di Acon la colonna Bdei termini noti.
Un sistema lineare di nequazioni in nincognite la cui matricedei coefficienti sia invertibilesi dice Crameriano.SOLUZIONE:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it43"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#43,43,"03/11/2044Teorema di CramerEsercizio (1):
det A= 1
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it44"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#44,44,"03/11/2045Teorema di CramerEsercizio (1):
det A= 1
unica soluzione del sistemaCome controllo possiamo sostituire i valori di (x, y, z) = (2, 0, −1)nelle equazioni del sistema e verificare che sono tutte soddisfatte:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it45"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#45,45,"03/11/2046Teorema di CramerEsercizio (2): Determinare la soluzione del sistema: 
det A= 36
Esercizio:Verificareche la soluz.(x1, x2, x3, x4) trovata èammissibile.03/11/20Geometria e Combinatoriasama@ing.uniroma3.it46"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#5,5,"03/11/206Matrice unità
Dimostrazione:
L'unico elemento ≠ 0 nella moltiplicazione per la i-esima riga è l’elemento della j-esima colonna (per Invale 1, per Avale aij). Dunque, l'elemento di posto (i, j) di AInè aij. Segue AIn= A. 03/11/20Geometria e Combinatoriasama@ing.uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#6,6,"03/11/207Matrice unità
Si dimostra in modo analogo che:
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#7,7,"Matrice Inversa
03/11/20Geometria e Combinatoriasama@ing.uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#8,8,"03/11/209Matrice inversaUna matrice quadrata Asi dice invertibilese esiste una matricequadrata Bdello stesso ordine di Atale che AB= BA= I. Indichiamo con GL(n, R) l'insieme delle matrici invertibilidi ordine n(anche note col nome Gruppo Lineare).Attenzione:•A≠ 0, altrimenti per qualunque Bavremmo AB = 0 e BA = 0. •det A≠ 0, altrimenti non esiste alcuna matrice Bt.c. AB = I, perché avremmo 1 = det I = det(AB) = det A det B= 0 det B= 0. 03/11/20Geometria e Combinatoriasama@ing.uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\3_Matrice_inversa.pdf#9,9,"03/11/2010La matrice inversa è unicaSe Aè una matrice invertibile e Be Csono due matrici taliche AB= BA= Ie AC= CA= I, allora B= C.Dimostrazione:Sappiamo che:  AB = BA = Ie   AC = CA = ICalcoliamo ora il prodotto CAB:CAB = (CA)B = IB = BD'altra parte:CAB = C(AB) = CI = CDunque CABè uguale sia a Bche a C.Segue Be Csono la stessa matrice.03/11/20Geometria e Combinatoriasama@ing.uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#0,0,03/11/20Geometria e Combinatoria sama@ing.uniroma3.it1L4: Rango di una matrice (7-8)Argomenti lezione:•Definizione di rango •Proprietà del rango•Teorema dell’orlare•Teorema di Rouché-Capelli
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#1,1,"Rango di una matrice
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#10,10,"03/11/2011Definizione di rangoSe tutti i minori di Ahanno determinante nullo, allora rk A= 0Una matrice ha rango 0 se e solo se è la matrice nulla.Dimostrazione:Se A= 0 allora tutti i minori di qualsiasi ordine estratti da Asono nulli e hanno quindi determinante nullo. Dunque Aha rango 0.Se rk A= 0, tutti i minori estratti da Ahanno determinante = 0. Poiché il determinante di una matrice di ordine 1 è uguale all’unico elemento della matrice, si ha che tuttigli elementi di Asono nulli.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#11,11,"03/11/2012Proprietà del rangoPer ogni matrice Asi ha:  
Dimostrazione:I minori della trasposta di Asono, ovviamente, tutte e sole le matrici trasposte dei minori di A. Poiché una matrice quadrata e la sua trasposta hanno lo stesso determinante, si ha 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#12,12,"03/11/2013Proprietà del rangoSia Auna matrice. Se tutti i minori estratti da Adi un certo ordine fissato nhanno determinante nullo, allora tutti i minori estratti daAdi ordine più grandedi nhanno determinante nullo. Si ha rk A < nEsempio:
Vediamo i minori di ordine 3:
Tutti i minori di ordine 3 hanno determinante nullo, segue rk A< 303/11/20Geometria e Combinatoria sama@ing.uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#13,13,"03/11/2014Teorema dell’orlareDato un minore Bdi ordine ndi una matrice A, un minore Cdi Adi ordine n + 1 è detto orlatodi Bse Bè un minore di C. In altre parole, il minore Cè ottenuto dal minore Baggiungendo   ad esso un’altra riga e un’altra colonna di A. Esempio:
minore Cminore B
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#14,14,"minore B
03/11/2015Teorema dell’orlareTeorema dell'orlare: Sia Auna matrice e sia Bun suo minore condeterminante ≠ 0. Se tutti gli orlati di Bhanno determinante nullo, allora il rango della matrice Aè uguale all'ordine del minore B.Esempio:Invece di calcolare i minori di tutti i 16 minori di ordine 3, possiamo limitarci a considerare solo gli orlati di Bche sono 4.[ N.B. I 4 orlati si ottengono da: terza riga –seconda colonna,terza riga –quarta colonna, quarta riga –seconda colonna,  quarta riga –quarta colonna.] 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#15,15,"minore B
03/11/2016Teorema dell’orlareTeorema dell'orlare: Sia Auna matrice e sia Bun suo minore condeterminante ≠ 0. Se tutti gli orlati di Bhanno determinante nullo, allora il rango della matrice Aè uguale all'ordine del minore B.Esempio:Invece di calcolare i minori di tutti i 16 minori di ordine 3, possiamo limitarci a considerare solo gli orlati di Bche sono 4.… Facendo i calcoli si trova che hanno tutti determinante nullo:possiamo fermarci e affermare che rk A= 203/11/20Geometria e Combinatoria sama@ing.uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#16,16,"03/11/2017Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:
Consideriamo il minore B1formato dalla prima riga e dalla prima colonna. Ovviamente il suo determinante è diverso da 0.Proseguiamo orlando B1. . .N.B. Bisogna orlare solamente se il minore B1ha det B1≠ 0 !B1
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#17,17,"03/11/2018Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:
Questo minore ha determinante nullo: dobbiamo proseguire.
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#18,18,"03/11/2019Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:Anche il minore così ottenuto ha determinante nullo: dobbiamo proseguire.
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#19,19,"03/11/2020Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:Questo minore (che chiameremo B2) ha determinante nonnullo: il rango di Aè almeno 2.Ora dobbiamo proseguire considerando gli orlati di B2. . .
N.B. Bisogna orlare solamente se il minore B2ha det B2≠ 0 !B2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#2,2,"03/11/203Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
I minori di ordine 1di Asono ovviamente le 12 matrici a una rigae una colonna formate dai 12 elementi di A.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#20,20,"03/11/2021Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:Þotteniamo un minore che ha determinante = 0
B2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#21,21,"03/11/2022Teorema dell’orlareEsercizio di base: Calcoliamo il rango della matrice:
Þotteniamo due minori che hanno determinante = 0Þpoiché B2non ha altri orlati,concludiamo che rk A= 2B2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#22,22,"03/11/2023Teorema dell’orlareEsercizio: Calcoliamo il rango della matrice col teorema dell’orlare:
•Il minore B1formato dalla prima riga e dalla prima colonna è invertibile (detB1 ≠ 0). Quindi rk A≥ 1.•Determinante degli orlati di B1 : orlando B1con la seconda riga      e la seconda colonna otteniamo un minore B2con detB2 ≠ 0 B1
B203/11/20Geometria e Combinatoria sama@ing.uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#23,23,"03/11/2024Teorema dell’orlareEsercizio: Calcoliamo il rango della matrice col teorema dell’orlare:
B2•Consideriamo un orlato di B2. Se orliamo B2con la terza riga e la terza colonna otteniamo un minore con determinante nullo:
•Consideriamo un altro orlato di B2. Se orliamo B2con la terza riga e la quarta colonna otteniamo un minore con determinante nullo:
B2non ha altri orlati.rk A= 203/11/20Geometria e Combinatoria sama@ing.uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#24,24,"Teorema di Rouchè-Capelli
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#25,25,"03/11/2026Sistemi di equazioni lineariDal teorema di Cramer: un sistema di nequazioni in nincogniteha una sola soluzione se la matrice dei coefficienti è invertibileStudiamo ora il caso più generale in cui abbiamo:•Sistema di pequazioni lineari a coefficienti reali in qincognite•La matrice dei coefficienti del sistema non è invertibileSfrutteremo il calcolo del rango di due particolari matrici perindividuare se un sistema ha o non ha soluzioni.Inoltre, studieremo il metodo di Rouché-Capelli per il calcolo delle eventuali soluzioni del sistema (se il sistema è risolubile).03/11/20Geometria e Combinatoria sama@ing.uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#26,26,"03/11/2027DefinizioniSistema di pequazioni lineari a coefficienti reali in qincognite: 
matrice dei coefficienti del sistemamatrice completa del sistema
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#27,27,"03/11/2028DefinizioniSistema di pequazioni lineari a coefficienti reali in qincognite: 
matrice colonna dei termini notimatrice colonna delle incognite
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#28,28,"03/11/2029DefinizioniSistema di pequazioni lineari a coefficienti reali in qincognite: 
Unasoluzione del sistema risolubile Sè una q-upla di numeri reali che sostituiti nelle equazioni del sistema alle incognite danno delle identità. Indichiamo con il simbolo Sol (S) l’insieme delle soluzionidi S.
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#29,29,"03/11/2030DefinizioniSistema di pequazioni lineari a coefficienti reali in qincognite: 
Ogni sistema Spuò essere scritto nella forma matriciale:
Una soluzione del sistema Ssi scrive come la matrice colonna:
Per verifica, se X0è sostituita in Salla matrice colonna X :
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#3,3,"03/11/204Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
Vediamo i minori di ordine 2:
un minore di ordine 203/11/20Geometria e Combinatoria sama@ing.uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#30,30,"03/11/2031DefinizioniUn esempio: 
La matrice Aè invertibile. Si tratta quindi di un sistema Crameriano. 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#31,31,"03/11/2032DefinizioniUn esempio: 
La matrice Aè invertibile. Si tratta quindi di un sistema Crameriano. Esso è pertanto dotato di una sola soluzione. Svolgendo i calcoli: 
Un sistema Crameriano di nequazioni in nincognite ha la matricedei coefficienti Ae la matrice completa A’ambedue di rango n.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#32,32,"Il sistema non ha soluzioni: La prima e terza equazione sono evidentemente incompatibili
03/11/2033DefinizioniUn altro esempio: 
rk A= 2rk A’= 3In questo caso il teorema dell’orlare nonci avrebbe avvantaggiato,perché l’unico orlato è anche l’unico minore di ordine 3 di A’.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#33,33,"03/11/2034Teorema di Rouché-CapelliTeorema di Rouché-Capelli: Sia Sun sistema lineare. Sia Ala matrice dei coefficienti del sistema Se sia  A’la matrice completa del sistema.   Il sistema Sè risolubile se e solo se rk A’= rk A
rk A= 2rk A’= 3
rk A= 2rk A’= 2Esempi:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#34,34,"03/11/2035Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti diS e sia A’la matrice completa del sistema. Mostrare che rk A’≥ rk A.Dimostrazione:Sia ril rango di A: allora Apossiede almeno un minore di ordine rcon determinante non nullo. Sia Bun tal minore. Bè un minore anche di A’che ha, pertanto, rango almeno r.Inoltre, nel caso in cui il sistema è non risolubile si può dimostrareche rk A’= rk A + 1. [Se il sistema è risolubile già sappiamo che rk A’= rk A.] 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#35,35,"03/11/2036Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (1):
rk A= 22–2–3411= 06–1–223–2461= 069–1B2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#36,36,"03/11/2037Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (1):
rk A= 2
determinante = 0, ultima colonna * 2 = prima colonna
determinante = 0, già noto (vedi A)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it37"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#37,37,"03/11/2038Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (1):
rk A= 2
determinante = 0sistema risolubile !
rk A’=2determinante = 0, già noto (vedi A)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it38"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#38,38,"03/11/2039Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (2):
rk A= 2
11–121–3= 032–411–121–3= 053–7Non serve calcolare gli orlati di B2con la quarta colonna, perché è identica alla prima.B2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it39"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#39,39,"03/11/2040Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (2):
rk A= 2determinante = 0
determinante ≠003/11/20Geometria e Combinatoria sama@ing.uniroma3.it40"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#4,4,"03/11/205Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
Vediamo i minori di ordine 2:un altro minore di ordine 2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#40,40,"03/11/2041Teorema di Rouché-CapelliSia Sun sistema lineare. Sia Ala matrice dei coefficienti di Se sia A’la matrice completa del sistema. Allora si ha: rk A’≥ rk A.Esempio (2):
rk A= 2determinante = 0sistema non risolubile !
determinante ≠0rk A’≥303/11/20Geometria e Combinatoria sama@ing.uniroma3.it41"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#41,41,"03/11/2042Procedimento di Rouché-CapelliTeorema: Sia Sun sistema lineare risolubile, e siano Ae A’la matrice dei coefficienti di Se la matrice completa di S. Sia nil rango di A(e anche il rango di A’, dato che Sè risolubile) e sia Bun minore invertibile di Adi ordine n. Allora il sistema Sè equivalente al sistema ridottoSRche siottiene considerando solo le nequazioni di Scorrispondenti alle righe di B. Dunque: Sol(S) = Sol(SR)Il teorema ci dice che, scelte in modo opportuno nequazioni di S, le altre sono “conseguenza” di queste n.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it42"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#42,42,"03/11/2043Procedimento di Rouché-CapelliCome risolvere un sistema lineare Sdi pequazioni in qincognite.Sia Ala matrice del sistema Se sia A’la matrice completa di S.Esempio:  
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it43"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#43,43,"03/11/2044Procedimento di Rouché-Capelli1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo un minore Bdi Adi ordine ncon determinante ≠ 0;Esempio:
Facendo i calcoli si trova che Aha rango 2 e che un minoredi ordine 2 con determinante non nullo è, e.g., il minore B: 
detB ≠ 0
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it44"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#44,44,"03/11/2045Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe:Esempio:
determinante = 0
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it45"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#45,45,"03/11/2046Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe:2.1Se tutti gli orlati così determinati hanno determinante nullo, allora rk A = rk A’e per il teorema di Rouché-Capelli il sistema è risolubile: passiamo al punto successivo;Esempio:
determinante = 003/11/20Geometria e Combinatoria sama@ing.uniroma3.it46"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#46,46,"03/11/2047Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe:2.1Se tutti gli orlati così determinati hanno determinante nullo, allora rk A = rk A’e per il teorema di Rouché-Capelli il sistema è risolubile: passiamo al punto successivo;2.2 Invece, se anche uno solo di tali orlati ha determinante ≠ 0,      il rango di A’è diverso dal rango di A(è anzi esattamente uguale a 1 + rk A): il sistema non è risolubile e ci fermiamo.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it47"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#47,47,"03/11/2048Procedimento di Rouché-Capelli3. Consideriamo il sistema ridotto SRformato dalle nequazioni  i cui coefficienti concorrono a formare il minore B. Il sistema ridotto SRè equivalente al sistema S;Esempio:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it48"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#48,48,"03/11/2049Procedimento di Rouché-Capelli4. Portiamo a secondo membro (nel sistema SR) le q–nincognite i cui coefficienti nonconcorrono a formare il minore B;Esempio:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it49"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#49,49,"03/11/2050Procedimento di Rouché-Capelli5. Poniamo le incognite portate a secondo membro uguali a dei parametri h1, h2, . . . , hq–n(se q= na secondo membro non c’è alcuna incognita e quindi non occorre assegnare alcun parametro);Esempio:
al variare dei parametrih (h1)e k(h2)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it50"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#5,5,"03/11/206Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
Vediamo i minori di ordine 2:6 minori scegliendo le prime due righe di Ain tutti i modi possibili:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#50,50,"03/11/2051Procedimento di Rouché-Capelli6. Risolviamo il sistema parametrico Crameriano (di matrice B)nelle incognite rimaste a primo membro: otteniamo queste incognite in funzione dei parametri h1, h2, . . . , hq–n.Esempio:
al variare dei parametrih (h1)e k(h2)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it51"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#51,51,"03/11/2052Procedimento di Rouché-Capelli
Verifica correttezza soluzione:
Possiamo verificare che le soluzioni così trovate sono corrette sostituendo le espressioni trovate nelle equazioni del sistema S.Sostituendo, ad esempio, nella prima equazione di Stroviamo:
OKAttenzione: Stiamo verificando solamente che le soluzioni  trovate siano effettivamente soluzioni, ma non stiamo verificando che siano tuttele soluzioni del sistema S.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it52"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#52,52,"03/11/2053Procedimento di Rouché-CapelliOsservazioni: •Il procedimento dipende da quale minore Bscegliamo.Cambiando minore Botterremo le stesse soluzionima parametrizzate in forma diversa.Esempio:
C
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it53"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#53,53,"03/11/2054Procedimento di Rouché-CapelliOsservazioni: •Il procedimento dipende da quale minore Bscegliamo. Cambiando minore Botterremo le stesse soluzionima parametrizzate in forma diversa.Esempio:
C
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it54"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#54,54,"03/11/2055Procedimento di Rouché-CapelliOsservazioni: •Sia Sun sistema risolubile di pequazioni in qincognite. Sia nil rango della matrice del sistema. Allora le soluzioni di Sdipendono da q–nparametri.•Cosa significa che “p” = n?Se p = n, quando consideriamo il sistema ridotto SRdobbiamo prendere nequazioni, quindi tutte le equazioni di S. Pertanto tutte le equazioni di Ssono necessarie.
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it55"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#55,55,03/11/2056Procedimento di Rouché-CapelliOsservazioni: •Sia Sun sistema risolubile di pequazioni in qincognite. Sia nil rango della matrice del sistema. Allora le soluzioni di Sdipendono da q–nparametri. •Cosa significa che “q” = n?Se q = nquando consideriamo il sistema ridotto SRabbiamo un sistema di nequazioni in nincognite e la matrice del sistema ridotto contiene un minore di ordine ninvertibile.  Il sistema ridotto è pertanto Crameriano.Segue che il sistema Sha un’unica soluzione.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it56
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#56,56,"03/11/2057Procedimento di Rouché-CapelliCome risolvere un sistema lineare Sdi pequazioni in qincognite.Sia Ala matrice del sistema Se sia A’la matrice completa di S. Esercizio (1):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it57"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#57,57,"03/11/2058Procedimento di Rouché-CapelliEsercizio (1):1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo un minore Bdi Adi ordine ncon determinante ≠ 0;
rk A = 2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it58"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#58,58,"03/11/2059Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe;Esercizio (1):
rk A = rk A’ = 2Il sistema ammette quindi soluzioni.Poichè il rango della matrice del sistema A’è uguale al numero delle incognite (ovvero xe y), allora possiamo affermare che il sistema ha un’unica soluzione.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it59"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#59,59,"03/11/2060Procedimento di Rouché-Capelli3. Consideriamo il sistema ridotto SRformato dalle nequazioni  i cui coefficienti concorrono a formare il minore B. Il sistema ridotto SRè equivalente al sistema S;Esercizio (1):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it60"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#6,6,"03/11/207Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
Vediamo i minori di ordine 2:In totale abbiamo 18 minori di ordine 2:•6 minori scegliendo le prime due righe di Ain tutti i modi possibili.•6 minori scegliendo la prima riga e l’ultima riga di Ain tutti i modi possibili.•6 minori scegliendo le ultime due righe di Ain tutti i modi possibili.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#60,60,"03/11/2061Procedimento di Rouché-Capelli4. Portiamo a secondo membro (nel sistema SR) le q–nincognite i cui coefficienti nonconcorrono a formare il minore B;Esercizio (1):
Questo è un sistema Crameriano: non dobbiamo portare a secondo membro alcuna incognita.
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it61"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#61,61,"03/11/2062Procedimento di Rouché-Capelli5. Poniamo le incognite portate a secondo membro uguali a dei parametri h1, h2, . . . , hq–n(se q= na secondo membro non c’è alcuna incognita e quindi non occorre assegnare alcun parametro);Esercizio (1):
Questo è un sistema Crameriano: non dobbiamo portare a secondo membro alcuna incognita.Abbiamo q= n, quindi assegniamo alcun parametro.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it62"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#62,62,"03/11/2063Procedimento di Rouché-Capelli6. Risolviamo il sistema parametrico Crameriano (di matrice B)nelle incognite rimaste a primo membro: otteniamo queste incognite in funzione dei parametri h1, h2, . . . , hq–n.Esercizio (1):
Possiamo risolvere il sistema tramite il teorema di Cramer e trovare l'unica soluzione di S:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it63"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#63,63,"03/11/2064Procedimento di Rouché-CapelliCome risolvere un sistema lineare Sdi pequazioni in qincognite.Sia Ala matrice del sistema Se sia A’la matrice completa di S. Esercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it64"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#64,64,"03/11/2065Procedimento di Rouché-CapelliEsercizio (2):1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo un minore Bdi Adi ordine ncon determinante ≠ 0;
rk A ≥ 2Il minore B2di Aè invertibile
rk A ≥ 3Il minore B3di Aè invertibile
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it65"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#65,65,"03/11/2066Procedimento di Rouché-CapelliEsercizio (2):1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo un minore Bdi Adi ordine ncon determinante ≠ 0;
rk A ≥ 2Il minore B2di Aè invertibile
rk A ≥ 3Il minore B3di Aè invertibileDobbiamo orlare B3. L'unico orlato di B3è la matrice A stessa.Svolgendo i calcoli si verifica che il det A = 0, in quanto la terzacolonna coincide con la quarta colonna. Quindi rk A= 3.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it66"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#66,66,"03/11/2067Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe;Esercizio (2):
Si ottiene un unico possibile minore:Facendo i calcoli si trova che il minore così ottenuto ha determinante nullo. Dunque rk A’= 3 = rk A, e il sistema ha soluzioni.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it67"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#67,67,"03/11/2068Procedimento di Rouché-Capelli3. Consideriamo il sistema ridotto SRformato dalle nequazioni  i cui coefficienti concorrono a formare il minore B. Il sistema ridotto SRè equivalente al sistema S;Esercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it68"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#68,68,"03/11/2069Procedimento di Rouché-Capelli4. Portiamo a secondo membro (nel sistema SR) le q–nincognite i cui coefficienti nonconcorrono a formare il minore B;Esercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it69"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#69,69,"03/11/2070Procedimento di Rouché-Capelli5. Poniamo le incognite portate a secondo membro uguali a dei parametri h1, h2, . . . , hq–n(se q= na secondo membro non c’è alcuna incognita e quindi non occorre assegnare alcun parametro);Esercizio (2):
Soluzioni del  sistema S al variare del parametro h
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it70"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#7,7,"03/11/208Definizione di rangoSia Auna matrice di tipo (p, q). Sia nun numero intero positivotale che n≤ ped n≤ q. Unminoredi ordine ndi Aè una matrice che si ottiene scegliendo nrighe ed ncolonne di Ae prendendo gli elementi di Ache si trovano sia sulle righe che sulle colonne scelte. Esempio:
Vediamo i minori di ordine 3:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#70,70,"03/11/2071Procedimento di Rouché-Capelli6. Risolviamo il sistema parametrico Crameriano (di matrice B)nelle incognite rimaste a primo membro: otteniamo queste incognite in funzione dei parametri h1, h2, . . . , hq–n.Esercizio (2):
Soluzioni del  sistema S al variare di h
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it71"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#71,71,"03/11/2072Procedimento di Rouché-CapelliCome risolvere un sistema lineare Sdi pequazioni in qincognite.Sia Ala matrice del sistema Se sia A’la matrice completa di S. Esercizio (3):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it72"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#72,72,"03/11/2073Procedimento di Rouché-CapelliEsercizio (3):1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo un minore Bdi Adi ordine ncon determinante ≠ 0;
rk A ≥ 2Il minore B2di Aè invertibileDobbiamo considerare gli orlati di B2fino a che eventualmente ne troviamo uno con determinante ≠ 0. Facendo i calcoli (sono 6 orlati) si trova che hanno tutti determinante = 0, dunque Aha rango 2.[ In realtà, serve calcolare solo 4 orlati di B2(quarta/quinta colonna combinata a terza/quarta riga), perché le prime due colonne di Asono identiche. ]  03/11/20Geometria e Combinatoria sama@ing.uniroma3.it73"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#73,73,"03/11/2074Procedimento di Rouché-Capelli2. Calcoliamo il rango della matrice A’, ovvero calcoliamoi determinanti degli orlati di Bcon l'ultima colonna di A’(cioè con la colonna dei termini noti) e con tutte le possibili righe;Esercizio (3):
Abbiamo 2 orlati di B2(terza e quarta riga) con l’ultima colonna di A’.Entrambi gli orlati hanno determinante nullo.Pertanto A’ha rango 2 e il sistema è risolubile.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it74"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#74,74,"03/11/2075Procedimento di Rouché-Capelli3. Consideriamo il sistema ridotto SRformato dalle nequazioni  i cui coefficienti concorrono a formare il minore B. Il sistema ridotto SRè equivalente al sistema S;Esercizio (3):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it75"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#75,75,"03/11/2076Procedimento di Rouché-Capelli4. Portiamo a secondo membro (nel sistema SR) le q–nincognite i cui coefficienti nonconcorrono a formare il minore B;Esercizio (3):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it76"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#76,76,"03/11/2077Procedimento di Rouché-Capelli5. Poniamo le incognite portate a secondo membro uguali a dei parametri h1, h2, . . . , hq–n(se q= na secondo membro non c’è alcuna incognita e quindi non occorre assegnare alcun parametro);Esercizio (3):
Soluzioni del  sistema S al variare di h1 , h2 , h3
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it77"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#77,77,"03/11/2078Procedimento di Rouché-Capelli6. Risolviamo il sistema parametrico Crameriano (di matrice B)nelle incognite rimaste a primo membro: otteniamo queste incognite in funzione dei parametri h1, h2, . . . , hq–n.Esercizio (3):
Soluzioni del  sistema S al variare di h1 , h2 , h3Risolvendo questo sistema: 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it78"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#78,78,"03/11/2079Sunto: Procedimento Rouché-Capelli
6. Risolviamo il sistema parametrico Crameriano (di matrice B) nelle incogniterimaste a primo membro: otteniamo queste incognite in funzione dei parametri h1, h2, . . . , hq–n.Sia A(A’) la matrice (completa) del sistema Sdi pequazioni e qincognite. 1. Calcoliamo il rango della matrice A(sia nquesto rango) e scegliamo unminore Bdi Adi ordine ncon determinante ≠ 0;2. Calcoliamo il rango della matrice A’, ovvero calcoliamo i determinanti degli orlati di Bcon l'ultima colonna di A’e con tutte le possibili righe;3. Serk A = rk A’: Prendiamo il sistema ridotto SRformato dalle nequazionii cui coefficienti concorrono a formare il minore B. SRè equivalente a S;4. Portiamo a secondo membro (nel sistema SR) le q–nincognite i cuicoefficienti nonconcorrono a formare il minore B;5. Poniamo le incognite portate a secondo membro uguali a dei parametri h1, h2,. . . , hq–n(se q= na secondo membro non c’è  alcuna incognita e quindi non occorre assegnare alcun parametro);03/11/20Geometria e Combinatoria sama@ing.uniroma3.it79"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#8,8,"03/11/209Definizione di rangoI minori di una matrice sono sempre delle matrici quadrate, di cui possiamo quindi calcolare il determinante.Una matrice Aha rango(o caratteristica) rk Auguale ad nse:1. Esiste almeno un minore di Adi ordine ncon determinante ≠ 02. Tutti i minori di Adi ordine maggioredi nhanno determinante = 0Esempio:
Tale minore è invertibile, ovvero ha determinante ≠ 0.Il rango della matrice Aè maggiore o uguale a 2.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\4_Rango_di_una_matrice.pdf#9,9,"03/11/2010Definizione di rangoI minori di una matrice sono sempre delle matrici quadrate, di cui possiamo quindi calcolare il determinante.Una matrice Aha rango(o caratteristica) rk Auguale ad nse:1. Esiste almeno un minore di Adi ordine ncon determinante ≠ 02. Tutti i minori di Adi ordine maggioredi nhanno determinante = 0Esempio:
Tutti i quattro minori di Adi ordine 3 non sono invertibiliIl rango della matrice Aè quindi uguale a 2 :  rk A= 203/11/20Geometria e Combinatoria sama@ing.uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#0,0,03/11/20Geometria e Combinatoria sama@ing.uniroma3.it1L5: Metodo di Gauss (9-10)Argomenti lezione:•Introduzione•Metodo di Gauss•Calcolo del determinante con Gauss•Calcolo del rango con Gauss•Matrice Inversa con Gauss –Jordan  
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#1,1,"03/11/202Gauss: IntroduzioneProblema affrontato: Determinazione di eventuali soluzioni di sistemi di pequazioni in qincogniteApproccio visto finora: Metodo di Rouché-CapelliIdea di Rouché-Capelli: Determinare le soluzioni di un sistema parametrizzato basato su nequazioni ed nincognite in cui la matrice dei coefficienti è invertibile. Si utilizza il metodo di Cramer basato sul calcolo del determinante di matrici di ordine n. 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#10,10,"03/11/2011Gauss: MetodoAttenzione: ogni matrice quadrata a scalini è una matrice triangolare
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#11,11,"03/11/2012Gauss: MetodoAttenzione: ogni matrice quadrata a scalini è una matrice triangolare, però:nontutte le matrici triangolari sono matrici a scalini di altezza 1 !Contro-esempio:   
Nonè una matrice a scalini come le precedenti: perché ha uno scalino di altezza 2!03/11/20Geometria e Combinatoria sama@ing.uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#12,12,"03/11/2013Gauss: MetodoEsempio (4): 
–1 ( x+ 2y= 4 ) 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#13,13,"03/11/2014Gauss: MetodoEsempio (4): 
Il sistema Sha una sola soluzione:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#14,14,"03/11/2015Gauss: MetodoEsempio (5): 
–2 ( x+ 2y= 1 )
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#15,15,"03/11/2016Gauss: MetodoEsempio (5): 
Questo sistema non ha soluzioni 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#16,16,"03/11/2017Gauss: MetodoIl metodo di Gauss fa uso delle seguenti tipologie di operazioniper trovare un sistema equivalente la cui matrice sia a scalini :•Se in un sistema Ssommiamo a una equazione un’altra equazione del sistema moltiplicata per una costante,            otteniamo un sistema S’equivalente al sistema S.•Se in un sistema Smoltiplichiamo un’equazione per unacostante non nulla, otteniamo un sistema S’equivalente ad S.•Se in un sistema S scambiamo tra loro due equazioni,    otteniamo un sistema S’equivalente ad S. 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#17,17,"03/11/2018Gauss: MetodoEsercizio (1): 
–( x+ y+ z= 1 )
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#18,18,"03/11/2019Gauss: MetodoEsercizio (1):
–( x+ y+ z= 1 )
–( x+ y+ z= 1 )
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#19,19,"03/11/2020Gauss: MetodoEsercizio (1):
–( x+ y+ z= 1 )
Il sistema Sha    una sola soluzione:–( x+ y+ z= 1 )
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#2,2,03/11/203Gauss: IntroduzioneLimiti del metodo visto finora: Il numero di operazioni necessarie per calcolare il determinante di una matrice di ordine naumenta molto velocemente al crescere di n. Applicazioni pratiche: Risolvere sistemi con alcune decine di equazioni e incognite. Metodo di Rouché-Capelli è poco efficiente.Metodo alternativo per un sistema di pequazioni in qincognite:Metodo di Gauss: rimpiazzareil sistema di cui si cercano le eventuali soluzioni con un sistema avente le stesse soluzioni         per il quale sia abbastanza agevole la loro determinazione.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it3
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#20,20,"03/11/2021Gauss: MetodoEsercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#21,21,"03/11/2022Gauss: MetodoEsercizio (2):
–1–2
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#22,22,"03/11/2023Gauss: MetodoEsercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#23,23,"03/11/2024Gauss: MetodoEsercizio (2) -NOTE:
Ho due colonne uguali, già so che non ho una sola soluzioneInoltre se moltiplico per -2 la prima colonna e la sommo alla seconda, ottengo la terza 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#24,24,"03/11/2025Operazioni elementariDue matrici Ae A’si dicono equivalenti per rigase è possibilepassare da una all’altra per mezzo di operazioni del tipo:•Sommare alla riga i-esima della matrice la riga j-esima moltiplicata per un numero reale k, con i≠j.•Scambiare tra loro due righe della matrice.Questi tipi di operazioni si dicono operazioni elementari di riga.Esempio:
–2 (prima riga)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#25,25,"03/11/2026Operazioni elementariDue matrici Ae A’si dicono equivalenti per rigase è possibilepassare da una all’altra per mezzo di operazioni del tipo:•Sommare alla riga i-esima della matrice la riga j-esima moltiplicata per un numero reale k, con i≠j.•Scambiare tra loro due righe della matrice.Questi tipi di operazioni si dicono operazioni elementari di riga.Esempio:
scambio di righe
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#26,26,03/11/2027Operazioni elementariDue matrici Ae A’equivalenti per riga soddisfano le proprietà:Proprietà riflessiva Ogni matrice Aè equivalente per riga a se stessa.(Infatti per passare daA ad A non è necessaria nessuna operazione.)Proprietà simmetrica Se una matrice Aè equivalente per riga a unamatrice A’allora A’è equivalente ad A.(Basta infatti ripercorre a ritroso ciascuna operazione elementare.)Proprietà transitiva Se una matrice Aè equivalente per riga a unamatrice A’e se A’è equivalente per riga a una matrice A’’ allora Aè equivalente a A’’.(Se passiamo da Aad A’e poi da A’ad A’’ siamo passati da Aad A’’.)03/11/20Geometria e Combinatoria sama@ing.uniroma3.it27
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#27,27,03/11/2028Calcolo del determinanteAbbiamo dimostrato in precedenza la seguente proprietà: Siano Ae Bdue matrici quadrate di ordine nche si ottengonouna dall’altra scambiandofra loro due righe. Allora detA= − detB.Si può inoltre dimostrare che:Sia Auna matrice quadrata e sia A’la matrice ottenuta da Asommando alla riga i-esima la riga j-esima moltiplicata per k.Allora detA’ = detA.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it28
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#28,28,"03/11/2029Calcolo del determinanteSegue la seguente proprietà:Se Ae A’sono matrici quadrate equivalenti per riga, analizziamole operazioni elementari necessarie per passare da Aad A’ . Tra le operazioni elementari ci saranno:•un certo numero di operazioni di sommaa una riga di un’altra riga moltiplicata per un fattore (il determinante non cambia);•un certo numero mdi operazioni di scambiodi righe. Per lo scambio di righe (m> 0), si ha:Se nonsi ha scambio di righe (m= 0), allora det A’ = det A . 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#29,29,"03/11/2030Calcolo del determinantePer calcolare il determinante di una matrice quadrata A, operiamo nel seguente modo:1. Determiniamo, con il metodo di Gauss, una matrice a scalini A’equivalente per righe ad A, e contiamo il numero di scambi di riga che abbiamo operato per far ciò. Sia mquesto numero.Esempio:
m = 1–1
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#3,3,"03/11/204Gauss: Esempio 1
Determiniamo x4dalla quarta equazione:     x4= 0Determiniamo x3dalla terza equazione:       x3= 1 / 4 Determiniamo x2dalla seconda equazione:  x2= 1 / 6 Determiniamo x1dalla prima equazione:      x1= –1 / 12 
Unica soluzione di S: 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#30,30,"03/11/2031Calcolo del determinantePer calcolare il determinante di una matrice quadrata A, operiamo nel seguente modo:2. Calcoliamo il determinante di A’semplicemente moltiplicando gli elementi della sua diagonale principale (dato che una matrice quadrata a scalini è triangolare superiore). Notare che detA’= 0se e solo se almeno uno di questi elementi si annulla.Esempio:
detA’= 503/11/20Geometria e Combinatoria sama@ing.uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#31,31,"03/11/2032Calcolo del determinantePer calcolare il determinante di una matrice quadrata A, operiamo nel seguente modo:3. Si ha quindi:Esempio:
m = 1detA’= 5
–1
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#32,32,"03/11/2033Calcolo del determinanteEsercizio (1):
m = 2m = 1
–(seconda riga)
det A = det A’ = 0
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#33,33,"03/11/2034Calcolo del rangoTeorema: Se Ae A’sono matrici equivalenti per riga, allora esse hanno ranghi uguali. In formule si ha:  rkA’  =  rkA .  (Notare che le matrici Ae A’possono anche essere non quadrate)Ci conviene trasformare A in A’ tramite operazioni elementari,        e poi calcolare il rango di A’  (ovvero di una matrice a scalini) ?Teorema: Il rango di una matrice a scaliniè uguale al numero degli scalini (cioè il numero di righe non nulle) della matrice.03/11/20Geometria e Combinatoria sama@ing.uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#34,34,"03/11/2035Calcolo del rangoTeorema: Il rango di una matrice a scaliniè uguale al numero degli scalini (cioè il numero di righe non nulle) della matrice.Esempio:
La matrice Aha 3 scalini
Prendiamo il minore di Aformato dalle righe non nulle di Ae dalle tre colonne contenenti gli scalini03/11/20Geometria e Combinatoria sama@ing.uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#35,35,"03/11/2036Calcolo del rangoTeorema: Il rango di una matrice a scaliniè uguale al numero degli scalini (cioè il numero di righe non nulle) della matrice.Esempio:
La matrice Aha 3 scalini
Matrice triangolare superiore, con det ≠ 0. Da cui: rk A≥ 3Ogni minore di Adi ordine 4 deve avere una riga tutta di 0          e ha pertanto determinante nullo. Segue che rk A= 3. 03/11/20Geometria e Combinatoria sama@ing.uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#36,36,"03/11/2037Calcolo del rangoData una matrice A, ne calcoliamo il rango nel seguente modo:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it37"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#37,37,"03/11/2038Calcolo del rangoData una matrice A, ne calcoliamo il rango nel seguente modo:1. Determiniamo, con il metodo di Gauss, una matrice a scalini A’equivalente per righe ad A.Esempio:
–2 1
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it38"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#38,38,"03/11/2039Calcolo del rangoData una matrice A, ne calcoliamo il rango nel seguente modo:1. Determiniamo, con il metodo di Gauss, una matrice a scalini A’equivalente per righe ad A.Esempio:
2–1
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it39"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#39,39,"03/11/2040Calcolo del rangoData una matrice A, ne calcoliamo il rango nel seguente modo:1. Determiniamo, con il metodo di Gauss, una matrice a scalini A’equivalente per righe ad A.Esempio:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it40"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#4,4,"03/11/205Gauss: Esempio 2
Ricaviamo dalla terza equazione:            x3= 2 –x4Sostituiamo x3nella seconda equazione:     x2= –1Sostituiamo x2e x3nella prima equazione:   x1= 1 Assegniamo a x4il valore di un parametro hSoluzioni del sistema S: 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#40,40,"03/11/2041Calcolo del rangoData una matrice A, ne calcoliamo il rango nel seguente modo:2. Contiamo il numero di scalini di A’. Siano n . Si ha allora:rkA = rkA’ = nEsempio:
rk A = rk A’’’  = 303/11/20Geometria e Combinatoria sama@ing.uniroma3.it41"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#41,41,"03/11/20Geometria e Combinatoria sama@ing.uniroma3.it42
Calcolo del rangoEsercizio:
-2-2-3
-2-1rk = 4det = 36"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#42,42,"03/11/2043Risolvere il sistemaEsercizio (2):
scambio di righe
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it43"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#43,43,"03/11/2044Risolvere il sistemaEsercizio (2):
1 (prima equ.)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it44"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#44,44,"03/11/2045Risolvere il sistemaEsercizio (2):
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it45"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#45,45,"03/11/2046Risolvere il sistemaEsercizio (2):
–1 (terza equ.)
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it46"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#46,46,"03/11/2047Risolvere il sistemaEsercizio (2):
Le soluzioni del   sistema sono:
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it47"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#47,47,"03/11/2048Rango e determinanteEsercizio (3):
–3/2 2–4
–8
A’’’ha 4 scalinirkA = rkA’’’  = 42. Contiamo il numero di scalini di A’. Siano n. Si ha allora: rkA = rkA’ = n–2 / 25detA = -4803/11/20Geometria e Combinatoria sama@ing.uniroma3.it48"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#48,48,"Anche l’inversa di una matrice può essere calcolata sfruttando il metodo di eliminazione di Gauss.𝐴𝐼⇒[𝐼|𝐴!""]1.Si scrive una matrice a blocchi 𝑛×2𝑛𝐴𝐼;2.Si opera Gauss fino ad ottenere nel primo blocco I;3.La matrice nel secondo blocco è 𝐴!"".03/11/20Geometria e Combinatoria sama@ing.uniroma3.it49Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#49,49,"[𝐴|𝐼]=𝑎""""𝑎""#𝑎#""𝑎##…𝑎""$…𝑎#$⋮⋮𝑎$""𝑎$#⋱⋮…𝑎$$1001…0…0⋮⋮00⋱⋮…1𝑎′""""𝑎′""#0𝑎′##…𝑎′""$…𝑎′#$⋮⋮00⋱⋮…𝑎′$$𝛾′""""𝛾′""#𝛾′#""𝛾′##…𝛾′""$…𝛾′#$⋮⋮𝛾′$""𝛾′$#⋱⋮…𝛾′$$03/11/20Geometria e Combinatoria sama@ing.uniroma3.it50Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#5,5,"03/11/206Gauss: Esempio 3
Dalla seconda equazione ricaviamo:      x2= 2 –x3Sostituendo x2nella prima equazione:  x1= –1 + 2x3–x4Assegniamo a x3il valore di un parametro h1e assegniamo a x4il valore di un parametro h2Soluzioni del sistema S: 
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#50,50,"[𝐴|𝐼]=𝑎""""𝑎""#𝑎#""𝑎##…𝑎""$…𝑎#$⋮⋮𝑎$""𝑎$#⋱⋮…𝑎$$1001…0…0⋮⋮00⋱⋮…1𝑎′""""𝑎′""#0𝑎′##…𝑎′""$…𝑎′#$⋮⋮00⋱⋮…𝑎′$$𝛾′""""𝛾′""#𝛾′#""𝛾′##…𝛾′""$…𝛾′#$⋮⋮𝛾′$""𝛾′$#⋱⋮…𝛾′$$03/11/20Geometria e Combinatoria sama@ing.uniroma3.it51Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#51,51,"𝑎′""""𝑎′""#0𝑎′##…0…0⋮⋮00⋱⋮…𝑎′$$𝛾′′""""𝛾′′""#𝛾′′#""𝛾′′##…𝛾′′""$…𝛾′′#$⋮⋮𝛾′$""𝛾′$#⋱⋮…𝛾′$$𝛾′′%&=𝛾′%&−'(!"")(#!)(!!03/11/20Geometria e Combinatoria sama@ing.uniroma3.it52Matrice Inversa
−𝑎!""#𝑎!##"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#52,52,"𝑎′""""𝑎′""#0𝑎′##…0…0⋮⋮00⋱⋮…𝑎′$$𝛾""""((…(𝛾""#((…(𝛾#""((…(𝛾##((…(…𝛾""$((…(…𝛾#$((…(⋮⋮𝛾′$""𝛾′$#⋱⋮…𝛾′$$
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it53Matrice Inversa−𝑎!$%𝑎!%%"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#53,53,"𝑎′""""00𝑎′##…0…0⋮⋮00⋱⋮…𝑎′$$𝛾""""((…(𝛾""#((…(𝛾#""((…(𝛾##((…(…𝛾""$((…(…𝛾#$((…(⋮⋮𝛾′$""𝛾′$#⋱⋮…𝛾′$$
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it54Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#54,54,"𝑎′""""00𝑎′##…0…0⋮⋮00⋱⋮…1𝛾""""((…(𝛾""#((…(𝛾#""((…(𝛾##((…(…𝛾""$((…(…𝛾#$((…(⋮⋮'$!%)!!%'#!%)!!%⋱⋮…'!!%)!!%
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it55Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#55,55,"1001…0…0⋮⋮00⋱⋮…1'$$%…%)$$%'$#%…%)$$%'#$%…%)##%'##%…%)##%…'$!%…%)$$%…'#!%…%)##%⋮⋮'$!%)!!%'#!%)!!%⋱⋮…'!!%)!!%
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it56Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#56,56,"𝐴!""='$$%…%)$$%'$#%…%)$$%'#$%…%)##%'##%…%)##%…'$!%…%)$$%…'#!%…%)##%⋮⋮'$!%)!!%'#!%)!!%⋱⋮…'!!%)!!%
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it57Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#57,57,"Esempio:𝐴=4000002001112001
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it58Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#58,58,"Esempio:𝐴=1001000000001001""+00−100100""#!""+100−11Divido la seconda riga per 203/11/20Geometria e Combinatoria sama@ing.uniroma3.it59Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#59,59,"Esempio:𝐴!""=""+00−100100""#!""+100−11
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it60Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#6,6,"03/11/207Gauss: Esempi 1, 2, 3
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#60,60,"Esercizio:𝐴=4221−110−1−2210110−11001000000001001
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it61Matrice Inversa
+2-2-4"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#61,61,"Esercizio:𝐴=10010−10102021−1−150001010−20010120−4
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it62Matrice Inversa
+2-2-4"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#62,62,"Esercizio:𝐴=10010−10102021−1−150001010−20010120−4
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it63Matrice Inversa-2"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#63,63,"Esercizio:𝐴=10010−10100001−3−130001010−20−21−21600
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it64Matrice Inversa-2"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#64,64,"Esercizio:𝐴=10010−10100001−3−130001010−20−21−21600
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it65Matrice Inversa"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#65,65,Esercizio:𝐴=10010−10100001−3000001010−20−21−41616detA = 0 A non è invertibile03/11/20Geometria e Combinatoria sama@ing.uniroma3.it66Matrice Inversa
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#7,7,"03/11/208Gauss: Esempi 1, 2, 3
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it8"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#8,8,"03/11/209Gauss: Esempi 1, 2, 3
Sono tutte matrici a scalini :quattro scalini di altezza 1(nessun parametro)tre scalini di altezza 1(1 parametro: x4 = h1)due scalini di altezza 1(2 parametri: x3 = h1 ; x4 = h2)x1x2x3x4
03/11/20Geometria e Combinatoria sama@ing.uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\5_Gauss.pdf#9,9,"03/11/2010Gauss: MetodoIl metodo di Gauss per la determinazione delle eventualisoluzioni di un sistema Sconsiste nel trasformare il sistema Sin un sistema S’ad esso equivalente avente la matrice dei coefficienti a scalini. Ecco alcune matrici a scalini ( ●è un num. ≠ 0; * num. qualsiasi):
Sistemaparametrico( x4= h1 )x4Sistemacon unicaSoluzione(se esiste)Sistemaparametrico( x2= h1 )x2Sistemaparametrico(x1= h1  ;x4= h2 )x1x403/11/20Geometria e Combinatoria sama@ing.uniroma3.it10"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#0,0,Geometria e Combinatoria  marcella.sama@uniroma3.itL6: I vettori geometrici (11)Argomenti lezione:•Introduzione •Vettori del piano  •Addizione di vettori •Moltiplicare un vettore per uno scalare •Vettori dello spazio •Rette e piani per l’origine •Punto medio
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#1,1,23/11/202IntroduzioneIntroduciamo il concetto di vettore di un piano. Definiamo le operazionidi addizione di due vettori e di moltiplicazione di un vettore per un numero reale.Notiamo che hanno le stesse proprietàdelle operazioni di addizione tra matrici e di moltiplicazione di una matrice per un numero reale. Estendiamo poi allo spaziole definizioni di vettore e delle loro operazioni e verifichiamo che queste ultime hanno proprietà simili alle proprietà dei vettori del piano. Geometria e Combinatoria  marcella.sama@uniroma3.it
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#10,10,"23/11/2011Addizione di vettoriProprietà del parallelogramma:1. In un parallelogramma i lati opposti hanno la stessa lunghezza2. Le diagonali di un parallelogramma si intersecano in un punto   Mche è detto il punto medio dei vertici opposti.
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#11,11,"23/11/2012Addizione di vettoriTorniamo ancora sulla definizione di parallelogramma.A partire da tre punti O, Ae B, cerchiamo il punto C 
Determiniamo il punto medio Mdei punti Ae B.Determiniamo il punto Csimmetrico del punto Orispetto al punto medio M.
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#12,12,"23/11/2013Addizione di vettoriTorniamo ancora sulla definizione di parallelogramma.A partire da tre punti O, Ae B, cerchiamo il punto C Determiniamo il punto medio Mdei punti Ae B.Determiniamo il punto Csimmetrico del punto Orispetto al punto medio M.Il punto Cè allineato ai punti O, Ae B.
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#13,13,"23/11/2014Addizione di vettoriDefinizione: Dati quattro punti qualsiasi A, B, C, D, diciamoche essi formano un parallelogrammase il punto Cè il simmetrico del punto Arispetto al punto Mmedio di Be D.Se i punti A, B, Dnon sono allineati, otteniamo un parallelogramma nondegenereDA
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#14,14,"DBC23/11/2015Addizione di vettoriDefinizione: Dati quattro punti qualsiasi A, B, C, D, diciamoche essi formano un parallelogrammase il punto Cè il simmetrico del punto Arispetto al punto Mmedio di Be D.Se i punti A, B, Dsono allineati, otteniamo un parallelogramma degenere
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#15,15,"23/11/2016Addizione di vettoriRegola del parallelogramma: Dati i vettori v:= OAe w:= OB, poniamo per definizione v+ w:= OC, dove Cè l’unico punto del pianotale che OACBsia un parallelogramma.Cè il simmetrico di Orispetto al punto medio Mdi Ae B.→→→
MMGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#16,16,"23/11/2017Addizione di vettoriTeorema: L’operazione di addizione tra vettori soddisfa:1.Proprietà associativa:Esempio: 
v+wu+v(u+v)+wu+(v+w)
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#17,17,"23/11/2018Addizione di vettoriTeorema: L’operazione di addizione tra vettori soddisfa:1.Proprietà associativa:2.Proprietà commutativa:3.Esistenza dello zero:
O = BIl simmetrico (C) di Orispetto a Mè il punto Astesso.Segue: 
MP = A = C
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#18,18,"23/11/2019Addizione di vettoriTeorema: L’operazione di addizione tra vettori soddisfa:1.Proprietà associativa:2.Proprietà commutativa:3.Esistenza dello zero:4.Esistenza dell'opposto:
Il vettoreOB è unico!→Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#19,19,"23/11/2020Moltiplicare un vettore per uno scalareDato un vettore v:= OPe uno scalare hinR, definiamo il vettore hvinV 2(O).Se v= 0 poniamo: h0 := 0 qualsiasi sia hin R.Se v≠ 0 i punti Oe P, sono distinti. Il punto Odelimita le due semirette r1(passante per P) e r2.   Poniamo: →
OPr1r2
•se h= 0 allora Q= O;•se h> 0 allora Qè il punto di r1tale che d(O, Q) = hd(O, P);•se h < 0 allora Qè il punto di r2tale che d(O, Q) = –hd(O, P).Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#2,2,"23/11/203Vettori del pianoConsideriamo un piano e fissiamo su esso una distanza con unità di misura U1U2. Fissiamo poi una volta per tutte un punto O del piano, che chiamiamo origine.Definizioni: Dato comunque un punto P, chiamiamo vettore applicatoin Odi verticePla coppia di punti Oe P. Indichiamo questo vettore con il simbolo OP. Diremo anche che il vettore OPha come origine il punto O.         →→OPGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#20,20,"23/11/2021Moltiplicare un vettore per uno scalareTeorema: L'operazione di moltiplicazione di un vettore per uno scalare verifica le proprietà:1 v= vper ogni vin V 2(O) Dimostrazione: Dato v:=OA, vogliamo determinare 1v. Per definizione di moltiplicazione di un vettore per uno scalare: se v= 0, si ha 1v= 0 e quindi 1v= v;se v= OA≠ 0, si ha O≠ A.r1è la semiretta delimitata da Oe passante per A. Il vettore 1vè uguale al vettore OB,dove B (= A) è il punto di r1tale che d(O, B) = 1 d(O, A). Quindi 1v= v.→→OA = Br1→Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#21,21,"OO23/11/2022Moltiplicare un vettore per uno scalareTeorema: L'operazione di moltiplicazione di un vettore per uno scalare verifica le proprietà:1 v= vper ogni vin V 2(O) h (k v) = (h k) vper ogni vin V 2(O), hin R, kin REsempio:PvP’P’’PvP’’kvh (kv)(h k) v
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#22,22,"OP = h (v1 + v2 )
23/11/2023Moltiplicare un vettore per uno scalareTeorema: Le operazioni di addizione tra vettori e di moltiplicazione di un vettore per uno scalare verificano le seguenti proprietà,     dette proprietà distributive:
Esempio:v1+v2OP’1  = h v1OP’2  = h v2→→OP= h v1+ h v2→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#23,23,"23/11/2024Moltiplicare un vettore per uno scalareEsercizio:  Verificare che   (–1) v= –vper ogni vin V 2(O)Dimostrazione: Dato v:= OAe dato –v := OB. Per definizione di moltiplicazione di un vettore per uno scalare: se v= 0, si ha –1v= 0. Inoltre –v = 0. Segue –1v= 0 = –v;se v= OA≠ 0, si ha O≠ A.r2è la semiretta delimitata da Oe non passante per A. Il vettore –1vè uguale al vettore OC,dove Cè il punto di r2tale che d(O, C) = | –1| d(O, A) = d(O, A). Quindi C= B. Segue –1v= –v.→→
r2→= CGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#24,24,"23/11/2025Vettori dello spazioL’insieme V 3(O) dei vettori dello spazio con origine in O verificale seguenti proprietà di addizione tra vettori e di moltiplicazionedi un vettore per uno scalare [in modo analogo a V 2(O)]:1. Proprietà associativa:2. Proprietà commutativa:3. Esistenza dello zero:4. Esistenza dell'opposto: 
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#25,25,"23/11/2026Vettori dello spazioL’insieme V 3(O) dei vettori dello spazio con origine in O verificale seguenti proprietà di addizione tra vettori e di moltiplicazione di un vettore per uno scalare [in modo analogo a V 2(O)]:
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#26,26,"23/11/2027Rette e piani per l’origineOsservazioni:Se rè una retta passante per l'origine, Ae Bsono due punti di rallora il termine Cdel vettore OA+ OBè un punto di r.→→
MrGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#27,27,"23/11/2028Rette e piani per l’origineOsservazioni:Se rè una retta passante per l'origine, Ae Bsono due punti di rallora il termine Cdel vettore OA+ OBè un punto di r.Se rè una retta passante per l'origine, Aè un punto di rallora il termine Ddel vettore k OA è un punto di r.→→→
OADk OAr→OA→Esempio:
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#28,28,"23/11/2029Rette e piani per l’origineOsservazioni:Se rè una retta passante per l'origine, Ae Bsono due punti di rallora il termine Cdel vettore OA+ OBè un punto di r.Se rè una retta passante per l'origine, Aè un punto di rallora il termine Ddel vettore k OA è un punto di r.Analogamente:Se πè un piano passante per l'origine, Ae Bsono due punti di πallora il termine Cdel vettore OA+ OBè un punto di π.Se πè un piano passante per l'origine, Aè un punto di πallora il termine Ddel vettore k OA è un punto di π.→→→→→→Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#29,29,"23/11/2030Rette e piani per l’origineEsercizio: Sia runa retta non passante per l'origine. Siano Ae Bdue punti di r.Domanda 1: Il vettore OA+ OBha termine sulla retta r ? Il punto medio Mtra Ae Bappartiene alla retta r. Il simmetrico Cdi Orispetto a Msta sulla retta spassante per Oe M.Dunque Cnon appartiene alla retta r, perché l’unico punto in comune tra le rette re sè il punto M.→→s
rGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#3,3,"23/11/204Vettori del pianoConsideriamo un piano e fissiamo su esso una distanza con unità di misura U1U2. Fissiamo poi una volta per tutte un punto O del piano, che chiamiamo origine.Definizioni: Dato comunque un punto P, chiamiamo vettore applicatoin Odi verticePla coppia di punti Oe P. Indichiamo questo vettore con il simbolo OP. Diremo anche che il vettore OPha come origine il punto O. Il simbolo V 2(O) indica l'insieme dei vettori applicati in O. Il vettore OOviene chiamato vettore nullo e indicato con il simbolo 0. Abbiamo quindi 0 = OO.→→→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#30,30,"23/11/2031Rette e piani per l’origineEsercizio: Sia runa retta non passante per l'origine. Siano Ae Bdue punti di r.Domanda 2: Se kè uno scalare, il vettore k OA ha termine su r ?→
trO ≠ Aperché Onon appartiene a r, Aappartiene a r.k OA è un punto della retta tpassante per Oe A:•per k= 1 si ottiene il vettore OAstesso;•per k≠ 1 si ottiene un vettore il cui termine è un punto di tdiverso da Ae, quindi, non appartenente a r.L’unico punto in comune tra re tè A.→→B
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#31,31,"23/11/2032Punto medioTeorema: Dati due punti Ae Bdel piano o dello spazio,                   il loro punto medio Mè dato dalla formula: Dimostrazione: Sia Cil punto tale che OC= OA + OB. Dobbiamo mostrare che OM= 1/2 OC.Sappiamo che il punto Cè il simmetrico di Orispetto al punto M. 
→→→→→
MMGeometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#32,32,"23/11/2033Punto medioTeorema: Dati due punti Ae Bdel piano o dello spazio,                   il loro punto medio Mè dato dalla formula: Dimostrazione: Sia Cil punto tale che OC= OA + OB. Dobbiamo mostrare che OM= 1/2 OC.Sappiamo che il punto Cè il simmetrico di Orispetto al punto M. Distinguiamo due casi: •Se Mcoincide conO, allora Ccoincide conO, e OM = OC = 0. •Se Mnoncoincide con O, detta rla retta passante per Oe M,    per la definizione di prodotto scalare vettore, il termine del vettore2OMè esattamente il simmetrico di Mrispetto ad O:  2OM= OC. 
→→→→→→→→→→Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#4,4,"23/11/205Vettori del pianoEsempio:
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#5,5,"23/11/206Addizione di vettoriIntroduciamo in V 2(O) un’operazione di addizione di vettori:dati due vettori ve w, il vettore somma è definito come v+ w.Regola del parallelogramma: Dati i vettori v:= OAe w:= OB, poniamo per definizione v+ w:= OC, dove Cè l’unico punto del pianotale che OACBsia un parallelogramma.→→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#6,6,"23/11/207Addizione di vettoriIntroduciamo in V 2(O) un’operazione di addizione di vettori:dati due vettori ve w, il vettore somma è definito come v+ w.Regola del parallelogramma: Dati i vettori v:= OAe w:= OB, poniamo per definizione v+ w:= OC, dove Cè l’unico punto del pianotale che OACBsia un parallelogramma.Come si procede nel seguente caso? →→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#7,7,"23/11/208Addizione di vettoriTorniamo sulla definizione di parallelogramma.A partire da tre punti O, Ae B, cerchiamo il punto C Sia rla retta passante per Oe A.Sia sla retta passante per Oe B. Determiniamo la retta r’passante     per Be parallela alla retta r.Determiniamo la retta s’passante     per Ae parallela alla retta s.Determiniamo il punto Ccome intersezionedelle rette r’e s’.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#8,8,"23/11/209Addizione di vettoriTorniamo sulla definizione di parallelogramma.A partire da tre punti O, Ae B, cerchiamo il punto C Osservazioni:Se O= Ala retta rè indeterminata Se O= Bla retta sè indeterminataSe le rette re ssono determinate (O≠ Ae O≠ B) ma coincidono,allora non possiamo determinare l’ intersezione tra le rette r’ed s’,  e quindi il punto C.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\6_Vettori.pdf#9,9,"23/11/2010Addizione di vettoriTorniamo sulla definizione di parallelogramma.A partire da tre punti O, Ae B, cerchiamo il punto C Osservazioni:Se O= Ala retta rè indeterminata Se O= Bla retta sè indeterminataSe le rette re ssono determinate (O≠ Ae O≠ B) ma coincidono,allora non possiamo determinare l’ intersezione tra le rette r’ed s’,  e quindi il punto C.Ci si trova in questa situazione, quando i punti O, A, e Bsono allineati.
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#0,0,Geometria e Combinatoria  marcella.sama@uniroma3.itL7: Combinazioni lineari di vettori geometrici (12)Argomenti lezione:•Introduzione•Combinazione lineare di vettori•Vettori linearmente indipendenti
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#1,1,"23/11/202Introduzione•Introduciamo il concetto di combinazione lineare di vettori(del piano o dello spazio) e di vettori linearmente indipendenti.•Dimostriamo poi che nel pianoesistono coppie di vettori linearmente indipendenti, ma non esistono più di due vettori linearmente indipendenti.•Si dimostra infine che nello spazioesistono terne di vettori linearmente indipendenti, ma non esistono più di tre vettori linearmente indipendenti.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#10,10,"23/11/2011Vettori linearmente indipendentiTeorema: Dati comunque 2 vettori linearmente indipendentidi V 2(O), ogni vettore di V 2(O) è loro combinazione lineare.In altre parole: se v1:= OP1e v2:= OP2sono vettori di V 2(O) linearmente indipendenti, allora per ogni v:= OPin V 2(O),  esistono h1in R e h2in Rtali che:    v= h1v1+ h2v2.→→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#11,11,"23/11/2012Vettori linearmente indipendentiTeorema: Dati comunque 2 vettori linearmente indipendentidi V 2(O), ogni vettore di V 2(O) è loro combinazione lineare.Dimostrazione: Poniamo v1:= OP1, v2:= OP2, v:= OP. Poiché i vettori v1e v2sono linearmente indipendenti, i tre punti O, P1e P2nonsono allineati (vedi teorema precedente). OP’1PP’2è  un parallelogramma.→→→
Esiste h1in Rtale che OP’1= h1v1Esiste h2in Rtale che OP’2= h2v2
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#12,12,"23/11/2013Vettori linearmente indipendentiTeorema: Dati comunque 3 vettori di V 2(O), essi sono linearmente dipendenti.Dimostrazione:Siano v1, v2e v3i tre vettori. Distinguiamo due casi:•Supponiamo v1e v2sono linearmente dipendenti. Allora esistono h1e h2non entrambi nullitali che h1v1 + h2v2= 0. Segue h1v1+ h2v2+ 0v3= 0 e i tre vettori sono lin. dipendenti;•Supponiamo v1e v2sono linearmente indipendenti. Allora esistono due numeri reali h1e h2tali che v3= h1v1 + h2v2Segue h1v1 + h2v2 + (–1)v3= 0 e i tre vettori sono lin. dipendenti.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#13,13,"23/11/2014Vettori linearmente indipendentiTeorema: Dati comunque nvettori di V 2(O) conn≥3, essi sono linearmente dipendenti.Dimostrazione:Dobbiamo dimostrare che in V 2(O) non esistono più di due vettori che siano tra loro linearmente indipendenti.Sappiamo che 3 vettori in V 2(O) sono tra loro lin. dipendenti.Esistono quindi h1, h2e h3non tutti nullitali che:h1v1+ h2v2+ h3v3= 0Ora siano dati nvettori v1, v2, v3, v4, …, vn, con n> 3.Allora si ha: h1v1+ h2v2+ h3v3+ 0v4+ 0v5+ ... + 0vn= 0.Pertanto gli nvettori sono linearmente dipendenti. Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#14,14,"23/11/2015Vettori linearmente indipendentiNel caso di vettori dello spaziosi dimostrano i seguenti teoremi:Teorema: Siano v1:= OP1, v2:= OP2due vettori di V 3(O) linearmente indipendenti. L’insieme delle loro combinazioni lineari è formato da tutti e soli i vettori OPtali che il punto Pappartenga al piano passante per i punti non allineatiO, P1e P2.Teorema: Tre vettori v1:= OP1, v2:= OP2e v3:= OP3di V 3(O) sono linearmente dipendentise e solo se i punti O, P1, P2e P3sono complanari.→→→→→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#15,15,"23/11/2016Vettori linearmente indipendentiNel caso di vettori dello spaziosi dimostrano i seguenti teoremi:Teorema: Dati tre vettori linearmente indipendentidi V 3(O), ogni vettore di V 3(O) è loro combinazione lineare. In altre parole: se v1:= OP1, v2:= OP2e v3:= OP3sono vettori di V 3(O) linearmente indipendenti, allora per ogni v:= OPin V 3(O), esistono h1in R, h2in Re h3in Rtali che:v= h1 v1+ h2 v2+ h3 v3.Teorema: Dati comunque n≥ 4 vettori di V 3(O), essi sono linearmente dipendenti.→→→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#2,2,"23/11/203Combinazione lineare di vettoriSia nel piano che nello spazio, si ha la seguente definizione. Dati nvettori v1, v2, ... , vn, e dati nnumeri reali a1, a2, ... , an,il vettore v:= ∑!""#$𝑎!𝑣!viene chiamato combinazione linearedei vettori v1, v2, ... , vncon coefficientia1, a2, ... , an. Esempio:
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#3,3,"23/11/204Combinazione lineare di vettoriDati comunque nvettori v1, v2, ... , vn, si ha: ∑!""#$0𝑣!= 0Dimostrazione:Per definizione, abbiamo 0v= 0 per ogni vettore v. Pertanto 0v1+ 0v2+ ... + 0vn= 0 + 0 + ... + 0 = 0L’ultima uguaglianza si ottiene applicando ripetutamente la proprietà 0 + 0 = 0, caso particolare di v+ 0 = v con v= 0.
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#4,4,"23/11/205Vettori linearmente indipendentiSia nel piano che nello spazio, si ha la seguente definizione.Dati nvettori v1, v2, ... , vn, essi si dicono linearmentedipendentise esistono a1, a2, ... , ancoefficienti non tutti nullitali che ∑!""#$𝑎!𝑣!= 0Dati nvettori v1, v2, ... , vn, essi si dicono linearmente indipendenti se l’uguaglianza ∑!""#$𝑎!𝑣!= 0è verificata solamentenel caso in cui a1= a2= ... = an= 0. L’unica loro combinazione lineare uguale al vettore nullo è la combinazione lineare con tutti i coefficienti nulli.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#5,5,"23/11/206Vettori linearmente indipendentiAnalizziamo il significato geometrico di indipendenza lineare.Teorema: Un vettore v1è linearmente dipendentese e solo se v1= 0.Dimostrazione:Supponiamo che v1= 0: Allora 1v1= 0 è una combinazione lineare di v1con coefficiente non nullouguale al vettore nullo.Dunque, per definizione, v1è linearmente dipendente.Viceversa, supponiamo che v1sia linearmente dipendente. Allora, per definizione, esiste h≠0 tale che h v1= 0. Moltiplicando ambo i membri per h–1si ha: h–1hv1= h–10. D’altra parte h–1h v1= 1v1= v1e   h–10 = 0.  Dunque v1= 0.Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#6,6,"23/11/207Vettori linearmente indipendentiAnalizziamo il significato geometrico di indipendenza lineare.Teorema: Dato un vettore del piano (o dello spazio) v:= OAlinearmente indipendente. Sia rla retta passante per Oe A.Dato un punto qualsiasi Pdella retta r, esiste un solo scalarehin Rtale che OP= h OA.Dimostrazione:Se P= Oallora OP= 0: basta porre h= 0.Se P≠O, sia d(P ,O) = kd(A,O):•Se Pin r1, OP= k OA, h= k.•Se Pin r2, OP= –kOA, h= –k.→→→OAr1r2r→→→→→Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#7,7,"OA23/11/208Vettori linearmente indipendentiAnalizziamo il significato geometrico di indipendenza lineare.Segue il teorema: Dato un vettore del piano (o dello spazio) v:= OAlinearmente indipendente. L’insieme delle combinazioni linearidi v, cioè l’insieme dei vettori hval variare di hin R, è formato da tutti e soli i vettori OPtali che il punto Pappartenga alla rettarpassante per i punti distinti Oe A.r→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#8,8,"23/11/209Vettori linearmente indipendentiTeorema: Due vettori v1:= OP1e v2:= OP2sono linearmentedipendentise e solo se i punti O, P1e P2sono allineati.Dimostrazione: Supponiamo che O, P1e P2sono allineati. Abbiamo due casi: •Se P1= Oallora v1= 0. Pertanto 1v1+ 0v2= 0.Dunque v1e v2sono linearmente dipendenti. •Se P1≠Oallora i punti P1e Oindividuano una retta r. Poiché O, P1e P2sono allineati il punto P2appartiene a r.Grazie al teorema precedente, esiste un hin Rtale che v2= h v1.Allora abbiamo: hv1+ (–1) v2= 0.Dunque v1e v2sono linearmente dipendenti.→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\7_Combinazione_lineare.pdf#9,9,"23/11/2010Vettori linearmente indipendentiTeorema: Due vettori v1:= OP1e v2:= OP2sono linearmentedipendentise e solo se i punti O, P1e P2sono allineati.Dimostrazione: Viceversasupponiamo che v1e v2sono linearmente dipendenti. Sappiamo che esistono due numeri reali he knon entrambi nulli taliche: h v1+ k v2= 0. Ad esempio, k≠0. Moltiplicando per k –1 si ha: k –1 hv1+ v2= 0Dunque: v2= –k –1hv1. Essendo v2multiplo di v1, il termine P2di v2appartiene a r.Pertanto esiste una retta rche contiene i punti O, P1e P2.→→
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#0,0,"23/11/201L8: Spazi vettoriali sui reali (11-14)Argomenti lezione:•Introduzione •Gli spazi vettoriali•Proprietà degli spazi vettoriali•Sottospazi vettoriali
Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#1,1,"23/11/202Vettori del pianoConsideriamo un piano e fissiamo su esso una distanza con unità di misura U1U2. Fissiamo poi una volta per tutte un punto O del piano, che chiamiamo origine.Definizioni: Dato comunque un punto P, chiamiamo vettore applicatoin Odi verticePla coppia di punti Oe P. Indichiamo questo vettore con il simbolo OP. Diremo anche che il vettore OPha come origine il punto O.         →→OPIl simbolo V 2(O) indica l'insieme dei vettori applicati in O. Il vettore OOviene chiamato vettore nullo e indicato con il simbolo 0. Abbiamo quindi 0 = OO.23/11/202Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#10,10,"23/11/2011Esempi di spazi vettoriali Contro-esempio: Consideriamo R2con le operazioni cosi definite:•Le proprietà (1, 2, 3, 4) che coinvolgono solo l'operazione di addizione sono tutte verificate;•La proprietà 5 non è sempre verificataper il seguente motivo:se k= 1  e  a1≠ 0, si ha che 1(a1, a2) ≠ (0, a2).Pertanto R2con queste operazioni nonè uno spazio vettoriale. 
23/11/2011Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#11,11,"Proprietà degli Spazi Vettoriali
23/11/2012Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#12,12,"23/11/2013Proprietà degli spazi vettorialiLegge di cancellazione della somma:Siano u, v, wvettori di uno spazio vettoriale V , u+ v= u+ wse e solo se v= wCome casi particolari abbiamo:  •u+ v= use e solo se   v= 0•u+ v= wse e solo se   v= w–uDimostrazione:Se v= wallora vale l’uguaglianza u + v= u+ w.Viceversa, se u + v= u + wallora col vettore –uotteniamo:–u+ (u+ v) = –u+ (u+ w)Per la proprietà associativa: (–u+ u) + v= (–u+ u) + wCioè 0 + v= 0 + w. Vale a dire v= w.23/11/2013Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#13,13,"23/11/2014Proprietà degli spazi vettorialiTeorema: In uno spazio vettoriale Vvalgono le proprietà:Dimostrazione:1. Utilizzando le proprietà che definiscono uno spazio vettorialeabbiamo:  0 v= (0 + 0) v= 0 v+ 0 vDalla legge di cancellazione segue allora che 0 v= 0.2. Calcolando il prodotto di uno scalare hper il vettore nullo,abbiamo:  h0 = h(0 + 0) = h0 + h0Dalla legge di cancellazione segue allora che h0 = 0.
23/11/2014Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#14,14,"23/11/2015Proprietà degli spazi vettorialiTeorema: Sia vun vettore di uno spazio vettoriale V, e sia hin R.Se h v= 0 allora h= 0 oppure v= 0.Dimostrazione:Sappiamo che hv= 0. Dobbiamo mostrare che h= 0 oppure v= 0. Se h= 0 abbiamo finito, se h≠ 0 mostriamo che v= 0. Moltiplichiamo per h–1entrambi i membri di h v= 0 e otteniamo: h–1(h v) = h–10 h–1 ( hv) = (h–1 h) v= 1 v= vh–1 0 = 0Pertanto v= 0.23/11/2015Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#15,15,"23/11/2016Proprietà degli spazi vettorialiTeorema: Se vè un vettore di uno spazio vettoriale V, allora vale l’uguaglianza (–1) v= –v.Dimostrazione:Dobbiamo mostrare che (–1) vè l’oppostodel vettore v.Dobbiamo cioè mostrare che v+ (–1) v= 0. Allora: v+ (–1) v= 1v+ (–1) v= (1 + (–1)) v= 0 v= 0.
23/11/2016Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#16,16,"Sottospazi vettoriali
23/11/2017Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#17,17,"23/11/2018Sottospazi vettorialiObiettivo: Identificare se un sottoinsiemenon vuoto Edi unospazio vettoriale Vè esso stesso uno spazio vettoriale.Metodologia: •prima dobbiamo stabilire se abbiamo delle operazioni in E; •poi dobbiamo verificare se queste operazioni soddisfano le proprietà che definiscono uno spazio vettoriale.Definizione: Un sottoinsieme non vuoto Edi uno spazio vettoriale Vsi dice sottospaziovettoriale di Vse:
23/11/2018Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#18,18,"23/11/2019Sottospazi vettoriali
Esercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici che hanno almeno un elemento nullo. Per esempio:Domanda: Stabilire se Eè uno spazio vettoriale rispetto alle operazioni che possiamo indurre dallo spazio vettoriale M (2, 2, R).Contro-esempio: 
Segue che A + Bnon è necessariamente una matrice di E !Da cui Enonè uno spazio vettoriale rispetto a M (2, 2, R).23/11/2019Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#19,19,"Esercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici che hanno tutti gli elementi interi. Per esempio:Domanda: Stabilire se Eè uno spazio vettoriale rispetto alle operazioni che possiamo indurre dallo spazio vettoriale M (2, 2, R).Contro-esempio: Se moltiplichiamo la matrice di Aper uno scalare pari ad k= ½  non otteniamo una matrice di E !23/11/2020Segue che k A non è necessariamente una matrice di E !Da cui Enonè uno spazio vettoriale rispetto a M (2, 2, R).
Sottospazi vettoriali
23/11/2020Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#2,2,"23/11/203Vettori dello spazioIn maniera analoga, l’insieme dei vettori dello spazio con origine in O viene definito con il simbolo V 3(O).
23/11/203Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#20,20,"23/11/2021Sottospazi vettorialiDefinizione: Un sottoinsieme non vuoto Edi uno spazio vettoriale Vsi dice sottospaziovettoriale di Vse:Domanda: Il sottospazio Eè uno spazio vettoriale? Per rispondere alla domanda dobbiamo verificare tutte le proprietà.
23/11/2021Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#21,21,"23/11/2022Sottospazi vettorialiDefinizione: Un sottoinsieme non vuoto Edi uno spazio vettoriale Vsi dice sottospaziovettoriale di Vse:Domanda: Il sottospazio Eè uno spazio vettoriale? Per rispondere alla domanda dobbiamo verificare tutte le proprietà.In particolaredobbiamo chiederci se nel sottoinsieme E diV:•Esiste l’elemento neutro: il vettore 0 in Vappartiene anche a E ?•Esiste l’elemento opposto: il vettore –uin Vappartiene anche a E ?
23/11/2022Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#22,22,"23/11/2023Sottospazi vettorialiTeorema: Se Eè un sottospazio vettoriale di uno spazio vettoriale V,allora 0 è in Ee, per ogni vettore udi E, il vettore –uè in E. Da cui Eè esso stesso uno spazio vettoriale. Dimostrazione:•V ogliamo mostrare che 0 è in E. Sappiamo che se kè un numero reale e se vè un vettore di E,     allora si ha che k vappartiene a E. In particolare, ciò è vero se k= 0.Dunque:  0 vè in E, ma 0 v= 0, e quindi il vettore 0 è in E.•V ogliamo mostrare che se uè un vettore di E, allora –uè in E.Sappiamo che k uappartiene al sottospazio Equalunque sia k.In particolare, (–1) uappartiene a E. Poiché (–1) u= –uallora il vettore –uè in E. 23/11/2023Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#23,23,"23/11/2024Sottospazi vettorialiTeorema: Se Eè un sottospazio vettoriale di uno spazio vettoriale V,allora 0 è in Ee, per ogni vettore udi E, il vettore –uè in E. Da cui Eè esso stesso uno spazio vettoriale. Osservazione: Se un sottoinsieme Edi uno spazio vettoriale Vnoncontiene il vettore 0, allora Enonè un sottospazio vettoriale di V!Segue che dato un sottoinsieme Edi uno spazio vettoriale Vper mostrare che Eè uno spazio vettoriale dobbiamo innanzituttoverificare se il vettore 0 appartiene al sottoinsieme E!23/11/2024Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#24,24,"23/11/2025Sottospazi vettorialiEsercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici:al variare di ae bin R. Domanda: Eè un sottospazio vettoriale di M (2, 2, R) ?Notiamo che il sottoinsieme Enon contiene la matrice nulla. Dunque Enon è un sottospazio vettoriale.
Segue che dato un sottoinsieme Edi uno spazio vettoriale Vper mostrare che Eè uno spazio vettoriale dobbiamo innanzituttoverificare se il vettore 0 appartiene al sottoinsieme E!
23/11/2025Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#25,25,"23/11/2026Sottospazi vettorialiEsercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici:al variare di ae bin R.  Eè un sottospazio vettoriale di M (2, 2, R) ?
Chiaramente il sottoinsieme Eè non vuoto, perché contiene, ad esempio, la matrice nulla. Osservazione: Se a= bla matrice ha determinante nullo, e quindi non è invertibile. Ciò non implica nulla riguardo la matrice opposta!  Verifichiamo se Eè un sottospazio. 23/11/2026Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#26,26,"23/11/2027Sottospazi vettorialiEsercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici:al variare di ae bin R.  Eè un sottospazio vettoriale di M (2, 2, R) ?
Chiaramente il sottoinsieme Eè non vuoto, perchè contiene, ad esempio, la matrice nulla. Verifichiamo se Eè un sottospazio.Prese due matrici in E: 
(M+ N) appartiene a Ese e solo sea3:= a1+ a2 e  b3:= b1+ b2.
23/11/2027Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#27,27,"23/11/2028Sottospazi vettorialiEsercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici:al variare di ae bin R.  Eè un sottospazio vettoriale di M (2, 2, R) ?
Chiaramente il sottoinsieme Eè non vuoto, perchè contiene, ad esempio, la matrice nulla. Verifichiamo se Eè un sottospazio.Analogamente, presa una matrice Min E: (kM) appartiene a Ese e solo sea4:= ka1e  b4:= kb1.
23/11/2028Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#28,28,"23/11/2029Sottospazi vettorialiEsercizio: Sia Eil sottoinsieme di M(2, 2, R) formato dalle matrici:al variare di ae bin R.  Eè un sottospazio vettoriale di M (2, 2, R) ?
Chiaramente il sottoinsieme Eè non vuoto, perchè contiene, ad esempio, la matrice nulla. Verifichiamo se Eè un sottospazio.Riassumendo: (kM) appartiene a Ese e solo sea4:= ka1e  b4:= kb1.(M+ N) appartiene a Ese e solo sea3:= a1+ a2 e  b3:= b1+ b2.
23/11/2029Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#29,29,"23/11/2030Sottospazi vettorialiEsercizio: Consideriamo lo spazio vettoriale M(n, n, R) delle matrici quadrate di ordine n. Vediamo alcuni esempi di suoi sottospazi: •il sottoinsieme TR(n) delle matrici triangolari superiori;Infatti:1. Tale sottospazio è non vuoto, perché la matrice nulla è una particolare matrice triangolare superiore;  2. La somma di due matrici triangolari superiori è una matrice triangolare superiore;3. Moltiplicando una matrice triangolare superiore per uno scalare   si ottiene una matrice triangolare superiore. Dunque TR(n) è un sottospazio vettoriale di M(n, n, R). 23/11/2030Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#3,3,"23/11/204IntroduzioneIniziamo lo studio degli spazi vettoriali sui reali:  L’insieme delle matrici M (p, q, R) con le operazioni di addizione tra matrici e di moltiplicazione di una matrice per uno scalare; L’insieme dei vettori V 2(O) o V 3(O) con le operazioni di addizione tra vettori e di moltiplicazione di un vettore per uno scalare.
23/11/204Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#30,30,"23/11/2031Sottospazi vettorialiEsercizio: Consideriamo lo spazio vettoriale M(n, n, R) delle matrici quadrate di ordine n. Vediamo alcuni esempi di suoi sottospazi:•il sottoinsieme TR(n) delle matrici triangolari superiori;•il sottoinsieme TR(n) delle matrici triangolari inferiori;Si verifica analogamente a TR(n).  
23/11/2031Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#31,31,"23/11/2032Sottospazi vettorialiEsercizio: Consideriamo lo spazio vettoriale M(n, n, R) delle matrici quadrate di ordine n. Vediamo alcuni esempi di suoi sottospazi:•il sottoinsieme TR(n) delle matrici triangolari superiori;•il sottoinsieme TR(n) delle matrici triangolari inferiori;•il sottoinsieme S(n, R) delle matrici simmetriche;1. Se Ae Bsono in S(n, R), allora A+Bappartiene a S(n, R)? Sappiamo che tA= Ae tB= B. Dimostriamo che t(A+ B) = A+B. Si ha t(A+ B) = t A+ t B= A+ B.2. Se Aappartiene a S(n, R) e kè uno scalare, allora k Aè in S(n, R)?Sappiamo che tA= A. Dobbiamo mostrare che t(k A) = k A. Si ha t(k A) = k  t A= k A. 23/11/2032Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#32,32,"23/11/2033Sottospazi vettorialiEsercizio: Consideriamo lo spazio vettoriale M(n, n, R) delle matrici quadrate di ordine n. Vediamo alcuni esempi di suoi sottospazi:•il sottoinsieme TR(n) delle matrici triangolari superiori;•il sottoinsieme TR(n) delle matrici triangolari inferiori;•il sottoinsieme S(n, R) delle matrici simmetriche;•il sottoinsieme A(n, R) delle matrici antisimmetriche (vale a dire delle matrici Atali che tA = –A);Si verifica analogamente a S(n, R). 
23/11/2033Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#33,33,"23/11/2034Sottospazi vettorialiConsideriamo ora un sistema Sdi pequazioni lineari in qincognite. Spuò essere scritto nella forma matriciale AX= B, dove:•la matrice dei coefficienti Aappartiene a M(p, q, R);•la matrice colonna dei termini noti Bappartiene a M(p, 1, R);•la matrice colonna delle incognite Xappartiene a M(q, 1, R);•le soluzioni di Sformano un sottoinsieme Sol(S) di M(q, 1, R). Domanda: Sol(S) è un sottospazio di M(q, 1, R) ?
23/11/2034Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#34,34,"23/11/2035Sottospazi vettorialiConsideriamo ora un sistema Sdi pequazioni lineari in qincognite. Spuò essere scritto nella forma matriciale AX= B, dove:•la matrice dei coefficienti Aappartiene a M(p, q, R);•la matrice colonna dei termini noti Bappartiene a M(p, 1, R);•la matrice colonna delle incognite Xappartiene a M(q, 1, R);•le soluzioni di Sformano un sottoinsieme Sol(S) di M(q, 1, R). Domanda: Sol(S) è un sottospazio di M(q, 1, R) ?La matrice nulla appartiene a Sol(S) se e solo se A0 = B= 0 ! Definizione: Un sistema Sdi equazioni lineari si dice omogeneose i termini noti di tutte le equazioni del sistema Ssono nulli (B = 0).23/11/2035Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#35,35,"23/11/2036Sottospazi vettorialiDefinizione: I seguenti sottospazi vengono detti sottospazi banali: •Il sottoinsieme {0} (vettore nullo) dello spazio vettoriale V ; •Lo spazio vettoriale contenente tutto V(ovvero Vstesso) . Osservazione 1: Un sistema lineare omogeneo S: AX= 0 è sempre risolubile.Infatti rk A= rk A’. 
23/11/2036Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#36,36,"23/11/2037Sottospazi vettorialiDefinizione: I seguenti sottospazi vengono detti sottospazi banali: •Il sottoinsieme {0} (vettore nullo) dello spazio vettoriale V ; •Lo spazio vettoriale contenente tutto V(ovvero Vstesso) . Osservazione 1: Un sistema lineare omogeneo S: AX= 0 è sempre risolubile.AX= 0 ammette (almeno) la soluzione X= 0, detta soluzione banale. N.B. Un sistema omogeneo può avere altre soluzioni oltre alla banale.Osservazione 2: Un sistema S’non omogeneo noncontiene la soluzione banale.Infatti S’: AX= B≠ 0. 23/11/2037Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#37,37,"23/11/2038Sottospazi vettorialiDefinizione: I seguenti sottospazi vengono detti sottospazi banali: •Il sottoinsieme {0} (vettore nullo) dello spazio vettoriale V ; •Lo spazio vettoriale contenente tutto V(ovvero Vstesso) . Osservazione 1: Un sistema lineare omogeneo S: AX= 0 è sempre risolubile.AX= 0 ammette (almeno) la soluzione X= 0, detta soluzione banale. N.B. Un sistema omogeneo può avere altre soluzioni oltre alla banale.Osservazione 2: Un sistema S’non omogeneo noncontiene la soluzione banale.L'insieme delle soluzioni di S’ nonè quindi un sottospazio vettoriale! 23/11/2038Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#38,38,"23/11/2039Sottospazi vettorialiTeorema: Sia S: AX=0 un sistema lineare omogeneo di pequazioni in qincognite.L’insieme Sol(S) è un sottospazio vettoriale di M(q, 1, R).Dimostrazione: •Sol(S) ≠ ∅perché contiene la matrice nulla. •Siano ora X1e X2due elementi di Sol(S). Dobbiamo dimostrare che X1+ X2appartiene a Sol(S). X1e X2sono due soluzioni di S, quindi A X1= 0 e A X2= 0. Abbiamo che A (X1+ X2) = A X1+ A X2= 0 + 0 = 0.  •Dobbiamo dimostrare che  A(kX1) = 0. Abbiamo che A(kX1) = k (A X1) = k 0 = 0. 23/11/2039Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#39,39,"23/11/2040Sottospazi vettorialiEsercizio: Dimostrare che un sistema omogeneo S: AX= 0 ammette soluzioni non banali se e solo se il rk Aè minore del numero delle incognite.Soluzione: Il sistema Sammette soluzioni non banali se ha più di una soluzione. Sappiamo che le soluzioni di un sistema risolubile di matrice Adipendono da q–rk Aparametri, dove qè il numero delle incognite. Quindi il sistema Sha più di una soluzione se e solo se q–rk A> 0.23/11/2040Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#4,4,"Spazi Vettoriali
23/11/205Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#40,40,"23/11/2041EserciziEsercizio: Sia Eil sottoinsieme di M (2, 2, R) formato dalleseguenti matrici, al variare di ain R:Stabilire se Eè un sottospazio vettoriale di M (2, 2, R). •Eè non vuoto.•Consideriamo due matrici MeN, calcoliamo la loro somma:
Dovremmo avere:  a3= a1+ a2;  a32= a12 + a22 In generale non è vero: se a1= a2= 1 allora a3= 2  ma  a32≠ 2 !Dunque Enonè un sottospazio vettoriale di M (2, 2, R).23/11/2041Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#5,5,"23/11/206Gli spazi vettoriali: EsempioConsideriamo l'insieme M(p, q, R) delle matrici a coefficienti reali aventi prighe e qcolonne. Abbiamo già visto le seguenti proprietà:
Pr. associativa della sommaEsistenza dello zeroEsistenza dell’oppostoPr. commutativa della somma
23/11/206Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#6,6,"23/11/207Gli spazi vettorialiDefinizione di spazio vettoriale sui reali:Sia dato un insieme non vuoto V, i cui elementi sono vettori. Chiamiamo, invece, scalarii numeri reali in R. In Vsia definita un’operazione binaria interna, che data una coppia (v,w)in V associ un altro vettore in V(addizionev+ w). In Vsia definita un’operazione binaria esterna, che data una coppia (k, v) con vettore vin Ve scalare kin Rassoci un altro vettore in V(moltiplicazione kv). v + wè il vettore somma, mentre kvè il prodotto scalare vettore.23/11/207Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#7,7,"23/11/208Gli spazi vettorialiL’insieme Vviene detto spazio vettoriale su Rse sono verificate:
23/11/208Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#8,8,"23/11/209Esempi di spazi vettoriali Con le 8 operazioni appena definite si definiscono spazi vettoriali:•M(p, q, R), V 2(O) e V 3(O); •L’insieme R in cui i numeri reali rivestono il ruolo sia di vettori che di scalari;•L’insieme delle n-uple di numeri reali (nè un numero naturale):•L’insieme R[x] dei polinomi a coefficienti reali nell'incognita x(le 8 operazioni appena viste si applicano all’addizione tra polinomi e alla moltiplicazione di uno scalare per un polinomio).
23/11/209Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\8_Spazi_vettoriali.pdf#9,9,"23/11/2010Esempi di spazi vettoriali Contro-esempio: Consideriamo R2con le operazioni cosi definite:•Le proprietà (1, 2, 3, 4) che coinvolgono solo l'operazione di addizionesono tutte verificate;
23/11/2010Geometria e Combinatoria marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#0,0,"23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it1L9: Generatori (12,15)Argomenti lezione:•Introduzione•Combinazione lineare di vettori•Vettori generatori di un sottospazio"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#1,1,"Sottospazio vettoriale
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it2"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#10,10,"23/11/2011Combinazione lineare di vettori Definizione: Dati dei vettori v1, v2, . . . , vrdi uno spazio vettoriale Ve degli scalari k1, k2, . . . , kr, una combinazione lineare dei vettori v1, v2, . . . , vra coefficienti k1, k2, . . . , krè ∑!""#%𝑘!𝑣!.Esempio: Scrivere le combinazioni lineari delle matrici:Le loro combinazioni lineari sono tutte e sole le matrici del tipo:
al variare di k1, k2, k3e k4in R.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it11"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#11,11,"23/11/2012Combinazione lineare di vettori Definizione: Dati dei vettori v1, v2, . . . , vrdi uno spazio vettoriale Ve degli scalari k1, k2, . . . , kr, una combinazione lineare dei vettori v1, v2, . . . , vra coefficienti k1, k2, . . . , krè ∑!""#%𝑘!𝑣!.Esempio: Scrivere le combinazioni lineari delle matrici:Le loro combinazioni lineari sono tutte e sole le matrici del tipo:
al variare di k1, k2, k3e k4in R.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it12"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#12,12,"23/11/2013Combinazione lineare di vettori Definizione: Dati dei vettori v1, v2, . . . , vrdi uno spazio vettoriale Ve degli scalari k1, k2, . . . , kr, una combinazione lineare dei vettori v1, v2, . . . , vra coefficienti k1, k2, . . . , krè ∑!""#%𝑘!𝑣!.Esempio: Scrivere le combinazioni lineari delle matrici:Le loro combinazioni lineari sono tutte e sole le matrici del tipo:
al variare di k1, k2, k3e k4in R.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it13"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#13,13,"Generatori
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it14"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#14,14,"23/11/2015Vettori generatori di un sottospazioTeorema: L'insieme delle combinazioni linearidei v1, v2, . . . , vral variare dei coefficienti k1, k2, . . . , krè un sottospazio vettor. di Vchiamato sottospazio vettoriale generatodai vettori v1, v2, . . . , vr:L(v1, v2, . . . , vr):= ∑!""#%𝑘!𝑣!𝑘!∈ℝ}.N.B. Tale sottospazio vettoriale contiene i vettori v1, v2, . . . , vred  è contenuto in tuttii sottospazi vett. di Vcontenenti v1, v2, . . . , vr.
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it15"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#15,15,"23/11/2016Vettori generatori di un sottospazioTeorema: L'insieme delle combinazioni linearidei v1, v2, . . . , vral variare dei coefficienti k1, k2, . . . , krè un sottospazio vettor. di Vchiamato sottospazio vettoriale generatodai vettori v1, v2, . . . , vr:L(v1, v2, . . . , vr):= ∑!""#%𝑘!𝑣!𝑘!∈ℝ}.Dimostrazione: 1.Notiamo cheL(v1, v2, . . . , vr) contiene tutti i vettori v1, v2, ..., vrPer esempio si ha: v1= 1v1+ 0v2+ . . . + 0vr2.Sia Eun sottospazio vettoriale di Vcontenente v1, v2, ... , vr.  Allora: Econtiene tutti i vettori del tipo k1v1, k2v2, ... , krvr.         Econtiene tutte le loro combinazioni lineari: k1v1+k2v2+ ... +krvr. Quindi Eè generato daL(v1, v2, . . . , vr). 23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it16"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#16,16,"23/11/2017Vettori generatori di un sottospazioTeorema: L'insieme delle combinazioni linearidei v1, v2, . . . , vral variare dei coefficienti k1, k2, . . . , krè un sottospazio vettor. di Vchiamato sottospazio vettoriale generatodai vettori v1, v2, . . . , vr:L(v1, v2, . . . , vr):= ∑!""#%𝑘!𝑣!𝑘!∈ℝ}.Dimostrazione: 3.Dimostriamo che L(v1, v2, ... , vr) è un sottospazio vettor. di VL(v1, v2, ... , vr) è non vuoto (e.g. contiene i vettori v1, v2, ... , vr) Dati   u= k1v1+ k2v2+ ... + krvre    v= h1v1+ h2v2+ ... + hrvr.Sia( u + v ) che ( k u ) appartengono a L(v1, v2, ... , vr). Infatti:     u + v= (k1 + h1) v1 + (k2 + h2) v2 + ... + (kr+ hr) vrk u= (kk1) v1+ (kk2) v2+ ... + (kkr) vr23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it17"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#17,17,"23/11/2018Vettori generatori di un sottospazioDefinizione: Se V= L(v1, v2, ... , vr) allora Vè generatodai vettori v1, v2, ... , vr .In altre parole, v1, v2, ... , vrsono generatoridi (o generano) V se e solo se ogni vettore di Vè combinazione lineare di v1, v2, ... , vr.Esempi: Data una retta rpassante per l’origine Odel piano o dello spazio,    e dato un punto Adella retta rdistinto da O, l'insieme dei vettoriOPcon Pin rè un sottospazio vettoriale generatodal vettore OA.Dati in V 2(O) due vettori OP1e OP2con O, P1e P2non allineati,i vettori OP1e OP2generanoV 2(O). →→→→→→23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it18"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#18,18,"23/11/2019Vettori generatori di un sottospazioDefinizione: Se V= L(v1, v2, ... , vr) allora Vè generatodai vettori v1, v2, ... , vr.In altre parole, v1, v2, ... , vrsono generatoridi (o generano) V se e solo se ogni vettore di Vè combinazione lineare di v1, v2, ... , vr.Esempi: Dati in V 3(O) due vettori OP1e OP2con O, P1e P2non allineati,i vettori OP1e OP2generanoil sottospazio di V 3(O) formato dai vettori OPcon Pappartenente al piano passante per O, P1e P2.V 3(O) è generatodai vettori OP1, OP2e OP3con O, P1, P2e P3non complanari.→→→→→→→→23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it19"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#19,19,"23/11/2020Vettori generatori di un sottospazioDefinizione: Se V= L(v1, v2, ... , vr) allora Vè generatodai vettori v1, v2, ... , vr.In altre parole, v1, v2, ... , vr sono generatoridi (o generano) V se e solo se ogni vettore di Vè combinazione lineare di v1, v2, ... , vr.Esempi: Consideriamo le seguenti tre matrici di M(2, 2, R): Il sottospazio vettoriale che esse generanoè quello formato dallematrici del tipo k1A1+ k2A2+ k3A3. Facendo i calcoli: 23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it20"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#2,2,"23/11/203IntroduzioneEsempio:  Consideriamo le seguenti tre matrici di M(2, 2, R):  
Queste tre matrici appartengono al sottospazio vettoriale S(2, R) di M(2, 2, R) formato dalle matrici simmetriche.Queste tre matrici appartengono anche al sottospazio EdiM (2, 2, R) formato dalle matrici del tipo: Esistono altri sottospazi contenenti le tre matrici …Domanda: C’è un sottospazio più ""piccolo"" di tutti gli altri ?
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it3"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#20,20,"Definizione: Se V= L(v1, v2, ... , vr) allora Vè generatodai vettori v1, v2, ... , vr.In altre parole, v1, v2, ... , vrsono generatoridi (o generano) V se e solo se ogni vettore di Vè combinazione lineare di v1, v2, ... , vr.Esempi: Consideriamo i tre polinomi 1, x, x2. Vediamo che le loro combinazioni lineari sono i polinomi del tipo: k1+ k2 x+ k3 x2 .Dunque 1, x, x2generanoR3[x], ovvero il sottospazio vettoriale di R[x] formato dai polinomi di grado minore di 3. In maniera analoga si potrebbe verificare che 1, x, x2, . . . , xngeneranoRn+1[x].23/11/2021Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it21"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#21,21,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? Dobbiamo stabilire se vè combinazione lineare di v1, v2e v3. Vale a dire se esistono tre scalari k1, k2e k3tali che:(0, 1, 0, 2) = k1(3, 2, 2, 1) + k2(1, 0, 1, –1) + k3(0, 1, 1, 2) 
23/11/2022Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it22"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#22,22,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? Dobbiamo stabilire se vè combinazione lineare di v1, v2e v3. Vale a dire se esistono tre scalari k1, k2e k3tali che:(0, 1, 0, 2) = k1(3, 2, 2, 1) + k2(1, 0, 1, –1) + k3(0, 1, 1, 2) (0, 1, 0, 2) = (3k1+ k2,  2 k1+ k3,  2k1+ k2+ k3,  k1–k2+ 2k3)
23/11/2023Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it23"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#23,23,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? 
23/11/2024Vettori generatori di un sottospazio
rkA= 3rkA’= 3vappartiene a Ese e solo se il sistema è risolubilecalcolare il rango di Ae A’e applicareRouché-Capelli23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it24"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#24,24,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? 
23/11/2025Vettori generatori di un sottospazio
rkA= 3rkA’= 3Abbiamo che rkA=rkA’.il sistema è risolubile!Quindi vappartiene aE23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it25"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#25,25,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? 
23/11/2026Vettori generatori di un sottospazio
rkA= 3rkA’= 3Le soluzioni del sistema: k1= 1/3, k2= –1, k3= 1/3(non ho parametri datoche rk A= qincognite) 23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it26"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#26,26,"Esercizio: Sia Eil sottospazio vettoriale di R4generato dai vettori v1:= (3, 2, 2, 1), v2:= (1, 0, 1, –1) e v3:= (0, 1, 1, 2). Domanda: Il vettore v:= (0, 1, 0, 2) appartiene al sottospazio E? 
23/11/2027Vettori generatori di un sottospazio
rkA= 3rkA’= 3
Le soluzioni del sistema:k1= 1/3, k2= –1, k3= 1/323/11/20Geometria e Combinatoria marcella.sama@uniroma3.it27"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#27,27,"Esercizio: Sia Eil sottospazio vettoriale di M(2, 3, R) generato da:Domanda: Le seguenti matrici appartengono a  E? 
23/11/2028Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it28"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#28,28,"Esercizio: Sia Eil sottospazio vettoriale di M(2, 3, R) generato da:
23/11/2029Vettori generatori di un sottospazio
Consideriamo una combinazione lineare delle quattro matrici:
Aappartiene a Ese e solo se il seguente sistema è risolubile: 
Il sistema nonè risolubile,Anonappartiene a E23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it29"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#29,29,"Esercizio: Sia Eil sottospazio vettoriale di M(2, 3, R) generato da:
23/11/2030Vettori generatori di un sottospazio
Consideriamo una combinazione lineare delle quattro matrici:
Bappartiene a Ese e solo se il seguente sistema è risolubile: 
Facendo i calcoli si ha:Il sistema è risolubile,Bappartiene a E23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it30"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#3,3,"23/11/204IntroduzioneEsempio:  Consideriamo le seguenti tre matrici di M(2, 2, R):  
Domanda: C’è un sottospazio più ""piccolo"" di tutti gli altri ?Un Fdi M(2, 2, R) che contiene le tre matrici deve contenere:•le matrici del tipo k1A1, k2A2, k3A3con k1, k2e k3numeri reali;•le somme di questi multipli: k1A1+ k2A2+ k3A3; •i multipli delle matrici create, poi le loro somme, e così via.Segue l’insieme Fdelle matrici del tipo: k1A1+ k2A2+ k3A3Si dimostra che Fè un sottospazio vettoriale di M(2, 2, R). Ad esempio: A1si ottiene per k1= 1, k2= k3= 0.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it4"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#30,30,"Osservazione: In generale non c’e alcun motivo perché dato un qualsiasi spazio vettoriale Vesistano v1, v2, ... , vrche generano V.Esempio: Si consideri lo spazio vettoriale dei polinomi R[x]. Consideriamo un numero finito di npolinomi f1[x], . . . , fn[x]. Essi non possono essere generatori di R[x], perchè tutte le combinazioni lineari di f1[x], . . . , fn[x] sono polinomi di grado minore o uguale a g(ovvero il massimo dei gradi di tali polinomi). Ma allora il polinomio xg+1, appartenente a R[x], nonè ottenibile come combinazione lineare di f1[x], . . . , fn[x]. Questi ultimi nonsono quindi generatori di R[x]. 23/11/2031Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it31"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#31,31,"Definizione: Diciamo che uno spazio vettoriale Vè finitamente generatose esistono v1, v2, ... , vrtali che V= L(v1, v2, ... , vr) .Esempi:•V 2(O) è finitamente generato;•V 3(O) è finitamente generato;•R[x] nonè finitamente generato. 
23/11/2032Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it32"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#32,32,"Esercizio (1): Dati r+1 vettori v1, v2, ..., vr, vr+1 di uno spazio vett. Vmostrare che L(v1, v2, ... , vr)  ÍL(v1, v2, ... , vr, vr+1). Dobbiamo mostrare che ogni combinazione lineare dei vettori v1, v2, ..., vrè anche combinazione lineare dei vettori v1, v2, ..., vr,vr+1.Infatti se vè combinazione lineare dei vettori v1, v2, ..., vr, esistono numeri reali k1, k2, . . . , krtali che:v= k1v1+ k2v2+ . . . + krvrv= k1v1+ k2v2+ . . . + krvr+ 0vr+1 Segue che vè combinazione lineare di v1, v2, ..., vr, vr+1. 23/11/2033Vettori generatori di un sottospazio
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it33"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#33,33,"Esercizio (2): Stabilire se le matrici S1e S2generano S(2, R).
23/11/2034Vettori generatori di un sottospazio
Dobbiamo verificare se una qualsiasi matrice simmetrica Spuò essere espressa come combinazione lineare di S1e S2.Dobbiamo stabilire se esistono k1e k2tali che S= k1S1+ k2S2, cioè:
Determiniamo k1e k2se e solo se a= c.Dunque nontutte le matrici simmetriche sono combinazioni linearidi S1e S2. Perciò, S1e S2nongenerano S(2, R).23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it34"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#34,34,"Esercizio (3): Stabilire se le matrici S1, S2e S3generano S(2, R).
23/11/2035Vettori generatori di un sottospazio
Dobbiamo verificare se una qualsiasi matrice simmetrica Spuò essere espressa come combinazione lineare di S1, S2e S3.Dobbiamo stabilire se esistono k1, k2e k3t.c. S= k1S1+ k2S2 + k3S3 :Basta porre: k1= b , k2= a , k3= c.Dunque tuttele matrici simmetriche sono combinazioni linearidi S1, S2e S3. Perciò, S1, S2e S3generanoS(2, R).
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it35"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#35,35,"Esercizio (4): Si consideri il sottospazio vettoriale di R[x] generato dai polinomi p1(x) := 3+2x,  p2(x) := x+x3,  p3(x) := 1+x+x2–x3.Stabilire se i polinomi  p(x) := 1 + 2x+ x3e   q(x) := –7 + 2x2+ 2x3appartengono al sottospazio E.Stabiliamo se p(x)è combinazione lineare di p1(x), p2(x) e p3(x), cioè:p(x) = k1p1(x) + k2p2(x) + k3p3(x) 
23/11/2036Vettori generatori di un sottospazio
Svolgendo i calcoli si vede che questo sistema nonè risolubile. Perciò, p(x) nonappartiene al sottospazio E.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it36"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#36,36,"Esercizio (4): Si consideri il sottospazio vettoriale di R[x] generato dai polinomi p1(x) := 3+2x,  p2(x) := x+x3,  p3(x) := 1+x+x2–x3.Stabilire se i polinomi  p(x) := 1 + 2x+ x3e   q(x) := –7 + 2x2+ 2x3appartengono al sottospazio E.Stabiliamo se q(x)è combinazione lineare di p1(x), p2(x) e p3(x), cioè:q(x) = k1p1(x) + k2p2(x) + k3p3(x) 
23/11/2037Vettori generatori di un sottospazio
Svolgendo i calcoli si vede che questo sistema è risolubile. Perciò, q(x) appartiene al sottospazio E.
–7 + 2x2+ 2x3  =–7 + 2x2+ 2x3  =
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it37"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#4,4,"23/11/205IntroduzioneEsempio:  Consideriamo le seguenti tre matrici di M(2, 2, R):  
Domanda: C’è un sottospazio più ""piccolo"" di tutti gli altri ? Segue l’insieme Fdelle matrici del tipo: k1A1+ k2A2+ k3A3Dimostriamoche Fè un sottospazio vettoriale di M(2, 2, R). Prese le matrici A := k1A1+k2A2+k3A3e  B := h1A1+h2A2+h3A3Verifichiamo che:k A = k (k1A1+k2A2+k3A3) = (k k1) A1+ (k k2) A2 + (k k3) A3A + B= k1A1+ k2A2+ k3A3+ h1A1+ h2A2+ h3A3= (k1+h1 ) A1+ (k2 +h2 ) A2+ (k3+h3) A323/11/20Geometria e Combinatoria marcella.sama@uniroma3.it5"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#5,5,"Dipendenza e indipendenza lineare
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it6"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#6,6,"23/11/207Combinazione lineare di vettori Sia nel piano che nello spazio, si ha la seguente definizione.Dati nvettori v1, v2, ... , vn, essi si dicono linearmentedipendentise esistono a1, a2, ... , ancoefficienti non tutti nullitali che a1v1+ a2v2+ ... + anvn= 0Dati nvettori v1, v2, ... , vn, essi si dicono linearmente indipendenti se l’uguaglianza a1v1+ a2v2+ ... + anvn= 0è verificata solamentenel caso in cui a1= a2= ... = an= 0. L’unica loro combinazione lineare uguale al vettore nullo è la combinazione lineare con tutti i coefficienti nulli.23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it7"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#7,7,"23/11/208Combinazione lineare di vettoriSia nel piano che nello spazio, si ha la seguente definizione. Dati nvettori v1, v2, ... , vn, e dati nnumeri reali a1, a2, ... , an,il vettore v:= ∑!""#$𝑎!𝑣!viene chiamato combinazione linearedei vettori v1, v2, ... , vncon coefficientia1, a2, ... , an. Esempio:
Geometria e Combinatoria  marcella.sama@uniroma3.it"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#8,8,"23/11/209Combinazione lineare di vettori Definizione: Dati dei vettori v1, v2, . . . , vrdi uno spazio vettoriale Ve degli scalari k1, k2, . . . , kr, una combinazione lineare dei vettoriv1, v2, . . . , vra coefficienti k1, k2, . . . , krè   ∑!""#%𝑘!𝑣!
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it9"
data_test\rootfolder\università\GeometriaECombinatoria\9_Generatori.pdf#9,9,"23/11/2010Combinazione lineare di vettori Definizione: Dati dei vettori v1, v2, . . . , vrdi uno spazio vettoriale Ve degli scalari k1, k2, . . . , kr, una combinazione lineare dei vettoriv1, v2, . . . , vra coefficienti k1, k2, . . . , krè ∑!""#%𝑘!𝑣!.Esempio: Scrivere le combinazioni lineari delle matrici:Le loro combinazioni lineari sono tutte e sole le matrici del tipo:
23/11/20Geometria e Combinatoria marcella.sama@uniroma3.it10"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al Machine Learning  
 
1"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#1,1,"Introduzione al  
machine Learning
Intuitivamente, un sistema è in grado di apprendere se, 
attraverso la sua attività, è in grado di migliorare le 
proprie prestazioni.
Nell’IA, il miglioramento delle prestazioni coincide in 
generale con l’acquisizione di nuove conoscenze.
 2"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#10,10," 11
Applicazioni Finanziarie  
Applicazioni in Medicina (e.g., rilevamento di tumori nelle 
scansioni cerebrali)
Recommender Systems (e.g., raccomandare un prodotto a cui 
un cliente potrebbe essere interessato, sulla base di acquisti 
passati)
Rilevamento di frodi con carte di credito  
Rilevamento di pattern di accesso anomali a un sito Web
Segnalazione automatica di commenti offensivi nei forum  
Identiﬁcazione di fake news
Esempi di applicazione"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#11,11," 12
Applicazioni in vari campi dell’ingegneria (Civile, 
Aeronautica, Telecomunicazioni, ecc. ecc.)
Marketing (e.g., segmentazione dei clienti in base ai loro 
acquisti in modo da poter progettare una strategia di 
marketing diversa per ogni segmento)  
Previsione dei ricavi della tua azienda per il prossimo anno, 
sulla base di varie metriche di performance
Costruire un bot intelligente per un gioco  
Far reagire la tua app ai comandi vocali  
Creare un chatbot o un assistente personale
Esempi di applicazione"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#12,12,"metodi di apprendimento
Apprendimento supervisionato
Richiede che si apprenda una funzione partendo da esempi di input 
e output
Apprendimento non supervisionato
Richiede di imparare a riconoscere pattern o schemi nell’input 
senza alcuna indicazione speciﬁca dei valori di uscita.
Apprendimento per rinforzo
L’agente apprende in base al rinforzo (ricompensa) ottenuto.
 13"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#13,13,"Tipici problemi di  
Machine Learning
Regression 
Classiﬁcation  
ClusteringUna tipica classiﬁcazione dei problemi affrontati in ML  
è la seguente:
 14"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#14,14,"Applicazioni di  
Machine Learning
DEMO
 15"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#2,2,"Introduzione al  
machine Learning
Qualsiasi cambiamento in un sistema che gli permetta di 
avere prestazioni migliori la seconda volta, nella 
ripetizione dello stesso compito o di un altro compito 
tratto dalla stessa popolazione.
(Simon, 1984)
 3"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#3,3,"Introduzione al  
machine Learning
A computer program is said to learn from experience E 
with respect to some class of tasks T and performance 
measure P, if its performance at tasks in T, as measured 
by P, improves with experience E .
(Mitchell, 1997)
 4"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#4,4,"Definizioni
Task T : obiettivo del sistema
Giocare a dama
Guidare un autoveicolo
Riconoscere parole pronunciate
Experience E : Insieme di addestramento dal quale apprendere
Partite giocate
Percorsi
.........
Performance measure P : misura della capacità di eseguire il 
task
Numero di partite vinte
Numero di parole classiﬁcate correttamente
 5"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#5,5,"Introduzione al  
machine Learning
Un elemento fondamentale dell’apprendimento è la 
capacità di valutare le proprie prestazioni, o almeno di 
accettare una valutazione dall’esterno.
Senza una valutazione, infatti, non sarebbe possibile 
parlare di miglioramento.
A sua volta, la valutazione delle prestazioni richiede la 
capacità di accettare un certo tipo di informazioni 
dall’ambiente esterno.
 6"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#6,6,"Progetti Rilevanti nello 
Sviluppo del Machine Learning
1989 : Guida autoveicolo - ALVINN system (Pomerlau, 1989)
1995 : Classiﬁcazione nuove strutture astronomiche - NASA: classiﬁcazione 
oggetti celesti (Fayyad et al., 1995)
1992-95 : Backgammon - TD-Gammon (Tesauro, 1992, 1995): 
apprendimento su 1 milione di partite giocate contro se stesso.
2004 : DARPA introduce la “DARPA Grand Challenge”, una sﬁda per la 
guida autonoma di veicoli.
2006 : Geoffrey Hinton dell’Università di Toronto introduce un algoritmo di 
apprendimento veloce  per reti neurali artiﬁciali, che dà il via alla 
rivoluzione del Deep Learning.
 7"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#7,7," 8
2006 : Netﬂix lancia la “Netﬂix Prize competition”, con una borsa di 
un milione di dollari, sﬁdando i gruppi di ricerca ad usare il Machine 
Learning per migliorare la accuracy del proprio Recommender 
System  di almeno il 10%. Un gruppo ha vinto il premio nel 2009.
2010 : ImageNet lancia un concorso annuale - la “ImageNet Large 
Scale Visual Recognition Challenge (ILSVRC)” - in cui i team 
utilizzano il Machine Learning per rilevare e classiﬁcare 
correttamente gli oggetti in un set di dati di immagini ampio e ben 
curato. L’errore di classiﬁcazione migliora dal 25% nel 2011 a pochi 
punti percentuali nel 2015, grazie ai progressi nelle deep 
convolutional neural networks.
Progetti Rilevanti nello 
Sviluppo del Machine Learning"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#8,8," 9
2011 : IBM Watson, un sistema di question-answering, batte i 
campioni del gioco Jeopardy!   Brad Rutter e Ken Jennings. IBM 
Watson è ora utilizzato in diversi settori, tra cui l’assistenza sanitaria 
e la vendita al dettaglio. 
2014 : Facebook pubblica un lavoro su DeepFace, un sistema basato 
su reti neurali artiﬁciali in grado di identiﬁcare volti con 
un’accuratezza del 97%, una prestazione al livello “umano”, che 
migliora di circa il 27% le prestazioni di sistemi precedenti.
2014 : Il Il consumo di energia per il raffreddamento dei Data Center 
è stato ridotto del 40% con un modello di Machine Learning:
Progetti Rilevanti nello 
Sviluppo del Machine Learning
Gao,	J.	(2014) .	Machine	Learning	Applica:ons	for	Data	Center	Op:miza:on.	 Google	Research.  
hCps://sta:c.googleusercontent.com/media/research.google.com/it//pubs/archive/42542.pdf"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#9,9," 10
2015 : AlphaGo di DeepMind batte il giocatore Fan Hui nel gioco del 
Go. Nel 2016 , batte Lee Sedol e, nel 2017 , batte Ke Jie.
2017 : Il software per analizzare le immagini delle galassie sotto lenti 
gravitazionali è stato velocizzato di un fattore di 10 milioni  con un 
modello di Machine Learning:
Progetti Rilevanti nello 
Sviluppo del Machine Learning
Hezaveh,	 Y.D.,	 Levasseur,	 I.P .,	 Marshall,	 P .J.	 (2017).	 Fast	 Automated	 Analysis	 of	 Strong	
Gravita:onal	Lenses	with	Convolu:onal	Neural	networks.	 Nature ,	548,	pp.	555-557.  
hCps://arxiv.org/abs/1708.08842
Recentemente David Patterson (Turing Award winner) e Jeff Dean (Google AI 
head) hanno dichiarato l'alba di una ""età dell'oro"" per l'architettura dei computer 
grazie al Machine Learning . "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Algoritmo K-NN
Machine Learning "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#1,1,"Sommario
Ripasso su Information Retrieval 
Algoritmo k-NN 
kd-trees per k-NN
 
2"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#10,10,"Modello Bag-of-Words
Un problema che emerge in questa semplice rappresentazione è 
relativa ai termini poco frequenti (“rare words”). 
In effetti, in tale rappresentazione tutti i termini sono considerati 
ugualmente importanti.  
In realtà certi termini hanno poca capacità discriminante ai ﬁni 
della determinazione della rilevanza di un documento (e.g., 
quando ne calcoliamo la distanza rispetto ad un altro).  
Ad esempio, nel caso di una collezione di documenti relativi 
all’industria automobilistica, è piuttosto probabile avere il termine 
“automobile” in quasi ogni documento. 
Tali termini dominerebbero dunque quelli più rari. 
 
11"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#11,11,"Modello TF-IDF
Una rappresentazione alternativa che possiamo considerare è 
quella chiamata 
 tf-idf
. 
Come vedremo, questa rappresentazione enfatizza i termini 
“importanti”, individuati dalle seguenti caratteristiche: 
•
 appaiono frequentemente in un documento (“common locally”) 
•
 appaiono raramente nel corpus (“rare globally”) 
 
12"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#12,12,"Modello TF-IDF
Deﬁniamo 
 Document Frequency
  (
df
) per il termine 
 t
 come il 
numero di documenti nel corpus che contengono 
 t
. 
Deﬁniamo inoltre l’
 Inverse Document Frequency
  come segue: 
dove N è la cardinalità del corpus. 
 
13idf t= logN
dft"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#13,13," 
14termine dft idft
car 18.165 1,65
auto 6.723 2,08
insurance 19.241 1,62
best 25.235 1,5ESEMPIO: 
Nella seguente tabella sono riportati alcuni esempi di valori df e idf 
relativi alla collezione Reuters, costituita da 806.791 documenti:
Modello TF-IDF"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#14,14,"Modello TF-IDF
Il tf-idf è deﬁnito come segue: 
In sostanza il 
 tf-idf
 per un termine 
 t
 in un documento 
 d
 assegna al 
termine un peso nel documento che è: 
•
 molto elevato quando 
 t
 è molto frequente in un piccolo numero 
di documenti; 
•
 più basso quando il termine è poco frequente nel documento, 
oppure quando è presente in molti documenti; 
•
 il più basso quando il termine compare in tutti i documenti. 
 
15tf-idf t,d=t f t,d ·idft"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#15,15,"Metriche
Vediamo ora come possiamo calcolare la distanza tra due 
 item
.
 
16distanza( xi,xq)= |xi xq|
distanza( xi,xq)=q
(xi[1] xq[1])2+···+(xi[d] xq[d])2
distanza( xi,xq)=q
(xi xq)T·(xi xq)
Nel semplice caso di una dimensione possiamo deﬁnire la 
funzione distanza come segue (Distanza Euclidea):
Nel caso di 
 d 
dimensioni, la funzione 
 distanza
  può assumere la 
seguente forma (Distanza Euclidea):
che possiamo riscrivere come segue, in forma matriciale:"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#16,16,"Metriche
 
17distanza( xi,xq)=q
a1(xi[1] xq[1])2+···+ad(xi[d] xq[d])2
distanza( xi,xq)=q
(xi xq)T·A ·(xi xq)
Nel caso in cui vogliamo pesare in modo diverso le varie 
dimensioni, possiamo usare una 
 Scaled Euclidean distance
 :
A=2
664a10 ... 0
0 a2 ... 0
... ... ... ...
00 ... a d3
775
che possiamo riscrivere come segue, in forma matriciale:
dove:"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#17,17,"Cosine Similarity
Una metrica largamente utilizzata per quantiﬁcare la similarità tra 
due documenti 
 x
i 
e 
x
q 
è la 
 cosine similarity
 , che si avvale della 
rappresentazione vettoriale dei documenti: 
 
18sim(xi,xq)=xT
i·xq
kxik·kxqk
dove il numeratore rappresenta il prodotto scalare tra i due vettori 
e il denominatore il prodotto tra i moduli dei due vettori. 
L’effetto del denominatore è dunque quello di normalizzare i 
vettori 
 x
i 
e 
x
q 
ottenendone i corrispondenti versori. Possiamo 
dunque riscrivere la precedente espressione come segue: 
sim(xi,xq)=ˆxT
i·ˆxq"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#18,18,"Consideriamo ad esempio i documenti in ﬁgura a), rappresentati 
mediante i vari 
 tf
. La quantità: 
 
19Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17Doc1 Doc2 Doc3
car 0,88 0,09 0,58
auto 0,10 0,71 0
insurance 0 0,71 0,70
best 0,46 0 0,41
Cosine Similarity
ha i valori 30,56, 46,84 e 41,30 per Doc1, Doc2 e Doc3. 
Applicando la normalizzazione otteniamo la ﬁgura b): 
a) 
 b) kxk=vuutdX
j=1x2
j"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#19,19,"La similarità deﬁnita in precedenza corrisponde al coseno 
dell’angolo tra i due vettori: 
 
20θ
01
1sim(xi,xq)=xT
i·xq
kxik·kxqk= cos( ✓)
ˆxi
ˆxq
Cosine Similarity"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#2,2,"Document Retrieval
 
3Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..
Supponiamo di avere disponibile un corpus di documenti: Come 
possiamo misurare la similarità tra di loro? Come possiamo 
effettuare ricerche? "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#20,20,"K-NN: Complessità della ricerca 
 
21Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Il calcolo delle distanze tra documenti può essere molto pesante 
computazionalmente quando N è molto elevato: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#21,21,"K-NN: Complessità della ricerca 
 
22
Dato un 
 query point
 , il costo della scansione su tutti i punti è: 
•
 O(N) per una query per 1-NN 
•
 O(N log k) per una query per k-NN 
Per rendere più efﬁciente la ricerca è possibile utilizzare una 
particolare struttura dati, i 
 KD-Trees
 . "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#22,22,"KD-Trees
 
23
Permette un’organizzazione strutturata degli item: 
•
 partiziona ricorsivamente i data point in “axis aligned boxes”. 
Comporta un più efﬁciente pruning dello spazio di ricerca. 
Ottiene buoni risultati in dimensioni “low-medium”. 
Riferimenti: 
Bentley, J.L. “Multidimensional Binary Search Trees Used for Associative Searching”, in: 
Communications of the ACM , 18(9), 1975, pp. 509-517.
Friedman, J.H., Bentley, J.L., Finkel, R.A. “An Algorithm for Finding Best Matches in 
Logarithmic Expected Time”, in: ACM Transactions on Mathematical Software , 3(3), 1977, pp. 
209-226."
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#23,23,"KD-Trees
 
24
Costruzione dell’albero: 
Data Point x[1] x[2]
1 0,00 0,00
2 1,00 4,31
3 0,13 2,85
… … …
feature 1feature 2"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#24,24,"KD-Trees
 
25
Split relativo alla prima feature: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#25,25,"KD-Trees
 
26
Consideriamo ora la parte sinistra: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#26,26,"KD-Trees
 
27
Split relativo alla seconda feature: 
Data Point x[1] x[2]
3 0,13 2,85
… … …Data Point x[1] x[2]
1 0,00 0,00
… … …x[2] > 0,1 x[2] ≤ 0,1
0,1
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#27,27,"KD-Trees
 
28
Si procede in tal modo ﬁno a completare l’albero: 
•split feature 
•split value 
•bounding box
x[1] > 0,5 x[1] ≤ 0,5
x[2] ≤ 0,1 x[2] > 0,1"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#28,28,"KD-Trees
 
29
Esempi di bounding box: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#29,29,"KD-Trees
 
30
Euristiche per effettuare le decisioni sugli splitting: 
•
 Scelta della dimensione (la più ampia, dim. alternate) 
•
 Valore della feature a cui effettuare lo split (mediana, centro 
del box) 
•
 Condizione di terminazione (numero di punti sotto una 
determinata soglia, larghezza del box sotto una determinata 
soglia)"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#3,3,"Nearest Neighbor
 
4Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare l’articolo più simile nel 
corpus di documenti disponibili: 
documento xqnearest neighbor"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#30,30,"KD-Trees
 
31
Dato un query point (in verde), attraversiamo l’albero alla ricerca 
del nearest neighbor. 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#31,31,"KD-Trees
 
32
Prima metà dell’area: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#32,32,"KD-Trees
 
33
.. e così via … 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#33,33,"KD-Trees
 
34
Abbiamo raggiunto la foglia che contiene il query point: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#34,34,"KD-Trees
 
35
Calcolo della distanza del NN tra i punti contenuti nella foglia: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#35,35,"KD-Trees
 
36
Backtrack e proviamo altri rami per ogni nodo visitato: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#36,36,"KD-Trees
 
37
Valutiamo la distanza dal bounding box: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#37,37,"KD-Trees
 
38
La distanza è minore di quella corrente, perciò visitiamo i 
sottoalberi (in questo caso le foglie). La prima ha distanza 
minore: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#38,38,"KD-Trees
 
39
Backtrack e visitiamo l’altra foglia: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#39,39,"KD-Trees
 
40
La distanza dal bounding box è superiore alla minima, perciò 
possiamo potare il ramo: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#4,4,"Algoritmo 1-NN
 
5dist min = 1
nearest doc = ;
for i=1,. . . ,N
 = distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o
if <dist min
nearest doc = xi; documento pi` u vicino corrente
dist min =   ; distanza minima corrente
return nearest doc
Input: documento 
 x
q
 per la query e documenti 
 x
1
 , 
x
2
, … , 
 x
N 
Output: documento 
 x
i
 più vicino (nearest_doc) a 
 x
q "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#40,40,"KD-Trees
 
41
Backtrack e proviamo altri rami per ogni nodo visitato: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#41,41,"KD-Trees
 
42
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#42,42,"KD-Trees
 
43
Backtrack e proviamo altri rami per ogni nodo visitato: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#43,43,"KD-Trees
 
44
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#44,44,"KD-Trees
 
45
Pruning complessivo: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#45,45,"Riferimenti
 
46
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#5,5," 
6Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare i k articoli più simili nel 
corpus di documenti disponibili: 
documento xqk nearest neighbors
k Nearest Neighbors"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#6,6,"Algoritmo k-NN
 
7
Input: documento 
 x
q
 per la query e documenti 
 x
1
 , 
x
2
, … , 
 x
N 
Output: lista dei k documenti più vicini a 
 x
q 
lista kdist min = sort(  1, 2,...,  k)
lista knearest doc = sort( x1,x2,..., xk)
for i=k+1,. . . ,N
 = distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o
if <lista kdist min[ k]
inserisci  in lista kdist min ; inserimento in lista ordinata
inserisci xiin lista knearest doc ; inserimento in lista ordinata
return lista knearest doc"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#7,7,"Criticità nella NN search
Per effettuare una ricerca dei nearest neighbors occorre risolvere i 
seguenti problemi: 
•
Come rappresentare gli item coinvolti (nel nostro esempio i 
documenti). 
•
Come valutare la distanza tra gli item, ossia deﬁnire una metrica 
che consenta di calcolare la similarità tra i vari item. 
 
8"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#8,8,"Richiami su 
Rappresentazione dei Documenti
Vediamo ora due possibili metodi per la rappresentazione dei 
documenti non strutturati: 
•
 bag of words 
•
 tf-idf 
 (term frequency - inverse document frequency)  
 
9"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#9,9,"Modello Bag-of-Words
In questo modello è ignorato l’esatto ordine dei termini nel 
documento. 
Viene preso in considerazione solo il numero di occorrenze (
 term 
frequency
 : 
tf
) di ogni termine nel documento. 
In tal modo è possibile rappresentare ogni documento mediante 
un vettore di occorrenze: 
 
10Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Machine Learning con Python: 
Introduzione  
 
1"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#1,1,"Introduzione al 
Machine Learning con Python   
Testo consigliato:
 2Andreas C. Müller,  Sarah Guido
“Introduction to Machine Learning with Python - A guide for Data Scientists”
O’Reilly, 2017.
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#10,10," 11
Caricamento del  
Dataset IRIS
Il nostro obiettivo è quello di realizzare un modello di 
machine learning che apprenda, dagli esempi disponibili, 
come classiﬁcare la specie di un nuovo ﬁore iris partendo 
dalle 4 misure relative ai suoi petali e sepali.
Il dataset Iris è incluso in scikit-learn  nel modulo 
datasets . E’ possibile caricarlo chiamando la funzione 
load_iris :
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#11,11," 12
L’oggetto iris restituito da load_iris  è un Bunch  object, ed 
è simile a un dizionario. Esso contiene chiavi e valori:
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#12,12," 13
Bunch objects
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#13,13," 14
Il valore associato alla chiave DESCR  è una descrizione 
sintetica del dataset. Vediamo i primi caratteri di tale 
descrizione:
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#14,14," 15
Vediamo i valori associati alle chiavi target_names  e 
feature_names :
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#15,15," 16
I dati sono contenuti nei campi data e target . Vediamo il 
tipo e lo shape di data:
Dataset IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#16,16," 17
L’array target  contiene le specie di ciascuno dei ﬁori del 
dataset ( 0 per setosa , 1 per versicolor , 2 per virginica ): 
Dataset IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#17,17,"I dati che useremo per il training e il test possono essere 
visti come segue:
 18
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#18,18,"Esempi di valori delle feature presenti in data:
 19
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2
X"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#19,19,"Esempi di valori delle specie presenti in target :
 20
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2
y"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#2,2," 3https://github.com/amueller/introduction_to_ml_with_python
Gli esempi di codice presentati nel libro sono disponibili 
nel seguente sito :
Introduzione al 
Machine Learning con Python   "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#20,20," 21
Suddivisione in 
Training Set e Test Set 
scikit-learn  contiene una funzione che mescola il dataset 
delle osservazioni disponibili e ne fa la suddivisione in  
training set e test set . Si tratta della funzione:
train_test_split
Questa funzione estrae il 75% degli esempi per formare il 
training set , costituito quindi dal 75% delle righe in data 
e le corrispondenti label in target .
Il rimanente 25% degli esempi va a costituire il test set ."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#21,21," 22
Istruzioni per lo split:
ndarray da ripartire tra  
X_train e X_testfunzione per lo split
ndarray da ripartire tra  
y_train e y_test
Suddivisione in 
Training Set e Test Set "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#22,22," 23
Shape delle variabili relative al training set e al test set:
Suddivisione in 
Training Set e Test Set "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#23,23," 24
Ispezione dei Dati
Prima di costruire un modello di machine learning è 
sempre opportuno ispezionare i dati disponibili, intanto 
per capire se il problema è risolvibile mediante tecniche 
di machine learning.
L’ispezione è utile anche per la individuazione di 
eventuali anomalie, inconsistenze, ecc.
Un ottimo metodo per effettuare tale ispezione è quello 
di visualizzare i dati in questione (e.g., scatter plot).
Nella ﬁgura che segue viene rappresentato un “pair plot” 
delle feature relativamente alle osservazioni del training 
set per il nostro esempio."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#24,24," 25
Ispezione dei Dati"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#25,25," 26
K-Nearest Neighbors 
Costruzione del Modello 
L’algoritmo k-NN  in scikit-learn  è implementato nella 
classe KNeighborsClassiﬁer  nel modulo neighbors .
Prima di usare il modello, dobbiamo istanziare la classe in 
un oggetto. In tal modo impostiamo i parametri del 
modello.
Il parametro più importante di KNeighborsClassiﬁer è il 
numero del neighbors, che in questo caso impostiamo a 1:
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#26,26," 27
K-Nearest Neighbors 
Costruzione del Modello 
L’oggetto knn incapsula l’algoritmo che sarà utilizzato per 
costruire il modello a partire dai dati di training, così 
come l’algoritmo per fare le previsioni su nuovi data 
points.
Nel caso di KNeighborsClassiﬁer  verrà semplicemente 
memorizzato il training set."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#27,27," 28
Addestramento del Modello
Per addestrare il modello sul training set, scikit-learn  
mette a disposizione il metodo ﬁt da chiamare 
sull’oggetto knn:
metodo per l’addestramento"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#28,28," 29
Uso del Modello  
per effettuare Previsioni 
Dato un nuovo data point da classiﬁcare:
features del nuovo ﬁore da classiﬁcare "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#29,29," 30
… possiamo usare il metodo predict per la predizione 
della sua specie:
metodo per la predizione
Uso del Modello  
per effettuare Previsioni "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#3,3,"Testo consigliato:
 4A. Géron
“Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow”
O’Reilly, 2019.
Introduzione al 
Machine Learning con Python   "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#30,30," 31
Valutazione del Modello 
Per valutare il modello possiamo richiamare il metodo 
predict  su tutti gli esempi del test set:
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#31,31," 32
Calcolo del punteggio:
Valutazione del Modello "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#32,32," 33
Sintesi della esercitazione
Deﬁnizione di un task di machine learning (classiﬁcazione delle specie Iris 
mediante k-NN ).
Individuazione dei data points  (esempi, osservazioni) disponibili per 
addestrare il sistema (supervised learning task)
Split  del dataset, import  della classe, che poi è istanziata su un oggetto (setting 
parameters)
Fase di addestramento (metodo ﬁt) e valutazione  (metodo score ):
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#4,4," 5
Scikit-learn  è uno dei package più popolari per il 
Machine Learning in Python.
Mette a disposizione efﬁcienti implementazioni di 
numerosi algoritmi di ML e un gran numero di utili 
strumenti per attività di pre- e post- processing relative a 
task di ML.
E’ possibile trovare la documentazione necessaria nel 
seguente sito: 
http://scikit-learn.org
Scikit-Learn "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#5,5," 6
Jupiter Notebook : ambiente interattivo per eseguire 
codice nel browser.
NumPy : è uno dei package fondamentali per il calcolo 
scientiﬁco in Python.
Librerie e Strumenti 
pandas : libreria per data wrangling e analisi.
matplotlib : libreria per il plotting.
mglearn : libreria di utility functions che gli autori (Müller 
& Guido) hanno scritto per il loro libro, in modo da non 
“intasare” il codice presentato con dettagli di plotting e di 
data loading."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#6,6,"Versioni linguaggio e librerie:
 7
Ambiente di Sviluppo 
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#7,7,"Cominciamo con un semplice esempio di classiﬁcation, 
utilizzando il data set Iris.
Questo è un famoso data set che contiene 150 esempi di 
ﬁori iris, descritti da 4 features (lunghezza e larghezza di 
petali e sepali) e appartenenti ad una di tre specie 
differenti:
Iris setosa
Iris versicolor  
Iris virginica  
 8
Una prima applicazione:  
Classificazione delle specie IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#8,8,"Ecco un esempio di ﬁori iris relativo alle tre specie:
 9
Una prima applicazione:  
Classificazione delle specie IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#9,9," 10
Una prima applicazione:  
Classificazione delle specie IRIS
Petal
Sepal
La classiﬁcazione può essere fatta in base ai valori delle 4 
features, ossia lunghezza e larghezza dei petali e sepali:"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#0,0,"Intelligenza Artiﬁciale 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione (Ex02)
1"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Dataset Better Life Index 
Richiami: Model Selection, Simple Linear Regression, Funzione di Costo 
Libreria Scikit-learn 
Linear Regression in Python 
Esempio: Dataset Diabete 
Linear Regression e Predizione 
Esercitazione su dataset Better Life Index"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#10,10,"Il modulo 
 linear_model
  di 
sklearn
  implementa l'addestramento basandosi 
su un modello lineare. La funzione di costo di default è la 
 RSS
. 
La funzione 
 ﬁt()
 prende come parametri due arrays 
 X
 e 
y
, effettua 
l'addestramento (o 
 ﬁtting
 ) e memorizza i coefﬁcienti nella variabile 
 coef_
 . 
Ad esempio: 
>>> 
from 
sklearn 
import
 linear_model 
>>> 
reg 
=
 linear_model
 .
LinearRegression() 
>>> 
reg
.
fit([[
0
, 
0
], [
1
, 
1
], [
2
, 
2
]], [
0
, 
1
, 
2
]) 
LinearRegression()  
>>> 
reg
.
coef_ 
array([0.5, 0.5]) 
Nell'esempio si impiegano 2 valori (cioè 2 features) per punto, e la retta ha 
2 coefﬁcienti 
 w
1
. Il valore di 
 w
0
 si ottiene con la variabile 
 intercept_
  del 
modello. 
Nota
 : l'underscore nel nome delle variabili indica che i valori sono ottenuti 
durante l'addestramento, e perciò non sono iperparametri del modello.
Linear Regression in Python
11"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#11,11,"Il modulo 
 metrics
  di 
sklearn
  implementa varie misure di performance. 
https://scikit-learn.org/stable/modules/model_evaluation.html  
Nota: troviamo MSE ma non RSS.
Scikit-learn e le misure di performance
12
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#12,12,"Un dataset diabete è un dataset 
 toy 
(cioè utile per scopi didattici e per 
testare il codice)  
 disponibile all'interno della libreria scikit-learn. 
URL: 
 https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html   
https://scikit-learn.org/stable/datasets/toy_dataset.html   
442 istanze 
10 features reali normalizzate ove richiesto -.2 < x < .2 
age age in years
sex
bmi body mass index
bp average blood pressure
s1 tc, total serum cholesterol
s2 ldl, low-density lipoproteins
s3 hdl, high-density lipoproteins
s4 tch, total cholesterol / HDL
s5 ltg, possibly log of serum triglycerides level
s6 glu, blood sugar level
Target: intero nell'intervallo 25 - 346 che indica quanto la malattia sia 
accresciuta dopo 1 anno
Esempio: dataset diabete
13"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#13,13,"Codice per impiegare il dataset: 
import 
matplotlib.pyplot  
as 
plt 
import 
numpy 
as 
np 
from 
sklearn 
import
 datasets, linear_model 
from 
sklearn.model_selection  
import
 train_test_split 
from 
sklearn.metrics  
import 
mean_squared_error
 , 
r2_score  
# Carico il dataset  
diabetes_X, diabetes_y 
 = 
datasets
 .
load_diabetes
 (return_X_y
 =
True
) 
# Mantengo solo la terza feature  
diabetes_X 
 =
 diabetes_X[:, 
 np
.
newaxis
, 
2
] 
# Suddivido il dataset in training/test 80/20%  
diabetes_X_train,diabetes_X_test,diabetes_y_train, diabetes_y_test 
 =    
  train_test_split(diabetes_X, diabetes_y,test_size=0.2) 
... 
Esercizio
 : completa il codice impiegando un modello lineare, 
visualizzando il valore dei coefﬁcienti e l'errore MSE.
Esempio Python: diabete (1)
14"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#14,14,"# Istanzia un modello di regressione lineare  
regr 
= 
linear_model
 .
LinearRegression
 () 
# Addestramento con funzione di costo RMSE  
regr
.
fit(diabetes_X_train, diabetes_y_train) 
# Ricava le predizioni sul test set  
diabetes_y_pred 
 =
 regr
.
predict(diabetes_X_test) 
# Stampa i parametri del modello  
print
(
""Coefficients: 
 \n
""
, regr
.
coef_) 
# Valuto il MSE  
print
(
""Mean squared error: 
 %.2f
"" 
% 
mean_squared_error
 (diabetes_y_test, diabetes_y_pred)) 
plt
.
scatter
(diabetes_X_test, diabetes_y_test, color
 =
""black""
) 
plt
.
plot
(diabetes_X_test, diabetes_y_pred, color
 =
""blue""
, linewidth
 =
3
) 
plt
.
xticks
(()) 
plt
.
yticks
(()) 
plt
.
show
() 
# Coefficients:   [938.23786125]  
# Mean squared error: 2548.07
Esempio Python: diabete (2)
15
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#15,15,"Il modulo 
 linear_model
  permette facilmente di fare predizione sui dati. 
La funzione 
 predict()
  prende un array di istanze (una o più features) e 
ricava il valore in base al modello addestrato. 
X_new = [[
 22587
]] 
print
(model.predict(X_new))
Linear Regression e predizione
16"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#16,16,"Il problema consiste nel determinare i due parametri 
 w
. Chiaramente il 
modello può solo approssimare la correlazione tra i valori.  
Se facciamo più ipotesi, cioè creiamo più modelli, ci occorre una misura di 
performance (o di costo) per confrontarli e scegliere il più adatto.
Esempio: dataset Better Life Index (3)
17PIL pro capiteLivello di soddisfazione
PIL pro capitew0=8w1=-5×10-5
w0=4w1=5×10-5 w0=0w1=2×10-5w0=?
w1=?Livello di soddisfazione"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#17,17,"Accedi al seguente notebook dove i dati sono già caricati e formattati per gli step 
successivi:  
https://colab.research.google.com/drive/1apLqC0KAveOkkCT8JuO5kNQyj1GT5Hz9?usp=sharing   
Risolvi i seguenti esercizi: 
Esercizio #1
 : crea e addestra un modello lineare con funzione di costo RSS 
Esercizio #2
 : visualizza i parametri del modello 
Esercizio #3
 : prendi tre campioni random dal dataset e ricava la predizione in base 
al modello addestrato 
Esercizio #4
 : calcola RSS MSE e RMSE valutando i tre campioni 
Esercizio #5
 : suddividi il dataset in input in train e test con un rapporto 80/20 
Esercizio #6
 : addestra nuovamente il modello, e ricava RSS MSE e RMSE sui test set 
Esercizio #7
 : suddividi nuovamente il dataset ma con un rapporto 50/50. Valuta 
nuovamente le performance del modello e discuti eventuali differenze nei valori 
ottenuti.
Esercizio Python: Better Life Index
18"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#18,18,"Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016
Testi di Riferimento
19"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami
Le tecniche di 
 Regressione
  ricadono nell'ambito dell'apprendimento 
Model-based
 , dove  
Si costruisce un modello che rappresenta le caratteristiche dei dati in 
ingresso (es. andamento).  
Tale modello verrà poi impiegato nella fase di 
 predizione
  su istanze in 
ingresso distinte da quelle impiegate durante l'apprendimento.
3
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#3,3,"Datasets
Durante le esercitazioni faremo uso di vari datasets, alcuni reali, altri 
sintetici che ci permetteranno di mettere in evidenza vari aspetti e 
problematiche rilevanti nell'ambito dell'apprendimento automatico.
4"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#4,4,"Esempio: dataset Better Life Index (1)
Dataset che lega il benessere (life satisfaction) con indicatori giudicati essenziali 
nella vita quotidiana (es. salario, livello istruzione), suddivisi per nazione. 
https://stats.oecd.org/index.aspx?DataSetCode=BLI  
5
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#5,5,"Esempio: dataset Better Life Index (2)
Valore del PIL (GDP) annuale 
https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD
6
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#6,6,"Se prendiamo i due dataset e creiamo un join, possiamo mettere in 
correlazione due variabili, es. PIL pro capite e livello di soddisfazione 
percepito. 
Si nota come i due valori siano correlati, sebbene non esattamente, con un 
legame lineare. 
Possiamo supporre che esista un modello 
 lineare
  (o 
ordinary least squares
 ) 
che leghi la soddisfazione con il valore del PIL (fase di 
 model selection
 ).
Richiami: Model selection
7
PIL pro capiteLivello di soddisfazione
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#7,7,"Richiami: Simple Linear Regression Model
I parametri del modello lineare sono 
 w
0
 e 
w
1
. 
Attenzione: non esiste un formalismo standard per rappresentare i 
parametri, a volte si impiega 
 θ
 o altri simboli. 
I parametri del modello lineare sono 
 w
0
 e 
w
1
.  
Adattando tali valori possiamo deﬁnire qualsiasi modello lineare.
8yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
x
PIL pro capiteLivello di soddisfazione"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#8,8,"Tipicamente is impiega una misura di costo basata sulla distanza tra valore 
esatto e valore determinato dal modello, come la 
 Residual Sum of Squares  
(RSS), sempre positiva, chiamata anche 
 Sum of Squared Residuals
  (SSR) o 
Sum of Squared estimate of Errors
  (SSE): 
Valori prossimi allo 
 0
 indicano un modello ideale. 
La 
Mean Square Error 
 (MSE), chiamata anche 
 Mean Squared Deviation  
(MSD), corrisponde alla RSS normalizzata sul numero di campioni.  
È utile per valutare il modello ﬁnale dopo l'addestramento.
Richiami: funzione di costo
9RSS( w0,w1)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0+w1xi)]2"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#9,9,"È la libreria con licenza aperta (BSD) più conosciuta di machine learning in 
Python. La prima release risale al 2010.  
https://scikit-learn.org/stable/   
Include gli algoritmi più popolari di classiﬁcazione, regressione, clustering 
(es. support-vector machines, random forests, gradient boosting, k-means e 
DBSCAN). 
Alcune parti del codice sono state scritte in modo altamente efﬁciente con 
varie tecnologie (vedi Cython) 
È facilmente interfacciabile con altre librerie per la gestione e il calcolo 
numerico di dati, es. NumPy (algebra lineare), SciPy (ottimizzazione, 
algebra lineare, analisi dei segnali, etc) e Pandas.
Richiami: la libreria Scikit-learn
10"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex03)
1"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Richiami: Classiﬁcazione e Regressione, overﬁtting, underﬁtting 
4 datasets: Forge, Wave, Wisconsin breast cancer, Boston housing 
Classiﬁcazione k-Neighbors e Scikit-learn, decision boundaries 
Misura R
2 
k-Neighbors regression e Scikit-learn 
Esercizi su linear, Ridge e LASSO regressioni su vari dataset"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#10,10,"Regression: Boston housing dataset
Il dataset di 506 istanze mira a predire il costo degli immobili residenziali in 
vari quartieri di Boston nel 1970, impiegando 13 features (es. il tasso di 
crimine, vicinanza al ﬁume, accessibilità alle autostrade). 
from 
sklearn.datasets 
 import 
load_boston
boston 
= 
load_boston
 ()
print
(
""Data shape: {}""
 .
format
(
boston
.
data
.
shape
))
> Data shape: (506, 13)
È possibile combinare due o più features creandone ulteriori non presenti nel 
dataset originale, attività che rientrano nella fase di 
 feature engineering, 
 dove 
si identiﬁcano o costruiscono le caratteristiche salienti. 
In questo esempio combiniamo 2 features alla volta: 
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
> X.shape: (506, 104)
Ora abbiamo 104 features, ottenute dalle 13 originali con tutte le 91 possibili 
combinazioni di coppie.
11"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#11,11,"Classiﬁcazione k-Neighbors (k-NN)
Nel caso più semplice l'algoritmo k-NN considera solo 1 vicino (k=1), che 
risulta il più vicino all'istanza su cui vogliamo esprimere una predizione. 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
1
)
Per k=3: 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
3
)
Per il forge dataset otteniamo:
12
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#12,12,"Esercizio: Scikit-learn, k-NN e valutazione
La libreria Scikit-learn rende disponibile la classe 
 KNeighborsClassiﬁer
  per 
creare modelli basati sull'algoritmo k-NN. 
La funzione 
 score
 ()
 valuta l'accuracy media, cioè il numero di label 
correttamente stimate rispetto al totale delle istanze valutate. 
from 
sklearn.neighbors 
 import 
KNeighborsClassifier
model 
= 
KNeighborsClassifier
 (
n_neighbors
 =
3
)
model
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
clf
.
score
(
X_test
, 
y_test
)))
Esercizio
 : (1) prendere il dataset forge, (2) creare una partizione training/
test, (3) addestrare un classiﬁcatore KNeighborsClassiﬁer  
e (4) valutarne 
l'accuratezza. 
13"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#13,13,"k-NN e decision boundaries
In presenza di 2 features è possibile rappresentare su un piano 
 2d
 la classe 
che verrebbe assegnata dal modello per ogni punto del piano, così da 
riconoscere il conﬁne tra una label e l'altra. Sfruttiamo la libreria 
 mglearn
 : 
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
10
, 
3
))
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
 
 clf 
= 
KNeighborsClassifier
 (
n_neighbors
 =
n_neighbors
 )
.
fit
(
X
, 
y
)
  
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
True
, 
eps
=
0.5
, 
ax
=
ax
, 
alpha
=.
4
)
  
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
  
ax
.
set_title
 (
""{} neighbor(s)""
 .
format
(
n_neighbors
 ))
  
ax
.
set_xlabel
 (
""feature 0""
 )
  
ax
.
set_ylabel
 (
""feature 1""
 )
axes
[
0
]
.
legend
(
loc
=
3
)
Quali considerazioni possiamo fare?
14
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#14,14,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?
15
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#15,15,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?  
Tutte le istanze avrebbero lo stesso neighbors e le predizioni sarebbero 
sempre le stesse.
16
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#16,16,"Esercizio: studio dell'accuracy
Colleziona le accuracy del classiﬁcatore KNeighborsClassiﬁer sul training 
set sia sul test set, al variare di k in [1,10], e valuta gli andamenti. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
66
)
training_accuracy 
 = 
[]
test_accuracy 
 = 
[]
...
plt
.
plot
(
neighbors_settings
 , 
training_accuracy
 , 
label
=
""training accuracy""
 )
plt
.
plot
(
neighbors_settings
 , 
test_accuracy
 , 
label
=
""test accuracy""
 )
plt
.
ylabel
(
""Accuracy""
 )
plt
.
xlabel
(
""n_neighbors""
 )
plt
.
legend
()
17"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#17,17,"Esercizio: studio dell'accuracy
Con k=1 si ha una accuracy massima per il training set. Con 
 k
 più grandi la 
complessità del modello si riduce e l'accuracy decrementa. 
Al contrario, con 
 k=1 
l'accuracy sul test set è più bassa (circa 0.90), 
sintomo che il modello è 
 troppo complesso
 . Allo stesso modo con 
 k
 elevati 
l'accuracy 
 non è soddisfacente 
 poiché il  
modello è 
 troppo semplice
 . 
Per questo dataset un valore ottimale si ottiene intorno a k=6. 
Attenzione:  solitamente i graﬁci non sono sempre così 
 smooth
 .
18
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#18,18,"k-neighbors regression
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
1
)
19
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#19,19,"k-neighbors regression (2)
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
3
)
20
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami: classiﬁcazione e regressione
Finora abbiamo visto problemi di regressione, dove si richiede di predire 
un valore numerico a partire da una istanza in ingresso. 
L'obiettivo della classiﬁcazione è assegnare una 
 label
 ad una istanza in 
ingresso.  
Se le label sono due si parla di 
 binary classiﬁcation
 , altrimenti 
 multiclass
 . 
Il dataset 
 iris
 è un esempio di multiclass classiﬁcation. 
Un modello ben addestrato mostra la capacità di generalizzare sui dati del 
test set, e in fase di produzione. 
Chiaramente se training set e test set hanno molte caratteristiche in 
comune, allora ci aspettiamo che il modello addestrato, se ben progettato, 
sia anche accurato.
3"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#20,20,"Performance: la misura 
 R
2
21
R
2
 è il 
coefﬁciente di determinazione
 , e indica la porzione di varianza della 
variabile y correttamente predetta dal modello (cioè dalle features impiegate), 
perciò è una misura di accuratezza. 
Assume valori in [0,1]. Per valori prossimi a 
 1
 il modello predice 
accuratamente il valore della variabile dipendente 
 y
 in base al valore delle 
features.  
Ad esempio: per 
 R
2
=0.83, il 17% della variazione nei dati non è rappresentato dal 
modello, o perché è dovuto al caso, o perché dipende da un features che non sono stata 
considerate. 
Per valori vicini a 0, il modello si comporta come un predittore che assume 
sempre il valor medio come output, perciò non tiene conto della varianza 
La funzione 
 score()
  del modello Python valuta il valore 
 R
2
 sui dati in input.R2=1−RSS
∑N
i=1(yi−¯y)2=1−∑N
i=1(yi−̂yi)2
∑N
i=1(yi−¯y)2=∑N
i=1(̂yi−¯y)2
∑N
i=1(yi−¯y)2"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#21,21,"scikit-learn: k-neighbors regression
La classe KNeighborsRegressor implementa l'algoritmo di regressione k-neighbors. 
Il parametro 
 n_neighbors
  corrisponde a 
 k
. 
reg 
= 
KNeighborsRegressor
 (
n_neighbors
 =
k
)
Esercizio
 : completa il codice con la classe suddetta e valuta i graﬁci che ottieni:  
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
15
, 
4
))
# create 1,000 data points, evenly spaced between -3 and 3
line 
= 
np
.
linspace
 (
-
3
, 
3
, 
1000
)
.
reshape
(
-
1
, 
1
)
# make predictions using 1, 3, or 9 neighbors
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
...
ax
.
plot
(
line
, 
reg
.
predict
(
line
))
ax
.
plot
(
X_train
, 
y_train
, 
'^'
, 
c
=
mglearn
.
cm2
(
0
), 
markersize
 =
8
)
ax
.
plot
(
X_test
, 
y_test
, 
'v'
, 
c
=
mglearn
.
cm2
(
1
), 
markersize
 =
8
)
ax
.
set_title
 (
""{} neighbor(s)\n train score: {:.2f} test score: {:.2f}""
 .
format
(
n_neighbors
 , 
reg
.
score
(
X_train
, 
y_train
),
reg
.
score
(
X_test
, 
y_test
)))
ax
.
set_xlabel
 (
""Feature""
 )
ax
.
set_ylabel
 (
""Target""
 )
axes
[
0
]
.
legend
([
""Model predictions""
 , 
""Training data/target""
 ,
         
 ""Test data/target""
 ], 
loc
=
""best""
)
22"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#22,22,"scikit-learn: k-neighbors regression
Considerando più istanze durante la predizione si ottiene chiaramente una 
curva più 
 smooth
 .
23
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#23,23,"k-NN nella pratica
L'algoritmo ha due parametri principali: 
 k
 e la 
 misura di distanza
 . 
In generale, si possono usare bassi valori per 
 k
 (es. 5) sebbene occorra 
sperimentare il valore esatto in base al dataset.  
La 
misura euclidea
  si adatta bene in molti scenari. 
Il k-NN è spesso la scelta iniziale per la sua semplicità, ma in alcuni 
contesti non è adatto: 
Per training set molto grandi (numero di istanze e/o features) che 
causano tempi di predizione lenti, a meno di non precomputare 
l'output in una fase preliminare prima di impiegare l'algoritmo in 
produzione. 
Dataset sparsi, cioè con features spesso senza valore.
24"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#24,24,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
.
25"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#25,25,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
. 
from 
sklearn.linear_model 
 import 
LinearRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
60
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
42
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""lr.coef_: {}""
 .
format
(
lr
.
coef_
))
print
(
""lr.intercept_: {}""
 .
format
(
lr
.
intercept_
 ))
> lr.coef_: [ 0.394]
> lr.intercept_: -0.031804343026759746
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.67
> Test set score: 0.66
Nota: coef_ è di tipo NumPy array, avendo dimensione pari al numero di 
features per istanza. 
Cosa possiamo dire con i valori di performance ottenuti?
26"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#26,26,"Esercizio: linear regression e wave dataset
> Training set score: 0.67
> Test set score: 0.66
Sono valori piuttosto bassi.  
I valori sul training e test set sono molto simili, sintomo di 
 underﬁtting
 .  
Per modelli lineari e dataset semplici (es. mono-dimensionali) esiste un 
rischio minore di fare overﬁtting data la semplicità del modello. 
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.
27"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#27,27,"Esercizio: linear regression e wave dataset
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.  
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
0
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.95
> Test set score: 0.61
La differenza tangibile tra training e test set è sintomo di overﬁtting. 
Occorre adattare il modello. 
28"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#28,28,"Richiami: Ridge regression
Nella 
 ridge regression
  si implementa un forma semplice di 
regolarizzazione
 , cioè tecniche per affrontare il problema del overﬁtting. 
I parametri 
 w
 del modello lineare devono rispettare un vincolo 
aggiuntivo: il valore assoluto dei singoli parametri deve essere piccolo.  
Intuitivamente:
  ogni feature può avere un effetto limitato sul valore 
predetto dal modello. 
Prende il nome di L2 regularization. 
La funzione che rappresenta il costo nella ridge è la seguente:
29
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#29,29,"Scikit-learn: Ridge regression
La classe 
 Ridge
  nel modulo sklearn.linear_model implementa la ridge 
regression: 
clf 
=
 Ridge(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro 
 alpha,
  che per default assume valore 1. 
30"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#3,3,"Richiami: overﬁtting e underﬁtting
Supponiamo di avere il seguente dataset che rappresenta la possibilità che 
un cliente acquisti una barca in base a certe sue caratteristiche: 
Se guardi questi dati, che proﬁlo di cliente potenzialmente interessato a 
comprare puoi identiﬁcare dalle features riportate?
4
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#30,30,"Esercitazione: Ridge regression
Esercizio
 : impiegare la ridge regression nel Boston housing dataset.  
Cosa ti aspetti dalle performance che ottieni rispetto alla linear regression 
senza regolarizzazione? 
Esercizio
 : ricava gli score per 
 λ
 pari a 0.1 e 10. Cosa ti aspetti? 
Esercizio
 : crea un graﬁco 2d dove visualizzi i parametri dei tre modelli 
ridge
 , 
ridge10
  e 
ridge01
 . Cosa ti aspetti nella distribuzione dei parametri? 
Esercizio
 : Come pensi che vari lo score 
 R
2
, sul training e sul test set, al 
variare del numero di istanze usate durante l'addestramento?
31"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#31,31,"Richiami: LASSO
Nel modello 
 LASSO
  si impiega la 
 L1-regularization
 , dove alcuni parametri 
assumono valore esattamente pari a 0, ignorando perciò alcune features. 
Può essere interpretato come una sorta di 
 feature selection
 , cioè un 
processo per selezionare le feature più rilevanti nel task in esame. 
Il vantaggio è avere un modello più semplice, più veloce da addestrare, che 
considera solo le features più rilevanti.
32
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#32,32,"Scikit-learn: LASSO
La classe 
 Lasso
  nel modulo sklearn.linear_model implementa il modello 
LASSO:  
clf 
=
 Lasso(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro alpha, che per default assume valore 1. 
Esercizio
 : impiegare LASSO nel Boston housing dataset. Cosa ti aspetti 
dalle performance che ottieni rispetto alla linear e Ridge regression?
33"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#33,33,"Esercitazione: LASSO
Esercizio
 : impiega LASSO nel Boston housing dataset 
Esercizio
 : prova a variare nuovamente 
 λ
 per migliorare le performance. 
34"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#34,34,"Ridge e LASSO: considerazioni
Solitamente si impiega la Ridge come primo approccio.  
Nel caso ci siano molte features, ma solo un sottoinsieme verosimilmente 
rilevanti, LASSO risulta la scelta migliore. 
LASSO inoltre produce modelli più semplici e più facilmente interpretabili 
rispetto a Ridge, utile per investigare il dataset nelle fasi iniziali. 
Scikit-learn implementa la classe 
 ElasticNet
  che combina i due approcci e 
ottiene ottime performance, ma con due iperparametri da impostare, uno 
per L1 e uno per L2 regularization.
35"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#35,35,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
36"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#4,4,"Richiami: overﬁtting e underﬁtting (2)
Cliente di 
 45 anni o più
 , 
meno di 3 ﬁgli
  o 
non divorziato
 . 
Questa ""regola"" è al 
 100%
  accurata. 
Ma una regola sull'età del tipo età=66 OR 52 OR 53 OR 58 è altrettanto 
accurata. 
Dobbiamo ricordarci che il modello dovrà funzionare altrettanto 
accuratamente su dati mai visti in precedenza. 
Le regole che abbiamo escogitato sembrano funzionare, ma sono troppo 
speciﬁche per le istanze del nostro dataset. Se nel test set abbiamo istanze 
simili, allora questo semplice modello può funzionare, ma non è detto che 
funzioni anche in produzione.
5"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#5,5,"Richiami: overﬁtting e underﬁtting (3)
Il nostro obiettivo è sempre trovare il modello più semplice che abbia 
buone performance anche sul test set. 
Costruire un modello troppo complesso rispetto ai dati disponibili crea 
overﬁtting
 .  
Il modello è troppo speciﬁco per le istanze nel training set ma non è capace di 
generalizzare sui dati nel test set. 
Un modello troppo semplice rispetto ai dati disponibili può creare 
fenomeni di 
 underﬁtting
 , cioè scarse performance perﬁno nel training set 
poiché non riesce a catturare tutte le caratteristiche e legami tra le features.
6
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#6,6,"4 datasets
Introduciamo 4 datasets utili per osservare come si comportano diversi 
algoritmi di machine learning implementati in scikit-learn. 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Wisconsin Breast Cancer dataset
  (classiﬁcazione) 
Boston housing dataset
  (regressione)
7"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#7,7,"Classiﬁcazione: Forge dataset
26 istanze, 2 features per istanza, e 2 classi: 
# codice per ottenere il dataset
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
# grafico le istanze
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 ], 
loc
=
4
)
plt
.
xlabel
(
""First feature""
 )
plt
.
ylabel
(
""Second feature""
 )
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
8
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#8,8,"Regressione: wave dataset
Singola feature per istanza, singolo valore reale in output. 
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
40
)
plt
.
plot
(
X
, 
y
, 
'o'
)
plt
.
ylim
(
-
3
, 
3
)
plt
.
xlabel
(
""Feature""
 )
plt
.
ylabel
(
""Target""
 )
Per dataset così piccoli è sempre utile studiare le caratteristiche delle 
istanze su graﬁci.
9
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#9,9,"Classiﬁcazione: Wisconsin Breast Cancer dataset
Misure cliniche associate a patologie tumorali, con label '
 benigno
 ' '
maligno
 '  
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
print
(
""cancer.keys(): \n{}""
 .
format
(
cancer
.
keys
()))
> cancer.keys():
> dict_keys(['feature_names', 'data', 'DESCR', 'target', 'target_names'])
print
(
""Shape of cancer data: {}""
 .
format
(
cancer
.
data
.
shape
))
> Shape of cancer data: (569, 30)
print
(
""Sample counts per class:\n{}""
 .
format
(
{
n
: 
v 
for 
n
, 
v 
in 
zip
(
cancer
.
target_names
 , 
np
.
bincount
 (
cancer
.
target
))}))
> Sample counts per class: {'benign': 357, 'malignant': 212}
print
(
""Feature names:\n{}""
 .
format
(
cancer
.
feature_names
 ))
> Feature names:
['mean radius' 'mean texture' 'mean perimeter' 'mean area'
'mean smoothness' 'mean compactness' 'mean concavity'
'mean concave points' 'mean symmetry' 'mean fractal dimension'
'radius error' 'texture error' 'perimeter error' 'area error'
'smoothness error' 'compactness error' 'concavity error'
'concave points error' 'symmetry error' 'fractal dimension error'
'worst radius' 'worst texture' 'worst perimeter' 'worst area'
'worst smoothness' 'worst compactness' 'worst concavity'
'worst concave points' 'worst symmetry' 'worst fractal dimension']
10"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Alberi di Decisione
Machine Learning "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#1,1,"Sommario
Introduzione ai Decision Trees 
Esempio di applicazione 
Feature split learning 
Decision Stump 
Algoritmo greedy decision tree learning 
Classiﬁcazione mediante Decision Trees
 
2"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#10,10,"Learning Goal 
 
11
Il nostro obiettivo è dunque quello di costruire un albero di 
decisione che minimizzi il Classiﬁcation Error sui dati di 
training, calcolato mediante la metrica di qualità che 
abbiamo deﬁnita. 
Purtroppo questo è un task estremamente difﬁcile: 
•abbiamo un numero esponenziale di possibili alberi da considerare  
•problema NP-hard 
•possiamo però utilizzare delle euristiche che funzionano bene in 
pratica"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#11,11,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto” e consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai diversi valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
12Vediamo informalmente come poter procedere per costruire un albero di 
decisione:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#12,12,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
13Primo problema:
feature
 selection"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#13,13,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
14Secondo problema:
stopping conditions"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#14,14,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
15Chiamata ricorsiva:
chiamata ricorsiva"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#15,15,"Predizioni con Decision Stump 
[feature selection]
 
1622  18
SicuroRoot node: relativo a tutte le osservazioni. 
22: output “Sicuro” 
18: output “Rischioso” 
Ora dobbiamo selezionare una feature  
(feature selection problem)"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#16,16,"Predizioni con Decision Stump 
[feature: Reputazione]
 
17Reputazione22  18
SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Se scegliamo “Reputazione”:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#17,17,"Decision Stump 
[feature: Reputazione]
 
18SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
set  ŷ = “majority value” "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#18,18,"Decision Stump 
[feature: Reputazione]
 
19SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#19,19,"Decision Stump 
[feature: Durata]
 
20SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14Se scegliamo “Durata”:
4 errori 6 errori"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#2,2,"Alberi di Decisione 
Vediamo ora un altro metodo per la classiﬁcazione, molto 
utile nella pratica. 
Un albero di decisione prende come ingresso un oggetto o 
una situazione descritta da un insieme di attributi (features) e 
restituisce una “decisione”. 
Effettua dunque una “classiﬁcazione” della situazione 
presentata in input.  
 
3"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#20,20,"Selezione della migliore feature 
[feature selection]
 
21SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Dobbiamo deﬁnire un criterio per la scelta della migliore feature:
vs."
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#21,21,"Selezione della migliore feature 
[feature selection]
 
22SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 erroriPer far questo consideriamo gli errori già visti in precedenza …….
vs."
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#22,22," 
23SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 errori…… e usiamoli per calcolare il Classiﬁcation Error per ogni feature:
vs.4+4
22 + 18=0 .24+6
22 + 18=0 .25
Scegliamo la feature con il Classiﬁcation Error più basso.
Selezione della migliore feature 
[feature selection]"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#23,23,"Calcolo Classiﬁcation Error 
Abbiamo dunque diviso il calcolo del Classiﬁcation Error in 
due fasi: 
1.
 Per ogni nodo relativo ad un sottoinsieme dei dati, ottenuto 
considerando uno dei possibili valori della feature 
d’interesse, assegniamo il valore della majority class del 
nodo (
 ŷ
 = “majority class”). 
2.
 Calcolo del Classiﬁcation Error considerando come  
predizione per ogni nodo considerato quella assegnata nel 
passo precedente. 
 
24"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#24,24,"Algoritmo per  
Feature Split Selection 
Dato un sottoinsieme M di osservazioni disponibili (nodo 
dell’albero): 
• 
∀
 feature 
 ɸ
j
(
x
): 
•
 Split dei dati M in  base ai valori della feature 
 ɸ
j
(
x
). 
•
 Calcolo del Classiﬁcation Error per il Decision Stump 
della feature 
 ɸ
j
(
x
). 
•
 Scelta della feature 
 ɸ
j*
(
x
) con il Classiﬁcation Error più 
basso. 
 
25"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#25,25,"Tree Learning 
[recursive stump learning]
 
26SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9    0 9    4 4    14
costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Sufﬁciente costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Scarsa 
foglia dell’alberoLa costruzione dell’albero si effettua come segue:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#26,26,"Tree Learning 
[secondo livello]
 
27SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#27,27,"Tree Learning 
[secondo livello]
 
28SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0Reddito
RischiosoAlto Modesto
0     9 4     5
altro 
decision 
stump"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#28,28,"Tree Learning 
[terzo livello]
 
29Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#29,29,"Tree Learning 
[stopping conditions]
 
30Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3 stopping conditions?"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#3,3,"Esempio di applicazione 
[valutazione richiesta prestito]
 
4Richiesta 
PrestitoModello di 
ClassiﬁcazioneSicuro
Rischioso
Input: xi(Output: y i = +1)
(Output: y i = -1)
Vediamo un esempio di applicazione, relativo alla 
valutazione di richieste di prestito da parte di un cliente alla 
propria banca:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#30,30,"Stopping Conditions 
La costruzione di un ramo dell’albero si ferma quando arriviamo 
ad un nodo nel quale si veriﬁca una delle seguenti condizioni: 
1.
 Gli esempi relativi al nodo sono tutti di uno stesso tipo (e.g., 
tutti 
Sicuro
  o tutti 
 Rischioso
 ): scegliamo come foglia il valore in 
questione. 
2.
 Gli esempi relativi al nodo sono di tipo diverso, e non ci sono 
più feature da considerare: scegliamo come foglia il majority 
value. 
3.
 Nel nodo non ci sono più esempi, ma c’è ancora qualche 
feature non considerata nel percorso che porta a quel nodo: 
valore di default (e.g., maggioranza nodo genitore). 
 
31"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#31,31,"Algoritmo greedy decision tree 
learning 
1. Start da un nodo relativo a M esempi 
2. Feature Selection 
3. Per ogni split: 
if
  Stopping Condition 
then
: costruire la foglia con la previsione 
 ŷ 
else
:  decision_tree_learning(nodo relativo allo split) 
 
32decision_tree_learning (nodo) 
Chiamata RicorsivaNon ci sono altre 
operazioni da fareSelezione Feature  
per dividere i dati"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#32,32,"Algoritmo per fare previsioni 
mediante Decision Tree 
Vediamo ora il semplice algoritmo che implementa la funzione 
T(
x
), ossia l’algoritmo che, a fronte di un ingresso 
 x
i
, visita l’albero 
di decisione costruito nella fase di training e fornisce in output una 
previsione 
 ŷ
i
: 
 
33 
if
 tree_node corrente è una foglia 
         
 then
: 
return
  majority class dei punti relativi alla foglia 
        
 else
: 
•
next_node = ﬁglio di tree_node il cui valore della feature 
corrisponde all’input 
•
return
  predict(next_node, input) predict (tree_node, input) "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#33,33,"Riferimenti
 
34
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#4,4,"Esempio di applicazione 
Nel formulare questo problema come un problema di 
apprendimento dobbiamo anzitutto decidere quali proprietà, 
o attributi (features), sono disponibili per descrivere esempi 
(osservazioni) nel dominio. 
In genere, alcune delle caratteristiche prese in considerazione 
i tali casi sono le seguenti: 
•
  reputazione cliente (e.g., ha pagato regolarmente vecchi prestiti?) 
•
reddito cliente 
•
durata prestito  
•
  altre informazioni personali (età, motivo per il prestito, ecc.)  
 
5"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#5,5,"Decision Tree Classiﬁer 
 
6Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniEsempio di decision tree per il problema in esame:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#6,6,"Valutazione richiesta prestito 
 
7
Sicuro
DurataRedditoReputazioneStart
Sicuro
Rischioso
Rischioso
Rischioso
SicuroDurataScarsa
Eccellente
Sufﬁciente
Alto
Modesto
3 anni
5 anni
3 anni
5 annixi = (Reputazione = Scarsa , Reddito = Alto, Durata = 5 anni)  "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#7,7," 
8Richiesta 
PrestitoModello di 
Classiﬁcazione
Input: xiSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1)
Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniRichiesta 
PrestitoSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1) Input: xi
Decision Tree Model 
T(xi)"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#8,8,"Apprendimento albero dai dati
 
9
Reputazione Durata Reddito yi
eccellente 3 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
sufﬁciente 3 anni alto Rischioso
scarso 5 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
scarso 3 anni alto Rischioso
scarso 5 anni modesto Rischioso
sufﬁciente 3 anni alto Rischioso
eccellente 3 anni modesto SicuroT(xi)
Vediamo come sia possibile costruire (ossia apprendere) un decision 
tree a partire da un certo numero di osservazioni:  
Minimizzazione  
funzione di costo"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#9,9,"Metrica di Qualità 
[quality metric]
 
10Errore =#previsioni errate
#esempi
La metrica che si usa misura la frazione delle previsioni 
errate fornite dall’albero:
Ovviamente: 
• miglior valore possibile: 0.0 
• peggior valore possibile: ?"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Algoritmo C4.5"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#1,1,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error  
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5
2"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#10,10,"Guadagno
Introduciamo ora il Guadagno (Gain)  di un attributo A 
Calcolo di Gain(S,A) per ciascun attributo A 
•Riduzione di Entropia attesa a seguito dell’ordinamento del 
set di istanze S basato su A 
Scelta dell’attributo con il valore di Guadagno più elevato 
come nodo dell’albero 
Gain(S,A) = Entropy(S) – Expectation(A)  
 
 
 
dove {S1 ... Si ... Sn} sono le partizioni di S secondo i valori 
dell’attributo A, n il numero di valori distinti di A, |Si| il 
numero di istanze nella partizione Si e |S| il numero totale di 
istanze in S)( )( ),(
1in
iiS EntropySSS Entropy AS Gain ∗ − = ∑
=
11"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#11,11,"Scelta Nodo Radice
Se Outlook è radice dell’albero ci 
sono 3 partizioni sulle istanze (S1 per 
Sunny , S2 per Cloudy, S3 per Rainy ) 
S1 (Sunny) = {istanze 1,2,8,9,11} 
|S1| = 5 (di queste 5 istanze, i 
valori per Play sono 3 No e 2 Yes) 
Entropy(S1) =  
= -2/5 (log2 2/5) – 3/5 (log2 3/5) =        
= -0.4 (-1.322) – 0.6 (-0.737) =  
= 0.53 +0.44 = 0.97 
Analogamente si ottiene  
 Entropy(S2) = 0  
 Entropy(S3) = 0.97 
 12"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#12,12,"Scelta Nodo Radice
Gain(S,Outlook) = Entropy(S) – Expectation(Outlook) = 
= Entropy(S) – [|S1|/|S| * Entropy(S1) + |S2|/|S| * Entropy(S2) +  
+ |S3|/|S| * Entropy(S3)] = 0.94 – [5/14 * 0.97 + 4/14 * 0 + 5/14 * 0.97]  
da cui si ottiene 
Gain(S,Outlook) = 0.247 
Analogamente 
Gain(S,Temperature) = 0.029 
Gain(S,Humidity) = 0.152 
Gain(S,Windy) = 0.048  
In conclusione Gain(S,Outlook)  è il guadagno più elevato e quindi 
Outlook dovrebbe essere scelto come radice dell’Albero di Decisione  
13"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#13,13,"Scelta Nodi Successivi 
Ripetiamo il procedimento per il ramo 
 Sunny
  …
temperatureoutlook
rainy sunnycloudy
hot mild cold?
0    2 1    1 1    04    0
windyoutlook
rainy sunnycloudy
false?
true
1    2 1    14    0 humidityoutlook
rainy sunnycloudy
high?
normal
0    3 2    04    0
14
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#14,14,"Scelta Nodi Successivi 
… e per il ramo Rainy
humidityoutlook
rainy sunnycloudy
high normalMild High False Yes
Cool Normal False Yes
Cool Normal True No
Mild Normal False Yes
Mild High True NoNo Yes Yes 
15
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#15,15,"humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normal
Decision Tree 
windy
high
No Yes falseIn conclusione, si ottiene il seguente Albero di Decisione
16
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#16,16,"Scelta Nodo Radice 
La selezione dell’attributo come nodo radice è eseguita 
valutando il Guadagno di Informazione (Information Gain)  per 
ciascun attributo e scegliendo quello che dà il valore maggioreQual è l’attributo migliore per essere nodo radice dell’albero?
outlook
rainy sunnycloudyhumidity
low hightemperature
cold hotmildwindy
false true
2     
34     
04     
23     
13     
23     
46     
12     
26     
23     
3
17"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#17,17,"Algoritmo C4.5
N.B. Pure: all instances in the subset fall in the same classSet di dati (tabella) attributo-valore
18"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#18,18,"Algoritmo C4.5
Salvatore Ruggieri. 2000. Efficient C4.5.  Technical Report. University of 
Pisa.  
Abstract: We present an analytic evaluation  of the run-time behavior  of the 
C4.5 algorithm which highlights some efficiency improvements. We have 
implemented a more efficient version of the algorithm, called EC4.5, that 
improves on C4.5 by adopting the best among three strategies at each node 
construction. The first strategy uses a binary search of thresholds instead of 
the linear search of C4.5. The second strategy adopts a counting sort method 
instead of the quicksort of C4.5. The third strategy uses a main-memory 
version of the RainForest algorithm for constructing decision trees. Our 
implementation computes the same decision trees as C4.5 with a 
performance gain of up to 5 times.
19"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#19,19,"Esercizio
Creare l’Albero di Decisione (Indice) per la  
Previsione di Rischio per Richieste di Prestito
20"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#2,2,"Algoritmo C4.5
 J. Ross Quinlan. 1993. C4.5: Programs for Machine Learning.   
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. 
 X. Wu, V. Kumar, J. R. Quinlan , J. Ghosh, Q. Yang, H. Motoda, G. J. 
McLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J. 
Hand, and D. Steinberg. 2007. Top 10 Algorithms in Data Mining.  
Knowledge and Information Systems , Volume 14, Issue 1, December 
2007, Pages 1-37, Springer-Verlag New York, Inc. New York, NY, USA.  
DOI=http://dx.doi.org/10.1007/s10115-007-0114-2  
3"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#20,20,"Esercizio
21"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#21,21,"Esercizio
( ) )( )( ,)( )(log )(
12
1
An Expectatio S Entropy AS GainS EntropySSAn Expectatiop p S Entropy
in
iiin
ii
− =∗ =∗− =
∑∑
==
22"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#22,22,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer  
23"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#23,23,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
24"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#24,24,"Algoritmo CART
Breiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984). 
Classification and Regression Trees.  Monterey, CA: Wadsworth & 
Brooks/Cole Advanced Books & Software. 
25"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#25,25,"Algoritmo CART
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Si basa sul Gini Index (o Indice di Gini) 
In corrispondenza di un certo nodo t dell’albero in costruzione, e rispetto alla 
corrispondente partizione del dataset di training, si definisce l’Indice di Gini 
come segue: 
 
      dove p(j/t) è la frequenza relativa (proporzione) della classe j  al nodo t  
L’Indice di Gini misura l’ impurezza ( o disordine)  del dataset corrispondente a t 
•Massimo valore ( 1-1/n c, con nc=numero di classi equiprobabili) quando i 
record sono equamente distribuiti fra tutte le classi 
•Minimo valore (0) quando tutti i record appartengono a una sola classeGini(t)=1−∑
j[p(j/t)]2
26"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#26,26,"Indice di Gini
           
Nel caso di una sola classe: 
                                                     
Nel caso di nc classi equiprobabili 
                                               
 
       dove n è il numero di record del dataset al nodo tGini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−12=0
Gini(t)=1−∑
j((n/nc)/n)2=1−∑
j(1/nc)2=1−nc(1/nc)2=1−1/nc
27"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#27,27,"Indice di Gini
           
C1=0, C2=6 —> P(C1)=0/6=0 , P(C2)=6/6=1  
                             
C1=1, C2=5 —> P(C1)=1/6 , P(C2)=5/6  
                                    
C1=2, C2=4 —> P(C1)=2/6 , P(C2)=4/6  
                                    
C1=3, C2=3 —> P(C1)=3/6=0.5 , P(C2)=3/6=0.5  
                                   Gini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−P(C1)2−P(C2)2=1−0−1=0
Gini(t)=1−1/62−5/62=0.278
Gini(t)=1−2/62−4/62=0.444
Gini(t)=1−0.52−0.52=0.500
28"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#28,28,"Algoritmo CART
29
Criterio di Splitting: Minimizzare l’Indice di Gini della suddivisione  
Quando un nodo t è suddiviso in k partizioni (figli), la qualità della suddivisione è 
calcolata come:  
 
 
 
 
dove  
   ni = numero di record della partizione (figlio) i 
   n = numero di record del dataset al nodo t 
   n i/n = peso dei vari Gini(i) 
Dato il dataset associato al nodo t, si sceglie l’attributo che fornisce il più piccolo 
Gini split(t) per partizionare il dataset 
•E’ necessario enumerare tutti i possibili punti di splitting per ciascun attributo, 
ovverosia tutte le possibili partizioni   
 Ginisplit=k
∑
i=1ni/n*Gini(i)"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#29,29,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
•Scelta della migliore feature utilizzando come metrica il Gini Index   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
30"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#3,3,"Algoritmo C4.5
4"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#4,4,"Algoritmo C4.5
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Sviluppato da J. R. Quinlan nel 1993 come estensione dell’ Algoritmo ID3   
L’Albero ottenuto può essere usato per la classificazione, per cui 
l’Algoritmo C4.5  è spesso indicato come Statistical Classifier 
Basato sulla Teoria dell’Informazione (Claude E. Shannon, A Mathematical 
Theory of Communication , 1948) 
Strategia “divide and conquer” (suddivisione del problema in 
sottoproblemi più semplici e loro risoluzione ricorsiva):  
•Scelta di uno degli attributi come nodo radice 
•Creazione ramo per ciascun valore di quell’attributo 
•Suddivisione delle istanze lungo i rami 
•Ripetizione del processo per ciascun ramo finché tutti le istanze nel ramo hanno 
la stessa classe di appartenenza (si dice che tutti i sottoalberi sono “puri”)  
Assunzione di fondo: quanto più semplice  è l’albero che classifica le 
istanze, tanto meglio  è
 5"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#5,5,"Entropia
Introduciamo il concetto di Entropia (Entropy) [(dal greco antico ἐν   
en, ""dentro"", e τροπή  tropé, “trasformazione"")] 
Entropia in Meccanica Statistica: grandezza interpretata come 
misura del disordine presente in un sistema fisico qualsiasi, 
incluso - come caso limite - l’universo 
Entropia in Teoria dell’Informazione: quantità di incertezza o 
informazione presente in un segnale aleatorio 
•Primo Teorema di Shannon (Codifica di Sorgente): “Una 
sorgente casuale d’informazione non può essere rappresentata 
con un numero di bit (da cui la base 2 del logaritmo) inferiore 
alla sua entropia, cioè alla sua autoinformazione media.”  
Tale teorema ha quindi un’implicazione in termini di 
rappresentazione dati, in quanto l’Entropia può essere 
interpretata anche come la minima complessità descrittiva di 
una variabile aleatoria, ovvero il limite inferiore della 
compressione dei dati 
 6"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#6,6,"Tabella di Dati
7
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#7,7,"Decision Tree
8humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normalwindy
high
No Yes false
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#8,8,"Entropia
Intro duciamo il concetto di Entropia (Entropy) di un set di istanze  
S è un set di istanze (i.e., record della tabella) 
A è una feature (Play nell’esempio) 
{S1 ... Si ... Sn} sono le partizioni  di S secondo gli n valori che può 
assumere A (“Yes” e “No”  nell’esempio) 
{p1 ... pi ... pn} sono le proporzioni  di {S1 ... Si ... Sn} in S 
Si definisce Entropia di S la seguente grandezza
( ) ∑
=∗− =n
ii i p p S Entropy
12log )(
9"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#9,9,"Entropia
Nel caso dell’esempio 
S è il set di 14 istanze 
L’obiettivo è classificare le istanze secondo i valori della 
feature Play, ossia “Yes” e “No”  
La proporzione delle istanze con valore “Yes” è 9 su 14 
(9/14=0.64) 
La proporzione delle istanze con valore “No” è 5 su 14 
(5/14=0.36) 
L’Entropia misura l’ impurezza di S e in questo caso vale  
Entropy(S)= - 0.64 (log2 0.64) – 0.36 (log2 0.36)=  
= - 0.64 (- 0.644) – 0.36 (- 1.474) = 0.41 + 0.53 = 0.94 
10"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcation:  
Boosting"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#1,1,"Sommario
Introduzione 
Ensemble Learning 
Boosting 
AdaBoost
 
2"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#10,10,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
11
Ogni classiﬁcatore esprime un voto in base al valore della 
feature relativa. 1
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
f1(xi) = -1 f2(xi) = +1 f3(xi) = -12 3
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#11,11,"Ensemble Model 
I vari voti espressi dai classiﬁcatori sono combinati insieme 
come segue per formulare la previsione ﬁnale: 
 
12
Se il segno è positivo la previsione vale +1, se è negativo vale -1. 
Questo è un semplice esempio di Ensemble Classiﬁer. 
Si segnala l’importanza dei pesi w
 i
, che devono essere 
individuati mediante un processo di training. F(xi) = sign[w 1 * f 1(xi) + w 2 * f 2(xi) + w 3 * f 3(xi)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#12,12,"Riepilogo sugli 
Ensemble Classiﬁer 
Obiettivo: 
•
 predire un output 
 ŷ
 (+1 o -1 nell’esempio) a partire da un 
input 
 x 
 
13
Apprendimento dell’Ensemble Model: 
• Classiﬁers: f 1(x), f2(x), …, f T(x) 
• Coefﬁcienti: ŵ1, ŵ2, …, ŵT 
Predizione: 
ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#13,13,"Boosting 
xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizionef1(xi)
ŷi = sign[f 1(xi)]
Consideriamo un problema di apprendimento automatico per  
la classiﬁcazione: 
 
14"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#14,14," 
15Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#15,15," 
16Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#16,16," 
17Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#17,17," 
18Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
4     3 3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#18,18," 
19Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
Sicuro4     3 3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#19,19,"L’esempio precedente ci mostra che il decision stump non è 
riuscito a catturare adeguatamente le informazioni dal numero 
limitato di dati disponibili. 
 
20
Quello che fa il Boosting è considerare il decision stump, lo 
valuta, vede come classiﬁca i vari punti, e addestra un 
successivo decision stump (un successivo classiﬁcatore) con il 
quale si focalizza soprattutto sui punti dove il precedente 
classiﬁcatore era debole. Boosting: focus sugli “hard points” "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#2,2,"Boosting question 
 
3
Can a set of weak learners be combined to create a stronger learner? 
(Kearns e Valiant, 1988, 1989)
Sì!!  —>  Boosting  
(Schapire, 1990)
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#20,20," 
21xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
Valutazione
Individuazione
punti critici
(2° classiﬁcatore)Apprendimentoyif1(xi)
… e così viaŷiBoosting:  focus sugli “hard points” 
l’algoritmo di apprendimento 
focalizza l’attenzione 
sui punti “critici”"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#21,21,"Apprendimento su Dati Pesati 
[weighted data]
L’idea è quella di dare maggiore attenzione ai data points 
ritenuti maggiormente importanti: 
•
 ogni data point (
 x
i
, y
i
) è pesato mediante un 
 α
i 
•
 più il punto è ritenuto importante, più è elevato il peso 
 α
i  
•
 l’algoritmo di apprendimento rimane lo stesso 
 
22"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#22,22," 
23Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Redditopeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#23,23," 
24Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Reddito
2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#24,24," 
25Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9Rischioso≤100K$ >100K$Reddito
3     6.5 2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#25,25,"Apprendimento su Dati Pesati 
[weighted data]
Tale approccio comporta che: 
•
 Ogni punto i (
 x
i
, y
i
) conta come 
 α
i
 punti.  
•
 L’algoritmo di apprendimento rimane lo stesso. 
L’apprendimento su dati pesati non è solo relativo ai decision 
stumps. 
Esso si può applicare a molti algoritmi di Machine Learning  
•
 ad esempio, nel gradient ascent per la logistic regression: 
 
26w(t+1)
j w(t)
j+⌘·NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
↵i w(t+1)
j w(t)
j+⌘·NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#26,26,"Boosting   
Algoritmo Greedy per l’apprendimento di “ensemble” dai 
dati. 
Si avvale di weak learners usati come black box.  
Weak Learning Assumption
 : ciascun weak learner deve 
avere prestazioni migliori di un classiﬁcatore “random”. 
Nel Boosting i base classiﬁers sono addestrati in sequenza.  
Per migliorare le prestazioni di un weak learner, l’algoritmo 
deve poter manipolare i dati in ingresso, altrimenti si 
ottengono sempre gli stessi risultati 
 
27"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#27,27,"Boosting framework 
Step principali: 
 
28xi(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
(2° classiﬁcatore e ŵ)Apprendimentof1(xi)
… e così viaŷi = sign[f1(xi)]
ŷi = sign[ŵ1*f1(xi) + ŵ 2*f2(xi)]Individuazione
punti critici
e ricalcolo pesi
Predizioneŵ, f2(xi)weighted data
Idea del Boosting: aggiungere via via 
nuovi classiﬁcatori ottimizzando i pesi 
per focalizzarsi sui punti critici per poi 
apprendere i coefﬁcienti dei diversi 
classiﬁcatori. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#28,28,"AdaBoost 
[Adaptive Boosting]
Proposto da Yoav Freund e Robert E. Schapire nel 1996. 
I due autori hanno vinto il Gödel Prize nel 2003. 
Algoritmo estremamente utile e facile da implementare.  
 
29Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese Society 
for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. Riferimenti:
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in:  Thirteenth  
International Conference on Machine Learning , 1996, pp. 148-156. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#29,29,"AdaBoost 
[Adaptive Boosting]
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
(
minimizza funzione di costo
 ) 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
30ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#3,3,"Introduzione al Boosting 
Il Boosting è una potente tecnica per combinare molti 
classiﬁcatori “di base” (detti anche “weak learners”) per produrre 
una forma di comitato le cui prestazioni sono di gran lunga 
migliori di ciascuno dei classiﬁcatori. 
Originariamente progettato per risolvere problemi di 
classiﬁcazione, può anche essere esteso alla regressione 
(Friedman, 2001).  
 
4"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#30,30,"Evidenziamo qui il processo di training dei vari classiﬁcatori, basato su 
una forma pesata dei punti del training set (linee rosse). 
Ogni peso dipende dalle prestazioni del precedente classiﬁcatore (linee 
verdi)
 
31f1(x) fT(x){↵(1)
i} {↵(T)
i}
f2(x)······
······{↵(2)
i}
ˆy= sign[TX
t=1ˆwtft(x)]
Boosting framework "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#31,31,"Dobbiamo risolvere i seguenti due problemi: 
1. come calcolare il coefﬁciente 
 ŵ
t  
(qual è la mia 
“ﬁducia” in f
 t
(
x
) ?) 
2. come ricalcolare i pesi 
 α
i 
(individuare i punti “critici”) 
 
32
AdaBoost 
[Adaptive Boosting]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#32,32,"Il peso 
 ŵ
t
 rappresenta un “grado di ﬁducia” nella 
 f
t
. Pertanto:
 
33
1° problema: 
Calcolo del coefﬁciente 
 ŵ
t 
ft(x) buona?
ŵt elevato ŵt bassosi no
Una funzione è considerata “buona” se ha un basso training error 
Vediamo come misurare l’errore nel caso di dati “pesati” (“weighted 
classiﬁcation error”) "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#33,33,"Weighted Classiﬁcation Error 
La misura di un errore pesato è simile a quella di un errore calcolato 
su dati non pesati. 
 
34
Vediamo un semplice esempio: 
Data point i yi αi ŷi risultato
1 +1 1.2 +1
 👍
2 -1 0.5 +1
 👎
3 -1 0.7 -1
 👍
… … … …
peso previsioni corrette 1.9
peso previsioni errate 0.5"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#34,34,"Weighted Classiﬁcation Error 
Peso totale degli errori = 
 
35NX
i=1↵iI[ˆyi 6=yi]
NX
i=1↵i
 Peso totale di tutti i data points = 
L’errore “pesato” misura la frazione del peso degli errori: 
weighted error =peso totale degli errori
peso totale di tutti i data points=PN
i=1↵iI[ˆyi 6=yi]
PN
i=1↵i
Miglior valore: 0.0    Peggior valore: random classiﬁer "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#35,35,"Calcolo del coefﬁciente 
 ŵ
t 
[per il classiﬁcatore f
 t
(
x
)]
La formula usata in 
AdaBoost è la seguente:
 
36   
sui training dataŵt
0.01 (1 - 0.01)/0.01 = 99 +2.3
0.5 (1 - 0.5)/0.5 = 1 0
0.99 (1 - 0.99)/0.99 = 0.01 -2.31 weighted error (ft)
weighted error (ft)weighted error (ft)ˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘
Vediamo un esempio: 
ft(x) buona?si
no"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#36,36,"2° problema: Ricalcolo pesi alfa
Come sappiamo, dobbiamo focalizzarci soprattutto sui data point 
dove la funzione commette errori: 
 
37↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yift(xi) classiﬁca 
 bene xi?
decrementa αisi no
incrementa αi
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#37,37,"2° problema: Ricalcolo pesi alfa 
Vediamo un esempio:
 
38↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yi
  ft(xi) = y i ? ŵtmoltiplicare α i per: implicazioni
SI (corretto) +2.3 0.1 diminuisci l’importanza del punto
SI (corretto) 0 1 mantieni la stessa importanza
NO (errore) +2.3 9.98 aumenta l’importanza del punto
NO (errore) 0 1 mantieni la stessa importanza"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#38,38,"Normalizzazione pesi alfa 
La normalizzazione dei pesi 
 α
i
 è suggerita dal fatto che:  
•
 se la funzione sbaglia spesso la classiﬁcazione di 
 x
i
, il peso 
 α
i 
tende ad assumere valori molto alti 
•
 se la funzione prevede spesso correttamente la classiﬁcazione 
di 
x
i
, il peso 
 α
i 
tende ad assumere valori molto bassi 
Tutto ciò può causare instabilità numerica dopo varie iterazioni. 
Si normalizza come segue in modo tale che, dopo ogni iterazione, 
la somma dei pesi 
 α
i
 risulti sempre uguale ad 1:
 
39↵i ↵iPN
j=1↵j"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#39,39,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
40ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#4,4,"Introduzione al Boosting 
Suo impatto per il Machine Learning: 
approccio di default per molti task di computer vision (e.g., 
face detection) 
numerose applicazioni nell’industria 
vince molte “ML competitions” (Kaggle, KDD Cup, ecc.): 
•   
malware classiﬁcation 
•
credit fraud detection 
•
sales forecasting 
•
Higgs boson detection, ecc., ecc.  
Si basa sul concetto di Ensamble Learning  
 
5"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#40,40,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
41ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#41,41,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
42ˆy= sign[TX
t=1ˆwtft(x)]ˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#42,42,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
43ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#43,43,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
44ˆy= sign[TX
t=1ˆwtft(x)]↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yi"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#44,44,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
45ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#45,45,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
46ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#46,46,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
47ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yiˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#47,47,"Riferimenti 
 
48Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese 
Society for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. 
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in: 
Thirteenth  International Conference on Machine Learning , 1996, pp. 148-156. 
Friedman, J.H. “Greedy Function Approximation: A Gradient Boosting Machine”, in: 
Annals of Statistics , 29(5), 2001, pp. 1189-1232. Schapire, R.E.  “The Strength of Weak Learnability”, in: Machine Learning , 5(2), 1990, 
pp. 197–227.
Machine Learning: Classiﬁcation, University of Washington - Coursera, 2017."
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#5,5,"Weak Classiﬁers
L’idea è quella di partire da Simple (o Base o Weak) 
Classiﬁers, come ad es.:  
 
6SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente+
++++-
--
-+
+
Logistic Regression 
con semplici featuresShallow 
Decision TreeDecision Stump
Essi in genere sono caratterizzati da bassa varianza (scarso 
overﬁtting) ma alto bias. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#6,6,"Andamento Errori  
e Bias-Variance Trade-off
 
7
L’andamento del training error e del true error per la classiﬁcation è in 
genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e variance.True Error
Training Error
Model ComplexityClassiﬁcation
Error
(Weak Learner)"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#7,7," 
8
Un approccio per migliorare un classiﬁcatore può essere quello di 
aggiungere più features al classiﬁcatore, ad es.: 
•
 logistic regression: polinomio di grado più elevato, cercando di 
evitare l’overﬁtting 
•
 decision trees: aumentare la profondità dell’albero 
Nel Boosting si fa qualcosa di diverso: si parte da un insieme di weak 
classiﬁers i cui risultati sono opportunamente combinati per ottenere 
uno strong classiﬁer.
Introduzione al Boosting "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#8,8,"Ensemble Classiﬁer 
Alla base del Boosting c’è l’idea dell’Ensemble Classiﬁer, che 
ora vedremo. 
Consideriamo un weak classiﬁer, ad esempio un Decision 
Stump:  
 
9
Esso, a fronte del valore della feature d’interesse, restituisce 
un risultato (+1 o -1). SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Input: xi
Output: ŷ = f( xi)"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#9,9,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
101
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
2 3"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Overﬁtting e Regularization
Machine Learning "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#1,1,"Sommario
Introduzione 
Overﬁtting nella Classiﬁcazione 
Regolarizzazione 
L2 Penalty 
L1 Penalty (sparse solutions)
 
2"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#10,10,"Funzione di Qualità 
nel caso L
 2
 Penalty
 
11
Questo è il caso in cui usiamo la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L2 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.    
                                           Qualit` a totaleL2=l n L(w)  ·kwk2
2
<latexit sha1_base64=""3dst1017rZDOv7BwzXBseJyVJLg="">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#11,11," 
12Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞: 
0<kˆwk2
2<kˆwMLEk2
2
<latexit sha1_base64=""GbN8PXIxssjt4tSdrVsj583mbQM="">AAACT3icdVBNSyNBFOyJ3/Erq0cvjUHwFGaioAcP4rLgQUHBRCEThzedpzbp+aD7ja408+P2J+zRg2ev7mlv4kycg0YtaCiq6vFeV5gqach1H5zaxOTU9MzsXH1+YXFpufFjpWuSTAvsiEQl+iIEg0rG2CFJCi9SjRCFCs/D4c/SP79FbWQSn9F9iv0IrmN5JQVQIQWNnsv3uK+6qIn7YaIG1r8Bsnd5/iYGtp1fFu+7VGB9wt9kj49+jY/Ug0bTbbkj8M/Eq0iTVTgJGo/+IBFZhDEJBcb0PDelvgVNUijM635mMAUxhGvsFTSGCE3fjkrI+UZmgBKeouZS8ZGI7ycsRMbcR2GRjIBuzLhXil95vYyudvtWxmlGGItyEUmFo0VGaFm0i3wgNRJBeTlyGXMBGohQSw5CFGJW1F324Y3//jPptlveVqt9ut3cP6iamWVrbJ1tMo/tsH12yE5Yhwn2hz2xZ/bP+ev8d15qVbTmVGSVfUBt7hUB/7VE</latexit>
Funzione di Qualità 
nel caso L
 2
 Penalty"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#12,12," 
13Come già visto nel caso della Regressione, per la 
determinazione del parametro λ non usiamo mai il Test Set. Ci 
avvaliamo invece: 
del Validation Set , se abbiamo a disposizione un 
numero sufﬁcientemente elevato di osservazioni; 
della Cross-Validation , se abbiamo a disposizione un 
numero limitato di osservazioni. 
Scelta del Parametro di Tuning 
 λ"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#13,13,"Bias-Variance Tradeoff
 
14
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., maximum likelihood (MLE) 
ﬁt per polinomi di grado elevato per λ = 0) Il parametro λ controlla la complessità del modello: "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#14,14,"L
2
 Regularization 
Esempio
 
15
Vediamo l’effetto della L 2 regularization nel caso visto in 
precedenza (caso con 20 features):
Regularization:
Range coefﬁcienti: 
Decision boundary:"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#15,15,"Gradient Ascent 
con la L
 2
 Regularization 
 
16
Come è noto, nell’algoritmo Gradient Ascent dobbiamo 
aggiornare il vettore dei pesi w come segue:
w(t+1) w(t)+↵·rQualit` a totaleL2(w(t))
<latexit sha1_base64=""TzTwdt9I3sAyHV9gN7z7vrC1WrU="">AAAC0nicfVFNb9NAEB2bj5bw0QBHLisipFaVIjtUKscKOHDg0EpNWykJ0XgzaZeuvdbuGChWDogrf5BDpf4Uxk4O0AJjaefNvDc7452stCZwkvyM4lu379xdW7/Xuf/g4aON7uMnR8FVXtNQO+v8SYaBrCloyIYtnZSeMM8sHWfnbxr++BP5YFxxyBclTXI8LczcaGRJua6DMWTgwMIMavgMC/ggfhMYtiGFLYmVKCwQzCWH4OVzolP/rFvWbLcKFL6EM/FNpEXrRNHgQnKZsEuG5f4vctZwAFVbZSS6EmYq3rWdmxkWEtfwXs6B4M3/zrAFHehMu72kn7SmboJ0BXqwsv1p93I8c7rKqWBtMYRRmpQ8qdGz0ZYWnXEVqER9jqc0ElhgTmFSt3tYqBdVQHaqJK+MVW2Sfq+oMQ/hIs9EmSOfhetck/wbN6p4/mpSm6KsmArdNGJjqW0UtDeyYFIz44kZm8lJmUJp9MhM3ijUWpKVbLx5j/T6398ER4N++rI/ONjp7b1evcw6PIPn8rYp7MIevIN9GIKO3kYfoxBxfBh/jb/F35fSOFrVPIU/LP7xC+iqucA=</latexit>
Dobbiamo dunque calcolare il gradiente della funzione di 
qualità totale ( L2 regularized log-likelihood ):
Qualit` a totaleL2=l n L(w)  ·kwk2
2
<latexit sha1_base64=""3dst1017rZDOv7BwzXBseJyVJLg="">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#16,16,"Gradient Ascent 
con la L
 2
 Regularization 
 
17
Nell’algoritmo l’aggiornamento dei pesi possiamo farlo per 
ogni componente w j:
w(t+1)
0 w(t)
0+↵·@Qualit` a totaleL2(w(t))
@w0
w(t+1)
1 w(t)
1+↵·@Qualit` a totaleL2(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j+↵·@Qualit` a totaleL2(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D+↵·@Qualit` a totaleL2(w(t))
@wD
<latexit sha1_base64=""DNhBsTO/Fo42FgAscBocdQBJt+Y="">AAAHvXic3VVLb9NAEJ4GiEt4pXDksiKiKlRK7XCAGxXkwIFDK5G2Up1G680k3dQvvGtCZOWHckDiwA9hdm1BmxQkokpFbGTvvL7sN/NJ3iANpdKu+2WtduPmrbqzfrtx5+69+w+aGw8PVJJnAnsiCZPsKOAKQxljT0sd4lGaIY+CEA+Ds7cmf/gJMyWT+IOepdiP+DiWIym4plCyUfsODfAhAIQxSIihIOsj7Rwy+nGYwXOYU80UBpRzyT6hfQs0bIMHz8hnsEmPDyEhRxQvkQkhyswyskRtWxQnXAqntBtPwJCQmmxmeY0sB0E4n6rMP2tiaTAmounEz/QuYB9yG5XkfaPMgPbEcjGs5pbBe3p3yN6y/SaUGVJ0usDLPKbfy0781cncdsAsZ7+ySs5ljbfynLy/ntOfpsSucU7ezzmZGTXOsVYXelC2/82l2KJ/FV7JpOQ3WVmjyZVqdH0KTf5xhborK9T9TxTqVgoZbZC+ysPffp8bg2bLbbt2sWXDq4wWVGtv0PzqDxORRxhrEXKljj031f2CZ1qKEOcNP1eYcnHGx3hMZswjVP3CXjlz9jRXXCcsxYzJkNkgnkcUPFJqFgVUGXF9qhZzJnhZ7jjXo1f9QsZprjEW5iAtQ7QHKZFJusuQDWWGWnPDHJmMmeAZ1xozybgQFMzpcjPz8Ba7XzYOOm3vRbuz32ntvqkmsw6P4Qlp5MFL2IV3sAc9EPWdeq9+Uh84rx10QicuS2trFeYRXFjO9AeM558S</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#17,17,"Gradient Ascent 
con la L
 2
 Regularization 
 
18
La derivata parziale della funzione di qualità totale rispetto al 
termine generico w j è la seguente:
Componente MLE Componente L 2 Penalty@Qualit` a totaleL2(w(t))
@wj= derivata parziale[ j] 2 w(t)
j
<latexit sha1_base64=""qwKQWDz8o+RHfQa5roWAERrRYkA="">AAAC/HicbVI7b9RAEB47PMLxOkJJs+KEFApO9gUJGqQIGgqKROKSSHfmtF7PhU3WD+2OE4J1VPwEWqjoorT8FwokfgqzjosjyUqz8+033zy83rQy2lEU/Q7ClWvXb9xcvdW7fefuvfv9B2s7rqytwrEqTWn3UunQ6ALHpMngXmVR5qnB3fTwjY/vHqF1uize00mFSS73Cz3XShJTZf8r9GAKc7AgQUHDuGJkgUCzNy1DgPCJ9wa2oW5Zzae/HJmxL9k8h7DgcwPveB8xXud4ylEDGbPHzHxgv87qp4y9LUBc2fG4rXPQKrzmFdvyFBkjy+oj1vvefo7zGp+7Gn6WCVdIOPMZ24g1hiM5T5SxF22Pg+WJZv1BNIzaJS6DuAMD6NbWrP9nmpWqzrEgZaRzkziqKGmkJa0MLnrT2mEl1aHcxwnDQubokqb9YwvxpHaSSlGhFdqIlsTljEbmzp3kKStzSR/dxZgnr4pNapq/TBpdVDVhoXwj0gbbRk5ZzU8BRaYtEkk/OQpdCCWtJEKrhVSKyZrfRo/vI7749ZfBzmgYbwxH288Hm6+7m1mFR/CYbzWGF7AJb2ELxqCCIvgWfA9+hF/Cn+FpeHYuDYMu5yH8t8Jf/wA0VMWQ</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#18,18,"Gradient Ascent 
con la L
 2
 Regularization 
 
19
Questa è la versione dell’algoritmo:
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrQualit` a totaleL2(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
w(t+1)
j w(t)
j+↵⇤(derivata parziale[ j] 2 w(t)
j)
t t+1
<latexit sha1_base64=""2zh0FCvD+/2VMpyTakbuiEO167M="">AAAGWXicnVTLbhMxFL0taSjl1dIlmxEVqC+iTBCCTVEFLEBCqJXoQ8qEyHGc1O28NPa0TUO+kC9ACIlfYAsbjh0zbdoGKsayfX1f5/rY41YaSqWr1S8Tk9dKU+Xr0zdmbt66fefu7Ny9bZXkGRdbPAmTbLfFlAhlLLa01KHYTTPBolYodloHr4x951BkSibxB91LRSNi3Vh2JGcaqmRuskYBtUhQlyTF1CdGIaQu5GUa0Aw9svYE2jasR9B9xLxIPi1B9mgNvYoe2K6R6Rij8UgoRcspg85DfILRYEg6QR/inDg5Kqyeldt2zWFRyGB8hcMLLJKpywPOEN93+ovV7iGniR0UFYa0jXVmYwPgMfiHGEer33SoEqvvsDQxJ+jMZWvC5x3Gms28OIYjbWteGkE1kbWinhd2FuBJ2UoTy8DpXvagT4HK4dMHzxV6Cjly8aeYHUjZmV16tF+czaplyIwV24z0+i8o/hmEU0batn5Jh/AzPBhOTExWnKbhpQ7chkM28eb0IrtnCZ3vmHmPOUC0OR1j28d6lMNjx7G0/JlMfXqL7L1Cu0YryGewHqNvIL7ndJ/GZlr95zkNrsDKUVHzn+iV4m8ILA8dy1CGlsD7soih94qNMNwZLpjlbNndp/9l3rBRc5WY/6qFeDa2hqUr3jU9dm/a7cNHFnOTY8vtuVekObtQrVTt510UfCcskPs2mrPfgnbC80jEmodMqbpfTXWjzzIteSgGM0GuRMr4AeuKOsSYRUI1+vY5HHgPc8V04qUi82ToWaU4G9FnkVK9qAXPiOk9dd5mlJfZ6rnuPG/0ZZzmWsTcAGkZCgukeCbxzgqvLTOhNTOVC0/GHmcZ01pk0mOcQ5nj4TV8+Od3f1HYrlX8J5XaZm1h/aVjZpru0wP7+j6jdXqDe79FvPS59KP0s/Rr6mt5ojxdnhm6Tk64mHka+crzvwEKslZZ</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#19,19,"Funzione di Qualità 
nel caso L
 1
 Penalty
 
20
Questo è il caso in cui usiamo la somma dei valori assoluti 
per la penalty ( L1 Regularization ). E’ in genere chiamata 
“sparse logistic regression ”. 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L1 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.                                              Qualit` a totaleL1=l n L(w)  ·kwk1
<latexit sha1_base64=""kVQvjmORbVIpZXR5YRGRGxnE/j0="">AAACzHicbVFNb9QwEJ2Ej5bla4EjF4sVEhxYJS1SuYAquHBAqJXYbaXd1cpxpq1V24nsCVBFufIfOSDxUxinOWxbRrI98948z9hT1EYHyrLfSXrr9p27W9v3RvcfPHz0ePzk6TxUjVc4U5Wp/HEhAxrtcEaaDB7XHqUtDB4V558if/QdfdCV+0YXNa6sPHX6RCtJDFVjA0sgQPjJewuH0IAEA5qjv8ys+ax4RQyh47iFL7zn7At4z2tTbcD1eEQtawjOQPXaqOrgFeMF32egZOQHI6/77De9wnCmZb7kM8aKvVj7kptzFT9EV+/YZGN/sbcRjNbjSTbNehM3nXxwJjDYwXr8Z1lWqrHoSBkZwiLPalq10pNWBrvRsglYS3UuT3HBrpMWw6rtJ9CJl02QVIkavdBG9CBuKlppQ7iwBWdaSWfhOhfB/3GLhk7erVrt6obQqViItMG+UFBe82hRlNojkYydo9BOKOklEXotpFIMNjzr+B/59dffdOY703x3unP4drL/cfiZbXgOL3h2OezBPnyGA5iBSj4kZWITl35NKW3T7jI1TQbNM7hi6a9/TBq4og==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#2,2,"Metriche di Qualità 
[quality metric]
 
3Errore =#previsioni errate
#esempi
Una metrica che si usa misura la frazione delle previsioni errate 
fornite:
miglior valore possibile: 0.0
Accuracy =#previsioni corrette
#esempi
<latexit sha1_base64=""NDG+msvJ/lTBIqDvf5G5eA2dVhE="">AAACPXicbVA9TxtBEN0jBIiTEBPKNCusSKmsO4JEGiRIGtIRCQOSz7LmhjEZsfeh3TmEdbrfxE/Ir0hBAanoEG1a9oyF+HrV03vzdnZeUhh2Eobnwcyr2ddz8wtvWm/fvV/80F76uOfy0iL1MDe5PUjAkeGMesJi6KCwBGliaD85/tH4+ydkHefZrowLGqRwlPGIEcRLw/bPWOhUqi3E0gKOa72h45FnVdy5c/xrJ9zEOR5ibi2JUF3f2+QoLbiuW61huxN2wwn0cxJNSUdNsTNsX8SHOZYpZYIGnOtHYSGDCqwwGqpbcemoADyGI+p7mkFKblBNTq7159KB5Logq9noiUgPExWkzo3TxE+mIL/dU68RX/L6pYy+DSrOilIow2aRsKHJIoeWfZekD7mpAZqfk+ZMI1jwtVjWgOjF0pfb9BE9vf452VvtRl+7q7/WOpvfp80sqE9qRX1RkVpXm2pb7aieQnWm/qpL9S/4E1wF18HN3ehMMM0sq0cI/t8C0Zew6Q==</latexit>
Un’altra metrica possibile misura la frazione delle previsioni 
corrette:
miglior valore possibile: 1.0"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#20,20," 
21Anche in questo caso vediamo cosa accade a fronte di diversi valori 
del parametro λ: 
Se λ = 0: 
ci riconduciamo alla soluzione standard, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞:  
si va verso soluzioni “sparse”, in cui vari w j sono uguali a zero.
Funzione di Qualità 
nel caso L
 1
 Penalty"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#21,21,"Pesi nella regolarizzazione 
 
22
Nelle ﬁgure seguenti riportiamo un esempio di andamento 
dei pesi w j al variare di 𝜆 per i due tipi di penalty:
L2 Penalty
 L1 Penaltyλ λ "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#22,22,"Riferimenti
 
23
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#3,3," 
4
Overﬁtting 
Apprendimento della Decision Boundary 
j 𝜱j wj
0 1 0.23
1 x{1} 1.12
2 x{2} -1.07
x[1] x[1]x[2] x[2]
Data Points dell’esempio Decision Boundary:
0.23 + 1.12 x[1] - 1.07 x[2] = 0Score( x) < 0 Score( x) > 0"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#4,4," 
5
j 𝜱j wj
0 1 1.68
1 x{1} 1.39
2 x{2} -0.59
3 x{1}^2 -0.17
4 x{2}^2 -0.96
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
1.68 + 1.39 x[1] - 0.59 x[2] - 0.17 x[1]^2  - 0.96 x[2]^2 = 0Score( x) < 0 Score( x) > 0
Decision Boundary:"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#5,5," 
6
j 𝜱j wj
0 1 21.6
1 x{1} 5.3
2 x{2} -42.7
3 x{1}^2 -15.9
4 x{2}^2 -48.6
5 x{1}^3 -11.0
6 x{2}^3 67.0
… … …
11 x[1]^6 0.8
12 x[2]^6 -8.6
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
I valori assoluti di vari coefﬁcienti 
wj sono aumentati(chiaro overﬁtting)Decision Boundary"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#6,6," 
7
x[2]
x[1]x[2]
x[1]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
(overﬁtting ancora più evidente)j 𝜱j wj
0 1 8.7
1 x{1} 5.1
2 x{2} 78.7
… … …
11 x{1}^6 -7.5
12 x{2}^6 3803
13 x{1}^7 21.1
14 x{2}^7 -2406
… … …
39 x[1]^20 -2*10^-8
40 x[2]^20 0.03
I valori assoluti di vari coefﬁcienti 
wj sono aumentati ancora di piùDecision Boundary"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#7,7,"Andamento Errori  
e Bias-Variance Trade-off
 
8
L’andamento del training error e del true error per la 
classiﬁcation è in genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e varianza.True Error
Training Error
Model ComplexityClassiﬁcation
Error
Dato un modello con parametri ŵ, si ha overﬁtting 
se esiste un modello con i parametri stimati w’ tale 
che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
ŵ w’
"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#8,8,"Regularization 
nella Classiﬁcazione
 
9
L’idea è quella di limitare il valore assoluto dei coefﬁcienti w i 
deﬁnendo come segue la funzione di qualità totale (da 
massimizzare nella fase di training): 
Qualità_totale  = misura del “ﬁt” - misura grandezza coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la MLE. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#9,9,"Misura dei Coefﬁcienti 
 
10
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex04)
1"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#1,1,"Sommario
Esercizi su Linear models per la classiﬁcazione"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#10,10,"LinearLogistic: Breast cancer dataset
Esercizio
 : visualizza i parametri del modello. Cosa ti aspetti? 
plt
.
plot
(
logreg
.
coef_
.
T
, 
'o'
, 
label
=
""C=1""
)
plt
.
plot
(
logreg100
 .
coef_
.
T
, 
'^'
, 
label
=
""C=100""
)
plt
.
plot
(
logreg001
 .
coef_
.
T
, 
'v'
, 
label
=
""C=0.001""
 )
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
ylim
(
-
5
, 
5
)
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
legend
()
11"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#11,11,"LinearLogistic: Breast cancer dataset
Regolarizzazioni alte spingono i parametri a 0.  
In alcuni casi (
 mean perimeter
 ), per C=100 e C=1 il coefﬁciente è negativo, 
positivo per C=0.001.  
12
Attenzione: 
 È sbagliato 
pensare che i parametri 
suggeriscano quali features 
determinino direttamente la 
classe (tumore maligno o 
meno). L'importanza della 
feature dipende strettamente 
dal modello preso in 
considerazione."
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#12,12,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature 
impiegando la L1 regularization. 
13"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#13,13,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature impiegando la L1 
regularization. 
for 
C
, 
marker 
in 
zip
([
0.001
, 
1
, 
100
], [
'o'
, 
'^'
, 
'v'
]):
lr_l1 
= 
LogisticRegression
 (
C
=
C
, 
penalty
=
""l1""
)
.
fit
(
X_train
, 
y_train
)
print
(
""Training accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_train
, 
y_train
)))
print
(
""Test accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_test
, 
y_test
)))
plt
.
plot
(
lr_l1
.
coef_
.
T
, 
marker
, 
label
=
""C={:.3f}""
 .
format
(
C
))
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
ylim
(
-
5
, 
5
)
plt
.
legend
(
loc
=
3
)
> Training accuracy of l1 logreg with C=0.001: 0.91
> Test accuracy of l1 logreg with C=0.001: 0.92
> Training accuracy of l1 logreg with C=1.000: 0.96
> Test accuracy of l1 logreg with C=1.000: 0.96
> Training accuracy of l1 logreg with C=100.000: 0.99
> Test accuracy of l1 logreg with C=100.000: 0.98
14"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#14,14,"LinearLogistic: Breast cancer dataset
L'effetto della L1 regularization dipende dal valore del parametro, in modo 
simile al caso della regressione. 
15
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#15,15,"Linear models per la classiﬁcazione multiclass
Alcuni modelli non si adattano facilmente al caso multiclass.  
Un approccio piuttosto semplice è il
  one-vs-rest:
  si creano vari modelli, 
dove ogni modello si addestra a riconoscere una speciﬁca classe. Durante 
la predizione vengono valutati tutti i modelli e quello con score più alto 
determina la classe in output. 
Chiaramente si avranno un insieme di parametri da addestrare per ogni 
classe. 
16"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#16,16,"Linear models per la classiﬁcazione multiclass
Esempio
 : creiamo un dataset con 2 features e 3 classi e impieghiamo il 
Linear SVM per la classiﬁcazione. Il dataset è creato seguendo una 
distribuzione gaussiana. 
from 
sklearn.datasets 
 import 
make_blobs
X
, 
y 
= 
make_blobs
 (
random_state
 =
42
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 , 
""Class 2""
 ])
17
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#17,17,"Linear models per la classiﬁcazione multiclass
linear_svm 
 = 
LinearSVC
 ()
.
fit
(
X
, 
y
)
print
(
""Coefficient shape: ""
 , 
linear_svm
 .
coef_
.
shape
)
print
(
""Intercept shape: ""
 , 
linear_svm
 .
intercept_
 .
shape
)
> Coefficient shape: (3, 2)
>Intercept shape: (3,)
Ogni riga di 
 _coef
  rappresenta il vettore dei parametri per una delle 3 
classi, e le colonne sono le 2 features. 
 intercept_
  è un array 1d che 
memorizza l'intercetta per ogni classe. 
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
[
'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
ylim
(
-
10
, 
15
)
plt
.
xlim
(
-
10
, 
8
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
18"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#18,18,"Linear models per la classiﬁcazione multiclass
Ogni istanza etichettata con la classe 0 è al di sopra della 
 boundary  
deﬁnita dal classiﬁcatore per la class 0. Le istanze delle altre classi al di 
sotto. Stessa cosa per la classe 1 e 2, e i relativi classiﬁcatori. 
Cosa succede se una istanza si trova nel triangolo centrale? 
19
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#19,19,"Linear models per la classiﬁcazione multiclass
Cosa succede se una istanza si trova nel triangolo centrale? 
La classe associata corrisponde alla linea più vicina. 
20
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#2,2,"Richiami: Linear models per la classiﬁcazione
I modelli lineari possono essere impiegati per la classiﬁcazione con 
decision boundary
  che rappresento linee, piani o iperpiani.  
Nella logisitic regression si impiega un modello lineare tradizionale il cui 
output è valutato da una funzione 
 logistic
  (s
igmoid function
 ) che restituisce 
un valore in [0,1] ed indica la probabilità di appartenenza ad una certa 
classe (> 0.5) o meno (< 0.5). 
Il 
gradient descent
  è impiegato per minimizzare la funzione di costo. 
I due algoritmi di classiﬁcazione lineari più famosi sono la 
 logistic 
regression
 , e i 
linear support vector machine
  (o Linear SVM) che vedremo 
in seguito. 
Scikit-learn fornisce la classe 
 linear_model.LogisticRegression
  e 
svm.LinearSVC
  che implementa i due algoritmi.
3"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#20,20,"Linear models per la classiﬁcazione multiclass
Il seguente codice mostra le regioni associate alle predizioni 
mglearn
.
plots
.
plot_2d_classification
 (
linear_svm
 , 
X
, 
fill
=
True
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
                            [
 'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
      
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#21,21,"Linear models per la classiﬁcazione multiclass
22
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#22,22,"Considerazioni sul tuning
Gli iperparametri C e 
 λ
 sono solitamente campionati su scala logaritmica. 
Se si assume che il dataset contenga solo alcune feature rilevanti si può 
testare la L1 regularization, altrimenti si tende a preferire la L2.  
La L1 regularization è utile anche per dare una interpretazione del modello.   
I modelli lineari sono veloci da addestrare, anche su dati sparsi. 
Per dataset con >100.000 istanze si può impiegare il parametro 
 solver='sag'  
nella LogisticRegression e Ridge, che rende l'apprendimento più veloce. 
Altre opzioni sono SGDClassiﬁer e SGDRegressor che implementano 
versioni più scalabili dei relativi algoritmi. 
I parametri possono indicare quali feature siano più rilevanti, nei casi in cui 
le feature sono indipendenti tra loro. 
I modelli lineari hanno buone performance quando il numero di features è 
grande rispetto al numero di istanze. Sono impiegati anche su grandi dataset 
perché spesso gli altri modelli non sono facilmente addestrabili.
23"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#3,3,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
...
4"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#4,4,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
LinearSVC
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
2
, 
figsize
=
(
10
, 
3
))
for 
model, 
ax 
in 
zip
([
LinearSVC
 (), 
LogisticRegression
 ()], 
axes
):
clf 
= 
model
.
fit
(
X
, 
y
)
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
False
, 
eps
=
0.5
,
ax
=
ax
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
ax
.
set_title
 (
""{}""
.
format
(
clf
.
__class__
 .
__name__
 ))
ax
.
set_xlabel
 (
""Feature 0""
 )
ax
.
set_ylabel
 (
""Feature 1""
 )
axes
[
0
]
.
legend
()
Nota: 
 Impieghiamo entrambe le implementazioni, anche se l'algoritmo SVM 
lo vedremo in dettaglio in seguito. 
5"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#5,5,"Linear models per la classiﬁcazione: forge dataset
In questo dataset la decision boundary è rappresentata da una retta. 
6
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#6,6,"Scikit-learn: Logistic regression
In Scikit-learn, la Logistic regression impiega la 
 L2
 di default. 
Il parametro 
 penalty
  speciﬁca quale regolarizzazione impiegare {‘l1’, ‘l2’, 
‘elasticnet’, ‘none’}.  
Il parametro 
 C
 indica il peso della regolarizzazione (valori bassi 
rappresentano una regolarizzazione maggiore), il default è C=1.0  
7"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#7,7,"Richiami: Linear models per la classiﬁcazione
Al variare di 
 C
 si può notare l'effetto sul dataset considerato. 
Con alta regolarizzazione (C basso) il modello sbaglia a classiﬁcare 2 
istanze cercando di considerare la ""maggioranza"" durante la scelta della 
decision boundary. 
Per valori più alti di C la retta si inclina dando più importanza ai 2 punti. 
Un punto rimane comunque non classiﬁcato, ed è impossibile considerarlo 
con una semplice linea retta. 
8
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#8,8,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la 
 linera logistic 
 nel caso del Breast cancer dataset, 
considerando valori di C pari a 0.01, 1 e 100. Commenta i risultati ottenuti 
in termini di accuracy e potenziali fenomeni di over o underﬁtting.
9"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#9,9,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la linera logistic nel caso del Breast cancer dataset, 
considerando valori di C pari a 1, 100 e 0.01. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
logreg 
= 
LogisticRegression
 (C=1)
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_test
, 
y_test
)))
Training set score: 0.953
Test set score: 0.958
Training set score: 0.972
Test set score: 0.965
Training set score: 0.934
Test set score: 0.930
Per C=1 c'è un probabile underﬁtting. Per C=100 (modello più complesso) 
migliorano le performance. Per C=0.01 si incrementa l'underﬁtting iniziale.
10"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Decision Trees (Ex05)
1"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#1,1,"Sommario
Richiami 
scikit-learn e decision trees 
Visualizzazione 
Feature importance 
Decision trees e regressione 
Pruning"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#10,10,"scikit-learn e decision trees
tree 
= 
DecisionTreeClassifier
 (
max_depth
 =
4
, 
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 0.988
> Accuracy on test set: 0.951
Più bassa sul training, ma migliora (meno overﬁtting) sul test.
11"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#11,11,"scikit-learn: visualizzare i decision trees
La funzione 
 export_graphviz
  del modulo 
 tree
 permette di visualizzare 
l'albero. Salva un ﬁle .dot che può essere importato per la visualizzazione. 
from 
sklearn.tree 
 import 
export_graphviz
export_graphviz
 (
tree
, 
out_file
 =
""tree.dot""
 , 
class_names
 =
[
""malignant""
 , 
""benign""
 ], 
feature_names
 =
cancer
.
feature_names
 , 
impurity
 =
False
, 
filled
=
True
)
import 
graphviz
with 
open
(
""tree.dot""
 ) 
as 
f
:
dot_graph 
 = 
f
.
read
()
graphviz
 .
Source
(
dot_graph
 )
Visualizzare il ""comportamento"" di un algoritmo di ML è molto utile per 
spiegarne l'output (
 explaination
 ), in questo caso anche ai non-esperti.
12"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#12,12,"scikit-learn: visualizzare i decision trees
L'albero generato:
13
samples  indica il numero di 
istanze, value  la rispettiva 
suddivisione in base alle label, 
class  la classe majoriy."
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#13,13,"scikit-learn: visualizzare i decision trees
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile feature_importances_ del modello è un array con valori in [0,1] 
dove 1 indica ""predice perfettamente in valore target"". 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
14"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#14,14,"Decision trees e feature importance
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile 
 feature_importances_
  del modello è un array con valori in 
[0,1] dove 1 indica ""predice perfettamente in valore target"". È valutata 
mediante la metrica GINI. 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
15"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#15,15,"Decision trees e feature importance
Si può notare come worst radius è la feature più discriminante. Questo 
indica anche che l'albero è ben costruito avendo questa feature in cima. 
Puoi dire che una 
 feature
  con bassa importance è poco discriminante?
16
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#16,16,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
Esercizio: 
 In questo esempio come costruiresti l'albero di decisione?
17
X[0]X[1]"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#17,17,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
In questo esempio, l'informazione rilevante è contenuta in X[1]. Infatti non 
possiamo dire che un valore alto per la feature X[0] identiﬁca la classe 0, e 
uno basso la classe 1. L'albero effettivamente impiega la feature corretta.
18
X[0]X[1]"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#18,18,"scikit-learn: decision tree per la regressione
La classe DecisionTreeRegressor impiega lo stesso algoritmo in ambito di 
regressione 
import 
pandas 
as 
pd
ram_prices 
 = 
pd
.
read_csv
 (
""data/ram_price.csv""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
ram_prices
 .
price
)
plt
.
xlabel
(
""Year""
)
plt
.
ylabel
(
""Price in $/Mbyte""
 )
19
https://github.com/amueller/introduction_to_ml_with_python/blob/master/data/ram_price.csvSu scala logaritmica per le y si può 
ipotizzare una relazione lineare"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#19,19,"scikit-learn: decision tree per la regressione
Confrontiamo i decision trees con un modelli lineare, con l'accortezza di 
convertire i dati in valori logaritmo altrimenti il modello lineare non può 
funzionare. 
from 
sklearn.tree 
 import 
DecisionTreeRegressor
# use historical data to forecast prices after the year 2000
data_train 
 = 
ram_prices
 [
ram_prices
 .
date 
< 
2000
]
data_test 
 = 
ram_prices
 [
ram_prices
 .
date 
>= 
2000
]
# predict prices based on date
X_train 
 = 
data_train
 .
date
[:, 
np
.
newaxis
]
# we use a log-transform to get a simpler relationship of data to target
y_train 
 = 
np
.
log
(
data_train
 .
price
)
tree 
= 
DecisionTreeRegressor
 ()
.
fit
(
X_train
, 
y_train
)
linear_reg 
 = 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
# predict on all data
X_all 
= 
ram_prices
 .
date
[:, 
np
.
newaxis
]
pred_tree 
 = 
tree
.
predict
(
X_all
)
pred_lr 
 = 
linear_reg
 .
predict
(
X_all
)
# undo log-transform
price_tree 
 = 
np
.
exp
(
pred_tree
 )
price_lr 
 = 
np
.
exp
(
pred_lr
)
Cosa ti aspetti?
20"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#2,2,"Richiami: Decision Trees
Impiegati spesso per la classiﬁcazione e regressione.  
In sintesi creano una albero di nodi if/else che porta ad una certa 
decisione.  
Si può rappresentare come un albero dove le foglie contengono la risposta.
3
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#20,20,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Ma che succede dopo l'ultima data presente nel dataset?
21
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#21,21,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Attenzione: 
 L'algoritmo decision tree non è in grado di fare predizioni su 
nuovi dati con la data oltre a quella contenuta nel dataset. 
22
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#22,22,"scikit-learn: decision tree e pruning
Per limitare l'overﬁtting e la complessità, solitamente è sufﬁciente 
impiegare una tecnica di pre-pruning con uno dei seguenti parametri: 
max_depth
 , 
max_leaf_nodes
 ,  o.  
min_samples_leaf
Nota: 
 min_samples_leaf indica il minimo numero di istanze per foglia. 
Esercizio
 : prova ad addestrare nuovamente il decision trees sul breast 
cancer dataset impostano a turno uno di questi valori e valutare le 
variazioni di accuracy.
23"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#3,3,"Richiami: Decision Trees
In ML, ogni ""domanda"" in un nodo è chiamata comunemente 
 test
, ed è 
spesso codiﬁcata con feature su domini continui, ad esempio: 
la feature 
 i
 è maggiore del valore 
 a
? 
L'algoritmo si focalizza nello scegliere le sequenze if/else che portano ad 
una riposta più velocemente, ovvero sono più 
 informative
  per la variabile 
target.
4"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#4,4,"Dataset two_moons
Toy dataset generato da scikit-learn 
sklearn.datasets.make_moons(
 n_samples=100
 , 
*
, 
shuﬄe=True
 , 
noise=None
 , 
random_state=None
 )
Ogni istanza ha 2 valori. 
Ad esempio, per 75 istanze otteniamo: 
Per la profondità 0 dell'albero, quale test immagineresti?
5
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#5,5,"Decision Trees su two_moons dataset
Depth = 1 
Depth = 2 
...
6
dove [2,32] indica che 2 istanze appartengono 
alla classe 1 e 32 alla classe 2
Se in una foglia ci sono istanze appartenenti 
ad una sola classe allora la foglia si chiama 
pure."
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#6,6,"Richiami: Decision Trees
Ogni test considera una singola feature, perciò la relativa decisione è 
rappresentata come una asse parallelo ad uno degli assi. 
Nella predizione, una volta arrivati ad una foglia, si assegna la classe target 
che appare più spesso nella regione associata. In modo simile per la 
regressione si opera una media dei valori delle istanze nella regione. 
Per dataset grandi, creare foglie pure è molto dispendioso in termini di 
risorse computazione e può creare fenomeni di overﬁtting. 
Si possono implementare tecniche di early stopping limitando la 
profondità dell'albero (
 pre-pruning
 ), oppure rimuovere o fondere foglie 
che contengono poca informazione (
 post-pruning
  o 
pruning
 )
7"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#7,7,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
...
8"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#8,8,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
tree 
= 
DecisionTreeClassifier
 (
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%?
9"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#9,9,"scikit-learn e decision trees
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%? Sì, per come funziona l'algoritmo 
l'albero cresce ﬁno a creare foglie pure che rappresentazione perfettamente 
l'appartenenza delle istanze alle relative label.  
L'accuracy sul test set è leggermente inferiore ai modelli lineari (95% ca). 
Esercizio
 : Prova a impostare una profondità col parametro 
 max_depth  
durante la costruzione dell'oggetto DecisionTreeClassiﬁer. Cosa ti aspetti 
sulle due accuracy?
10"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#0,0,"Machine Learning 
Anno Accademico 2021 - 2022 
  
Richiami di Matematica"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#1,1,"Sommario
Richiami sulle Funzioni Convesse 
Funzioni di più Variabili (Derivate Parziali) 
Gradiente di una Funzione 
Algoritmo di Gradient Descent 
Cenni di Calcolo delle Probabilità
 
2"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#10,10,"Funzioni Convesse 
 11
wg(w)
v wg(w)
g(v)
..g(v)+rg(v)T(w v)g(v)+dg(v)
dw(w v)
caso  
monodimensionale
Per una funzione convessa g(
 w
) differenziabile, il “piano” tangente giace sempre al 
di sotto del graﬁco della funzione:
g(w) g(v)+rg(v)T(w v)"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#11,11,"Funzioni di più Variabili
 
12"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#12,12,"Derivate Parziali di 
Funzioni di più Variabili 
 13g(w0+ w0,w1) g(w0,w1)
 w0
<latexit sha1_base64=""+SgtUNqNwOjhFnklqk6DFaFtyzI="">AAACZXicbVHJTsMwEHXCXrayiAsHLCokEFAlgARHBBw4gkShUlNVEzMtFs6CPaGqonwn4sCZr0AiKT10YU7P772ZsZ/9WElDjvNp2VPTM7Nz8wulxaXlldXy2vqjiRItsCYiFem6DwaVDLFGkhTWY40Q+Aqf/NfrQn96R21kFD5QL8ZmAJ1QtqUAyqlW+c1raxBpZ9+LclsxJe1mrdTJ+CH3blAR8G5xPOKjBjc74Md8su0fX5YOD8pa5YpTdfrFJ4E7ABU2qLtW+ct7jkQSYEhCgTEN14mpmYImKRRmJS8xGIN4hQ42chhCgKaZ9qPJ+F5igCIeo+ZS8T6Jwx0pBMb0Aj93BkAvZlwryP+0RkLti2YqwzghDEWxiKTC/iIjtMwzQP4sNRJBcXPkMuQCNBChlhyEyMkk/4RSnoc7/vpJ8HhSdU+rJ/dnlcurQTLzbJvtsn3msnN2yW7ZHasxwT7YjzVrzVnf9rK9aW/9WW1r0LPBRsre+QVEDroO</latexit>0< | w0|< 
<latexit sha1_base64=""u356CZIh7btrlBj4nRu25R6OhAY="">AAACG3icbVC7TgJBFJ3FF+ILtbSZSIxWZBdNtLAwamGJiTwSIOTucMEJs4/M3NWYDZ/gJ/gVtlrZGVsLC//FATFR8FQn55ybe8/1YyUNue6Hk5mZnZtfyC7mlpZXVtfy6xtVEyVaYEVEKtJ1HwwqGWKFJCmsxxoh8BXW/P7Z0K/doDYyCq/oLsZWAL1QdqUAslI7v+vyY95UNkK8eY6KgN+2U3fwo1nTyF4A7XzBLboj8GnijUmBjVFu5z+bnUgkAYYkFBjT8NyYWilokkLhINdMDMYg+tDDhqUhBGha6ajQgO8kBijiMWouFR+J+HsihcCYu8C3yQDo2kx6Q/E/r5FQ96iVyjBOCEMxXERS4WiREVraysg7UiMRDC9HLkMuQAMRaslBCCsm9nU5+w9vsv00qZaK3n6xdHlQODkdfybLttg222MeO2Qn7IKVWYUJds8e2RN7dh6cF+fVefuOZpzxzCb7A+f9C3UZoAU=</latexit>
Consideriamo una funzione                 di 2 variabili deﬁnita in un campo A.
g(w0,w1)
<latexit sha1_base64=""0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U="">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>
che si chiama rapporto incrementale parziale rispetto a       della     , perché in 
esso consideriamo incrementata soltanto la      , mantenendo inalterata la      .
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
g
<latexit sha1_base64=""M1D3T4qT4zLethYLQWkyJspQDuA="">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
si ha                                 e si può considerare il seguente rapporto incrementale:
(w0+ w0,w1)2A
<latexit sha1_base64=""MtP2/MU/+3Vkqc9/VVk+7SdRHu8="">AAACLXicbVDLSgNBEJz1bXxFPXoZDIKihN0oqLf4OHiMYFTIhtA7tjpk9sFMr0GW/RY/wa/wqicPgnr1N5yNOfiqU01VFz3VQaKkIdd9cYaGR0bHxicmS1PTM7Nz5fmFUxOnWmBTxCrW5wEYVDLCJklSeJ5ohDBQeBZ0Dwr/7Aa1kXF0QrcJtkO4iuSlFEBW6pR3V/3Y+kU86+WdzM35OvcPURHwXvHc4D8HvHyN+zLie51yxa26ffC/xBuQChug0Sm/+RexSEOMSCgwpuW5CbUz0CSFwrzkpwYTEF24wpalEYRo2lm/Ys5XUgMU8wQ1l4r3RfyeyCA05jYM7GQIdG1+e4X4n9dK6XKnnckoSQkjUSwiqbC/yAgtbXXkF1IjERQ/R267C9BAhFpyEMKKqT1myd7D+93+LzmtVb3Nau14q1LfH1xmgi2xZbbKPLbN6uyINViTCXbHHtgje3LunWfn1Xn/Gh1yBplF9gPOxyfAg6f7</latexit>
Sia                    .   Esiste allora un intorno circolare di centro       e 
opportuno raggio 𝜎, contenuto in A. Ne segue che, se:
P
<latexit sha1_base64=""Vg7Q1rv1rOgh7aYWrlRKdHDIMjA="">AAAB/3icbVC7TsNAEDzzDOEVoKQ5ESFRRXZAgjKChjJI5CElVnS+bMIp57O5WyNFVgq+ghYqOkTLp1DwL5yNC0iYajSzo92dIJbCoOt+OkvLK6tr66WN8ubW9s5uZW+/baJEc2jxSEa6GzADUihooUAJ3VgDCwMJnWBylfmdB9BGROoWpzH4IRsrMRKcoZX8fmTNLJs2Z3RQqbo1NwddJF5BqqRAc1D56g8jnoSgkEtmTM9zY/RTplFwCbNyPzEQMz5hY+hZqlgIxk/zo2f0ODEMIxqDpkLSXITfiZSFxkzDwE6GDO/MvJeJ/3m9BEcXfipUnCAoni1CISFfZLgW9mGgQ6EBkWWXAxWKcqYZImhBGedWTGw9ZduHN//9ImnXa95prX5zVm1cFs2UyCE5IifEI+ekQa5Jk7QIJ/fkiTyTF+fReXXenPef0SWnyByQP3A+vgGy5pat</latexit>
P⌘(w0,w1)2A
<latexit sha1_base64=""JoT9dMpAcV9D5gyTs2M1a0HUaxE="">AAACLnicbVDLSgNBEJz1bXxFPXoZDEIECbtRUDz5uHiMYBIhG8LspBMHZx/O9EbCkn/xE/wKr3oSPASvfoaz64IarVNNVTc9VV4khUbbfrOmpmdm5+YXFgtLyyura8X1jYYOY8WhzkMZqmuPaZAigDoKlHAdKWC+J6Hp3Z6nfnMASoswuMJhBG2f9QPRE5yhkTrFYzc0drqd1EbUhbtYDGj5W7wfdew9+uvt7FJXBPS0UyzZFTsD/UucnJRIjlqnOHa7IY99CJBLpnXLsSNsJ0yh4BJGBTfWEDF+y/rQMjRgPuh2kmUc0Z1YMwxpBIoKSTMRfm4kzNd66Htm0md4oye9VPzPa8XYO2onIohihICnh1BIyA5proQJDrQrFCCy9OdATXbOFEMEJSjj3IixabNg+nAm0/8ljWrF2a9ULw9KJ2d5Mwtki2yTMnHIITkhF6RG6oSTB/JEnsmL9Wi9WmPr/Wt0ysp3NskvWB+fwZ2pFA==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#13,13," 14
Se esiste determinato e ﬁnito il seguente limite:
lim
 w0!0g(w0+ w0,w1) g(w0,w1)
 w0
<latexit sha1_base64=""JRgIcRMvmpBtpSOD2ft2HVySLE8="">AAACh3icbVHLTsMwEHTCu7wKHDlgUSEVASUBBBx5HTiCRAGpqaKN2RYL5yF7Q4WifAVfx4EP4UYSeqCUPY1nZzzJOEiUNOQ4H5Y9MTk1PTM7V5tfWFxarq+s3ps41QLbIlaxfgzAoJIRtkmSwsdEI4SBwofg5bLcP7yiNjKO7ugtwW4I/Uj2pAAqKL/+7ikZ+pl3hYqAD/zMybmnZf+ZQOt4wMtjT4PI+k0vLi4qc7JBXul2+G/bLh8VuPk23+Pjtn90+Uh+7tcbTsupho8DdwgabDg3fv3Te4pFGmJEQoExHddJqJuBJikU5jUvNZiAeIE+dgoYQYimm1Xl5XwrNUAxT1BzqXhF4m9HBqExb2FQKEOgZ/N3V5L/7Top9U67mYySlDASZRBJhVWQEVoWHSB/khqJoPxy5DLiAjQQoZYchCjItHimWtGH+/fvx8H9Qcs9bB3cHjXOLobNzLJ1tsmazGUn7IxdsxvWZoJ9WRtW09q25+x9+9g+/ZHa1tCzxkbGPv8G8XPF8g==</latexit>Derivate Parziali di 
Funzioni di più Variabili 
la funzione   si dice parzialmente derivabile rispetto a       nel punto            .
g
<latexit sha1_base64=""M1D3T4qT4zLethYLQWkyJspQDuA="">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
(w0,w1)
<latexit sha1_base64=""Hc3a+9D9w2RpqKTtwd9bdjillWY="">AAACGHicbVC7TsNAEDyHVwgvAyXNiYAUJBTZAQnKCBrKIJGHlFjR+bIJJ84P3a1BkeUf4BP4Clqo6BAtHQX/gm1SkISpRjM72p11Qyk0WtaXUVhYXFpeKa6W1tY3NrfM7Z2WDiLFockDGaiOyzRI4UMTBUrohAqY50pou3eXmd++B6VF4N/gOATHYyNfDAVnmEp986DSC1I/i8cPST+2kmM6rdjJUd8sW1UrB50n9oSUyQSNvvndGwQ88sBHLpnWXdsK0YmZQsElJKVepCFk/I6NoJtSn3mgnThvk9DDSDMMaAiKCklzEf4mYuZpPfbcdNJjeKtnvUz8z+tGODx3YuGHEYLPs0UoJOSLNFciLQ10IBQgsuxyoMKnnCmGCEpQxnkqRunfSuk/7Nn286RVq9on1dr1abl+MflMkeyRfVIhNjkjdXJFGqRJOHkkz+SFvBpPxpvxbnz8jhaMSWaXTMH4/AEzF6Cm</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#14,14," 15
Supponiamo ora che la funzione g sia parzialmente derivabile rispetto a w
 0 
in ogni punto del campo A.  
Per ogni punto di A resta ben determinato il corrispondente valore della 
derivata parziale rispetto a w
 0
. 
Nasce così in A una nuova funzione di due variabili w
 0
, w
 1
 che si chiama 
derivata parziale rispetto a 
 w
0
 della funzione g 
 e si denota ad esempio come 
segue:Derivate Parziali di 
Funzioni di più Variabili 
@g
@w0
<latexit sha1_base64=""VQx8u7rzFuG6k3KXt2wTraBjelE="">AAACI3icbZC5TsNAEIbX3IQrQEmzIkKiCjYgQRlBQxkkApFiyxpvJmHF+tDumEOWH4NH4ClooaJDNBR5F2wTiXOqX98/s7PzB4mShmz73ZqYnJqemZ2bry0sLi2v1FfXzk2caoEdEatYdwMwqGSEHZKksJtohDBQeBFcHZf+xTVqI+PojO4S9EIYRnIgBVCB/PqOO9AgMjcBTRJU5hLeUjbM87z2BW/8zC4I57zm1xt2066K/xXOWDTYuNp+feT2Y5GGGJFQYEzPsRPysvJloTCvuanBBMQVDLFXyAhCNF5WHZbzrdQAxTxBzaXiFcTvExmExtyFQdEZAl2a314J//N6KQ0OvUxGSUoYiXIRSYXVIiO0LBJD3pcaiaD8OXIZcQEaiFBLDkIUMC0iLPNwfl//V5zvNp295u7pfqN1NE5mjm2wTbbNHHbAWuyEtVmHCXbPHtkTe7YerBfr1Xr7bJ2wxjPr7EdZow9TRaVm</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#15,15," 16Derivate Parziali di 
Funzioni di più Variabili 
supposto determinato e ﬁnito.
Analogamente si deﬁnisce la derivata parziale rispetto a      , nel punto    ,  
come il limite
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
P
<latexit sha1_base64=""RzOqhOyvtYvEmUKPvym5XynVJro="">AAAB/nicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBIg8pjqLzZRNOOZ+tuzVSZEXiK2ihokO0/AoF/8LZuICEqUYzO9rdCWIpDLrup1NaWV1b3yhvVra2d3b3qvsHHRMlmkObRzLSvYAZkEJBGwVK6MUaWBhI6AbT68zvPoA2IlJ3OIthELKJEmPBGVrJ9yNrZtm0NR9Wa27dzUGXiVeQGinQGla//FHEkxAUcsmM6XtujIOUaRRcwrziJwZixqdsAn1LFQvBDNL85jk9SQzDiMagqZA0F+F3ImWhMbMwsJMhw3uz6GXif14/wfHlIBUqThAUzxahkJAvMlwL+y/QkdCAyLLLgQpFOdMMEbSgjHMrJradiu3DW/x+mXQade+s3rg9rzWvimbK5Igck1PikQvSJDekRdqEk5g8kWfy4jw6r86b8/4zWnKKzCH5A+fjG1b5loM=</latexit>
lim
 w1!0g(w0,w1+ w1) g(w0,w1)
 w1
<latexit sha1_base64=""AAg1+BW2nr0op9Oj8OQeUTZZmyE="">AAACiHicjVFNTxsxEPVuaaHpB6E99jIiqkT6Ee0CEvSGoAeOIDWAlI1Ws2YSLLwfsmeJkLX/on+uh/6RnvCmORDgwJye38ybZz9nlVaWo+hPEL5Yeflqde11583bd+/XuxsfzmxZG0lDWerSXGRoSauChqxY00VlCPNM03l2fdT2z2/IWFUWv/i2onGO00JNlET2VNr9nWiVpy75SZoRZqmLG0iMml4xGlPOIPLHiUHppltJ6Re1Pm7WpC5qvsEy45Vf4f6iPnyH58j6zZJ/00m7vWgQzQseg3gBemJRJ2n3b3JZyjqngqVGa0dxVPHYoWElNTWdpLZUobzGKY08LDAnO3bz9Br4XFvkEioyoDTMSbqvcJhbe5tnfjJHvrIPey35VG9U82R/7FRR1UyFbI1YaZobWWmUD4HgUhlixvbmBKoAiQaZyShAKT1Z+39q84gfvv4xONsexDuD7dPd3sHhIpk18Ulsii0Riz1xII7FiRgKKf4FEPSDL2EnjMK98Mf/0TBYaD6KpQoP7wB2TsYJ</latexit>
E se avviene che tale derivata esista in ogni punto                , resta ivi 
deﬁnita una nuova funzione delle variabili            che si chiama la derivata 
parziale rispetto a       della                  e si indica ad esempio come segue:
(w0,w1)2A
<latexit sha1_base64=""tqi9PhFGSNkmscV0Id0WgsEszQ0="">AAACBHicbVC7TsNAEDyHVwgvAyXNiQgpSCiyAxKUARrKIJGHlFjW+bIJp5wfulsniqK0fAUtVHSIlv+g4F+wjQsITDWa2dXOjhdJodGyPozC0vLK6lpxvbSxubW9Y+7utXQYKw5NHspQdTymQYoAmihQQidSwHxPQtsbXad+ewxKizC4w2kEjs+GgRgIzjCRXNOsTFzrhE5c+5j2REAvXbNsVa0M9C+xc1ImORqu+dnrhzz2IUAumdZd24rQmTGFgkuYl3qxhojxERtCN6EB80E7syz5nB7FmmFII1BUSJqJ8HNjxnytp76XTPoM7/Wil4r/ed0YBxfOTARRjBDw9BAKCdkhzZVIKgHaFwoQWZocaPI7Z4ohghKUcZ6IcdJRKenDXvz+L2nVqvZptXZ7Vq5f5c0UyQE5JBVik3NSJzekQZqEkzF5JE/k2XgwXoxX4+17tGDkO/vkF4z3L2CgljI=</latexit>
w0,w1
<latexit sha1_base64=""vH1j0jv1BCwogwzrtRh5C1k41l0="">AAAB+nicbVC7TsNAEDzzDOEVoKQ5ESFRoMgOSFBG0FAGiTykxLLOl0045Xy27tZEkclP0EJFh2j5GQr+Bdu4gISpRjO72tnxIykM2vantbS8srq2Xtoob25t7+xW9vbbJow1hxYPZai7PjMghYIWCpTQjTSwwJfQ8cfXmd95AG1EqO5wGoEbsJESQ8EZplJ34tmndOI5XqVq1+wcdJE4BamSAk2v8tUfhDwOQCGXzJieY0foJkyj4BJm5X5sIGJ8zEbQS6liARg3yfPO6HFsGIY0Ak2FpLkIvzcSFhgzDfx0MmB4b+a9TPzP68U4vHQToaIYQfHsEAoJ+SHDtUiLADoQGhBZlhyoUJQzzRBBC8o4T8U4baac9uHMf79I2vWac1ar355XG1dFMyVySI7ICXHIBWmQG9IkLcKJJE/kmbxYj9ar9Wa9/4wuWcXOAfkD6+MbgT2TrA==</latexit>
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
g(w0,w1)
<latexit sha1_base64=""0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U="">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>
@g
@w1
<latexit sha1_base64=""hykhrxvVEe3yRLuSCDFkAUXCvfY="">AAACFXicbVC7TgJBFJ3FF+ILtbQZJSZWZBdNtCTaWGIijwQIuTtccMLsIzN3NWSztZ/gV9hqZWdsrS38F3eRRAVPdeac+5h73FBJQ7b9YeUWFpeWV/KrhbX1jc2t4vZOwwSRFlgXgQp0ywWDSvpYJ0kKW6FG8FyFTXd0kfnNW9RGBv41jUPsejD05UAKoFTqFfc7Aw0i7oSgSYKKh0ny87jrOUnSK5bssj0BnyfOlJTYFLVe8bPTD0TkoU9CgTFtxw6pG2czhcKk0IkMhiBGMMR2Sn3w0HTjySkJP4wMUMBD1FwqPhHxd0cMnjFjz00rPaAbM+tl4n9eO6LBWTeWfhgR+iJbRFLhZJERWqYZIe9LjUSQ/Ry59LkADUSoJQchUjFKQyukeTiz18+TRqXsHJcrVyel6vk0mTzbYwfsiDnslFXZJauxOhPsnj2yJ/ZsPVgv1qv19l2as6Y9u+wPrPcvW36gVg==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#16,16," 17
Osserviamo che, mentre per le funzioni di una variabile la derivabilità in un 
punto implica la continuità in tale punto, non sussiste il fatto analogo per le 
funzioni di due variabili.Derivate Parziali di 
Funzioni di più Variabili 
Possono cioè in un punto esistere le due derivate parziali senza che la 
funzione g sia continua in esso.
Tutte le considerazioni fatte ﬁno ad ora sulle funzioni di due variabili si 
estendono immediatamente al caso delle funzioni di più di due variabili:
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#17,17,"Gradiente
 
18"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#18,18,"Gradiente di una Funzione 
 19
Il gradiente di una funzione è una diretta generalizzazione della nozione di 
derivata per una funzione a più variabili.
rg(w)=2
6666666664@g(w)
@w0
@g(w)
@w1
···
@g(w)
@wn3
7777777775
<latexit sha1_base64=""06VfDqyZDj5rj/n4a5yMYNZXbn4="">AAADBnicpVI9j9QwEHXCxx3L1y6UNBYrpKNZJQcSNCedoKE8JPbupPVqNXFmc9Y5TmRPuFtZ6fkVtFDRIVr+BgX/BWeJBOxSwcjF6L158zxjZ7VWjpLkWxRfuXrt+s7ujcHNW7fv3B2O7h27qrESp7LSlT3NwKFWBqekSONpbRHKTONJdv6y40/eonWqMm9oVeO8hMKopZJAAVqMopEwkGkQhJfki3ZPZJXO/UX7mB9woXFJM85FhoUyHqyFVetlywc8hFhakF7UYEmB9tsd2vYXe7HwSdu2XIhw/kmebshlXpH7j34m9BsINHk/FxdWFWc0HyyG42SSrINvJ2mfjFkfR4vhd5FXsinRkNTg3CxNapr7zkpqDCaNwxrkORQ4C6mBEt3cr9+u5Y8aB1TxGi1Xmq9B/F3hoXRuVWahsgQ6c5tcB/6NmzW0fD73ytQNoZGdESmNayMnrQqfAnmuLBJBd3PkynAJFojQKg5SBrAJv6TbR7o5/XZyvD9Jn0z2Xz8dH77oN7PLHrCHbI+l7Bk7ZK/YEZsyGV1G76MP0cf4Xfwp/hx/+VkaR73mPvsj4q8/AIJp+C8=</latexit>
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>
Data la seguente funzione:
deﬁniamo gradiente di g il vettore le cui componenti sono le derivate 
parziali della funzione:"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#19,19," 
20
w0w1ŵ
ŵ0ŵ1gradiente:
ijrg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
W(t)gGradiente di una Funzione "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#2,2,"Richiami sulle 
Funzioni Convesse
 
3"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#20,20," 
21
w0w1ŵ
ŵ0ŵ1
ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>W(t)gGradiente di una Funzione "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#21,21," 
22w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#22,22,"Derivata Direzionale 
 23
Si può dimostrare che la derivata direzionale secondo n è:
@g
@n=↵·@g
@w0+ ·@g
@w1
<latexit sha1_base64=""+Er6gFVcrheB4cs8jHX92VkksPI="">AAACdXicjVHBbtNAEF2btqSBlgBSOSCkFSkIqVKw00gth0oVvXAMUpNWii1rvJmkq67Xq91xUWX5wGdy4MwncK2dBkFpqZjT2/fe7Oy+SY2SjoLgm+c/WFlde9habz96vLH5pPP02djlhRU4ErnK7WkKDpXUOCJJCk+NRchShSfp+VGjn1ygdTLXx3RpMM5gruVMCqCaSjpfo5kFUUYGLElQ5byqfh90VfEDHoEyZ8AjMc2J32f/kgR1ww6PUqT/84dV1U463aDXH3zo7+3z2yDsBYvqsmUNk873aJqLIkNNQoFzkzAwFJfNpUJh1Y4KhwbEOcxxUkMNGbq4XERV8TeFA8q5Qcul4gsS/+woIXPuMktrZwZ05v7WGvIubVLQbD8upTYFoRbNIJIKF4OcsLLeAfKptEgEzcuRS80FWCBCKzkIUZNFvZQmj1+f5v8G434v3O31Pw+6hx+XybTYS/aavWMh22OH7BMbshET7Ie34W15L7yf/it/2397bfW9Zc9zdqP891efxMJr</latexit>
Detto 
 n
 il versore della direzione 
 n
, la    è il prodotto scalare dei due 
vettori:@g
@n
<latexit sha1_base64=""g3oVOo0czFVRrXmUUHD+5Uu0VMQ="">AAACFHicdVC7TsNAEDzzDOEVoKQ5ESFRWXaIBHQRNJRBIoCURNH62IQT57N1t0aKLLd8Al9BCxUdoqWn4F+wQxDvqeZm9nE7QaykJc97cSYmp6ZnZktz5fmFxaXlysrqiY0SI7AlIhWZswAsKqmxRZIUnsUGIQwUngaXB4V/eoXGykgf0zDGbggDLftSAOVSr8I7fQMi7cRgSIJKB1n2+dBZVu5Vqp5bq+/Vdnb5b+K73ghVNkazV3ntnEciCVGTUGBt2/di6qbFSKEwK3cSizGISxhgO6caQrTddHRJxjcTCxTxGA2Xio9E/NqRQmjtMAzyyhDowv70CvEvr51Qf7ebSh0nhFoUi0gqHC2ywsg8IuTn0iARFD9HLjUXYIAIjeQgRC4meWZFHh9H8//JSc31t93aUb3a2B8nU2LrbINtMZ/tsAY7ZE3WYoJds1t2x+6dG+fBeXSe3ksnnHHPGvsG5/kN2TSgHQ==</latexit>
rg·n
<latexit sha1_base64=""HmMzMEElHE9OTkg5/sPKXqpLV5A="">AAACF3icdVC7TsNAEDzzDOEVoKQ5ESFRRU6IlNAhaCiDRCBSHEXryyacOJ+tuzUCWfkAPoGvoIWKDtFSUvAv2CZIPKe50cys9nb8SElLrvvqTE3PzM7NFxaKi0vLK6ultfVTG8ZGYFuEKjQdHywqqbFNkhR2IoMQ+ArP/IvDzD+7RGNlqE/oOsJeACMth1IApVK/VPY0+Ar4iHtiEBL3CK/IHyb5KynR43ExTbmVWn2v1mjy36RacXOU2QStfunNG4QiDlCTUGBtt+pG1EvAkBQKx0UvthiBuIARdlOqIUDbS/Jjxnw7tkAhj9BwqXgu4teJBAJrrwM/TQZA5/anl4l/ed2Yhs1eInUUE2qRLSKpMF9khZFpS8gH0iARZD9HLjUXYIAIjeQgRCrGaW1ZH59H8//Jaa1S3a3Ujuvl/YNJMwW2ybbYDquyBttnR6zF2kywG3bH7tmDc+s8Ok/O80d0ypnMbLBvcF7eAZzfoGg=</latexit>
cioè è la componente del gradiente sulla retta orientata 
 n
. Questo signiﬁca 
che la derivata direzionale della funzione 
 g 
è massima secondo la 
direzione e verso del vettore gradiente.
Si può avere una visione globale di tutte queste possibili derivate, 
collegando al punto 
 P 
il gradiente della funzione g in tale punto."
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#23,23," 
24w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#24,24," 25
La proprietà citata in precedenza del vettore gradiente, ossia il fatto che il 
gradiente fornisce direzione della pendenza più ripida, è alla base di 
algoritmi di Ricerca Locale che operano in spazi continui.
Tali algoritmi si dividono in due classi principali: 
•
Algoritmi a Salita più Ripida (Hill-Climbing) 
•
Algoritmi a Discesa del Gradiente (Gradient Descent)
Algoritmo Gradient Descent"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#25,25," 
26
w0w1g
ŵ
ŵ0ŵ1
ij
W(t+1)W(t)
- 𝛼 * gradiente
Algoritmo Gradient Descent"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#26,26,"Algoritmo Gradient Descent
 
27w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrg(w(t))k2>✏
w(t+1) w(t) ↵⇤rg(w(t))
t t+1
<latexit sha1_base64=""C1wbNEwaiOAK1Ma17wL9dfyBIzQ="">AAADRnichVJNbxMxEPWmfJTw1cKRy4iIKmlFtBuE4AKq4MKxlUhaKQ6R15kmVr32yp6ltKv9X/wE/gIHuMKJG+KKN42qpEViDtZ4Zt574/GkuVae4vhr1Fi7dv3GzfVbzdt37t67v7H5YOBt4ST2pdXWHabCo1YG+6RI42HuUGSpxoP0+G2dP/iIzitr3tNpjqNMTI06UlJQCI03o32e4lSZUmg1NdtVc4unVk/Kk+pD2U46FbyCGDhwwk9Utm2eFw5BW1BGnamAOQtnVl8hsxMLUvhCaAw4zqG5BRTwSfAvaGdKY1UT6gE6Am5EqsWCflq1l8SpU3XOq8Zlr4a8Bo65V9qac8KZz4XEMpFZyC7hduq2ucYjEs7ZE1jlhKfAhc5nAmAb/qe/IhR3n9dStMxNsANJk6OZXAywOd5oxd14bnDVSRZOiy1sb7zxjU+sLDI0JLXwfpjEOY1K4UjJMK0mLzyGDo7FFIfBNSJDPyrnf1/Bk8ILspCjA6VhHsRlRCky70+zNFRmgmb+cq4O/is3LOjo5ahUJi8IjayFKPzdXMhLp8JSIUyUQyJRd471DkjhBBE6BULKECzCltXzSC6//qoz6HWTZ93efq+1+2YxmXX2iD1mbZawF2yXvWN7rM9k9Dn6Hv2Ifja+NH41fjf+nJc2ogXmIVuxNfYXr1EImg==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#27,27,"Algoritmo Gradient Descent
 
28
Funzione non convessa di due variabili:"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#28,28,"Richiami di Probabilità
 
29"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#29,29,"Variabili Aleatorie
Le quantità di interesse che sono determinate dal risultato di 
un esperimento casuale sono dette 
 variabili aleatorie
 . 
Poiché il valore di una variabile aleatoria è determinato 
dall’esito di un esperimento, possiamo assegnare delle 
probabilità ai suoi valori possibili. 
Esempi di v.a.: risultato del lancio di un dado, risultato del 
lancio di una moneta, ecc.
 
30"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#3,3,"Insiemi Convessi 
 4Un insieme C in uno spazio vettoriale è convesso  se, comunque si scelgano 
due punti v e w appartenenti a C, il segmento che unisce i due punti 
appartiene a C.
Più formalmente:
Un insieme C in uno spazio vettoriale è convesso  se, ∀ v, w ∈ C, e ∀ λ ∈ [0, 1], si 
ha:
 v+( 1  )w2C"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#30,30,"Valore Atteso
Il concetto di Valore Atteso è uno dei più importanti concetti 
in tutta la teoria della probabilità. 
Sia X una variabile aleatoria discreta che può assumere i 
valori x
 1
, x
2
, …, x
 N
. Il Valore Atteso di X è il numero: 
 
31E[X],NX
i=1[xi·P(X=xi)]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#31,31,"Valore Atteso
 
32
Si tratta della media pesata dei valori possibili di X, usando 
come pesi le probabilità che tali valori vengano assunti da X. 
Per questo E[X] è anche detto 
 media
  di X (termine che però è 
sconsigliabile), oppure 
 aspettazione
  (
expectation
 ). "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#32,32,"Valore Atteso
Sia X il punteggio che si ottiene lanciando un dado non 
truccato. Quanto vale E[X]?
 
33E[X]=1 ·1
6+2 ·1
6+3 ·1
6+4 ·1
6+5 ·1
6+6 ·1
6=7
2=3.5
ESEMPIO: lancio di un dado"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#33,33,"Valore Atteso
Si noti che in questo esempio il valore atteso di X non è uno 
dei possibili valori che X può assumere.  
Perciò, anche se E[X] è chiamato 
 valore atteso
  di X, ciò non 
vuole affatto dire che noi ci attendiamo di vedere questo 
valore, ma piuttosto che ci aspettiamo che sia il limite a cui 
tende il punteggio medio del dado su un numero crescente di 
ripetizioni.
 
34
ESEMPIO: lancio di un dado"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#34,34,"Valore Atteso
ESEMPIO: Indicator Function
 
35E[I]=1 ·P(I= 1) + 0 ·P(I= 0) = P(I= 1) = P(A)
Se I[A] è la funzione indicatrice di un evento A, ossia se:
     allora:
Quindi il valore atteso della indicator function di un evento è 
la probabilità di quest’ultimo.I[A],8
<
:1 se A si veriﬁca
0 se A non si veriﬁca"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#35,35,"Valore Atteso
Proprietà di E
 
36
Si riportano qui di seguito alcune proprietà della funzione E (a e 
b sono variabili aleatorie):
E[a+b]= E[a]+E[b]
E[k·a]= k·E[a] (k costante)
E[a·b]= E[a]·E[b]( aebi n d i p e n d e n t i )"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#36,36,"Varianza
 
37
Sia X una variabile aleatoria con media 
 μ
. La varianza di X è la 
quantità:
Var(X),E[(X µ)2]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#37,37,"Varianza
 
38
Esiste una formula alternativa per la varianza, che si ricava in 
questo modo:
ossia:
Var(X)=E[X2] E[X]2Var(X),E[(X µ)2]=
=E[X2 2µX+µ2]=
=E[X2] 2µ·E[X]+µ2=
=E[X2] µ2"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#4,4,"Insiemi Convessi 
 5Vediamolo nel caso a due dimensioni:L’espressione: 
corrisponde dunque ai punti appartenenti al  segmento che unisce i due punti 
v e w, al variare di λ ∈ [0, 1]. v+( 1  )w"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#5,5," 
6wv
λv + (1-λ)wλ(v - w)
λv + (1- λ)w = w + λ(v-w)
λ = 1
λ = 0Insiemi Convessi 
[caso a due dimensioni]
λ > 1
λ < 0λ = 0.6
C"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#6,6," 7Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si ?
si
 noInsiemi Convessi 
[caso a due dimensioni]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#7,7," 8Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si no
si
 noInsiemi Convessi 
[caso a due dimensioni]
"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#8,8,"Funzioni Convesse 
 9con 2[0,1]
wg(w)
v wg(w)
g(v)
.. .
.. g(v)+( 1  )g(w)
g( v+( 1  )w)
 v+( 1  )wg( v+( 1  )w) g(v)+( 1  )g(w)Sia C un insieme convesso. Una funzione                     si dice convessa se, per 
ogni v e w appartenenti al suo dominio di deﬁnizione, vale la seguente proprietà:g:C!R
g:R!R"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#9,9,"Deﬁnizione di Funzione  
Strongly Convex
 
10
Una funzione 
 g
 è detta 
 λ
-strongly convex
  se, per ogni 
 w
, 
v
 e 
α 
∈
 (0, 1), si ha:
Ovviamente, ogni funzione convessa è 0
 -strongly convex.g(↵v+( 1 ↵)w)↵g(v)+( 1  ↵)g(w)  
2↵(1 ↵)kv wk2
wg(w)
v wg(w)
g(v)
.. .
..  
2↵(1 ↵)kv wk2
↵v+( 1 ↵)wg(↵v+( 1 ↵)w)↵g(v)+( 1 ↵)g(w)"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Ensembles di Decision Trees (Ex 06)
1"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#1,1,"Sommario
Ensembles 
Random Forests 
Gradient boosted regression trees"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#10,10,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT.
11"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#11,11,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT. 
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
100
, 
random_state
 =
0
)
forest
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
forest
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
forest
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.972
L'accuracy è più alta rispetto al modello lineare e al DT. 
È possibile fare un tuning con i parametri max_features e l'approccio 
pruning, ma su alcuni dataset i valori di default possono essere già 
sufﬁcienti.
12"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#12,12,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
13"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#13,13,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
Il valore aggregato ha più variabilità e tendenzialmente è più accurato. Il 
modello considera più features dando meno importanza alle singole (es. 
worst radius
 )
14
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#14,14,"Considerazioni sui Random forests (1)
I RF sono modelli di ML molto utilizzati essendo versatili, non richiedono 
lunghe fasi di tuning degli iperparametri e il rescaling dei dati. 
D'altro canto se hai bisogno di una rappresentazione compatta, il singolo 
DT è la soluzione migliore. È impossibile interpretare il valore di centinaia 
o più DT, soprattutto se hanno profondità elevate. 
Le implementazione dei RF possono essere facilmente parallelizzate su più 
CPU. Il parametro 
 n_jobs
  imposta il numero di core da impiegare (un 
valore pari a -1 indica l'uso di tutti i core). 
L'approccio random nei RF rende i modelli generati sugli stessi dati anche 
molto diversi tra loro. Se vuoi ottenere risultati riproducibili, imposta il 
parametro 
 random_state
 . 
I RF non mostrano buone prestazioni su dati sparsi e/o con molte features, 
es. dati testuali. I modelli lineare sono da preferire.
15"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#15,15,"Considerazioni sui Random forests (2)
Un parametro elevato di n_estimators solitamente migliora le performance, 
ma richiede più tempo e memoria per il training. 
Una indicazione per il parametro 
 max_features
  è impostarlo pari a 
sqrt(n_features)
  per la classiﬁcazione, e 
 log2(n_features)
  per la 
regressione.
16"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#16,16,"Ensembles: Gradient boosted regression trees
I 
Gradient boosted regression trees
  (
gradient boosting machines
 ) 
GBRT  
sono un approccio di 
 ensembles
 , e possono essere impiegate sia per la 
classiﬁcazione sia per la regressione.  
A differenza dei RF, gli alberi sono costruiti in modo sequenziale, dove 
ogni albero tenta di risolvere i problemi mostrati in precedenza. 
L'algoritmo è basato sull'approccio 
 boosting
  visto in precedenza.  
Al posto dell'elemento casuale, è impiegato l'approccio pre-pruning. Gli 
alberi prodotti non sono profondi (tipicamenti depth da 1 a 5), e questo 
rende il modello più compatto e veloce nelle predizioni. 
I singoli alberi sono modelli 
 semplici
  (in ML sono spesso chiamati 
 weak 
learners
 ) che producono buone performance su alcune istanze dei dati. 
Rispetto ai RF sono più sensibili alla scelta degli iperparametri, ma possono 
produrre risultati migliori, per questo sono spesso impiegati in scenari reali.
17"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#17,17,"Ensembles: Gradient boosted regression trees
Oltre al pre-pruning e al numero di alberi (
 n_estimators
 ), un altro 
iperparametro fondamentale è il 
 learning_rate,
  che controlla quanto un 
albero deve correggere gli errori prodotti dal precedente. Un valore elevato 
genera modelli più complessi. Allo stesso modo, un valore elevato di 
n_estimators
  incrementa la complessità e può ridurre gli errori commessi. 
In scikit-learn, la classe 
 GradientBoostingClassiﬁer
  implementa gli GBRT. 
Nel caso del Breast cancer dataset, con 100 alberi, con profondità max pari 
a 3 e un learning rate pari a 0.1: 
from 
sklearn.ensemble 
 import 
GradientBoostingClassifier
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.958
18"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#18,18,"Gradient boosted regression trees
Otteniamo una accuracy pari al 100%, potrebbe indicare un possibile 
overﬁtting.  
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate.
19"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#19,19,"Gradient boosted regression trees
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.991
Accuracy on test set: 0.972
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
learning_rate
 =
0.01
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.988
Accuracy on test set: 0.965
Entrambi gli approcci riducono la complessità e l'accuracy sul training set. 
In questo scenario, ridurre la profondità migliora maggiormente le 
performance.
20"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#2,2,"Ensembles
In ML, l'
 ensembles
  un approccio che combina più modelli di ML per 
creare un nuovo modello più soﬁsticato, che potenzialmente aggrega i 
beneﬁci dei singoli modelli.  
Esistono vari approcci di ensembles. Due approcci basati sui decision trees 
(
DT
) si sono dimostrati molto adatti in vari domini: 
Random forests 
Gradient boosted decision trees.
3"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#20,20,"Gradient boosted regression trees
Avendo impiegato 100 alberi, è poco pratico visualizzare le decision 
boundaries di ognuno, ma possiamo analizzare le feature importance. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
plot_feature_importances_cancer
 (
gbrt
)
Noti differenze rispetto ai RF?
21
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#21,21,"Gradient boosted regression trees
I generale otteniamo 
 importance
  simili, ma in questo caso alcune features 
hanno peso pari a 0, cioè sono completamente ignorate dal modello.
22
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#22,22,"Gradient boosted regression trees: considerazioni (1)
Entrambi gli approcci ensembles mostrano buoni risultati su dati simili. Si 
può applicare prima l'approccio RF, piuttosto robusto.  
I GBRT richiedono un tuning degli iperparametri più lungo rispetto ai RF. 
Se il tempo impiegato per la predizione non è soddisfacente, o è 
fondamentale raggiungere una accuracy massima, si può considerare il 
GBRT. 
Come per i RF, i GBRT funzionano bene senza rescaling, e su combinazioni 
di feature binary o continous. Ma non sono efﬁcienti per dataset con molte 
features. 
I due iperparametri fondamentali sono 
 n_estimators
  e 
learning_rate
 . Sono 
dipendenti l'uno dall'altro. Un basso learning rate richiede più alberi per 
raggiungere la stessa complessità. Un valore elevato di 
 n_estimators  
migliora il modello, ma fa tendere il modello all'overﬁtting. 
Tipicamente si imposta 
 n_estimators
  in base alle risorse a disposizione, 
dopodiché si ottimizza il valore 
 learning_rates
 .
23"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#23,23,"Gradient boosted regression trees: considerazioni (2)
Altro iperparametro fondamentale è 
 max_depth
  (o alternativamente 
max_leaf_nodes
 ) per ridurre la complessità per ogni albero. Tipicamente si 
imposta a un valore molto basso, es. < 5.  
Con dataset di larghe dimensioni, si può considerare anche la libreria 
xgboost
 , che possiede una implementazione più ottimizzata.
24"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#24,24,"Esercizio su ensembles
Esercizio
 : impiegare i due approcci ensembles sui restanti dataset introdotti 
nelle precedenti esercitazioni: 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Boston housing dataset
  (regressione) 
Valutare la accuracy rispetto all'approccio basato sulla regressione lineare 
e al singolo decision tree.  
Operare un tuning degli iperparametri per incrementare le performance. 
25"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#25,25,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
26"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#3,3,"Ensembles: Random forests
I 
random forests
  (
RF
) sono una collezione di DTs, ognuno costruito in 
modo leggermo diverso dall'altro durante il training. 
I DTs tendono a mostrare overﬁtting. I RF tendono ad affrontare questa 
problematica: ogni albero può mostrare overﬁtting su certi dati, ma se ne 
costruiamo diversi in modo indipendente e mediamo i risultati complessivi, 
l'effetto dell'overﬁtting si riduce.  
Per creare diversi DTs, introduciamo un elemento casuale durante il 
processo di training, ad esempio selezionando: 
diversi set di training 
diverse features in ogni split test
4"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#4,4,"Scikit-learn: Random forests
In scikit-learn esiste una implementazione dei RF per la classiﬁcazione e 
per la regressione: 
 RandomForestClassiﬁer
  e 
RandomForestRegressor
 . 
Il numero di DTs è un iperparametro del modello RF e si imposta col 
parametro 
 n_estimators
  del costruttore (es. 10). 
Inizialmente si costruisce un 
 bootstrap sample
  dei dati.  
Dal training set estraiamo 
 n_samples
  istanze in modo casuale, con 
ripetizione, e ripetiamo n_samples volte. 
Il dataset che si ottiene è grande come quello originale, ma alcune 
istanze si possono ripetere, altre sono mancanti (approssimativamente 
1/3)  
Es.: se il dataset = ['a', 'b', 'c', 'd'], un possibile bootstrap è ['b', 'd', 'd', 
'c'], un altro ['d', 'a', 'd', 'a']. 
Dopodiché si addestra un DT per ogni boostrap sample.
5"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#5,5,"Scikit-learn: Random forests
Un ulteriore elemento casuale è introdotto in ogni nodo dell'albero. 
Durante la costruzione, invece di scegliere il test migliore, si selezionando 
un modo casuale un sottoinsieme di features e si seleziona la migliore 
considerando tale sottoinsieme.  
Il numero di features è impostato col parametro del costruttore 
max_features
  (ulteriore iperparametro del modello). 
Un valore alto di 
 max_features
  riduce la casualità nel modello RF, ma 
migliora il ﬁt sui dati. Un valore basso produce degli alberi molto 
complessi per raggiungere lo stesso livello di ﬁt. 
Per generare l'output, ogni DT è valutato sull'istanza in input e i risultati 
sono sottoposti a 
 soft voting, 
 cioè le probabilità per ogni 
 label
 ottenute dai 
singoli DT sono mediate e la classe con probabilità più alta è l'output del 
RF.
6"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#6,6,"Scikit-learn: Random forests e two_moons
Esercizio
 : col dataset 
 two_moons
  crea un modello RF con 5 alberi. 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
...
7"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#7,7,"Scikit-learn: Random forests e two_moons
Col dataset two_moons creiamo un modello RF con 5 alberi: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
stratify
 =
y
,
random_state
 =
42
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
5
, 
random_state
 =
2
)
forest
.
fit
(
X_train
, 
y_train
)
I parametri sono salvati nella variabile 
 estimator_
  del modello. 
Possiamo rappresentare i decision boundary per ogni modello: 
fig
, 
axes 
= 
plt
.
subplots
 (
2
, 
3
, 
figsize
=
(
20
, 
10
))
for 
i
, (
ax
, 
tree
) in 
enumerate
 (
zip
(
axes
.
ravel
(), 
forest
.
estimators_
 )):
ax
.
set_title
 (
""Tree {}""
 .
format
(
i
))
mglearn
.
plots
.
plot_tree_partition
 (
X_train
, 
y_train
, 
tree
, 
ax
=
ax
)
mglearn
.
plots
.
plot_2d_separator
 (
forest
, 
X_train
, 
fill
=
True
, 
ax
=
axes
[
-
1
, 
-
1
],
alpha
=.
4
)
axes
[
-
1
, 
-
1
]
.
set_title
 (
""Random Forest""
 )
mglearn
.
discrete_scatter
 (
X_train
[:, 
0
], 
X_train
[:, 
1
], 
y_train
)
8"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#8,8,"Scikit-learn: Random forests e two_moons
Cosa puoi notare riguardo i modelli e i training set? 
9
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#9,9,"Scikit-learn: Random forests e two_moons
Ogni modello ha decision boundaries distinti, dove alcune istanze non sono 
correttamente classiﬁcati.  
Ogni modello ha un training set leggermente distinto: alcune istanze del 
training set complessivo non sono presenti. 
Le boundaries del modello ﬁnale sono più ""smooth"". 
10
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Voting e Stacking ensembles (Ex 07)
1"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#1,1,"Sommario
Voting 
Stacking 
Mutilayer Stacking 
Datasets MNIST e notMNIST 
Altri dataset di immagini 
Esercitazioni"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#10,10,"Multilayer Stacking ensemble
È possibile considerare più blender, ognuno basato su un modello distinto 
(es. regressione lineare, random forest, etc), ottenendo un nuovo layer. 
In questo caso si suddivide il training set in 3 parti. La prima usata nel 
primo layer, come nel caso precedente. La seconda usata dai modelli che 
combinano le predizioni del primo layer. E la restate parte che combina le 
predizioni del secondo layer. 
Nota: scikit-learn non supporta lo stacking.  
Ma ci sono librerie open source, es.  
https://github.com/viisar/brew   
https://github.com/Menelau/DESlib  
11
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#11,11,"MNIST
E’ un dataset molto conosciuto (rielaborato da 
 NIST
 ) di cifre per addestrare sistemi 
di classiﬁcazione basati sulle immagini. 
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others."" 
Contiene 60K immagini di addestramento e 10K di training. 
1998: un linear classiﬁer ha ottenuto 7.6% di errore rate. 
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%. 
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono centrate 
in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare una cifra. 
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#12,12,"MNIST: train.csv e test.csv
Il ﬁle train.csv contiene una matrice con 785 colonne. La prima 
colonna è il 
 label
 della cifra (es. 3) e le restanti colonne sono la 
rappresentazione sequenziale dell’immagine: 
Il ﬁle test.csv ha la stessa rappresentazione senza la prima colonna. 
Esempio di immagini:
13
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#13,13,"MNIST: Considerazioni
Non è impiegato per sistemi avanzati poiché è un task semplice. 
Algoritmi classici di ML raggiungono i 97% di precisione, 
approcci Deep Learning il 99.7% 
Troppo utilizzato: si rischia di ideare nuovi approcci adatti solo per 
questo dataset. 
Molto diverso dai task studiati oggi.
14"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#14,14,"MNIST dataset
scikit-learn include il dataset che può essere facilmente usato: 
from
 sklearn.datasets 
 import
 fetch_openml
import
 numpy 
as
 np
mnist = fetch_openml(
 'mnist_784'
 , version=
 1
, as_frame=
 False
)
mnist.target = mnist.target.astype(np.uint8)
from
 sklearn.model_selection 
 import
 train_test_split
# 50K instanze per il training, 10K validation e 10K test
X_train_val, X_test, y_train_val, y_test = train_test_split(
    mnist.data, mnist.target, test_size=
 10000
, random_state=
 42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=
 10000
, random_state=
 42
)
15"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#15,15,"notMNIST
Simile a MNIST, contiene 10 labels (lettere da A a J), ma ogni lettera 
nel dataset occorre con font diversi, es: 
http://yaroslavvb.blogspot.ﬁ/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione 
notMNIST_small.tar.gz -> test 
16
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#16,16,"fashion-MNIST
Fornito da Zalando. 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc). 
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST: 
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
17
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#17,17,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes. 
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su 
WordNet. In media 1K immagini per concetto. 
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi. 
Open Image
 : 9 milioni di URLs di immagini annotate con bounding 
boxes e migliaia di classi. 
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 
questions per immagini con 10 ground truth answers per question. 
The Street View House Numbers
 : 600K immagini di numeri civici. 
Risultati sperimentali ottenuti per varie architetture avanzate: 
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
18"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#18,18,"Esercitazione: Voting Classiﬁer
Impiega il dataset MNIST con uno split 50K/10K/10K. Scegli almeno tre 
classiﬁcatori e addestrali singolarmente.  
Crea un ensemble Voting, e valutalo sia con approccio soft che hard voting, 
sia sul validation sia sul test set.  
Confronta i risultati con i classiﬁcatori singoli. 
Prova a rimuovere il classiﬁcatore che si comporta meglio e valuta 
nuovamente le prestazioni.
19"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#19,19,"Esercitazione: Stacking Ensemble
Esegui i singoli classiﬁcatori scelti in precedenza e colleziona gli output sul 
validation set. 
Crea un nuovo training set con tali predizioni. Ogni istanza del set è una 
vettore che contiene l'insieme di predizioni per una certa immagine, e il 
target e la classe associata all'immagine. Addestra un classiﬁcatore con tale 
training set. Valutalo sul test set. 
Hai appena realizzato un Stacking ensemble.
20"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#2,2,"Ensembles: Voting
L'approccio voting si ispira alla ﬁlosoﬁa 
 wisdom of the crowd.
  Supponiamo 
di avere più classiﬁcatori (es. Logistic regression, SVM, Random forest, k-
NN). Prendiamo la predizione di ognuno e scegliamo quella che riceve 
""più voti"". Questa forma di aggregazione prende il nome di 
 hard-voting
 . 
Se partiamo da weak classiﬁers con accuracy non soddisfacente, il 
classiﬁcatore risultante può raggiungere accuracy elevate.
3
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#20,20,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
21"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#3,3,"Scikit-learn: Voting
La classe 
 VotingClassiﬁer
  di scikit-learn implementa l'approccio.  
Esercizio
 : completa il seguente frammento di codice basandoti sulla 
documentazione online di VotingClassiﬁer. 
from 
sklearn.ensemble 
 import 
VotingClassifier
(... importa gli altri classificatori ...)
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
...
voting_clf 
 = 
VotingClassifier
 (
    
...
, 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
4"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#4,4,"Scikit-learn: Voting
Impieghiamo SVM, RandomForest e LogisticRegression: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.ensemble 
 import 
VotingClassifier
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
SVC
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
log_clf 
 = 
LogisticRegression
 ()
rnd_clf 
 = 
RandomForestClassifier
 ()
svm_clf 
 = 
SVC
()
voting_clf 
 = 
VotingClassifier
 (
    
estimators
 =
[(
'lr'
, 
log_clf
), (
'rf'
, 
rnd_clf
), (
'svc'
, 
svm_clf
)], 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
5"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#5,5,"Scikit-learn: Voting
(segue)
from 
sklearn.metrics 
 import 
accuracy_score
for 
clf 
in (
log_clf
, 
rnd_clf
, 
svm_clf
, 
voting_clf
 ):
    
clf
.
fit
(
X_train
, 
y_train
)
    
y_pred 
= 
clf
.
predict
(
X_test
)
    
print
(
clf
.
__class__
 .
__name__
 , 
accuracy_score
 (
y_test
, 
y_pred
))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.888
VotingClassifier 0.904
6"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#6,6,"Scikit-learn: Voting
Se i classiﬁcatori impiegati sono in grado di stimare probabilità di 
appartenenza alle singole label, cioè implementano la funzione 
predict_proba(), il voting può valutare le medie delle probabilità prodotte 
da ogni classiﬁcatore.  
L'approccio si chiama 
 soft voting,
  e si seleziona col parametro voting del 
costruttore: 
    
voting
=
'soft'
Esercizio
 : controlla che i classiﬁcatori impiegati in precedenza 
implementino predict_proba() e, in caso affermativo, lancia nuovamente il 
codice precedente e valuta la differenza di performance.
7"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#7,7,"Scikit-learn: Voting
og_clf = LogisticRegression(solver=
 ""lbfgs""
, random_state=
 42
)
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
svm_clf = SVC(gamma=
 ""scale""
, probability=
 True
, random_state=
 42
)
voting_clf = VotingClassifier(
    estimators=[(
 'lr'
, log_clf), (
 'rf'
, rnd_clf), (
 'svc'
, svm_clf)],
    voting=
 'soft'
)
voting_clf.fit(X_train, y_train)
VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),
                             ('rf', RandomForestClassifier(random_state=42)),
                             ('svc', SVC(probability=True, random_state=42))],
                 
 voting='soft'
 )
from
·
sklearn.metrics
 ·
import
·
accuracy_score
for
·
clf
·
in
·
(log_clf,
 ·
rnd_clf,
 ·
svm_clf,
 ·
voting_clf):
    
clf.fit(X_train,
 ·
y_train)
    
y_pred
·
=
·
clf.predict(X_test)
    
print
(clf.__class__.__name__,
 ·
accuracy_score(y_test,
 ·
y_pred))
from sklearn.metrics import accuracy_score
for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.896
VotingClassifier 0.92
8"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#8,8,"Ensembles: Stacking
Un ulteriore approcio ensembles è lo 
 stacking
 , che sta per 
 stacked 
generalization
 . 
Invece di aggregare il risultato con una tecnica di voting, addestriamo un 
ulteriore modello per questo scopo, chiamato 
 blender
  o 
meta learner
 . 
9
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#9,9,"Stacking
Un approccio che spesso si impiega per addestrare il blender è il 
 hold-out 
set
. Inizialmente il training set è suddiviso in 2. Il primo è usato per 
addestrare i modelli nel primo layer, mentre il secondo (held-out) è usato 
per creare le predizioni. Per ogni istanza ci sono 3 predizioni. Tali 
predizioni costituiscono le features di una istanza in un 
 nuovo training set
 , 
il cui valore target è quello originale. Il blender è addestrato sul nuovo set.
10
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al 
Clustering
Machine Learning "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#1,1,"Sommario
Supervised e Unsupervised Learning 
Introduzione al Clustering 
Algoritmo k-means  
Algoritmo k-means++
 
2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#10,10,"k-means Clustering 
 
11
Vediamo un esempio di esecuzione dell’algoritmo nel caso in cui i 
data points siano quelli riportati in ﬁgura. 
Supponiamo di scegliere come numero di cluster: k=3 "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#11,11,"k-means Clustering 
 
12
µ1,µ2,...,µ k
Scelta del numero di cluster k e inizializzazione dei k centroidi:
Esempio per k = 3
μ1
μ2
μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#12,12,"Voronoi Tesselation 
 
13
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#13,13,"k-means Clustering 
 
14
zi argmin
jkµj xik2
Assegnazione delle osservazioni al più vicino centroide:
μ1
μ2
μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#14,14,"k-Means Clustering 
 
15
Si ricalcolano i centroidi come media delle osservazioni assegnate 
ad ogni cluster:
µj=1
njX
i:zi=jxi
μ1
μ2μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#15,15,"k-Means Clustering 
 
16
zi argmin
jkµj xik2
Si riassegnano le osservazioni al centroide più vicino:
… e così via ﬁno al raggiungimento di una cond. di terminazione.μ1
μ2μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#16,16,"Algoritmo k-means 
 
17
L’algoritmo può essere pertanto sintetizzato come segue:
Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj xik2; assegniamo i data points al cluster center pi` u vicino
for j=1,. . . ,k
µj=1
njX
i:zi=jxi; aggiorniamo ciascun cluster center come media dei suoi data points"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#17,17,"Algoritmo k-means 
come Coordinate Descent 
 
18µj argmin
µX
i:zi=jkµ xik2
Si noti che la formula per il calcolo delle medie: 
è equivalente alla seguente espressione: µj=1
njX
i:zi=jxi"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#18,18,"Algoritmo k-means 
come Coordinate Descent 
 
19
Abbiamo dunque la seguente versione equivalente dell’algoritmo:
dove si alternano le minimizzazioni (a): z dato 
 μ
 e (b): 
 μ
 dato z. Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj xik2; assegniamo i data points al cluster center pi` u vicino
for j=1,. . . ,k
µj argmin
µX
i:zi=jkµ xik2; calcolo centroidi che minimizzano la somma del
; quadrato delle norme per i loro data points"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#19,19,"In genere k-means converge ad un ottimo locale. 
L’algoritmo è molto sensibile all’inizializzazione dei centroidi. 
Vediamo un esempio: 
 
20
Convergenza di k-means "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#2,2,"Supervised vs. Unsupervised 
Learning
Come sappiamo, molti problemi e metodi di Machine Learning 
rientrano in una delle due seguenti categorie: apprendimento 
supervisionato
  o 
non supervisionato
 . 
Gli esempi visti ﬁno ad ora rientrano nel dominio 
dell’apprendimento supervisionato: 
•
In quei casi (linear regression, logistic regression, ecc.) si 
hanno delle osservazioni che, a fronte di una certa 
conﬁgurazione delle features, ci dicono quale sia la 
soluzione corretta.
 
3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#20,20," 
21
Convergenza di k-means 
Data la scelta dei centroidi iniziali mostrata nella ﬁgura a sinistra, 
si ottiene il risultato mostrato a destra:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#21,21," 
22
Convergenza di k-means 
Altra scelta dei centroidi iniziali:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#22,22," 
23
Convergenza di k-means 
Altra scelta dei centroidi iniziali:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#23,23,"k-means++ 
 
24Arthur, D. e Vassilvitskii, S. “k-means++: the advantages of careful seeding”, in Proc. of the 
18th ACM-SIAM Symp. on Discrete Algorithms , 2007, pp. 1027-1035.
Bahmani, B., Moseley, B., Vattani, A., Kumar, R. e Vassilvitskii, S. “Scalable k-means++”, in 
Proc. of VLDB , 2012.
Come abbiamo visto, l’inizializzazione di k-means è critica ai ﬁni 
della qualità dell’ottimo locale trovato. 
Ora vediamo k-means++, un metodo che consiste in una 
particolare inizializzazione dei centroidi che in genere dà buoni 
risultati. 
Riferimenti:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#24,24,"k-means++ 
 
25
Smart initialization
 : 
1.
 Scegliere il primo centroide in modo casuale tra tutti i data 
points. 
2.
 Per ogni osservazione 
 x
i
, calcolare la distanza d(
 x
i
) tra 
x
i
 e il più 
vicino centroide. 
3.
 Scegliere il nuovo centroide tra i data point, con la probabilità 
di 
x
i
 di essere scelto proporzionale a d(
 x
i
) , ossia al quadrato 
della distanza tra 
 x
i
 e il centroide più vicino già scelto. 
4.
 Ripeti gli step 2 e 3 ﬁno ad arrivare a scegliere k centroidi.
2 "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#25,25,"k-means++: esempio 
 
26
Vediamo un esempio di inizializzazione con k=3, relativo alle 
osservazioni in ﬁgura:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#26,26," 
27
Scelta random del primo cluster center:
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#27,27," 
28
Scelta del secondo cluster center. Si sceglie il punto con la 
probabilità maggiore, dove la probabilità è proporzionale a d(
 x
). 
In ﬁgura sono mostrate le varie distanze. 
2 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#28,28," 
29
Supponiamo che venga scelto il secondo cluster center in verde: 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#29,29," 
30
Scelta dell’ultimo cluster center. Di nuovo, si sceglie il punto con 
la probabilità maggiore, dove la probabilità è proporzionale a 
d(
x
i
), quadrato della distanza tra il punto i e il più vicino 
centroide: 
2 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#3,3,"Supervised vs. Unsupervised 
Learning
Nel caso non supervisionato ci troviamo in una situazione più 
impegnativa, nella quale abbiamo le varie osservazioni 
caratterizzate dai vari valori delle 
 features
 , ma per le quali non 
abbiamo disponibili le soluzioni. 
In questa situazione, in un certo senso dobbiamo lavorare alla 
cieca. 
La situazione è deﬁnita 
 unsupervised
  proprio perché nei 
 data 
points
  disponibili ci manca la risposta che può supervisionare la 
nostra analisi. 
 
4"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#30,30," 
31
Supponiamo che il cluster center scelto sia quello in blu. I tre 
centroidi scelti sono quelli con cui inizializziamo l’algoritmo k-
means. 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#31,31,"k-means++: pros & cons 
 
32
Eseguire k-means++ per individuare i centroidi iniziali è 
certamente più oneroso computazionalmente rispetto alla scelta 
random dei suddetti centroidi. 
Per contro, l’esecuzione di k-means con l’inizializzazione di k-
means++ è spesso più efﬁciente, nel senso che converge in genere 
più rapidamente. 
In generale possiamo dire che k-means++ tende a migliorare la 
qualità dell’ottimo locale trovato e diminuire il tempo di 
esecuzione. "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#32,32,"Cluster Heterogeneity 
 
33
L’algoritmo k-means cerca di minimizzare la somma dei quadrati 
delle distanze (
 distortion
 ): 
Come abbiamo visto, in genere l’algoritmo trova un minimo 
locale. costo kmeans =kX
j=1X
i:zi=jkµj xik2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#33,33,"Cluster Heterogeneity 
 
34
Confrontiamo i seguenti due risultati: la ﬁgura a destra è 
sicuramente migliore. La ﬁgura a sinistra è più “eterogenea”. 
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#34,34,"Cosa accade al crescere di k 
 
35
Consideriamo il caso estremo k = N: 
•
 Signiﬁca che ogni cluster center è un data point. 
•
 Il costo (heterogeneity) è uguale a zero. 
Il costo (heterogeneity) decresce al crescere di k. "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#35,35,"Scelta del numero di cluster k 
 
36
“Elbow Method”: Un’euristica usata è quella di scegliere un punto 
che si trova nel “gomito” della curva: 
k (# di cluster)(minimo della 
cluster heterogeneity)costo_k_means 
minimo
123456"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#36,36,"Riferimenti
 
37
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#4,4,"Clustering 
Dobbiamo chiederci quale tipo di analisi sia possibile in tale 
contesto. 
Possiamo ad esempio cercare di comprendere le relazioni tra le 
osservazioni. 
Un approccio che possiamo usare in tali situazioni è quello della 
cluster analysis
 , o 
clustering
 . 
L’obiettivo del 
 clustering
  è quello di veriﬁcare, date le features in 
input, se le osservazioni disponibili ricadono all’interno di gruppi 
relativamente distinti tra di loro. 
 
5"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#5,5,"Clustering 
Il 
clustering
  è in effetti una delle tecniche più utilizzate per la 
exploratory data analysis
 . 
In tante discipline, dalle scienze sociali alla biologia alla computer 
science, gli studiosi cercano di avere delle prime “intuizioni” sui 
dati di cui dispongono identiﬁcando gruppi signiﬁcativi dei data 
points: 
•
i venditori cercano di identiﬁcare cluster di clienti, in base ai loro proﬁli, 
per migliorare l’attività di marketing (
 market segmentation
 ); 
•
i medici cercano di raggruppare i pazienti in base alle loro condizioni 
cliniche; 
•
gli astronomi identiﬁcano cluster di stelle in base alla loro prossimità 
spaziale; 
•
ecc. ecc.
 
6"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#6,6,"Clustering 
Esempio in due dimensioni: individuare la 
 cluster structure
  solo 
dagli input: 
 
7
feature 1feature 2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#7,7,"Clustering 
Ogni cluster è deﬁnito dal 
 centroide
  (
cluster center
 ) e dalla forma 
(shape/spread): 
 
8
feature 1feature 2
1 2
3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#8,8,"Ciascuna osservazione 
 x
i
 è assegnata al cluster 
 k
 se: 
•
 Il punteggio (
 score
 ) di 
x
i
 sotto il cluster 
 k
 è migliore rispetto agli 
altri cluster. 
Per semplicità, spesso si deﬁnisce lo 
 score
  come la distanza dal 
centroide
  del cluster (si ignora lo shape). 
 
9
Clustering "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#9,9,"k-means Clustering 
L’algoritmo 
 k-means
  assume come 
 score
  proprio la distanza di una 
osservazione dal 
 centroide
 . Più bassa è la distanza, “migliore” è lo 
score
 . 
Deﬁnizione dei simboli utilizzati nell’esempio che segue: 
 
10nj: numero di  elementi nel cluster jµj: centroide  del cluster j
zi: label del cluster a cui appartiene xiN: numero delle osservazioni
j: indice dei cluster 
k: numero dei clusterxi: osservazione i-esima (              ) xi2Rd"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 08)
1"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Preprocessing: Scaling 
Scaling in Scikit-learn 
Scaling e classiﬁcazione 
Scikit-learn e K-Means  
Esempi di limiti dell'algoritmo K-Means "
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#10,10,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set? 
Le istanze nel test set sono state scalate in modo improprio rispetto ai valori 
originali, e si trovano in posizioni relative diverse da quelle originali.
11
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#11,11,"Scikit-learn: Scaling
Nota: In scikit-learn, gli scaler hanno spesso il metodo ﬁt_transform() che 
combina le 2 operazioni: 
from 
sklearn.preprocessing 
 import 
StandardScaler
scaler 
= 
StandardScaler
 ()
X_scaled 
 = 
scaler
.
fit
(
X
)
.
transform
 (
X
)
# stesso risultato ma più efficient
X_scaled_d 
 = 
scaler
.
fit_transform
 (
X
)
12"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#12,12,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler sul dataset breast cancer e impiega 
l'algoritmo di classiﬁcazione SVC(C=100). Confronta la performance senza 
scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
...
13"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#13,13,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler e StandardScaler sul dataset breast cancer 
e impiega l'algoritmo SVC(C=100). Confronta la performance senza scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
svm 
= 
SVC
(
C
=
100
)
svm
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test
, 
y_test
)))
>> Test set accuracy: 0.63
# con scaling
scaler 
= 
MinMaxScaler
 ()
scaler
.
fit
(
X_train
)
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
svm
.
fit
(
X_train_scaled
 , 
y_train
)
print
(
""Scaled test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test_scaled
 , 
y_test
)))
>> Scaled test set accuracy: 0.97 (con StandardScaler si ottiene 0.96)
14"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#14,14,"Scikit-learn: K-means
Scikit-learn implementa l'algoritmo con la classe 
 KMeans
 . Il parametro 
n_clusters
  è richiesto per speciﬁcare il numero di cluster.  
Supponiamo di avere il seguente  
dataset: 
L'output dell'algoritmo può essere  
rappresentato col diagramma  
Voronoi Tesselation. 
from 
sklearn.cluster 
 import 
KMeans
k 
= 
5
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
y_pred 
= 
kmeans
.
fit_predict
 (
X
)
print (
y_pred)
>> array([4, 0, 1, ..., 2, 1, 0],  
dtype=int32)
print (y_pred 
 is 
kmeans
.
labels_)
>> True
15
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#15,15,"Scikit-learn: Limiti K-means
Possiamo ottenere le coordinate dei 5 centroidi: 
kmeans
.
cluster_centers_
>> array([[-2.80389616, 1.80117999],
[ 0.20876306, 2.25551336],
[-2.79290307, 2.79641063],
[-1.46679593, 2.28585348],
[-2.80037642, 1.30082566]])
E predire la classe di nuove istanze: 
X_new 
= 
np
.
array
([[
0
, 
2
], [
3
, 
2
], [
-
3
, 
3
], [
-
3
, 
2.5
]])
kmeans
.
predict
(
X_new
)
>> array([1, 1, 2, 2], dtype=int32)
Nota
 : K-Means non si comporta molto bene con cluster che hanno 
diametri molto distinti tra loro, poiché l'algoritmo valuta solo la distanza 
col centroide.
16"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#16,16,"Scikit-learn: K-means
Invece dell'
 hard clustering
  visto ﬁnora, dove l'output è un singolo cluster, 
possiamo ottenere uno score (anche chiamato 
 similarity score
  o 
afﬁnity
 ) per 
ogni cluster col 
 soft clustering
  mediante la funzione 
 transform
 (): 
kmeans
.
transform
 (
X_new
)
>> array([[2.81093633, 0.32995317, 2.9042344 , 1.49439034, 2.88633901],
[5.80730058, 2.80290755, 5.84739223, 4.4759332 , 5.84236351],
[1.21475352, 3.29399768, 0.29040966, 1.69136631, 1.71086031],
[0.72581411, 3.21806371, 0.36159148, 1.54808703, 1.21567622]])
È possibile impostare i centroidi iniziali in modo manuale col parametro 
init
: 
good_init 
 = 
np
.
array
([[
-
3
, 
3
], [
-
3
, 
2
], [
-
3
, 
1
], [
-
1
, 
2
], [
0
, 
2
]])
kmeans 
= 
KMeans
(
n_clusters
 =
5
, 
init
=
good_init
 , 
n_init
=
1
)
L'iperparametro 
 n_init
  speciﬁca quante volte l'algoritmo deve essere 
eseguito prima di selezionare la soluzione migliore ottenuta.
17"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#17,17,"Scikit-learn: K-means
Per valutare la bontà della soluzione si misura il costo basato sulla cluster 
heterogeneity, chiamato anche 
 inertia
  del modello, cioè la distanza 
quadratica media con i centroidi. 
kmeans
.
inertia_
>> 211.59853725816856
kmeans
.
score
(
X
)
>> -211.59853725816856
Nota
 : di default KMeans() usa l'inizializzazione dei centroidi proposta in K-
Means++. Se vuoi impiegare quella dell'algoritmo originale, imposta il 
parametro 
 init='random'
 .
18"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: K-means
Esempio con un dataset toy: 
from 
sklearn.datasets 
 import 
make_blobs
from 
sklearn.cluster 
 import 
KMeans
# generate synthetic two-dimensional data
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
19
n_clusters=2 n_clusters=4 n_clusters=3"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
20Secondo te è un output ideale?
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#2,2,"Clustering
Ci focalizziamo sugli algoritmi di 
 clustering
 . Esistono anche 
 trasformazioni 
unsupervised
 , utili per creare nuove rappresentazioni utili per analizzare 
dati o per darli in input a successivi algoritmi. Un approccio comune è la 
riduzione di dimensionalità
 , dove le N dimensioni corrispondenti alle 
features vengono ""compresse"" in poche dimensione (es. 2 o 3). 
La challenge del clustering è capire se l'algoritmo applicato su dati non 
etichettati (cioè senza output) riesce comunque a trovare qualcosa di utile. 
Esempio: Classiﬁcation (sx) e Clustering senza label (dx) 
3
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21K-means assume che ogni cluster abbia lo 
stesso diametro, e deﬁnisce la boundary tra i 
cluster esattamente a metà tra i due centroidi. 
Alcuni punti del graﬁco potevano essere 
classiﬁcati in modo diverso.
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
22
Secondo te è un output ideale?"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
23
I dati sono distribuiti (""allungati"") sulla diagonale, 
non seguono una distribuzione sferica. 
L'algoritmo valuta solo la distanza dal centroide."
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#23,23,"Scikit-learn: Limiti K-means
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
kmeans 
= 
KMeans
(
n_clusters
 =
2
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
))
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
mglearn
.
cm2
(
0
), 
mglearn
.
cm2
(
1
)], 
s
=
100
, 
linewidth
 =
2
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
24
Shape complesse non sono 
valutate correttamente."
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#24,24,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
25"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#3,3,"Preprocessing: Scaling
Alcuni algoritmi di ML sono sensibili allo 
 scaling
  dei dati. Per tale motivo 
spesso si opera un rescaling e shifting. 
Vediamo qualche esempio dalla libreria mglearn: 
mglearn
.
plots
.
plot_scaling
 ()
4
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#4,4,"Preprocessing: Scaling
Il diagramma mostra 4 scaler della libreria scikit-learn.  
StandardScaler
 : garantisce media 0 e varianza 1  
Non garantisce alcun intervallo max e min 
RobustScaler
 : approccio statistico simile,  
usa mediana e quartili, è meno sensibile  
agli 
outliers
 . 
MinMaxScaler
 : sposta i dati nell'intervallo [0,1] 
Normalizer
 : effettua un rescaling in modo che  
la distanza euclidea sia pari a 1, cioè proietta  
i punti su una circonferenza (o sfera) di raggio 1.  
Ogni punto è scalato per l'inverso della lunghezza.  
Utile quando si ha interesse soprattutto riguardo la direzione, piuttosto 
che della lunghezza del feature vector.
5
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Scaling
Usiamo il breast cancer dataset per testare i vari scaling su un contesto 
supervised con algoritmo SVM/SVC: 
from 
sklearn.datasets 
 import 
load_breast_cancer
from 
sklearn.model_selection 
 import 
train_test_split
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
,
random_state
 =
1
)
print
(
X_train
.
shape
)
print
(
X_test
.
shape
)
>> (426, 30)
>> (143, 30)
from 
sklearn.preprocessing 
 import 
MinMaxScaler
scaler 
= 
MinMaxScaler
 ()
# consideriamo solo X_train, 
 non il y_train
scaler
.
fit
(
X_train
)
>> MinMaxScaler(copy=True, feature_range=(0, 1))
# trasformiamo i dati
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
6"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#6,6,"Scikit-learn: Scaling
# stampa i valori delle features prima e dopo il rescaling
print
(
""transformed shape: {}""
 .
format
(
X_train_scaled
 .
shape
))
print
(
""per-feature minimum before scaling:\n {}""
 .
format
(
X_train
.
min
(
axis
=
0
)))
print
(
""per-feature maximum before scaling:\n {}""
 .
format
(
X_train
.
max
(
axis
=
0
)))
print
(
""per-feature minimum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
max
(
axis
=
0
)))
>> transformed shape: (426, 30)
per-feature minimum before scaling:
[ 6.98 9.71 43.79 143.50 0.05 0.02 0. 0. 0.11
0.05 0.12 0.36 0.76 6.80 0. 0. 0. 0.
0.01 0. 7.93 12.02 50.41 185.20 0.07 0.03 0.
0. 0.16 0.06]
per-feature maximum before scaling:
[ 28.11 39.28 188.5 2501.0 0.16 0.29 0.43 0.2
0.300 0.100 2.87 4.88 21.98 542.20 0.03 0.14
0.400 0.050 0.06 0.03 36.04 49.54 251.20 4254.00
0.220 0.940 1.17 0.29 0.58 0.15]
per-feature minimum after scaling:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
per-feature maximum after scaling:
[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
7"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#7,7,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?
8"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#8,8,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?  
Sì, perché il max e min sono stati ricavati dal training set, e possono 
essere distinti da quelli nel X_test.
9"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#9,9,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set?
10
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 09)
1"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Agglomerative clustering 
Hierarchical clustering 
Dendograms 
DBSCAN 
Accelerated K-Means e Mini-batch K-Means 
Silhoutte score"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#10,10,"DBSCAN
DBSCAN (density-based spatial clustering of applications with noise) è un 
algoritmo che non richiede la scelta del numero di cluster a priori, inoltre può 
gestire conﬁgurazioni complesse dei dati (es. non sferiche). a differenza degli 
approcci visti ﬁnora. 
È generalmente più lento ma può scalare su dataset molto grandi. 
L'algoritmo identiﬁca i punti nel feature space che si trovano in regioni 
""popolate"" o 
 dense 
 e costruisce i cluster in base ad esse. I punti in queste 
regioni si chiamano 
 core samples
 .  
Ci sono 2 iperparametri: 
 min_samples
  e 
eps
. Se esistono almeno 
 min_samples  
punti con distanza inferiore a 
 eps
 rispetto a un punto X, allora  X è un 
 core 
sample
 . I core sample che sono vicini tra loro (distanza < eps) sono inseriti 
nello stesso cluster. Un cluster deve avere almeno min_samples punti. 
I punti che non sono assegnati a nessun cluster diventano i punti di partenza 
per una nuova iterazione. Quelli che non sono assegnati ad alcun cluster 
sono considerati rumore.
11"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#11,11,"DBSCAN
Nota
 : anche in DBSCAN la funzione predict() non è implementata. 
Esempio: 
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
Perché l'output è sempre -1?
12"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#12,12,"DBSCAN
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
L'algoritmo usa il valore di default per eps che non è adatto per il piccolo dataset 
analizzato. 
mglearn
.
plots
.
plot_dbscan
 ()
min_samples: 2 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 2 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 2 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 2 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 3 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 3 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 3 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 3 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 5 eps: 1.000000 cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
min_samples: 5 eps: 1.500000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 2.000000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
13"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#13,13,"DBSCAN
Diverse conﬁgurazioni variando gli iperparametri (i punti in bianco sono 
considerati rumore). Cosa noti? 
14
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#14,14,"DBSCAN
Incrementando 
 eps
 ci sono più punti che appartengono a clusters, e si 
riducono anche il numero di clusters. 
Nota: è più facile impostare il valore di eps operando prima la normalizzazione delle features con 
StandardScaler
  o 
MinMaxScaler.  
Incrementando 
 min_samples
 , meno punti saranno core points, e più punti 
saranno etichettati come rumore. 
15
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#15,15,"DBSCAN - Esercizio
Esercizio
 : impiega l'algoritmo DBSCAN sul moon dataset, con o senza la 
normalizzazione. Valuta i cluster ottenuti.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
...
16"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#16,16,"DBSCAN - Esercizio
Esercizio: impiega l'algoritmo DBSCAN sul moon dataset.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
# media 0 e varianza unitaria
scaler 
= 
StandardScaler
 ()
scaler
.
fit
(
X
)
X_scaled 
 = 
scaler
.
transform
 (
X
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X_scaled
 )
plt
.
scatter
(
X_scaled
 [:, 
0
], 
X_scaled
 [:, 
1
], 
c
=
clusters
 , 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
17"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#17,17,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
Esercizio
 : Cosa succede se decrementiamo il valore di default di eps (0.5) a 
0.2, o lo incrementiamo a 0.7?
18
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#18,18,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
eps = 0.2 -> 8 clusters 
eps = 0.7 -> 1 cluster
19
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#19,19,"Accelerated K-Means e Mini-batch K-Means
L'algoritmo 
 accelerated
  K-Means evita di calcolare distanze non 
necessarie.  
Impiega la 
 triangle inequality 
  AC< AB+BC, dove A,B e C sono 3 punti, e 
tiene traccia del valore del upper e lower bounds delle distanze tra 
centroidi e istanze. È l'approccio normalmente impiegato 
nell'implementazione KMeans di scikit-learn. 
L'approccio 
 Mini-batch
  seleziona un piccolo insieme di istanze su cui 
valutare le distanze, creando una 
 inerzia
  nella modiﬁca dei clusters. 
Incrementa la velocità, ma se il numero di cluster è elevato si ottengono 
conﬁgurazioni meno ottimali. 
from 
sklearn.cluster 
 import 
MiniBatchKMeans
minibatch_kmeans 
 = 
MiniBatchKMeans
 (
n_clusters
 =
5
)
minibatch_kmeans
 .
fit
(
X
)
20"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#2,2,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
Quali criteri di unione (merge) puoi immaginare?
3"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#20,20,"Accelerated K-Means e Mini-batch K-Means
Mini-batch vs K-Means tradizionale impiegando diversi numeri di clusters 
k. Con un numero elevato di clusters l'inerzia si riduce notevolmente, e si 
limita il tempo di training. 
Ricordiamo che l'
 inertia
  del modello e' la distanza quadratica media con i 
centroidi, cioè la
  cluster heterogeneity 
 (vedi lezione sul clustering).
21
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#21,21,"Il numero ottimale di clusters
Alcuni algoritmi richiedono di speciﬁcare il numero di clusters, che 
possono produrre risultati molto diversi anche con valori simili: 
Potremmo scegliere il modello con minore inertia, ma nell'esempio con 
k=3 otteniamo 653.2, mentre con k=8 si ha inertia=119.1. Più cluster 
abbiamo, più si riduce la distanza col rispettivo centroide e la rispettiva 
inertia del modello. 
22
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#22,22,"Richiami: elbow method
Se graﬁchiamo il valore dell'inertia in funzione del numero di clusters 
 k
 si 
vede chiaramente con dopo un ""drop"" elevato, il decremento si riduce 
notevolmente. 
23
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#23,23,"Silhoutte score
Un metodo più formale è il calcolo del valore della silhoutte su tutte le 
istanze. Si ricava con
  (b-a)/max(a,b)
  dove 
 a
 è la distanza media rispetto 
alle altre istanze nel cluster, 
 b
 è la 
 mean nearest-cluster distance
 , cioè la 
distanza media delle istanze rispetto al cluster più vicino. 
Il coefﬁciente varia in [-1,+1], dove un valore vicino:  
a +1 indica una istanza vicina al proprio cluster e lontana dagli altri,  
allo 0, istanza vicina al boundary del cluster 
a -1 l'istanza potrebbe essere stata assegnata al cluster sbagliato. 
from 
sklearn.metrics 
 import 
silhouette_score
silhouette_score
 (
X
, 
kmeans
.
labels_
)
0.655517642572828
24"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#24,24,"Silhoutte score
Un valore pari a 4 di cluster massimizza il valore della silhoutte
25
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#25,25,"Silhoutte diagram
Graﬁci del valore di silhoutte per ogni istanza, ordinati per il cluster di 
appartenenza. Per k=4 abbiamo che gran parte delle istanze sorpassano il 
valore di silhoutte associato a quella conﬁgurazione (linea rossa)
26
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#26,26,"Silhoutte: Esercizio
Esercizio
 : riprendi il dataset blobs e l'approccio agglomerative e ricava il 
numero ottimale di cluster col approccio 
 Agglomerative
 . 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
...
27"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#27,27,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
28"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#3,3,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
In scikit-learn la fusione di cluster può seguire uno dei seguenti criteri: 
ward
  (default): si scelgono i cluster i cui merge riducono al massimo 
l'incremento di varianza tra tutti i cluster. Di solito porta ad avere 
cluster di dimensione confrontabile. 
average
 : i due cluster che hanno distanza media tra tutti punti minore 
complete
 : i due cluster che hanno distanza massima tra due punti 
minore.
4"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#4,4,"Agglomerative Clustering
Esempio libreria 
 mglearn
 : 
mglearn
.
plots
.
plot_agglomerative_algorithm
 ()
5
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Agglomerative Clustering
Esempio scikit-learn: 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
agg 
= 
AgglomerativeClustering
 (
n_clusters
 =
3
) # parametro obbligatorio
assignment 
 = 
agg
.
fit_predict
 (
X
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
assignment
 )
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
Nota
 : l'agglomerative clustering non può predire un cluster per nuovi dati, 
perciò non è possibile usare la funzione predict().
6
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#6,6,"Hierarchical clustering
Ad ogni passo dell'algoritmo agglomerative si creano diverse 
conﬁgurazioni che possono essere rilevanti per analizzare i dati, soprattutto 
se si hanno poche features. 
mglearn
.
plots
.
plot_agglomerative
 ()
7
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#7,7,"Dendrograms
Per dataset con molte features è comunque possibile rappresentare i dati 
sottoforma di dendogrammi. Scikit-learn non implementa tale funzionalità, 
usiamo la libreria 
 scipy
 : 
from 
scipy.cluster.hierarchy 
 import 
dendrogram
 , 
ward
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
# ward clustering sui dati
# la funzione restituisce un array che contiene le distanze ricavate
# durante il clustering agglomerative
linkage_array 
 = 
ward
(
X
)
# Visualizziamo il dendogramma con le distanze tra i cluster
dendrogram
 (
linkage_array
 )
# Nel plot aggiungiamo il numero di clsuter
ax 
= 
plt
.
gca
()
bounds 
= 
ax
.
get_xbound
 ()
ax
.
plot
(
bounds
, [
7.25
, 
7.25
], 
'--'
, 
c
=
'k'
)
ax
.
plot
(
bounds
, [
4
, 
4
], 
'--'
, 
c
=
'k'
)
ax
.
text
(
bounds
[
1
], 
7.25
, 
' two clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
ax
.
text
(
bounds
[
1
], 
4
, 
' three clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
plt
.
xlabel
(
""Sample index""
 )
plt
.
ylabel
(
""Cluster distance""
 )
8"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#8,8,"Dendrograms
Dal seguente diagramma come immagini che si sia comportato l'algoritmo 
di clustering?
9
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#9,9,"Dendrograms
Sulle ascisse abbiamo le istanze numerate (da 0 a 11). Salendo si notano i 
nuovi cluster che uniscono le istanze, oppure cluster già presenti. 
Es. al principio si uniscono 1 e 4 in un cluster, poi 6 e 9 in un altro, etc. 
In cima abbiamo 2 cluster, uno con 11,0,5,10,7,6 e 9; l'altro coi 
restanti punti. 
La lunghezza in verticale delle linee rappresentano le distanze tra i due 
cluster o punti che si fondono. 
10
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 10)
1"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Image segmentation 
Clustering per il preprocessing 
Grid search 
Active learning 
Gaussian Mixtures"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#10,10,"Clustering per il semi-supervised learning
Soluzione: 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
X_digits_dist 
 = 
kmeans
.
fit_transform
 (
X_train
)
representative_digit_idx 
 = 
np
.
argmin
(
X_digits_dist
 , 
axis
=
0
)
X_representative_digits 
 = 
X_train
[
representative_digit_idx
 ]
# facciamo un labeling manuale delle 50 cifre
y_representative_digits 
 = 
np
.
array
([
4
, 
8
, 
0
, 
6
, 
8
, 
3
, 
...
, 
7
, 
6
, 
2
, 
3
, 
1
, 
1
])
l
og_reg 
= 
LogisticRegression
 ()
log_reg
.
fit
(
X_representative_digits
 , 
y_representative_digits
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9244444444444444
11
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#11,11,"Clustering per il preprocessing
Etichettiamo le restanti istanze nei cluster con le label che abbiamo creato 
in modo manuale (
 label propagation
 ), e proviamo nuovamente ad 
addestrare la logistic regression: 
y_train_propagated 
 = 
np
.
empty
(
len
(
X_train
), 
dtype
=
np
.
int32
)
for 
i 
in 
range
(
k
):
  
y_train_propagated
 [
kmeans
.
labels_
==
i
] 
= 
y_representative_digits
 [
i
]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
, 
y_train_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9288888888888889
Un leggero incremento. Non conviene propagare le label alle istanze 
lontano dal centroide e vicine al boundary.
12"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#12,12,"Clustering per il preprocessing
Proviamo a fare propagation solo al 20% delle istanze più vicine al centroide 
percentile_closest 
 = 
20
X_cluster_dist 
 = 
X_digits_dist
 [
np
.
arange
(
len
(
X_train
)), 
kmeans
.
labels_
]
for 
i 
in 
range
(
k
):
in_cluster 
 = 
(
kmeans
.
labels_ 
 == 
i
)
cluster_dist 
 = 
X_cluster_dist
 [
in_cluster
 ]
cutoff_distance 
 = 
np
.
percentile
 (
cluster_dist
 , 
percentile_closest
 )
above_cutoff 
 = 
(
X_cluster_dist 
 > 
cutoff_distance
 )
X_cluster_dist
 [
in_cluster 
 & 
above_cutoff
 ] 
= -
1
partially_propagated 
 = 
(
X_cluster_dist 
 != -
1
)
X_train_partially_propagated 
 = 
X_train
[
partially_propagated
 ]
y_train_partially_propagated 
 = 
y_train_propagated
 [
partially_propagated
 ]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train_partially_propagated
 , 
y_train_partially_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9422222222222222
94.2% è molto vicino al risultato ottenuto con l'addestramento sull'interno 
dataset etichettato (96.7%). In effetti le istanze etichettate automatichemente 
con 
label propagation
  sono corrette al 99%.
13"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#13,13,"Active Learning
È un approccio iterativo dove l'algoritmo propone alcune istanze per essere 
etichettate manualmente. Ci sono diverse strategie per selezionare queste 
istanze: 
quelle su cui l'algoritmo mostra maggiore incertezza,  
quelle che potenzialmente riducono maggiormente il tasso di errore, 
quelle su cui diversi modelli (es. SVM, Random forest, etc) trovano 
maggiore disaccordo. 
Il procedimento continua ﬁnché non si hanno miglioramenti di 
performance tangibili. 
14"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#14,14,"Gaussian Mixtures
Il 
Gaussian mixture model (GMM)
  suppone che le istanze siano generate 
da un mix di diverse distribuzioni gaussiano i cui parametri sono incogniti. 
Le istanze generate da una singola distribuzione formano un cluster a 
forma di ellissoide, con diverse forme, dimensioni, densità e orientamenti.  
Al principio non sappiamo quali distribuzioni generino una speciﬁca 
istanza. Occorre stimarle durante la fase di training. 
15
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#15,15,"Gaussian Mixtures
La classe 
 GaussianMixture
  suppone di conoscere in anticipo il numero 
 k
 di 
distribuzioni. 
Per ogni istanza, prendiamo casualmente un cluster dei 
 k
. La probabilità di 
scegliere il 
 j
-mo cluster e deﬁnita dal peso del cluster 
 ϕ
(j)
. L'indice del 
cluster selezionato per l'istanza 
 i
-ma è 
 z
(i)
. 
Se 
z
(i)
=
j
, la posizione della istanza 
 x
(i)
 è campionata in modo casuale da 
una distribuzione gaussiana con media 
 μ
(j)
 e matrice di covarianza 
 Σ
(j)
, e la 
indichiamo con:
16
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#16,16,"Gaussian Mixtures
Rappresentiamo il modello graﬁcamente dove si notano le dipendenze tra le 
variabili casuali. Le circonferenze sono le variabili casuali, i quadrati i parametri. 
I rettangoli sono 
 plates
 , e indicano che i loro contenuti sono ripetuti diverse volte 
(es. 
m
 volte corrispondenti al numero di variabili casuali, o 
 k
 volte, cioè il 
numero di medie e covarianze, ed un solo array di parametri 
 ϕ
). 
Ogni variabile 
 z
(i) 
è ricavata da una distribuzione 
 categorical
  con pesi 
 ϕ
. 
Ogni 
variabile 
 x
(i)
 è ricavata da una distribuzione gaussiana con media e matrice di 
covarianza deﬁnita dal suo cluster 
 z
(i)
.
17
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#17,17,"Gaussian Mixtures
(cont...) Le frecce rappresentano dipendenze tra le variabili. Ad esempio, 
z
(i)
 dipende dal vettore dei pesi 
 ϕ
, per ogni 
 i
. 
A seconda del valore di 
 z
(i)
, l'istanza 
 x
(i)
 è campionata da una diversa 
distribuzione (freccia ondulata).  
I nodi colorati rappresentano dati noti, gli altri contengono parametri da 
stimare.
18
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: Gaussian Mixtures
Una volta addestrato il modello impiegando la classe 
 GaussianMixture
 () 
possiamo ottenere facilmente i parametri 
 ϕ
, 
μ
 e 
Σ
: 
from 
sklearn.mixture 
 import 
GaussianMixture
gm 
= 
GaussianMixture
 (
n_components
 =
3
, 
n_init
=
10
)
gm
.
fit
(
X
)
# mostriamo i parametri stimati
gm
.
weights_
>>> array([0.20965228, 0.4000662 , 0.39028152])
gm
.
means_
>>> array([[ 3.39909717, 1.05933727],
[-1.40763984, 1.42710194],
[ 0.05135313, 0.07524095]])
gm
.
covariances_
>>> array([[[ 1.14807234, -0.03270354],
[-0.03270354, 0.95496237]],
[[ 0.63478101, 0.72969804],
[ 0.72969804, 1.1609872 ]],
[[ 0.68809572, 0.79608475],
[ 0.79608475, 1.21234145]]])
E ora?
19"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Gaussian Mixtures
Impieghiamo l'algoritmo di Expectation Maximization (EM), simile come 
idea al K-Means. Inizializza i parametri dei cluster in modo casuale, e 
iterativamente raggiunge lo stato di convergenza. Assegna le istanze ai 
cluter (
 expectation step
 ) e poi aggiorna i cluster (
 maximization step
 ). Ricava 
i valori del centro dei cluster (medie), la loro dimensione, forma e 
orientazione (matrice di covarianze) e il relativo peso (
 Φ
). 
EM usa un soft clustering, stimando la probabilità di appartenenza. Durante 
il 
maximization step
  ogni cluster è aggiornato con tutte le istanze nel 
dataset, dove ogni istanza è pesata con la relativa probabilità di 
appartenenza (chiamata anche 
 responsability
  del cluster per l'istanza). 
Perciò ogni cluster viene aggiornato maggiormente dalle istanze che più 
verosimilmente appartengono ad esso. 
L'algoritmo richiede diversi run (es. n_init=10), poiché può facilmente 
produrre cattive conﬁgurazioni.
20"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#2,2,"Image segmentation e Instance segmentation
Nella 
 Image segmentation
  si suddivide una immagine in porzioni, dove 
ogni porzione contiene pixel che rappresentano un oggetto associato alla 
porzione (es. pedone, portiera di un auto, etc). Una porzione può 
contenere istanze multiple di un oggetto. 
Nella Instance segmentation ogni porzione contiene una singola istanza 
(es. ogni pedone ha una segmentation distinta). 
Affrontiamo il problema con un approccio basato sulla 
 color segmentation.  
Non è il più efﬁcace, ma per alcuni domini è sufﬁciente (es. analizzare la 
percentuale di zone verdi da immagini satellitari). 
Associamo un pixel ad un segmento se ha colore simile. 
3"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Gaussian Mixtures
Possiamo valutare la convergenza e il numero di iterazioni: 
gm
.
converged_
>> True
gm
.
n_iter_
>> 3
Una volta ricavati i parametri possiamo predire il cluster (hard clustering) o 
i clusters (soft clustering) più adatti per una certa istanza: 
gm
.
predict
(
X
)
>> array([2, 2, 1, ..., 0, 0, 0])
gm
.
predict_proba
 (
X
)
>> array([[2.32389467e-02, 6.77397850e-07, 9.76760376e-01],
[1.64685609e-02, 6.75361303e-04, 9.82856078e-01],
[2.01535333e-06, 9.99923053e-01, 7.49319577e-05],
...,
[9.99999571e-01, 2.13946075e-26, 4.28788333e-07],
[1.00000000e+00, 1.46454409e-41, 5.12459171e-16],
[1.00000000e+00, 8.02006365e-41, 2.27626238e-15]])
21"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Gaussian Mixtures
Essendo un modello generativo, puoi anche generare nuove istanze dal 
modello: 
X_new
, 
y_new 
= 
gm
.
sample
(
6
)
X_new
>> array([[ 2.95400315, 2.63680992],
[-1.16654575, 1.62792705],
[-1.39477712, -1.48511338],
[ 0.27221525, 0.690366 ],
[ 0.54095936, 0.48591934],
[ 0.38064009, -0.56240465]])
y_new
>>array([0, 1, 2, 2, 2, 2])
oppure stimare la densità del modello per un certo punto. Col metodo 
score_samples
 () si ricava la log della 
 probability density function 
 (PDF): 
gm
.
score_samples
 (
X
)
>> array([-2.60782346, -3.57106041, -3.33003479, ..., -3.51352783,
-4.39802535, -3.80743859])
Per stimare la prob che una istanza cada in una certa regione occorre 
integrare la funzione sull'intervallo.
22"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Gaussian Mixtures
Il graﬁco precedente rappresenta la densità per mezzo dei colori: 
È stato facile rappresentare i dati perché abbiamo usato una gaussiana 2D. 
Per altri dataset occorrono più dimensioni (e molte più istanze). Se 
l'algoritmo non riesce a convergere si possono impostare vincoli sulla 
forma e orientazione delle distribuzioni (es. parametro 
 covariance_type
 )
23
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#3,3,"Scikit-learn: Image segmentation
Carichiamo una immagine, che sarà memorizzata in un array 3d, dove la 
profondità (numero di canali) rappresenta l'intensità RGB in [0,1], o 
[0,255] se si impiega imageio.imread() 
from 
matplotlib.image 
 import 
imread
import
 urllib2
f = 
urllib2.urlopen
 (
'
http://.../image.png
 '
)
f = 
os
.
path
.
join
(
""images""
 ,
""image.png""
 )       # in alternativa
image 
= 
imread
(f)
image
.
shape
>> (533, 800, 3)
Nota: alcune immagini hanno meno canali (es. scala di grigio), o più canali 
(es. alpha channel, segnale infrared).
4"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#4,4,"Scikit-learn: Image segmentation
Il seguente codice ridimensiona l'array come un array 1D, dove ogni 
elemento è una tripla. Dopodiché fa clustering raggruppando pixel con 
colori simili. Inﬁne ricava il colore ""medio"" per mezzo del centroide e 
riordina il risultato come le dimensioni dell'immagine iniziale: 
X 
= 
image
.
reshape
(
-
1
, 
3
)
kmeans 
= 
KMeans
(
n_clusters
 =
8
)
.
fit
(
X
)
segmented_img 
 = 
kmeans
.
cluster_centers_
 [
kmeans
.
labels_
]
segmented_img 
 = 
segmented_img
 .
reshape
(
image
.
shape
)
5
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#5,5,"Clustering per il preprocessing
Il clustering può essere usato anche come tecnica di 
 dimensionality 
reduction
 , ad esempio per rendere più adatto un dataset per un approccio 
supervised, riducendo il numero di features e la dimensione totale.  
Es. prendiamo il MNIST dataset (1797 immagini 8x8 in scala di grigio) e 
impieghiamo la logistic regression per la classiﬁcazione: 
from 
sklearn.datasets 
 import 
load_digits
X_digits
 , 
y_digits 
 = 
load_digits
 (
return_X_y
 =
True
)
from 
sklearn.model_selection 
 import 
train_test_split
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X_digits
 , 
y_digits
 )
from 
sklearn.linear_model 
 import 
LogisticRegression
log_reg 
 = 
LogisticRegression
 (
random_state
 =
42
)
log_reg
.
fit
(
X_train
, 
y_train
)
log_reg
.
score
(
X_test
, 
y_test
)
0.9666666666666667
6"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#6,6,"Clustering per il preprocessing
Usiamo inizialmente il cluster per raggruppare le immagini simili usando 
50 clusters (usarne solo 10 non è ottimale poiché esistono molti modi per 
rappresentare la stessa cifra), e usiamo la distanza da questi cluster come 
input al posto dell'immagine originale: 
from 
sklearn.pipeline 
 import 
Pipeline
pipeline 
 = 
Pipeline
 ([
    (
""kmeans""
 , 
KMeans
(
n_clusters
 =
50
)),
    (
""log_reg""
 , 
LogisticRegression
 ()),
])
pipeline
 .
fit
(
X_train
, 
y_train
)
pipeline
 .
score
(
X_test
, 
y_test
)
0.9822222222222222
Abbiamo dimezzato il tasso d'errore! 
Nota: Pipeline combina più operazioni di 
 trasformazione
  sui dati, cioè 
devono comparire classi che implementano 
 ﬁt
() e 
transform
 (). Per ultimo 
c'è l'estimator che deve includere l'implementazione di 
 ﬁt
().
7"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#7,7,"Tuning degli iperparametri: grid search
Per il tuning degli iperparametri (numero di cluster) possiamo impiegare lo 
score della fase supervised, senza il bisogno di calcolare la silhoutte. 
La classe GridSearchCV ottimizza il valore degli iperparametri in modo 
esaustivo iterando su intervalli (approccio grid-search con cross-
validazione). 
from 
sklearn.model_selection 
 import 
GridSearchCV
# dizionario chiave->valore, dove la chiave è il nome del iperparametro,
# il valore è il range di valori da valutare
param_grid 
 = 
dict
(
kmeans__n_clusters
 =
range
(
2
, 
100
))
grid_clf 
 = 
GridSearchCV
 (
pipeline
 , 
param_grid
 , 
cv
=
3
, 
verbose
=
2
)
grid_clf
 .
fit
(
X_train
, 
y_train
)
grid_clf
 .
best_params_
>> {'kmeans__n_clusters': 90}
grid_clf
 .
score
(
X_test
, 
y_test
)
>> 0.9844444444444445
8"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#8,8,"Clustering per il semi-supervised learning
Potremmo avere dataset poche istanze con label (etichettate), e molte 
istanze senza label. Non è sufﬁciente per l'addestramento supervised. 
Ad esempio, impiegando solo 50 istanze dal dataset delle cifre otteniamo 
una accuracy piuttosto bassa: 
n_labeled 
 = 
50
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
[:
n_labeled
 ], 
y_train
[:
n_labeled
 ])
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.826666666666666
9"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#9,9,"Clustering per il semi-supervised learning
Esercizio: prova a fare il clustering del dataset delle cifre (split X_train) 
usando 50 clusters impiegando KMeans. Per ogni cluster trova la cifra con 
distanza minima dal centroide dal cluster. Usa queste cifre come il nuovo 
dataset di 50 immagini per addestrare la logistic regressione e valuta la 
differena nelle performance. 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
...
10"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alle  
Reti Neurali Artiﬁciali
1"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#1,1,"Sommario
Introduzione alle Reti Neurali Artiﬁciali 
Unità di Calcolo nelle Reti Neurali  
Reti Neurali a uno strato alimentate in avanti (percettroni) 
Reti Neurali multistrato alimentate in avanti 
Algoritmo di Back-propagation 
Esempio di esecuzione dell’algoritmo
2"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#10,10,"ReLU 
(Rectiﬁed Linear Unit)
gg(in i) = max(in i,0)
<latexit sha1_base64=""fdZuD83MuMKqvRY6gR2pKYYhfhM="">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>
ini 0
11"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#11,11,"Funzione Gradino
La motivazione biologica è che un 1 rappresenta 
l’emissione di un impulso lungo l’assone, mentre uno 0 
rappresenta l’assenza di una tale emissione.
La soglia individua l’ingresso pesato minimo che fa in 
modo che il neurone invii l’impulso.
La funzione a gradino ha una soglia t tale che il 
risultato è 1 quando l’ingresso supera questa soglia.
12"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#12,12,"Funzione Gradino
In molti casi risulterà dal punto di vista matematico 
conveniente sostituire la soglia con un peso d’ingresso 
extra.
Questo consentirà di avere un elemento di 
apprendimento più semplice in quanto si dovrà 
preoccupare solo di modiﬁcare dei pesi anziché 
modiﬁcare sia dei pesi che delle soglie.
Quindi, invece di avere una soglia t, considereremo per 
ciascuna unità un ingresso aggiuntivo, la cui attivazione 
a
0
 è ﬁssata a -1.
13"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#13,13,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
14"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#14,14,"Unità di Calcolo nelle Reti Neurali 
Il peso extra W
 0,i
 associato ad a
 0
 ricopre il ruolo della 
soglia t, dove W
 0,i
 = t e a
 0 
= -1. 
In questo modo tutte le unità possono avere una soglia 
ﬁssata a 0.ai=gradinot0
@nX
j=1Wj,iaj1
A=gradino00
@nX
j=0Wj,iaj1
A
<latexit sha1_base64=""bnb4YwLA9yDvbdcHkbSf+9auugw="">AAACfXicfVFNb9NAEF2brxI+moI4IcGIqFKRosgulcqlUgUXjkUiTaU4WOPNJJ12vbZ2x4jK8g/gJ3LgN/ATwA45QFrxTk9v5r3ZnclKw16i6HsQ3rp95+69rfu9Bw8fPd7u7zw59UXlNI11YQp3lqEnw5bGwmLorHSEeWZokl2+7+qTL+Q8F/aTXJU0y3FpecEapZXS/jdMGY4gEfrauuulwznbokkFEkML2YPEV3laXxzFzefaNjBp+ZAbSIaA6QUkjpfn8vqmhGgzIfpvQi/tD6JRtAJcJ/GaDNQaJ2n/RzIvdJWTFW3Q+2kclTKr0QlrQ00vqTyVqC9xSdOWWszJz+rVyhrYrTxKASU5YAMrkf521Jh7f5VnbWeOcu43a514U21ayeLtrGZbVkJWd4OEDa0Gee24vQXBnB2JYPdyArag0aEIOQbUuhWr9jjdPuLN318np/uj+M1o/+PB4PjdejNb6rl6pfZUrA7VsfqgTtRYafUzeBa8CF4Gv8LdcBiO/rSGwdrzVP2D8PA3NkzAIQ==</latexit>
15"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#15,15,"Funzione Gradino 
(con soglia zero)
g
0g(in i)=⇢1i f i n i 0
0 otherwise
<latexit sha1_base64=""xUm3gk/S64XZW4FVFriL5T2ehIM="">AAACfnicbVHLbtNAFB2bR4t5BSqxYcEVKVVZkNoFqd0gVbBhWSTSVspE0Xhy41x1PDYz19DI8g/whyz4Bz4BO7VQaTmro3PuY+bctDTkOY5/BuGt23fubmzei+4/ePjo8eDJ0xNfVE7jWBemcGep8mjI4piJDZ6VDlWeGjxNzz92/uk3dJ4K+4VXJU5zlVlakFbcSrPBj2xXMl5wTbaZ0WuA9yANLljWADLFjGytnFOrpjamgQhaJLADMk+Li5oWsH2lG2SGXyHebkDKy9L4b2nBS3TfyWNnRhLtvJ8L0lG25BFEs8EwHsVrwE2S9GQoehzPBr/kvNBVjpa1Ud5PkrjkaTuXSRtsIll5LJU+VxlOWmpVjn5arzNr4FXlFRdQogMysBbxaketcu9XedpW5oqX/rrXif/zJhUvDqdtIGXFaHW3iMngepHXjtpjIMzJIbPqXo5AFrRyihkdgdK6Fav2Ol0eyfXf3yQn+6Pk7Wj/87vh0Yc+mU3xXLwUuyIRB+JIfBLHYiy0+B08C14EEIpwJ3wT7l2WhkHfsyX+QXj4B8OsvNA=</latexit>
ini
16"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#16,16," Vediamo adesso alcuni semplici esempi di 
reti neurali per la realizzazione di
Porte Logiche
17"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#17,17,"Porte logiche
Lavorando in modo  adeguato sui pesi si possono realizzare 
porte logiche con una rete neurale formata da un solo 
neurone:
18"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#18,18,"Porta AND
•
(Soglia t =1.5) 
•
 W
0
=1.5 
•
W
1
=1 
•
W
2
=1 
•
a
0
= -1 
•
Per a
1
=1 e a
2
= 1si ha: in=0.5 => 
 g(in)=1
  (funzione g a gradino) 
•
Per a
1
=1 e a
2
= 0 si ha: in=-0,5 => 
 g(in)=0   
19"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#19,19,"Porta OR
•
(Soglia t = 0.5)
•
 W
0
=0.5
•
W
1
=1
•
W
2
=1
•
a
0
= -1
•
Per a
1
=1 e a
2
= 1si ha: in=1.5 => 
 g(in)=1
  (funzione g a gradino)
•
Per a
1
=1 e a
2
= 0 si ha: in=0.5 => 
 g(in)=1
•
 Per a
1
=0 e a
2
= 0 si ha: in=-0.5 => 
 g(in)=0
20"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#2,2,"Il cervello
•Costituito da circa 1011 neuroni
•1014 sinapsi
•Segnali basati su potenziale elettrochimico
 Quando il potenziale 
sinaptico supera una certa 
soglia la cellula emette un 
impulso
3"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#20,20,"Porta NOT
•
(Soglia t = - 0.5)
•
 W
0
= - 0.5
•
W
1
= - 1
•
a
0
= -1
•
Per a
1
=1 => 
 g(in)=0
  (funzione g a gradino)
•
Per a
1
=0 si ha: in=0.5 => 
 g(in)=1
21"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#21,21,"Strutture di Rete
•
Ci sono due categorie principali di strutture di reti 
neurali:
•
Feed-forward 
 (o acicliche o alimentate in avanti)
•
Ricorrenti
  (o cicliche)
•
Noi ci occuperemo solo di reti feed-forward.
•
Esse sono una tipologia di reti neurali caratterizzate 
dall’avere un verso delle sinapsi, dallo strato di input allo 
strato di output.
22"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#22,22,"Esempio di Rete Feed-Forward
•
Una rete alimentata in avanti rappresenta una funzione dei 
suoi input:
a5
23"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#23,23,"•
L’output dell’intera rete 
 a
5
 è funzione dei suoi input 
 a 
•
I pesi 
 W
 agiscono da parametri della funzione. 
•
La rete calcola una funzione 
 f
W
(x) 
•
La funzione 
 f
W 
rappresenta una funzione dello 
 spazio 
delle ipotesi 
 H 
che può essere booleana o continua. 
•
Se i pesi vengono modificati, cambia la funzione 
rappresentata dalla rete. 
•
Le reti feed-forward sono in genere organizzate a strati, 
in modo tale che ogni unità riceva gli input solo dalle 
unità dello strato immediatamente precedente.
Esempio di Rete Feed-Forward
24"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#24,24,"•
Si tratta di una rete feed-forward in cui 
 tutti
 gli input sono 
collegati direttamente a 
 tutti
 gli output.
•
Esempio:
• 3 unità di output
• 5 unità di input
• 1 unità di output
• 2 unità di input
Reti Feed-Forward a Strato Singolo 
(percettroni)
25"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#25,25,"•
Esaminiamo lo spazio delle ipotesi che un percettrone 
può rappresentare.
•
Se ha una funzione di attivazione a soglia, si può 
pensare che il percettrone rappresenti una funzione 
booleana. 
•
Oltre alle funzioni elementari AND, OR e NOT viste 
prima, un percettrone può rappresentare funzioni 
booleane “complesse” in modo molto compatto. 
•
Vedi, ad esempio, la 
 funzione di maggioranza
 .
Reti Feed-Forward a Strato Singolo 
(percettroni)
26"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#26,26,"La Funzione di Maggioranza
•
Percettrone a soglia 
•
Restituisce 1 se e solo se più della metà dei suoi 
 n
 input binari 
vale 1 
•
Basta porre: W
j
=1 per ogni input e W
0
=n/2 
•
Un albero di decisione necessiterebbe di 
 O(2
n
)
 nodi per 
rappresentare la stessa funzione. 
27"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#27,27,"•Un percettrone a soglia non può rappresentare tutte le 
funzioni booleane. 
•Infatti restituisce 1 se e solo se la somma pesata dei suoi 
input è positiva: 
•L’equazione                 deﬁnisce un iperpiano  nello spazio 
degli input. 
•Il percettrone restituisce 1 se e solo se l’input si trova da 
una parte speciﬁca rispetto a tale iperpiano. 
•Per questo il percettore a soglia è chiamato anche 
separatore lineare .nX
j=0Wjxj>0 oppure:
Separabilità Lineare di un Percettrone a Soglia
WT·x>0
<latexit sha1_base64=""d9P2mD7Jg+O+gyHjQQ5KI5NUFrA="">AAACFnicbVC7TsNAEDyHVwgvAyXNKRESVWQHJKhQBA1lkPKSkhCdL5twyvmhuzVKZKXnE/gKWqjoEC0tBf+CbYwECVONZna1O+MEUmi0rA8jt7S8srqWXy9sbG5t75i7e03th4pDg/vSV22HaZDCgwYKlNAOFDDXkdByxpeJ37oDpYXv1XEaQM9lI08MBWcYS32z2EWYoDOMWrObOu3ygY/0R5rM6Dm1Cn2zZJWtFHSR2BkpkQy1vvnZHfg8dMFDLpnWHdsKsBcxhYJLmBW6oYaA8TEbQSemHnNB96I0y4wehpqhTwNQVEiaivB7I2Ku1lPXiSddhrd63kvE/7xOiMOzXiS8IETweHIIhYT0kOZKxCUBHQgFiCz5HKjwKGeKIYISlHEei2HcWtKHPZ9+kTQrZfu4XLk+KVUvsmby5IAUyRGxySmpkitSIw3CyT15JE/k2XgwXoxX4+17NGdkO/vkD4z3LwRxnsk=</latexit>
WT·x=0
<latexit sha1_base64=""ChE2zA/JsnaGrMeC8O8z0h7ASAE="">AAACFnicbVC7SgNBFJ2Nrxhfq5Y2Q4JgFXajoI0QtLGMkBckMcxObuKQ2QczdyVhSe8n+BW2WtmJra2F/+LuuoImnupwzr3ce44TSKHRsj6M3NLyyupafr2wsbm1vWPu7jW1HyoODe5LX7UdpkEKDxooUEI7UMBcR0LLGV8mfusOlBa+V8dpAD2XjTwxFJxhLPXNYhdhgs4was1u6rTLBz7SH2kyo+fUKvTNklW2UtBFYmekRDLU+uZnd+Dz0AUPuWRad2wrwF7EFAouYVbohhoCxsdsBJ2YeswF3YvSLDN6GGqGPg1AUSFpKsLvjYi5Wk9dJ550Gd7qeS8R//M6IQ7PepHwghDB48khFBLSQ5orEZcEdCAUILLkc6DCo5wphghKUMZ5LIZxa0kf9nz6RdKslO3jcuX6pFS9yJrJkwNSJEfEJqekSq5IjTQIJ/fkkTyRZ+PBeDFejbfv0ZyR7eyTPzDevwAC357I</latexit>
28"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#28,28,"• Percettrone elementare (senza strati nascosti): non può classificare 
pattern che non siano linearmente separabili.
• Questi casi però sono frequenti: ad esempio problema dello XOR .
• Caso particolare della classificazione di punti nell’ipercubo unitario: 
ogni punto è in classe 0 o in classe 1.
• Per lo XOR si considerano gli angoli del quadrato unitario (i punti 
(0,0), (0,1), (1,0) e (1,1))
Separabilità Lineare di un Percettrone a Soglia
29"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#29,29,"Marvin Minsky
Limiti del Percettrone 
30"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#3,3," Warren Sturgis McCulloch  (1899 – 1969) Neurofisiologo e cibernetico 
americano.  
 Walter Pitts  (1923 – 1969) fu un logico che lavorò nel campo della 
psicologia conoscitiva.  
Primo modello matematico di una cellula nervosa descritto in un famoso 
articolo: A Logical Calculus of the Ideas Immanent in Nervous Activity 
(1943).  
 Nello scritto del 1943 tentarono di dimostrare che il programma della 
macchina di Turing poteva essere effettuato anche in una rete finita di 
neuroni  e che il neurone fosse l’unità logica di base del cervello. I pionieri
4"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#30,30,"Marvin Minsky
1969 : Minsky e Papert, Perceptrons
Limiti del Percettrone 
31"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#31,31,"Apprendimento nel Percettrone
•
Nonostante il loro potere espressivo limitato, esiste un semplice 
algoritmo di apprendimento capace di adattare un percettrone a 
soglia a qualsiasi insieme di addestramento linearmente 
separabile (noi vedremo una versione dell’algoritmo per 
l’apprendimento nei percettroni a sigmoide). 
•
L’idea base dell’algoritmo è quella di calcolare i pesi della rete in 
modo tale da minimizzare una determinata funzione di costo 
sull’insieme di training. 
•
In tal modo il processo di apprendimento è formulato come una 
ricerca di ottimizzazione nello spazio dei pesi.
32"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#32,32,"•
La funzione di costo sull’insieme di training che viene usata 
tradizionalmente è la 
 somma dei quadrati degli errori
 , dove 
il singolo errore è la differenza tra l’output desiderato y e 
l’output della rete f
W
(
x
)
. 
Il quadrato dell’errore per un singolo 
esempio di training è il seguente: 
essendo 
 x
 il vettore relativo ai dati di input dell’esempio,            
y il valore corretto della funzione di output e f
 w
(
x
) il valore di 
output ottenuto dalla rete avente in input 
 x
.
E=1
2Err2=1
2(y fw(x))2
Apprendimento nel Percettrone
33"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#33,33,"Possiamo usare tale metodo per ridurre il quadrato dell’errore 
(ricerca del minimo globale) calcolando la derivata parziale di E 
rispetto ad ogni peso:
dove g’ è la derivata della funzione di attivazione.
Per la sigmoide:
Metodo della Discesa del Gradiente
34"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#34,34," α = step size  o tasso di apprendimento .Il peso deve essere aggiornato in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E vista in precedenza:
L’aggiornamento del peso è pertanto il seguente:
Metodo della Discesa del Gradiente
35"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#35,35,"Algoritmo completo di apprendimento 
a discesa di gradiente per percettroni
Metodo della discesa del gradiente
36"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#36,36," Gli esempi di addestramento vengono fatti passare attraverso la 
rete uno per volta, modificando leggermente i pesi a ogni 
iterazione per ridurre l’errore.  
 Ogni ciclo attraverso tutti gli esempi prende il nome di epoca . 
 Le epoche sono ripetute secondo un ben preciso criterio di 
terminazione (e.g., quando le modifiche dei pesi sono piccole). 
Altri metodi calcolano il gradiente per l’intero training set, 
sommando tutti i contributi dati dall’equazione precedente prima 
di aggiornare i pesi. 
Metodo della Discesa del Gradiente
37"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#37,37,"Percettrone a soglia
 Per percettroni a soglia  la g’(in)  è indefinita.
 In questo caso la regola di apprendimento del percettrone 
originale sviluppata da Rosenblatt (1957) è la seguente:
Essa è simile a quella vista, tranne per il fatto che la g’(in) è 
omessa. 
Poiché g’(in) è la stessa per tutti i pesi, la sua omissione 
cambia solo la dimensione e non la direzione 
dell’aggiornamento globale dei pesi.
38"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#38,38,"Il Percettrone di Rosemblatt
39"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#39,39,"Reti Feed-Forward Multistrato
 Si tratta di reti con unità nascoste, in cui esiste un 
verso di propagazione del segnale dall’input 
all’output. 
 Ciascun nodo dello strato i-mo è collegato con tutti 
i nodi dello strato i+1-mo. 
 Percettrone multistrato . 
40"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#4,4,"John McCarthy ha indicato il lavoro di Nicolas Rashevsky  (1936, 
1938) come il primo modello matematico di apprendimento neurale. 
 Alan Turing  (1948) scrisse un rapporto di ricerca intitolato Intelligent 
Machinery  che inizia con la frase "" I propose to investigate the 
question as to whether it is possible for machinery to show intelligent 
behaviour "" e prosegue descrivendo un'architettura di rete neurale 
ricorrente che ha definito "" B-type unorganized machines  ""e un 
approccio per addestrarla. 
Sfortunatamente, tale rapporto non è stato pubblicato fino al 1969 ed 
è stato quasi ignorato fino a poco tempo fa.I pionieri
5"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#40,40,"Esempio di Rete Neurale Feed-Forward Multistrato 
41"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#41,41,"Spazio delle ipotesi H per il  
percettrone multistrato
•
Il vantaggio di aggiungere strati nascosti è quello di 
ampliare lo spazio delle ipotesi rappresentabili dalla rete. 
•
Possiamo infatti considerare ogni unità nascosta come un 
percettrone che rappresenta una funzione a soglia 
morbida nello spazio di input (vedi figura seguente). 
•
Ogni unità di output può dunque rappresentare una 
combinazione lineare (a soglia morbida) di molte 
funzioni simili.
42"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#42,42,"Output di un Percettrone  
a due Input (con sigmoide)
43"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#43,43,"• Fig. (a): cresta  prodotta da due funzioni a 
soglia morbida rivolte in direzioni opposte 
e limitando il risultato con un’altra soglia.
• Fig. (b): protuberanza  prodotta dalla 
combinazione di due creste ad angolo retto 
(cioè, combinando le uscite di quattro unità 
nascoste).
(a) (b)⇓
Combinazione di Funzioni  
a Soglia Morbida
fw(x 1,x2) fw(x 1,x2)
44"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#44,44,"Con un solo strato nascosto sufficientemente grande 
possiamo rappresentare qualsiasi funzione continua degli 
input con accuratezza arbitraria. 
Con due strati nascosti possono essere rappresentate anche 
funzioni discontinue (il numero delle unità nascoste cresce 
esponenzialmente con il numero degli input).
Purtroppo, data una qualsiasi struttura di rete prefissata , è 
difficile stabilire esattamente quali funzioni possano essere 
rappresentate e quali non possano esserlo.
Reti Feed-Forward Multistrato
45"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#45,45,"Apprendimento nelle Reti  
Multistrato Feed-Forward 
Gli algoritmi per l’apprendimento per le reti multistrato sono 
simili all’algoritmo di apprendimento per i percettroni visto in 
precedenza.
Una differenza è costituita dal fatto che nelle reti multistrato 
avremo in generale più unità di output.
Ciò comporta che avremo un vettore di output fw(x) calcolato 
dalla rete anziché un valore singolo e, per ogni esempio, un 
vettore di output y.
46"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#46,46,"•L’idea base rimane la stessa, che è quella di calcolare i pesi della 
rete in modo da minimizzare la somma dei quadrati degli errori che, 
per un singolo esempio, è definita come segue:
•Dato un certo esempio, il vettore di errore in output è il seguente:
•Indichiamo come segue l’i-esimo componente del suddetto vettore:
•E’ inoltre utile definire come segue un errore modificato:
 
Apprendimento nelle Reti  
Multistrato Feed-Forward 
y fw(x)
47"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#47,47,"Back-propagation
 : strato di output
Per lo strato di output, il peso deve essere aggiornato
 in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 52 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
48"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#48,48,"Back-propagation
 : strato nascosto  
(versione intuitiva)
Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
Dobbiamo però definire una quantità analoga all’errore per i nodi di 
output.
E’ a questo punto che entra in gioco la retropropagazione :
L’idea  è  che  il  nodo  nascosto  j  sia  “responsabile”  per  una  parte  
dell’errore ∆i in ognuno dei nodi di output ai quali è collegato.
In tal modo i valori ∆ sono suddivisi in base alla forza delle connessioni 
tra nodo nascosto e nodo di output e passati all’indietro per fornire i 
valori ∆j allo strato nascosto.
49"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#49,49,"La regola di propagazione per i valori       è dunque la seguente:
L’aggiornamento del peso è pertanto il seguente, identica a quella 
che riguarda lo strato di output:
Back-propagation
 : strato nascosto  
(versione intuitiva)
50"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#5,5,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
6"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#50,50,"Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
L’idea è, di nuovo, quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 53 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
Back-propagation
 : strato nascosto  
(versione formale)
51"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#51,51,"Calcolo del gradiente  
(strato di output)
52"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#52,52,"Calcolo del gradiente  
(strato nascosto)
53"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#53,53,"Processo di Retropropagazione
In sintesi, il processo di retropropagazione può essere descritto 
come segue: 
•
Si calcolano i valori 
 ∆ 
per le unità di output usando l’errore 
osservato. 
•
Cominciando dallo strato di output, si ripete quanto segue per 
ogni strato della rete fino a raggiungere l’ultimo strato 
nascosto: 
o
si propagano all’indietro i valori ∆ verso lo strato 
precedente; 
o
si aggiornano i pesi tra i due strati.
54"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#54,54,"Back-propagation
1. Presentazione pattern d’ingresso 
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
55"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#55,55,"Unità di input akUnità di output ai
Unità nascoste aj2. Propagazione dell’input in avanti sullo strato nascosto 
Wk,jWj,i
Back-propagation
56"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#56,56,"3. Propagazione dallo strato nascosto allo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
57"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#57,57,"4. Calcolo dei valori DELTA per lo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
58"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#58,58,"5. Retropropagazione dell’errore
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
L’errore si retropropaga  su 
ciascun nodo proporzionalmente  
alla forza  di connessione tra il 
nodo nascosto e il nodo di output
Back-propagation
59"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#59,59,"6. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
60"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#6,6," Ogni unità i calcola per prima cosa una somma pesata 
dei propri input:
 Successivamente si applica una funzione di attivazione  
g alla somma per derivare l’output:
Unità di Calcolo nelle Reti Neurali
ini=nX
j=1Wj,iaj
<latexit sha1_base64=""eWDCyQ6ONiLa3NNG6gCYSqPL4Ko="">AAACI3icbVC7TsNAEDzzDOEVoKQ5ESFRoGADEjRIETSUIBGCFAdrfSxwcD5bd2sEsvwZfAJfQQsVHaKh4F+4hBS8phrN7Gp3Js6UtOT7797Q8Mjo2Hhlojo5NT0zW5ubP7ZpbgS2RKpScxKDRSU1tkiSwpPMICSxwnZ8vdfz2zdorEz1Ed1l2E3gQstzKYCcFNXWQsJbt1dIXUaS73Ae2jyJiqudoDwtdMnbjq/KkoerHKIrHtXqfsPvg/8lwYDU2QAHUe0jPEtFnqAmocDaTuBn1C3AkBQKy2qYW8xAXMMFdhzVkKDtFv1gJV/OLVDKMzRcKt4X8ftGAYm1d0nsJhOgS/vb64n/eZ2czre7LnOWE2rRO0RSYf+QFUa6xpCfSYNE0PscudRcgAEiNJKDEE7MXYVV10fwO/1fcrzeCDYa64eb9ebuoJkKW2RLbIUFbIs12T47YC0m2D17ZE/s2XvwXrxX7+1rdMgb7CywH/A+PgGXqaO/</latexit>
ai=g(ini)=g0
@nX
j=1Wj,iaj1
A
<latexit sha1_base64=""L8MWGsH2A4rKpI1HGBXATIbImqQ="">AAACOnicbVDBShxBEO3RxOjG6MYcvTRZAivIMqOB5CKIguRoIOsKO+tQ09aOpT09Q3dNUIb5o3xCvsKbJF68idd8QHo3e0g07/R4rx5V9dJSk+MwvAnm5p89X3ixuNR6ufxqZbX9eu3IFZVV2FeFLuxxCg41Gewzscbj0iLkqcZBerE/8Qdf0ToqzBe+KnGUQ2ZoTArYS0n7ABKSOzLrxoyXPl+TaRLa8JLMYo1j7srYVXlSn+9EzUltGjnwfJMaGW9KSM5jS9kZbyTtTtgLp5BPSTQjHTHDYdK+jU8LVeVoWGlwbhiFJY9qsExKY9OKK4clqAvIcOipgRzdqJ7+28h3lQMuZIlWkpZTEf9O1JA7d5WnfjIHPnOPvYn4P29Y8fjjyFdQVoxGTRYxaZwucsqSLxLlKVlkhsnlKMlIBRaY0ZIEpbxY+WZbvo/o8fdPydFWL9rubX1+39ndmzWzKNbFW9EVkfggdsUncSj6Qolv4lr8ED+D78FdcB88/BmdC2aZN+IfBL9+A3R4rDw=</latexit>
7"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#60,60,"7. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
61"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#61,61,"Esempio di Esecuzione
• Vediamo un esempio di esecuzione dell’algoritmo di Back-
propagation applicato sulla seguente rete:
a1 a2
0 1U1 U2
1 1U3 U4U5
1a5
W3,5=1.5 W4,5=-1.0
a3 a4
W1,3=1 W2,4=2W1,4=-1 W2,3=0.51 11Target = 1
Output Layer
Hidden Layer
Input Layer
62"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#62,62,"Esempio di Esecuzione
•Eseguiamo l’algoritmo su un solo esempio di addestramento e, per il 
quale dunque conosciamo l’output corretto ( Target = 1 ) a fronte di un 
certo input  X.
• Supponiamo che i valori dell’input per l’esempio e in questione 
siano i seguenti:
•  Input U1: 
•  Input U2:  
63"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#63,63,"Esempio di Esecuzione
1. Presentazione del pattern in ingresso :
64"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#64,64,"Esempio di Esecuzione
2. Passo Feed-Forward ( hidden layer ):
65"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#65,65,"Esempio di Esecuzione
3. Passo Feed-Forward ( output layer ):
66"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#66,66,"Esempio di Esecuzione
• A fronte di questo risultato in uscita possiamo calcolare il quadrato 
dell’errore:  
• L’errore non è molto alto, ma applicando l’algoritmo alla rete 
possiamo cercare di ridurlo.  
67"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#67,67,"Esempio di Esecuzione
4. Calcolo del valore ∆ in uscita ( output layer ):
68"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#68,68,"Esempio di Esecuzione
  5. Passo di Backward Propagation dell’errore ( hidden layer ):
69"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#69,69,"Esempio di Esecuzione
6. Passo di aggiornamento dei pesi ( link in ingresso all’output layer ):
70"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#7,7,"Unità di Calcolo nelle Reti Neurali
Usando funzioni diverse come 
 g
 si possono ottenere 
modelli differenti. Ad esempio:
g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
Funzione a gradino:
g(in i) = tanh(in i)
<latexit sha1_base64=""Cms3QN8iP8ejsRthjNVvwV/Syf0="">AAACH3icbVDLSgNBEJz1GeMr6tHLYBAUIexGQS9C0ItHBRMDSQi9Y5sMmZ1dZnrFEPIRfoJf4VVP3sSrB//F3c0ejFqnmqpueqr8SElLrvvpzMzOzS8sFpaKyyura+uljc2GDWMjsC5CFZqmDxaV1FgnSQqbkUEIfIU3/uA89W/u0VgZ6msaRtgJoKflnRRAidQtHfT22oQPNJJ63JX7nJ/yyZtA98dTXrFbKrsVNwP/S7yclFmOy27pq30bijhATUKBtS3PjagzAkNSKBwX27HFCMQAethKqIYAbWeUhRrz3dgChTxCw6XimYg/N0YQWDsM/GQyAOrb314q/ue1Yro76SSZophQi/QQSYXZISuMTNpCfisNEkH6c+RScwEGiNBIDkIkYpzUl/bh/U7/lzSqFe+wUr06KtfO8mYKbJvtsD3msWNWYxfsktWZYI/smb2wV+fJeXPenY/J6IyT72yxKTif33PtosY=</latexit>
 Tangente iperbolica:
Sigmoide: g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>
ReLU:g(in i) = max(in i,0)
<latexit sha1_base64=""fdZuD83MuMKqvRY6gR2pKYYhfhM="">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>
8"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#70,70,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
71"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#71,71,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
72"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#72,72,"Esempio di Esecuzione
• Ciò completa l’aggiornamento dei pesi per il training example 
corrente.
• Per verificare che l’algoritmo abbia effettivamente ridotto 
l’errore in output, eseguiamo la parte feed-forward ancora una 
volta per confrontare l’uscita attuale con la precedente.
73"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#73,73,"Esempio di Esecuzione
• Nuovo  Passo Feed-Forward ( hidden layer ):
74"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#74,74,"Esempio di Esecuzione
• Nuovo Passo Feed-Forward ( output layer ):
75"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#75,75,"Esempio di Esecuzione
• Il nuovo quadrato dell’errore è il seguente:
• La differenza con il vecchio valore è:
76"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#76,76,"Esempio di Esecuzione
• L’esecuzione dell’algoritmo di Backpropagation che abbiamo 
visto è relativo ad un solo passaggio per un solo esempio di 
addestramento.  
• Si ricorda che l’algoritmo completo fa passare gli esempi di 
addestramento attraverso la rete uno per volta, modificando 
leggermente i pesi a ogni iterazione per ridurre l’errore.  
  
• Ogni ciclo attraverso tutti gli esempi prende il nome di epoca .  
• Le epoche sono ripetute fino a quando non viene soddisfatto un 
criterio di terminazione (in genere, quando le modifiche ai pesi 
sono diventate molto piccole).  
77"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#77,77,"Sintesi degli Argomenti 
Trattati nella Lezione 
Una Rete Neurale è un modello computazionale che presenta alcune proprietà del cervello: consiste di molte 
unità semplici che lavorano in parallelo senza alcun controllo centralizzato.  Le connessioni tra le unità hanno 
pesi numerici che possono essere modiﬁcati dall’elemento di apprendimento.  
Il comportamento di una rete neurale è determinato dalla topologia delle connessioni e dalla natura delle 
singole unità. Le reti alimentate in avanti  in cui le connessioni formano un grafo diretto aciclico, sono le più 
semplici da analizzare. Le reti alimentate in avanti implementano funzioni senza stato. 
Un percettrone è una rete alimentata in avanti con un singolo strato di unità e può rappresentare solo funzioni 
linearmente separabili . Se i dati sono linearmente separabili si può utilizzare la regola di apprendimento del 
percettrone  per modiﬁcare i pesi della rete in modo da farli corrispondere esattamente ai dati. 
Le reti alimentate in avanti multistrato possono rappresentare qualsiasi funzione, dato un sufﬁciente numero di 
unità. 
L’algoritmo di apprendimento backpropagation (propagazione all’indietro ) funziona su reti multistrato 
alimentate in avanti effettuando una discesa del gradiente nello spazio dei pesi per minimizzare l’errore in 
uscita. Esso converge a una soluzione localmente ottima ed è stato usato con successo in un’ampia varietà di 
applicazioni. La sua convergenza è spesso molto lenta.
78"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#8,8,"Funzione Gradino
g
t0g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
ini
9"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#9,9,"Sigmoide
g
01g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>
ini
10"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 11)
1"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Richiami percettrone e MLP 
Sci-kit learn e percettrone 
MLP e regressione 
MLP e classiﬁcazione 
Keras 
Esempio fashion_mnist 
Keras: Sequential models, parametri, metriche, training, predizione"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Richiami: Multi-Layer Perceptron (MLP)
Perché è fondamentale inserire una funzione di attivazione? 
Se combiniamo diversi layer e unità otteniamo semplicemente una 
sequenza di combinazioni lineari, perciò una trasformazione lineare 
input-output. È come ottenere un singolo layer. Non possiamo 
rappresentare funzioni complesse non lineari.
11"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché nella MLP si preferisce la funzione logistica (o sigmoide) 
alla funzione gradino (o step function)?
12g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
Funzione a gradino:
Sigmoide: g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Richiami: Multi-Layer Perceptron (MLP)
Perché nella MLP si preferisce la funzione logistica (o sigmoide) alla 
funzione gradino (o step function)? 
Con la funzione gradino i gradienti genererebbero una superﬁcie piatta, 
che non permetterebbe di adattare i parametri. 
La funzione logistica è deﬁnita ed ha derivata ovunque.  
La ReLU non è differenziabile per 
 in=0
, e ha derivata 0 per 
 in<0
. Ma 
empiricamente mostra buone performance ed è rapido il calcolo della 
derivata. Inoltre non avendo un valore max in output riduce alcune 
problematiche nelle architetture più complesse.
13
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"MLP e regressione
Una MLP può essere usata per produrre un singolo valore, es. creando un 
layer di output con una singola unità. Nel caso di 
 multivariate regression
 , il 
layer può contenere più unità. 
Solitamente non si inserisce la funzione di attivazione in output in modo da 
non imporre intervalli. Se c'è bisogno di valori positivi si può inserire una 
ReLU
  o una 
 softplus activation function
  (una versione smooth della ReLU). 
La loss function usata durante il training è la 
 mean squared error
 . Nel caso 
di molti outlier nel training set è possibile considerare anche la 
 mean 
absolute error
 . La Huber loss è una combinazione di entrambe.
14"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"MLP e regressione: architettura tipica
Conﬁgurazione tipica degli iperparametri di una MLP usata per la 
regressione:
15
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"MLP e classiﬁcazione
Inserendo un layer con una singola unità e con funzione di attivazione 
logistica possiamo stimare la probabilità di appartenenza dell'input a una 
certa classe (binary classiﬁcation). Nel caso 
 multilabel binary classiﬁcation
 , 
(es. email spam/no_spam, urgent/no_urgent) si avranno più unità di output. 
Se una istanza può appartenere ad una di n possibili classi (es. una cifra da 
0 a 9), l'output layer conterrà n unità con una funzione 
 softmax
  che 
garantisce che ogni unità produca una probabilità la cui somma sia 1. In 
questo caso si impiega la 
 cross-entropy
  come funzione di loss. 
16
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"Keras
Keras (
 https://keras.io
 ) 
sono API per il Deep Learning ad alto livello per 
costruire ed addestrare architetture di reti neurali. 
Si basa a sua volta su librerie che permettono di eseguire le reti su varie 
piattaforme, es. TensorFlow, Microsoft Cognitive Toolkit (CNTK), Theano; 
Apache MXNet, Apple’s Core ML, Javascript o Typescript (Keras code in 
web browsers), or PlaidML (on GPUs). 
TensorFlow integra Keras e lo arricchisce di altre funzionalità (es. 
TensorFlow’s Data API) 
Installazione (via PIP):  
python3 -m pip install --upgrade tensorﬂow
17"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Keras: esempio 
 fashion_mnist
Entrambe le versioni corrispondono alla 2.8.0 
import
 tensorflow 
 as
 tf
from
 tensorflow 
 import
 keras
print
(tf.__version__)
print
(keras.__version__)
Impieghiamo il dataset fashion_mnist: 
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
print
(X_train_full.shape)
print
(X_train_full.dtype)
>> (60000, 28, 28)
>> uint8
X_valid, X_train = X_train_full[:
 5000
] / 
255.0
, X_train_full[
 5000
:] / 
255.0
y_valid, y_train = y_train_full[:
 5000
], y_train_full[
 5000
:]
class_names = [
 ""T-shirt/top""
 , 
""Trouser""
 , 
""Pullover""
 , 
""Dress""
, 
""Coat""
,
""Sandal""
 , 
""Shirt""
, 
""Sneaker""
 , 
""Bag""
, 
""Ankle boot""
 ]
print
(class_names[y_train[
 0
]])
>> 
'Coat'
18"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Keras: sequential models
Il modello 
 Sequential
  è il più semplice e consiste in una singolo stack di 
layers connessi sequenzialmente: 
model = keras.models.Sequential()
# converto le istanze in input in array 1D
# equivale a una operazione: X.reshape(-1,1)
# è obbligatorio specificare il input_shape
model.add(keras.layers.Flatten(input_shape=[
 28
, 
28
]))
# layer denso con 300 unità e ReLU come activation function
# ogni layer contiene i propri parametri (pesi e bias) riferiti alle 
connessioni
# con il layer precedente
model.add(keras.layers.Dense(
 300
, activation=
 ""relu""
))
# layer denso di 100 unità
model.add(keras.layers.Dense(
 100
, activation=
 ""relu""
))
# layer di output con 10 unità (una per classe) e softmax activation function
model.add(keras.layers.Dense(
 10
, activation=
 ""softmax""
 ))
19"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Keras: sequential models
In alternativa, invece di creare un layer alla volta, possiamo passare una 
lista al costruttore:  
model = keras.models.Sequential([
keras.layers.Flatten(input_shape=[
 28
, 
28
]),
keras.layers.Dense(
 300
, activation=
 ""relu""
),
keras.layers.Dense(
 100
, activation=
 ""relu""
),
keras.layers.Dense(
 10
, activation=
 ""softmax""
 )
])
Sono possibile varie forme di import, tutte equivalenti: 
from 
keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow.keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow 
 import 
keras
output_layer 
 = 
keras
.
layers
.
Dense
(
10
)
20"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Richiami: Percettrone
Una delle architetture più semplici, dove un singolo layer è connesso con 
tutti gli input dello strato precedente (
 fully connected 
 o
 dense layer
 ), cioè 
l'
input layer
 : 
Nota
 : nei precedenti lucidi si è usata la notazione dove gli input 
 x
 sono 
anche indicati con la lettera 
 a
. La step function 
 step()
  corrisponde alla 
funzione di attivazione 
 g(in).
3
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Keras: parametri
Per monitorare l'architettura creata usiamo la funzione summary():  
model
.
summary()
Nota: i layer densi contengono molti parametri (es. 235.500!)
21
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Keras: parametri
Per accedere ai singoli layers usiamo il parametro 
 layers
 , e le funzioni 
get_weights
 () e 
set_weights
 (): 
>>> 
model
.
layers
[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,
<tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,
<tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,
<tensorflow.python.keras.layers.core.Dense at 0x13240d240>]
>>> 
model
.
layers
[
1
]
.
name
'dense_3'
>>> 
model
.
get_layer
 (
'dense_3'
 )
.
name
'dense_3'
>>> 
weights
, 
biases 
= 
hidden1
.
get_weights
 ()
>>> 
weights
array([[ 0.03854964, -0.04054524, 0.00599282, ..., 0.02566582,
0.01032123, 0.06914985],
...,
[ 0.02632413, -0.05105981, -0.00332005, ..., 0.04175945,
0.0443138 , -0.05558084]], dtype=float32)
>>> 
weights
.
shape
(784, 300)
>>> 
biases
array([0., 0., 0., 0., 0., 0., 0., 0., 0., ..., 0., 0., 0.], dtype=float32)
>>> 
biases
.
shape
(300,)
22"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Keras: parametri
A cosa può servire una funzione set_weights()?
23"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Keras: parametri
A cosa può servire una funzione set_weights()? 
Possiamo operare regolarizzazioni manuali, oppure sovrascrivere i 
valori iniziali random con valori ottenuti da precedenti fasi di training. 
Per impiegare altri criteri di inizializzazione dei kernel (cioè delle matrici 
dei parametri della rete) consultare 
 https://keras.io/initializers/
24"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Keras: metriche
La funzione compile() prende in input la 
 loss 
function
  e il 
optimizer
 , cioè 
l'algoritmo per stimare i parametri, ed eventuali altri parametri, come la 
metrica per stimare l'errore:  
model
.
compile
(
loss
=
""sparse_categorical_crossentropy""
 ,
optimizer
 =
""sgd""
,
metrics
=
[
""accuracy""
 ])
Dove:  
loss=""sparse_categorical_crossentropy"" è equivalente a  
loss=keras.losses.sparse_categorical_crossentropy.  
optimizer=""sgd"" è equivalente a optimizer=keras.optimizers.SGD()  
metrics=[""accuracy""] è equivalente a 
metrics=[keras.metrics.sparse_categorical_accuracy]  
Per una lista completa consultare 
 https://keras.io/losses/  
https://keras.io/
optimizers/
   e  
https://keras.io/metrics/  
25"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"Keras: metriche
Nell'esempio impieghiamo 
 sparse_categorical_crossentropy
  loss perché 
abbiamo label sparse, cioè per ogni istanza abbiamo solo una target class 
da 0 a 9, e ogni classe è esclusiva.  
Se avessimo avuto un target on vettore di 10 reali, es [0,0,...,1.0,...,0] 
avremmo dovuto impiegare la 
 categorical_crossentropy 
 loss. Per convertire 
label sparse in vettori impiegare 
 keras.utils.to_categorical()
 . 
Per la binary classiﬁcation avremmo usato la 
 sigmoid
  activation invece 
della softmax, e la 
 binary_crossentropy
  loss.
26"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Keras: training
Inﬁne non ci resta che addestrare il modello: 
# il validation set è opzionale
>>> 
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
... 
validation_data
 =
(
X_valid
, 
y_valid
))
...
Train on 55000 samples, validate on 5000 samples
Epoch 1/30
55000/55000 [==========] - 3s 55us/sample - loss: 1.4948 - acc: 0.5757
- val_loss: 1.0042 - val_acc: 0.7166
Epoch 2/30
55000/55000 [==========] - 3s 55us/sample - loss: 0.8690 - acc: 0.7318
- val_loss: 0.7549 - val_acc: 0.7616
[...]
Epoch 50/50
55000/55000 [==========] - 4s 72us/sample - loss: 0.3607 - acc: 0.8752
- val_loss: 0.3706 - val_acc: 0.8728
Otteniamo una accuracy del 87% sul validation set dopo 50 epoche, simile 
all'accuracy del training set, perciò non dovrebbe esserci overﬁtting. 
27"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Keras: training
Sel nel dataset ci sono classi meno frequenti di altre, si può impiegare il 
parametro 
 class_weight
  nella funzione 
 ﬁt
() in modo da diminuire l'effetto 
delle classi più rappresentate.  
Si può fare lo stesso ma per le singole istanze col parametro 
 sample_weight 
Il parametro 
 history
  è creato dopo il ﬁt, e contiene un oggetto 
 History
  con 
dati utili relativi all'addestramento: 
import 
pandas 
as 
pd
pd
.
DataFrame
 (
history
.
history
)
.
     
plot
(
figsize
=
(
8
, 
5
))
plt
.
grid
(
True
)
# set the vertical range to [0-1]
plt
.
gca
()
.
set_ylim
 (
0
, 
1
) 
plt
.
show
()
Cosa puoi dire dal graﬁco?
28
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Keras: training
Conferma il probabile scarso overﬁtting.  
Al principio il modello si comporta meglio col validation set, ma spesso è 
dovuto al caso. 
Il ﬁtting termina con l'accuracy sul training leggermente migliori rispetto al 
validation, fenomeno che capita spesso per training lunghi. 
Il validation error è ancora in discesa quando termina il training. Conviene 
aumentare le epoche.
29
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#29,29,"Keras: training e test
Una volta terminato il training è possibile validare il modello sul test set: 
>>> 
model
.
evaluate
 (
X_test
, 
y_test
)
8832/10000 [==========================] - ETA: 0s - loss: 0.4074 - acc: 
0.8540
[0.40738476498126985, 0.854]
Le performance sono leggermente minori poiché gli iperparametri li 
abbiamo scelti in base al training e validation set. 
Ricordati di non modiﬁcarli in base al test set.
30"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Richiami: Percettrone
Un singolo percettrone, indicato anche con Threshold logic unit (TLU) o 
Linear threshold unit (LTU), può essere usato come classiﬁcatore.  
Se la combinazione lineare degli input è oltre una certa soglia l'output 
assumerà la classe ""positiva"", altrimenti ""negativa"". 
Il training consiste nel trovare i pesi 
 w
 (parametri). 
Una rappresentazione alternativa indica esplicitamente un layer 
passthtough
  per i valori in input, e una unità 
 bias
 che restituisce sempre 1. 
Nell'esempio ci sono 3 outputs, perciò 3 distinte classi binarie in output: 
4
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#30,30,"Keras: predizione
Una volta addestrato possiamo fare predizione: 
>>> 
X_new 
= 
X_test
[:
3
]
>>> 
y_proba 
 = 
model
.
predict
(
X_new
)
>>> 
y_proba
.
round
(
2
)
array([[0. , 0. , 0. , 0. , 0. , 0.09, 0. , 0.12, 0. , 0.79],
[0. , 0. , 0.94, 0. , 0.02, 0. , 0.04, 0. , 0. , 0. ],
[0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]],
dtype=float32)
Dall'esempio: class 9 (ankle boot) prob=79%, class 7 (sneaker) prob=12%, 
class 5 (sandal) prob=9% 
Se ci interessa solo la classe con probabilità più alta: 
>>> 
y_pred 
= 
model
.
predict_classes
 (
X_new
)
>>> 
y_pred
array([9, 2, 1])
>>> 
np
.
array
(
class_names
 )[
y_pred
]
array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')
31"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#31,31,"Esercizio
Impiegare il dataset MNIST (cifre numeriche) e una architettura simile 
all'esempio precedente.  
Valutare l'accuracy dopo 50 epoche. 
# import dataset
from
 keras.datasets 
 import
 mnist
# load dataset
(x_train, y_train),(x_test, y_test) 
 =
 mnist
.
load_data()
32
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#32,32,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
33"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Sci-kit learn: Perceptron
La classe Perceptron implementa un singolo TLU: 
import 
numpy 
as 
np
from 
sklearn.datasets 
 import 
load_iris
from 
sklearn.linear_model 
 import 
Perceptron
iris 
= 
load_iris
 ()
X 
= 
iris
.
data
[:, (
2
, 
3
)] 
# petal length, petal width
y 
= 
(
iris
.
target 
== 
0
)
.
astype
(
np
.
int
) 
# Iris Setosa?
per_clf 
 = 
Perceptron
 ()
per_clf
.
fit
(
X
, 
y
)
y_pred 
= 
per_clf
.
predict
([[
2
, 
0.5
]])
La classe Perceptron implementa un singolo TLU.  
L'apprendimento è basato sull'algoritmo Stochastic Gradient Descent, cioè 
sulla classe SGDClassiﬁer con i seguenti parametri: 
 loss
=""perceptron"", 
learning_rate
 =""constant"", 
 eta0
=1 (
learning rate
 ), and 
 penalty
 =None 
(
nessuna regolarizzazione
 ). Per ogni istanza in input i pesi sono aggiornati 
in base all'errore prodotto.
5"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Richiami: Multi-Layer Perceptron (MLP)
Al contrario della classiﬁcazione basata sulla logistic regression, il 
percettrone non produce probabilità, ma effettua predizioni in base ad una 
soglia preﬁssata. Per tale motivo si preferisce la logistic regression. 
Per stimare funzioni anche non lineare, si possono ""impilare"" più TLU 
raggruppati in singoli layer creando architetture 
 deep
 . Il ﬂusso dei segnali è 
monodirezionale (
 feedforward
 ).
6
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Richiami: Multi-Layer Perceptron (MLP)
L'algoritmo per stimare i pesi è 
 backpropagation
  training algorithm ed è 
basato sul calcolo dei gradienti degli errori rispetto ad ogni singolo 
parametro (
 automatic differentation
  o 
autodiff
 ).  
In particolare viene impiegato il 
 reverse-mode autodiff
 , adatto quando ci 
sono molte connessioni (pesi) e pochi output. 
In sintesi si analizzano 
 mini-batch
  di istanze estratte dal training set (es. 32). 
Alla ﬁne di una 
 epoca
  si è analizzato l'intero dataset. Il processo itera ﬁno 
alla convergenza. 
Il mini-batch viene dato in input alla rete e per ogni istanza viene ricavato 
l'output (
 forward pass
 ).  
Per mezzo della loss function è ricavato l'errore commesso dalla rete. 
La 
chain rule
  determina quanto ogni output contribuisce all'errore. Il 
processo è ripetuto anche per i layer precedenti, ﬁno all'input (
 reverse pass
 ). 
Inﬁne il 
 gradient descent
  impiega tali error gradients per aggiornare i pesi.
7"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: L'inizializzazione dei pesi deve essere random. Se tutti i pesi e 
bias fossero impostati a 0 cosa accadrebbe?
8"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Richiami: Multi-Layer Perceptron (MLP)
L'inizializzazione dei pesi deve essere random. Se tutti i pesi e bias fossero 
impostati a 0 cosa accadrebbe? 
Tutte le unità di un layer si comporterebbero nello stesso modo.  
Il backpropagation inﬂuenzerebbe tutte le unità allo stesso modo. 
Potremmo avere 100ia di unità per layer, ma è come se ne avessimo 
una sola. 
L'assegnazione casuale dei pesi evita la simmetria e, il backpropagation 
""addestra"" gruppi di unità in modo diverso.
9"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché è fondamentale inserire una funzione di attivazione?
10"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 12)
1"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Architetture non sequenziali e Keras 
Output multipli 
Keras: Modelli statici e dinamici  
Save & Restore 
Callbacks 
Early stopping 
TensorBoard 
Fine tuning degli iperparametri 
Numero hidden layers, numero nodi per layers 
TensorFlow playground"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Keras: Modelli dinamici
Si crea una subclass di 
 Model
 , nel costruttore si deﬁnisce il modello (cioè i 
layers) e nella funzione 
 call()
  si deﬁnisce come saranno elaborati i dati, e 
può comprendere loop, istruzioni if-else, etc. 
Per esempio, per il Wide & deep model: 
class 
WideAndDeepModel
 (
keras
.
models
.
Model
):
def 
__init__
 (
self
, 
units
=
30
, 
activation
 =
""relu""
, 
**
kwargs
):
super
()
.
__init__
 (
**
kwargs
) 
# standard args (e.g., name)
self
.
hidden1 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
hidden2 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
main_output 
 = 
keras
.
layers
.
Dense
(
1
)
self
.
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)
def 
call
(
self
, 
inputs
):
input_A
, 
input_B 
 = 
inputs
hidden1 
 = 
self
.
hidden1
(
input_B
)
hidden2 
 = 
self
.
hidden2
(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
main_output 
 = 
self
.
main_output
 (
concat
)
aux_output 
 = 
self
.
aux_output
 (
hidden2
)
return 
main_output
 , 
aux_output
model 
= 
WideAndDeepModel
 ()
11"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Keras: Modelli dinamici
I modelli dinamici hanno lo svantaggio che 
 non
 possono essere facilmente 
ispezionati da Keras, tantomeno essere salvati o clonati. 
Il metodo summary() restituisce una lista di layer ma non come sono 
connessi. 
12"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Keras: Save & Restore
Addestrare i modelli può richiedere molto tempo. È fondamentale poter 
salvare i parametri durante (
 checkpoints
 ) o alla ﬁne dell'addestramento. 
model
.
save
(
""my_keras_model.h5""
 )
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
Il salvataggio interessa i parametri, l'architettura, e gli iperparametri. 
Per il Model subclassing si usano le funzioni save_weights() e 
load_weights(), che interessano però solo i pesi.
13"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"Keras: callbacks
È possibile deﬁnire una funzione 
 callback
  che verrà invocata al principio e 
alla ﬁne di ogni epoca, o batch. Nell'esempio la funzione 
ModelCheckpoint salva il modello a intervalli regolari (default: alla ﬁne di 
ogni epoca): 
[
...
] 
# dopo la compilazione del modello
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
 (
""my_keras_model.h5""
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
10
, 
callbacks
 =
[
checkpoint_cb
 ])
Se impiego un validation set, posso usare il parametro save_best_only=True 
in ModelCheckpoint per salvare il modello quando le prestazioni sono le 
migliori. Se interrompo e incomincio di nuovo l'addestramento, riparto 
dall'ultimo modello potenzialmente privo di overﬁtting. 
Si può deﬁnire la propria callback agganciandola agli eventi 
on_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_begin(), 
on_batch_end(), on_batch_end()
 , es.: 
class 
PrintValTrainRatioCallback
 (
keras
.
callbacks
 .
Callback
 ):
  
def 
on_epoch_end
 (
self
, 
epoch
, 
logs
):
      
print
(
""\nval/train: {:.2f}""
 .
format
(
logs
[
""val_loss""
 ] 
/ 
logs
[
""loss""
]))
14"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"Keras: early stopping
Con la stessa tecnica possiamo interrompere il training se, dopo un certo 
numero di epoche (parametro 
 patience
 ), non ci sono incrementi di 
prestazioni tangibili: 
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
                                    
 (
""my_keras_model.h5""
 ,
save_best_only
 =
True
)
early_stopping_cb 
 = 
keras
.
callbacks
 .
EarlyStopping
                                    
 (
patience
 =
10
, 
restore_best_weights
 =
True
)
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
                    
 validation_data
 =
(
X_valid
, 
y_valid
),
                    
 callbacks
 =
[
checkpoint_cb
 , 
early_stopping_cb
 ]) 
# rollback al best model 
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
15"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"TensorBoard
Un tool utile per visualizzare l'andamento dell'addestramento. Aggiorna la 
visualizzazione in base a un ﬁle binario chiamato event ﬁle.  
Si possono salvare i dati di ogni training in una directory distinta, così è 
possibile caricarli e confrontarli. Di seguito TensorBoard si occupa di 
creare la directory e salvarci i dati: 
root_logdir 
 = 
os
.
path
.
join
(
os
.
curdir
, 
""my_logs""
 )
def 
get_run_logdir
 ():
import 
time
run_id 
= 
time
.
strftime
 (
""run_
%Y
_
%m
_
%d
-
%H
_
%M
_
%S
""
)
return 
os
.
path
.
join
(
root_logdir
 , 
run_id
)
run_logdir 
 = 
get_run_logdir
 () 
# es. './my_logs/run_2019_01_16-11_28_43'
[
...
] 
# Build and compile your model
tensorboard_cb 
 = 
keras
.
callbacks
 .
TensorBoard
 (
run_logdir
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
                    
 validation_data
 =
(
X_valid
, 
y_valid
), 
                    
 callbacks
 =
[
tensorboard_cb
 ])
16"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"TensorBoard
TensorBoard può funzionare come server in locale: 
$ 
tensorboard --logdir
 =
./my_logs --port
 =
6006
TensorBoard 2.0.0 at http://mycomputer.local:6006 
 (
Press CTRL+C to quit
 )
Per l'interfacciamento con Colab consultare: 
https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/
docs/get_started.ipynb
17
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Fine tuning degli iperparametri
Rispetto ad altri modelli le reti neurali hanno numerosi iperparametri da 
deﬁnire. Un approccio spesso usato è quello di esplorare lo spazio delle 
conﬁgurazioni con le classi 
 GridSearchCV
  o 
RandomizedSearchCV.  
Deﬁniamo una funzione che prende in input gli iperparametri da 
ottimizzare:  
def 
build_model
 (
n_hidden
 =
1
, 
n_neurons
 =
30
, 
learning_rate
 =
3e-3
, 
input_shape
 =
[
8
]):
model 
= 
keras
.
models
.
Sequential
 ()
# necessario per far si che il primo layer sia inizializzato correttamente
options 
 = 
{
""input_shape""
 : 
input_shape
 }
for 
layer 
in 
range
(
n_hidden
 ):
model
.
add
(
keras
.
layers
.
Dense
(
n_neurons
 , 
activation
 =
""relu""
, 
**
options
))
options 
 = 
{}
model
.
add
(
keras
.
layers
.
Dense
(
1
, 
**
options
))
optimizer 
 = 
keras
.
optimizers
 .
SGD
(
learning_rate
 )
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
optimizer
 )
return 
model
...
18"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Fine tuning degli iperparametri
Dopodiché istanziamo una regressione per Keras; 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default.  
Abbiamo appena creato un modello, e possiamo seguire i soliti step: 
keras_reg
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
              
 validation_data
 =
(
X_valid
, 
y_valid
),
              
 callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)])
mse_test 
 = 
keras_reg
 .
score
(
X_test
, 
y_test
)
y_pred 
= 
keras_reg
 .
predict
(
X_new
)
Qualsiasi parametro aggiuntivo passato a ﬁt() sarà inoltrato al modello 
Keras. 
19"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Fine tuning degli iperparametri
Miglioriamo l'esplorazione con un comportamento random, e deﬁnendo 
degli intervallo per i parametri impiegati: 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default. 
Possiamo deﬁnire intervalli da cui campionare casualmente i valori degli 
iperparametri che abbiamo deﬁnito in build_model(): 
from 
scipy.stats 
 import 
reciprocal
from 
sklearn.model_selection 
 import 
RandomizedSearchCV
param_distribs 
 = 
{
""n_hidden""
 : [
0
, 
1
, 
2
, 
3
],
""n_neurons""
 : 
np
.
arange
(
1
, 
100
),
""learning_rate""
 : 
reciprocal
 (
3e-4
, 
3e-2
),
}
# RandomizedSearchCV usa la K-fold cross-validation, ignora X/y_valid
rnd_search_cv 
 = 
RandomizedSearchCV
 (
keras_reg
 , 
param_distribs
 , 
n_iter
=
10
, 
cv
=
3
)
rnd_search_cv
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
,
validation_data
 =
(
X_valid
, 
y_valid
),
callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)]) 
20"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Architetture non sequenziali: wide & deep
Si possono impiegare architetture più complesse di quelle viste ﬁnora, ad 
esempio quelle non sequenziali. 
Nella 
 wide & deep 
 l'input è connesso direttamente con l'output. Questo 
permette di apprendere sia patterns 
 deep
  (con la pipeline MLP 
tradizionale), sia regole semplici, per mezzo del percorso breve.
3
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Fine tuning degli iperparametri
I valori degli iperparametri si ottengono alle variabili: 
>>> 
rnd_search_cv
 .
best_params_
{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}
>>> 
rnd_search_cv
 .
best_score_
-0.3189529188278931
>>> 
model 
= 
rnd_search_cv
 .
best_estimator_
 .
model
Si possono impiegare per validare il modello sul test set. 
Se lo spazio degli iperparametri è molto grande, si parte con una 
esplorazione grossolana degli intervalli, e successivamente si rafﬁna lo 
spazio limitandolo agli intervalli potenzialmente più promettenti. 
21"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Fine tuning degli iperparametri
Altre librerie per il tuning degli iperparametri: 
• 
Hyperopt
 : a popular Python library for optimizing over all sorts of complex 
search spaces (including real values such as the learning rate, or discrete values 
such as the number of layers).
• 
Hyperas
 , 
kopt 
 or 
Talos
 : optimizing hyperparameters for Keras model (the ﬁrst 
two are based on Hyperopt).
• 
Scikit-Optimize 
 (skopt): a general-purpose optimization library. The 
BayesSearchCV 
 class performs Bayesian optimization using an interface 
similar to 
Grid
 SearchCV .
• 
Spearmint
 : a Bayesian optimization library.
• 
Sklearn-Deap
 : a hyperparameter optimization library based on evolutionary 
algorithms, also with a 
 GridSearchCV
 -like interface.
22"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Numero di hidden layers
Una MLP con 1 hidden layer e un numero sufﬁciente di nodi può 
modellare qualsiasi funzione complessa. Ma le deep networks usano i nodi 
in modo più efﬁcienti, perciò richiedono meno potenza computazionale. 
Gli strati più vicini all'input possono rappresentare forme semplici e relative 
caratteristiche (es. segmenti, orientazioni), i layer intermedi combinano questi 
elementi per forme più complesse (es. quadrati, cerchi), mentre i layer ﬁnali si 
focalizzano sulle forme ad alto livello (es. viso delle persone). 
Inoltre le architetture deep riescono più facilmente a generalizzare a nuovi 
datasets.  
Una parte dei layers di una rete addestrata a riconoscere facce possono essere 
impiegati in una nuova rete per riconoscere tagli di capelli, evitando una scelta 
random dei parametri iniziali (
 transfer learning
 ). 
In generale si parte con pochi hidden layer (1 o 2) per task semplici, 
incrementandoli per task complessi, ﬁnché si raggiunge l'overﬁtting. Per i 
task molto complessi si cercano modelli pre-addestrati da cui partire con 
nuovi addestramenti. 
23"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Numero di nodi per layers
Il numero di nodi per l'input layer è determinato dalle istanze in entrata. 
I restanti layer tipicamente formano una piramide, dove i nodi si riducono 
all'avvicinarsi del layer di output. L'idea è che gli ultimi layer 
rappresentano poche e salienti features ad alto livello. 
Ma sperimentazioni più recenti suggeriscono di mantenere costante il 
numero di nodi per layer, ottenendo un singolo iperparametro da 
ottimizzare. 
Anche per il numero di nodi si può partire da un numero basso e 
incrementarlo ﬁno a quando può comparire l'overﬁtting.
24"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Altri iperparametri
Learning rate: il valore ottimale è solitamente la metà di quello massimo, 
cioè quello che genera divergenza nell'algoritmo di training.  
Si parte da un valore alto, dove si ha sicura divergenza, e poi si divide 
per 3 e si ripete ﬁno a quando la divergenza scompare. 
Batch size: inﬂuisce sia sulle performance che su tempo di addestramento. 
Solitamente inferiore a 32. Un valore basso garantisce una iterazione di 
training veloce. Un valore alto più precisione nella stima dei gradienti. 
Per altre raccomandazioni:  
Practical recommendations for gradient-based training of deep 
architectures   
 https://arxiv.org/abs/1206.5533  
25"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"TensorFlow Playground
Tool interattivo per sperimentare reti neurali 
https://playground.tensorﬂow.org/   
26
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Esercitazione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, 
cosa puoi constatare?  
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. 
Addestrala varie volte, cosa noti? 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
Aumenta i nodi a 8. Riprova. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 
8 nodi. Cosa noti?
27"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Esercitazione - soluzione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, cosa puoi constatare?  
Gli strati più vicini all'output sono più complessi. 
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Si accelera il training, ma ora i boundaries sono lineari. 
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. Addestrala varie volte, cosa noti? 
I tempi di apprendimento variano molto e spesso ci si blocca in minimi locali. 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
La rete non trova soluzioni buone. Troppi pochi parametri generano underﬁtting. 
Aumenta i nodi a 8. Riprova. 
Più veloce, e non ferma più come nel caso precedente. Reti più complesse hanno più chance di 
trovare soluzioni ottime o tendenti all'ottimo, anche se possono comunque rimanere ""bloccate"" su 
plateaus. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 8 nodi. Cosa noti? 
Training time più lungo, spesso rallentanti da plateaus. I nodi nei layer verso l'output si aggiornano 
più velocemente degli altri. È il 
 vanishing gradinets
  problem. Si può risolvere con una 
inizializzazione più accurata dei pesi, altri ottimizzatori (es. AdaGrad e Adam) e con la Batch 
normalization.
28"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
29"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Architetture non sequenziali e Keras
Impieghiamo le 
 functional API
  di Keras.  
Quando creiamo un layer possiamo passargli un parametro aggiuntivo che 
corrisponde all'input del layer, es: 
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
Il layer 
 Concatenate
  permette di concatenare e creare un input composito 
per un certo layer. 
input 
= 
keras
.
layers
.
Input
(
shape
=
X_train
.
shape
[
1
:])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
Concatenate
 ()[
input
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input
], 
outputs
=
[
output
])
4"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Architetture non sequenziali e Keras
Se volessimo suddividere l'input in 2 parti, eventualmente in 
sovrapposizione, e mandare su 2 strati distinti, allora dobbiamo creare 2 
input layers: 
input_A 
 = 
keras
.
layers
.
Input
(
shape
=
[
5
])
input_B 
 = 
keras
.
layers
.
Input
(
shape
=
[
6
])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input_B
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
]
, 
outputs
=
[
output
])
5
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Architetture non sequenziali e Keras
Avendo creato due input, dobbiamo speciﬁcarli esplicitamente nella 
funzione ﬁt(), dopo aver compilato il modello: 
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
""sgd""
)
X_train_A
 , 
X_train_B 
 = 
X_train
[:, :
5
], 
X_train
[:, 
2
:]
X_valid_A
 , 
X_valid_B 
 = 
X_valid
[:, :
5
], 
X_valid
[:, 
2
:]
X_test_A
 , 
X_test_B 
 = 
X_test
[:, :
5
], 
X_test
[:, 
2
:]
X_new_A
, 
X_new_B 
 = 
X_test_A
 [:
3
], 
X_test_B
 [:
3
]
history 
 = 
model
.
fit
(
(
X_train_A
 , 
X_train_B
 )
, 
y_train
, 
epochs
=
20
,
validation_data
 =
((
X_valid_A
 , 
X_valid_B
 ), 
y_valid
))
mse_test 
 = 
model
.
evaluate
 ((
X_test_A
 , 
X_test_B
 ), 
y_test
)
y_pred 
= 
model
.
predict
((
X_new_A
, 
X_new_B
))
6"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Output multipli
Perché costruire architetture con output multipli? 
Il task lo potrebbe richiedere, es. localizzare e classiﬁcare un oggetto in 
una foto, cioè un problema di regressione e classiﬁcazione.  
Lo stesso vale per task più distinti. Sebbene si possano addestrare reti 
distinte, conviene condividere i parametri che in qualche modo 
rappresentano potenziali features che sono di interesse per entrambi i 
task, in modo da dover addestrare una sola volta la rete. 
Implementare una forma di regolarizzazione dei parametri per ridurre 
l'overﬁtting. Se per esempio aggiungiamo un secondo output in una 
certa parte della rete, imponiamo che  
la sottorete si addestri in modo autonomo,  
senza dipendere dalla restante parte della rete.
7
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Output multipli e Keras
Per aggiungere un secondo output (aux) è sufﬁciente collegarlo al layer 
giusto e aggiungerlo alla lista degli output: 
[
...
] # Stesso codice visto fino al layer di output
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)(
hidden2
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
],
                             
 outputs
=
[
output
, 
aux_output
 ])
Ogni output deve possedere la propria 
 loss function
 , da indicare quando 
compiliamo. Solitamente si da più peso alla loss dell'output ﬁnale: 
model
.
compile
(
loss
=
[
""mse""
, 
""mse""
], 
loss_weights
 =
[
0.9
, 
0.1
], 
optimizer
 =
""sgd""
)
Nella architettura vogliamo che entrambi gli output producano lo stesso 
risultato (y_train): 
history 
 = 
model
.
fit
([
X_train_A
 , 
X_train_B
 ], [
y_train
, 
y_train
], 
epochs
=
20
,
                    
 validation_data
 =
([
X_valid_A
 , 
X_valid_B
 ], [
y_valid
, 
y_valid
])) 
8"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Output multipli e Keras
Durante l'addestramento, oltre alla loss totale, sarà prodotta anche la loss 
del layer di output principale e aux: 
total_loss
 , 
main_loss
 , 
aux_loss 
 = 
model
.
evaluate
 (
                             [
 X_test_A
 , 
X_test_B
 ], [
y_test
, 
y_test
])
Anche la funzione predict() produrrà un doppio output: 
y_pred_main
 , 
y_pred_aux 
 = 
model
.
predict
([
X_new_A
, 
X_new_B
])
9"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Keras: Modelli statici e dinamici
Entrambe le API, sequential e functional, seguono un approccio 
dichiarativo
 , dove prima si deﬁniscono i layer, come sono connessi, e 
successivamente viene avviato il ﬂusso dei dati. Si hanno i seguenti 
vantaggi: 
il modello può facilmente essere salvato, clonato e condiviso 
la struttura può essere visualizzata 
il framework può inferire il tipo di dati e controllare i tipi (favorisce il 
debug) 
Ma non si possono prevedere loop, architetture dinamiche, conditional 
branching e altri comportamenti dinamici. 
Per tale motivo si impiega il Subclassing API.
10"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Classiﬁcatore di Bayes"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#1,1,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#10,10,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#11,11,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#12,12,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
ℜ1eℜ2rappresentano due regioni disgiunte
dell’insieme deinumeri reali .
Sipuò dimostrare che esiste unpunto x*per il
quale l’errore èminimo .
Infatti per x*=x B(dove Bstaper Bayes) l’area
indicata come reducible error èpari a0.
Ciascuno dei due integrali esprime laparte
della distribuzione diprobabilità diuna classe
che cade nell’area dell’altra classe (errata) .
Inquesto caso, lasuperficie decisionale (vedi
dopo) èunpunto sull’asse deinumeri reali ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#13,13,"Classificatore di Bayes30 CHAPTER 2. BAYESIAN DECISION THEORY
2.7 Error Probabilities and Integrals
We can obtain additional insight into the operation of a general classiﬁer — Bayes or
otherwise — if we consider the sources of its error. Consider ﬁrst the two-category
case, and suppose the dichotomizer has divided the space into two regions R1andR2
in a possibly non-optimal way. There are two ways in which a classiﬁcation error can
occur; either an observation xfalls in R2and the true state of nature is ω1, orxfalls
inR1and the true state of nature is ω2. Since these events are mutually exclusive
and exhaustive, the probability of error is
P(error )= P(x∈R2,ω1)+P(x∈R1,ω2)
=P(x∈R2|ω1)P(ω1)+P(x∈R1|ω2)P(ω2)
=/integraldisplay
R2p(x|ω1)P(ω1)dx+/integraldisplay
R1p(x|ω2)P(ω2)dx. (68)
This result is illustrated in the one-dimensional case in Fig. 2.17. The two in-
tegrals in Eq. 68 represent the pink and the gray areas in the tails of the functions
p(x|ωi)P(ωi). Because the decision point x∗(and hence the regions R1andR2) were
chosen arbitrarily for that ﬁgure, the probability of error is not as small as it might
be. In particular, the triangular area marked “reducible error” can be eliminated if
the decision boundary is moved to xB. This is the Bayes optimal decision boundary
and gives the lowest probability of error. In general, if p(x|ω1)P(ω1)>p(x|ω2)P(ω2),
it is advantageous to classify xas in R1so that the smaller quantity will contribute
to the error integral; this is exactly what the Bayes decision rule achieves.
ω2 ω1
x
x* R2 R1p(x|ωi)P(ωi)
reducible
error
∫p(x|ω1)P(ω1)dx
R2∫p(x|ω2)P(ω2)dx
R1xB
Figure 2.17: Components of the probability of error for equal priors and (non-optimal)
decision point x∗. The pink area corresponds to the probability of errors for deciding
ω1when the state of nature is in fact ω2; the gray area represents the converse, as
given in Eq. 68. If the decision boundary is instead at the point of equal posterior
probabilities, xB, then this reducible error is eliminated and the total shaded area is
the minimum possible — this is the Bayes decision and gives the Bayes error rate.
In the multicategory case, there are more ways to be wrong than to be right, and
it is simpler to compute the probability of being correct. Clearly
P(correct )=c/summationdisplay
i=1P(x∈Ri,ωi)"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#14,14,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )
!Vogliamo eseguire la stima (grossolana) delle probabilità a priori 
delle classi wie delle densità di probabilità condizionali per un nuovo 
pattern xdata la classe wi  a partire dal training set (per la seconda 
stima consideriamo l’intorno del pattern xcerchiato in figura)"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#15,15,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#16,16,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#17,17,"Approccio Bayesiano
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes : approccio parametrico e
non-parametrico
Mentre
 lastima delle probabilità apriori èabbastanza semplice
(senon sihanno elementi sipossono ipotizzare leclassi
equiprobabili) ,laconoscenza delle densità condizionali è
possibile “solo inteoria”;nella pratica duesoluzioni :
Approccio
 parametrico :sifanno ipotesi sulla forma delle
distribuzioni (es.distribuzione multinormale )esiapprendono i
parametri fondamentali (vettore medio ,matrice dicovarianza )
daltraining set.
Approccio
 nonparametrico :siapprendono ledistribuzioni dal
training set(es.attraverso ilmetodo Parzen Window ).
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere unaragionevole certezza (osperanza )chelaforma della
distruzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
L’approccio
 parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#18,18,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#19,19,"Approccio Bayesiano
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere una ragionevole certezza (osperanza )che laforma della
distribuzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
!L’approccio parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#2,2,"Probabilità
Quando un agente conosce l’ambiente circostante , l’approccio
logico gliconsente di derivare piani efficaci . Ma gliagenti non 
hanno quasi maiaccesso a tutta l’informazione necessaria : 
devono quindi agire in condizioni di incertezza .
La teoria della probabilità èilmodo migliore di ragionare in 
condizioni di incertezza ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#20,20,"Distribuzione Normale (d=1)
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
N.B. La funzione p(x) sopra nonvaconfusa con la densità di probabilità assoluta 
checompare a denominatore del Teorema di Bayes. Sono due grandezze diverse !"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#21,21,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza!Vogliamo eseguire la stima dei parametri tramite il Metodo 
della Massima Verosimiglianza ( Maximum Likelihood )
Il metodo consiste nel massimizzare la funzione di verosimiglianza, definita in 
base alla probabilità di osservare una data realizzazione campionaria , 
condizionatamente ai valori assunti dai parametri statistici oggetto di stima"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#22,22,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#23,23,"Esempio Stima di µes(d=1)
8prof. Davide Maltoni –Università di Bologna
ML
Classificazione…in forma grafica

01495.07559.441
1416.32 855.171)25(4015.0 8.31829252
   
  e e p
ATTENZIONE SIAMO NEL 
CONTINUO :
𝑝è unadensità di 
probabilità : 𝑝(25) non è la 
probabilità del valore 25 
(questa vale 0!) ma la 
densità di probabilità nel
punto 25. Solo considerando
un intervallo di valori (anche
piccolo) sulla base possiamo
parlare di probabilità . 
In altre parole l’intervallo
𝑥,𝑥+𝑑𝑥ha probabilità
𝑝𝑥𝑑𝑥.N.B. Siamo nelcontinuo: p(25) è una densità di probabilità , non una probabilità !  "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#24,24,"Esempio Stima di µes(d=1)
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#3,3,"Spazio di Probabilità
Uno spazio di probabilità èuna terna (Ω, !, P) dove
!Ωèun insieme qualunque (in genere pensato come l’insieme
deirisultati possibili di un esperimento casuale );!!èdetta σ-algebra , ovvero un insieme di insiemi (glieventi ) 
per iquali sipuòcalcolare una probabilit à;
!P()èappunto una misura di probabilit àsuΩ(P:Ω → [0, 1]).
Per la precisione , una σ-algebra èuna famiglia di insiemi taliche
!∅∈!;!se A ∈!allora anche ilsuocomplementare Āèin!;
!unioni numerabili di elementi di !appartengono ancora ad !."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#4,4,"Spazio di Probabilità
Ad esempio : nell’esperimento “lancio di un dado”,
Ω= {1, 2, 3, 4, 5, 6}, !èla σ-algebra generata dagli
eventi elementari di Ω, cioè di fatto, quelli per iquali è
possibile calcolare una probabilit à.
Ad esempio E= “numero pari” = {2, 4, 6}, F= “numero
maggiore di 4” = {5, 6}. 
G = “ numero 7” appartiene a !?"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#5,5,"Esempio di Misura di Probabilità
Se ildado non ètruccato , cioèglieventi elementari sono
equiprobabili , allora
""#=#&'() *'+,-.+,/) '#
#&'() 0,(()1)/) 2)Ω
cioè, negli esempi precedenti
""#=#2,4,6
#1,2,3,4,5,6=3
6=1
2
"";=#5,6
#1,2,3,4,5,6=2
6=1
3"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#6,6,"Probabilità
Una probabilità (grado di credenza) èuna misura su un insieme di 
eventi che soddisfa tre assiomi (assiomi di Kolmogorov [1]):
!La misura di ogni evento è compresa fra 0 e 1;
!La misura dell’ intero insieme di eventi è 1;
!La probabilità dell’ unione di eventi disgiunti (o mutuamente
esclusivi )è pari alla somma delle probabilità dei singoli eventi .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
disgiunti quando la lorointersezione èvuota .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
indipendenti se P(A∩B) = P(A) ⋅P(B). 
[1] S. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , Pearson, 2020."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#7,7,"Probabilità
Un modello probabilistico consiste in uno spazio di possibili esiti
(cioè descrizioni complete di stati) mutuamente esclusivi insieme 
alla misura di probabilità associata ad ogni esito. 
Probabilità condizionata P(A/B) , dove Ae Bsono proposizioni (cioè 
enunciati che affermano che qualcosa è verificato): “la probabilità 
di A, posto che tutto quello che sappiamo èB”.
In altritermini, la probabilità condizionata P(A/B) esprime una 
“correzione ” delle aspettative per A, dettata dall’osservazione di B.
Esempio: P(carie/maldidenti)=0.8 indica che se un paziente ha il mal di 
denti e non è disponibile nessun’altra informazione, la probabilità che 
abbia una carie sarà 0.8.
N.B. La probabilità condizionata P(A/B) ha senso solo se Bha 
probabilità non nulla di verificarsi ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#8,8,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#9,9,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alla  
Regressione
Machine Learning "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Regressione 
Simple Linear Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo) 
Multiple Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo)
 
2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#10,10,"Il Processo di Training
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione
tra valori 
osservati e 
previsti ∀ iyi osservatoxi ŷi previsto
 11xi
Funzione  
di Costopesi ŵ 0 e ŵ 1  
calcolati(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#11,11," 12Il Processo di Training
•Dati di training : insieme di esempi ( xi, yi) relativi a casi conosciuti 
(i punti nel piano x-y), da utilizzare per calcolare la funzione di 
costo RSS. 
•Estrazione di features : in questo caso tale funzione è inattiva, nel 
senso che riproduce in uscita il suo ingresso xi. 
•Modello di ML : ipotesi f scelta, istanziata con i valori dei pesi più 
opportuni. 
•Comparazione tra dati osservati e dati previsti : per ogni esempio 
abbiamo il valore vero yi e il valore previsto ŷi, da utilizzare per il 
calcolo della funzione RSS. 
•Algoritmo di Apprendimento : algoritmo che calcola i pesi che 
minimizzano la funzione di costo RSS, da utilizzare per deﬁnire il 
modello di ML."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#12,12,"Minimizzazione  della funzione RSS
In sintesi, il processo di apprendimento è formulato come una 
ricerca di ottimizzazione (ricerca del minimo) nello 
 spazio dei 
pesi
. 
A tal ﬁne possiamo calcolare e avvalerci del 
 gradiente
  della 
“misura d’errore” 
 RSS
 deﬁnita in precedenza.  
Si può dimostrare che la 
 RSS
 è una funzione convessa.  
Ricordiamoci che, per funzioni convesse, quando il gradiente è 
uguale a zero si ha un minimo globale. 
 
13"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#13,13,"Minimo  di una funzione convessa
 
14
w0w1g
ŵ
w
ŵ0ŵ1
gradiente:ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#14,14,"Gradiente della funzione RSS
Il gradiente della funzione RSS: 
    
   è deﬁnito come segue:
 
15rRSS( w0,w1)=2
4@RSS
@w0
@RSS
@w13
5RSS( w0,w1)=NX
i=1[yi (w0+w1xi)]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#15,15,"Calcolo del Gradiente  
della funzione RSS
 
16rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5@RSS
@w1=NX
i=12[yi (w0+w1xi)]1·( xi)= 2NX
i=1[yi (w0+w1xi)]xi@RSS
@w0=NX
i=12[yi (w0+w1xi)]1·( 1) = 2NX
i=1[yi (w0+w1xi)]"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#16,16,"Algoritmi per adattare il modello 
Una volta calcolato il gradiente della funzione 
 RSS
, ci sono 
due possibili approcci per minimizzare la funzione di 
costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero (ossia al vettore nullo) e si 
risolvono le equazioni (non sempre è possibile o conveniente dal punto di 
vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
17"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#17,17,"Forma Chiusa (1/4)
Poniamo il gradiente uguale al vettore nullo: 
ossia:
 
18 2NX
i=1[yi (w0+w1xi)] = 0
 2NX
i=1[yi (w0+w1xi)]xi=0rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5=0"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#18,18,"Forma Chiusa (2/4)
Dalla prima equazione otteniamo:
 
19PN
i=1yi ˆw0PN
i=11 ˆw1PN
i=1xi=0
ˆw0=PN
i=1yi
N ˆw1PN
i=1xi
N
da cui si ha:"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#19,19,"Forma Chiusa (3/4)
Dalla seconda equazione otteniamo: 
da cui si ha:
 
20PN
i=1xiyi ˆw0PN
i=1xi ˆw1PN
i=1x2
i=0
ˆw1=PN
i=1xiyi ˆw0PN
i=1xiPN
i=1x2
i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#2,2,"Introduzione alla Regressione
 
3I modelli a regressione vengono utilizzati per prevedere 
variabili target su scala continua , il che li rende 
interessanti per risolvere molte questioni in ambito 
scientiﬁco e anche industriale, come ad esempio:
• trovare relazioni fra variabili 
• valutare tendenze 
• effettuare previsioni ( e.g., vendite di una azienda nei prossimi mesi )"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#20,20,"Forma Chiusa (4/4)
e con facili passaggi otteniamo: 
che, insieme a: 
vista in precedenza, ci consente di calcolare i valori dei due 
pesi che minimizzano la funzione RSS.
 
21ˆw1=PN
i=1xiyi PN
i=1xiPN
i=1yi
NPN
i=1x2
i (PN
i=1xi)2
N
ˆw0=PN
i=1yi
N ˆw1PN
i=1xi
N"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#21,21,"Gradient Descent (1/3)
Come sappiamo, con questo approccio dobbiamo 
aggiornare i pesi in modo tale da spostarci nella direzione 
opposta al gradiente:
 
22w(t+1) w(t) ↵·rRSS(w(t))
w=w0
w1 
dove:
ossia:
w(t+1)
0 w(t)
0 ↵·@RSS(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@RSS(w(t))
@w1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#22,22,"Gradient Descent (2/3)
Rivediamo l’espressione del gradiente di RSS: 
L’aggiornamento dei due pesi può dunque essere effettuato 
come segue, scegliendo un opportuno 
 step size
 :
 
23rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5=2
4 2PN
i=1[yi ˆyi(w0,w1)]
 2PN
i=1[yi ˆyi(w0,w1)]xi3
5
w(t+1)
0 w(t)
0+2↵·NX
i=1[yi ˆyi(w(t))]
w(t+1)
1 w(t)
1+2↵·NX
i=1[yi ˆyi(w(t))]xi"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#23,23,"Gradient Descent (3/3)
Dobbiamo inﬁne scegliere un 
 criterio di convergenza
 . 
Come già detto, per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
24krRSS(w(t))k2✏"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#24,24,"Algoritmo di Gradient Descent 
 
25w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
w(t+1)
0 w(t)
0+2↵·NX
i=1[yi ˆyi(w(t))]
w(t+1)
1 w(t)
1+2↵·NX
i=1[yi ˆyi(w(t))]xi
t t+1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#25,25,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Fino ad ora abbiamo ipotizzato, per la funzione 
 f(
x
)
, un andamento 
lineare per il nostro caso di studio relativo ai prezzi degli appartamenti. 
Tuttavia l’esperienza comune ci induce a pensare che la relazione tra 
le due variabili (area e prezzo di un appartamento) non sia proprio 
lineare. In genere, all’aumentare della metratura il prezzo aumenta ma 
non in modo esattamente proporzionale. Potremmo ipotizzare ad 
esempio una funzione quadratica o addirittura polinomiale di grado p: 
 
26f(x)=w0+w1x+w2x2
f(x)=w0+w1x+w2x2+···+wpxpy
Areax
y
Areax
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#26,26,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
In quest’ultimo caso avremmo una 
 Polinomial Regression
 , 
il cui modello è il seguente: 
 
27yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
In genere, le potenze della x sono trattate come differenti 
features
 : 
feature 1 = 1
feature 2 = x
feature 3 = x2
······ ···
feature p+1 = xp"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#27,27,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, con un solo input x
 i
, è il seguente: 
 
28yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i
dove le features che compaiono possono assumere forme 
diverse (non necessariamente solo potenze della x). "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#28,28,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Inoltre, è importante considerare anche il caso in cui ci 
siano più input. 
Per l’esempio degli appartamenti potremmo voler 
considerare non solo l’area ma anche altre caratteristiche 
(#bagni, #camere da letto, anno di costruzione, ecc.). 
In tal caso avremmo in input un vettore 
 x
i
 per ogni 
esempio noto, le cui componenti sono appunto l’area, il 
#bagni, ecc. 
    
 
29"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#29,29,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, che ha in input un vettore 
 x
i
, è pertanto il 
seguente: 
 
30
dove le features che compaiono, ciascuna delle quali è 
funzione del vettore 
 x
i
, possono assumere forme diverse. yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#3,3,"Modello a 
Regressione Lineare Semplice
 
4L’obiettivo di un modello a Regressione Lineare 
Semplice ( univariata ) consiste nell’individuare le 
relazioni esistenti tra un’unica caratteristica (la variabile 
descrittiva x) e una risposta continua (variabile target y)."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#30,30," 
31Anche in questo caso possiamo utilizzare, come funzione di 
costo da minimizzare, la RSS deﬁnita come segue, a partire 
da N osservazioni disponibili:
Il problema di addestrare il nostro modello è dunque quello 
di trovare i valori dei pesi ŵ0 ,ŵ1 ,…, ŵD che minimizzano la 
funzione RSS (convessa anche in questo caso).
Multiple Regression 
[caso di Linear Regression con Multiple Features]
RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0 0(xi)+ ···+wD D(xi))]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#31,31,"Il Processo di Training 
[caso di Linear Regression con Multiple Features]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione 
tra valori 
osservati e 
previsti ∀ iyi osservato(xi) ŷi previsto
 32xi
Funzione  
di Costovettore di pesi 
 ŵ calcolatoɸ
(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#32,32,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In molti casi può essere conveniente usare una 
notazione matriciale. 
L’espressione: 
 
33
relativa all’i-esimo valore per y, può essere scritta 
come segue: yi=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#33,33,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
 
34
oppure: yi=[w0w1···wD]·2
664 0(xi)
 1(xi)
···
 D(xi)3
775+✏i
yi=[ 0(xi) 1(xi)··· D(xi)]·2
664w0
w1
···
wD3
775+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#34,34,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In sintesi: 
 
35yi=DX
j=0wj j(xi)+✏i=wT· (xi)+✏i= T(xi)·w+✏i
w=2
664w0
w1
···
wD3
775 (xi)=2
664 0(xi)
 1(xi)
···
 D(xi)3
775
dove: 
xi=2
664xi,1
xi,2
···
xi,d3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#35,35,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Possiamo inﬁne rappresentare tutte le osservazioni y in 
modo compatto come segue: 
 
36
    ossia: 
y=  ·w+✏2
664y1
y2
···
yN3
775=2
664 0(x1) 1(x1)...  D(x1)
 0(x2) 1(x2)...  D(x2)
... ... ... ...
 0(xN) 1(xN)...  D(xN)3
775·2
664w0
w1
···
wD3
775+2
664✏1
✏2
···
✏N3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#36,36,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
dove: 
    
 
37✏=2
664✏1
✏2
···
✏N3
775 y=2
664y1
y2
···
yN3
775
 =2
664 0(x1) 1(x1) ...  D(x1)
 0(x2) 1(x2) ...  D(x2)
... ... ... ...
 0(xN) 1(xN) ...  D(xN)3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#37,37,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora la funzione RSS: 
 
38RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1✏2
i=✏T·✏
che possiamo scrivere anche così: RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1[yi ( 0(xi)w0+...+ D(xi)wD)]2=NX
i=1[yi  T(xi)·w]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#38,38,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Da una precedente espressione per 
 y
 ricaviamo il vettore 
 ε
: 
 
39✏=y  w y= w+✏)
La funzione RSS assume pertanto la seguente forma in notazione 
matriciale: 
RSS(w)=(y  w)T(y  w)"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#39,39,"Gradiente della funzione RSS 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora il gradiente della funzione RSS, partendo dalla 
precedente espressione matriciale. 
Applicando una nota regola di calcolo differenziale matriciale 
si ottiene: 
 
40rRSS(w)=r[(y  w)T(y  w)] = 2 T(y  w)"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#4,4,"Esempio 
 
5A titolo di esempio possiamo considerare il caso della 
previsione del prezzo di un appartamento (variabile target y) 
data la sua metratura (variabile descrittiva x).
Tipicamente, in casi come questo abbiamo a disposizione un 
certo numero di esempi (osservazioni), costituiti da 
appartamenti già venduti per ciascuno dei quali abbiamo a 
disposizione l’area in mq o in sq.ft. ( x) e il prezzo pagato per 
l’acquisto ( y).
Ciascuna delle suddette osservazioni può essere rappresentata 
da un punto in un piano cartesiano x-y, come illustrato nella 
ﬁgura che segue."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#40,40,"Algoritmi per adattare il modello 
[caso di Linear Regression con Multiple Features]
Anche in questo caso, una volta calcolato il gradiente della 
funzione 
 RSS
, ci sono due possibili approcci per 
minimizzare la funzione di costo: 
“Forma chiusa”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
41"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#41,41,"Forma Chiusa 
[caso di Linear Regression con Multiple Features]
Poniamo il gradiente uguale al vettore nullo: 
 
42ˆw=( T ) 1 Ty
da cui si ha:  2 Ty+2 T ˆw=0
 T ˆw= Ty
( T ) 1( T )ˆw=( T ) 1 Ty
Iˆ w =( T ) 1 TyrRSS(w)= 2 T(y  w)=0"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#42,42,"Gradient Descent (1/4) 
[caso di Linear Regression con Multiple Features]
Dobbiamo aggiornare il vettore dei pesi in modo tale da 
spostarci nella direzione opposta al gradiente:
 
43w(t+1) w(t) ↵·rRSS(w(t))
dove:
rRSS(w(t))=2
66664@RSS
@w0
@RSS
@w1
···
@RSS
@wD3
77775w(t)=2
6664w(t)
0
w(t)
1
···
w(t)
D3
7775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#43,43,"Gradient Descent (2/4) 
[caso di Linear Regression con Multiple Features]
I singoli pesi devono dunque essere aggiornati come segue:
 
44w(t+1)
0 w(t)
0 ↵·@RSS(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@RSS(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j ↵·@RSS(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D ↵·@RSS(w(t))
@wD"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#44,44,"Gradient Descent (3/4) 
[caso di Linear Regression con Multiple Features]
Per comprendere gli aggiornamenti da fare per i singoli pesi, 
calcoliamo la derivata parziale di RSS, espressa in questa 
forma:
 
45
rispetto al generico peso j-esimo:
@RSS(w(t))
@wj=NX
i=12[yi ˆyi(w(t))]·[ @ˆyi(w(t))
@wj]=
=2NX
i=1[yi ˆyi(w(t))]·[  j(xi)] = 2NX
i=1 j(xi)[yi ˆyi(w(t))]RSS(w(t))=NX
i=1[yi ˆyi(w(t))]2=NX
i=1{yi [ 0(xi)w(t)
0+···+ j(xi)w(t)
j+···+ D(xi)w(t)
D]}2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#45,45,"Gradient Descent (4/4) 
[caso di Linear Regression con Multiple Features]
Anche in questo caso dobbiamo inﬁne scegliere un 
 criterio 
di convergenza
 . 
Sappiamo che per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
46krRSS(w(t))k2✏"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#46,46,"Algoritmo di Gradient Descent 
[caso di Linear Regression con Multiple Features]
 
47w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
w(t+1)
j w(t)
j ↵⇤derivata parziale[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#47,47,"Riferimenti
 
48
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#5,5,"Esempio
 
6Il problema da risolvere è il seguente: scegliere lo spazio delle 
ipotesi  H (e.g., insieme di polinomi di grado massimo k) e la 
funzione f(x) (ipotesi) che approssima meglio le osservazioni 
disponibili di una funzione sconosciuta, da utilizzare per 
prevedere i prezzi di altri appartamenti (diversi dagli esempi).
y
Area xy
Area x
y
Area x
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#6,6,"Apprendimento induttivo 
(Inductive Learning method)
La difﬁcoltà che si incontra in tale attività è dovuta al 
fatto che non è facile stabilire se una particolare f sia una 
buona approssimazione della funzione sconosciuta. 
Una buona ipotesi si potrà generalizzare  bene, ossia 
potrà predire correttamente esempi che non ha ancora 
incontrato.Il problema dell’induzione
 7"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#7,7,"Simple Linear Regression Model
 
8In ﬁgura è rappresentato un modello lineare per f(x), dove il 
peso wo rappresenta l’intercetta e il peso w1 rappresenta la 
pendenza della retta. Si noti l’offset verticale che costituisce 
l’errore che in genere esiste tra la previsione e il valore effettivo. 
Abbiamo dunque, per il valore vero e quello previsto per un 
certo valore dell’ascissa:
yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
Area x
Prezzo"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#8,8,"Simple Linear Regression Model
 
9Supponiamo di scegliere il modello lineare. Una volta 
deﬁnito tale modello, ossia la forma della funzione f(x), 
occorre determinare i due pesi incogniti, ossia l’intercetta e la 
pendenza, che deﬁniscano la f(x) “migliore” secondo un certo 
criterio.
Un criterio possibile è quello di minimizzare gli errori che si 
hanno sulle osservazioni. "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#9,9,"Simple Linear Regression Model
 
10Una delle funzioni utilizzate a tal ﬁne, che deve essere per 
l’appunto minimizzata, è la Residual Sum of Squares (RSS) , 
deﬁnita come segue, a partire da N osservazioni disponibili:
RSS( w0,w1)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0+w1xi)]2
Il problema di addestrare il nostro modello è dunque quello 
di trovare i valori dei due pesi ŵ0 e ŵ1 che minimizzano la 
funzione RSS."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#0,0,"Distribuzione Normale Multivariata (Multinormale)
9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#1,1,"Richiami
!La Matrice di Covarianza si indica di solito con Σed è una generalizzazione del 
concetto di varianza al caso di dimensione maggiore di uno
!E’ una matrice che rappresenta la variazione di ogni variabile rispetto alle altre 
(inclusa se stessa)
!E’ sempre simmetrica e definita positiva (i.e., ha tutti gli autovalori strettamente 
positivi) ---> ammette sempre Matrice Inversa
!La Matrice Simmetrica è una matrice quadrata che ha la proprietà di essere la 
trasposta (vedi sotto) di se stessa 
!La Matrice Inversa di una matrice A è pari alla sua Matrice Aggiunta (i.e., Matrice 
Trasposta Coniugata) diviso il det(A)
!La Matrice Trasposta di una matrice è la matrice ottenuta scambiando le righe con 
le colonne
!La Matrice Trasposta Coniugata di una matrice a valori complessi è la matrice 
ottenuta effettuando la trasposta e scambiando ogni valore con il suo complesso 
coniugato"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#10,10,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#11,11,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#12,12,"Esempio Stima di µes(d=2)
14prof. Davide Maltoni –Università di Bologna
ML
Classificazionein forma grafica
vista 
dall’alto
vista 
laterale"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#13,13,"Classiﬁcatore di Bayes con Distribuzioni Multinormali
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#14,14,"15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
Classiﬁcatore di Bayes con Distribuzioni Multinormali"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#15,15,"Altri Esempi di Superfici Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadraticheStessa Matrice di Covarianza: Iper-piani
Iper-piano: sottospazio di dimensione inferiore di uno rispetto allo spazio in cui è 
contenuto"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#16,16,"Altri Esempi di Superﬁci Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadratiche
Differenti Matrici di Covarianza: Iper-quadratiche
Iper-quadratica: (iper -)superficie di uno spazio d -dimensionale sui complessi o sui 
reali rappresentata da un'equazione polinomiale del secondo ordine nelle variabili 
spaziali (coordinate)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#17,17,"Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
Obiettivo: stimare la classe di appartenenza del pattern x (57,168)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#18,18,"17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#19,19,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#2,2,"Richiami
!Premessa :lanozione diautovalore siriferisce alle sole matrici
quadrate ,ossia alle matrici aventi lostesso numero dirighe edi
colonne .
!Chiarito ciò,siaAuna matrice quadrata diordine nacoefficienti in
uncampo !(dove !potrebbe essere ilcampo ℝdeinumeri reali oil
campo ℂdeinumeri complessi ).
!Sidice cheloscalare λ0∈!èunautovalore della matrice quadrata
Aseesiste unvettore colonna non nullo v∈!ntale che
Av=λ0v
!Ilvettore vèdetto autovettore relativo all’autovalore λ0"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#20,20,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#21,21,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#22,22,"Bayes e Confidenza di Classificazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#23,23,"Bayes Parametrico In Pratica
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#24,24,"Bayes Parametrico In Pratica
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#25,25,"Problemi Closed e Open Set
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#26,26,"Problemi Closed e Open Set
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#3,3,"Richiami
!E’utile osservare chesevèunautovettore relativo all’autovalore λ0,
allora anche %v,con%∈!e%≠0,èunautovettore relativo aλ0.
!Infatti moltiplicando ambo imembri della relazione
Av=λ0v
perloscalare %≠0,siottiene
%(Av)=%(λ0v)⟺A(%v)=λ0(%v)
!Ciòdimostra cheanche %vèunautovettore associato aλ0."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#4,4,"9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#5,5,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#6,6,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti (!12=0) 
non siavera in generale , iClassificatori Naïve Bayes sidimostrano lavorare bene su
molti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#7,7,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#8,8,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ!Vogliano eseguire la stima dei parametri tramite il Metodo della 
Massima Verosimiglianza ( Maximum Likelihood )campioni in blu
vettore medio da 
stimare in rosso"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#9,9,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#0,0,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#1,1,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#10,10,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
Ricordiamo che x è il pattern da classificare, xisono i pattern del 
Training Set"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#11,11,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili hanno più
probabilità diesserlo inunospazio apiùdimensioni .
Qualsiasi modello lineare può essere trasformato inunmodello non
lineare applicando ilkernel trick (stratagemma del kernel) almodello :
sostituendo lesuefeature (predittori) conunafunzione kernel ."
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#12,12,"Kernel Trick
!Le funzioni kernel sono usate per operare nello spazio delle 
feature senza calcolare le coordinate dei dati nello spazio di 
input, ma piuttosto calcolando il prodotto scalare fra le immagini 
di tutte le copie di dati nello spazio funzione!Tale operazione è spesso computazionalmente più economica 
che l’esplicito calcolo delle coordinate, in quanto il prodotto 
scalare gode di alcune proprietà speciali!Infatti spesso si può calcolare φ(xi)""φ(xj) senza prima calcolare il 
valore di φ in ogni punto [dove x è il pattern nell’ input space (con 
ddimensioni) e φ(x) è il corrispondente pattern nel feature space 
(con m>d dimensioni)!Le funzioni kernel sono state introdotte per sequenze di dati, 
grafi, testi, immagini e vettori"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#13,13,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
In questo caso il valore 
dell’iperparametro h
non è legato alla 
lunghezza di uno 
spigolo dell’ipercubo, 
ma all’ ampiezza della 
funzione multinormale "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#14,14,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(N.B. In questo caso il valore dell’iperparametro hè legato alla lunghezza 
dello spigolo dell’ ipercubo )
(N.B. In questo caso il valore dell’iperparametro hè legato all’ampiezza della 
funzione multinormale )"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#15,15,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(con hlegato alla lunghezza dello spigolo dell’ ipercubo )
(con hlegato all’ampiezza della funzione normale )
Sipuò notare come nelcaso della Funzione Kernel normale ,lesuperfici
decisionali risultino molto piùregolari (smoothed)"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#16,16,"Riferimenti
!S.J. Russell, and P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!R. O. Duda, P. Hart, and D. G. Stork Pattern Classification , 
Wiley -Interscience, 2000.
!D. Maltoni, Machine Learning , Università di Bologna, 2021.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#17,17,"Matlab
Questo esempio mostra come eseguire la classificazione in Matlab tramite 
NaÏve Bayes Classifier
MATLAB > Help > Examples > Statistics and Machine Learning Toolbox > 
Classification
Dataset: Fisher’s Iris Data
Fisher's iris data consists of measurements on the sepal length, sepal width, 
petal length, and petal width for 150 iris specimens. There are 50 specimens 
from each of three species. Load the data and see how the sepal 
measurements differ between species. You can use the two columns 
containing sepal measurements.
load fisheriris
gscatter(meas(:,1), meas(:,2), species,'rgb','osd');
xlabel('Sepal length');
ylabel('Sepal width');
N = size(meas,1);
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#18,18,"Matlab
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#19,19,"Matlab
Approccio Parametrico: modelliamo ciascuna variabile in ciascuna classe tramite 
una distribuzione Gaussiana. Ci calcoliamo il resubstitution error (errore sul 
training set, di solito stima ottimistica dell’errore reale sul test set) e il cross -
validation error (in cui si suddivide il training set in gruppi di eguale numerosità, 
si esclude iterativamente un gruppo alla volta e lo si cerca di predire con i gruppi 
non esclusi)
nbGau = fitcnb(meas(:,1:2), species);
nbGauResubErr = resubLoss(nbGau)
[x,y] = meshgrid(4:.1:8,2:.1:4.5);
x = x(:);
y = y(:);
cp = cvpartition(species,'KFold',10)
nbGauCV = crossval(nbGau, 'CVPartition',cp);
nbGauCVErr = kfoldLoss(nbGauCV)
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbGauResubErr = 0.2200
nbGauCVErr = 0.2200
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#2,2,"Appr occi Non Parametrici e Stima della Densità
L'ipercubo (o n-cubo) è una forma geometrica regolare immersa in 
uno spazio di quattro o piùdimensioni
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#20,20,"Matlab
Approccio Non Parametrico: in questo caso modelliamo ciascuna variabile in 
ciascuna classe tramite una stima della densità di probabilità mediante funzione 
kernel (settata a ‘box’)
nbKD = fitcnb(meas(:,1:2), species, 'DistributionNames','kernel', 'Kernel','box');
nbKDResubErr = resubLoss(nbKD)
nbKDCV = crossval(nbKD, 'CVPartition',cp);
nbKDCVErr = kfoldLoss(nbKDCV)
labels = predict(nbKD, [x y]);
gscatter(x,y,labels,'rgb','osd')
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbKDResubErr = 0.2067
nbKDCVErr = 0.2133
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#21,21,"Esercizio 1
5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#22,22,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#23,23,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#24,24,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#25,25,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#26,26,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#27,27,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#28,28,"Esercizio 3
7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#29,29,"Esercizio 37) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#3,3,"Appr occi Non Parametrici e Stima della Densità
!In Teoria della Probabilità, la distribuzione binomiale è una 
distribuzione di probabilità discreta che descrive il numero di 
successi in un processo di Bernoulli!Tale processo vale nel caso di esperimenti di prove ripetute (i.e., 
esperimenti in cui si vuole misurare quante volte si verifichi un 
certo esito su tutte le prove effettuate)!E’ necessario che il risultato di una prova non influenzi le 
successive, ossia che le singole prove siano fra loro indipendenti!La formula da utilizzare in questi casi è la Formula di Bernoulli : 
se l’evento da noi indagato ha una probabilità p di verificarsi per 
ciascuna prova ed effettuiamo n prove indipendenti, la probabilità 
che l’evento si verifichi kvolte (con k ≤ n) è data da
P(k successi su n prove)=n
k⎛
⎝⎜⎜⎞
⎠⎟⎟pk⋅(1−p)n−k"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#30,30,"Esercizio 4 
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
  
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#31,31,"Esercizio 4
Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#32,32,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#33,33,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#34,34,"Si supponga di partecipare a un gioco 
a premi, in cui si può scegliere fra tre 
porte: dietro una di esse c’è 
un’automobile, dietro le altre, due 
capre. 
Si sceglie una porta, diciamo la numero 
1. A quel punto, il conduttore del gioco 
a premi, che sa cosa si nasconde 
dietro ciascuna porta, ne apre un’altra, 
diciamo la 3, rivelando una capra. 
Quindi domanda: “vorresti scegliere la 
numero 2 o conservare la tua scelta 
iniziale?”
Ti conviene cambiare la tua scelta 
originale?
Problema"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#35,35,"Dal quiz televisivo americano Let’s Make a Deal , 
condotto dal presentatore Maurice Halprin , noto
con lo pseudonimo di Monty Hall. 
4500 puntate dal 1963 al 1991.
Il concorrente deve scegliere una delle tre
porte chiuse cheha davanti a sé: dietro a due 
di esse c’èuna capra , dietro l’altra c’èuna 
automobile . 
Ovviamente , né luiné ilpubblico sanno dietro
a quale porta sitrova l’auto .
Il concorrente fa la suascelta .
Problema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#36,36,"A questo punto, ilpresentatore apre
una delle altre due porte , rivelando
una capra .
Quindi chiede al concorrente se vuole
mantenere la porta scelta , o se vuole
cambiarla .
Domanda : al concorrente conviene
cambiare ? 
La risposta sembra ovvia : sono rimaste
due porte , e dietro una di esse c’è
l’auto . Cambiare porta non dovrebbe
influenzare le probabilità di vincita chea 
questo punto èlogico ritenere pari a 1/2, 
chesidecida di cambiare o meno .Problema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#37,37,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#38,38,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#39,39,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#4,4,"Appr occi Non Parametrici e Stima della Densità
!Esempi di casi di distribuzione binomiale sono i risultati di una 
serie di lanci di una stessa moneta o di una serie di estrazioni 
da un'urna (con reintroduzione o reimbussolamento), ognuna 
delle quali può fornire due soli risultati : il successo con 
probabilità pe il fallimento con probabilità q=1−p!Reimbussolamento: dovendo estrarre un certo numero di 
carte/palline/numeri da un mazzo/urna/bussolo, ogni oggetto 
estratto è immesso nuovamente prima di estrarre 
carte/palline/numeri successivi"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#40,40,"h""ps ://www.youtube.com /watch?v =nYX8DMG8_ywProblema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#5,5,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#6,6,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#7,7,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#8,8,"Iperparametri
14prof. Davide Maltoni –Università di Bologna
ML
FondamentiIperparametri
Molto
 algoritmi richiedono didefinire, primadell’apprendimento
vero eproprio, ilvalore deicosiddetti iperparametri H.
Esempi
 diiperparametri :
Il
numero dineuroni inunareteneurale .
Il
numero divicini kinunclassificatore k-NN.
Il
grado diunpolinomio utilizzato inunaregressione .
Il
tipodilossfunction .
Si
procede con unapproccio adue livelli nelquale perogni
valore «ragionevole » degli iperparametri si esegue
l’apprendimento, ealtermine della procedura siscelgono gli
iperparametri chehanno fornito prestazioni migliori .
Ma
come sivalutano leprestazioni ,esuquali dati?"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#9,9,"Iperparametri
!Ricordiamo che
!Il Training Set è l’insieme di pattern su cui addestrare il 
sistema, trovando il valore ottimo per i parametri (e.g., i pesi 
delle connessioni in una rete neurale)!Il Validation Set è l’insieme di pattern su cui tarare gli 
iperparametri (ciclo esterno)!Il Test Set è l’insieme di pattern su cui valutare le prestazioni 
finali del sistema
!N.B. Sempre forte è la tentazione di tarare gli iperparametri 
direttamente sul Test Set, ma questo dovrebbe essere evitato, 
pena sovrastima delle prestazioni! "
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2019 -2020
Bayes & Nearest Neighbor"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#1,1,"Classiﬁcatore Nearest Neighbor (NN)
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#10,10,"Da NN a k-NN
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#11,11,"Da NN a k-NN
28prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDa NN a k-NN
La
regola nearest neighbor produce unpartizionamento dello
dello spazio, noto come tassellazione diVoronoi :
Ogni elemento 𝐱𝑖∈TSdetermina untassello, all’interno delquale i
pattern saranno assegnati allastessa classe di𝐱𝑖.
La
regola diclassificazione nearest neighbor èpiuttosto radicale ;
infatti basta che unelemento deltraining setnon siamolto
“affidabile” (outlier )affinché tuttiipattern nelle suevicinanze siano
inseguito etichettati noncorrettamente .
Che
 errore commette ilclassificatore NNsultraining set?
Un
modo generalmente piùrobusto ,chepuòessere visto come
estensione della regola nearest -neighbor (inquesto caso detta
1-nearest neighbor )èilcosiddetto classificatore k-nearest
neighbor (k-NN).
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#12,12,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#13,13,"k-Nearest Neighbor ( k-NN)4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#14,14,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#15,15,"k-Nearest Neighbor ( k-NN)28 CHAPTER 4. NONPARAMETRIC TECHNIQUES
Here the summation over the ﬁrst bracketed term represents the probability of error
due to ipoints coming from the category having the minimum probability and k−i>i
points from the other category. The summation over the second term in the brackets
is the probability that k−ipoints are from the minimum-probability category and
i+1<k−ifrom the higher probability category. Both of these cases constitute
errors under the k-nearest-neighbor decision rule, and thus we must add them to ﬁnd
the full probability of error (Problem 18).
Figure 4.16 shows the bounds on the k-nearest-neighbor error rates for several
values of k. As kincreases, the upper bounds get progressively closer to the lower
bound — the Bayes rate. In the limit as kgoes to inﬁnity, the two bounds meet and
thek-nearest-neighbor rule becomes optimal.
0 0.1 0.2 0.3 0.40.10.20.30.4
Bayes Rate
P*P
1
3
5
9
150.5
Figure 4.16: The error-rate for the k-nearest-neighbor rule for a two-category problem
is bounded by Ck(P∗) in Eq. 55. Each curve is labelled by k; when k=∞, the
estimated probabilities match the true probabilities and thus the error rate is equal
to the Bayes rate, i.e., P=P∗.
At the risk of sounding repetitive, we conclude by commenting once again on the
ﬁnite-sample situation encountered in practice. The k-nearest-neighbor rule can be
viewed as another attempt to estimate the a posteriori probabilities P(ωi|x) from
samples. We want to use a large value of kto obtain a reliable estimate. On the
other hand, we want all of the knearest neighbors x′to be very near xto be sure
thatP(ωi|x′) is approximately the same as P(ωi|x). This forces us to choose a
compromise kthat is a small fraction of the number of samples. It is only in the limit
asngoes to inﬁnity that we can be assured of the nearly optimal behavior of the
k-nearest-neighbor rule.
4.5.5 Computational Complexity of the k–Nearest-Neighbor
Rule
The computational complexity of the nearest-neighbor algorithm — both in space
(storage of prototypes) and time (search) — has received a great deal of analy-
sis. There are a number of elegant theorems from computational geometry on the
construction of Voronoi tesselations and nearest-neighbor searches in one- and two-
dimensional spaces. However, because the greatest use of nearest-neighbor techniques
is for problems with many features, we concentrate on the more general d-dimensional
case.
Suppose we have nlabelled training samples in ddimensions, and seek to ﬁnd
the closest to a test point x(k= 1). In the most naive approach we inspect each
stored point in turn, calculate its Euclidean distance to x, retaining the identity only
of the current closest one. Each distance calculation is O(d), and thus this search4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)Inparticolare ,sipuò dimostrare (vedi Duda etal.,2000 )che Ck(P*) èdefinita come
lapiùpiccola funzione concava diP*maggiore di"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#16,16,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#17,17,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#18,18,"Espansione Lucido Precedente (k=1,3)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#19,19,"Espansione Lucido Precedente (k=5,7)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#2,2,"Classiﬁcatore Nearest Neighbor (NN)
26prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore Nearest Neighbor (NN)
Data una metrica 𝑑𝑖𝑠𝑡(∙)nello spazio multidimensionale (es.
distanza euclidea )ilclassificarore nearest neighbor (letteralmente “il
piùvicino traivicini”),classifica unpattern𝐱conlastessa classe
dell’elemento 𝐱′adesso piùvicino neltraining setTS:
𝑑𝑖𝑠𝑡𝐱,𝐱′=𝑚𝑖𝑛
𝐱𝑖∈TS𝑑𝑖𝑠𝑡𝐱,𝐱𝑖
Invece
 diderivare daidatiledistribuzioni condizionali delle classi
perpoifaruso della regola diBayes perlaclassificazione,
questo classificatore cerca inmodo piuttosto pragmatico di
massimizzare direttamente laprobabilità aposteriori ;infatti se𝐱′
èmolto vicino a𝐱èlecito supporre che:
𝑃𝑤𝑖𝐱≈𝑃𝑤𝑖𝐱′
In
effetti, sipuòdimostrare (solo però nelcaso diTSpopolato da
infiniti campioni) chelaprobabilità dierrore P(nella figura sotto)
della regola nearest neighbor nonèmaipeggiore deldoppio del
minimo errore possibile P*(quello Bayesiano ).
Nella
 pratica ,questo non significa però chel’approccio
Bayesiano fornisca sempre risultati migliori dinearest neighbor ,
infatti selastima delle densità condizionali èpoco accurata i
risultati delclassificatore Bayesiano possono essere peggiori .
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#20,20,"Espansione Lucido Precedente (k=9,11)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#21,21,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#22,22,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#23,23,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#24,24,"k-NN e Conﬁdenza di Classiﬁcazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#25,25,"k-NN e Confidenza di Classificazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#26,26,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#27,27,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/
https ://github.com /mariusmuja /flann"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#28,28,"NN e Complessità ComputazionaleFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relative"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#29,29,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi non appartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#3,3,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#30,30,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#31,31,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#32,32,"NN e Metriche
35prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Metriche
Il
comportamento della regola k-NNèstrettamente legato alla
metrica (funzione distanza )adottata .
La
distanza euclidea ,cherappresenta ilcaso L2nella definizione
dimetriche diMinkowski ,èsicuramente lametrica piùspesso
utilizzata .
𝐿𝑘𝐚,𝐛=෍
𝑖=1𝑑
𝑎𝑖−𝑏𝑖𝑘1/𝑘
Nella
 pratica ,prima diadottare semplicemente ladistanza
euclidea èbene valutare lospazio divariazione delle componenti
(ofeature )elapresenza dieventuali forti correlazioni trale
stesse .
Supponiamo
 adesempio divoler classificare lepersone sulla
basedell’altezza edella lunghezza delpiede .Ogni pattern𝐱
(bidimensionale) risulta costituito dadue feature (𝑥1=altezza,
𝑥2=lunghezza delpiede) .
Lospazio divariazione dell’altezza (210-140 =70cm) risulta
maggiore diquello della lunghezza delpiede (40-20=20cm).
Pertanto selasimilarità trapattern venisse misurata consemplice
distanza euclidea lacomponente altezza“peserebbe ”piùdella
componente lunghezza delpiede .𝑥2140 cm 210 cm𝑥1
20 cm40 cm"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#33,33,"NN e Metriche
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#34,34,"Normalizzazione
36prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNormalizzazione
Perevitare iproblemi legati adiversi spazi divariazioni delle feature ,
particolarmente fastidiosi peralcune tecniche (es.retineurali), si
consiglia dinormalizzare ipattern .
Lenormalizzazioni piùcomuni sono :
Min
-Max scaling :per ogni feature 𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcolano il
massimo 𝑚𝑎𝑥𝑖eilminimo𝑚𝑖𝑛𝑖esiapplica una trasformazione
lineare (scaling )che«tipicamente» mappa𝑚𝑖𝑛𝑖a0e𝑚𝑎𝑥𝑖a1.
𝑥′=𝑥−𝑚𝑖𝑛𝑖/𝑚𝑎𝑥𝑖−𝑚𝑖𝑛𝑖
Standardization
 :perogni feature𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcola lamedia
𝑚𝑒𝑎𝑛𝑖eladeviazione standard 𝑠𝑡𝑑𝑑𝑒𝑣 𝑖esitrasformano ivalori
come :
𝑥′=𝑥−𝑚𝑒𝑎𝑛𝑖/𝑠𝑡𝑑𝑑𝑒𝑣 𝑖
Dopo latrasformazione tutte lefeature hanno (sul training set)
media 0edeviazione standard 1.
Attenzione :iparametri della normalizzazione (es.minimi, massimi) si
calcolano sulsolo training setelatrasformazione siapplica siaatutti
idati(training, validation ,test).
Lesemplici tecniche sopra descritte operano sulle singole feature
indipendentemente .Una tecnica dinormalizzazione efficace (mapiù
costosa) che opera simultaneamente sututte lefeature tenendo
conto della lorocorrelazione èlaWhitening transform ."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#35,35,"Normalizzazione
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#36,36,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, matraloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#37,37,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#38,38,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, ma traloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#39,39,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#4,4,"Classiﬁcatore Nearest Neighbor (NN)
Quando laprobabilità aposteriori diuna classe èvicina a1,la
probabilità dierrore Bayesiano P*èpiccola ,così come la
probabilità dierrore Pdella regola nearest neighbor .Quando
ciascuna classe èquasi ugualmente probabile ,siaBayes cheNN
hanno untasso dierrore ~(1-1/c),con cnumero diclassi .Nel
mezzo, iltasso dierrore NNèlimitato daltasso dierrore diBayes :
!∗≤!≤!∗2−%
%−1!∗(Eq.52)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#40,40,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti
(!12=0) non siavera in generale , iClassificatori Naive Bayes sidimostrano lavorare
bene sumolti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#41,41,Whitening Transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#42,42,"Metric Learning
38prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMetric Learning
Unapproccio piùgenerale allascelta della metrica dautilizzare in
unadeterminata applicazione, consiste nellearning supervisionato
della metrica stessa daidatideltraining set.
Obiettivo èdeterminare unatrasformazione degli input che:
«avvicini »pattern della stessa classe
«allontani »pattern diclassi diverse
Ladistanza euclidea nella spazio originale è:
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐚−𝐛𝑡𝐚−𝐛=𝐚−𝐛2
Untipico approccio dimetric learning lineare determina (con
training supervisionato) una matrice 𝐆che trasforma gliinput, e
continuare adapplicare ladistanza euclidea agliinput trasformati
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝐚−𝐆𝐛2
Vedremo una possibile soluzione diquesto problema nell’ambito
della riduzione didimensionalità con LDA (Linear Discriminant
Analysys ).
Sono anche possibili approcci nonlineari :
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝜙𝐚−𝐆𝜙𝐛2
dove𝜙èunafunzione nonlineare ."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#43,43,"Metric Learning
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#44,44,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#45,45,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#46,46,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (3 ed.) , Pearson, 2009.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. "
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#5,5,"Esempi NN
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#6,6,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempi Bayes"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#7,7,"Esempi NN
27prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi NN
Nell’esempio visto in precedenza, 
 la regola NN assegna il 
pattern 𝐱alla classe 𝑤1(maschi -blu)
La figura seguente mostra il partizionamento dello spazio 
operato dalla regola NN su un training set con 5 classi:
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#8,8,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#9,9,"Da NN a k-NN
"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Classiﬁcatore Bayesiano (Ex 13)
1"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#1,1,"Sommario
..."
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#10,10,"Naive Bayes classiﬁer: step 2
Per ogni dataset ricaviamo 2 statistiche: media e deviazione standard. 
La media può essere ricavata così: 
 μ
 = sum(x)/n * count(x) 
    
dove x è la lista dei valori (o colonna) sui cui stiamo stimando la media.  
# Calculate the mean of a list of numbers
def mean
 (
numbers
)
:
return 
sum
(
numbers
)
/
float
(
len
(
numbers
))
Per la deviazione standard 
 σ
 si ha: 
 sqrt( 
Σ
i
(x
i
 – 
μ
(x))
2
 / N-1)  
from math import 
 sqrt
 
# Calculate the standard deviation of a list of numbers
def stdev
 (
numbers
)
:
avg
 = 
mean
(
numbers
)
variance
  = 
sum
([(
x
-
avg
)
**
2 
for 
x 
in 
numbers
])
 / 
float
(
len
(
numbers
)
-
1
)
return 
sqrt
(
variance
 )
Media e deviazione standard devono essere calcolate per ogni feature e 
considerando tutte le istanze.
11"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#11,11,"Naive Bayes classiﬁer: step 2
Media e deviazione standard devono essere calcolate per ogni feature e considerando 
tutte le istanze. 
La funzione 
 zip(*...)
  separa le colonne del dataset e restituisce una tupla per ogni 
colonna contenente i relativi valori delle features. 
 def summarize_dataset
 (
dataset
)
:
summaries
 =
[(
mean
(
column
),
stdev
(
column
),
len
(
column
)) 
for 
column 
in 
zip
(
*
dataset
)]
del
(
summaries
 [
-
1
])
return 
summaries
Ad esempio: 
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summary
 = 
summarize_dataset
 (
dataset
)
print
(
summary
)
> [(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]
12"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#12,12,"Naive Bayes classiﬁer: step 3
Vogliamo ricavare le statistiche per ogni classe (o label). Sfruttiamo la funzione 
separate_by_class()
  deﬁnita in precedenza:  
def summarize_by_class
 (
dataset
)
:
separated
  = 
separate_by_class
 (
dataset
)
summaries
  = 
dict
()
for 
class_value
 , 
rows 
in 
separated
 .
items
()
:
summaries
 [
class_value
 ]
 = 
summarize_dataset
 (
rows
)
return 
summaries
Ad esempio:  
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
13
>>>
0
(2.7420144012, 0.9265683289298018, 5)
(3.0054686692, 1.1073295894898725, 5)
1
(7.6146523718, 1.2344321550313704, 5)
(2.9914679790000003, 1.4541931384601618, 5)"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#13,13,"Naive Bayes classiﬁer: step 4
Assumiamo che la probabilità che un certo valore 
 x
 osservato sia funzione 
da una distribuzione gaussiana, descritta interamente dai due valori: media 
e deviazione standard.  
La funzione di densità di probabilità sarà così ricavata (vedi lezione; la y 
corrisponde alla media): 
f(x) = (1 / sqrt(2 * PI) * Σ) * exp(-((x-
 μ
)^2 / (2 * Σ^2)))
Dove 
 Σ
 è la matrice di covarianza (con d =1 coincide con la varianza). 
Esercizio
 : deﬁnire la funzione 
 calculate_probability(x, mean, stdev) 
 per il 
calcolo della densità di probabilità.
14
"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#14,14,"Naive Bayes classiﬁer: step 4
Esercizio
 : deﬁnire la funzione calculate_probability(x, mean, stdev) per il 
calcolo della densità di probabilità. 
from math import sqrt
from math import pi
from math import 
 exp
def calculate_probability
 (
x
, 
mean
, 
stdev
)
:
exponent
  = 
exp
(
-
((
x
-
mean
)
**
2
 / 
(
2
 * 
stdev*
*
2 
)))
return 
(
1
 / 
(
sqrt
(
2
 * 
pi
)
 * 
stdev
))
 * 
exponent
print
(
calculate_probability
 (
1.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
2.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
0.0
, 
1.0
, 
1.0
))
> 
0.3989422804014327
> 
0.24197072451914337
> 
0.24197072451914337
Notare come per x=1, e media e varianza pari a 1, l'apice della campana 
assume valore 0.39. Per x=2 e x=0, e medesime statistiche, il valore è 0.24.
15"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#15,15,"Naive Bayes classiﬁer: step 5
Ora impieghiamo le statistiche ricavate dal training data per nuovi dati. La 
stima delle probabilità viene stimata per ogni classe. 
P(class|data) = P(X|class) * P(class) 
Attenzione: Avendo eliminato la frazione, il risultato non è strettamente 
una probabilità.  
Vogliamo massimizzare tale valore, ovvero prendere la classe con valore di 
probabilità massimo. 
L'approccio naive implica l'indipendenza, es: 
P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)
16"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#16,16,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Esempio: 
# Test calculating class probabilities
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summaries
  = 
summarize_by_class
 (
dataset
)
probabilities
  = 
calculate_class_probabilities
 (
summaries
 , 
dataset
[
0
])
print
(
probabilities
 )
> {0: 0.05032427673372075, 1: 0.00011557718379945765}
17"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#17,17,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Calcola il numero totale di istanze a partire dalle statistiche passate 
come parametro. 
Valuta il valore P(class) come frazione tra il numero di istanze per una 
classe e il numero di istanze nel dataset 
Stima la probabilità per ogni valore in input impiegando la funzione 
densità di probabilità, e le statistiche per ogni colonna associata ad una 
certa classe. Le probabilità saranno moltiplicate se associate alla stessa 
classe. 
Il processo sarà ripetuto per ogni classe nel dataset. 
Restituire un dizionario classe->probabilità
18"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#18,18,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
def calculate_class_probabilities
 (
summaries
 , 
row
)
:
 
# numero totale di istanze di training
 
total_rows
  = 
sum
([
summaries
 [
label
][
0
][
2
] 
for 
label 
in 
summaries
 ])
 
# output
probabilities
  = 
dict
()
 
# per ogni chiave (classe) e valore (istanze di quella classe)
for 
class_value
 , 
class_summaries 
 in 
summaries
 .
items
()
:
   
# probabilità calcolata in base alle frequenze
probabilities
 [
class_value
 ]
 = 
summaries
 [
class_value
 ][
0
][
2
]
/
float
(
total_rows
 )
   
# per ogni istanza in summaries associata ad una classe
for 
i 
in 
range
(
len
(
class_summaries
 ))
:
      
# ricava le statistiche di quella classe
mean
, 
stdev
, 
count
 = 
class_summaries
 [
i
]
      
# aggiorna la probabilità per quella classe
probabilities
 [
class_value
 ]
 *= 
calculate_probability
 (
row
[
i
], 
mean
, 
stdev
)
return 
probabilities
19"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#19,19,"Naive Bayes classiﬁer: esercitazione
Considerare il dataset Kaggle Adult income dataset:  
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html   
Contiene 16 colonne: 
Target ﬁled: Income  
-- The income is divide into two classes: <=50K and >50K   
Number of attributes: 14  
-- These are the demographics and other features to describe a person 
Analizza il dataset passo passo seguendo le considerazioni su: 
https://www.kaggle.com/code/prashant111/naive-bayes-classiﬁer-in-python/notebook  
Applica l'algoritmo Naive Bayes classiﬁer per i suddetto dataset.  
Nota
 : alcuni attributi potrebbero dover essere normalizzati oppure convertiti in valori 
numerici.
20"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#2,2,"Scikit-learn: Classiﬁcatori Naive Bayes
Un approccio di classiﬁcazione molto veloce nell'addestramento, che non 
richiede che il training set sia caricato interamente in memoria, anche se a 
volte mostrano performance peggiori rispetto agli approcci lineare (es. 
LogisticRegression e LinearSVC). 
Naive
  perché basato sull'assunzione che le feature siano indipendenti dal 
punto di vista statistico, spesso inesatta. 
Es. un problema cardiovascolare può dipendere dal colesterolo, peso, livelli di 
diabete, etc; se presenti contemporaneamente possono aumentarne il rischio, ma 
l'approccio naive le valuta singolarmente. 
Si ricavano i parametri del modello analizzando le features singolarmente, e 
collezionando statistiche per ogni feature per ogni classe. 
Ricavare la classe più verosimile (con più alta probabilità 
 a posteriori
 ) si 
ottiene mediante il 
 Teorema di Bayes
 . 
L'approccio naive (indipendenza tra features) ci porta a non interpretare la probabilità 
in output poiché risulta essere una approssimazione troppo grossolana rispetto a 
quella reale. 
3"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#20,20,"Naive Bayes classiﬁer: esercitazione
Alcune funzioni di supporto: 
# Load a CSV file
def 
load_csv
 (
filename
 ):
  dataset = 
 list
()
  
with 
open
(filename, 
 'r'
) 
as 
file
:
    csv_reader = reader(
 file
)
    
for
 row 
in
 csv_reader:
      
if 
not
 row:
        
 continue
      dataset.append(row)
  
return
 dataset
# Convert string column to float
def 
str_column_to_float
 (
dataset
, 
column
):
  
for
 row 
in
 dataset:
    row[column] = 
 float
(row[column].strip())
# Convert string column to integer
def 
str_column_to_int
 (
dataset
, 
column
):
  class_values = [row[column] 
 for
 row 
in
 dataset]
  unique = 
 set
(class_values)
  lookup = 
 dict
()
  
for
 i, value 
 in 
enumerate
 (unique):
    lookup[value] = i
  
for
 row 
in
 dataset:
    row[column] = lookup[row[column]]
  
return
 lookup
21"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#21,21,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Tutorial 
 https://machinelearningmastery.com/naive-bayes-classiﬁer-scratch-
python/  
Dataset: 
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html  
Testi di Riferimento
22"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#3,3,"Classiﬁcatori Naive Bayes: pregi e difetti
Semplice implementazione (basata sulle occorrenze) 
Può funzionare anche su dataset piccoli 
È veloce e richiede poca memoria 
Gestiste il caso di valori mancanti nei dati  
Poco sensibile a dati rumorosi 
L'assunzione dell'indipendenza statistica è raramente soddisfatta; il modello non 
considera le dipendenze tra features 
I dati nel continuo devono essere spesso rielaborati (es. binning) 
Non raggiunge prestazioni ottimali rispetto ad altri approcci 
Non supporta l'
 online learning
 : occorre riaddestrare il modello in presenza di 
nuovi dati. 
Non funziona correttamente se i dati nel test set non sono presenti nel training.
4"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#4,4,"Scikit-learn: Classiﬁcatori Naive Bayes
Ci sono vari classiﬁcatori implementati in Scikit-learn: 
GaussianNB: adatto a dati nel continuo 
CategoricalNB: features discrete distribuite su categorie predeﬁnite 
BernoulliNB: assume dati binari 
MultinomialNB: assume feature che accumulano valori (es. frequenza) 
ComplementNB: variazione del Multinomial per correggere alcune 
assunzioni sui dati. 
BernoulliNB e MultinomialNB sono spesso usati per dati testuali. 
Per dataset di training molto grandi e sparsi si può usare il parametro 
 partial_ﬁt
  che 
riduce la richiesta di memoria. 
È una valida alternativa a 
 logistic regression
  e 
decision trees
 .
5"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#5,5,"Scikit-learn: BernoulliNB
Conteggia quante volte una feature non è pari 0 per ogni classe. 
Ad esempi, 4 istanze con 4 feature binarie ciascuna. La 1a e 3a istanza 
hanno classe '0', mentre la 2a e 4a hanno classe '1'. 
X 
= 
np
.
array
([[
0
, 
1
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
1
],
[
0
, 
0
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
0
]])
y 
= 
np
.
array
([
0
, 
1
, 
0
, 
1
])
Effettuando il conteggio per entrambe le classi si ha: 
counts 
= 
{}
for 
label 
in 
np
.
unique
(
y
):
# iterate over each class
# count (sum) entries of 1 per feature
counts
[
label
] 
= 
X
[
y 
== 
label
]
.
sum
(
axis
=
0
)
print
(
""Feature counts:\n{}""
 .
format
(
counts
))
Feature counts:
{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}
6"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#6,6,"Scikit-learn: MultinomialNB e GaussianNB
 ,
MultinomialNB
  tiene conto del valor medio per ogni feature per ogni 
classe. 
 GaussianNB
  ricava valor medio e varianza. 
La predizione su una istanza è ricavata valutando tutte le classi e 
scegliendo quella ottimale. 
MultinomialNB e BernoulliNB hanno un singolo parametro 
 alpha
 , che 
determina la complessità del modello. Ai dati sono aggiunti 
 alpha
  istanze 
virtuali che hanno valori positivi per tutte le features. Questo genera uno 
""smoothing"" sulle statistiche calcolate.  
Valori elevati di 
 alpha
  creano smoothing elevati e modelli meno 
complessi.  
GaussianNB
  è più adatto a dataset con molte features. 
 MultinomialNB
  è 
migliore rispetto a 
 BernoulliNB
  con dataset con un numero elevato di 
features diverse da 0 (es. grandi documenti testuali).
7"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#7,7,"Naive Bayes classiﬁer da zero
Proviamo a fare l'implementazione del classiﬁcatore 
Step 1: Separate By Class.  
Step 2: Summarize Dataset.  
Step 3: Summarize Data By Class.  
Step 4: Gaussian Probability Density Function.  
Step 5: Class Probabilities 
Immaginiamo di impiegare il dataset 
 Iris
: 
lunghezza e larghezza sepalo (reali) 
lunghezza e larghezza petalo (reali) 
classe di appartenenza = {Iris-setosa, Iris-versicolor, Iris-virginica}
8"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#8,8,"Naive Bayes classiﬁer: step 1
Calcoliamo la probabilità di appartenenza di una istanza ad una certa 
classe. 
Separiamo i dati in ingresso in base alla classe di appartenenza.  
# Split the dataset by class values
# Restituisce un dizionario classe -> lista di istanze
# Funziona per ogni dataset il cui ultimo valore è la classe di appartenenza
def separate_by_class
 (
dataset
)
:
separated
  = 
dict
()
for 
i 
in 
range
(
len
(
dataset
))
:
vector
 = 
dataset
[
i
]
class_value
  = 
vector
[
-
1
]   # ultimo valore
if 
(
class_value 
 not 
in 
separated
 )
:
separated
 [
class_value
 ]
 = 
list
()
separated
 [
class_value
 ].
append
(
vector
) 
return 
separated
9"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#9,9,"Naive Bayes classiﬁer: step 1
# Iris dataset
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
0
[3.393533211, 2.331273381, 0]
[3.110073483, 1.781539638, 0]
[1.343808831, 3.368360954, 0]
[3.582294042, 4.67917911, 0]
[2.280362439, 2.866990263, 0]
1
[7.423436942, 4.696522875, 1]
[5.745051997, 3.533989803, 1]
[9.172168622, 2.511101045, 1]
[7.792783481, 3.424088941, 1]
[7.939820817, 0.791637231, 1]
10"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Support Vector Machine (SVM)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#1,1,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#10,10,"SVM50 CHAPTER 5. LINEAR DISCRIMINANT FUNCTIONS
transformation ϕ() that well separates the data — so the expected number of support
vectors is small — then Eq. 107 shows that the expected error rate will be lower.
y1y2
R1
R2
optimal hyperplanemaximummargin b
maximummargin b
Figure 5.19: Training a Support Vector Machine consists of ﬁnding the optimal hy-
perplane, i.e., the one with the maximum distance from the nearest training patterns.
The support vectors are those (nearest) patterns, a distance bfrom the hyperplane.
The three support vectors are shown in solid dots.
5.11.1 SVM training
We now turn to the problem of training an SVM. The ﬁrst step is, of course, to choose
the nonlinear ϕ-functions that map the input to a higher dimensional space. Often
this choice will be informed by the designer’s knowledge of the problem domain. In
the absense of such information, one might choose to use polynomials, Gaussians or
yet other basis functions. The dimensionality of the mapped space can be arbitrarily
high (though in practice it may be limited by computational resources).
We begin by recasting the problem of minimizing the magnitude of the weight
vector constrained by the separation into an unconstrained problem by the method
of Lagrange undetermined multipliers. Thus from Eq. 106 and our goal of minimizing
||a||, we construct the functional
L(a,α)=1
2||a||2−n/summationdisplay
k=1αk[zkatyk−1]. (108)
and seek to minimize L() with respect to the weight vector a, and maximize it with
respect to the undetermined multipliers αk≥0. The last term in Eq. 108 expresses
the goal of classifying the points correctly. It can be shown using the so-called Kuhn-
Tucker construction (Problem 30) (also associated with Karush whose 1939 thesis
addressed the same problem) that this optimization can be reformulated as maximiz-
ing
L(α)=n/summationdisplay
k=1αi−1
2n/summationdisplay
k,jαkαjzkzjyt
jyk, (109)
subject to the constraintsVedi Duda et al., Pattern Classification , 2000, pg. 262"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#11,11,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#12,12,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  ℜd: spazio vettoriale di d
dimensioni ( d=3 in figura)
xi: vettore di d componenti 
relativo al pattern i-esimo 
del TS
yi: etichetta relativa al 
pattern i-esimo del TS
w: vettore che indica la 
direzione ortogonale a tutti 
i vettori dell’iperpiano H
b : coefficiente del termine 
noto che compare nell’eq. 
del iperpiano H"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#13,13,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Iperpiano : sottospazio inferiore di una dimensione allo spazio in cui è 
definito (e.g., nello spazio 3D gli iperpiani sono i piani)
!Equazione cartesiana di un piano:
Il luogo delle soluzioni (x,y,z) che verificano l’equazione è il luogo dei 
punti P = (x,y,z) che appartengono al piano
!L’equazione del piano specifica due elementi
!la terna (w1,w2,w3) dei coefficienti detti parametri direttori del piano
che individua la direzione ortogonale a tutti i vettori del piano
!il coefficiente del termine noto b
!In sintesi, per individuare univocamente un piano nello spazio è 
sufficiente disporre della direzione ortogonale al piano we del 
coefficiente bw1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#14,14,"Qualche Richiamo
!Sia      uno spazio vettoriale di dimensione n sul campo    . 
Il prodotto scalare fra due vettori di      è un’operazione che 
generalmente si indica con il simbolo “ •” ed è definita come segue:
ovvero associa ad una coppia di vettori x=(x 1,x2,...,x n)e y=(y 1,y2,...,y n) 
un numero reale così definito 
x∙y = <x,y> = x1y1+x 2y2,..., +x nyn
!Alle volte il prodotto scalare è definito anche come
x∙y = = < x,y> = xty
dove xtyè il prodotto riga per colonna tra il vettore trasposto xte il 
vettore y
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
ℜn
ℜn
•: ℜn×ℜn→ℜℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#15,15,"Qualche Richiamo
!La norma di un vettore                                    è un’applicazione che 
ad un vettore associa un numero reale
Essa è pari alla radice quadrata della somma del quadrato delle 
componenti del vettore o, equivalentemente, alla radice quadrata del 
prodotto scalare del vettore con se stesso
!Fra le proprietà di cui gode la norma vi è quella di omogeneità : x=x1,x2,...,xn ( )∈ ℜn
•: ℜn→ℜ
x=x12+x22+...+xn2=x•x
per ogni x∈ ℜn e per ogni λ∈ ℜ si ha
λx=λx
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#16,16,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Dato un piano P di equazione
la sua distanza dall’origine degli assi è pari a
!
""!""+""""""+""#""=!
%
!Si può dimostrare che la distanza !di un punto ""da un piano P è pari a
&=%'(+!
""!""+""""""+""#""=%'(+!
%=)(+)
%
mentre se il punto ""appartiene al piano, cioè se ""∈P, allora la 
distanza !é per definizione zero w1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#17,17,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
In altri termini, D(x) è la funzione distanza dall’iperpiano, cioè indica 
quanto il pattern xè distante dalla superficie decisionale "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#18,18,"SVM Lineari: Pattern Separabili
182 4. LINEAR MODELS FOR CLASSIFICATION
Figure 4.1 Illustration of the geometry of a
linear discriminant function in two dimensions.
The decision surface, shown in red, is perpen-
dicular to w, and its displacement from the
origin is controlled by the bias parameter w0.
Also, the signed orthogonal distance of a gen-
eral point xfrom the decision surface is given
byy(x)/∥w∥.x2
x1wx
y(x)
∥w∥
x⊥
−w0
∥w∥y=0
y<0y>0
R2R1
an arbitrary point xand let x⊥be its orthogonal projection onto the decision surface,
so that
x=x⊥+rw
∥w∥. (4.6)
Multiplying both sides of this result by wTand adding w0, and making use of y(x)=
wTx+w0andy(x⊥)=wTx⊥+w0=0, we have
r=y(x)
∥w∥. (4.7)
This result is illustrated in Figure 4.1.
As with the linear regression models in Chapter 3, it is sometimes convenient
to use a more compact notation in which we introduce an additional dummy ‘input’
value x0=1and then deﬁne /tildewidew=(w0,w)and/tildewidex=(x0,x)so that
y(x)=/tildewidewT/tildewidex. (4.8)
In this case, the decision surfaces are D-dimensional hyperplanes passing through
the origin of the D+1-dimensional expanded input space.
4.1.2 Multiple classes
Now consider the extension of linear discriminants to K> 2classes. We might
be tempted be to build a K-class discriminant by combining a number of two-class
discriminant functions. However, this leads to some serious difﬁculties (Duda and
Hart, 1973) as we now show.
Consider the use of K−1classiﬁers each of which solves a two-class problem of
separating points in a particular class Ckfrom points not in that class. This is known
as a one-versus-the-rest classiﬁer. The left-hand example in Figure 4.2 shows an4.1. Discriminant Functions 181
(McCullagh and Nelder, 1989). Note, however, that in contrast to the models used
for regression, they are no longer linear in the parameters due to the presence of the
nonlinear function f(·). This will lead to more complex analytical and computa-
tional properties than for linear regression models. Nevertheless, these models are
still relatively simple compared to the more general nonlinear models that will be
studied in subsequent chapters.
The algorithms discussed in this chapter will be equally applicable if we ﬁrst
make a ﬁxed nonlinear transformation of the input variables using a vector of basis
functions φ(x)as we did for regression models in Chapter 3. We begin by consider-
ing classiﬁcation directly in the original input space x, while in Section 4.3 we shall
ﬁnd it convenient to switch to a notation involving basis functions for consistency
with later chapters.
4.1. Discriminant Functions
A discriminant is a function that takes an input vector xand assigns it to one of K
classes, denoted Ck. In this chapter, we shall restrict attention to linear discriminants ,
namely those for which the decision surfaces are hyperplanes. To simplify the dis-
cussion, we consider ﬁrst the case of two classes and then investigate the extension
toK>2classes.
4.1.1 Two classes
The simplest representation of a linear discriminant function is obtained by tak-
ing a linear function of the input vector so that
y(x)=wTx+w0 (4.4)
where wis called a weight vector , andw0is abias (not to be confused with bias in
the statistical sense). The negative of the bias is sometimes called a threshold .A n
input vector xis assigned to class C1ify(x)/greaterorequalslant0and to class C2otherwise. The cor-
responding decision boundary is therefore deﬁned by the relation y(x)=0 , which
corresponds to a (D−1)-dimensional hyperplane within the D-dimensional input
space. Consider two points xAandxBboth of which lie on the decision surface.
Because y(xA)=y(xB)=0 ,w eh a v e wT(xA−xB)=0 and hence the vector wis
orthogonal to every vector lying within the decision surface, and so wdetermines the
orientation of the decision surface. Similarly, if xis a point on the decision surface,
theny(x)=0 , and so the normal distance from the origin to the decision surface is
given by
wTx
∥w∥=−w0
∥w∥. (4.5)
We therefore see that the bias parameter w0determines the location of the decision
surface. These properties are illustrated for the case of D=2in Figure 4.1.
Furthermore, we note that the value of y(x)gives a signed measure of the per-
pendicular distance rof the point xfrom the decision surface. To see this, consider
Vedi Bishop, Pattern Recognition and Machine Learning , 2006, pg. 182In questo caso la notazione è 
y(x) = wTx + w0  = D(x) = w · x + b
cioè
wTx =w · x = <w,x>
w0 = b"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#19,19,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Vincoli da soddisfare"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#2,2,"Dilemma
Reti Neurali a un solo strato :
Pro: algoritmo di apprendimento semplice ed efficiente
Cons : potere espressivo limitato (i.e., possono apprendere solo 
“confini” decisionali lineari nello spazio di input)
Reti Neurali multistrato :
Pro: potere espressivo elevato (i.e., possono rappresentare funzioni        
generiche non lineari)
Cons : algoritmo di apprendimento complicato (a causa della 
abbondanza di minimi locali e dell’alto numero di dimensioni  
dello spazio dei pesi)
?:
Pro: potere espressivo elevato
Pro: algoritmo di apprendimento efficiente"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#20,20,"SVM Lineari: Pattern Separabili
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM lineari: Pattern Separabili (2)
Laminima distanza tral’iperpiano diseparazione eunpattern del
training setèdetta margine (W).
Ladistanza dei punti che giacciono sull’iperpiano 𝐷𝐱=+1
dall’iperpiano diseparazione (𝐷𝐱=0)è1/𝐰;lostesso vale peri
puntisull’iperpiano 𝐷𝐱=−1.
Pertanto ilmargine èW=2/𝐰.
L’iperpiano ottimo secondo SVM èquello soddisfa ivincoli di
separazione dei pattern emassimizza ilmargine W(o
alternativamente minimizza ilsuoinverso) :
Minimizza :𝐰2/2
Vincoli :𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0𝑝𝑒𝑟𝑖=1…𝑛
Ipattern deltraining setchegiacciono sulmargine (cerchi pieni in
figura) sono detti support vector .Talipattern, checostituiscono icasi
più complessi, definiscono completamente lasoluzione del
problema, che può essere espressa come funzione disolo tali
pattern ,indipendentemente dalla dimensionalità dello spazio𝑑edal
numero𝑛dielementi inTS.𝐷𝐱=+11/𝐰
𝐷𝐱=0
𝐷𝐱=−1𝐷𝐱>+1
𝐷𝐱<−11/𝐰Laminima distanza trapattern del training set didue classi
differenti piùvicini all’iperpiano diseparazione èdetta margine (-)."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#21,21,"SVM Lineari: Pattern Separabili
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 
"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#22,22,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Funzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#23,23,"6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 SVM Lineari: Pattern Separabili
VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#24,24,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
prodotto scalare fra 
coppie di vettori del TS 
VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#25,25,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#26,26,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#27,27,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#28,28,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#29,29,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
Vi saranno quindi tante
variabili di slack (scarto)
quanti sono ipattern del
Traning Set(TS) .
Tali variabili saranno, però,
diverse dazero (>0)solo per
ipattern non separabili, cioè
classificati erroneamente"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#3,3,"Support Vector Machine (SVM)
LeMacchine aVettori diSupporto oMacchine Kernel (Support Vector Machine,
SVM) costituiscono uninsieme dimetodi diapprendimento supervisionato .
Possono essere utilizzate siaperfare Classificazione ,siaperfare Regressione .
Inunbreve lasso temporale dalla loro prima implementazione hanno trovato
applicazione inunnutrito numero dibranche scientifiche come Fisica, Biologia,
Chimica :
!Preparazione difarmaci
!Ricerca direlazioni quantitative sulle proprietà distrutture
!Chemiometria
!Sensoristica
!Ingegneria chimica
!Computer vision (e.g.,face detection erecognition inimmagini evideo)
!..."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#30,30,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#31,31,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  -Se C ---> ∞  : non ammettiamo violazioni del margine (hard -margin SVM)
-Se C è finito : ammettiamo violazioni del margine e pattern misclassificati 
(soft-margin SVM)VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#32,32,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  
All’aumentare del valore di C
!diminuisce il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#4,4,"SVM
!In1936 ,R.A.Fisher suggested the first algorithm forPattern Recognition
(Fisher 1936 ).
!Aronszajn (1950 )introduced the“Theory ofReproducing Kernels” .
!In1957 Frank Rosenblatt invented alinear classifier called the perceptron (the
simplest kind offeedforward neural network) .
!Vapnik and Lerner (1963 )introduced the Generalized Portrait algorithm (the
algorithm implemented by support vector machines isanonlinear
generalization oftheGeneralized Portrait algorithm) .
!Aizerman, Braverman and Rozonoer (1964 )introduced the geometrical
interpretation ofthekernels asinner products inafeature space .
!Vapnik and Chervonenkis (1964 )further developed the Generalized
Portrait algorithm .
!...
!SVMs close totheir current form were first introduced with apaper attheCOLT
1992 conference (Boser, Guyon and Vapnik 1992 ).
!In1995 thesoft margin classifier was introduced byCortes and Vapnik (1995 );
inthe same year the algorithm was extended tothe case ofregression by
Vapnik (1995 )inThe Nature ofStatistical Learning Theory .
fonte: https://www.svms.org/history.html"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#5,5,"SVM! SVMs (Vapnik, 1990’s) choose the linear separator with the 
largest margin  
• Good according to intuition, theory, practice  
• SVM became famous when, using images as input, it gave 
accuracy comparable to neural-network with hand-designed 
features in a handwriting recognition task Support Vector Machine (SVM) 
V. Vapnik Robust to 
outliers! 
A. Chervonenkis    XXV «                         »   * 1 
1964 
    5 1 9 . 9 5 
                             
 .  .       ,  .  .             
(      ) 
                                  ,                          -
                    .                -                              
                          .                                         -
                                                                
                           . 
1.          
  1 9 5 7  .                                                     -
                                   ,                            -
      . 
                                              ,                
                                                                     
               ,        ,   -       ,                                -
  ,     -       ,                                                    -
     . 
  
      
   . 1 
  1 9 5 7  .                                                  .   -
                                  ,                                  
                   .     -                                    . 1. 
                        ,                                        , 
                                  -        . 
   ,                                                ,        -
        ,                                                        . 
               ,                                      ,             -
    ,          % ,...,  ,                             ,              , 
                   .                                                
        .                                                        
[1].          [ 1]                                           ,           
                                                     .               , 
                                                                     
                                 ,                                  
         .              ,                    U                      
                   
£*= ejx     §2   . . .   cnfn, 
112 
                        
1.              .  . ,              .  .                                     -
             .                          ,  . X X I V ,   6, 1 9 6 3 . 
2. X        .  ,              .  ,              .  .                - 1 ,     
                            .                        ,   4.    -          . 
     . , 1 9 6 2 . 
3.            .  .                                                      . 
 .         ,        .            .    . ,  . 2,   2, 1 9 6 2 . 
4.                .    .                                                    -
            .                        ,   4.    -          .      . , 1 9 6 2 . 
5.            .                                               .          -
              ,   4.    -          .      . , 1 9 6 2 . 
ON A P E R C E P T R O N C L A S S 
V. N . V A P N I K , A . Y A . C H E R V O N E N K I S 
A c l a s s of p e r c e p t r o n s d i f f e r i n g f r o m p e r c e p t r o n s in e x i s t e n c e w i t h t h e l e a r n i n g m e t -
hod is c o n s i d e r e d . S u c h a p e r c e p t r o n is d e s c r i b e d , i t s b l o c k - s c h e m e a n d t h e l e a r n i n g m e t -
hod s a r e p r o p o s e d . T h e a l g o r i t h m s f o r v a r i o u s c l a s s e s of p e r c e p t r o n s a r e c o m p a r e d w i t h 
the t h e o r y of p a t t e r n r e c o g n i t i o n w i t h t h e h e l p of a g e n e r a l i z e d p o r t r a i t . Journal of Machine Learning Research 16 (2015) 2067-2080 Published 9/15
Alexey Chervonenkis’s Bibliography
Alex Gammerman alex@cs.rhul.ac.uk
Vladimir Vovk v.vovk@rhul.ac.uk
Computer Learning Research Centre, Department of Computer Science
Royal Holloway, University of London
This bibliography does not contain Alexey’s patents (he has at least two), technical reports,
unpublished manuscripts, and collections edited by him. ""NA"" indicates that a journal paper
was not assigned to a volume; e.g., it is common for Russian journals (such as Проблемы
управления and, in some years, Автоматика и телемеханика ) not to have volumes, and
also to have pages numbered separately inside each issue. All papers published by Alexey
before 2001 (and afterwards in the case of papers whose original language was Russian) have
author lists ordered according to the Cyrillic alphabetic order; for other papers the order
may reﬂect the authors’ contributions (people who contributed most tend to be listed ﬁrst)
and administrative positions (bosses tend to be listed last).
The bibliography is given by the year of the original publication (which may be di ﬀerent
from the year of the English translation, always given ﬁrst when available).
1964
[1] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of perceptrons. Au-
tomation and Remote Control ,2 5 ( 1 ) : 1 0 3 – 1 0 9 ,1 9 6 4 . R u s s i a no r i g i n a l : В.Н.Вапник ,
А.Я.Червоненкис .Об одном классе персептронов .Автоматика и телемеханика ,
25(1):112–120, 1964; with English summary entitled “On a perceptron class”. The orig-
inal article submitted on 21 February 1963.
[2] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of pattern-recognition
learning algorithms. Automation and Remote Control ,2 5 ( 6 ) : 8 3 8 – 8 4 5 ,1 9 6 4 . R u s s i a n
original: В.Н.Вапник ,А.Я.Червоненкис .Об одном классе алгоритмов обучения
распознаванию образов .Автоматика и телемеханика , 25(6):937–945, 1964; with
English summary entitled “A class of algorithms for pattern recognition learning”. The
submission date is not given.
[3] Vladimir N. Vapnik, Lyudmila M. Dronfort, and Alexey Ya. Chervonenkis. Some ques-
tions of the self-organization of recognizing systems (in Russian). In Theory and Appli-
cation of Automatic Systems (Russian), pages 172–177. Nauka, Moscow, 1964. In the
original language: В.Н.Вапник ,Л.М.(Людмила Михайловна )Дронфорт ,А.Я.
Червоненкис .Некоторые вопросы самоорганизации распознающих устройств .
Теория и применение автоматических систем ,сс.1 7 2 – 1 7 7 . Наука ,Москва ,1 9 6 4 .
c 2015 Alex Gammerman and Vladimir Vovk."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#6,6,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#7,7,"SVM
Le SVM si fondano su tre idee chiave
!L’adozione di tecniche di ottimizzazione matematica per 
individuare soluzioni (i.e., iperpiani) con un basso tasso di errori
!La ricerca di un separatore con margine largo per migliorare la 
generalizzazione 
!L’impiego dello stratagemma del kernel (kernel trick) per rendere 
computazionalemente efficienti ampi spazi di feature1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#8,8,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 Iperpiano: sottospazio di dimensione inferiore di uno (n-1) rispetto allo spazio in 
cui è contenuto (n) (e.g., se lo spazio ha dimensione 3, i suoi iperpiani sono i piani)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#9,9,"3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
SVM"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#0,0,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#1,1,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#10,10,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Si può vedere che il kernel RBF (o gaussiano) equivale a eseguire 
il prodotto interno dei dati di input mappati in un feature space a 
dimensione infinita "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#11,11,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Il kernel 2-layer Neural Network è anche detto kernel Sigmoid"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#12,12,"SVM Non Lineari: Kernel Function
!Inoltre spesso viene chiamato kernel lineare il kernel
che equivale a utilizzare una funzione di mapping φtale 
che φ(x)=x, cioè a nonutilizzare un kernelK(x,x')=(x⋅x')"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#13,13,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  All’aumentare del valore dell’iperparametro q (grado del polinomio)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#14,14,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  
Al diminuire del valore dell’iperparametro !(deviazione standard)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#15,15,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#16,16,"SVM: Multiclasse
14 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: estensione multiclasse  
SVM  è in grado  di determinare  la superficie  di separazione  tra 2 
classi  di pattern ; come  gestire  allora  i problemi  con più di 2 classi  ? 
Si tratta  di un problema  ancora  aperto  anche  se esistono  diverse  
soluzioni ; le più utilizzate  sono : 
 
One-Against -One: che studieremo  in seguito  nell’ambito  dei multi -
classificatori . 
 
One-Against -All: 
Date  𝑠 classi , 𝑤1,𝑤2…𝑤𝑠 
Per ogni classe  𝑤𝑘, si determina  con SVM  la superficie  di 
separazione  tra i pattern  di 𝑤𝑘 (etichettati  +1) da una parte,  e i 
pattern  di tutte le rimanenti  classi  𝑤ℎ,ℎ≠𝑘 (etichettati  -1) 
dall’altra,  ottenendo  la funzione  𝐷𝑘𝐱 che indica  quanto  𝐱 è 
distante  dalla  superficie  decisionale  in direzione  di 𝑤𝑘. 
Maggiore  è 𝐷𝑘𝐱 più confidenti  siamo  dell’appartenenza  di 𝐱 a 
𝑤𝑘.  
Al termine  del training,  si assegna  il pattern  𝐱 alla classe  𝑘∗ per 
cui è massima  la distanza  dalla  superficie  decisionale :  
𝑘∗=𝑎𝑟𝑔 𝑚𝑎𝑥
𝑘𝐷𝑘𝐱 
Nota : È necessario  eseguire  𝑠 training  SVM   
 
 
 !One-Against -One
!One-Against -All"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#17,17,"One-Against -One
E’ingenere piùaccurato diOne-Against -All(vedi dopo), anche se
meno efficiente inquanto richiede l’addestramento diunnumero
maggiore diclassificatori
24 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  One-Against -One 
L’approccio  One-Against -One, consente  di risolvere  un problema  di 
classificazione  multi -classe , attraverso  classificatori  binari . 
È l’approccio  adottato  dalla  libreria  LIBSVM  (usata  in BioLab ). 
Se 𝑠 sono  le classi  del problema,  si addestrano  
𝑠×𝑠−1/2 classificatori  binari : tutte le possibili  coppie , 
indipendentemente  dall’ordine . 
Durante  la classificazione,  il pattern  𝐱 viene  classificato  da ogni 
classificatore  binario,  che assegna  un voto alla classe  (tra le due) 
più probabile .  
Al termine  il pattern  𝐱 è assegnato  alla classe  che ha ricevuto  più 
voti (majority  vote rule).  
 
È in genere  più accurato  di One-Against -All (discusso  in precedenza  
per SVM),  anche  se meno  efficiente  in quanto  richiede  
l’addestramento  di un numero  maggiore  di classificatori . 
 
 (Numero di combinazioni di classe k=2)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#18,18,"14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
 ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVMSVM: Multiclasse
(con x pattern da classificare 
e k=1, 2 ... s)  
14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVM"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#19,19,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#2,2,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili nello spazio di
partenza hanno piùprobabilità diesserlo inuno spazio apiùdimensioni,
essendo ilnumero digradi dilibertà piùelevato ."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#20,20,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
 15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM   
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#21,21,"SVM: Implementazione
27LIBSVM :AL i b r a r yf o rS u p p o r tV e c t o rM a c h i n e s
CHIH-CHUNG CHANG and CHIH-JEN LIN ,N a t i o n a lT a i w a nU n i v e r s i t y
LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package
since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained
wide popularity in machine learning and many other areas. In this article, we present all implementation
details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass
classiﬁcation probability estimates and parameter selection are discussed in detail.
Categories and Subject Descriptors: I.5.2 [ Pattern Recognition ]: Design Methodology— Classiﬁer design
and evaluation ;G . 1 . 6[ Numerical Analysis ]: Optimization— Quadratic programming methods
General Terms: Algorithms, Performance, Experimentation
Additional Key Words and Phrases: Classiﬁcation LIBSVM optimization regression support vector machines
SVM
ACM Reference Format:
Chang, C.-C. and Lin, C.-J. 2011. LIBSVM : A library for support vector machines. ACM Trans. Intell. Syst.
Technol. 2, 3, Article 27 (April 2011), 27 pages.
DOI=10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
1. INTRODUCTION
Support Vector Machines (SVMs) are a popular machine learning method for clas-
siﬁcation, regression, and other learning tasks. Since the year 2000, we have been
developing the package LIBSVM as a library for support vector machines.1LIBSVM is
currently one of the most widely used SVM software. In this article,2we present all
implementation details of LIBSVM .H o w e v e r ,t h i sa r t i c l ed o e sn o ti n t e n dt ot e a c ht h e
practical use of LIBSVM . For instructions of using LIBSVM ,s e et h e README ﬁle included
in the package, the LIBSVM FAQ ,3and the practical guide by Hsu et al. [2003].
LIBSVM supports the following learning tasks.
(1) SVC: support vector classiﬁcation (twoclass and multiclass);
(2) SVR: support vector regression.
(3) One-class SVM.
1The Web address of the package is at http://www.csie.ntu.edu.tw/ ∼cjlin/libsvm.
2This LIBSVM implementation document was created in 2001 and has been maintained at
http://www.csie.ntu.edu.tw/ ∼cjlin/papers/libsvm.pdf.
3LIBSVM FAQ :h t t p : / / w w w . c s i e . n t u . e d u . t w / ∼cjlin/libsvm/faq.html.
This work was supported in part by the National Science Council of Taiwan via the grants NSC 89-2213-E-
002-013 and NSC 89-2213-E-002-106.
Authors’ addresses: C.-C. Chang and C.-J. Lin (corresponding author), Department of Computer Science,
National Taiwan University, Taipei 106, Taiwan; email: cjlin@csie.ntu.edu.tw.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that
copies show this notice on the ﬁrst page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior speciﬁc permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1( 2 1 2 )
869-0481, or permissions@acm.org.
c⃝2011 ACM 2157-6904/2011/04-ART27 $10.00
DOI 10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
ACM Transactions on Intelligent Systems and Technology, Vol. 2, No. 3, Article 27, Publication date: April 2011.
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: implementazione
Iltraining diSVM, richiede algoritmi numerici nonbanali ingrado di
risolvere unproblema diprogrammazione quadratica .Alcune
implementazioni sono disponibili on-line:
LIBSVM
 -http://www .csie.ntu.edu.tw/~cjlin/libsvm
Attenzione
 iKernel (RBF, ecc.)sono parametrizzati inmodo
diverso daquello comune (vedi Readme .txtdiLibSvm e[1]).In
particolare sifausodelparametro gamma (𝛾)perregolare la
complessità della superficie decisionale .Aumentando γla
superficie puòassumere forme piùcomplesse .
N.B.Con kernel RBFγopera inmodo inverso rispetto a𝜎.
Inserito
γanche nelkernel polinomiale (oltre algrado polinomio e
Coef 0)
Per
 laclassificazione multiclasse utilizza internamente One-
Against -One [2](accurato mainefficiente permolte classi ).
Wrapped
 daScikit -Learn→sklearn .svm.SVC
[1]C.W.Hsu, C.C.Chang, andC.J.Lin,APractical Guide toSupport Vector
Classification, disponibile sulsitoweb diLIBSVM
[2]C.C.Chang andC.J.Lin.LIBSVM :alibrary forsupport vector machines .
ACM Transactions onIntelligent Systems andTechnology, 2:27:1--27:27,
2011 ,disponibile sulsitoweb diLIBSVM
LIBLINEAR
 -https ://www .csie.ntu.edu.tw/~cjlin/liblinear /
Stessi
 autori diLIBSVM, consigliata nelcaso lineare perelevata
dimensionalità edelevato numero dipattern .
Wrapped
 daScikit -Learn→sklearn .svm.LinearSVC
SVM
 -light -http://svmlight .joachims .org"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#22,22,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaSVM Lineare"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#23,23,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
SVM Non Lineare (Kernel Polinomiale)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#24,24,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#25,25,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#26,26,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Lineare e Non Lineare (Kernel Polinomiale)
Caso Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#27,27,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Non Lineare (Kernel Polinomiale e Kernel RBF)
Caso Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#28,28,"Esempi LIBSVM
Una semplicissima applicazione sviluppata
daicreatori della libreria LIBSVM che ne
illustra ilfunzionamento èdisponibile allink
seguente :
https://www.csie.ntu.edu.tw/~cjlin/libsvm/
Inparticolare, cliccando col mouse si
tracciano dei punti sullo schermo,
premendo suChange sicambia laclasse (il
colore deipunti relativi) ;infine, premendo
suRun, una semplice SVM attribuisce al
piano l’appartenenza alle varie classi
mostrandole colorate inmaniera diversa .
LIBSVM is an integrated software for support vector classification, (C -SVC, nu -SVC), 
regression (epsilon -SVR, nu -SVR) and distribution estimation (one -class SVM). 
It supports multi -class classification. "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#29,29,"Esempi LIBSVM
This isasimple graphical interface which
shows how SVM separate data inaplane .
You canclick inthewindow todraw data
points .Use ""change"" button tochoose
class 1,2or3(i.e.,uptothree classes are
supported), ""load"" button toload data from
afile,""save"" button tosave data toafile,
""run"" button toobtain anSVM model, and
""clear"" button toclear thewindow .Youcan
enter options inthebottom ofthewindow,
thesyntax ofoptions isthesame as`svm -
train' .Note that""load"" and""save"" consider
data inthe classification but not the
regression case .Each data point hasone
label (the color) which must be1,2,or3
and two attributes (x-axis and y-axis
values) in[0,1].Type `make' inrespective
directories tobuild them ..."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#3,3,"!Dato un insieme              , una funzione                           è un kernel se 
risulta che  
dove                     e   è uno spazio di Hilbert
!Lo Spazio di Hilbert è uno spazio vettoriale che generalizza la nozione 
di Spazio Euclideo
!φ è la funzione di mapping dall’Input Space al Feature Space
!Si può dimostrare che una funzione                           è un kernel se, e 
solo se, comunque si scelgano r elementi x1, x 2, ..., x r∈X, la matrice 
K=[k(x i,xj)]i,j=1,...,r è simmetrica e semidefinita positiva
!Ogni matrice simmetrica semidefinita positiva ha tutti gli autovalori non 
negativik(x,y)=φ(x),φ(y)   ∀x,y∈XX⊂ ℜ k:X×X→ℜ
ϕ:X→ΗΗ
k:X×X→ℜKernel"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#30,30,Esempi LIBSVM
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#31,31,"Esempi LIBSVM
Q:What isthedifference between
nu-SVC and C-SVC? Basically they
arethesame thing butwith different
parameters .The range ofCisfrom
zero toinfinity but nu isalways
between [0,1].Anice property ofnuis
thatitisrelated totheratio ofsupport
vectors and theratio ofthetraining
error.
Additionally one-class SVM type is
supported fordistribution estimation .
The one-class SVM type gives the
possibility tolearn from justone class
ofexamples and later ontest ifnew
examples match theknown ones ."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#32,32,"SVM in pratica
19 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM in pratica  
Lineare  o Non-lineare?   
se la dimensionalità  𝑑 dello  spazio  è molto  elevata  (es. 5000  
feature ) si utilizza  generalmente  SVM  lineare . Infatti  in uno 
spazio  così grande  i pattern  sono  tipicamente  molto  sparsi  e 
anche  «semplici»  iperpiani  sono  in grado  di separare  le 
classi  efficacemente . Il solo iperparametro  da tarare  è 𝐶.  
per bassa  dimensionalità  (es. 20 feature ) la scelta  primaria  è 
SVM  non lineare  con kernel  RBF. Gli iperparametri  da tarare  
sono  𝐶 e V (o γ se si utilizza  LIBSVM ). 
Per media  dimensionalità  (es. 200 features ) in genere  si 
provano  entrambe  le tipologie  (i.e., anche  questa  scelta  
diventa  un iperparametro ). 
Come  sempre  gli iperparametri  si tarano  su un validation  set 
separato,  oppure  attraverso  cross -validation  sul training  set. 
 
Come  gestire  il caso  multi -classe?   
Tipicamente  ci si affida  alla soluzione  disponibile  nella  libreria  
utilizzata  (One-Agaist -One per LIBSVM ). 
Se però il numero  di classi  è molto  elevato,  il costo  può 
diventare  inaccettabile  per certe  applicazioni . In questo  caso  
One-Against -All diventa  la scelta  obbligata .  
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#33,33,"SVM in pratica
"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#34,34,"SVM in sintesi
!Vantaggi
!Si basa su una teoria ben fondata
!Presenta eccellenti proprietà di generalizzazione
!La funzione obiettivo non presenta minimi locali
!Può essere impiegata per individuare funzioni discriminanti non lineari
!La complessità del classificatore è caratterizzata dal numero di su pport 
vector piuttosto che dalla dimensionalità dello spazio trasformato
!Svantaggi
!Tende ad essere più lenta rispetto ad altri metodi
!La programmazione quadratica è computazionalmente onerosa "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#35,35,"!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , 
Pearson, 2020.
!C. Burges, A Tutorial on Support Vector Machines for Pattern Recognition , 
1998.
!S. Gunn, Support Vector Machines for Classification and Regression , 1998.
!D. Maltoni, Machine Learning , Università di Bologna, 2017.
!C.W. Hsu, C.C. Chang, and C.J. Lin, A Practical Guide to Support Vector 
Classification , Last updated: May 19, 2016.
!C.C. Chang and C.J. Lin, LIBSVM: A Library for Support Vector Machines , ACM 
Transactions on Intelligent Systems and Technology, 2:27:1 —27:27, 2011.
!G. Raiconi, Support Vector Machines: Concetti ed Esempi , Università di 
Salerno 2016.
!R.O. Duda, P.E. Hart, and D.G. Stork. 2000. Pattern Classification (2nd 
Edition). Wiley -Interscience, New York, NY, USA. 
!C.M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.Riferimenti"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#4,4,"Kernel
!Uno spazio di Hilbert     è uno spazio vettoriale Hreale o 
complesso sul quale è definito un prodotto interno tale che, detta d 
la distanza indotta da       su H, lo spazio metrico ( H, d) sia completo
!Uno spazio metrico è un insieme di elementi, detti punti , nel quale è 
definita una distanza , detta anche metrica (lo spazio metrico più 
comune è lo spazio euclideo di dimensione 1, 2 o 3)
!Uno spazio metrico completo è uno spazio metrico in cui tutte le 
successioni di Cauchy sono convergenti ad un elemento dello spazio
!Una successione di Cauchy è una successione tale che, comunque si 
fissi una distanza arbitrariamente piccola ε> 0, da un certo punto in poi 
tutti gli elementi della successione hanno distanza reciproca inferiore 
ad ε=(H,⋅,⋅) Η
⋅,⋅
⋅,⋅"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#5,5,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#6,6,"SVM Non Lineari
!In altri termini, possiamo calcolare w*, b*e funzione di 
decisione in maniera analoga a quanto visto in precedenza
!Utilizzando il kernel evitiamo l’operazione costosa di 
trasformazione e prodotto interno nello spazio trasformato, 
essendo il kernel una funzione dei pattern originali definiti 
nell’Input Space ℜd
!Possiamo inoltre effettuare trasformazioni in spazi a 
dimensione infinita
!In sintesi, le proprietà del prodotto scalare consentono di 
esprimere il prodotto scalare dei pattern immagine (""(x) ∈ℜm) 
corrispondenti ai pattern in input (x ∈ℜd) semplicemente come 
funzioni kernel dei pattern in input (x ∈ℜd)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#7,7,"Kernel Trick
!Pattern linearmente non separabili possono diventare 
linearmente separabili se trasformati, o mappati, in uno spazio 
dimensionale superiore
!Il calcolo della matematica vettoriale (cioè i prodotti scalari) in 
uno spazio dimensionale assai elevato è costoso dal punto di 
vista computazionale
!Il trucco del kernel consente di calcolare in modo efficiente 
prodotti scalari di dimensioni molto elevate
!Esso consente di mappare in pattern in input in modo implicito 
in uno spazio dimensionale più elevato (possibilmente infinito) 
con un overhead computazionale ridotto
!“In modo implicito”, in quanto i vettori a dimensionalità 
superiore non sono mai effettivamente costruiti"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#8,8,"Kernel Function: Esempio
!Supponiamo di avere i seguenti due vettori bidimensionali 
""=$!,$""e &='!,'""
!La funzione seguente ((*)mappa vettori bidimensionali in vettori 
tridimensionali
!Il modo standard per calcolare
è prima mappare i pattern in input nello spazio delle feature e poi 
eseguire il prodotto scalare nello spazio a dimensione più elevata
!Tuttavia, il prodotto scalare può essere effettuato interamente nello 
spazio originale a due dimensioni(,=-!""
2-!-""
-""""
(""*(&
(""*(&=$!""'!""+2$!$""'!'""+$""""'""""=""*&"""
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#9,9,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#0,0,"MATLAB (MATrix LABoratory)
!Per installare il sofftware, accedere all’Area Sistemi Informativi di Roma Tre 
disponibile al seguente indirizzo: http://asi.uniroma3.it/ ---> cliccare su ‘servizi 
agli studenti’ ---> scorrere fino in fondo e cliccare su ‘MathWorks’
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#1,1,"MATLAB
Manualetto di Matlabr
L. Scuderi
1 Comandi d’avvio
Per avviare Matlab in ambiente Windows ` e su éciente selezionare con il mouse l’icona corrispon-
dente. In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il tasto di invio (o
enter, return, ...). Il simbolo >>che compare, ` e il prompt di Matlab . Per eseguire un comando
digitato occorre premere il tasto di invio. Per terminare la sessione di lavoro occorre digitare il
comando exit oppure quit .
Tabella 1. Alcuni comandi per gestire una sessione di lavoro.
Comando Signiﬁcato
help per visualizzare tutti gli argomenti presenti
help arg per visualizzare informazioni su arg
doc arg per visualizzare dettagliate informazioni su arg
clc per cancellare il contenuto della ﬁnestra di lavoro
; per non visualizzare il risultato di un’istruzione
... per continuare a scrivere un’istruzione nella riga successiva
who per visualizzare le variabili poste in memoria
whos per visualizzare informazioni sulle variabili poste in memoria
clear per cancellare tutte le variabili dalla memoria
clear var1 var2 per cancellare le variabili var1 evar2 dalla memoria
2 Le variabili in Matlab
I nomi delle variabili possono essere lunghi al massimo 32 caratteri. I caratteri utilizzabili sono
le lettere (maiuscole e minuscole), i numeri e il carattere “ _” (underscore). Un nome di variabile
deve cominciare con un carattere alfabetico (a-z, A-Z). Matlab distingue tra lettere maiuscole
e minuscole (ad esempio i nomi a1edA1rappresentano variabili diverse). La variabile si crea
automaticamente nel momento in cui si assegna ad essa un valore o il risultato di un’espressione.
L’assegnazione avviene mediante il simbolo =secondo la seguente sintassi
>> nome_variabile=espressione
Se la variabile che si vuole creare ` e di tipo stringa occorre racchiudere espressione tra una
coppia di apici. Nella tabella 2 abbiamo riportato alcune variabili scalari predeﬁnite.
Matlab lavora con sedici cifre signiﬁcative. Tuttavia, in output una variabile intera viene
visualizzata generalmente in un formato privo di punto decimale, mentre una variabile reale (non
intera) viene visualizzata solo con quattro cifre decimali. Se si vuole modiﬁcare il formato di output
si pu` o utilizzare uno dei comandi della tabella 3. Per visualizzare tutte le sedici cifre impiegate da
Matlab ` e necessario attivare il comando format long e .
Nella tabella 4 abbiamo riportato le principali operazioni eseguibili sulle variabili scalari. Oltre
alle operazioni di base, in Matlab sono presenti anche le funzioni predeﬁnite riportate nella tabella
5.
Gli elementi di un vettore vanno digitati tra parentesi quadre; gli elementi di un vettore riga
vanno separati con uno spazio oppure una virgola, quelli di un vettore colonna con un punto e virgola
1!Per avviare Matlab in ambiente Windows o Mac è sufficiente selezionare con 
il mouse l’icona corrispondente!In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il 
tasto Invio (o Enter, Return, ... )!Il simbolo >> che compare nella Command Window è il prompt di Matlab!Per eseguire un comando digitato occorre premere il tasto Invio!Per terminare la sessione di lavoro occorre digitare il comando exit o quit!Seguono alcuni comandi per gestire una sessione di lavoro"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#10,10,"Esempi in MATLAB
!Overfitting con SVM Non Lineare (Kernel Gaussiano)
σ=1/15, C=106Esempi in MATLAB –(7)
49
•Vediamo invece un esempio di overfitting utilizzando il kernel
gaussiano con 𝜎=1/15e 𝐶=106:
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#11,11,"Esempi in MATLAB
% … caricamento dei dati come nel caso precedente …%
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei petali
y = ~strcmp(species,'virginica'); % label 0 se Iris viginica, 1 se altre specie
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6,'KernelFunction' ,'gaussian' ,'KernelScale' ,
1/15);
% … disegno dello scatter plot come nel caso precedente …%
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2),'ko','MarkerSize',10) % cerchia i vettori di supporto
legend('Iris virginica','Altre specie','Support vectors','Location','southeast')
axis manual
% … disegno dello scatter plot come nel caso precedente …%
d=0.02; % intervallo utilizzato per generare la griglia di punti
[x1Grid,x2Grid]=meshgrid(min(X(:,1)):d:max(X(:,1)),min(X(:,2)):d:max(X(:,2))); % 
generazione della griglia
xGrid=[x1Grid(:),x2Grid(:)];
[~,scores1]=predict(SVMModel,xGrid); % valutiamo l’output del modello nei punti 
della griglia
contour(x1Grid,x2Grid,reshape(scores1(:,2),size(x1Grid)),[0 0],'k'); % plot del 
confine di decisione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#12,12,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#13,13,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#14,14,"Esempi in MATLAB
σ=1/15, C=106Esempi in MATLAB –(8)
50
𝐶=106,𝜎=1/15
!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#15,15,"Esempi in MATLAB
!Esempio di SVM Non Lineare (Kernel Gaussiano)
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#16,16,"Esempi in MATLAB
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Esempio di SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#17,17,"Esempi in MATLAB
σ=5, C=100
Esempi in MATLAB –(8)
51
𝐶=100,𝜎=5!Esempio di SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#18,18,"Classification Learner
The Classification Learner app lets you train models toclassify data using supervised
machine learning .
Using Classification Learner, you can perform common machine learning tasks such
asinteractively exploring your data, selecting features, specifying validation schemes,
training models, and assessing results .Choose from several classification types
including decision trees ,support vector machines (SVM) ,and k-nearest neighbors ,
and select from ensemble methods such asbagging, boosting, and random subspace .
Classification Learner helps you choose thebest model foryour data byletting you
perform model assessment and model comparisons using confusion matrices and
ROC curves .Export classification models tothe MATLAB workspace togenerate
predictions onnew data, orgenerate MATLAB code tointegrate models into
applications such ascomputer vision, signal processing, and data analytics ."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#19,19,"Classification Learner
Matrice diConfusione (oTabella diErrata Classificazione) :rappresentazione
dell'accuratezza diclassificazione statistica .
Ogni colonna della matrice rappresenta ivalori predetti, mentre ogni riga
rappresenta ivalori reali (i.e.,l'elemento sulla riga iesulla colonna jèilnumero di
casi incui ilclassificatore haclassificato laclasse ""vera"" icome classe j).
Attraverso questa matrice èosservabile seviè""confusione"" nella classificazione di
diverse classi .
Curve ROC (Receiver Operating Characteristic) :schemi grafici perunclassificatore
binario .
Lungo idue assi sipossono rappresentare lasensibilità e(1-specificità), come True
Positive Rate (vero positivo) eFalse Positive Rate (falso positivo) .Inaltri termini, si
studiano irapporti fraveri allarmi (hitrate) efalsi allarmi alvariare diuna soglia ."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#2,2,"Esempi in MATLAB
!Dataset multivariato Iris (Fisher's 1936 iris data)
!50 esemplari di Iris Setosa , 50 di Iris Versicolor , 50 di Iris Virginica
!4 feature: lunghezza e larghezza del sepalo, lunghezza e larghezza 
del petalo
!Sepalo: in botanica, ciascuno degli elementi, simili a foglioline verdi, 
che formano il calice del fiore
!Utilizzeremo solo lunghezza e larghezza del sepalo (per poter 
visualizzare i dati)
!Funzione fitcsvm di MATLAB (metodo di ottimizzazione adottato: 
Sequential Minimal Optimization (SMO))
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#20,20,"Classification Learner
-Avviare Matlab
-Scaricare il file ClassificationLearner_Example_Datasets.mat
-Doppio clic sul file ClassificationLearner_Example_Datasets.mat
-Selezionare i dati che si desidera importare 
[e.g., FisherIris (Numero di feature (predittori): 4, Numero di pattern (osservazioni): 150, Numero di 
classi: 3); tabella di 150 righe (osservazioni) e 5 colonne (4 valori delle feature + classe)]
-Digitare Finish per importarli nel Workspace di Matlab
-Avviare l’app Classification Learner (vedi scheda APPS o digitare al prompt il 
comando classificationLearner )"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#21,21,"Classification Learner
-New Session —> From Workspace
-Selezionare le feature e l’eventuale metodo di validazione
-Start Session
-Selezionare uno o più algoritmi di classificazione dalla barra superiore (per 
selezionare i parametri vedi Advanced)
-Train e buon divertimento!
-per ulteriori dettagli: https://it.mathworks.com/help/stats/classificationlearner -app.html"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#22,22,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#23,23,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#24,24,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#25,25,"CL Features
-Linear SVM
-Fine Gaussian SVM (Kernel Scale=0.35)
-Medium Gaussian SVM (Kernel Scale=1.4)
-Coarse Gaussian SVM (Kernel Scale=5.7)
-Quadratic SVM (Kernel Polinomiale con grado=2)
-Cubic SVM (Kernel Polinomiale con grado=3)
-Kernel scale parameter, specified as the comma -separated pair consisting of 'KernelScale' and 'auto' or a positive 
scalar. The software divides all elements of the predictor matrix X by the value of KernelScale. Then, the software 
applies the appropriate kernel norm to compute the Gram matrix.
-per ulteriori dettagli digitare al prompt il comando doc fitcsvm"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#26,26,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#27,27,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#28,28,"Altri Dataset
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#29,29,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#3,3,"Dataset Fisher Iris
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#30,30,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#31,31,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#32,32,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#33,33,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#34,34,"Classification Learner
“Plotting the fisheriris data, you can see that sepal length
and sepal width separate one ofthe classes well
(setosa) .You need toplot other predictors (features) to
see ifyou can separate theother two classes .”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#35,35,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#36,36,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#37,37,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#38,38,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#39,39,"Classification Learner
“Plotting thefisheriris data, you can seethat petal length and petal
width arethefeatures that separate theclasses best.”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#4,4,"Esempi in MATLAB
fitcsvm trains or cross -validates a support vector machine (SVM) model for 
two-class (binary) classification on a low -dimensional or moderate -
dimensional predictor data set. fitcsvm supports mapping the predictor data 
using kernel functions, and supports sequential minimal optimization (SMO), 
iterative single data algorithm (ISDA), or L1 soft -margin minimization via 
quadratic programming for objective -function minimization. Matlab Help
The support vectors are observations that occur on or beyond their estimated 
class boundaries. 
You can adjust the boundaries (and, therefore, the number of support 
vectors) by setting a box constraint during training using the 'BoxConstraint'
name -value ( C) pair argument."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#40,40,"L'errore di classificazione è uguale, ma i classificatori sono molto diversi fra loro!Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Classificatore 1  
(assegn aun 
oggetto sempre 
alla prima classe )
Errore: 3/10 = 0.3 
(30%)Classificatore 2Valutazione Prestazioni
Errore: 3/10 = 0.3
(30%)Il sempice errore di classificazione (i.e., numero di errori / numero totale di classificazioni) 
non sempre ci permette di capire o confrontare completamente due classificatori.
Esempio:"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#41,41,"Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Elementi della classe 1 classificati  
come appartenenti alla classe 1
Elementi della classe 1classificati 
come appartenenti alla classe 2
Elementi della classe 2 classificati  
come appartenenti alla classe 2Matrice di Confusione
Elementi della classe 2classificati  
come appartenenti alla classe 15 2
1 2EsempioMatrice Mche ci dice come un classificatore opera rispetto alle diverse classi 
m(i,j) = numero di elementi della classe iclassificati come elementi della classe j
In altri termini, indice di riga i:valore reale , indice di colonna j:valore predetto"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#42,42,"Matrice di Confusione
L'errore di classificazione può essere calcolato facilmente dalla matrice di 
confusione
La somma di tutti gli elementi non appartenenti alla diagonale principale
O, meglio, può essere calcolato come “1 -Accuracy”
Accuracy: somma elementi diagonale principale / numero elementi totali"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#43,43,"Nel caso di problema a due classi la matrice di 
confusione  assume una forma particolare (2 classi, 
positivi vs negativi)
True  
Positive  
(TP)False  
Negative  
(FN)
False  
Positive  
(FP)True  
Negative  
(TN)ESEMPIO: classificazione tra malati (positivi) e sani(negativi)
CLASSIFICAZIONE CORRETTA:
Veri positivi: pazienti malati classificati come malati
Veri negativi: pazienti sani classificati come sani
CLASSIFICAZIONE ERRATA:
Falsi positivi: pazienti sani classificati come malati
Falsi negativi: pazienti malati classificati come saniMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#44,44,"Dalla matrice di confusione possono essere calcolati diversi indici
Indice Formula Intuizione
Accuracy Percentuale di classificazioni corrette
Precision Percentuale di classificazioni positive che  
sono corrette
Recall (Sensitivity) Percentuale di elementi positivi del tes tset 
che sono stati classificati come positivi
Specificity Percentuale di elementi negativi del test set 
che sono stati classificati come negativi
Precision: se dico “positivo”, è corretto ?
Recall: riesco a trovare tuttii positivi del testing set?Matrice di Confusione
TN
TN+FPTP
TP+FNTP+TN
TP+FP+TN+FN
TP
TP+FP"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#45,45,"Matrice di Confusione
Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegnata
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 7/10 (0.7)
Recall: 7/7 (1)
Specificity: 0/3 (0)TP:7 FN:0
FP:3 TN:0Indice Formula
Accuracy
Precision
Recall (Sensitivity)
Specificity
Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 5/6 (0.83)
Recall: 5/7 (0.71)
Specificity: 2/3 (0.66)TP:5 FN:2
FP:1 TN:2TP+TN
TP+FP+TN+FN
TP
TP+FP
TP
TP+FN
TN
TN+FP"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#46,46,"blu50 10
20 20Supponiamo diaver addestrato unmodello utilizzando 100
esempi ditraining .Diquesti 100,60sono diclasse “rosso” e
40sono diclasse “blu”.
Ilmodello haeffettuato leseguenti classificazioni :
Etichette predette
rosso blu
rosso
Etichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#47,47,"rosso
blu50 10
20 20Etichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#48,48,"rosso
bluTP FN
FP TNEtichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#49,49,"Precision: =50 / (50+20) =0.7142
TP +FPEtichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Precision: ""Quanti dei pattern che ho predetto di tipo rosso sono
davvero pattern di classe rosso ?""
TPMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#5,5,"Esempi in MATLAB
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei sepali
y = ~strcmp(species, 'setosa' ); % label 0 se Iris setosa, 1 se altre specie
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,+Inf); % C=+Inf —> hard-margin linear SVM
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2), 'ko','MarkerSize' ,10) % cerchia i vettori di supporto
legend('Iris setosa' ,'Altre specie' ,'Support vectors' ,'Location' ,'southeast' )
axis manual
x1 = linspace( -5,5);
f=@(x)(-SVMModel.Bias -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % iperpiano di 
separazione
plot(x1,f(x1))
f1=@(x)( -SVMModel.Bias+1 -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
positivo
plot(x1,f1(x1))
f2=@(x)( -SVMModel.Bias -1-SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
negativo
plot(x1,f2(x1))"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#50,50,"Recall 
(Sensi tivity) :
TP
Sensitivity: =50 / (50+10) =0.8333Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
TP + FN
somma dei positivi nel training setMatrice di Confusione
“Dei pattern che dovrei predire come rosso (positivo) 
quanti ne ho predetti di classe rosso (positivo)?”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#51,51,"Specificity: = 20 / (20+20) =0.5Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Specifici ty:Matrice di Confusione
TN“Dei pattern che dovrei predire come blu(negativo) 
quanti ne ho predetti di classe blu(negativo)?”
TN+FP
somma dei negativi nel training set"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#52,52,"Lacurva ROC (Receiver Operating Characteristic) èuna
tecnica statistica attualmente utilizzata inuna grande varietà di
campi scientifici .
Questa tecnica trae origine nell'ambito della teoria della
rilevazione delsegnale .Sitratta diunametodologia cheèstata
adottata per laprima volta daalcuni ingegneri, durante la
seconda guerra mondiale, perl'analisi delle immagini radar elo
studio delrapporto segnale/disturbo .
E'possibile usare lacurva ROC anche pervalutare leprestazioni
diunmodello diclassificazione .Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#53,53,"Sistema molto utilizzato per valutare un classificatore binario
basato susoglia
Legenda: 
Positivo = Disease (Malati) 
Negativo = Normal (Sani)
Classificazione:
Negativo < !
Positivo > !
Variando il valore di soglia 
!(cut-off)si ottengono 
diversi valori di TP, TN, FP,
FN
Esempio: con ilvalore  di !
in figura i Falsi Positivi 
sono azeroCurva ROC
!"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#54,54,"La curva ROC mette in relazione la specificity (recall) 
conla sensitivity al variare della soglia
Fissata una soglia, quanti sono i veri positivi rispetto ai falsipositivi? 
Come si calcola:
Si fa variare la soglia calcolando i  
corrispondenti veri positivi e falsi  
positivi, che rappresentano un  
punto della curva
Il valore minimo/massimo della  
soglia è quello per cui sono tutti  
falsi positivi o tutti veri positiviCurva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#55,55,"Fissatauna sogliat,
peri tutti gliesempi  
quali il
(classificatore)modello
genera
unoscore >tvengono  
predetti positivi.
Questo cipermette di
quantificare, per ogni
scelta del valore di
soglia ,TP,TN, FPe
FN.
TP
FPCurva ROC
TN
FN"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#56,56,"Fissato unvalore dit
possiamo calcolare, ad
esempio :
TP=0.5  
FN=0.5  
FP=0.12  
FN=0.88
Possiamo  
identificare un  
punto sulla curva  
(associato al  
valore di tscelto)Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#57,57,"Possiamo calcolare TP  
e FP per una serie di  
valori  di t (es. 0.1,0.2,
0.3, 0.4, 0.5, 0.6, …,
1.0). In questo modo  
otteniamo diversi punti  
che compongono la  
curva ROC.
Curva ROC
Il valore degli score 
generati dal 
classificatore può 
variare tra 0 e 1."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#58,58,"A seconda di come si vuole operare si sceglie lasoglia
Esempio 1 (curva) : Sensitivity al 95%, si 
ottiene un corrispondente valore di Specificity
(70%)
Esempio 2 (segmento tratteggiato) : 
Sensitivity = 100-Specificity, si chiama 
Equal Error Rate
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#59,59,"Ciò che èimportante
però non èlacurva di
persé,mal’area sotto
la curva . Questa
quantità èindicata con
iltermine Area Under
theROC Curve (AUC )
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#6,6,"Esempi in MATLAB Esempi in MATLAB –(3)
45
𝐶=+∞C=+∞
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#60,60,"AUC = 1:
Il classificatore è  
perfetto
AUC = 0.5 :
Il classificatore è
totalmente casuale
(lancio diunamoneta)
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#61,61,"Rispetto a TP e FP :
TP:0, FP:0
Predice sempre «negativo»
TP:1, FP:1
Predice sempre «positivo»
TP:1, FP:0
Classificatore ideale
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#62,62,"Si possono confrontare curve ROC calcolando l'area
sotto la curva (AUC –Area Under theCurve)
Un AUC più grande 
implica unclassificatore
migliore
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#63,63,A B CA migliore di B migliore di C (C=lancio moneta)Curva ROC
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#64,64,"Join the protest!!!
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#7,7,"Esempi in MATLAB
C=+∞Esempi in MATLAB –(4)
46
𝐶=+∞
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#8,8,"Esempi in MATLAB
C=1Esempi in MATLAB –(5)
47
𝐶=1
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#9,9,"Esempi in MATLAB
C=10−6Esempi in MATLAB –(6)
48
𝐶=10−6
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: SVM (Ex 14)
1"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#1,1,"Sommario
Scikit-learn e SVM 
SVM e Iris dataset 
Use case: Stock forecasting 
Use case: Sentiment Analysis"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#10,10,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
... (completa)
11"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#11,11,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
df[
'Open-Close'
 ] = df.Open - df.Close
df[
'High-Low'
 ] = df.High - df.Low
  
# per ora uso solo 2 valori
X = df[[
 'Open-Close'
 , 
'High-Low'
 ]]
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
>> [1 1 1 ... 1 0 0]
... (segue)
12"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#12,12,"Esercitazione: stock forecasting
split_percentage = 
 0.8
split = 
 int
(split_percentage*
 len
(df))
  
# Train data set
X_train = X[:split]
y_train = y[:split]
  
# Test data set
X_test = X[split:]
y_test = y[split:]
cls = SVC().fit(X_train, y_train)
df[
'Predicted_Signal'
 ] = cls.predict(X)
df[
'Return'
 ] = df.Close.pct_change()
df[
'Strategy_Return'
 ] = df.Return *df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
import
 matplotlib.pyplot 
 as
 plt
%matplotlib 
 inline
  
plt.plot(df[
 'Cum_Ret'
 ],color=
 'red'
)
plt.plot(df[
 'Cum_Strategy'
 ],color=
 'blue'
)
13"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#13,13,"Esercitazione: stock forecasting
14
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#14,14,"Esercitazione: stock forecasting
L'algoritmo genera un ritorno del 18.87% in un 1 anno, rispetto al 5.97% 
del titolo azionario. 
La funzione accuracy_score() restituisce una accuracy del 62.07% sul train 
set e 50.67 sul test set. 
Esercizi: (1) crea il target value a distanza di più giorni dall'istanza 
corrente; (2) usa gli ultimi 15 valori Close come istanza di input per predire 
il successivo; (3) impiega altri kernel (es. rbf).
15
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#15,15,"Esercitazione: Sentiment Analysis
Tecnica molto popolare per classiﬁcare brani di testo, micropost o frasi in 
linguaggio naturale in base al sentimento (es. positivo, negativo, neutro). 
Supponiamo di impiegare le review di ﬁlm, es: 
http://www.cs.cornell.edu/people/pabo/movie-review-data/  
Movie-review data for use in sentiment-analysis experiments. Available are collections of 
movie-review documents labeled with respect to their overall 
 sentiment polarity
  (positive 
or negative) or 
 subjective rating
  (e.g., ""two and a half stars"") and sentences labeled with 
respect to their 
 subjectivity status
  (subjective or objective) or 
 polarity 
import pandas as pd  
trainData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/train.csv
 "") 
testData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/test.csv
 "") 
trainData.sample(frac=1).head(5) # shuffle the df and pick first 5  
      
Content                                             
 Label 
56
    jarvis cocker of pulp once said that he wrote ...   pos  
1467
  david spade has a snide , sarcastic sense of h...   neg  
392
   upon arriving at the theater during the openin...   pos  
104
   every once in a while , a film sneaks up on me...   pos  
1035
  susan granger's review of "" american outlaws ""...   neg
16"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#16,16,"Esercitazione: Sentiment Analysis
Per impiegare il testo come input agli algoritmi di ML spesso si effettua una 
pipeline di processamento per trasformare parole o frasi in vettori numerici. 
Per dettagli: 
 https://medium.com/@vasista/preparing-the-text-data-with-
scikit-learn-b31a3df567e
   e  
https://scikit-learn.org/stable/modules/
generated/sklearn.feature_extraction.text.TﬁdfVectorizer.html   
from sklearn.feature_extraction.text import TfidfVectorizer  
# ignora i termini che compaiono in meno di 5 documenti 
# e i termini che compaiono in > 80% dei documenti; 
# abilita l'inverse document frequency per pesare i termini 
vectorizer = TfidfVectorizer(min_df = 5,  
                             max_df = 0.8,  
                             sublinear_tf = True,  
                             use_idf = True)  
train_vectors = vectorizer.fit_transform(trainData['Content'])  
test_vectors = vectorizer.transform(testData['Content']) 
Esercizio
 : completa il codice impiegando SVM lineare e valutane 
l'accuratezza. Testa la predizione su review di Amazon.
17"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#17,17,"Esercitazione: Sentiment Analysis
from sklearn import svm 
from sklearn.metrics import classification_report 
classifier_linear = svm.SVC(kernel='linear') 
classifier_linear.fit(train_vectors, trainData['Label']) 
prediction_linear = classifier_linear.predict(test_vectors) 
time_linear_train = t1-t0 
time_linear_predict = t2-t1 
report = classification_report(testData['Label'], prediction_linear, 
output_dict=True) 
print('positive: ', report['pos']) 
print('negative: ', report['neg']) 
positive:  {'precision': 0.9191919191919192, 'recall': 0.91, 'f1-score': 
0.9145728643216081, 'support': 100} 
negative:  {'precision': 0.9108910891089109, 'recall': 0.92, 'f1-score': 
0.9154228855721394, 'support': 100} 
review = """"""Very good picture and sound, very glad I chose this unit"""""" 
review_vector = vectorizer.transform([review]) # vectorizing 
print(classifier_linear.predict(review_vector))  
18"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#18,18,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and TensorFlow: 
Concepts, Tools, and Techniques to Build Intelligent Systems
 . O'Reilly Media 
2017 
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-
using-pandas/notebook   
https://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-
b31a3df567e    
https://scikit-learn.org/stable/modules/generated/
sklearn.feature_extraction.text.TﬁdfVectorizer.html  
Tutorial: 
 https://www.geeksforgeeks.org/predicting-stock-price-direction-using-
support-vector-machines/?ref=rp  
Tutorial: 
 https://medium.com/@vasista/sentiment-analysis-using-
svm-338d418e3ff1
Testi di Riferimento
19"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#2,2,"Support Vector Machines
L'algoritmo SVM è impiegato in ambito di classiﬁcazione e regressione. 
Ha molti vantaggi tra cui: 
Efﬁcace in spazi con molte dimensioni (cioè features) 
Può trattare casi in cui le dimensioni sono maggiori delle istanze 
È efﬁciente in termini di spazio di memoria richiesto 
Attenzione: 
Se le dimensioni sono molto maggiori delle istanze, la scelta della 
funzione kernel e la regolarizzazione sono fondamentali. 
SVM non restituisce direttamente probabilità.
3"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#3,3,"Scikit-learn: Support Vector Machines
I dati in input supportati in scikit-learn sono sia 
 dense
  (es. 
numpy.ndarray
 , 
numpy.asarray
 ) sia sparsi (qualsiasi 
 scipy.sparse
 ) 
>>> 
from 
sklearn 
import
 svm 
>>> 
X 
=
 [[
0
, 
0
], [
1
, 
1
]] 
>>> 
y 
=
 [
0
, 
1
] 
>>> 
clf 
=
 svm
.
SVC() 
>>> 
clf
.
fit(X, y) 
SVC() 
>>> 
clf
.
predict([[
 2.
, 
2.
]]) 
array([1]) 
>>> 
# support vectors  
>>> 
clf
.
support_vectors_ 
array([[0., 0.],  
       [1., 1.]])  
>>> 
# indici dei support vectors  
>>> 
clf
.
support_ 
array([0, 1]...)  
>>> 
# numero dei support vectors per ogni classe  
>>> 
clf
.
n_support_ 
array([1, 1]...)
4"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#4,4,"Scikit-learn: Support Vector Machines
Esempio IRIS dataset: 
# carico il dataset IRIS
iris 
=
 load_iris()
# uso solo le prime due features
X 
=
 iris.data[:, :
 2
]
Y 
=
 iris.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)
# equivale a SVC(kernel
 =
""linear""
 )
svm 
=
 LinearSVC()
svm.fit(X_train_std, Y_train)
 
print
(
""Accuracy Train Set:""
 , svm.score(X_train_std, Y_train))
print
(
""Accuracy Test Set:""
 , svm.score(X_test_std, Y_test))
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire?
5"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#5,5,"Scikit-learn: Support Vector Machines
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire? 
Il modello soffre di overﬁtting. 
Esercizio: prova ad impiegare tutte le features del dataset.
6
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#6,6,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features.
7"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#7,7,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features. 
8
Accuracy Train Set: 0.81
Accuracy Test Set: 0.78Accuracy Train Set: 0.72
Accuracy Test Set: 0.8Accuracy Train Set: 0.76
Accuracy Test Set: 0.67"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#8,8,"Stock forecasting
Alcuni servizi web rendono disponibili gli andamenti di titoli azionari via 
APIs, es: 
Open: Starting price at which a stock is traded in a day. 
Close: Closing price. 
High: The highest price of equity symbol in a day. 
Low: The lowest price of the share in a day 
VWAP: Volume weighted average price 
Volume: Total volume of stocks traded on a particular day.  
I dati possono essere interpretati come 
 time series
 , cioè sequenze di valori 
ordinati temporalmente. 
Per approfondimenti:  
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-using-pandas/notebook  
Il task della stock price forecasting è predire il valore futuro (es. intraday, 
giornalieri, mensile, etc). di un titolo in base ai valori passati.
9"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#9,9,"Esercitazione: stock forecasting
Al seguente indirizzo trovi i dati storici del titolo RELIANCE: 
https://storage.googleapis.com/kaggle-forum-message-attachments/894813/16059/RELIANCE.csv 
Possiamo impiegare l'istanza attuale come input e tentare di fare predizione 
sul comprare (+1) oppure no (0). 
In ambito azionario è utile deﬁnire nuove features che combinano quelle 
attuali, es. Open-Close o High-Low: 
df[
'Open-Close'
 ] = df.Open - df.Close
La variabile target puoi essere approssimare nel seguente modo: 
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
Il ritorno cumulato può essere ottenuto nel seguente modo: 
df[
'Return'
 ] = df.Close.pct_change() 
 # variazione percentuale rispetto al prec
df[
'Strategy_Return'
 ] = df.Return * df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
Esercizio
 : impiega l'algoritmo SVM per la predizione e valuta l'accuratezza.
10"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Riduzione di Dimensionalità"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#1,1,"Sommario
!Introduzione
!Definizioni
!Le Principali Tecniche
!PCA vs LDA
!Principal Component Analysis (PCA)
!Linear Discriminant Analysis (LDA)
!t-SNE"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#10,10,"PCA: Retro -Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#11,11,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#12,12,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#13,13,"PCA: Scelta di k
8prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: scelta di 𝑘
Talvolta
 lascelta di𝑘èobbligata :adesempio per la
visualizzazione 2Do3Ddeidati.
Quando
 invecel’obiettivo èquello discartare informazione
inutile edati correlati mantenendo gran parte delcontenuto
informativo sipuòscegliere 𝑘nelmodo seguente :
Fissata
 una percentuale 𝑡delcontenuto informativo chesi
vuole preservare (es.𝑡=95%)sisceglie ilminimo valore di
𝑘percuilasomma deipiùgrandi𝑘autovalori ,rispetto alla
somma dituttigliautovalori ,èmaggiore ouguale a𝑡.
Considerando
 gliautovalori ordinati inordine decrescente :
𝑘=𝑎𝑟𝑔𝑚𝑖𝑛
𝑧σ𝑖=1…𝑧𝜆𝑖
σ𝑖=1…𝑑𝜆𝑖≥𝑡
Infatti, ricordando che gliautovalori denotano lavarianza
lungo idiversi assi, ilrapporto nella formula indica lavarianza
«conservata» rispetto allavarianza totale ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#14,14,"PCA: Codifica di Immagini
9prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: codifica di un’immagine
𝐱∈16500
𝐲∈15
𝐱′∈16500Immagine
originaleRicostruzione
(retroproiezione)
proiezione retro-proiezioneiprimi 8 autovettori o componenti principali
(denominati eigenfaces nell’applicazione al riconoscimento volto )
𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ15𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ15
-2532 2193 -2179 2099 491
427 -324 961 35 -40
-149 -624 317 -158 -142"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#15,15,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#16,16,"Singular Value Decomposition (SVD)
!LaDecomposizione aiValori Singolari (Singular Value
Decomposition, SVD) èuna importante fattorizzazione per
matrici avalori reali ocomplessi chesiavvale diautovalori
eautovettori
!Ogni matrice M∈!m×npuò essere fattorizzata in 
M=U""V*
dove
!Uèuna matrice m×munitaria (cioè UUt=Im)
!#èuna matrice m×ndiagonale rettangolare con soli elementi
reali non negativi
!V*èlatrasposta coniugata diuna matrice n×nunitaria V"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#17,17,"Singular Value Decomposition (SVD)
!Glielementi della diagonale di""sono detti valori singolari diM
!Lemcolonne diUsono dette vettori singolari sinistri diM
!Lencolonne diVsono dette vettori singolari destri diM
!Vale quanto segue
!Ivettori singolari sinistri diMsono gliautovettori diM∙M*
!Ivettori singolari destri diMsono gliautovettori diM*∙M
!Ivalori singolari diMsono leradici quadrate degli autovalori non
nulli diM∙M* eM*∙M"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#18,18,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#19,19,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2Ricordiamo, infatti, che gliautovettori della matrice dicovarianza !
sono paralleli agli assi dell’ellisse che rappresenta ladistribuzione dei
pattern delTraning Set(TS)"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#2,2,"Definizioni
2prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàDefinizioni
Obiettivo dei metodi per lariduzione didimensionalità
(dimensionality reduction )èquello dieseguire unmapping dallo
spazio iniziale𝑑aunospazio didimensione inferiore 𝑘,𝑘<𝑑.
Può essere vista come unaforma dicompressione (con perdita di
informazione) .Obiettivo èscartare leinformazioni non rilevanti o
meno rilevanti perilproblema diinteresse :
allevia
 iproblemi collegati allacurse ofdimensionality :operare
inspazi adelevata dimensionalità ,acausa delfatto che i
pattern sono molto sparsi, richiede ingenti moli didati per
l’addestramento .
operare
 inspazi adimensionalità inferiore rende piùsemplice
addestrare algoritmi dimachine learning .Scartando dati
ridondanti (informazioni correlate) erumorosi talvolta si
migliorano anche leprestazioni .
Attenzione :riduzione didimensionalità non significa mantenere
alcune «dimensioni» ecancellarne altre, ma «combinare »le
dimensioni inmodo opportuno ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#20,20,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#21,21,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#22,22,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#23,23,"Calcolo LDA
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#24,24,"Richiami
!Latraccia diuna matrice èdefinita solo per lematrici
quadrate edèlasomma degli elementi presenti sulla
diagonale principale .
!Traccia eautovalori diuna matrice :latraccia diuna
matrice èuguale allasomma deisuoi autovalori moltiplicati
perlerispettive molteplicità algebriche ,cioè seλ1,λ2,...,λp
sono gliautovalori distinti diuna matrice Adiordine n,
dette m1,m2,...,mplerispettive molteplicità algebriche, se
m1+m2+...+mp=n,allora
tr(A) =m1λ1+m2λ2+...+mpλp"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#25,25,"Richiami
!SiaAuna matrice quadrata diordine nesiaλ0unsuo
autovalore .Sidice molteplicità algebrica dell’autovalore λ0,
esiindica conma(λ0),ilnumero cheesprime quante volte
l’autovalore λ0annulla ilpolinomio caratteristico .
!Ricordiamo che ilpolinomio caratteristico associato auna
matrice quadrata Aèildeterminante della matrice A-λIn,
dove Aèlamatrice inesame, λèun’incognita eInèla
matrice identità dello stesso ordine di A.
Informule :
pA(λ):=det(A-λIn)"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#26,26,"Calcolo LDA
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa 𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#27,27,"t-distributed Stochastic Neighbor Embedding (t -SNE)
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten andG.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#28,28,"14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
t-SNE: Esempio"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#29,29,"t-SNE in Scikit -Learn
Per maggiori dettagli vedi documentazione online della libreria
open source scikit -learn :sklearn .manifold .TSNE!Esempio :visualizzazione 2Ddiundataset contenente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients)
invece deipixel .
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#3,3,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#30,30,"15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.I due cluster appaiono molto 
sovrapposti. 
I classificatori tradizionali 
(e.g., SVM) raggiungono una 
accuratezza di circa il 70%, 
sfruttando la maggiore 
densità dei pattern verdi 
(gatti) in una certa regione.t-SNE in Scikit -Learn"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#31,31,"!Matlab Toolbox for Dimensionality Reduction:
https://lvdmaaten.github.io/drtoolbox/
t-SNE in Matlab"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#32,32,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. "
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#4,4,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#5,5,"Esempio PCA vs LDA
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#6,6,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#7,7,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#8,8,"Principal Component Analysis (PCA)
!Riassumendo
!Dagli npattern delTraining Set (TS) sicalcolano vettore medio e
matrice dicovarianza !
!Dalla matrice dicovarianza sicalcolano idautovalori eautovettori
!Dei dautovalori siconsiderano solo ikautovalori con valore
maggiore (inordine decrescente)
!Lamatrice diproiezione ""ksarà unmatrice (d×k)lecuikcolonne
sono costituite dagli autovettori relativi aikautovalori calcolati
come sopra
!Gli autovettori !idella matrice di 
covarianza ""sono paralleli agli 
assi dell’ ellisse che rappresenta 
ladistribuzione dei pattern nel TS
!Gli autovalori #isono le varianze 
lungo gli assi !i
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#9,9,"PCA: Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Riduzione dimensionalità (Ex 15)
1"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#1,1,"Sommario
Richiami riduzione dimensionalità, projection, mainfold learning 
PCA in Python 
Scikit-learn e PCA 
PCA e compressione 
Randomized PCA 
Kernel PCA 
Locally Linear Embedding LLE 
Esercitazione"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#10,10,"PCA: Step by step in Python
Una volta ottenute le componenti, deﬁniamo il nuovo iperspazio con 
 d 
dimensioni. Prendiamo le prime d colonne di 
 V
 e proiettiamo le istanze nel 
nuovo spazio: 
X
d-proj
 = X W
 d 
In Python: 
W2 
= 
Vt
.
T
[:, :
2
]
X2D 
= 
X_centered
 .
dot
(
W2
)
11"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#11,11,"Scikit-learn e PCA
Scikit-learn implementa la PCA nel seguente modo: 
from 
sklearn.decomposition 
 import 
PCA
pca 
= 
PCA
(
n_components 
 = 
2
)
X2D 
= 
pca
.
fit_transform
 (
X
)
La variabile components_ contiene i vettori. Per accedere al primo vettore:  
pca.components_.T[:,0] 
Ogni componente è associata alla relativa varianza che si può analizzare 
con la variabile 
 explained_variance_ratio_
 . Considerando l'esempio 
precedente si ottiene: 
>>> 
pca
.
explained_variance_ratio_
array([0.84248607, 0.14631839])
12"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#12,12,"Scikit-learn e PCA
La scelta del numero di dimensioni dipende dalla varianza: si tende a 
scegliere il numero che garantisce sempre elevata varianza (es. 95%). 
Eccezione se vogliamo fare un diagramma dei campioni, in tal caso ci 
occorrono 2 o 3 dimensioni. 
Il seguente codice ricava il numero di dimensioni che preservano il 95% 
della varianza sul training set: 
pca 
= 
PCA
()
pca
.
fit
(
X_train
)
cumsum 
= 
np
.
cumsum
(
pca
.
explained_variance_ratio_
 )
d 
= 
np
.
argmax
(
cumsum 
>= 
0.95
) 
+ 
1
Un modo alternativo per speciﬁcare la varianza: 
pca 
= 
PCA
(
n_components
 =
0.95
)
X_reduced 
 = 
pca
.
fit_transform
 (
X_train
)
(continua)
13"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#13,13,"Scikit-learn e PCA
Ulteriore metodo per ﬁssare d è fare un graﬁco del cumsum della varianza. 
Il 
gomito
  della curva è dove la varianza interrompe la crescita veloce.  
Nell'esempio una dimensionalità inferiore a 100 è un valore ideale:
14
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#14,14,"PCA e compressione
Una volta ottenuto il dataset proiettato sulle componenti, la dimensione del 
dataset si riduce sensibilmente. 
La funzione 
 inverse_transform
 () di PCA permette di ricostruire una 
approsimazione del dataset con le dimensioni originali a partire dalle 
istanze nello spazio ridotto. 
X
recovered
  = X
 d-proj
 W
d
T 
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset. (2) visualizza le cifre ricostruite con 
 inverse_transform(). 
Suggerimento per visualizzare le cifre
 : 
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
15"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#15,15,"PCA e compressione
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset 
from
 sklearn.decomposition 
 import
 PCA
from
 sklearn 
 import
 datasets
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 fetch_openml
from
 sklearn.preprocessing 
 import
 StandardScaler
mnist = fetch_openml(
 'mnist_784'
 )
X_train, X_test, y_train, y_test  = train_test_split
        (mnist.data, mnist.target, test_size=
 1
/
7.0
, random_state=
 0
)
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
pca = PCA(n_components = 
 154
)
X_reduced = pca.fit_transform(X_train)
X_recovered = pca.inverse_transform(X_reduced)
(continua)
16"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#16,16,"PCA e compressione
original_len = X_train.flatten().size
print
(original_len)
red_len = X_reduced.flatten().size
print
(red_len)
rec_len = X_recovered.flatten().size
print
(rec_len)
pct = (red_len - original_len) * 
 100
 / original_len
print
 (pct)
47040000
9240000
47040000
-80.35714285714286 
Dataset ridotto al 20% della dimensione originale! 
17"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#17,17,"PCA e compressione
Esercizio
 : ... (2) visualizza le cifre ricostruite con 
 inverse_transform().  
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
plt.imshow(X_recovered[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
18
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#18,18,"Scikit-learn: Randomized PCA
Impiegando il parametro 
 svd_solver
 =
""randomized"", impieghiamo 
l'algoritmo Randomized PCA che riduce notevolmente il tempo di 
esecuzione essendo d << n: 
O(
m × n
2
) + O(
 n
3
)  --->   O(
 m × d
2
) + O(
 d
3
) 
Per default sciki-learn usa il solver 
 auto
, che impiega la versione 
randomized se 
 m
 o 
n
 sono maggiori di 500 e d è minore del 80% rispetto a 
m
 o 
n
.  
Per forzare l'impiego della versione esatta, impiegare l'opzione 
 full
. 
19"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#19,19,"Scikit-learn: Incremental PCA
L'algoritmo PCA richieda che l'intero dataset sia presente in memoria. 
L'algoritmo Incremental PCA accetta il dataset suddiviso in mini-batch, e 
può essere impiegato 
 online
 . 
from 
sklearn.decomposition 
 import 
IncrementalPCA
n_batches 
 = 
100
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
)
for 
X_batch 
 in 
np
.
array_split
 (
X_train
, 
n_batches
 ):
    
inc_pca
.
partial_fit
 (
X_batch
)
X_reduced 
 = 
inc_pca
.
transform
 (
X_train
)
Con la classe memmap di NumPy possiamo leggere gli array 
incrementalmente da ﬁle binary: 
X_mm 
= 
np
.
memmap
(
filename
 , 
dtype
=
""float32""
 , 
mode
=
""readonly""
 , 
shape
=
(
m
, 
n
))
batch_size 
 = 
m 
// 
n_batches
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
, 
batch_size
 =
batch_size
 )
inc_pca
.
fit
(
X_mm
)
20"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#2,2,"Richiami: riduzione di dimensionalità
In casi reali i dati da analizzare possono essere sempliﬁcati riducendo il 
numero di features. L'obiettivo è velocizzare il processo di training senza 
inﬂuire troppo sulle performance, e ridurre l'eventuale rumore, es: 
Nel MNIST dataset i pixel nei bordi sono sempre bianchi, possiamo 
pensare di rimuoverli 
Spesso i pixel neri sono correlati, cioè appaiono vicini. È possibile 
fonderli facendone una media.  
Se creassimo a caso immagini, in rarissimi casi potrebbero assomigliare 
alle cifre nel dataset. Perciò i gradi di libertà disponibili nella creazione 
di istanze sono notevolmente ridotti rispetto a quelli potenziali in uno 
spazio con le medesime dimensioni. 
Inoltre la riduzione di dimensionalità permette di creare graﬁci nel caso in 
cui le dimensioni siano 2 o 3.
3"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#20,20,"Scikit-learn: Kernel PCA (kPCA)
In modo simile ai kernel del SVM è possibile fare proiezioni non lineari 
complesse per la riduzione di dimensionalità. 
Similmente al SVM, ha il vantaggio di mantenere cluster di istanze dopo la 
proiezione, oppure operare 
 unrolling
  di forme complesse. 
In scikit-learn impiegando il kernel rbf si ha: 
from 
sklearn.decomposition 
 import 
KernelPCA
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.04
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
Di seguito alcuni esempi di proiezioni a 2 dimensioni con vari kernel:
21
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#21,21,"Scikit-learn: Kernel PCA (kPCA)
La scelta del kernel dipende dal task. Se il task è supervisionato, si può fare 
una semplice grid search sui kernel e i relativi iperparametri per ottenere 
performance migliori. 
Nel seguente codice si impiega una pipeline per il task di regressione: 
from 
sklearn.model_selection 
 import 
GridSearchCV
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.pipeline 
 import 
Pipeline
clf 
= 
Pipeline
 ([
(
""kpca""
, 
KernelPCA
 (
n_components
 =
2
)),
(
""log_reg""
 , 
LogisticRegression
 ())
])
param_grid 
 = 
[{
""kpca__gamma""
 : 
np
.
linspace
 (
0.03
, 
0.05
, 
10
),
""kpca__kernel""
 : [
""rbf""
, 
""sigmoid""
 ]
}]
grid_search 
 = 
GridSearchCV
 (
clf
, 
param_grid
 , 
cv
=
3
)
grid_search
 .
fit
(
X
, 
y
)
>>> 
print
(
grid_search
 .
best_params_
 )
{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}
22"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#22,22,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri?
23"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#23,23,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri? 
Se ricostruiamo i dati originali con le componenti PCA possiamo valutare 
le performance con una misura di discostamento (es. distanza quadratica). 
Attenzione
 : l'impiego dei kernel implica che la ricostruzione generi un 
feature space inﬁnito-dimensionale. Perciò non è possibile confrontare 
direttamente le istanze con lo spazio originale. Con la tecnica 
recontruction pre-image è possibile trovare il punto nello spazio originale 
che è vicino alla istanza 
 ricostruita
 .
24
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#24,24,"Scikit-learn: Kernel PCA (kPCA)
Il parametro ﬁt_inverse_transform=True adotta questa strategia: 
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.0433
,
              
 fit_inverse_transform
 =
True
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
X_preimage 
 = 
rbf_pca
.
inverse_transform
 (
X_reduced
 )
>>> 
from 
sklearn.metrics 
 import 
mean_squared_error
>>> 
mean_squared_error
 (
X
, 
X_preimage
 )
32.786308795766132
25"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#25,25,"Scikit-learn: Locally Linear Embedding (LLE)
È una ulteriore tecnica non lineare, ma non si basa sulle proiezioni. 
In sintesi, nella prima fase analizza le similarità tra una istanza e le istanze 
vicine (neighbors), e successivamente crea un iperspazio con meno 
dimensioni che mantiene queste tali relazioni.  
È un approccio ideale per fare unrolling e in presenza di poco rumore. 
from 
sklearn.manifold 
 import 
LocallyLinearEmbedding
lle 
= 
LocallyLinearEmbedding
 (
n_components
 =
2
, 
n_neighbors
 =
10
)
X_reduced 
 = 
lle
.
fit_transform
 (
X
)
Lo spazio risultate è correttamente dispiegato, anche se le distanze relative 
non sono mantenute coerenti.
26
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#26,26,"Esercitazione
Carica il dataset MNIST e suddividilo in 60K training e 10K test set. 
Addestra un classiﬁcatore Random Forest, calcola il tempo di training e le 
performance. 
Applica PCA con una 
 explained variance ratio
  del 95%. 
Addestra un nuovo classiﬁcatore Random Forest, calcola il tempo di 
training e le performance, e confronta i valori con i valori precedenti.
27"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#27,27,"Esercitazione
from
 sklearn.datasets 
 import
 fetch_openml
mnist = fetch_openml(
 'mnist_784'
 )
X_train = mnist[
 'data'
][:
60000
]
y_train = mnist[
 'target'
 ][:
60000
]
X_test = mnist[
 'data'
][
60000
:]
y_test = mnist[
 'target'
 ][
60000
:]
from
 sklearn.ensemble 
 import
 RandomForestClassifier
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
import
 time
t0 = time.time()
rnd_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
28"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#28,28,"Esercitazione
from
 sklearn.metrics 
 import
 accuracy_score
y_pred = rnd_clf.predict(X_test)
accuracy_score(y_test, y_pred)
from
 sklearn.decomposition 
 import
 PCA
pca = PCA(n_components=
 0.95
)
X_train_reduced = pca.fit_transform(X_train)
rnd_clf2 = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
t0 = time.time()
rnd_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
X_test_reduced = pca.transform(X_test)
y_pred = rnd_clf2.predict(X_test_reduced)
accuracy_score(y_test, y_pred)
29"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#29,29,"Esercitazione
from
 sklearn.linear_model 
 import
 LogisticRegression
log_clf = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf.predict(X_test)
print(
accuracy_score(y_test, y_pred))
log_clf2 = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf2.predict(X_test_reduced)
print(
accuracy_score(y_test, y_pred))
30"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#3,3,"Osservazione
Presi 2 punti a caso in un quadrato di dimensioni 1x1, la distanza media è 
0.52. In un cubo 3d è 0.66. In un ipercubo di 1M dimensioni è 408,25. 
In dataset con alta dimensionalità il rischio di data sparity è elevato. 
Una nuova istanza è molto probabile che sia lontana dalle altre già 
incontrate in precedenza; probabile overﬁtting durante il test. 
Se incrementiamo le istanze nel training set riduciamo il problema, ma il 
tempo di addestramento si allungano, e a volte non è possibile 
collezionare nuove istanze. 
Il numero di istanze da includere cresce esponenzialmente col numero 
di dimensioni del dataset.
4"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#30,30,"Esercitazione
>>>
Training took 57.60s
Training took 124.90s
0.9255
Training took 55.04s
Training took 15.68s
0.9201
31"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#31,31,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
32"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#4,4,"Projection
Spesso le features sono correlate tra loro, oppure assumono spesso valori in 
piccoli intervalli. 
Nell'esempio seguente si può notare come molti punti sono vicini ad un 
piano (2d). Se proiettiamo questi punti sul piano (sottospazio) otteniamo un 
dataset di dimensioni ridotte, con 2 nuove features, cioè le coordinate nel 
piano.
5
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#5,5,"Projection
In altri casi la proiezione è difﬁcile o impossibile. 
Nel dataset toy Swiss roll, semplici piani non permettono di mantenere la 
coerenza spaziale originale delle istanze. Solo ""dispiegando il rotolo"" di 
punti è possibile avere un piano coerente.
6
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#6,6,"Manifold learning
Nell'esempio precedente, il 
 roll
 è una struttura che assomiglia a un piano 
2d (d=2) che è disposta (rotolata) in uno spazio 3d (n=3 con n>d). 
Manifold assumption
 : l'ipotesi che molti dataset reali possono essere 
rappresentati in spazi con dimensioni ridotte. Inoltre suppone che nello 
spazio ridotto sia più facile risolvere problemi di classiﬁcazione, 
regressione, etc.  
Quest'ultima assunzione non è sempre vera, es:
7
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#7,7,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Quale piano sceglieresti?
8
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#8,8,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Il piano con massima varianza potenzialmente riduce la perdita di 
informazione durante la proiezione. 
PCA mira a identiﬁcare tali assi.
9
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#9,9,"PCA: Step by step in Python
Attenzione
 : se perturbiamo leggermente il training set, i 
 principal 
component 
 (gli assi) possono cambiare, ad esempio invertendo la 
direzione, anche se il piano deﬁnito da essi rimane generalmente lo stesso. 
Per trovare le compomenti si impiega la Singular Value Decomposition 
(SVD) che permette di ottenere la seguente decomposizione: 
X = U 
 Σ
 V
T 
dove le colonne di V rappresentano le componenti che stiamo cercando. 
In Python possiamo ottenerle nel seguente modo: 
X_centered 
 = 
X 
- 
X
.
mean
(
axis
=
0
)
U
, 
s
, 
Vt 
= 
np
.
linalg
.
svd
(
X_centered
 )
c1 
= 
Vt
.
T
[:, 
0
]
c2 
= 
Vt
.
T
[:, 
1
]
Attenzione
 : è sempre consigliabile centrare i dati nell'origine impiegando 
lo 
StandardScaler
 ().
10"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Valutazione delle prestazioni
Machine Learning "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Valutazione delle Prestazioni nella 
Regression 
Loss Function e le tre misure di Loss: 
•
 Training Error, Generalization Error, Test Error 
Overﬁtting 
Le tre fonti di errore: Noise, Bias, Variance
 
2"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#10,10,"Training Error vs.  
Complessità del Modello
 
11E’ interessante vedere come può variare tale errore in base 
alla complessità del modello.  
caso di modello costante:  
y
Area xPrezzo
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#11,11,"Training Error vs.  
Complessità del Modello
 
12caso di modello lineare:  
y
Area xPrezzo
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#12,12,"Training Error vs.  
Complessità del Modello
 
13
caso di modello quadratico:  
Complessità del modelloErrore 
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#13,13,"Training Error vs.  
Complessità del Modello
 
14
caso di modello polinomiale:  
Complessità del modelloErrore 
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#14,14,"Training Error vs.  
Complessità del Modello
 
15L’andamento dell’errore ha dunque in genere la seguente 
forma: 
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#15,15,"Training Error vs.  
Complessità del Modello
 
16Il training error non è una buona misura della predictive 
performance: 
Esso è eccessivamente ottimistico, proprio perché il vettore 
ŵ è calcolato afﬁnché il modello si adatti ai dati di training. y
Area xPrezzo
xt
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#16,16,"Generalization Error
 
17Sarebbe interessante conoscere il “loss” prendendo in 
considerazione tutte le possibili coppie ( x, y), ossia, per il 
nostro esempio degli appartamenti, tutte le possibili case della 
zona presa in considerazione, calcolando la media della 
funzione loss su tali appartamenti. 
In genere però nel nostro data set abbiamo soltanto un 
numero limitato di osservazioni ( x, y). "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#17,17,"Generalization Error
 
18Per effettuare una stima di tale costo dovremmo cercare di 
pesare le varie coppie ( x, y) in base alla probabilità che hanno 
di essere presenti nella zona d’interesse.  
E’ dunque utile prendere in considerazione la distribuzione 
degli appartamenti in base al valore della loro area:
Area"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#18,18,"Generalization Error
 
19Potremmo inoltre considerare la distribuzione delle case in 
base al loro prezzo, a parità di area:
Prezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#19,19,"Generalization Error
 
20Formalmente, possiamo deﬁnire il Generalization (o True) 
Error come segue:
Generalization Error = Ex,y[L(y,f ˆw(x))]
ossia come l’average value della funzione Loss, calcolato su 
tutte le possibili coppie ( x, y) pesate in base alla loro 
probabilità di comparire nella zona."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#2,2,"La valutazione delle prestazioni è di importanza cruciale 
per poter apprezzare il metodo che stiamo utilizzando per 
le nostre previsioni. 
Essa ci aiuta nella scelta tra modelli di diversa complessità 
a nostra disposizione. 
A tal ﬁne occorre deﬁnire una metrica che ci consenta di 
valutare quanto perdiamo (loss) quando facciamo una 
certa previsione. 
 
3
Introduzione alla  
Valutazione delle Prestazioni"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#20,20,"Generalization Error
 
21Vediamo ora di intuire come tale errore possa variare in base 
alla complessità del modello. 
Per far questo ci avvarremo della rappresentazione che segue, 
dove la regione in blu rappresenta, con le diverse gradazioni 
nei vari punti, la distribuzione di probabilità di avere una casa 
nel nostro data set (la parte bianca rappresenta le più alte 
probabilità):
y
Area xPrezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#21,21,"Generalization Error
 
22Per valutare l’errore consideriamo come la “ﬁtted function” f 
(in verde nella ﬁgura precedente e in quelle successive), che 
si adatta alle osservazioni del training set, possa predire i 
valori delle case non presenti nel training set, pesate dalle 
loro probabilità. 
Ossia dobbiamo vedere quanto la f sia “vicina” all’area in 
bianco della distribuzione rappresentata in ﬁgura. 
Nei lucidi che seguono cercheremo di intuire l’andamento del 
Generalization Error a fronte di diverse complessità del 
modello (costante, lineare, quadratico, ecc.)."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#22,22,"Generalization Error vs.  
Complessità del Modello
 
23caso di modello costante: 
Prezzo
AreaErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#23,23,"Generalization Error vs.  
Complessità del Modello
 
24caso di modello lineare: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#24,24,"Generalization Error vs.  
Complessità del Modello
 
25caso di modello quadratico: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#25,25,"Generalization Error vs.  
Complessità del Modello
 
26caso di modello polinomiale: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#26,26,"Generalization Error vs.  
Complessità del Modello
 
27caso di modello “High level”: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#27,27,"Generalization Error vs.  
Complessità del Modello
 
28L’andamento dell’errore è dunque in genere il seguente: 
Complessità del ModelloErrore"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#28,28,"Generalization Error
 
29Ricordiamoci però che, a differenza di ciò che accade per 
il training error, NON è possibile calcolare il 
Generalization Error. 
Per calcolarlo, dovremmo conoscere la “true distribution” 
delle probabilità vista prima, cosa che non sappiamo fare. "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#29,29,"Test Error
Deﬁnito come average loss sui punti dell’insieme di test:
 
30
Test Error =1
Ntest·X
i2testL[yi,fˆw(xi)]
AreaPrezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#3,3,"Loss Function
 
4Possiamo indicare una funzione di Loss come segue:
dove y è l’actual value, mentre la funzione f ci fornisce il 
valore previsto ŷ.  
Tale funzione L rappresenta il costo che abbiamo se usiamo 
la f con il vettore dei pesi ŵ a fronte dell’input x.L[y, f ˆw(x)]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#30,30,"Andamento degli errori  vs.  
Complessità del Modello
 
31Training Error: 
Training Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#31,31,"Andamento degli errori vs.  
Complessità del Modello
 
32Generalization Error: 
Generalization Error
Training Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#32,32,"Andamento degli errori vs.  
Complessità del Modello
 
33Test Error: approssima il Generalization Error 
Generalization Error
Training ErrorTest Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#33,33,"Overﬁtting
 
34Dato un modello con parametri ŵ, si ha overﬁtting se esiste un 
modello con i parametri stimati w’ tale che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
Generalization (true) Error
Training ErrorTest Error
ŵw’
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#34,34,"Training/Test Split
Un importante problema da considerare ai ﬁni 
dell’addestramento e della valutazione di un modello è la 
suddivisione delle osservazioni disponibili tra training set 
e test set:
 
35
Training Set Test Set"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#35,35,"Training/Test Split
Se per il training set abbiamo poche osservazioni 
rischiamo di non stimare in modo adeguato il modello, 
cosa che potrebbe comportare previsioni imprecise da 
parte dello stesso.
 
36
Training Set Test Set
Troppo pochi ➝ ŵ non stimato adeguatamente  "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#36,36,"Training/Test Split
D’altro canto, se abbiamo poche osservazioni per il test 
set rischiamo di non avere una rappresentazione adeguata 
dei dati che stiamo analizzando (e.g., tutte le case in 
vendita) 
 
37
Training Set Test Set
Troppo pochi ➝ true error non stimato  
                       adeguatamente dal test error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#37,37,"Training/Test Split
Purtroppo non esiste una formula che ci dica come 
suddividere esattamente i dati in training set e test set. 
Una regola pratica da poter seguire consiste nell’usare un 
numero sufﬁciente di punti per il test set per consentire 
una ragionevole approssimazione del true error: 
 
38
Training Set Test Set
Se ciò lascia troppi pochi punti per il training set,  ci 
possiamo avvalere di altri metodi che vedremo 
successivamente (
 cross validation
 )."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#38,38,"Le tre sorgenti di errore
Noise 
Bias  
Variance
 
39Test SetE’ estremamente utile analizzare le diverse cause che possono 
portare ad un errore nelle previsioni. Esse sono le seguenti:
Cominciamo a vedere in modo intuitivo di cosa si tratta."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#39,39,"Noise
Come sappiamo, in genere i dati sono intrinsecamente 
“rumorosi”. 
Nel nostro caso, possiamo ipotizzare che esista una “true 
function” che lega 
 x
 a y. Essa però non è una descrizione 
perfetta di tale legame. Ci sono infatti altri fattori che 
magari non abbiamo tenuto in conto (altri attributi, ecc.)
 
40
Tutto ciò comporta un “rumore” intrinseco, che possiamo 
rappresentare con il termine 
 ε
, che ha media uguale a zero.y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#4,4,"Esempi di Loss Function
 
5La funzione di Loss può essere ad esempio deﬁnita come 
Errore Assoluto (Absolute Error):
oppure come Errore Quadratico (Squared Error):L[y, f ˆw(x)] = |y fˆw(x)|
L[y, f ˆw(x)] = [ y fˆw(x)]2
Tali esempi di funzione assumono che il “loss” per 
underpredicting sia uguale a quello di overpredicting."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#40,40,"Noise
Tale rumore comporta in genere uno scostamento (spread) 
rispetto alla funzione vera. 
Possiamo dunque prendere in considerazione la varianza 
di tale variabile:
 
41varianza di ε
Il rumore in questione è chiamato “
 irreducible error
 ”.y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#41,41,"Bias
Il rumore prima descritto non lo possiamo controllare. 
Possiamo però controllare il bias e la variance. 
Per deﬁnire il bias, consideriamo ad es. un modello 
costante addestrato con diversi training set:
 
42y
Area xPrezzo
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#42,42,"Bias
Consideriamo adesso la funzione media (quella tratteggiata) 
delle varie funzioni f stimate:
 
43y
Area xPrezzo
y
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#43,43,"Bias
Il bias è deﬁnito come la differenza tra la funzione media 
e la true function:
 
44
E’ in sostanza una valutazione di quanto il mio modello si 
adatti alla true function.
low complexity → high biasy
Area xPrezzo
bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#44,44,"Variance
Per introdurre il concetto di varianza nella regression, 
dobbiamo considerare quanto le varie funzioni f stimate 
differiscono dalla funzione media. Vediamo ad esempio il 
caso di modello costante: 
 
45Non abbiamo una variazione elevata  
per le diverse funzioni stimate.
low complexity → low variancey
Area xPrezzo
y
Area xPrezzo
y
Area xPrezzo
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#45,45,"Variance
Per un modello polinomiale di grado elevato le cose 
vanno in modo diverso:
 
46
Prezzo
Prezzo
Area Area"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#46,46,"Variance
Se consideriamo le funzioni f stimate per i possibili 
training set:
 
47
Questa volta la variazione è elevata.
high complexity → high varianceArea AreaPrezzo
Prezzo
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#47,47,"Bias per  
high-complexity models
Il bias per modelli “high order” è invece in genere basso:
 
48high complexity → low biasy
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]
bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#48,48," 
49
Bias-Variance Tradeoff
bias variance
Complessità del Modello
sweet spotMSE = bias + variance2"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#49,49," 
50
Bias-Variance Tradeoff
goal in ML →  trovare il cosiddetto “sweet spot”
purtroppo non possiamo calcolare bias e variance!
Per calcolarle dovremmo avere a disposizione la true 
function e tutti i possibili training set. 
Vedremo in seguito come poter operare in pratica per 
ottimizzare il tradeoff."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#5,5,"Valutare la funzione Loss 
 
6Ai ﬁni della valutazione del “loss” occorre deﬁnire i 
seguenti tipi di errore: 
• Training Error 
• Generalization Error (True Error) 
• Test Error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#50,50," 
51
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)
bias + noise
#data points nel training settrue errorErrore
training error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#51,51," 
52Andamento del True Error:
Se abbiamo pochi punti nel training set l’errore è alto, perché la 
funzione f (ﬁtted function) non stima bene la “true relationship” 
tra 
x
 e y. 
Aumentando i punti l’errore diminuisce. 
Al limite, esso tende ad un valore uguale a: bias + noise. Questo 
perché, anche se avessimo tutte le osservazioni possibili, il 
modello potrebbe non essere sufﬁcientemente ﬂessibile per 
catturare perfettamente la “true relationship” (questa è la nostra 
deﬁnizione di bias). 
A ciò si aggiunge il noise che, come sappiamo, non possiamo 
controllare. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#52,52," 
53Andamento del Training Error:
Se abbiamo pochi punti nel training set l’errore è basso, 
perché la funzione f (ﬁtted function) può approssimare più 
facilmente la “true relationship” tra 
 x
 e y. 
Aumentando i punti l’errore aumenta. 
Al limite, anch’esso tende ad un valore uguale a: bias + noise. 
Questo perché, se avessimo tutte le osservazioni possibili, 
l’errore calcolato sarebbe proprio il true error che, come 
abbiamo visto, tende al valore bias + noise. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#53,53,"Workﬂow per Regression  
(e per il ML in generale)
I due task importanti che dobbiamo attuare nella 
regression sono: 
1.
 Scelta del modello di regressione (
 model selection
 ) 
2.
 Valutazione del modello (
 model assessment
 )
 
54"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#54,54,"Workﬂow per Regression (e ML)
1.
 Model selection 
Spesso dobbiamo scegliere dei parametri di tuning 
 λ 
che controllano la complessità del modello (e.g., grado 
del polinomio) 
2.
 Model assessment 
Una volta scelto il modello, dobbiamo effettuare la 
valutazione del Generalization Error.
 
55"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#55,55,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
• 
stima dei parametri 
 ŵ
λ
 sui training data 
•
 valutazione delle prestazioni sui test data 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso test error  
2.
 Model assessment 
Considerare il test error calcolato su 
 ŵ
λ
*
 (ﬁtted model per la 
complessità scelta 
 λ
*) per approssimare il Generalization 
Error.
 
56Un approccio ingenuo  al problema potrebbe essere il seguente:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#56,56,"Workﬂow per Regression (e ML)
 
57Attenzione! 
Si è veriﬁcato un Peaking!!!
•E’ accaduto che l’ipotesi (i.e., la funzione stimata) è stata 
selezionata  in base alle sue prestazioni sull’insieme di test . 
•L’informazione che avrebbe dovuto rimanere conﬁnata in 
tale insieme si è, per così dire, “inﬁltrata” nell’algoritmo di 
apprendimento."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#57,57,"Una soluzione è quella di considerare non solo due data 
set, ossia il training set e il test set: 
 
58
Training 
SetTest 
Set
ma considerarne tre (a patto di avere dati sufﬁcienti): 
Training 
SetTest 
Set
Validation
 Set
Workﬂow per Regression (e ML)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#58,58,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
•
 stima dei parametri 
 ŵ
λ 
sul training set 
•
 valutazione delle prestazioni sul validation set 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso errore sul 
validation set 
2.
 Model assessment 
Calcolo del test error (usando dunque il test set) con 
 ŵ
λ
*
 per 
approssimare il Generalization Error.
 
59L’approccio in questo caso è il seguente:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#59,59,"Tipici split 
 
60Non c’è una regola generale per suddividere le 
osservazioni disponibili tra i tre data set. 
Tipici split sono i seguenti:
Training 
SetTest 
Set
Validation
 Set
80%      10 %   10%
50%      25%   25%"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#6,6,"Training Error
 
7Consideriamo ancora l’esempio relativo ai prezzi degli 
appartamenti. Supponiamo di avere a disposizione le 
osservazioni come rappresentate in ﬁgura:
y
AreaxPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#60,60,"Riferimenti
 
61
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2008. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#7,7,"Training Error
 
8y
AreaxPrezzo
Come sappiamo, dobbiamo decidere il modello da 
utilizzare (lineare, quadratico, ecc.) e scegliere un 
sottoinsieme delle osservazioni per effettuare la fase di 
training del modello:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#8,8,"Training Error
 
9y
AreaxPrezzo
Possiamo ad esempio scegliere un modello quadratico e 
calcolare i pesi w tali da minimizzare la funzione RSS:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#9,9,"Calcolo del Training Error
 
10Una volta stimati i parametri del modello, possiamo 
valutare il training error di tale modello stimato come 
segue: 
1. Deﬁnizione di una Loss Function (absolute error, squared 
error, ecc.) 
2. Calcolo del Training Error come “average loss”, deﬁnito 
sugli N punti di training: 
Training Error =1
N·NX
i=1L[yi,fˆw(xi)]"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Reinforcement Learning"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#1,1,"Acknowledgements, sources and links
Organization, content and images of the slides are extracted from  the 
following sources:
•Reinforcement Learning: An Introduction . Richard S. Sutton  
and Andrew G. Barto, second edition, 2018.
•Implementation of Reinforcement Learning algorithms, from 
Sutton -Barto’s book . Denny Britz, GitHub project, 2016.
•Tutorial: Introduction to Reinforcement Learning with 
Function Approximation . Richard S. Sutton, 2016.
•UCL Course, Reinforcement Learning, videos and slides .  
David Silver, 2015.
•UCL course, Advanced Deep Learning & Reinforcement 
Learning, videos and slides . DeepMind, 2018."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#10,10,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(Ot,Rt,At−1,Ot−1,Rt−1,...))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. .."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#11,11,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(history ))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. .."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#12,12,"Not alone! Second actor: the environment
Agent, step t
•Receives observation Ot
•Receives scalar reward Rt 
•Computes his own state !!""
•Executes action At.
Environment, step t
•Receives action At 
•Computes his own state !!#$%
•Emits observation Ot+1
•Emits scalar reward Rt+1"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#13,13,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#14,14,"History , agent state , environment state
Notation
•History : the sequence of observations, actions, rewards up 
to  time step t:
Ht:=O1,R1,A1,...,At−1,Ot,Rt
•The agent selects actions, and the environment answers with
observations andrewards
•State : the information used (by the agent and the  
environment) to determine what happens next
•State is naturally a sequence St
•Agent state is a function of history: St := f (Ht)
•Environment state ""!""is different from agent state ""!#"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#15,15,"Markov state
Uncertainty
Since we have no control of environment, everything is a random  
variable
Definition
A sequence of states (random variables) is Markov if and only if
Pr(St+1|St)=Pr(St+1|S1,...,St)
•The future is independent of the past given the present:
St  →Ht+1:+ ∞
•Once the state is known, the history may be thrown away: the  
state is a sufficient statistic of the future
Exercise
Is the environment state ""!""Markov? Is the history HtMarkov?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#16,16,"Fully observable environments
•Agent observes environment
state: Ot = !!""=!!%
•Agent state andenvironment  
state coincides!
Anever -ending loop
•...we(the agent) receive Rt
and observe St...
•...and thus wedecide todo  
action At∼π(·,St)...
•...andenvironment answers  
At with a new reward, state  
pair Rt+1,St+1..."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#17,17,"Example: themaze
Exercise
Discuss this example in terms of the language you have  
learned up tonow."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#18,18,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4 What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#19,19,"Strategy Policy
Arrows represent the policy π: which action to take from  
every state.Example: a policy for themaze
"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#2,2,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#20,20,"Example: values for the policy of the maze
•Let πbe the optimal policy
•Value vπ (s) for every state s
Exercise
Choose a state s and compute vπ (s) by yourself. If sj denote s
the successor state of s, can the value vπ (sj) help with this  
computation?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#21,21,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#22,22,"Prediction , improvement and control
The prediction problem inRL
Forecast the future: can you say from each state how much will be  
your return? It depends on the policy!
The improvement problem inRL
Change the future: can you find a different policy that will give  
you a better return?
The control problem inRL
Change the future: can you find the best policy atall?
Exercise
State formally the prediction, the improvement and the control  
problem."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#23,23,"Gridworld example: prediction
Exercise
Compute the value function for the uniform random policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#24,24,"Gridworld example: improvement
Exercise
Find an improvement of the uniform policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#25,25,"Gridworld example: optimal control
Exercise
Compute the optimal value function over all possible policies.  
Given the optimal value v∗as above, find the optimal policy.  Is 
the optimal policy unique?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#26,26,"Wrapping up
Learning goals
•Understand the RL problem, and how RL differs from  
supervised learning
•Understand reward, return and how they are used to 
make  decisions
•Understand actions, states and rewards in term 
of  agent/environment interactions
•Understand the optimal control problem"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#27,27,"Wrapping up
What we (hopefully) have learnt
•Reinforcement Learning (RL) is concerned with goal -directed  
learning and decision -making. In RL an agent learns from  
experiences it gains by interacting with the environment. In  
supervised learning we cannot affect theenvironment
•In RL rewards are often delayed in time and the agent tries to  
maximize the cumulative sum of rewards, called return .Return 
is a long -term goal. For example, one may need to  make 
seemingly suboptimal moves to reach a winning position in a 
game
•An agent interacts with the environment via actions. The  
environment answers with states and rewards ... and so on in 
a  loop, that can finish after a certain number of steps or go 
on  forever
•Optimal control can be achieved by a prediction -improvement  
loop"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#28,28,"Exercises
•Can every decision task be represented as an optimization  
problem with respect to a suitable reward?
•Is the reward an intrinsic datum of the decision task?
•Make an example where the greedy policy isoptimal.
•Make an example of a decision task with non-Markov  
environment state.
•Make an example of a decision task with non-Markov agent  
state."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#29,29,"Exercises
The generic definition of policy is a time -dependant stochastic  
function of the history: πt (At|Ht ) = Pr(At |Ht ). Give a definition  of the 
policy in the following cases, and find a corresponding task.
•Fully observable environment, stochastic and non-stationary  
policy.
•Partially observable environment, stochastic and stationary  
policy.
•Fully observable environment, deterministic and stationary  
policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#3,3,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#4,4,"The RLproblem
Important points
•Trying to reach a goal
•Interactions: active decision -making agent vs environment
•Uncertainty about theenvironment
•Effects of actions cannot be fully predicted: 
adaptation required ( learning )
The RL reward hypothesis
All goals can be described by the maximization of some expected  
cumulative reward
•Is it true? Interesting analysis at  
http://incompleteideas.net/rlai.cs.ualberta.ca/ 
RLAI/rewardhypothesis.html
•Related with the expected utility hypothesis from von  
Neumann -Morgenstern utility theory"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#5,5,"The RLproblem
RL main task
Decision problem: we would like to choose actions that maximize  
the return , i.e. the total future reward
Sequential decision making
Actions may have long term consequences
Uncertainty
The best we can aim for is maximizing the value , i.e.the
expected total future reward
Exercise
Find an example of a deterministic task, that is, a task where  your 
actions gives a fixed outcome (that you may or may not know  in 
advance)"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#6,6,"The RLproblem
To be greedy can bewrong
•A financial investment (may take months to mature)
•Refuelling a helicopter (might prevent a crash in 
several  hours)
•Blocking opponent moves (might help winning chances 
many moves from now)
Exercise
Discuss the difference between return and value"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#7,7,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#8,8,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?
•Maze and Gridworld: −1 for every move. Correct. Why?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#9,9,"Examples
Games
TD-Gammon, 1995, ACM Communications .  
Atari’s family (video ).
•49 out of 57: DQN, 25 Feb 2015, Nature .
•52 out of 57: R2D2, Sep 2018, ICLR 2019 .
•51 out of 57: MuZero, Nov 2019, arXiv .
•57 out of 57: Agent57, Mar 2020, arXiv .
AlphaGo’s family (video ).
•AlphaGo, 27 Jan 2016, Nature .
•AlphaGo Zero, Oct 2017, Nature . 
•AlphaZero, Dec 2018, Science .
•MuZero, Nov 2019, arXiv .
StarCraft II (video ).AlphaStar, Nov 2019, Nature .
Protein folding
How a protein’s amino acid sequence dictates its three -dimensional  
structure? AlphaFold :Oct 2019, PROTEINS ;Jan 2020, Nature ."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#0,0,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equationsMDP: Markov Decision Processes
"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#1,1,"Basic block: state , action , model ,reward
uintermediate
or initial state
 vintermediate
or final state
w
r =+3
p(v,+3|u,a)=0.7
r =−1
p(w,−1|u,a)=0.3intermediate
or final stateaction a"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#10,10,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#11,11,"The D in MDP: decisions
Where are thedecisions?
•In any state s, the agent must choose between available  
actions a
•When choosing a from s, the environment answers s’ 
with probability #!!!"". Environment decision.
•The agent behaviour is given by probabilities π(a|s): ”how  
likely I’m going to choose a from s?”.  Agent decision.
Definition
A policy π is a probability distribution over actions given states:
π(a|s) := Pr(At = a|St =s)"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#12,12,"Example: uniform stochastic policy
A
1
B
1
0.5
0.5
0.8,+10
 0.2,+3
0.1,+2
 0.9,−30.5
0.5
0.1,+39
0.9,+42
0.1,−2
0.9,+3
2 2
What can wedo?
At every step, we choose the action according to the probability."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#13,13,"Example: deterministic policy
A
1
2B
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2
What can wedo?
At every step, we choose the given action."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#14,14,"Tabular representation
S and Aarefinite
A policy can be represented by a table: every line in the table  
corresponds to a state.
Stochastic policy
A[0.5,0.5]
B[0.5,0.5]
Deterministic policy
A2
B1"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#15,15,"The return : towards the goal
Definition
•Total return ofanepisode ending attime T:thevalue ofthe  
random variable Gt:=Rt+1+Rt+2+···+RTfortheepisode
•If the MDP is continuing, we need a discount factor :
Why?
•Transforming theterminal state inabsorbing with reward 0,we  
can use a unified notation for episodic and continuing MDP:
•In episodic tasks we can use γ = 1, in continuing tasks we  
must use γ <1!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#
!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#16,16,"The return : towards the goal
Why the discount
•The discount factor measures how much do we care about 
rewards far in thefuture
•A reward r after k + 1 time -steps is worth “only” γkr : wesay
myopic evaluation if γ ∼0, far-sighted evaluation if γ ∼1
•Convenience: avoids infinite returns in cyclic MDP
•We shouldn’t trust our model too much: uncertainty about  
the future may not be fully represented
•If the reward is financial, immediate rewards may earn more  
interest than delayed rewards
•Animal and human behaviour shows preference for immediate  
reward"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#17,17,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#18,18,"How much are states and actions worth?
Remark
The total return Gt at time t is a random variable:
Thus, it makes sense to compute its expected value.
Definition :state -value function
The state -value function vπ(s)foraMDP isthe return wecan
expect toaccumulate starting from state s,following thepolicy π:
vπ(s):=""π[Gt|St=s]
Exercise
Is the above definition/notation correct?!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#19,19,"How much are states and actions worth?
Total return
State -value function
vπ(s)=""π[Gt|St=s]
Definition: action -value function
The action -value function qπ (s,a) for a MDP is the return we can 
expect to accumulate starting from a state s, choosing action a, 
and then following the policy π:
qπ(s,a):=Eπ[Gt|St=s,At=a]!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#2,2,"Basic block: state , action , model ,reward
u
v
wa
r = +3, p =0.7
r=−1,p=0.3"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#20,20,"Example
Exercise
Compute qπ(A,1),qπ(A,2),qπ(B,1) and qπ(B,2) forthe uniform policy π."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#3,3,"Markov Decision Process: MDP
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
Distribution model
The probability distribution p is called distribution model , or  
simply model, of the MDP
Focus on finite MDP
From now on, assume that S, Aand Rarefinite"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#4,4,"MDP: meaning of the model
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
From distribution model to random variables St andRt
The probability distribution p of the MDP gives the next state and  
reward:
Pr(St=s',Rt=r|St−1=s,At−1=a):=p(s',r|s,a)"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#5,5,"MDP: meaning of the model
Exercises
•Explain what St,At and Rtare
•Given p, give a formula for Pr(St = s'|St−1 = s, At−1 = a)
•Given p, give a formula for ""[Rt|St−1 = s, At−1 =a]
•Given p, give a formula for ""[Rt|St−1 = s, At−1 = a,St = s']"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#6,6,"The M in MDP: Markov property
Tabular representation: transitions
An action a ∈Agives a transition probability from a state s toa
state s' :
Thus, we have a transition matrix Pa for each action a, and a  
corresponding underlying Markov stochastic process.
Tabular representation: rewards
An action a ∈A gives an average reward for any state s:
Thus, we have an average reward vector Ra for any action a.!!!!""≔#$#|$,'==!)*$=$#|*$%&=$,+$%&='
,!""=-,$|*$%&=$,+$%&='"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#7,7,"Example
u
1
2v
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#8,8,"Example
u1
2v1
0.8,+10 0.2,+3
0.1,+2 0.9,−30.1,+39
0.9,+42
0.9,+30.1,−2
2
= distribution model"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#9,9,"Episodic MDP
•If there is a special terminal  
state reachable from every  
state, the MDP is episodic
•Otherwise, the MDP is
continuing
•Episode : any sample
S0,A0,R1,S1,...terminating  
in the final state
Exercise
•Write an episode, and compute its probability 
of  happening. Hint: tricky question."
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 16)
1"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#1,1,"Sommario
Richiami RL e Q-learning 
Esempio taxi  
Ambiente OpenAI Gym 
Approccio non RL 
Approccio Q-Learning 
Approccio Epsilon-Greedy Q-Learning 
Valutazione e iperparametri"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#10,10,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
https://www.gymlibrary.ml  
La libreria include già l'ambiente Taxi già costruito. 
!
pip install cmake 
 'gym[atari]'
  scipy
import
 gym
# carichiamo l'environment taxi
env = gym.make(
 ""Taxi-v3""
 ).env
env.render()
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | 
: |
|
Y
| : |B: |
+---------+
11"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#11,11,"OpenAI Gym
...
env.reset() 
 # reset environment to a new, random state
env.render()
print
(
""Action Space {}""
 .
format
(env.action_space))
print
(
""State Space {}""
 .
format
(env.observation_space))
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : 
: : |
| | : | : |
|Y| : |
 B
: |
+---------+
>> Action Space Discrete(6)
>> State Space Discrete(500)
...
12"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#12,12,"OpenAI Gym
Le azioni sono codiﬁcate con interi:  
0 = south, 1 = north, 2 = east, 3 = west, 4 = pickup, 5 = dropoff 
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : 
| : |
|Y| : |
 B
: |
+---------+
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | : |
|Y| : 
|
B
: |
+---------+
13"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#13,13,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
# parametri (taxi row, taxi column, passenger index, destination index) 
state = env.encode(
 3
, 
1
, 
2
, 
0
)
print
(
""State:""
 , state)
env.s = state
env.render()
>> State: 328
+---------+
|
R
: | : :G|
| : | : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
14"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#14,14,"OpenAI Gym
Possiamo rappresentare un certo stato dell'environment esplicitamente. 
Allo stato sarà associato un id numerico (328). 
state 
=
 env.
encode
(
3
, 
1
, 
2
, 
0
)  
# (taxi row, taxi column, passenger index, destination index)
print
(
""State:""
 , state)
env.
s 
=
 state
env.
render
()
State: 328
+---------+
|
R
: | : :G|
| : : : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
15"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#15,15,"OpenAI Gym
La reward table rappresenta coppie stati x azioni. 
Ad esempio, per lo stato 328 otteniamo il seguente dizionario: 
env.P[
328
]
>>
{0: [(1.0, 428, -1, False)],
 1: [(1.0, 228, -1, False)],
 2: [(1.0, 348, -1, False)],
 3: [(1.0, 328, -1, False)],
 4: [(1.0, 328, -10, False)],
 5: [(1.0, 328, -10, False)]}
Dove il dizionario ha la struttura:  
{action: [(probability 
 sempre_1
 , next-state, reward, done)]}.
16"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#16,16,"Esercizio Taxi: senza RL
Supponi che l'agente abbia accesso unicamente la 
 reward table
  P per 
decidere quale azioni compiere. Perciò non apprende dall'esperienza 
acquista nel passato. 
Crea un loop che prosegua ﬁnché il cliente non sia arrivato a destinazione. 
Suggerimento: la funzione 
 env.action_space
 .
sample
 ()
 restituisce una 
azione in modo casuale.
17"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#17,17,"Esercizio Taxi: senza RL
env.
s 
= 
328  
# stato iniziale
epochs 
= 
0
penalties, reward 
 = 
0
, 
0
frames 
=
 [] 
# per animazione
done 
= 
False
while 
not
 done:
    action 
 =
 env.
action_space
 .
sample
()
    state, reward, done, info 
 =
 env.
step
(action)
    
if
 reward 
 == 
-
10
:
        penalties 
 += 
1
    
    frames.
 append
({
        
 'frame'
: env.
render
(mode
=
'ansi'
),
        
 'state'
: state,
        
 'action'
 : action,
        
 'reward'
 : reward
        }
    )
    epochs 
 += 
1
    
print
(
""Timesteps taken: {}""
 .
format
(epochs))
print
(
""Penalties incurred: {}""
 .
format
(penalties))
18"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#18,18,"Esercizio Taxi: senza RL
Per l'animazione: 
from
 IPython.
 display 
import
 clear_output
from
 time 
import
 sleep
def
 print_frames(frames):
    
for
 i, frame 
 in 
enumerate
 (frames):
        clear_output(wait
 =
True
)
        
 print
(frame[
'frame'
].
getvalue
 ())
        
 print
(
f""Timestep: 
 {i 
+ 
1
}
""
)
        
 print
(
f""State: 
 {frame[
'state'
]}
""
)
        
 print
(
f""Action: 
 {frame[
'action'
 ]}
""
)
        
 print
(
f""Reward: 
 {frame[
'reward'
 ]}
""
)
        sleep(
 .1
)
        
print_frames(frames)
L'algoritmo può impiegare molti step (oltre 1000) incorrendo in molte 
penalty (oltre 300).
19"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#19,19,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
20"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#2,2,"Richiami: Reinforcement Learning
Nell'ambito del Reinforcement Learning (RL), la 
 policy
  è la strategia per 
scegliere una azione nello stato corrente che determini la massima 
ricompensa (
 reward)
 . 
Il 
Q-learning
  è un algoritmo che mira a determinare col tempo la migliore 
azione (
 best action
 ), dato lo stato corrente (
 current state), 
 in base alla stima 
di 
reward
  attesa. 
Misura la bontà di una combinazione stato-azione in termini di 
 reward
 . 
Impiega una 
 Q-table
  aggiornata dopo ogni episodio, dove la riga 
corrisponde allo stato e la colonna all'azione. Il Q-value dentro la tabella 
indicano quanto una azione è stata buona (alto reward) in passato. 
È un algoritmo model-free, poiché l'agente non conosce il valore di una 
azione prima di effettuarla.  
Non segue un approccio greedy poiché scegliere sempre l'azione con 
reward immediato massimo potrebbe determinare sequenze di azioni non 
ottime.
3"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#20,20,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
%%time   # stampa il tempo trascorso al termine dell'esecuzione
import
 numpy 
as
 np
import
 random
from
 IPython.display 
 import
 clear_output
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
# per il report
all_epochs = []
all_penalties = []
q_table = np.zeros([env.observation_space.n, env.action_space.n])
...
21"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#21,21,"Esercizio: Q-learning in Python
...
for
 i 
in 
range
(
1
, 
100001
):
    state = env.reset()
    epochs, penalties, reward, = 
 0
, 
0
, 
0
    done = 
 False
    
    
while 
not
 done:
        action = np.argmax(q_table[state])
        next_state, reward, done, info = env.step(action) 
        
        old_value = q_table[state, action]
        next_max = np.
 max
(q_table[next_state])
        
 # eq Bellman 
        new_value = (
 1
 - alpha) * old_value + alpha * 
                    (reward + gamma * next_max)
        q_table[state, action] = new_value
...
22"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#22,22,"Esercizio: Q-learning in Python
...
        
 if
 reward == 
 -10
:
            penalties += 
 1
        state = next_state
        epochs += 
 1
        
    
if
 i % 
100
 == 
0
:
        clear_output(wait=
 True
)
        
 print
(
f
""Episode: 
 {i}
""
)
print
(
""Training finished.\n""
 )
>> Episode: 100000
>> Training finished.
>> CPU times: user 1min 25s, sys: 15 s, total: 1min 40s
>> Wall time: 1min 29s
q_table[
 328
] # l'azione migliore è north -2.27
>> array([-2.31436727, -2.27325184, -2.31164458, -2.3090025 , 
          -2.8816    , -2.8816    ])
23"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#23,23,"Esercizio: Q-learning in Python
Esercizio
 : valuta nuovamente l'algoritmo con le best action ricavate dalla 
Q-table. 
24"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#24,24,"Esercizio: Q-learning in Python
Valutazione dell'algoritmo con le best action ricavate dalla Q-table: 
total_epochs, total_penalties 
 = 
0
, 
0
episodes 
 = 
100
for
 _ 
in 
range
(episodes):
    state 
 =
 env.
reset
()
    epochs, penalties, reward 
 = 
0
, 
0
, 
0
    
    done 
 = 
False
    
while 
not
 done:
        
 action 
=
 np.
argmax
(q_table[state])
        state, reward, done, info 
 =
 env.
step
(action)
        
 if
 reward 
 == 
-
10
:
            penalties 
 += 
1
        epochs 
 += 
1
    total_penalties 
 +=
 penalties
    total_epochs 
 +=
 epochs
print
(
f""Results after 
 {episodes}
  episodes:""
 )
print
(
f""Average timesteps per episode: 
 {total_epochs  
/ 
episodes}
 ""
)
print
(
f""Average penalties per episode: 
 {total_penalties  
/ 
episodes}
 ""
)
>> Results after 100 episodes:
>> Average timesteps per episode: 13.01     
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
25"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#25,25,"Epsilon-Greedy Q-learning
Con l'approccio Epsilon-greedy Q-learning introduciamo il bilanciamento 
tra 
exploration
  e 
exploitation
 .  
Nei modelli model-free è fondamentale esplorare l'ambiente per ottenere 
informazioni su cui basare le successive decisioni informate. 
Nella versione Espilon-greedy, con probabilità epsilon l'agente sceglie una 
azione in modo casuale (esplorazione) e segue l'azioni valutata migliore 
nell'altro caso (1-epsilon).  
Esercizio
 : modiﬁca il codice introducendo questa versione.
26
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#26,26,"Epsilon-Greedy Q-learning
Esercizio
 : modiﬁca il codice introducendo questa versione. 
... 
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
epsilon = 
 0.1
...
while 
not
 done:
        
 if
 random.uniform(
 0
, 
1
) < epsilon:
            action = env.action_space.sample() 
 # Explore action space
        
 else
:
            action = np.argmax(q_table[state]) 
 # Exploit learned values
...
>> Results after 100 episodes:
>> Average timesteps per episode: 12.81     <-- invece di 13.01 
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
27"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#27,27,"Valutazione approccio RL
Alcune metriche da considerare nella valutazione sono: 
Numero medio di 
 penalità
  per episodio (ideale --> 0) 
Numero medio di 
 timesteps
  per percorso  
Valore medio di 
 reward
  per mossa
28
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#28,28,"Iperparametri
Alpha
 : da decrementare con l'incremento dell'esperienza acquisita 
Gamma
 : se ci avviciniamo all'obiettivo dobbiamo ridurre l'importanza 
della reward a lungo termine 
Epsilon
 : con l'accumularsi dei tentativi, epsilon deve ridursi. 
Esercizio: applica un approccio 
 grid search
  per ricavare una 
approssimazione degli iperparametri nello scenario del taxi che guida da 
solo.
29"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#29,29,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
30"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#3,3,"Richiami: Reinforcement Learning
Step #1: inizializzo la Q-table con valori pari a 0, ogni azioni e 
equiprobabile. 
Step #2: scegli l'azione in modo random, o sfrutta l'eventuale informazione 
che hai al principio 
Step #3: esegui l'azioni e colleziona il reward 
Step #4: aggiorna la Q-table di conseguenza 
4
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#4,4,"Richiami: Reinforcement Learning
L'equazione di 
 Bellman
  aggiorna i Q-values determinando il valore 
massimo di 
 reward
  atteso per ogni stato nella Q-table.  
Il primo termine 
 Q()
 indica il valore dell'azione corrente nello stato 
corrente. Il secondo combina il reward corrente e il valore discount dello 
stato futuro caratterizzato da reward massima.  
Il 
discount factor lambda
  [0,1] permette di ridurre il reward col tempo e 
indica quanta importanza assegnamo ai futuri reward: valori vicini allo 0 
indicano che l'agente si limita a valutare i reward immediati, vicini al 1 
permettono di valutare l'effetto a lungo termine dei reward. 
Il valore 
 alpha
  (learning rate (0,1]) determina l'importanza che assegniamo 
ai valori futuri rispetto a quelli attuali.
5
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#5,5,"Esempio: taxi che guida da solo
Deﬁniamo un ambiente (environment) sempliﬁcato dove un taxi deve 
prendere un cliente in una certa locazione e lasciarlo in un'altra. 
Vogliamo altresì: 
Lasciare il cliente nel luogo giusto 
Minimizzare il tempo per il trasporto 
Seguire le regole della strada 
Dobbiamo deﬁnire: rewards, states, actions. 
Quali puoi ipotizzare?
6"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#6,6,"Taxi che guida da solo: reward
Per i reward possiamo ipotizzare: 
Alto reward se il cliente viene lasciato correttamente. 
Penalizzazione se il cliente viene lasciato nella location sbagliata. 
Per ogni istante di tempo trascorso, una piccola penalità.
7"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#7,7,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Quanti sono il numero dei possibili stati?
8
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#8,8,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Possibili stati: 5 x 5 x 5 x 4 = 500
9
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#9,9,"Taxi che guida da solo: action space
L'agente può in ogni stato fare una delle seguenti azioni: 
muoversi a nord 
muoversi a su 
muoversi a est 
muoversi a ovest 
prendere il cliente 
lasciare il cliente 
Se l'agente non può fare una certa azione in uno stato (es. presenza di un 
muro) possiamo assegnare una penalità di -1.
10"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 17)
1"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#1,1,"Sommario
OpenAI GYM: Ambienti  
Deep Q-learning 
Libreria Baseline3"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#10,10,"OpenAI GYM: Environments
..
env = gym.make(
 ""Qbert-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
11
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#11,11,"OpenAI GYM: Environments
12
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#12,12,"Deep Q-learning
Per ambienti complessi (es. 10K stati e 1K azioni), la Q-table associata ad 
ogni observation può risultare complessa (10M di celle). La stima di un 
certo valore a partire da quelli esplorati in passato richiede: 
molta memoria per la Q-table 
tempo necessario per esplorare tutti gli stati e ricavare i valori 
Nel Deep Q-learning usiamo una rete neurale per stimare i Q-value, dove 
in output abbiamo il valore stimato per ogni azione.
13
Q learning Deep Q learning"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#13,13,"Deep Q-learning: Temporal Difference
La rete neurale ha bisogno di un valore di loss. 
Deﬁniamo la 
 Temporal Difference:   
Q(s,a)
  è il Q-value per una certa azione a. Dopo aver eseguito l'azione avremo 
un reward R(s,a). 
 Q
t-1
(s,a)
 è il Q-value precedente . 
Idealmente le due parti devono coincidere, essendo la prima impiegata per 
ricavare la seconda, ma la casualità dell'ambiente e il tempo di apprendimento 
creano discostamenti. 
Il valore del loss è determinato dal discostamento (
 Temporal Difference target)  
dal target: Q-value - Q* 
Impiegando il learning rate alpha, usiamo la TD per ricavare il nuovo Q-value.
14
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#14,14,"Deep Q-learning
Nel Deep Q-learning l'azione da eseguire è determinata dal valore 
massimo in output dalla rete (non esiste la Q-table tradizionale). Ogni 
nodo di output è una azione possibile. 
Otteniamo un problema di regressione, senza però conoscere il valore del 
target
  (nell'equazione in verde) non essendoci Q-table. 
La nuova eq per il Q-learning diverrà: 
il brackpropagation tenderà a convergere i Q-value e i reward. 
15
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#15,15,"Deep Q-learning: Neural Fitted Q Iteration 
La rete ci restituisce i Q-value target per ogni azione.  
La loss sarà così deﬁnita: 
Nota: nel Q-learning tradizionale, il Q-value viene aggiornato ad ogni 
transizione di stato. Nel Deep Q-learning il processo è più complesso...
16
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#16,16,"Deep Q-learning: Neural Fitted Q Iteration 
La rete deve valutare sia il valore 
 predetto
  sia il 
 target
 . Per tale motivo se ne 
usano 2 con stessa architettura ma pesi distinti. 
Una rete per i valori 
 target
  con i parametri ""ﬁssi"". Ad ogni C iterazioni (es. 
100) i parametri della 
 prediction
  network (aggiornata spesso, es. ogni 4 
steps) saranno copiati nella 
 target
  network. Questo rende il training più 
stabile poiché mantiene la funzione target stabile. Approccio ""
 Neural Fitted 
Q Iteration (NFQ)
 "" 
17
La target nework stima il Temporal difference target"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#17,17,"Experience replay
Data la numerosità degli stati possibili, conviene salvarli per poi ""rigiocarci"" 
in seguito. È una 
 off-line policy
 , cioè si sfrutta l'esperienza acquisita nelle 
azioni fatte nel passato per aggiornare i parametri attuali. 
Dare in input lunghe sequenze di stati correlati (es. foto di percorsi 
autostradali rettilinei) può creare bias nella rete e non permettere di 
adattarsi in altre situazione. 
A differenza del Q-learning, durante l'esecuzione i dati [state, action, 
reward, next_state] sono salvati in un buffer chiamato 
 experience replay
 . 
Supponendo che l'ambiente sia un gioco, durante il training possiamo 
campionare periodicamente (es. ogni 4 step) in modo casuale 64 frames 
(batch) dei 100K possibili in modo che abbiano scarsa correlazione tra 
loro. Questo permette di non introdurre bias dovuti alla particolare subset 
di istanze considerate.
18"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#18,18,"Deep Q-learning: step principali
Ricava i Q-values dalla rete per ogni azione dando in input lo stato 
corrente (es. screenshot). 
Seleziona una azione con 
 epsilon-greedy policy
 , cioè random con 
probabilità 
 epsilon
 , altrimenti l'azione con Q-value massimo. 
Valuta l'azione che genera il nuovo stato 
 s'
, e ricava il reward 
corrispondente. Lo stato 
 s'
 corrisponde allo screen successivo. La 
transizione 
 <s,a,r,s’>
  è salvata nel replay buffer. 
Campiona casualmente batch di transizioni dal replay buffer e ricava la loss 
corrispondente. 
Esegui il 
 gradient descent
  con la differenza tra 
 target Q
  e 
predicted Q 
impiegando la rete e i parametri attuali minimizzando la loss. 
Ogni C iterazioni trasferisci i parametri della rete alla rete target. 
Ripeti il procedimento M episodi.
19"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#19,19,"Deep Q-learning in Python: CartPole
# codice tratto da 
 https://github.com/mswang12/minDQN/blob/main/minDQN.py
import
 gym
import
 tensorflow 
 as
 tf
import
 numpy 
as
 np
from
 tensorflow 
 import
 keras
from
 collections 
 import
 deque
import
 time
import
 random
RANDOM_SEED = 
 5
tf.random.set_seed(RANDOM_SEED)
env = gym.make(
 'CartPole-v1'
 )
env.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
print
(
""Action Space: {}""
 .
format
(env.action_space))
print
(
""State space: {}""
 .
format
(env.observation_space))
# An episode a full game
train_episodes = 
 300
test_episodes = 
 100
...
20"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#2,2,"OpenAI GYM: Environments
La classe Env implementa il simulatore dell'ambiente in cui l'agente si 
muove.  
Alcuni esempi di environment disponibili in Gym: 
import
 gym
env = gym.make(
 'MountainCar-v0'
 )
Esempio
 : nel MointainCar, un carrello deve incrementare l'inerzia per 
riuscire a passare la collina.
3
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#20,20,"Deep Q-learning in Python: CartPole
...
def 
agent
(
state_shape
 , 
action_shape
 ):
    # l'output è il Q-value stimato per ogni azione
    learning_rate = 
 0.001
    init = tf.keras.initializers.HeUniform()
    model = keras.Sequential()
    model.add(keras.layers.Dense(
 24
, input_shape=state_shape, activation=
 'relu'
, 
kernel_initializer=init))
    model.add(keras.layers.Dense(
 12
, activation=
 'relu'
, kernel_initializer=init))
    model.add(keras.layers.Dense(action_shape, activation=
 'linear'
 , 
kernel_initializer=init))
    model.
 compile
(loss=tf.keras.losses.Huber(), 
optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=[
 'accuracy'
 ])
    
return
 model
def 
get_qs
(
model
, 
state
, 
step
):
    
return
 model.predict(state.reshape([
 1
, state.shape[
 0
]]))[
0
]
...
21"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#21,21,"Deep Q-learning in Python: CartPole
...
def 
train
(
env
, 
replay_memory
 , 
model
, 
target_model
 , 
done
):
    learning_rate = 
 0.7 
# Learning rate
    discount_factor = 
 0.618
    MIN_REPLAY_SIZE = 
 1000
    
if 
len
(replay_memory) < MIN_REPLAY_SIZE:
        
 return
    batch_size = 
 64
 * 
2
    mini_batch = random.sample(replay_memory, batch_size)
    current_states = np.array([transition[
 0
] 
for
 transition 
 in
 mini_batch])
    current_qs_list = model.predict(current_states)
    new_current_states = np.array([transition[
 3
] 
for
 transition 
 in
 mini_batch])
    future_qs_list = target_model.predict(new_current_states)
    X = []
    Y = []
...
22"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#22,22,"Deep Q-learning in Python: CartPole
...
    
for
 index, (observation, action, reward, new_observation, done) 
 in 
                                       
 enumerate
 (mini_batch):
        
 if 
not
 done:
            max_future_q = reward + discount_factor * 
        np.
 max
(future_qs_list[index])
        
 else
:
            max_future_q = reward
        current_qs = current_qs_list[index]
        current_qs[action] = (
 1
 - learning_rate) * current_qs[action] + 
                 learning_rate * max_future_q
        X.append(observation)
        Y.append(current_qs)
    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=
 0
, 
        shuffle=
 True
)
 ...
23"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#23,23,"Deep Q-learning in Python: CartPole
...
def 
main
():
    epsilon = 
 1 
# inizializzato ad 1, cioè ogni azione è random
    max_epsilon = 
 1
    min_epsilon = 
 0.01 
# al valore minimo, 1% sarà ancora esplorazione
    decay = 
 0.01
    
# 1. Initializzazione Target e Main models
    
# Main Model (updated every 4 steps)
    model = agent(env.observation_space.shape, env.action_space.n)
    
# Target Model (updated every 100 steps)
    target_model = agent(env.observation_space.shape, env.action_space.n)
    target_model.set_weights(model.get_weights())
    replay_memory = deque(maxlen=
 50
_
000
)
    target_update_counter = 
 0
    
# X = states, y = actions
    X = []
    y = []
...
24"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#24,24,"Deep Q-learning in Python: CartPole
...
    steps_to_update_target_model = 
 0
    
for
 episode 
 in 
range
(train_episodes):
        total_training_rewards = 
 0
        observation = env.reset()
        done = 
 False
        
 while 
not
 done:
            steps_to_update_target_model += 
 1
            
 if True:            # Su Colab può dare problemi
            
    env.render()
            random_number = np.random.rand()
            
 # 2. Esplora con Epsilon Greedy Exploration Strategy
            
 if
 random_number <= epsilon:
                
 # Explore
                action = env.action_space.sample()
            
 else
:
                
 # Exploit best known action
                
 # model dims are (batch, env.observation_space.n)
                encoded = observation
                encoded_reshaped = encoded.reshape([
 1
, encoded.shape[
 0
]])
                predicted = model.predict(encoded_reshaped).flatten()
                action = np.argmax(predicted)
            new_observation, reward, done, info = env.step(action)
            replay_memory.append([observation, action, reward, new_observation, done])
...
25"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#25,25,"Deep Q-learning in Python: CartPole
...
           
 # 3. Aggiorna la rete con la Bellman Equation
            
 if
 steps_to_update_target_model % 
 4
 == 
0 
or
 done:
                train(env, replay_memory, model, target_model, done)
            observation = new_observation
            total_training_rewards += reward
            
 if
 done:
                
 print
(
'Total training rewards: {} after n steps = {} with final 
                      reward = {}'
 .
format
(total_training_rewards, episode, reward))
                total_training_rewards += 
 1
                
 if
 steps_to_update_target_model >= 
 100
:
                    
 print
(
'Copying main network weights to the target network 
                           weights'
 )
                    target_model.set_weights(model.get_weights())
                    steps_to_update_target_model = 
 0
                
 break
        epsilon = min_epsilon+(max_epsilon - min_epsilon)*np.exp(-decay * episode)
    env.close()
if
 __name__ == 
 '__main__'
 :
    main()
26"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#26,26,"Action Space: Discrete(2)
State space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)
Total training rewards: 19.0 after n steps = 0 with final reward = 1.0
...
Copying main network weights to the target network weights
Total training rewards: 184.0 after n steps = 291 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 152.0 after n steps = 292 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 47.0 after n steps = 293 with final reward = 1.0
Total training rewards: 20.0 after n steps = 294 with final reward = 1.0
Total training rewards: 121.0 after n steps = 295 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 10.0 after n steps = 296 with final reward = 1.0
Total training rewards: 124.0 after n steps = 297 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 272.0 after n steps = 298 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 41.0 after n steps = 299 with final reward = 1.0
Deep Q-learning in Python: CartPole
27"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#27,27,"Deep Q-learning: Stable Baseline3
Stable Baselines3 (SB3) implementa algoritmi di RL in PyTorch.  
Possono essere impiegati in OpenAI GYM. 
Github repository: 
 https://github.com/DLR-RM/stable-baselines3  
La classe DQN implementa l'approccio descritto in precedenza 
https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html   
https://stable-baselines3.readthedocs.io/en/master/guide/examples.html  
28"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#28,28,"Deep Q-learning: Stable Baseline3
Algoritmi implementati:
29
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#29,29,"Deep Q-learning: CartPole in GYM
# Anaconda: conda install -c conda-forge stable-baselines3 
!
pip install stable-baselines3[extra]
import
 gym
from
 stable_baselines3 
 import
 DQN
env = gym.make(
 ""CartPole-v0""
 )
model = DQN(
 ""MlpPolicy""
 , env, verbose=
 1
)
model.learn(total_timesteps=
 10000
, log_interval=
 4
)
model.save(
 ""dqn_cartpole""
 )
del
 model 
# remove to demonstrate saving and loading
model = DQN.load(
 ""dqn_cartpole""
 )
obs = env.reset()
while 
True
:
    action, _states = model.predict(obs, deterministic=
 True
)
    obs, reward, done, info = env.step(action)
    env.render()                 
 # Su colab può dare problemi
    
if
 done:
      obs = env.reset()
30"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#3,3,"OpenAI GYM: Environments
La variabile 
 observation_space
  deﬁnisce la struttura e gli stati permessi 
dell'ambiente.  
Per esempio, posizione  rispetto all'orgine e velocità del carrello 
CartPole, rappresentati come vettore numerico. 
Ma in casi più complessi è possibile fare un rendering dello stato (es. 
uno screenshot di un arcade) è impiegare una matrice di pixel come 
stato. 
La variabile 
 action_space
  consiste nelle azioni permesse nell'ambiente. 
Gym fornisce diverse strutture per rappresentare osservazioni e stati (es. 
discrete action space, continuous action space, ecc). 
4"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#30,30,"Deep Q-learning: CartPole in GYM
L'output dipende dall'approccio RL scelto, es. per agenti PPO - Proximal 
Policy Optimization algorithm che combina il A2C multiple workers, e 
TRPO:
31
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#31,31,"Deep Q-learning: CartPole in GYM
32
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#32,32,"Deep Q-learning: CartPole in GYM
33
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#33,33,"Deep Q-learning: CartPole in GYM
34
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#34,34,"Esercitazione
Deﬁnisci una misura di prestazioni per confrontare diverse approcci RL 
Impiega la classe Deep Q Network (DQN) 
Sperimenta diversi iperparametri e valuta le differenze: 
learning_rate 
exploration_initial_eps  e  exploration_ﬁnal_eps 
buffer_size 
batch_size 
gamma 
train_freq 
Usa altri ambienti, es: Atlantis-v0, MountainCar-v0, o ambienti Atari.
35"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#35,35,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
36"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#4,4,"OpenAI GYM
Come ispezionare l'ambiente. 
import
 gym
def 
query_environment
 (
name
):
    env = gym.make(name)
    spec = gym.spec(name)
    
print
(
f
""Action Space: 
 {env.action_space}
 ""
)
    
print
(
f
""Observation Space: 
 {env.observation_space}
 ""
)
    
print
(
f
""Max Episode Steps: 
 {spec.max_episode_steps}
 ""
)
    
print
(
f
""Nondeterministic: 
 {spec.nondeterministic}
 ""
)
    
print
(
f
""Reward Range: 
 {env.reward_range}
 ""
)
    
print
(
f
""Reward Threshold: 
 {spec.reward_threshold}
 ""
)
query_environment(
 ""MountainCar-v0""
 )
3 azioni: Accelerate forward, decelerate, backward
>> Action Space: Discrete(3)
2 ﬂoat: velocità e posizione; (2,) indica la struttura del dato
>> Observation Space: 
                 Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)
200 step disponibili
>> Max Episode Steps: 200
>> Nondeterministic: False
Per il reward occorre ispezionare il codice (i.e., nessun reward tranne quando il carrello riesce ad uscire)
>> Reward Range: (-inf, inf)
>> Reward Threshold: -110.0
5"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#5,5,"OpenAI GYM
query_environment(
 ""CartPole-v1""
 )
2 valori: spingi a sinistra, spingi a destra
>> Action Space: Discrete(2)
4 valori: Cart Position, Cart Velocity, Pole Angle, Pole Velocity At Tip
>> Observation Space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), 
float32)
>> Max Episode Steps: 500
>> Nondeterministic: False
reward +1 per ogni step, e termino quando il palo cade, o se mi sposto di >2.4 unità dal centro
>> Reward Range: (-inf, inf)
>> Reward Threshold: 475.0
query_environment(
 ""MountainCarContinuous-v0""
 )
1 valore: quanta forza imprimere (a sinistra o destra)
>> Action Space: Box(-1.0, 1.0, (1,), float32)
>> Observation Space: Box(-1.2000000476837158, 0.6000000238418579, (2,), 
float32)
>> Max Episode Steps: 999
>> Nondeterministic: False
>> Reward Range: (-inf, inf)
>> Reward Threshold: 90.0
6"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#6,6,"OpenAI GYM
Nell'ambiente Atari breakout, l'observation space può corrispondere alle 
dimensioni dell screen (210x160) o alla RAM dell'elaboratore (128 bytes). 
query_environment(
 ""Breakout-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (210, 160, 3), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
query_environment(
 ""Breakout-ram-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (128,), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
7
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#7,7,"OpenAI GYM: Environments
Come applicare un'azione sull'ambiente. 
# reset 
obs = env.reset()
print
(
""The initial observation is {}""
 .
format
(obs))
random_action = env.action_space.sample()
# Applichiamo l'azione all'ambiente
new_obs, reward, done, info = env.step(random_action)
print
(
""The new observation is {}""
 .
format
(new_obs))
>> OUTPUT:
>> 
The initial observation 
 is
 [
-0.48235664   
0
.]
>> 
The new observation 
 is
 [
-0.48366517  
-0.00130853
 ]
8"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#8,8,"OpenAI GYM: Environments
Per visualizzare lo stato a video su Colab inserire il seguente codice: 
# vedi 
https://github.com/ryanrudes/colabgymrender  
!
pip install gym pyvirtualdisplay > /dev/null 
 2
>&
1
!
apt-get install -y xvfb python-opengl ffmpeg > /dev/null 
 2
>&
1
!
pip install colabgymrender==
 1.0.2
import
 gym
from
 colabgymrender.recorder 
 import
 Recorder
env = gym.make(
 ""MountainCar-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
observation = env.reset()
terminal = 
 False
while 
not
 terminal:
# Azione random
  action = env.action_space.sample()
  observation, reward, terminal, info = env.step(action)
env.play()
9
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#9,9,"OpenAI GYM: Environments
...
env = gym.make(
 ""Atlantis-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
10
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Introduzione al Deep Learning  
(Ex 18/19)
1"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#1,1,"Sommario
Introduzione 
Il concetto di Deep Learning 
Esempi di applicazioni 
Translational simmetry 
Convolutional Neural network 
•
Convolutional layer 
•
Local receptive ﬁeld 
•
Stride e Padding 
•
Filters e Feature Maps 
•
Pooling Layer 
Architettura LeNet-5 
Architettura AlexNet 
Architettura GoogleNet e Inception Module 
Architettura Residual Network (ResNet)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#10,10,"Esercizio
Realizzo un classiﬁcatore binario che mi identiﬁca se in una 
porzione di immagine c’è un pedone. 
Scorro l’immagine per trovare una porzione con un pedone  
 
        
11
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#11,11,"Object recognition
Yolo https://pjreddie.com/darknet/yolov2/ 
https://www.youtube.com/watch?v=VOC3huqHrss 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#12,12,"Pose estimation
Zhe Cao , Tomas Simon, Shih-En Wei, Yaser Sheikh   
https://www.youtube.com/watch?v=pW6nZXeWlGM 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#13,13,"Object Tracking
 Beijing DeepGlint  https://www.youtube.com/watch?v=xhp47v5OBXQ  
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#14,14,"Activity Recognition
 MIT CS & AI Lab http://relation.csail.mit.edu
https://www.youtube.com/watch?v=JBwSk6nJOyM 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#15,15,"Tesla Self Driving Demo 2016
Tesla   https://www.youtube.com/watch?v=VG68SKoG7vE 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#16,16,"Introduzione
Alcune soﬁsticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come: 
•
Riconoscere un giocattolo in una immagine 
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speciﬁche.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture. 
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identiﬁcarlo. 
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
17"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#17,17,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive ﬁeld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale. 
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
conﬁgurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"". 
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi
 . 
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
18"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#18,18,"L'architettura della Visual cortex
19
Secondo te è una MLP?Ad ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#19,19,"L'architettura della Visual cortex
20
È simile a una MLP , 
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#2,2,"Deep Learning - Cos’è?
Invece di una singola rete con molti parametri da individuare 
tutti insieme, si suddividono le elaborazione in più moduli 
distinti a cascata. 
Sviluppato negli anni ’80 (Geoff Hinton, Yann Lecun, Yoshua 
Bengio, Jürgen Schmidhuber) ispirandosi ai risultati sulla 
cognizione umana. 
Ma al tempo non c’erano le infrastrutture hardware e software 
adatte (GPU-enabled). 
Utile in scenari con grosse moli di dati complessi. 
Uno degli obiettivi è ignorare la (noiosa) fase di deﬁnizione di 
feature ad-hoc per lo speciﬁco problema da esaminare e lasciare 
alle reti neurali identiﬁcare le features più adatte.
3"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#20,20,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
21"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#21,21,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra 
notevolmente le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
22"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#22,22,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra notevolmente 
le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare. 
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo task
 , es. 
riconoscere linee orizzontali. 
•
I neuroni specializzati sono attivati se il pattern da identiﬁcare è localizzato in 
una certa zona.  
•
Ma vorremmo poter identiﬁcare lo stesso pattern indipendentemente da dove 
compare. 
Con 
translational symmetry
  intendiamo che lo stesso output deve essere 
prodotto anche a seguito di operazioni di traslazione sulla istanza in input. 
23"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#23,23,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
3. Le reti 
 MLP 
non riescono a codiﬁcare esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identiﬁcano 
features analizzando piccole aree dell'immagine. 
•
I neuroni ""ad alto livello"" combinano tali features per identiﬁcare features 
spazialmente più estese.
24"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#24,24,"Esempi di 
 translational simmetry
25
Nel task a lato, per addestrare una MLP dovremmo avere 
un training set con: 
•stessa specie animale che compare in varie 
posizioni, angolazioni e dimensioni. 
•specie visualizzate parzialmente (es. sul bordo). 
•casi di overlap tra specie diverse di animali"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#25,25,"Ulteriore considerazione: 
 sparsity
26Per riconoscere certe caratteristiche speciﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata. Non c'è bisogno di considerare l'intera immagine iniziale. 
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#26,26,"Convolutional NN
Le architetture 
 Convolutional NN (CNN)
  consistono in varie tecniche 
ispirate al funzionalmente del cervello.  
Il blocco più importante è il 
 convolutional layer
  così costituito: 
•
I nodi nel primo layer 
 non sono connessi con tutti i pixel
  dell'immagine in 
input, ma 
 solo in una regione
  (es. un rettangolo). Tale regione è chiamata 
Local receptive ﬁeld (LRF)
 . 
•
Questo permette alla rete di 
 specializzarsi
  su caratteristiche a basso 
livello che saranno poi elaborate in caratteristiche a più alto livello nei 
successivi hidden layer. 
•
Una rete CNN è 
 gerarchica
 , con più convolutional layer nascosti che 
individuano via via caratteristiche più astratte.
27"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#27,27,"CNN - Convolutional layer e LRF
28
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input: 
immagine 25x25 pixel
in bianco e neroOutput dopo il primo  
layer convolutivo.local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato 
da una certa posizione del 
LRF che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#28,28,"CNN - Struttura gerarchica
29Input layer: 
È un layer costituito da unità 
a cui viene associato il valore 
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerDato una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota: Nelle tradizionali MLP, input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori, ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN tale ridimensionamento è controproducente poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell'input layer le features 
corrispondono ai singoli pixel"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#29,29,"CNN - LRF
30Output layer precedente•In un certo layer convoluzionale, un nodo con indice (i, j) prende in input gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF va dalla riga i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e f w corrispondono all'altezza e larghezza del LRF. 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni.forward propagation
Esempio con LRF 3x3 
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding 
(discusso più avanti)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#3,3,"Deep Learning - Cos’è? (2)
In estrema sintesi: 
Si compongono più strutture di reti neurali in cascata il cui 
scopo è analizzare l’input ed estrarre ad ogni passo un 
insieme di features (in automatico). 
L’output di una rete neurale è l’input della successiva. 
Tipicamente l’input iniziale è low-level (es. gruppi di pixel di 
una immagine) e ogni rete genera rappresentazioni più ad 
alto livello (es. contorno viso, bocca, bocca sorridente etc.). 
Le elaborazioni degli strati intermedi sono tipicamente 
unsupervised.
4"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#30,30,"CNN - Stride
31•La distanza s tra due LRF adiacenti è chiamata stride. 
•Finora abbiamo visto stride di 1 pixel, ma la LRF può scorrere di più pixel. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3 
Stride = 2"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#31,31,"CNN: Padding
32•Supponendo stride > 1, può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input. 
•Il padding aggiunge dimensioni ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding). Si hanno i seguenti vantaggi:
•Permettere alla LRF di scorrere per intero l'immagine in input senza ignorarne delle parti.
•Un LRF potrebbe ""imparare"" a riconosce una certa feature quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo, senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#32,32,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la ﬁnestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della ﬁnestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#33,33,"CNN: Riduzione dimensionalità e Stride
34Output layer precedente•La presenza di stride > 1 altera gli indici iniziali e ﬁnali che identiﬁcato il LRF associato ad 
un certo nodo. 
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista.
•Stride > 1 riducono la dimensione del layer convoluzionale a scapito della precisione.
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3 
Stride = 2"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#34,34,"CNN: Filters
35Filters•Supponiamo di poter rappresentare graﬁcamente i pesi associati a un certo nodo, usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters o convolution kernels  
(o kernels )
•Ad esempio, una LRF 7 7 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#35,35,"Esempi di ﬁltri e attivazioni (1)
36Esempio di input 
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo.
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#36,36,"Esempi di ﬁltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#37,37,"CNN: Feature Maps
38Filters•Le LRF scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione. Tale approccio prende il nome di shared weights. 
•L'insieme delle attivazioni ottenute con lo stesso ﬁltro viene chiamato feature map. Esse 
possono essere visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map dove le zone dell'input simili a una 
linea verticale sono più evidenziate (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate. Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#38,38,"CNN: Stacking feature maps
In 
ogni layer
  possiamo contemplare 
 più ﬁltri con le medesime dimensioni
 . 
Ogni ﬁltro produrrà una diversa feature map. Ogni layer sarà così costituito 
da una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i ﬁltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di: 
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP. 
•
Durante la backpropagation, adattare ogni ﬁltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso ﬁltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
39"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#39,39,"CNN: Feature Maps
40...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB.Possiamo deﬁnire un certo numero di ﬁltri (es. 12) per riconoscere diverse caratteristiche salienti dell'immagine iniziale. I ﬁltri analizzano contemporaneamente 3 canali RGB, perciò i ﬁltri saranno deﬁniti con matrici a 3 dimensioni. Un ﬁltro applicato all'immagine in input produce un singolo convolutional layer.I successivi layer convoluzionali analizzato le attivazioni di più ﬁltri contemporaneamente. I ﬁltri di questo layer riconosceranno caratteristiche più astratte.depth = 3 depth = 12 depth = 7"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#4,4,"Deep Learning - Principali vantaggi
Rispetto ad altri approcci: 
Si può sviluppare un unico framework computazionale che 
può essere implementato ed eseguito su varie piattaforme 
hardware e cloud. 
Il framework offre funzionalità valide per molte architetture di 
reti e tasks (es. natural language processing, computer vision, 
speech recognition, etc.) 
Si possono condividere e riutilizzare i parametri ottenuti 
durante l’apprendimento per uno speciﬁco task in altri 
contesti.
5"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#40,40,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori: 
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
4101234567891011121300 12345678910111213
senza padding ('VALID') con padding ('SAME')ignorati
stride=5padding P=+3"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#41,41,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di ﬁltri per layer (o 
 depth
 ) 
Dimensione del LRF 
Stride e padding 
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una conﬁgurazione 
verosimilmente già ottimizzata.
42"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#42,42,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con ﬁltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200 
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile. 
•
Con ﬂoat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
43"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#43,43,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti: 
•
Meno complessità computazione 
•
Meno risorse di memoria 
•
Meno parametri (e ridurre l'overﬁtting come effetto collaterale) 
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF. 
•
Occorre deﬁnire dimensione, stride e padding 
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
44"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#44,44,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁeld (
 pooling size
 ), il 
pooling stride
 , e tipo di aggregazione. 
•
Spesso pooling size e stride corrispondono. 
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identiﬁcata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche. 
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta. 
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel ﬁeld considerato. 
•
average pooling:
  considero il valor medio nel ﬁeld.
45"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#45,45,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max. 
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
46
A causa del padding VALID 
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  f po è il pooling size, s po il pooling stride,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#46,46,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri. 
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente: 
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#47,47,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classiﬁcazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden: 
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID 
•Numero ﬁltri (o depth) = 96 
•L’output per ogni ﬁltro avrà dimensione di lato (227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 =290.400 nodi. 
•L'attivazione di un nodo si ricava considerando 11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri. 
•Per la proprietà degli shared weights, nella CNN il numero di parametri sarà 11x11x3x96 + 96 = 34.944. × ×
×
×
feature mapscomputazione"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#48,48,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST. 
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identiﬁcate dalle CNN 
per fare classiﬁcazione per mezzo della MLP. 
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#49,49,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/ "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#5,5,"DeepMind e Atari Breakout
Google Deepminds https://deepmind.com 
https://www.youtube.com/watch?v=eG1Ed8PTJ18 "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#50,50,"Architettura LeNet-5
convolutional layer#1 conv. layer
feature maps:  
28x28, depth 6#3 conv. layer 
feature maps: 
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling layer
feature maps: 
14x14, depth 6#4 pooling layer
feature maps: 
5x5, depth 16
conv. layer#6 fully connected layer 
nodi 84#5 conv. layer 
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer 
nodi 10
La conﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#51,51,"LeNet-5 in Keras
Con Keras l'implementazione di LeNet-5 per il dataset MNIST è rapida poiché i 
layer di pooling e di convoluzione sono già fatti:  
model = keras.Sequential()
model.add(layers.Conv2D(filters=
 6
, kernel_size=(
 3
, 
3
), activation=
 'relu'
, 
                     input_shape=(
 32
,
32
,
1
)))
model.add(layers.AveragePooling2D())
model.add(layers.Conv2D(filters=
 16
, kernel_size=(
 3
, 
3
), activation=
 'relu'
))
model.add(layers.AveragePooling2D())
# cambio il formato da matrice a vettore
model.add(layers.Flatten())
# layer fully connected o denso
model.add(layers.Dense(units=
 120
, activation=
 'relu'
))
model.add(layers.Dense(units=
 84
, activation=
 'relu'
))
model.add(layers.Dense(units=
 10
, activation = 
 'softmax'
 ))"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#52,52,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
53"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#53,53,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 .
54"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#54,54,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
55"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#55,55,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
56"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#56,56,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32.
57"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#57,57,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32. 
5.
Distribuire la computazione
  su più elaboratori.
58"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#58,58,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%).  
E' molto simile a 
 LeNet-5
  ma con più profondità, con stacking dei pooling layer 
uno dopo l'altro (senza strato di pooling). 
•
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer. 
Impiega ReLI, SGD e 
momentum. 
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 gpu)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#59,59,"Architettura AlexNet (2)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signiﬁcativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#6,6,"Robot Learns to Flip Pancakes
Petar Kormushev (IIT): https://www.youtube.com/watch?v=W_gxLKSsSIE 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#60,60,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁltri negli strati iniziali. 
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#61,61,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identiﬁcate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei ﬁltri
 . Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo. 
•
Si impiegano ﬁltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function. 
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 ."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#62,62,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempliﬁcare i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali. 
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5. 
•
Sperimentalmente si nota come gli inception module sono più 
efﬁcienti se usati negli higher layers. 
Inception module
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#63,63,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri. 
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#64,64,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classiﬁcazione 
 per mezzo di una softmax. 
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer. 
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati. 
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più efﬁciente il training e migliorare l’accuracy.
auxiliary classiﬁerauxiliary classiﬁer"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#65,65,"GoogLeNet: esempio di ﬁltri
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#66,66,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers. 
Una rete con tale profondità non potrebbe essere addestrata a causa del 
vanishing gradient problem. 
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice propagare segnali 
 su varie parti della rete. 
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#67,67,"ResNet: Residual learning
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning
 . 
Dal punto di vista operativo, è sufﬁciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#68,68,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza. 
69
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#7,7,"Chess Game
Stati possibili: ~1047
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#8,8,"Driverless cars
Stati possibili: ?Microsoft AirSim simulator 
https://www.youtube.com/watch?v=fv-oFP AqSZ4 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#9,9,"Esercizio
Voglio sapere se c’è un pedone di fronte a me analizzando 
l’immagine di una camera dalla mia auto, come procedo? 
10
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Ridge Regression 
Cross Validation
Machine Learning "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#1,1,"Sommario
Overﬁtting nella polynomial  regression 
Sintomi dell’Overﬁtting 
Funzione di Costo nella Ridge Regression 
Minimizzazione della Funzione di Costo 
Forma Chiusa 
Gradient Descent 
K-fold Cross Validation
 
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#10,10,"Overﬁtting e #input
 
11
Anche il numero di input inﬂuenza l’overﬁtting: 
1 input (e.g., sq.ft)  → per evitare l’overﬁtting servono 
osservazioni che sono molto “dense” sull’asse delle ascisse. 
Servono in sostanza osservazioni rappresentative di tutte le 
coppie (x, y), cosa  difﬁcile da ottenere.  
d input (e.g., sq.ft, #bagni, #camere-letto, anno di costruzione, 
ecc.) → è ancora  più difﬁcile avere molte osservazioni 
rappresentative delle coppie (x, y) .
AreaPrezzoy
x"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#11,11,"Funzione di Costo 
nella Ridge Regression
 
12
L’idea alla base della Ridge Regression è quella di limitare 
il valore assoluto dei coefﬁcienti wi deﬁnendo come 
segue la funzione di costo totale (da minimizzare nella 
fase di training): 
costo_ridge  = misura del “ﬁt” + misura della grandezza dei coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la RSS. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#12,12,"Misura dei Coefﬁcienti  
di Regressione
 
13
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#13,13,"Funzione di Costo 
nella Ridge Regression
 
14
La Ridge Regression usa la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta il costo totale nella Ridge è 
dunque la seguente:    
dove il parametro λ (tuning parameter ) serve per 
bilanciare i due termini.                                              costo ridge(w)=R S S ( w)+ ·kwk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#14,14," 
15Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵ = 0 
Se 0 < λ < ∞: 
Funzione di Costo 
nella Ridge Regression
0kˆwk2
2kˆwLSk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#15,15,"Bias-Variance tradeoff
 
16
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., standard least squares ﬁt 
per polinomi di grado elevato) "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#16,16,"Esempio di polynomial ﬁt 
rivisitato
 
17
Rivediamo ora la demo relativa al polinomio di grado 16, 
applicando però l’approccio della Ridge Regression con 
diversi valori del parametro λ. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#17,17,"Polinomio di grado 16 
lambda = 1.00e-25
 
18
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#18,18,"Polinomio di grado 16 
lambda = 1.00e-10
 
19
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#19,19,"Polinomio di grado 16 
lambda = 1.00e-06
 
20
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#2,2,"Il problema dell’Overﬁtting 
nella polynomial regression
 
3
Ricordiamo il nostro modello nella polynomial  
regression:
A seconda del grado del polinomio possiamo avere 
diverse situazioni:
overﬁt
yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
y
Area xPrezzo
AreaPrezzoy
x"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#20,20,"Polinomio di grado 16 
lambda = 1.00e-03 
 
21
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#21,21,"Polinomio di grado 16 
lambda = 1.00e+02
 
22
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#22,22," 
23costo ridge(w)=R S S ( w)+ ·kwk2
2=(y  w)T(y  w)+ ·wTw
kwk2
2=w2
0+w2
1+w2
2+···+w2
D=wT·w
Gradiente della Funzione di Costo 
Per il calcolo del gradiente della funzione di costo, 
riscriviamo tale funzione in notazione matriciale:
poiché:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#23,23,"Gradiente della Funzione di Costo 
 
24rcosto ridge(w)= r[(y  w)T(y  w)+ ·wTw]=
=r[(y  w)T(y  w)] + ·r[wTw]=
= 2 T(y  w)+ ·2w
Il gradiente della funzione è il seguente:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#24,24,"Algoritmi per adattare il modello 
[caso della Ridge Regression]
Anche nel caso della Ridge Regression, una volta calcolato 
il gradiente della funzione 
 costo_ridge
  ci sono due possibili 
approcci per minimizzare la funzione di costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
25"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#25,25,"Forma Chiusa 
[caso della Ridge Regression] 
 
26Poniamo il gradiente uguale a zero:
rcosto ridge( w)= 2 T(y  w)+2 · w=0
 2 Ty+2 T ˆw+2 · ˆw=0
  Ty+ T ˆw+ Iˆ w =0
 T ˆw+ Iˆ w = Ty
( T + I)ˆw= Ty
( T + I) 1( T + I)ˆw=( T + I) 1 Ty
Iˆ w =( T + I) 1 Ty
ˆwridge=( T + I) 1 Tyda cui si ha:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#26,26,"Gradient Descent (1/4) 
[caso della Ridge Regression] 
 
27w(t+1) w(t) ↵·rcosto ridge(w(t))
w(t+1)
0 w(t)
0 ↵·@costo ridge(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@costo ridge(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j ↵·@costo ridge(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D ↵·@costo ridge(w(t))
@wD
I singoli pesi devono pertanto essere aggiornati come segue:
Dobbiamo aggiornare il vettore dei pesi in modo tale da 
spostarci nel verso opposto al gradiente:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#27,27,"Gradient Descent (2/4) 
[caso della Ridge Regression] 
 
28@costo ridge(w(t))
@wj=@RSS(w(t))
@wj+ ·@(w(t)T·w(t))
@wjcosto ridge(w)=R S S ( w)+ ·kwk2
2=R S S ( w)+ ·wTw
Per il calcolo delle derivate parziali precedenti, consideriamo 
di nuovo l’espressione della funzione costo_ridge:
La derivata parziale della funzione di costo rispetto al 
generico peso w j è dunque:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#28,28,"Gradient Descent (3/4) 
[caso della Ridge Regression] 
 
29@RSS(w(t))
@wj= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
@(w(t)T·w(t))
@wj=2 ·w(t)
j
Poiché:
abbiamo:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#29,29,"Gradient Descent (4/4) 
[caso della Ridge Regression] 
 
30
L’aggiornamento del generico peso w j:
diventa:
ossia:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#3,3,"Sintomi dell’Overﬁtting
 
4
Spesso, quando il fenomeno dell’overﬁtting si manifesta, 
accade che i valori assoluti dei parametri stimati ŵ 
assumono valori molto alti. 
Vediamo ora una semplice demo in cui si mostra questo 
fenomeno."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#30,30,"Algoritmo di Gradient Descent 
[caso della Ridge Regression] 
 
31w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
w(t+1)
j (1 2↵ )w(t)
j ↵⇤derivata parziale RSS[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#31,31,"Andamento Coefﬁcienti 
Ridge
 
32
λ "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#32,32," 
33
Selezione dei parametri  
via Cross Validation 
Un problema importante è quello relativo alla scelta del 
parametro λ. Lo affrontiamo per la Ridge, ma le 
considerazioni sono più generali. 
Come è stato detto in precedenza, per ogni valore di λ che 
vogliamo considerare possiamo addestrare il nostro modello 
sui dati di training, valutarlo sul validation set e scegliere il 
valore di λ che ottiene i migliori risultati (validation error più 
basso). 
Possiamo poi valutare le prestazioni del modello selezionato 
sul test set."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#33,33,"Tutto ciò è certamente possibile, a patto di avere un numero 
sufﬁciente di dati:
 
34
Training 
SetTest 
Set
Validation
 Set
ﬁt ŵλ 
test prestazioni di ŵλ  
per selezionare λ* 
valutare il  
true error di ŵλ*  
Selezione dei parametri  
via Cross Validation "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#34,34,"La domanda che dobbiamo porci è però la seguente: cosa 
accade se non abbiamo dati sufﬁcienti per dividerli nei tre 
sottoinsiemi necessari? 
 
35
Dati disponibili
Resto dei dati Test 
Set
Selezione dei parametri  
via Cross Validation 
Supponiamo dunque di trovarci in questa situazione, in cui i 
dati disponibili sono pochi:
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#35,35," 
36
Dopo aver scorporato il test set di dimensione adeguata, 
vediamo come poter gestire il resto dei dati da utilizzare  per 
il training e la validation.
Un uso ingenuo potrebbe essere il seguente:
Selezione dei parametri  
via Cross Validation 
Resto dei dati 
Training 
Set
Validation
 Set
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#36,36," 
37
Il metodo però non funzionerebbe perché, con pochi dati a 
disposizione, il validation set non sarebbe sufﬁcientemente 
ampio per consentire una valutazione adeguata.
Questo varrebbe per la suddivisione mostrata nella ﬁgura 
precedente, ma anche per altre suddivisioni, come ad es.:
Selezione dei parametri  
via Cross Validation 
Validation
 Set
Validation
 Set"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#37,37," 
38
Ossia vale per qualsiasi scelta di un sottoinsieme dei dati 
disponibili, da utilizzare come validation set.
Quale di tali sottoinsiemi possiamo utilizzare? Sappiamo che 
ciascuno di essi è troppo piccolo per le valutazioni di nostro 
interesse.
Selezione dei parametri  
via Cross Validation 
La risposta è la seguente: li utilizziamo tutti, effettuando una 
“averge performance” su tutte le scelte. 
In tal modo (cross validation) si evita la “sensitivity” dei 
risultati in base al particolare sottoinsieme scelto, causata 
delle poche osservazioni che contiene."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#38,38," 
39
k-fold Cross Validation 
Consideriamo dunque il resto dei dati (N dati), ottenuto 
scorporando un training set di dimensione adeguata dai dati 
disponibili.
Suddividiamo tali N dati in K blocchi, assegnando casualmente  
i dati a ciascuno dei blocchi:
Resto dei dati 
N/K N/K N/K ………….1 2 K ………."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#39,39," 
40
k-fold Cross Validation 
Per ciascuno dei K blocchi, operiamo considerandolo il 
Validation Set, utilizzando quindi i dati rimanenti come 
Training Set.
In sostanza, dopo aver ﬁssato un valore per λ, operiamo 
come segue per il primo blocco (ricordiamoci che in verde 
abbiamo il Training Set):
Validation
 Set
ˆw(1)
 error 1( )1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#4,4,"Esempio di funzione
 
5
Applichiamo rumore gaussiano, campioniamo 30 
osservazioni e addestriamo vari modelli:y=s i n ( 4 x)"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#40,40," 
41
k-fold Cross Validation 
Per il secondo blocco abbiamo:
Validation
 Set
ˆw(2)
  error 2( )2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#41,41," 
42
k-fold Cross Validation 
… e così via ﬁno al blocco K:
Validation
 Set
ˆw(K)
 errorK( )K"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#42,42," 
43
k-fold Cross Validation 
L’algoritmo è il seguente:
Per ogni scelta del valore di λ:
 for k = 1, 2, …., K 
   1. stima di ŵλ sui blocchi di training 
   2. calcolo dell’errore sul “validation block”:
Calcolo dell’Average Error: CV( )=1
K·KX
k=1error k( )
Scelta di λ* che minimizza l’errore CV( λ)error k( )"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#43,43," 
44
leave-one-out Cross Validation 
Formalmente, la migliore approssimazione si ha per validation 
set di dimensione 1 (K = N).
In tal caso si parla di leave-one-out cross validation :
123 n
1 2 3 N
2 3 N
1 2 3 N
1 2 3 N
……………1…
…
…
…
…1 2 3 N"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#44,44,"Scelta del valore K 
 
45
Il Leave-one-out è molto pesante dal punto di vista 
computazionale: 
richiede il calcolo di N “ﬁt” del modello per ogni λ. 
In genere, tipici valori utilizzati per K sono: 
K = 5 (5-fold CV) 
K = 10 (10-fold CV)"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#45,45," 
46
La gestione dell’intercetta 
Nella discussione su Ridge e Cross Validation non abbiamo 
considerato il come gestire l’intercetta, che compare in tanti  
modelli.
yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i
Ricordiamoci innanzi tutto il modello a “multiple regression”:
Sappiamo che spesso la feature ɸ0 è posta uguale a 1. In tal 
caso il coefﬁciente w 0 rappresenta per l’appunto l’intercetta 
del modello."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#46,46," 
47
La gestione dell’intercetta 
Conosciamo bene la funzione di costo per la Ridge:
Minimizzando tale funzione, anche l’intercetta w 0 (così 
come gli altri coefﬁcienti) tende ad assumere piccoli valori.RSS(w)+ ·kwk2
2
In realtà ciò non sarebbe necessario. L’intercetta non è 
indicativa dell’overﬁtting."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#47,47," 
48
La gestione dell’intercetta 
Possiamo dunque considerare una versione modiﬁcata della 
funzione di costo per la Ridge:
In tal modo, la parte relativa alla L 2-norm (penalty) non 
considera w 0.
Vediamo come possiamo implementare ciò nel caso in cui si 
usi l’algoritmo di Gradient Descent.RSS(w0,wresto)+ ·kwrestok2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#48,48," 
49
L’algoritmo viene modiﬁcato come segue:
Algoritmo di Gradient Descent 
[caso della Ridge Regression senza penalizzazione dell’intercetta] 
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
ifj=0
w(t+1)
j w(t)
j ↵⇤derivata parziale RSS[ j]
else
w(t+1)
j (1 2↵ )w(t)
j ↵⇤derivata parziale RSS[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#49,49,"Riferimenti
 
50
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#5,5,"Polinomio di grado 2
 
6
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#6,6,"Polinomio di grado 4
 
7
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#7,7,"Polinomio di grado 16
 
8
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#8,8,"Overﬁtting con molte feature
 
9
Questo fenomeno accade non solo nella polynomial 
regression, ma anche: 
 quando è elevato il numero degli input d (e.g., per il 
caso degli appartamenti, oltre alla metratura abbiamo 
il #bagni, ecc.); 
e, più in generale, quando è elevato il numero delle 
feature ( D elevato):
yi=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#9,9,"Overﬁtting e #osservazioni
 
10
Il problema dell’overﬁtting, che in genere aumenta 
all’aumentare della complessità del modello, dipende 
anche dal numero delle osservazioni di cui disponiamo: 
Poche osservazioni (N piccolo) → è facile avere overﬁt al crescere 
della complessità del modello. 
Tante osservazioni (N molto grande)  → è più  difﬁcile avere overﬁt.Prezzo
Prezzo
Area Area"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Feature Selection e LASSO
Machine Learning 
 
1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#1,1,"Sommario
La Selezione delle Feature nella Regression 
Algoritmo All Subsets 
Approccio Greedy per Feature Selection (Forward Stepsize 
Algorithm) 
Algoritmo Coordinate Descent 
LASSO 
Confronto tra Ridge e LASSO
 
2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#10,10," 
11
La scelta del Modello 
Ci sono varie possibilità: 
Valutazione delle prestazioni sul validation set (se abbiamo dati sufﬁcienti) 
Cross Validation 
Altre metriche proposte in letteratura che penalizzano la “model 
complexity”
La domanda ora è la seguente: quale conﬁgurazione di 
feature scegliamo? 
Come sappiamo, non conviene scegliere il modello con RSS 
più basso, che diminuisce all’aumentare della complessità del 
modello."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#11,11,"Complessità di “All Subsets”
 
12
La complessità computazionale dell’algoritmo è elevata: basti 
considerare il numero di modelli da valutare! E’ esponenziale 
rispetto al numero delle feature:
[000 ···0]
[100 ···0]
[010 ···0]
···
[110 ···0]
···
[111 ···1]yi= ✏i
yi=w0 0(xi)+✏i
yi=w1 1(xi)+✏i
··· ··· ···
yi=w0 0(xi)+w1 1(xi)+✏i
··· ··· ···
yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i
2D+1feature vector"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#12,12,"Algoritmi Greedy
 
13
Un approccio alternativo è quello di utilizzare algoritmi 
greedy che ci consentono di ottenere soluzioni sub-ottime, 
ma con complessità computazionale molto più bassa.
L’algoritmo che ora vedremo si chiama Forward Stepsize 
Algorithm. Esso si distingue dal precedente perché, 
all’aumentare del numero di feature, sceglie solo una nuova 
feature conservando quelle scelte nei passi precedenti."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#13,13,"Forward Stepsize Algorithm
 
14
Partiamo dalla ﬁgura che rappresenta la fase ﬁnale di All Subsets:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#14,14," 
15
Vediamo come il Forward Stepsize si differenzia:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#15,15," 
16
Per #features = 1 sceglie la migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#16,16," 
17
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
deriva dal passo  
precedente
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#17,17," 
18
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
seconda feature 
selezionata"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#18,18," 
19
E’ evidente la differenza rispetto all’algoritmo All Subset:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
feature selezionate da 
“all subset algorithm”"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#19,19," 
20
… e così via …
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#2,2,"Selezione delle Feature
 
3
La selezione delle feature nella regression è una fase molto 
importante per due motivi: 
1. Efﬁcienza di elaborazione : 
•Se la dimensione di w è elevata (e.g., 100B) la predizione è 
molto pesante computazionalmente. 
•Del resto, se ŵ è sparso, il calcolo dipende solo dai valori 
non nulli. 
2. Interpretabilità : 
• Quali feature sono rilevanti per la nostra  predizione? "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#20,20," 
21
… ﬁno al caso che considera tutte le feature:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#21,21," 
22
Consideriamo il dizionario delle feature {
 ɸ
0
, 
ɸ
1
, … , 
ɸ
D
} 
Impostiamo l’insieme delle feature F come segue: F
 0
 = 
∅
   (
o impostiamo 
 ɸ
0
 a 1
); 
addestriamo e calcoliamo l’errore. 
t = 0 
•
Per ogni j (≠ dalle feature correnti), addestriamo il modello usando le 
feature correnti F
 t
 + {
ɸ
j
(x)} per ottenere il vettore dei pesi 
 ŵ
 per j. 
•
Selezioniamo la best feature 
 ɸ
j*
(x) (e.g., quella che dà luogo al training 
error più basso quando addestriamo con F
 t
 + {
ɸ
j*
(x)}) 
•
Set  F
 t+1
 <— F
 t 
+ {
ɸ
j*
(x)};  
•
t = t + 1 
•
Ripetere il ciclo 
Forward Stepsize Algorithm
L’algoritmo in sintesi è il seguente:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#22,22," 
23
La complessità computazionale di questo algoritmo è 
sensibilmente minore di quella dell’All Stepsize Algorithm. 
Infatti, il numero di modelli valutati (con D feature) è il 
seguente: 
1° step: D modelli 
2° step: D-1 modelli (si aggiunge 1 feature tra le D-1 possibili) 
3° step: D-2 modelli (si aggiunge 1 feature tra le D-2 possibili) 
ecc.
Forward Stepsize Algorithm
Il numero massimo di step è uguale a D. Abbiamo dunque: 
O(D2)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#23,23," 
24
Questo metodo, proposto da Robert Tibshirani nel 1996, consente 
di effettuare una feature selection, oltre a limitare i valori assoluti 
dei coefﬁcienti w. 
Lasso Regression usa la somma dei valori assoluti dei pesi ( L1 
Regularization ). 
La funzione che rappresenta il costo totale nel Lasso è dunque la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i due 
termini.                                              costo lasso(w)=R S S ( w)+ ·kwk1
LASSO 
(
Least Absolute Shrinkage and Selection Operator
 )"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#24,24," 
25Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵlasso = 0 
Se 0 < λ < ∞: 
Soluzioni Lasso 
per diversi valori 
 λ
0kˆwlassok1kˆwLSk1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#25,25,"Andamento Coefﬁcienti 
Ridge e Lasso
 
26
Ridge Lasso
λ λ "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#26,26,"Visualizzazione costo Ridge
 
27
ellissicosto ridge(w)=R S S ( w)+ ·kwk2
2
RSS(w)=NX
i=1[yi w0 0(xi) w1 1(xi)]2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#27,27," 
28
circonferenzecosto ridge(w)=R S S ( w)+ ·kwk2
2
kwk2
2=w2
0+w2
1
Visualizzazione costo Ridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#28,28,"Simulazione Ridge
 
29
λ = 0
λ→∞ˆwridge
ˆwridgeˆwridge
ˆwridge ˆwridge ˆwridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#29,29," 
30
costo lasso(w)=R S S ( w)+ ·kwk1
RSS(w)=NX
i=1[yi w0 0(xi) w1 1(xi)]2ellissi
Visualizzazione costo Lasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#3,3,"Selezione delle Feature
 
4
Un approccio che possiamo adottare per selezionare le 
migliori feature consiste nel considerare ogni possibile 
combinazione delle feature che abbiamo disponibili, 
veriﬁcando le prestazioni di ciascuna scelta. 
Questo è esattamente ciò che fa l’ All Subset Algorithm  che 
ora vediamo. 
Esso comincia considerando 0 feature, poi tutte le 
possibilità per 1 feature, poi tutte le possibilità per 2 
feature, ecc., scegliendo ogni volta la migliore 
combinazione."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#30,30," 
31
kwk1= |w0|+|w1|costo lasso(w)=R S S ( w)+ ·kwk1
diamonds 
Visualizzazione costo Lasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#31,31,"Simulazione Lasso
 
32
λ→∞λ = 0
ˆwlasso
ˆwlassoˆwlasso
ˆwlasso ˆwlasso ˆwlasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#32,32,"Confronto tra Ridge e Lasso
 
33
Per ogni valore di 
 λ
, per la Ridge esiste un certo valore 
 s
 tale 
che le seguenti due equazioni forniscono le stesse stime dei 
coefﬁcienti w
 ridge
:
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
jsargmin
w[RSS(w)+ ·kwk2
2]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#33,33,"Confronto tra Ridge e Lasso
 
34w1
w0
w2
0+w2
1s
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
js
Consideriamo per semplicità il caso a 2 dimensioni. L’equazione: 
indica che i coefﬁcienti ŵridge stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al cerchio deﬁnito da: w2
0+w2
1s"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#34,34,"Confronto tra Ridge e Lasso
 
35
Analogamente, per ogni valore di 
 λ
, per il Lasso esiste un 
certo valore 
 s
 tale che le seguenti due equazioni forniscono 
le stesse stime dei coefﬁcienti w
 lasso
:
argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|sargmin
w[RSS(w)+ ·kwk1]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#35,35,"Confronto tra Ridge e Lasso
 
36|w0|+|w1|sw0w1
|w0|+|w1|s
Analogamente, la seguente equazione:  
indica che i coefﬁcienti ŵlasso stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al “diamante”: argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|s"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#36,36,"Confronto tra Ridge e Lasso
 
37
La ﬁgura seguente ci mostra i punti di minimo per i due casi, e il 
perché Lasso spesso consente di eliminare alcune feature. In rosso 
sono indicate le curve di livello per RSS.
|w0|+|w1|s w2
0+w2
1s
w0w1
w0w1
ˆwLSˆwLS
ˆwlasso ˆwridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#37,37,"Confronto tra Ridge e Lasso
 
38
Se 
s
 è sufﬁcientemente grande, le regioni in verde conterranno la 
soluzione Least Squares. Pertanto le stime della Ridge regression e 
del Lasso saranno le stesse della Least Squares (tale grande valore per 
s
 corrisponde a 
 λ
 = 0) 
Se invece la soluzione Least Squares sta al di fuori delle regioni in 
verde, essa non può essere la soluzione perché non rispetta i vincoli 
citati in precedenza. 
I punti di minimo sono dunque quelli che corrispondono alla curva 
di livello più “stretta” che passa per l’area in verde (ricordiamoci che 
le curve di livello per RSS corrispondono a valori sempre più alti 
mano a mano che si “allargano” rispetto alla soluzione LS)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#38,38,"Confronto tra Ridge e Lasso
 
39
Nella ﬁgura abbiamo considerato il caso di 2 dimensioni per il 
vettore 
 w
. 
Nel caso di 3 dimensioni la “constraint region” in verde diventa una 
sfera per la Ridge e un poliedro per il Lasso. 
Nel caso di dimensione > 3, essa diventa una ipersfera per la Ridge e 
un politopo per il Lasso (politopo è un termine coniato da Alicia 
Boole, ﬁglia di George Boole)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#39,39,"Minimizzazione della  
funzione di costo Lasso
In precedenza abbiamo visto come poter minimizzare la 
funzione di costo (per LS e per Ridge) mediante: 
La forma chiusa (uguagliando a zero il gradiente della 
funzione) 
Gradient Descent 
Per il Lasso ci sono delle difﬁcoltà per il calcolo del gradiente.
 
40"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#4,4,"Ricerca delle migliori feature 
Size: 0
 
5# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#40,40,"Minimizzazione della  
funzione di costo Lasso
La funzione da minimizzare è la seguente: 
 
41
wj
|wj|
derivata = +1 derivata = -1
non derivabile
costo lasso(w)=R S S ( w)+ ·kwk1
come calcolare 
la derivata?"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#41,41,"Minimizzazione della  
funzione di costo
Non possiamo quindi calcolare il gradiente della funzione. 
Successivamente vedremo come utilizzare il concetto di 
subgradient
  per superare la difﬁcoltà appena vista. 
Ora cogliamo l’occasione per vedere un nuovo algoritmo per 
minimizzare una funzione di costo, chiamato 
 Coordinate 
Descent
 . 
Presenteremo l’algoritmo in generale, per poi vedere come esso 
possa essere usato convenientemente per minimizzare la 
funzione di costo per il Lasso.
 
42"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#42,42,"Il nostro scopo è quello di minimizzare una certa funzione:
Algoritmo Coordinate Descent
g(w)=g(w0,w1,···,wD)
La caratteristica distintiva del Coordinate Descent è che la 
minimizzazione avviene lungo una singola dimensione per 
volta, come illustrato qui di seguito nel semplice caso di 
funzione di due variabili w
 0
 e w
 1
. 
 
43"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#43,43,"Algoritmo Coordinate Descent
Curve di livello di una funzione g(
 w
) da minimizzare:
 
44
w0w1
scegliamo il 
punto inizialevalori di g( w) maggiori per  
curve di livello più esterne "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#44,44,"Facciamo variare una sola coordinata:
 
45
w0w1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#45,45,"Troviamo il minimo e spostiamoci su tale punto (axis-alined move):
 
46
w0w1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#46,46,"Facciamo variare una sola altra coordinata:
 
47
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#47,47,"Troviamo il minimo e passiamo su tale punto:
 
48
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#48,48,"……. e così via …….
 
49
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#49,49,"………
 
50
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#5,5," 
6# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature 
Size: 1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#50,50,"………
 
51
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#51,51,"………
 
52
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#52,52,"…. ﬁno ad arrivare al minimo globale:
 
53
w0w1
w0
1w00
1
w00
0w0
0
……
Algoritmo Coordinate Descent
per problemi convessi, 
step sempre più piccoli 
man mano che ci  
avviciniamo alla soluzione"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#53,53,"Algoritmo Coordinate Descent
 
54
Inizializza ŵ = 0 (o in modo “smart”) 
while  not converged: 
   scegli una coordinata j
si minimizza solo sulla j-esima coordinataˆwj argmin
!g(ˆw0,ˆw1,···,ˆwj 1,!,ˆwj+1,···,ˆwD)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#54,54,"Algoritmo Coordinate Descent
 
55
Come scegliere nell’algoritmo la coordinata successiva? 
In modo casuale (“random” o “stochastic"" coordinate descent) 
In modo “round robin” 
ecc. 
Si noti che in questo algoritmo non è necessario scegliere lo step size! 
Tale approccio è utilissimo per numerosi problemi 
Converge ad un ottimo in vari altri casi (e.g., funzione “strongly 
convex”) 
Converge per la funzione obiettivo Lasso "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#55,55,"Normalizzazione delle Feature
 
56
L’applicazione dell’algoritmo Coordinate Descent per il Lasso è 
sempliﬁcata se operiamo una normalizzazione delle feature. 
Per far questo dobbiamo prendere in considerazione la matrice 
delle feature   usata in precedenza, nella quale ogni colonna 
corrisponde ad una feature (0, 1, … D) applicata ai vari ingressi xi 
dei training data.  "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#56,56,"Normalizzazione Feature
 
57 =2
664 0(x1) 1(x1) ...  j(x1) ...  D(x1)
 0(x2) 1(x2) ...  j(x2) ...  D(x2)
... ... ... ... ... ...
 0(xN) 1(xN) ...  j(xN) ...  D(xN)3
775
 j(xk)= j(xk)qPN
i=1 2
j(xi)feature generica normalizzata:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#57,57,"Normalizzazione delle Feature
 
58Zj=vuutNX
i=1 2
j(xi)
Per normalizzare abbiamo usato a denominatore il seguente 
“normalizer”: 
Ricordiamoci che per i test data dovremo applicare lo stesso 
normalizer.  "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#58,58,"Coordinate Descent per 
Unregularized Regression
 
59
Vediamo ora come sia possibile applicare l’algoritmo Coordinate 
Descent nel caso di regressione senza regularization, ossia nel 
caso Least Squares. 
Il passo successivo sarà la sua applicazione al Lasso. 
Per l’applicazione al caso Least Squares (con feature 
normalizzate) dobbiamo calcolare le derivare parziali della 
funzione di costo RSS (necessarie per minimizzare sulla singola 
coordinata): 
RSS(w)=NX
i=1[yi DX
j=0wj j(xi)]2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#59,59,"Derivate di RSS 
con feature normalizzate
 
60@RSS(w)
@wj= 2NX
i=1 j(xi)[yi ˆyi(w)] = 2NX
i=1 j(xi)[yi DX
j=0wj j(xi)] =
= 2NX
i=1 j(xi)[yi X
k 6=jwk k(xi) wj j(xi)] =
= 2⇢jz }| {
NX
i=1 j(xi)[yi X
k 6=jwk k(xi)]
| {z }
prediz. senza  j+2wj,1z}|{
NX
i=1 2
j(xi)=
= 2⇢j+2wj"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#6,6," 
7# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliore feature
Ricerca delle migliori feature 
Size: 1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#60,60,"Ricerca del minimo per una 
coordinata
 
61⇢j=NX
i=1 j(xi)[yi X
k6=jwk k(xi)] =NX
i=1 j(xi)[yi ˆyi(ˆw j)]@RSS(w)
@wj= 2⇢j+2wj=0
ˆwj=⇢j
dove:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#61,61,"Algoritmo Coordinate Descent 
per Least Squares
 
62set:calcola:
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
⇢j=NX
i=1 j(xi)[z}| {
yi ˆyi(ˆw j)|{z}]residual senza la feature j
predizione senza 
la feature j
ˆwj=⇢j"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#62,62," 
63ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2
Algoritmo Coordinate Descent 
per Lasso
Vediamo ora la versione dell’algoritmo per il caso del Lasso. 
In questo caso l’impostazione per il peso 
 ŵ
j
 dipende dal valore 
assunto dal parametro 
 λ
: 
Una dimostrazione formale è mostrata nella prossima lezione. "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#63,63,"Coefﬁcienti per LS, Ridge e Lasso
 
64ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2
soft thresholding
+ 
2  
2⇢i 0 0 ⇢i0 0ˆwj ˆwj"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#64,64,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature normalizzate]
 
65ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2set:calcola:
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#65,65,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
66
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2zj=NX
i=1 j(xi)2
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#66,66," 
67
Un aspetto importante è il criterio di convergenza. 
Per problemi convessi (in particolare strongly convex) gli step 
sono sempre più piccoli mano a mano che ci si avvicina al 
punto di ottimo:
Algoritmo Coordinate Descent 
per Lasso
Un criterio che possiamo utilizzare per la convergenza è quello 
di considerare una misura degli step fatti in un ciclo completo su 
tutte le feature e fermarsi quando: 
 max step < 
 ε"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#67,67,"Scelta del parametro 
 λ
per approfondimenti: 
Murphy, K. “
 Machine Learning: A Probabilistic Perspective
 ”. The MIT Press, 
2012.
 
68
Il parametro 
 λ
 può essere scelto avvalendosi dell’approccio che 
usa il validation set, a patto di avere un numero sufﬁciente di 
osservazioni. 
Altrimenti possiamo usare la k-fold cross validation. 
Quest’ultima tende a scegliere il parametro che ottiene la 
migliore “predictive accuracy”. Essa tende a favorire soluzioni 
meno “sparse”, ossia con piccoli valori di 
 λ
, anziché soluzioni 
con maggiore feature selection."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#68,68,"Riferimenti
 
69
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#7,7," 
8# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliori 2 feature
Ricerca delle migliori feature 
Size: 2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#8,8," 
9
Ricerca delle migliori feature 
Size: 8
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#9,9," 
10# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature  
andamento in base al numero di feature"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Dimostrazioni Formali Lasso
Machine Learning "
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#1,1,"Sommario
 
2Dimostrazione della formula di aggiornamento dei 
coefﬁcienti nell’algoritmo coordinate descent per 
LASSO
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#10,10,"Differential set della  
funzione di costo Lasso
 
11
Il differential set rispetto al generico peso w
 j
 è pertanto il seguente:
@wj[costo lasso] = 2 zjwj 2⇢j+ ·@wj|wj|da RSS da L 1 penalty
@wj[costo lasso] = 2 zjwj 2⇢j+8
<
:   sewj<0
[  , ]s e wj=0
  sewj>0
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#11,11,"Differential Set della  
funzione di costo Lasso  
 
12
Abbiamo pertanto la seguente espressione ﬁnale:
@wj[costo lasso] =8
<
:2zjwj 2⇢j   sewj<0
[ 2⇢j  , 2⇢j+ ]s e wj=0
2zjwj 2⇢j+  sewj>0"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#12,12,"Soluzione ottima 
 
13
Se uguagliamo a zero la precedente espressione, abbiamo tre casi:
caso 1 (
 w
j  
< 0
):2zjˆwj 2⇢j  =0
ˆwj=2⇢j+ 
2zj=⇢j+ 
2
zj
ˆwj=⇢j+ 
2
zj<0 ⇢j+ 
2<0 ⇢j<  
2
da cui otteniamo:
Poiché 
 ŵ
j  
< 0, abbiamo:"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#13,13,"Soluzione ottima 
 
14
Abbiamo dunque:
In deﬁnitiva:
caso 2 ( wj  = 0): l’intervallo                                            deve contenere 0 [ 2⇢j  , 2⇢j+ ]
  
2⇢j 
2 2⇢j+  0 2⇢j  0
⇢j 
2⇢j   
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#14,14,"Soluzione ottima 
 
15
caso 3 (
 w
j  
> 0
):
da cui otteniamo:
Poiché 
 ŵ
j  
> 0, abbiamo:2zjˆwj 2⇢j+ =0
ˆwj=2⇢j  
2zj=⇢j  
2
zj
ˆwj=⇢j  
2
zj>0 ⇢j  
2>0 ⇢j> 
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#15,15," 
16
In conclusione:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2@wj[costo lasso] =8
<
:2zjwj 2⇢j   sewj<0
[ 2⇢j  , 2⇢j+ ]s e wj=0
2zjwj 2⇢j+  sewj>0
Soluzione ottima "
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#16,16,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
17
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2zj=NX
i=1 j(xi)2
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#17,17,"Coefﬁcienti per LS, Ridge e Lasso
 
18
soft thresholding
+ 
2  
2⇢i 0 0 ⇢i0 0ˆwj ˆwjˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#18,18,"Riferimenti
 
19
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#2,2,"Ottimizzazione Lasso
 
3
Come sappiamo, la Funzione Obiettivo per il Lasso da ottimizzare 
mediante Coordinate Descent è la seguente:
RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
Vediamo come calcolare le derivate parziali dei due termini 
presenti nell’espressione rispetto ai pesi w j."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#3,3,"Derivazione del termine RSS
 
4RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
@RSS(w)
@wj= 2NX
i=1 j(xi)[yi ˆyi(w)] = 2NX
i=1 j(xi)[yi DX
j=0wj j(xi)] =
= 2NX
i=1 j(xi)[yi X
k 6=jwk k(xi) wj j(xi)] =
= 2⇢jz }| {
NX
i=1 j(xi)[yi X
k 6=jwk k(xi)]
| {z }
prediz. senza  j+2wj,zjz}|{
NX
i=1 2
j(xi)=
= 2⇢j+2wjzj"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#4,4," 
5
In questo caso c’è il problema del calcolo della derivata parziale:
RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
 ·@|wj|
@wj=?
Derivazione del termine L
 1
 penalty
derivata = +1 derivata = -1
non derivabilewj|wj|
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#5,5,"Subgradiente di Funzioni Convesse 
 6
I metodi che conosciamo (e.g., Gradient Descent, Coordinate 
Descent) richiedono che la funzione da ottimizzare sia 
differenziabile. 
E’ possibile però generalizzare la discussione andando al di là 
delle funzioni differenziabili. 
E’ possibile ad esempio mostrare come i precedenti algoritmi 
possano essere applicati anche per funzioni non differenziabili, 
utilizzando il subgradiente anziché il gradiente."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#6,6,"Subgradiente di Funzioni Convesse
 
7Un vettore S che soddisfa la: 
è detto subgradiente di g in v.g(w) g(v)+ST(w v)
.wg(w)
vS1pendenza 
S2 pendenza 
. 
. 
.g:R!R
L’insieme dei subgradienti di g in v è chiamato “differential set” e 
indicato: @g(v)"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#7,7,"Subgradiente della funzione  
Valore Assoluto
 
8
Nel punto non derivabile della funzione “valore assoluto” i 
subgradienti variano da -1 a +1:
derivata = +1 derivata = -1
wj|wj|"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#8,8,"Subgradiente della funzione  
Valore Assoluto
 
9
Il “differential set” è dunque il seguente per i vari punti:
@wj|wj|=8
<
:{ 1} sewj<0
[ 1,1] se wj=0
{1} sewj>0"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#9,9,"Subgradiente di L
 1
 term
 
10
Nel caso del Lasso abbiamo:
 ·@wj|wj|=8
<
:   sewj<0
[  , ]s e wj=0
  sewj>0"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Fonti di Errore 
Expected Prediction Error
Machine Learning "
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#1,1,"Sommario
Le tre fonti di errore: Noise, Bias, Variance 
Deﬁnizione e derivazione formale delle tre fonti di 
errore 
Expected Prediction Error 
 
2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#10,10,"Noise: 
Varianza dell’Errore del modello
 
11
EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
y=fw(true)(x)+ ✏
 2= varianza di ✏"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#11,11,"Bias della funzione stimata 
 
12bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
x
t(true) (true)
(true)average 
estimated 
function:
f¯w(xt),Etrain [fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#12,12,"Varianza della funzione stimata 
 
13EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#13,13,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Vediamo ora come dimostrare la formula dell’EPE, in cui 
entrano in gioco i tre termini che abbiamo deﬁniti 
formalmente in precedenza:
 
14EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#14,14,"Dimostrazione per  
l’Expected Prediction Error (EPE)
A tal ﬁne, ricordiamo innanzi tutto la deﬁnizione di tale 
errore:
 
15EPE = Etrain[Generalization Error per ˆw(train)] =
=Etrain[Ex,y[L(y,f ˆw(train) (x))]]
1.
 Consideriamo: 
2.
 Riferiamoci ad uno speciﬁco 
 x
tL[y, f ˆw(x)] = ( y ˆy)2=[y fˆw(x)]2
Facciamo poi le seguenti due assunzioni (già citate prima):"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#15,15,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Con le due assunzioni precedenti l’espressione per l’EPE 
si sempliﬁca come segue:
 
16EPE( xt)=Etrain ,yt[(yt ˆyt)2]=Etrain ,yt[(yt fˆw(train) (xt))2]
dove non abbiamo più l’Expectation su 
 x
, avendo ﬁssato 
uno speciﬁco 
 x
t
, e dove l’Expectation su y è diventata 
l’Expectation su y
 t
 perché dobbiamo considerare solo le 
osservazioni che abbiamo a fronte dell’input 
 x
t
."
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#16,16,"Expected Prediction Error
Partendo da tale espressione, vediamo come dimostrare la 
formula dell’EPE:
 
17EPE( xt)= Etrain ,yt[(yt ˆyt)2]=Etrain ,yt[(yt fˆw(train) (xt))2]=
=Etrain ,yt[(yt fz }| {
fw(true) (xt)+fz }| {
fw(true) (xt) ˆfz }| {
fˆw(train) (xt))2]=
=Etrain ,yt[((yt f)+(f ˆf))2]=
=Etrain ,yt[(yt f)2+ 2(yt f)·(f ˆf)+(f ˆf)2]=
=Etrain ,yt[(yt f)2]+2 ·Etrain ,yt[(yt f)·(f ˆf)] +Etrain ,yt[(f ˆf)2]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#17,17,"Expected Prediction Error
1° termine: Si sempliﬁca come segue, poiché  y
 t
 e f non 
dipendono dal training set:
 
18
Si noti che l’Expectation del quadrato dell’errore 
 ε
 è la 
varianza di 
 ε
, avendo esso media nulla.Etrain ,yt[(yt f)2]=Eyt[(yt f)2]=Eyt[✏2], 2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#18,18,"Expected Prediction Error
2° termine:
 
192·Etrain ,yt[(yt f)·(f ˆf)] = 2 ·Etrain ,yt[(✏)·(f ˆf)] =
=2 ·Etrain ,yt[✏]·Etrain ,yt[(f ˆf)] =
=2 ·0·Etrain ,yt[(f ˆf)] = 0
Si noti che ε è indipendente da  e da , e quindi è 
indipendente da           .  
Si ricordi, inoltre, che l’Expectation dell’errore ε è uguale 
a zero.ˆf f
(f ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#19,19,"Expected Prediction Error
3° termine:
 
20
L’espressione per l’errore EPE può essere dunque scritta 
così:
Abbiamo: Etrain ,yt[(f ˆf)2]=Etrain [(f ˆf)2]
EPE( xt)= 2+M S E ( ˆf)MSE( ˆf),Etrain[(f ˆf)2]
Consideriamo ora il Means Squared Error (MSE), deﬁnito 
come segue:"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#2,2,"Deﬁnizione e derivazione 
formale
Occupiamoci della deﬁnizione e derivazione formale delle 
tre sorgenti di errore: 
noise 
bias 
variance 
A tal ﬁne introduciamo innanzi tutto l’Expected Prediction 
Error, le cui componenti sono le suddette sorgenti di errore.
 
3"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#20,20,"Means Squared Error
Dobbiamo ora dimostrare che:
 
21MSE[ fˆw(train) (xt)] = Etrain[(fw(true) (xt) fˆw(train) (xt))2]=
=Etrain[(fz }| {
fw(true) (xt) ¯fz}|{
f¯w(xt)+¯fz}|{
f¯w(xt) ˆfz }| {
fˆw(train) (xt))2]=
=Etrain[((f ¯f)+( ¯f ˆf))2]=
=Etrain[(f ¯f)2+ 2(f ¯f)·(¯f ˆf)+( ¯f ˆf)2]=
=Etrain[(f ¯f)2]+2 ·Etrain[(f ¯f)·(¯f ˆf)] +Etrain[(¯f ˆf)2]MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#21,21,"1° termine: ricordiamo che
 
22
Ne consegue che:
poiché   e    non dipendono dal training set. f¯f
Means Squared Error
¯f,Etrain [ˆf]
Etrain [(f ¯f)2]=(f ¯f)2,[bias( ˆf)]2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#22,22,"2° termine:
 
232·Etrain [(f ¯f)·(¯f ˆf)] = 2 ·(f ¯f)·Etrain [(¯f ˆf)] =
=2 ·(f ¯f)·(¯f Etrain [ˆf]) =
=2 ·(f ¯f)·(¯f ¯f)=
=2 ·(f ¯f)·0=0
Means Squared Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#23,23,"Means Squared Error
3° termine:
 
24Etrain [(¯f ˆf)2]=Etrain [(ˆf ¯f)2],var( ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#24,24,"E’ in tal modo dimostrato che:
 
25MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)
Means Squared Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#25,25,"In conclusione:
 
26EPE( xt)= 2+M S E [ fˆw(xt)] = 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
le 3 sorgenti di errore
Espressione per 
Expected Prediction Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#26,26,"Riferimenti
 
27
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#3,3,"Training Set Randomness
Un Training Set è un campione di N osservazioni (e.g., N 
appartamenti venduti di cui conosciamo le features e il 
prezzo).  
Cosa accade se il Training Set è costituito da altre N 
osservazioni diverse dalle precedenti?  
Come cambiano le prestazioni del sistema?
 
4"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#4,4,"Training Set Randomness
Ad esempio, nella ﬁgura sono mostrate due situazioni 
relative a due diverse scelte del training set:
 
5Test Set
Per valutare la prestazione dei due “ﬁt” dobbiamo 
prendere in considerazione il Generalization Error."
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#5,5,"Training Set Randomness
Nei due casi otterremo due diversi valori del 
Generalization Error:
 
6Test Set
"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#6,6,"Expected Prediction Error
Idealmente, vorremmo poter ottenere una misura delle 
prestazioni del sistema, mediata su tutti i possibili training 
set. 
Possiamo deﬁnire formalmente tale quantità, che 
chiamiamo Expected Prediction Error (EPE), come segue: 
 
7EPE = Etrain[Generalization Error per ˆw(train)]
“averaging” su tutti i possibili Training Set 
(pesati in base alle loro probabilità)parametri calcolati su 
uno speciﬁco Training Set"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#7,7,"Expected Prediction Error 
su un target input
Per analizzare questo tipo di errore, cominciamo a 
prendere in considerazione uno speciﬁco punto 
 x
t
: 
 
8Test 
x
t
Supponiamo  inoltre che la Loss function sia la seguente: 
L[y, f ˆw(x)] = ( y ˆy)2=[y fˆw(x)]2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#8,8,"Expected Prediction Error 
su un target input
E’ possibile dimostrare che l’errore EPE in 
 x
t
 è uguale alla 
somma di tre termini:
 
9
Vediamo ora di illustrare adeguatamente tali tre termini.EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#9,9,"Noise: 
Varianza dell’Errore del modello
 
10EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
fw(true) (x)
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione  
alla  
Classiﬁcazione
Machine Learning "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#1,1,"Sommario
Introduzione alla Classiﬁcazione 
Esempi di applicazione della Classiﬁcazione 
Decision Boundary 
Logistic Regression 
Maximum Likelihood Estimation 
Training mediante Gradient Ascent
 
2"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#10,10,"Introduzione alla Classiﬁcazione
 
11
•Come si vede in ﬁgura, tutte le immagini del test set, tranne una, 
sono classiﬁcate correttamente. 
•L’errore per il Boston terrier  è dovuto completamente alla nostra 
scelta delle features, scelta fatta basandoci sul training set 
disponibile (un po’ troppo piccolo). 
•Per migliorare dobbiamo perciò ricominciare, collezionando più 
dati e individuare più features."
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#11,11,"Learning Pipeline
 
12
•In ﬁgura è rappresentata la learning pipeline del problema di 
classiﬁcazione che stiamo considerando. 
•Lo stesso processo è usato essenzialmente per tutti i task di 
Machine Learning, non solo per la classiﬁcazione. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#12,12,"Learning Pipeline
 
13•Deﬁnire il problema . Qual è il task che vogliamo sia appreso dal 
computer? 
•Collezionare i dati . Raccogliere i dati per il training set e il test set. Più 
i dati sono numerosi e diversiﬁcati, meglio è per il successo del 
sistema da realizzare. 
•Individuare le features . Quali sono le features migliori per descrivere i 
dati? 
•Addestrare il modello . Scegliere il modello e calibrare i suoi parametri 
sul training set mediante metodi di ottimizzazione. 
•Testare il modello . Valutare sul test set le prestazioni del modello 
addestrato. Se i risultati non sono soddisfacenti, ripensare la scelta 
delle features utilizzate e collezionare, se possibile, più dati. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#13,13,"Minimizzazione di una funzione di costo
 
14
Caso della regressione:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#14,14,"Minimizzazione di una funzione di costo
 
15
Caso della classiﬁcazione:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#15,15,"Esempi di applicazione 
Object Detection
 
16
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#16,16,"Esempi di applicazione 
Spam Filtering
 
17(Testo della email, 
mittente, IP, ecc.)
Input: x Output: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#17,17,"Esempi di applicazione 
Image Classiﬁcation
 
18
Input: x Output: ŷ
(pixel dell’immagine) (categoria predetta)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#18,18,"Esempi di applicazione 
Diagnosi Mediche Personalizzate 
 
19Input: x Output: ŷ
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#19,19,"Esempi di applicazione 
Reading Your Mind
 
20
Output: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#2,2,"Introduzione alla Classiﬁcazione
Il task della 
 Classiﬁcazione
  è simile in linea di principio a 
quello della 
 Regressione  
La vera differenza tra i due è che, anziché predire un valore di 
output continuo, nella classiﬁcazione cerchiamo di prevedere 
valori discreti o 
 classi 
 
3"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#20,20,"Esempi di applicazione 
 
21Sentiment Analysis
Esempio: classiﬁcatore di reviews di ristorantiInput: xOutput: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#21,21,"Esempi di applicazione 
Sentiment Analysis
 
22
Input x:  In questo ristorante preparano i migliori  
“spaghetti alla carbonara” di Roma
ŷ = +1"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#22,22,"Punteggio di una frase 
(
Score
 ) 
 
23Termine Peso w
migliore 1.5
buono 1.0
cattivo -1.0
magniﬁco 2.0
terribile -2.1
eccezionale 2.7
il, noi, dove, ecc. 0.0Un modo che possiamo adottare per classiﬁcare una review come 
positiva o negativa consiste nel considerare alcuni “termini” che 
riteniamo rilevanti ai ﬁni della classiﬁcazione, calcolando per ciascuno 
di essi il numero di occorrenze con cui compare nella review e un 
“valore di rilevanza” (peso) da utilizzare per calcolare un “punteggio”. 
Ad esempio:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#23,23," 
24x1 = #eccezionalex2 = #terribile
+
++ ++-
--
-
+Score( x) = 2.7 x1 - 2.1 x2Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
-Score( x) < 0
Score( x) > 0r:  2.7 x1 - 2.1 x2 = 0  
      (decision boundary)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#24,24," 
25+
++ ++-
--
-
+Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
+Score( x) < 0
Score( x) > 0
x1 = #eccezionalex2 = #terribiler:  1.0 + 2.7 x1 - 2.1 x2 = 0 
    (decision boundary)Score( x) = 1.0 + 2.7 x1 - 2.1 x2"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#25,25," 26
ˆyi= sign[Score( xi)]Nel caso in cui i termini siano d possiamo calcolare il punteggio 
come segue:
e classiﬁcare la review in questo modo:
Punteggio di una frase 
(
Score
 ) 
dove:
sign(Score) =⇢+1 se Score >0
 1 se Score <0"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#26,26," 27ˆyi= sign[Score( xi)]Score( xi)= w0 0(xi)+w1 1(xi)+ ···+wD D(xi)=
=DX
j=0wj j(xi)=wT· (xi)Nel caso generale di classiﬁcazione binaria abbiamo:
Punteggio di una frase 
(
Score
 ) "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#27,27,"Afﬁdabilità della Previsione 
 28•La funzione sign vista in precedenza ci fornisce una 
classiﬁcazione binaria del sentiment della revisione. 
•Potremmo però essere interessati anche ad avere un grado di 
conﬁdenza della previsione. 
•Ad esempio, potremmo voler distinguere il caso di uno 
Score di poco superiore allo zero (e.g., 0.1) dal caso di uno 
Score ben più elevato (e.g., 4.0), punteggi che in entrambi i 
casi danno luogo a review positive. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#28,28,"Probabilità come “degree of belief” 
 290 1P(yi = +1)
Assolutamente certo 
review negative0.5
Assolutamente certo 
review positive
Non so se le review  
sono positive o negative•A tale scopo possiamo avvalerci del calcolo delle probabilità. 
•Se diciamo che la probabilità di avere y i = +1 è di 0.7, vogliamo 
dire che ci aspettiamo di avere nell’insieme delle review 
disponibili il 70% di review positive. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#29,29,"Probabilità come “degree of belief” 
Probabilità Condizionate 
 30•E’ molto utile in tale contesto considerare le probabilità 
condizionate. 
•Se diciamo ad esempio che la probabilità di avere una review 
positiva, condizionata al fatto di avere nella review 3 occorrenze 
di “eccezionale” ed 1 di “terribile”, è di 0.9, vogliamo dire che ci 
aspettiamo il 90% delle review positive nella lista delle review 
disponibili, considerando però solo quelle che hanno 3 
“eccezionale” e 1 “terribile” (in verde nella ﬁgura che segue). "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#3,3,"Introduzione alla Classiﬁcazione
In buona sostanza, un classiﬁcatore realizza un mapping: 
dove  
    è l’
 instance space
 , ossia l’insieme di tutte le possibili 
istanze del problema. Se esse sono descritte da un numero 
precisato di features, abbiamo: 
 
    è un ﬁnito e in genere piccolo insieme di 
 class labels
 : 
 
4C
C=[C1,C2,...,C k]X!C
X=[F1⇥F2⇥···⇥FD]X"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#30,30," 
31 xi : testo della review yi: sentiment
Il cacio e pepe era delizioso. +1
La carbonara era eccezionale. L’ambiente terribile. Il servizio eccezionale. 
Complessivamente un ristorante eccezionale.+1
Mia moglie ha preso i carcioﬁ alla romana, che erano pessimi. -1
………… -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale +1P(y i = +1| 3 eccezionale & 1 terribile) = 0.9Probabilità come “degree of belief” 
Probabilità Condizionate "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#31,31," 320 1P(yi = +1| xi)
Assolutamente certo 
che xi è negativa0.5
Assolutamente certo 
che xi è positiva
Non sono sicuro se la xi  
è positiva o negativaIn generale, dato un input xi, (e.g., una review) abbiamo la 
seguente situazione: Probabilità come “degree of belief” 
Probabilità Condizionate "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#32,32,"Link Function 
 33Score( xi, w)- ∞ + ∞ •Il problema che dobbiamo risolvere, se vogliamo avvalerci delle 
probabilità condizionate, è capire come passare dai valori dello 
Score a quelli delle probabilità. 
•La funzione Score ha un range che va da -∞ a +∞: 
•La probabilità, come sappiamo, può variare da 0 a 1:  
0 1P(yi = +1| xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#33,33," 34Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = g[Score( xi, w)]Link Function 
•Dobbiamo pertanto deﬁnire una “link function” g (generalized 
linear model ) che realizzi un mapping tra i due intervalli: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#34,34," 
35
•Una funzione tipicamente usata in questi casi è la funzione 
logistica , o sigmoide , così deﬁnita:Link Function 
•Essa, come si vede, ha l’insieme di deﬁnizione costituito 
dall’intervallo (-∞, +∞) e come codominio l’intervallo [0, 1].  "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#35,35," 36Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = sigmoid [Score( xi, w)]Logistic Regression Model 
•Il nostro modello diventa dunque il seguente: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#36,36," 37Logistic Regression Model 
•L’espressione per la probabilità, dato un ingresso xi ed un vettore 
dei pesi calcolato ŵ, è dunque la seguente: 
ˆP(yi=+ 1 |xi,ˆw)=1
1+e ˆwT· (xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#37,37," 38Il Processo di Training 
•Il processo di training consiste nel deﬁnire una funzione di costo, 
o una funzione che misura la “qualità” della previsione, e nel 
determinare la conﬁgurazione dei pesi (vettore w) che ottimizza 
la funzione per gli esempi di training. 
•Nella ﬁgura che segue sono mostrati i passi relativi a tale 
processo. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#38,38,"Il Processo di Training 
[caso della Classiﬁcazione]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
metrica 
valutazione 
qualità
Calcolo vettore 
dei pesi ŵyi osservato(xi)
 39xi
Funzione  
valutazione 
qualitàŵɸ
(N esempi)
Algoritmo di 
ApprendimentoˆP(yi=+ 1 |xi,ˆw)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#39,39,"Funzione per Valutazione Qualità 
 
40•Dobbiamo ora deﬁnire una funzione che possiamo usare per la 
valutazione della qualità delle prestazioni del sistema. 
•A tal ﬁne possiamo prendere in considerazione le probabilità 
condizionate deﬁnite in precedenza. 
•in particolare, per ciascuno degli esempi di training ( xi, yi) che 
abbiamo disponibili, possiamo calcolare la probabilità di avere in 
uscita un valore y i dato un vettore di pesi w (vedi ﬁgura seguente). "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#4,4,"Introduzione alla Classiﬁcazione
 
5
Vediamo un semplice esempio di classiﬁcazione: 
Supponiamo di voler addestrare un computer a distinguere 
immagini di gatti da immagini di cani (
 task
). 
•
Dobbiamo innanzi tutto procurarci un certo numero di 
immagini (
 training set
 ) in modo da poter addestrare il 
computer: 
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#40,40,"Maximum Likelihood Estimation 
(
MLE
)
 
41Data Point xi,1 xi,2 yi Scegliere w che massimizza:
x1, y1 2 1 +1 P(y 1=+1| x1, w)
x2, y2 0 2 -1 P(y 2=-1| x2, w)
x3, y3 3 3 -1 P(y 3=-1| x3, w)
x4, y4 4 1 +1 P(y 4=+1| x4, w)
L(w)=P(y1|x1,w)·P(y2|x2,w)·P(y3|x3,w)·P(y4|x4,w)La funzione che possiamo usare per la valutazione della qualità è: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#41,41," 
42L(w)=NY
i=1P(yi|xi,w)La forma generale della funzione Likelihood  è:
L’obiettivo è dunque quello di massimizzare tale funzione, ad 
esempio mediante Hill Climbing (o Gradient Ascent ), visto che 
non si ha una forma chiusa:
max
wL(w) = max
wNY
i=1P(yi|xi,w)
Maximum Likelihood Estimation 
(
MLE
)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#42,42," 
43•Per il calcolo del gradiente dobbiamo calcolare le varie derivate parziali 
della funzione. 
•Possiamo sempliﬁcare tale calcolo trasformando la funzione,  
considerando il logaritmo naturale del Likelihood: 
•In tal modo trasformiamo i prodotti in somme, pur non cambiando il 
punto di massimo assoluto. Infatti si ha:lnL(w)=l nNY
i=1P(yi|xi,w)=NX
i=1lnP(yi|xi,w)
ˆw= argmax
wL(w) ˆwln= argmax
wlnL(w) ˆw=ˆwln
Log-Likelihood 
[facilita l'operazione di derivazione]"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#43,43,"Log-Likelihood 
[facilita l'operazione di derivazione]
 
44
dove è stata utilizzata la Indicator Function :Per facilitare i calcoli possiamo riscrivere la funzione come segue:
lnL(w)=NX
i=1lnP(yi|xi,w)=
=NX
i=1{I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi= 1]·lnP(yi= 1|xi,w)}"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#44,44," 
45
Log-Likelihood 
[facilita l'operazione di derivazione]
Sostituendo alle probabilità P le seguenti espressioni:
otteniamo, per un solo punto  i, la forma che segue:P(yi=+ 1 |xi,w)=1
1+e wT· (xi)
P(yi= 1|xi,w)=1  P(yi=+ 1 |xi,w)=1 1
1+e wT· (xi)=
=1+e wT· (xi) 1
1+e wT· (xi)=e wT· (xi)
1+e wT· (xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#45,45,"Forma della Funzione da Derivare 
[per un punto 
 i
] 
 
46lnL(w)= I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi= 1]·lnP(yi= 1|xi,w)=
= I[yi= +1] ·ln1
1+e wT· (xi)+( 1 I[yi= +1]) ·lne wT· (xi)
1+e wT· (xi)=
= I[yi= +1] ·ln(1 + e wT· (xi))+
+(1 I[yi= +1]) ·[ wT· (xi) ln(1 + e wT· (xi))] =
= (1 I[yi= +1]) wT· (xi) ln(1 + e wT· (xi))"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#46,46," 
47
Regole applicate:
lne wT· (xi)
1+e wT· (xi)=l n ( e wT· (xi)) ln(1 + e wT· (xi))=
= wT· (xi) ln(1 + e wT· (xi))ln1
1+e wT· (xi)= ln(1 + e wT· (xi))
Forma della Funzione da Derivare 
[per un punto 
 i
] "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#47,47," 
48lnL(w)= (1 I[yi= +1]) wT· (xi) ln(1 + e wT· (xi))
Forma della Funzione da Derivare 
[per un punto 
 i
] "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#48,48,"Derivata Parziale per un punto
 
49dove:
e:Per uno solo punto i abbiamo:
@(wT· (xi))
@wj= j(xi)@lnL(w)
@wj= (1 I[yi= +1]) ·@(wT· (xi))
@wj @
@wjln(1 + e wT· (xi))=
= (1 I[yi= +1]) · j(xi)+ j(xi)·P(yi= 1|xi,w)=
= j(xi){I[yi= +1] P(yi=+ 1 |xi,w)}
@
@wjln(1 + e wT· (xi))=  j(xi)·e wT· (xi)
1+e wT· (xi)=  j(xi)·P(yi= 1|xi,w)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#49,49,"Derivata parziale su tutti i punti
 
50Sommando su tutti i punti i otteniamo:
Questa è la forma della derivata parziale che possiamo usare 
nell’algoritmo di Gradient Ascent  per trovare il vettore ŵ che 
ottimizza la funzione:@lnL(w)
@wj=NX
i=1 j(xi){ tra valore vero e predettoz }| {
I[yi= +1] P(yi=+ 1 |xi,w)}"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#5,5,"Introduzione alla Classiﬁcazione
 
6
•
Dobbiamo poi identiﬁcare le caratteristiche distintive 
(
features
 ) che ci possano consentire di distinguere le due 
tipologie di immagini. Nel nostro caso potremmo ad esempio 
scegliere le due seguenti: 
•
Dimensione del naso (da piccolo a grande) 
•
Forma delle orecchie (da arrotondate ad appuntite) 
supponendo di essere in grado di estrarle dalle immagini. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#50,50,"Algoritmo di Gradient Ascent
 
51w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrlnL(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1 j(xi){I[yi= +1] P(yi=+ 1 |xi,w(t))}
w(t+1)
j w(t)
j+↵⇤derivata parziale[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#51,51,"Riferimenti
 
52
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#6,6,"Introduzione alla Classiﬁcazione
 
7
•Se rappresentiamo le immagini del training set nello spazio 
delle features , abbiamo le seguente situazione, in cui le varie 
immagini appaiono ben aggregate:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#7,7,"Introduzione alla Classiﬁcazione
 
8•Ora che abbiamo una buona rappresentazione dei dati di 
training nello spazio delle features, l’ultimo passo per 
addestrare il computer a distinguere le immagini dei gatti da 
quelle dei cani è un problema geometrico: 
•identiﬁcare un modello (ad esempio un linear model ) che 
separi chiaramente i gatti dai cani nello spazio delle 
features."
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#8,8,"Introduzione alla Classiﬁcazione
 
9
•La ﬁgura che segue mostra un modello lineare (la retta in nero) 
“addestrato” ( trained linear model ), che divide lo spazio delle 
features in due regioni. 
•Una volta determinata questa linea, una nuova immagine la cui 
rappresentazione sta al di sopra della linea (regione blu) sarà 
considerata dal computer relativa ad un gatto. Se invece sta 
sotto la linea sarà considerata relativa ad un cane. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#9,9,"Introduzione alla Classiﬁcazione
 
10
•Per veriﬁcare l’efﬁcacia del sistema dobbiamo valutare le sue 
prestazioni su un insieme di immagini ( test set ) distinte da 
quelle usate per l’addestramento: "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#0,0,"Programmazione
Orientata agli Oggetti
Introduzione al Linguaggio di 
Programmazione Java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
Breve riassunto della storia del linguaggio Java
–Motivazioni del linguaggio e scelte progettuali
–Versione di Riferimento
Macchina virtuale JVM
La portabilità e la piattaforma Java
Librerie Standard Java
Java vs C
Java vs C++
Controllo del Flusso
Tipi di dato primitivi
–Un tipo molto particolare : String
Errori a tempo di compilazione e di esecuzione
Diagnostica in Java vs in C
Limiti del Paradigma Procedurale"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#10,10,"Programmazione orientata agli oggetti
Compilazione Nativa vs JVM
Codice C
001010101
0101011111
00010101Codice
Java
Java
BytecodeJVM
Compilazione Compilazione.java
.class"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#11,11,"Programmazione orientata agli oggetti
Java e Portabilità
●Java è supportato praticamente da tutti i sistemi 
operativi più diffusi (Mac OS, Windows, Linux)
●E da altrettante piattaforme hardware
—Lo stesso programma Java può essere eseguito su 
tutte le piattaforme che dispongono di una JVM
—Senza bisogno di ricompilarlo!
●Basta spostare i file .class
●Java permette di scrivere programmi altamente portabili
—Senza preoccuparsi di quali operazioni siano 
supportate da quali piattaforme
—N.B. Tuttavia le piattaforme sottostanti sono diverse, 
e talvolta rimane possibile osservarne le differenze 
anche programmando in Java
●Ad es. nomi dei file (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#12,12,"Programmazione orientata agli oggetti
Java e Portabilità: Dov’Eravamo 
Rimasti? Il Linguaggio C...
●Ad esempio, il seguente codice in C ha un comportamento 
indefinito
int i = 127;
i = i++;
●In C la rappresentazione dei tipi predefiniti non possiede 
una dimensione fissata da uno standard
✔Un int è grande quanto la parola del microprocessore 
usato. Rappresentazione degli interi a  8, 16 o 32 bit? 
Dipende dalla piattaforma: possibile overflow!
—Se ++ viene eseguito prima dell'assegnazione allora il valore 
in i sarà 1 (incrementa i a 2 ma il risultato, assegnato a i, è 
1)
—Se ++ è eseguito dopo l'assegnazione allora il valore in i 
sarà 2.
●Il comportamento dipende anche dalla precedenza data dal 
compilatore alle diverse operazioni"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#13,13,"Programmazione orientata agli oggetti
Portabilità del Codice Java
●In Java la sintassi e la semantica del linguaggio 
è ben definita e coerente su tutte le 
implementazioni della JVM
●Sono descritte in un documento noto come
Java Language Specification
—Eventuali ambiguità residuali sono progressiva-
mente identificate, quindi rimosse e/o accettate
●Le istruzioni non dipendono da una particolare 
piattaforma
—rimangono le stesse per ogni piattaforma hardware"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#14,14,"Programmazione orientata agli oggetti
Librerie di Java
●Altro principale motivo del successo di Java: 
distribuizione congiunta linguaggio e librerie
Piattaforma Java = Linguaggio + Compilatore + Librerie +...
●In C la libreria standard permette di gestire
—la memoria ( malloc, free , ...)
—l'I/O (FILE, printf, scanf , ...)
—le stringhe ( strcpy, strcat , ...)
—ecc. ecc....
●Ma non esiste il supporto per liste, insiemi, 
array associativi ecc. ecc.
●Tutto si può aggiungere ma..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#15,15,"Programmazione orientata agli oggetti
Librerie Standard di Java
●In Java quasi tutto quello di cui si ha bisogno è già 
presente nella libreria del linguaggio distribuita 
assieme al compilatore ed all’ambiente di 
esecuzione 
—Le collezioni sono presenti in Java da anni
—Librerie spesso sviluppate da esperti del settore
—Usate e testate da migliaia di utenti
●Rarissimo che si trovino ancora bug di significativo 
impatto pratico
●Queste librerie sono > sempre< , invariabilmente,  
meglio delle nostre implementazioni “artigianali”"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#16,16,"Programmazione orientata agli oggetti
Filosofia Java vs C (1)
●Al giorno d’oggi alcune differenze tra il linguaggio C ed il 
linguaggio Java (che pure deriva dal primo), si possono 
interpretare correttamente solo considerando le differenze 
nella filosofia di fondo da cui scaturirono i due linguaggi
●A sua volta queste derivano dalle differenze negli obiettivi 
●A sua volta queste differenze negli obiettivi nascono dalle 
differenze nel contesto in cui i due linguaggi sono nati
—C: nato in cui contesto in cui le risorse di calcolo erano scarse
—Java: era già chiaro che le risolse di calcolo sarebbero state 
sempre meno un problema per gli applicativi ordinari
—Il vero problema (per l’industria) erano i programmatori!
●C: linguaggio di medio livello di astrazione
—Ideato per scrivere parti dei S.O. 
●Java: linguaggio di alto livello di astrazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#17,17,"Programmazione orientata agli oggetti
Filosofia Java vs C (2)
●Java nasce cercando di correggere in tal senso i più 
evidenti difetti dei linguaggi C/C++ rispetto agli  
obiettivi all’epoca sentiti come più nuovi ed urgenti
●C: prestazioni e controllo anzitutto 
—meglio veloce/compatto che semplice e portabile
—non fare nulla se non è richiesto esplicitamente dal 
programmatore a cui si lascia il controllo diretto e quasi 
totale dell’esecuzione
●Java: semplice e portabile anzitutto
—evitiamo gli errori più comuni anche se farlo costa, in 
generale, e non serve sempre: semplicità piuttosto che 
prestazioni e portabilità piuttosto che controllo totale
—togliamo al programmatore alcune responsabilità, 
soprattutto quelle più faticose da gestire correttamente 
(es. gestione memoria)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#18,18,"Programmazione orientata agli oggetti
Java vs C++
●Alcune volte Java sembra veramente limitarsi a 
rimuovere  alcune possibilità aggiuntive offerte dal 
linguaggio di programmazione C++ 
—Il vero competitor iniziale di Java, più del linguaggio C…
●Perché nasce per supportare lo stesso paradigma (>>)
—Java rimuove (e non rimpiazza) i costrutti del linguaggio C++ più 
discutibili rispetto gli obiettivi della piattaforma Java stessa 
●I costrutti rimossi non sono strettamente indispensabili e rendono il 
linguaggio più utile solo per pochissimi esperti
●Contemporaneamente, però, finiscono  per renderlo più difficile da 
utilizzare correttamente da parte di tutti gli altri
●Ad es. in Java non esiste
—Ereditarietà multipla delle implementazioni (sino Java 7)
—Operator overloading
—Costruttore di copia
—Passaggio di parametri per variabile/riferimento
—Puntatori/Aritmetica dei puntatori..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#19,19,"Programmazione orientata agli oggetti
Un Programma Java
●La sintassi è simile al C perché ideata per esserlo
—con lo scopo di attrarre il parco programmatori del 
linguaggio Java, che non furono “sorpresi” dalla 
nuova sintassi
—Java è il più famoso linguaggio C-like ma ne esistono 
altri (C++)
●Ogni programma inizia con l’esecuzione del 
cosidetto metodo  statico main() esattamente come 
in C l’esecuzione comincia dalla funzione statica 
main()
●Curiosamente i nuovi linguaggi (tra tutti Scala) che 
cercano di “scalzare” Java, usano tattiche simili, se 
non addirittura più efficaci
—Compatibilità con la JVM"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#2,2,"Programmazione orientata agli oggetti
Breve Storia (1)
●Java è un linguaggio di programmazione 
sviluppato dalla Sun Microsystems e pubblicato 
nella sua versione 1.0 nel 1995
●Lo sviluppo di Java iniziò nei primi anni '90 sotto 
la guida di James Gosling
—Inizialmente il nome del linguaggio era Oak 
(quercia)
—ed era pensato per sistemi embedded 
(televisori, sportelli bancomat, palmari, ecc...)
●Verso il 1993 l'interesse verso i dispositivi 
embedded, per cui Java era stato pensato, crollò
—Java aveva (ben presto!) perso il suo originale e 
principale dominio di applicazione!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#20,20,"Programmazione orientata agli oggetti
Programma in C vs Java (1)
●Un programma che stampa tutti gli argomenti 
passati da linea di comando
●In C:
#include<stdio.h>
int main(int argc, char *argv[]) {
int i = 0;
for (i=0; i<argc; i++)
printf(“%s\n”, argv[i]);
return 0;
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#21,21,"Programmazione orientata agli oggetti
Programma in C vs Java (2)
●In Java (scriviamo un file JavaApp.java ):
public class JavaApp {
public static void main(String[] args) {
for (int i=0; i<args.length; i++)
System.out.println(args[i]);
}
}
Per eseguirlo (da linea di comando):
$ javac JavaApp.java
$ java JavaApp ciao mondo
$ ciao mondoCompilazione 
in ByteCode
Esecuzione 
tramite la JVM"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#22,22,"Programmazione orientata agli oggetti
Metodo main()
●Ogni programma Java inizia con l'esecuzione del main()
—La dichiarazione del metodo deve essere preceduta 
dalla parola chiave static
—N.B. usiamola per questo scopo ma dimentichiamoci 
della sua esistenza per le lezioni a venire (>>)
●Il main()
—Non restituisce alcun valore
●Il suo tipo di ritorno è void
—Prende in ingresso un array di stringhe
●String[] args
—argomento passato da linea di comando a sostituire la 
coppia di parametri in C
●char *argv[]
●int argc"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#23,23,"Programmazione orientata agli oggetti
Java: Produrre Stampe
●Per stampare sullo schermo è possibile usare
System.out.println( <valore> )
●println  stampa <valore>  e si posiziona su 
una nuova riga
●Il tipo del parametro attuale di println()  può 
essere qualsiasi:
—int, boolean, float, double, String , ..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#24,24,"Programmazione orientata agli oggetti
Tipi di Dato Primitivi Java
●N.B. a differenza che nel linguaggio C, la dimensione della 
rappresentazione di questi tipi di dato primitivi non dipendono 
dalla piattaforma, ma sono fissati (per sempre) nella JLS
●Java supporta  i seguenti tipi primitivi
—int
interi a 32 bit (da  -231 a 231 – 1)
—long
interi a 64 bit (da -263 a 263 – 1)
—char
caratteri in codifica UTF-16 (alfabeto latino,
arabo, greco, cinese, giapponese, ecc....)
—float
numeri in virgola mobile a 32 bit
—double
numeri in virgola mobile a 64 bit
—Altri tipi di dato primitivi meno usati ..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#25,25,"Programmazione orientata agli oggetti
Dichiarazione di Variabili
●Per dichiarare una variabile si usa la seguente 
sintassi: <tipo> <nome>;
int eta = 18;
●Java è case sensitive quindi eta != Eta != 
eTa != ETA != ... 
●Per evitare ambiguità (differentemente dal 
linguaggio C), ad ogni variabile deve essere 
assegnato un valore prima del suo utilizzo
✔In caso contrario la compilazione non andrà a 
buon fine"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#26,26,"Programmazione orientata agli oggetti
Tipo Booleano in Java
●A differenza di quanto accade nel linguaggio C, 
Java ha un tipo dedicato per le variabili 
booleane:
—boolean
variabili di tale tipo possono avere solo due 
valori: true e false
●Java offre i gli operatori logici and e or con la 
seguente  sintassi:
—And: &&
—Or: ||"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#27,27,"Programmazione orientata agli oggetti
Sistema dei Tipi Java
●Ogni variabile ha un certo tipo e può assumere solo 
valori appartenenti al dominio  di quel tipo
—Il tipo di una variabile deve essere specificato al 
momento della sua dichiarazione
int eta = 18;
—Se ad una variabile si assegna un valore non 
appartenente al dominio del suo tipo si genera 
un errore durante la compilazione
eta = false;
●Il comportamento di Java e C sono simili
●Sono entrambi linguaggi staticamente  tipati
✔già durante la compilazione deve essere noto il 
tipo di ogni dato utilizzato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#28,28,"Programmazione orientata agli oggetti
Il Tipo di Dato String
●Java introduce il tipo di dato String per 
rappresentare stringhe
—String  non è un tipo di dato primitivo (come ad es. 
int, double , …)
—Le stringhe, per diffusione ed importanza, hanno da 
subito meritato un supporto molto particolare dal 
linguaggio (e dal compilatore)
—si volevano attirare programmatori non esperti 
facilitando l’utilizzo delle stringhe
–È possibile dichiarare una variabile di tipo String ed 
assegnargli un valore come segue:
String nome = ""Bob"";
System.out.println(nome); // stampa Bob"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#29,29,"Programmazione orientata agli oggetti
String
●I letterali di tipo stringa sono compresi tra doppi 
apici
—""una stringa ""
●A differenza di C, è possibile assegnare più volte 
ad una variabile di tipo String  un letterale di 
stringa
String nome = ""Bob"";
nome = ""Alice""; // ok
System.out.println(nome); // Stampa Alice
●Molte operazioni sulle stringhe offerte direttamente 
dalle librerie Java distribuite con la piattaforma (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#3,3,"Programmazione orientata agli oggetti
Breve Storia (2)
●Tuttavia, sempre  nel 1993, la NCSA rilasciò  Mosaic
—Uno dei primi browser con interfaccia grafica
—Rese più accessibile Internet
●Il team di Java decise allora di dedicarsi allo sviluppo di 
un sistema embedded per i browser: le applet
—Le applet sono/erano piccole applicazioni che 
potevano essere eseguite all'interno del browser
●Lo scopo era quello di arricchire le pagine web 
tramite l'uso di contenuto interattivo
●Perché il concetto era rivoluzionario? il codice veniva 
scaricato da remoto ed eseguito (in maniera sicura) 
localmente. Javascript  non c’era ancora...
●Ci fu un significativo effetto traino. Ma oggi, quanti 
sanno cosa sia un’applet?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#30,30,"Programmazione orientata agli oggetti
Controllo del Flusso
●Le istruzioni per il controllo del flusso sono le 
stesse del C
—La sintassi è esattamente  la stessa
●Sono quindi presenti
—if e else
—switch , break
—for, while , do while
●break e continue"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#31,31,"Programmazione orientata agli oggetti
Controllo del Flusso
●Essendo presente il tipo boolean , le condizioni sono 
sempre espresse su espressioni di tipo boolean
int i = 0;
if (i) { … } 
●In Java NON compila
●In C è prassi comune eseguire controlli direttamente 
su espressioni di tipo int
char stringa[] = “null terminated”;
int c = 0;
while (stringa[c]) {
 printf(“%c\n”, stringa[c]);
 c++;
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#32,32,"Programmazione orientata agli oggetti
Errori: Tempo di Compilazione vs 
Tempo di Esecuzione
●Due momenti ben distinti in cui si può 
riscontrare un errore in un programma
—A tempo di compilazione
—A tempo di esecuzione
●La rapida risoluzione degli errori in tempi brevi, è 
importante per la produttività
●La diagnostica dovrebbe sempre riportare il 
motivo dell'errore e la posizione esatta in cui si è 
verificato
●La diagnostica del C talvolta risulta “vaga”
—Soprattutto per gli errori a tempo di esecuzione
Segmentation fault"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#33,33,"Programmazione orientata agli oggetti
Diagnostica
●La diagnostica è decisamente uno dei principali 
punti forti della piattaforma Java
●Permette di trovare gli errori di entrambi i tipi per risolverli 
tempestivamente, così riducendo:
—i tempi di ricerca degli errori (debugging)
—i costi
●Buona parte di questi vantaggi (soprattutto a tempo 
dinamico) derivano dall’adozione di un processore 
virtuale (JVM)
✔Ottenere le stesse funzionalità con un processore 
fisico è decisamente più ostico 
●Consiglio:  
Abituarsi fin da subito ad un uso ossessivo della diagnostica"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#34,34,"Programmazione orientata agli oggetti
Errori a Tempo di Compilazione
public class Prova {
public static void main(String[] args) {
System.out.println(""hi"")
}
}
Exception in thread ""main"" java.lang.Error: 
Unresolved compilation problem: 
Syntax error, insert "";"" to complete 
BlockStatements
at Prova.main(Prova.java:3)Il problemaDove si è 
verificato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#35,35,"Programmazione orientata agli oggetti
Errori a Tempo di Esecuzione (1)
●Gli errori a tempo di esecuzione sono 
decisamente più temibili
—Si verificano durante l'esecuzione del codice, 
non sono né riconoscibili né prevedibili dal 
compilatore
—In Java, gli errori a tempo di esecuzione sono 
spesso anche detti runtime- exception
●prendendo in prestito il  nome del costrutto del 
linguaggio pensato per gestirli (>>) 
●Anche in questo caso la diagnostica è molto precisa"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#36,36,"Programmazione orientata agli oggetti
Errori a Tempo di Esecuzione (2)
public class Prova {
public static void main(String[] args) {
int infinito = 1/0;
System.out.println(infinito);
}
}
La compilazione va a buon fine ma durante 
l'esecuzione si ha
Exception in thread ""main"" 
java.lang.ArithmeticException: / by zero
at Prova.main(Prova.java:3)Il problemaDove si è 
verificato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#37,37,"Programmazione orientata agli oggetti
Paradigma di Programmazione 
●Il paradigma di programmazione  influenza 
decisamente il modo di programmare
●Non esiste una definizione comunemente 
accettata di paradigma di programmazione
(e forse neanche serve...)
●Con un pò di esperienza inter-paradigma risulta 
facile apprezzare come un linguaggio di 
programmazione rende un paradigma più 
semplice da esprimere rispetto ad altri linguaggi
●Il vostro corso di studi ne tiene conto!
—Procedurale: FdI  -  I anno (Linguaggio C)
—Oggetti: POO  - II anno (Linguaggio Java)
—Funzionale: PF  - III anno (Linguaggio OCaml)
—Paradigma Ibrido Oggetti/Funzionale (Scala )"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#38,38,"Programmazione orientata agli oggetti
Il Paradigma Procedurale
●Il paradigma procedurale è stato il primo a diffondersi 
●La divisione tra dati ed operazioni è tipica 
dell'hardware moderno (memoria/CPU) e 
dell’architettura di Von Neumann
—T ale divisione impone che i dati siano sempre separati 
dalle operazioni
—La correlazione tra dati ed il codice che li lavora non è 
esplicita  
●Nel paradigma procedurale un programma è 
specificato come una sequenza di comandi che 
cambiano lo stato dell’esecuzione, passo dopo passo
●Il C è un linguaggio di programmazione che rende 
naturale esprimere il paradigma procedurale
●In effetti è un linguaggio “vicino alla macchina”"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#39,39,"Programmazione orientata agli oggetti
Limiti del Paradigma Procedurale (1)
●Uno dei maggiori limiti del paradigma procedurale 
è proprio la netta separazione tra dati ed 
operazioni sugli stessi
—lo stato è ben distinto e separato dalle operazioni
●Dati e funzioni che li lavorano, sono comunque 
separati nel codice
struct Persona {
const char* nome;
int eta;
};
int isMaggiorenne(struct Persona persona) {
return ( persona.eta >= 18 );
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#4,4,"Programmazione orientata agli oggetti
Breve Storia (3)
●Le applet sono ormai obsolete
–Ma cavalcando gli anni della diffusione di massa di internet, 
hanno sicuramente contribuito a rendere Java uno dei 
linguaggi più popolari tra gli sviluppatori dell’epoca
●La popolarità e diffusione di Java sono dovuti a molti fattori 
●Tra i principali sicuramente l’incremento di produttività dei 
programmatori che lo adottarono
●Java semplifica alcuni aspetti rispetto al C/C++
—possiede un gran numero di strumenti facenti parte della 
piattaforma  che semplificano grandemente lo sviluppo
—riduce significativamente il livello di expertise  necessario 
ad un programmatore per essere produttivo
—In sintesi, Java ampliò la disponibilità di manodopera  (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#40,40,"Programmazione orientata agli oggetti
Limiti del Paradigma Procedurale (2)
●È del tutto legittimo avere operazioni sugli 
stessi dati in luoghi anche molto distanti del 
codice
●Addirittura incentivata(!) la ripartizione dei due 
aspetti in file distinti
●La definizione di un tipo di dato in C specifica 
solo i dati componenti ma non le operazioni 
che vi si possono applicare
—queste sono definite altrove e non fanno parte 
della definizione del tipo di dato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#41,41,"Programmazione orientata agli oggetti
Limiti del Paradigma Procedurale (3)
struct Persona {
const char* nome;
int eta;
};void invecchia(struct Persona *p) {
p->eta = p->eta + 1;
}
int isMaggiorenne(struct Persona p) 
{
return ( p.eta >= 18 );
} File: Persona.h File: Persona.c
Dati                        Operazioni
●Il tipo di dato Persona  non definisce le operazioni che 
possono essere eseguite sul tipo stesso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#5,5,"Programmazione orientata agli oggetti
Breve Storia (4)
●Oltre 20 anni dopo la nascita e la sua diffusione di massa, 
rimane molto adottato sia nell’industria che 
nell’accademia
●T alvolta forse addirittura con eccessivo entusiasmo 
(RM3!)
●Ha conosciuto nuovi ed importanti ambiti di utilizzo
–Applicazioni su Web
–Sistemi embedded
–App Android
–E molti altri ancora (“ 3 Billion Devices Run Java ”)
●Vari motivi dietro la durata di questo successo (>>)
—pur avendo accumulato molti difetti, ha saputo innovarsi 
senza rompere la retro-compatibilità, che rimane un 
obiettivo dogmatico nonostante il succedersi di 
numerose nuove versioni, talune anche molto innovative"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#6,6,"Programmazione orientata agli oggetti
Quanto è Popolare Java?
https://www.tiobe.com/tiobe-index/Java 8
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#7,7,"Programmazione orientata agli oggetti
Da Java 1 a Java 17 in ~25 Anni
●Java 1.0: 1995, la prima versione di Java
●Java 1.1: 1997, Inner Classes e Reflection
●Java 1.2: 1998, Just In Time Compiler introdotto nella JVM di Sun, 
  Java Collections Framework
●Java 1.3: 2000
●Java 1.4: 2002
●Java 1.5 / 5: 2004, Generics, Auto boxing/unboxing, Enum, Varargs, for each loop
●Java 1.6 / 6: 2006
●Java 1.7 / 7: 2011
●Java 1.8 / 8: 2014, “Deriva funzionale”, lambda expressions
●Java 9: 2017, “Moduli”
●Java 10: 2018
●Java 11: 2019
●…
●Java 17!: 2021
●… e presto seguiranno altre: rilasci semestrali(Cambio politica dei rilasci, ora accellerati)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#8,8,"Programmazione orientata agli oggetti
La Portabilità di Java
●Java ha rivoluzionato il concetto di portabilità
●Uno dei principi fondamentali di Java
—Write Once Run Anywhere
—Un programma Java può essere eseguito su tutte 
le piattaforme che supportano Java senza dover 
ricompilare il codice  per quella specifica 
piattaforma
●Java è infatti nato come un linguaggio 
interpretato
—Il risultato della compilazione è il cosiddetto 
Bytecode : codice oggetto che può essere eseguito 
da un processore virtuale noto come
Java Virtual Machine (JVM)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-01-introduzione-java-da-C.pdf#9,9,"Programmazione orientata agli oggetti
JVM vs Codice Nativo
●Una JVM è, banalizzando, un processore “software” 
●Programma in grado di interpretare ed eseguire codice 
oggetto Java (bytecode) letto da file di 
estensione .class
—I dispositivi che supportano Java forniscono una 
implementazione della JVM per il sottostante hardware
●Il Bytecode può essere eseguito su qualunque computer 
che disponga di una implementazione della JVM
–Al contrario, i compilatori C generano codice nativo 
eseguibile solo su un particolare hardware
–Un programma C deve essere ricompilato  per ogni 
piattaforma su cui si desidera eseguirlo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#0,0,"Programmazione
Orientata agli Oggetti
Introduzione al Paradigma di 
Programmazione Orientato 
agli Oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
●Paradigmi di Programmazione
–Il Paradigma Orientato agli Oggetti
–Classi
–Oggetti
–Esercizio con Eclipse
–Gli oggetti in Rete
●La notazione puntata
●Stato degli oggetti
–Variabili di istanza
–Inizializzazione
–Campo d’Azione (Scope)
●Comportamento degli oggetti
–Metodi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#10,10,"Programmazione orientata agli oggetti
Oggetti: Stato + Comportamento (1)
●Secondo il paradigma OO l’esecuzione di un 
programma avviene con la creazione di un rete di 
oggetti che si scambiano messaggi, aggiornano ed 
interrogano il proprio stato durante l’esecuzione
●Ogni oggetto
—possiede  uno stato interno
—offre operazioni agli altri oggetti
●Gli oggetti sono dotati di:
—Stato: informazioni memorizzate in variabili di istanza  
(o campi o attributi)
—Comportamento : metodi  che si possono invocare 
sull'oggetto
—Identità : un oggetto può essere distinto dagli altri (anche 
e soprattutto da esemplari  della stessa tipologia)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#11,11,"Programmazione orientata agli oggetti
Oggetti: Stato + Comportamento (2)
●Ad esempio l'oggetto Giocatore  possiede come 
stato il suo nome e la stanza in cui si trova
●È possibile chiedere all’oggetto Giocatore  di 
compiere delle azioni
—ad es. getStanzaCorrente()  per  ottenere 
l’oggetto che rappresenta la stanza corrente
—ad es. setStanzaCorrente()  per spostarsi 
nella prossima stanza
●Può servire quindi interrogare l’oggetto Stanza
—ad es. getStanzaAdiacente()  per ottenere 
l’oggetto che rappresenta la stanza 
adiacente a quella considerata corrente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#12,12,"Programmazione orientata agli oggetti
Classe (1)
●Possono esistere vari oggetti dello stesso tipo
—diverse stanze; attrezzi; giocatori
●Tutti gli oggetti di un certo tipo possiedono le  
informazioni dello stesso tipo
—tutte le stanze hanno un nome ed una o più 
stanzaAdiacente
●Tutti gli oggetti di un certo tipo offrono le 
stesse operazioni
—A tutti i giocatori è possibile chiedere di spostarsi 
nella prossima stanza o di raccogliere un oggetto 
Attrezzo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#13,13,"Programmazione orientata agli oggetti
Classe (2)
●È necessario un meccanismo per costruire oggetti:
1)Possiedono una propria identità ed autonomia 
2)Possiedono informazioni e dati specifici...
3)...ma sembrano chiaramente rispondere anche ad altri tratti 
comuni a tutti gli oggetti della stessa tipologia
●Serve una sorta di fabbrica specializzata  che definisca 
come tutti gli oggetti di un certo tipo siano fatti 
lasciando la libertà di variare alcuni aspetti
●Si pensi ad un fabbrica di Orologi  tutti uguali
1)Ciascun esemplare è distinto dagli altri
2)Ciascun esemplare ha un numero di serie ed un colore 
diverso...
3)…ma tutti offrono la possibilità di leggere l’ora
●Nella programmazione orientata agli oggetti queste 
fabbriche sono dette classi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#14,14,"Programmazione orientata agli oggetti
Classe (3)
●Per ogni tipo di oggetto che si vuole rappresentare 
esiste una classe
—Una per Giocatore , una per Stanza , ecc...
●Tutti gli oggetti sono costruiti  a partire dalla 
definizione di una classe
●La classe astrae e definisce
—lo stato di un oggetto di un certo tipo
—il comportamento degli oggetti di un certo tipo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#15,15,"Programmazione orientata agli oggetti
Classe, un Esempio
●Tralasciamo per ora le stanze, gli attrezzi e i 
giocatori… T orneranno più tardi (>>)
●Più semplice utilizzare forme geometriche in un 
piano cartesiano con coordinate intere per un 
primo esempio di classe
—per rappresentare una forma è necessario 
conoscerne la posizione
—servono le coordinate di un punto sul piano 
cartesiano: x, y
●si definisce una classe Punto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#16,16,"Programmazione orientata agli oggetti
La Classe Punto (1)
public class Punto {
private int x;
private int y;
public void setX(int posX) {
x = posX;
}
public void setY(int posY) {
y = posY;
}
public int getX() {
return x;
}
public int getY() {
return y;
}
}Stato
Operazioni, per 
impostare e 
leggere lo stato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#17,17,"Programmazione orientata agli oggetti
La Classe Punto (2)
public class Punto {
private int x;
private int y;
public void setX(int posX) {
x = posX;
}
public void setY(int posY) {
y = posY;
}
public int getX() {
return x;
}
public int getY() {
return y;
}
}Ogni oggetto di tipo 
Punto ha una x e una y
variabili d’istanza
Inoltre, dispone di una 
serie di operazioni per 
leggere e impostare il 
suo stato
metodi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#18,18,"Programmazione orientata agli oggetti
Creazione di Oggetti
● La creazione di un oggetto a partire da una classe 
avviene utilizzando l’operatore new:
Punto origine = new Punto();
●Restituisce un riferimento  ad un oggetto appena 
creato  
●Ora è presente un oggetto in memoria ed è  
possibile chiedergli di svolgere delle operazioni per 
tramite del riferimento, qui conservato nella 
variabile locale origine  
●Ad esempio per impostare la ascissa ed ordinata
origine.setX(0);
origine.setY(0);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#19,19,"Programmazione orientata agli oggetti
Concetti Correlati ma Ben Distinti!
Questa semplice istruzione 
Punto origine = new Punto();
già nasconde almeno tre concetti 
chiaramente distinti sebbene correlati
I.Variabile locale
II.Riferimento
III.Oggetto:Punto
x1
0:Punto
x0
y0
origineriferimentooggetto
Variabile locale
Ci torneremo più volte sopra!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#2,2,"Programmazione orientata agli oggetti
Il Paradigma Orientato agli Oggetti (1)
●La divisione tra codice e operazioni è tipica 
dell'hardware moderno (memoria/CPU) secondo 
l’architettura di Von Neumann
●Ma gli esseri umani ragionano allo stesso modo?
●Ovvero, quando pensiamo ad un oggetto  pensiamo 
solo al suo stato od anche alle operazioni che vi si 
possono compiere
●Ad esempio… un televisore ...!?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#20,20,"Programmazione orientata agli oggetti
La Notazione Puntata
●Per richiedere un'operazione ad un oggetto si 
usa la cosidetta notazione puntata
<riferimento-oggetto>.<metodo>(<parametri-attuali>);
●Ad esempio:
—origine.setX(0);
●Anche solo questa notazione mostra come i dati 
siano stati  avvicinati  alle operazioni sugli stessi
dati.operazione(parametri)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#21,21,"Programmazione orientata agli oggetti
Classi e Oggetti
●A partire da una classe possiamo creare molte 
istanze,  ognuna dotata di uno stato autonomo
Punto unoZero = new Punto();
unoZero.setX(1);
unoZero.setY(0);
●L'oggetto  creato in precedenza (ovvero quello il cui 
riferimento è conservato dentro origine ) risulta invariato 
dopo tali operazioni e non viene modificato 
dall’invocazione di metodi tramite il riferimento conservato 
dentro unoZero  perché le operazioni sono svolte su un 
oggetto distintoUn nuovo oggetto viene creato in 
memoria; è possibile chiedergli di 
svolgere operazioni attraverso il 
riferimento conservato nella 
variabile locale unoZero"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#22,22,"Programmazione orientata agli oggetti
Terminologia
●
Nella programmazione orientata agli 
oggetti si utilizza la seguente terminologia:
–Oggetti o istanze : istanze di una certa classe, 
presenti in memoria, mantengono lo stato di un 
oggetto
– Metodi : specificano le operazioni che determinano il 
comportamento degli oggetti
•Es.: setX(), getY(), …
–Variabili di Istanza : consentono di memorizzare le 
informazioni di ciascun oggetto (lo stato dell’oggetto)
–Riferimento ad oggetto: un riferimento ad un 
oggetto in memoria (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#23,23,"Programmazione orientata agli oggetti
Classi e File
●In Java, una classe di nome XYZ DEVE essere 
contenuta all'interno di un file di nome XYZ.java
—esistono alcune eccezioni a questa regola che 
tralasciamo per il momento
classi nidificate  (>>)
●Da qualsiasi altra classe del nostro programma 
sarà possibile far riferimento ad una classe 
specificandone il suo nome
—In Java non è necessario importare un file esplicitamente 
per poter usare il codice in esso contenuto
—Ma bisogna mettere il compilatore (e la JVM durante 
l’esecuzione) in condizione di trovarlo a partire dal suo 
nome (>> )"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#24,24,"Programmazione orientata agli oggetti
Esercizio: Eclipse (0)
•JDK (Standard Edition)
–Scaricare ed installare dal sito della ORACLE 
l'ultima versione disponibile di Java 8
https://www.java.com/download/java8_update.jsp
–Recommended Version 8 Update 321
–Oppure Java 11
•Documentazione JDK
–Scaricare ed installare dal sito della ORACLE
•Strumenti di sviluppo 
–Un IDE professionale: Eclipse (4.X)
•Scaricare  Eclipse IDE for Java Developers da 
https://www.eclipse.org/downloads/eclipse-packages/
(è la versione usata anche in sede d’esame)
•Configurare Eclipse per compilare Java 7
25"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#25,25,"Programmazione orientata agli oggetti
Esercizio: Eclipse (1)
●Realizzare la classe Punto usando l'IDE eclipse
—File > New > Java Project
●Project Name: Forme > click su 'Finish'
—Selezionare il progetto appena creato
—File > New > Class
●Name: Punto > click su 'Finish'
●Oltre al codice mostrato prima, aggiungere il metodo
public void trasla(int dx, int dy)  che sposta il 
punto di dx sull'asse x e dy sull'asse y"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#26,26,"Programmazione orientata agli oggetti
Esercizio: Eclipse (2)
Realizzare la classe MainForme  usando l'IDE eclipse
—Creare una classe di nome MainForme
—Aggiungere il metodo main()
public class MainForme {
public static void main(String[] args) {
Punto origine = new Punto();
origine.setX(0);
origine.setY(0);
System.out.println(origine.getX());
System.out.println(origine.getY());
origine.trasla(1, 1);
System.out.println(origine.getX());
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#27,27,"Programmazione orientata agli oggetti
Gli Oggetti in Rete  (1)
●La definizione  di un programma “orientato agli oggetti” 
consiste nella definizione di diverse classi di oggetti
●L’esecuzione  di un programma orientato agli oggetti avviene 
orchestrando lo scambio di messaggi tra un plurarità di 
oggetti istanza delle classi definite nel programma
–gli oggetti devono “ conoscersi”
•un oggetto può possedere riferimenti  verso gli altri oggetti
•gli oggetti possono inviare messaggi ad altri oggetti dei 
quali possiedono un riferimento
●Si vuole realizzare la classe Rettangolo
—Stato composito:
●base
●altezza
●posizione del vertice in alto a sx"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#28,28,"Programmazione orientata agli oggetti
Gli Oggetti in Rete  (2)
●Il vertice in alto a sinistra è un oggetto istanza 
della classe Punto
—di coordinate (x, y)
●Ogni oggetto della classe Rettangolo  deve 
conoscere un oggetto della classe Punto che 
rappresenta il suo vertice in alto a sinistra
basealtezza
vertice
Di tipo Punto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#29,29,"Programmazione orientata agli oggetti
Gli Oggetti in Rete  (3)
:Rettangolo
 base 8
 altezza 3
 vertice
:Punto
 x 0
 y 0riferimento ad oggettooggetto
oggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#3,3,"Programmazione orientata agli oggetti
Il Paradigma Orientato agli Oggetti (2)
●Un problema è più naturalmente modellabile se 
pensato come popolato da una pluralità di 
oggetti che possiedono uno stato ( spento , 
acceso, sintonizzato  su un certo canale)
Televisore , Persona , ecc…
e che interagiscono ciascuno secondo i messaggi 
che sanno naturalmente interpretare:
fabio.accende(tvInSalone)
●Gli oggetti conoscono ed interagiscono con altri 
esemplari (anche dello stesso tipo)
—Un oggetto n11 di tipo Stanza  conosce altri 
oggetti Stanza , ad esempio n12, nelle immediate 
adiacenze a formare un oggetto Labirinto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#30,30,"Programmazione orientata agli oggetti
(Con Eclipse)  La Classe Rettangolo
●Nello stesso progetto della classe Punto
public class Rettangolo {
private int base;
private int altezza;
private Punto vertice;
public void setBase(int b) { base = b; }
public void setAltezza(int a) { altezza = a; }
public void setVertice(Punto v) { vertice = v; }
public int getBase() { return base; }
public int getAltezza() { return altezza; }
public Punto getVertice() { return vertice; }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#31,31,"Programmazione orientata agli oggetti
La Classe Rettangolo (2) 
●Il main() può essere modificato come segue
public class MainForme {
public static void main(String[] args) {
Punto origine = new Punto();
origine.setX(0);
origine.setY(0);
Rettangolo rect = new Rettangolo();
rect.setVertice(origine);
rect.setBase(8);
rect.setAltezza(3);
// …
// Seguono stampe per verificarne il funzionamento
}
}Dopo questa 
istruzione l'oggetto 
istanza di 
Rettangolo  
conosce l'oggetto  
istanza di Punto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#32,32,"Programmazione orientata agli oggetti
Messaggi tra Oggetti (1)
●Si vuole implementare il metodo
sposta(int deltaX, int deltaY)
nella classe  Rettangolo
●Per traslare il suo vertice il rettangolo può chiedere al suo 
stesso vertice di spostarsi: scambio di messaggi tra oggetti  
public class Rettangolo {
// … Come prima … 
public void sposta(int deltaX, int deltaY) {
vertice.trasla(deltaX, deltaY);
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#33,33,"Programmazione orientata agli oggetti
Messaggi tra Oggetti (2)
●E se la classe Punto non disponesse del metodo 
trasla() ?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#34,34,"Programmazione orientata agli oggetti
Messaggi tra Oggetti (3)
public class Rettangolo {
// … come prima … 
public void sposta(int deltaX, int deltaY) {
int xVertice = vertice.getX();
int yVertice = vertice.getY();
vertice.setX(xVertice + deltaX);
vertice.setY(yVertice + deltaY);
}
}
●Il comportamento desiderato è comunque ottenibile 
utilizzando i metodi setX() e setY() ma il  codice risulta 
“meno pulito” rispetto alla soluzione basata sulla disponibilità 
del metodo  trasla()  già all’interno della classe Punto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#35,35,"Programmazione orientata agli oggetti
Variabili di Istanza e Metodi
●Una classe definisce sia delle variabili di 
istanza sia dei metodi; rappresentano, rispett.
—lo stato degli oggetti istanza di quella classe
—il comportamento  di tali oggetti 
●La definizione di una classe segue questa 
sintassi difatti:
public class <NomeClasse> {
 <definizione di variabili di istanza>
 <definizione di metodi>
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#36,36,"Programmazione orientata agli oggetti
Variabili di Istanza (1)
●
Le variabili di istanza memorizzano 
informazioni che rappresentano lo stato 
di un oggetto
public class Rettangolo {
private int base;
private int altezza;
private Punto vertice;
…
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#37,37,"Programmazione orientata agli oggetti
Variabili di Istanza (2)
●Nella definizione di una variabile di istanza:
—Modificatore di visibilità (>>)
—Tipo
—Nome della variabile
private int base;
Modificatore di visibilitàTipoNome della variabile
●Il modificatore di visibilità specifica se una certa variabile è 
visibile dall'esterno
—Per il momento si usa private : la variabile è visibile solo 
all'interno della classe in cui è dichiarata
—Per accedervi dall'esterno si usano i metodi getter e setter
 "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#38,38,"Programmazione orientata agli oggetti
Variabili Istanza: Inizializzazione
●Ci sono diversi modi per inizializzare lo stato di un oggetto
●Le variabili di qualsiasi genere (ovvero di istanza, locali ed 
altro >>) vengono sempre inizializzate, esplicitamente od 
implicitamente
●In Java non esiste il problema delle variabili accidentalmente 
rimaste non inizializzate tipico del linguaggio C
●Per le variabili di istanza: s e non viene specificato alcun 
valore iniziale, assumono un valore di default:
●per le variabili di un tipo numerico ( int, float…) è 0
Rettangolo rect = new Rettangolo();
System.out.println(rect.getBase()); // Stampa 0
●Stampa (sempre e prevedibilmente) 0 nonostante 
non sia stato invocato il metodo setBase(0);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#39,39,"Programmazione orientata agli oggetti
Variabili di Istanza:
Campo d’Azione (o Scope )
●Le variabili di istanza sono visibili all'interno 
della sola classe in cui sono dichiarate
—Ogni metodo può referenziarle semplicemente per nome
public class Rettangolo {
private int base;
// ...
public int getBase() {
return base;
}
// …
}Qui ‘base’ fa 
riferimento alla 
variabile di 
istanza base"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#4,4,"Programmazione orientata agli oggetti
Il Paradigma Orientato agli Oggetti (3)
●Ognuno di questi oggetti ha delle proprietà
—Peso, Nome, Altezza , …
●Ognuno di questi oggetti può svolgere delle 
azioni
—Un oggetto Macchina  può accendersi()
—Un oggetto Persona  può salutare()
●Risulta più naturale programmare se 
programmiamo in maniera più vicina a come 
naturalmente pensiamo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#40,40,"Programmazione orientata agli oggetti
Variabili di Istanza
●Una variabile di istanza ha un valore come parte dello 
stato di uno specifico oggetto istanza della sua classe
●Si usa dire che una variabile di istanza “appartiene ad 
un oggetto”  anche se è definita  nella sua classe
●Un oggetto, tramite le proprie variabili di istanza, 
possiede un proprio stato autonomamente  rispetto a 
tutti gli altri oggetti istanza della sua stessa classe
Rettangolo rect1 = new Rettangolo();
rect1.setBase(10);
rect1.base; // NON COMPILA
Rettangolo rect2 = new Rettangolo();
rect2.setBase(20); /* N.B. la base del secondo oggetto cambia;
                      Quella del primo rimane invariata */"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#41,41,"Programmazione orientata agli oggetti
Un Parallelismo con il Linguaggio C (1)
●Pare abbastanza naturale associare una variabile di 
istanza di una classe Java ad un campo di una 
struct  di C
typedef struct {
 int base;
...
} Rettangolo;
Rettangolo *r = malloc(sizeof(Rettangolo));
r->base = 15;
Rettangolo *r2 = malloc(sizeof(Rettangolo));
r2->base = 30;
free(r1);
free(r2);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#42,42,"Programmazione orientata agli oggetti
Un Parallelismo con il Linguaggio C (2)
●I metodi definiscono le operazioni che si possono 
svolgere su un oggetto di una certa classe
●Viene naturale associare un metodo di una classe 
Java ad una funzione C che opera su una struct
typedef struct {
int base;
…
} Rettangolo;
void setBase(Rettangolo * this, int base) {
this->base = base; 
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#43,43,"Programmazione orientata agli oggetti
Invocazione dei Metodi
●L'invocazione dei metodi è alla base della 
programmazione orientata agli oggetti come 
meccanismo per lo scambio di messaggi tra oggetti
●I metodi mettono in comunicazione diretta l’oggetto che 
invoca il metodo con quello su cui il metodo viene 
invocato
●Ad esempio:
—Per impostare od ottenere la base di un rettangolo 
abbiamo invocato dei metodi della classe Rettangolo
—Per spostare un oggetto istanza della classe Rettangolo  il 
suo metodo sposta()  ha invocato dei metodi della classe 
Punto una cui istanza ne rappresenta il vertice
 "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#44,44,"Programmazione orientata agli oggetti
Metodo main()
●L'esecuzione di un programma inizia sempre 
con l'invocazione di un particolare e specifico 
metodo 
●Per convenzione (eredità dal linguaggio C) tale 
metodo si chiama main()
—Questo metodo “scatena” l’esecuzione 
invocando a sua volta altri metodi
●Tranne che per il metodo main() da cui comincia 
l’esecuzione, per ogni invocazione di metodo 
esiste sempre un metodo invocante  ed un 
metodo invocato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#45,45,"Programmazione orientata agli oggetti
Metodo Invocante e Invocato
public class Main {
public static void main(String args[]) {
Rettangolo rect = new Rettangolo();
rect.setBase (22);
}
}Metodo 
invocante
Metodo 
invocatoMetodo 
invocatoInvocazione di metodo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#46,46,"Programmazione orientata agli oggetti
Definizione di Metodo
●I metodi sono dichiarati all'interno della 
definizione di una classe e definiscono il 
comportamento di tutti gli oggetti appartenenti a 
quella classe
●La dichiarazione di un metodo comprende due parti:
—Intestazione
●Modificatore di accesso/visibilità
●Tipo valore restituito
●Nome del metodo
●Lista dei parametri formali
—Corpo
●Definizioni di variabili locali
●Istruzioni
public void setX(int x) {   …   }Corpo Intestazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#47,47,"Programmazione orientata agli oggetti
Metodi: Valore Restituito
●I metodi possono comunicare verso l'esterno 
restituendo un valore
—Il metodo invocato  comunica con il metodo invocante
—esattamente come per le funzioni in C
●Se un metodo non ritorna nessun valore al 
momento della dichiarazione del tipo di ritorno 
si utilizza la parola chiave  void"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#48,48,"Programmazione orientata agli oggetti
Metodi e Aggiornamenti di Stato
●Conviene, per diversi motivi (>>), distinguere sempre i 
metodi che
—interrogano  (solamente) lo stato dell'oggetto su cui sono 
invocati
●Solo lettura dello stato
—aggiornano  lo stato dell'oggetto su cui sono invocati
●Anche scrittura dello stato
●Ad esempio (nella classe Punto)
public int getX() { 
return x;       // interroga lo stato
}
public void trasla(int dx, int dy) {
x += dx;    // aggiorna lo stato
y += dy;        // aggiorna lo stato
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#49,49,"Programmazione orientata agli oggetti
(Esercizio con Eclipse) 
Variabili di Istanza e Metodi
●Realizzare la classe Attrezzo
—Con le variabili di istanza
●nome di tipo String
●peso di tipo int
—aggiungere i relativi metodi getter & setter
●Realizzare la classe Stanza
—Con le variabili di istanza
●nome di tipo String
●stanzaAdiacente  di tipo Stanza
●attrezzoContenuto di tipo Attrezzo
—aggiungere i relativi metodi getter & setter"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#5,5,"Programmazione orientata agli oggetti
Il Paradigma Orientato agli Oggetti (4)
●E’ infatti possibile definire classi di oggetti che
—mantengono uno stato
—offrono operazioni che lo modificano/interrogano
in maniera logicamente coesa
●La realizzazione di un programma consiste nella 
definizione di opportune classi di oggetti che si 
scambiano messaggi che sanno come interpretare
●Java è solo uno dei tanti linguaggi ideati per 
supportare la programmazione secondo il 
paradigma orientato agli oggetti
●Anzi… a ben vedere esistono fonti che spiegano 
come programmare in maniera orientata agli 
oggetti anche in linguaggio C (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#50,50,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (1)
●Lo stato di un oggetto può essere cambiato
:Attrezzo
nome“spada”
peso7public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 Osso.setNome(“osso”);
 Osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#51,51,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (2)
●Lo stato di un oggetto può essere cambiato
:Attrezzo
nome“spada”
peso7public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 osso.setNome(“osso”);
 osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}:Attrezzo
nome“osso”
peso0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#52,52,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (3)
public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 osso.setNome(“osso”);
 osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}:Attrezzo
nome“osso”
peso1:Attrezzo
nome“spada”
peso7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#53,53,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (4)
public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 Osso.setNome(“osso”);
 Osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}:Stanza
nome“N11”
attrezzoContenuto
...:Attrezzo
nome“osso”
peso1:Attrezzo
nome“spada”
peso7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#54,54,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (5)
public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 Osso.setNome(“osso”);
 Osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}:Stanza
nome“N11”
attrezzoContenuto
...:Attrezzo
nome“osso”
peso1:Attrezzo
nome“spada”
peso7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#55,55,"Programmazione orientata agli oggetti
Modificare lo Stato di un Oggetto (6)
public class MainStanzeAttrezzi {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo();
 spada.setNome(“spada”);
 spada.setPeso(7);
 Attrezzo osso = new Attrezzo();
 Osso.setNome(“osso”);
 Osso.setPeso(1);
 Stanza n11 = new Stanza();
 n11.setNome(“N11”);
 n11.setAttrezzo(spada);
 n11.setAttrezzo(osso);
}
}:Attrezzo
nome“osso”
peso1:Attrezzo
nome“Spada”
peso7
:Stanza
nome“N11”
attrezzoContenuto
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#56,56,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti
(continua...)
●La creazione di un nuovo oggetto in memoria 
avviene tramite l'operatore new
●L'operatore new restituisce un 
riferimento ad un oggetto 
appena creato 
●Ad esempio: Stanza n11 = new Stanza();
●La variabile locale n11 NON contiene l'oggetto 
creato, ma bensì un riferimento  ad esso (>>)
n11:Stanza
nome
attrezzoContenuto
...
n11Questa freccia entrante 
in un oggetto è la nostra 
rappresentazione grafica 
dei riferimenti!Questa rettangolo è 
la nostra 
rappresentazione 
grafica degli oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#6,6,"Programmazione orientata agli oggetti
La Rete di Oggetti (1)
●L’esecuzione di un programma Java si risolve 
nello scambio di messaggi tra oggetti che 
aggiornano ed interrogano il proprio stato
●Ad esempio, se si volesse rappresentare la 
topologia delle aule della nostra università, 
useremmo degli oggetti Stanza (n10, n11, 
campusOne , ...)
—Per potersi scambiare messaggi, questi oggetti 
devono conoscersi tramite dei riferimenti
—si crea una Rete di Oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#7,7,"Programmazione orientata agli oggetti
La Rete di Oggetti (2)
:Stanza
nome “Aula N11”
stanzaAdiacente:Stanza
nome “Aula N12”
stanzaAdiacente
:Stanza
nome “CampusOne”
stanzaAdiacenteUna “rete” di oggetti
riferimento
riferimentoriferimentooggetto
oggettooggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#8,8,"Programmazione orientata agli oggetti
La Rete di Oggetti (3)
●Grazie ad un riferimento è possibile rappresentare 
l’oggetto Stanza  corrente di un ipotetico oggetto 
Giocatore
●Grazie ai collegamenti tra oggetti è possibile 
spostarsi all’interno di un oggetto Labirinto  che 
conosce  certamente le stanze
●Un oggetto Stanza  può “contenere” un oggetto 
Attrezzo
●L’oggetto Giocatore  potrebbe “chiedere” 
all’oggetto Stanza  corrente quale oggetto Attrezzo  
possiede, usando operazioni come 
prendiAttrezzo()  e rimuoviAttrezzo()
●Allo scopo deve scambiare messaggi con l'oggetto 
Stanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-02-paradigma-OO.pdf#9,9,"Programmazione orientata agli oggetti
La Rete di Oggetti (4)
:Stanza
nome “Aula N11”
stanzaAdiacente
attrezzo
:Attrezzo
nome “Spada”
peso 7:Giocatore
nome “Alice”
stanzaCorrente
Altre
stanze..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#0,0,"Programmazione
Orientata agli Oggetti
Oggetti e Riferimenti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
●Riferimenti ad Oggetti
●Molteplici riferimenti verso lo stesso oggetto
●Riferimenti ed Effetti Collaterali
●Riferimenti e passaggio dei parametri per valore
●Metodi che restituiscono riferimenti
●Riferimento nullo e NullPointerException
●Campo d’Azione delle variabili e Shadowing
●La parola chiave this
●Convenzioni di Stile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#10,10,"Programmazione orientata agli oggetti
Molteplici Riferimenti verso 
lo Stesso Oggetto (4)
public class MainStanzeRiferimenti {
public static void main(String[] args) {
Stanza n12 = new Stanza();
n12.setNome(“aula n12”);
Stanza n11 = new Stanza();
n11.setNome(“aula n11”);
n11.setStanzaAdiacente(n12);
Stanza n11Alias = n11;
}
}
n11:Stanza
nome“aula n11”
stanzaAdiacente
...n11
n11Aliasn12:Stanza
nome“aula n12”
stanzaAdiacente
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#11,11,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (1)
●
Qual è l'output del seguente programma?
public static MainRiferimentiSideEffect {
public static void main(String[] args) {
Stanza n11 = new Stanza();
Stanza n11Alias  = n11;
n11.setNome(“N11”);
n11Alias .setNome(“ aula N11”);
System.out.println(n11.getNome());
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#12,12,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (2)
public static MainRiferimentiSideEffect {
public static void main(String[] args) {
Stanza n11 = new Stanza();
Stanza n11Alias = n11;
n11.setNome(“N11”);
n11Alias.setNome(“ aula N11”);
System.out.println(n11.getNome());
}
}
n11:Stanza
nome
stanzaAdiacente
...n11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#13,13,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (3)
public static MainRiferimentiSideEffect {
public static void main(String[] args) {
Stanza n11 = new Stanza();
Stanza n11Alias = n11;
n11.setNome(“N11”);
n11Alias.setNome(“ aula N11”);
System.out.println(n11.getNome());
}
}
n11:Stanza
nome
stanzaAdiacente
...n11
n11Alias"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#14,14,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (4)
public static MainRiferimentiSideEffect {
public static void main(String[] args) {
Stanza n11 = new Stanza();
Stanza n11Alias = n11;
n11.setNome(“N11”);
n11Alias.setNome(“ aula N11”);
System.out.println(n11.getNome());
}
}
n11:Stanza
nome“N11”
stanzaAdiacente
...n11
n11Alias"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#15,15,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (5)
public static MainRiferimentiSideEffect {
public static void main(String[] args) {
Stanza n11 = new Stanza();
Stanza n11Alias = n11;
n11.setNome(“N11”);
n11Alias.setNome(“ aula N11”);
System.out.println(n11.getNome());
}
}
n11:Stanza
nome“aula N11”
stanzaAdiacente
...n11
n11Alias"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#16,16,"Programmazione orientata agli oggetti
Più Riferimenti & Side-Effect (6)
●L'output è “ aula N11 ”
●Sorprendente per chi aveva creato l’oggetto e lo 
aveva chiamato semplicemente “ n11”?
●Questo tipo di comportamenti spesso vengono 
indicati con il nome di 
Effetti Collaterali  (Side-Effect )
—un’azione genera effetti visibili ben al di fuori 
dell’ambito in cui è avvenuta
●Sia la variabile n11 che n11Alias  fanno 
riferimento allo stesso oggetto
—una modifica effettuata a tale oggetto tramite uno dei 
due riferimenti e visibile anche usando l’altro"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#17,17,"Programmazione orientata agli oggetti
Riferimenti per Valore (1)
●Quando una variabile contenente un riferimento è passata 
come argomento ad un metodo
—il passaggio è per valore
—viene copiato il riferimento  contenuto nell’argomento
—l'oggetto a cui fa riferimento NON viene copiato
●Tramite due copie distinte ma identiche dello stesso 
riferimento si finisce per accedere (e modificare) lo stesso 
oggetto
●Il cambio di stato operato ad un oggetto all’interno del 
metodo invocato  è visibile (come effetto collaterale) anche al 
livello metodo invocante  che effettuato la chiamata passando 
per valore un riferimento all’oggetto
—Passando per valore riferimenti si possono quindi ottenere  
effetti simili a quelli che in altri linguaggi si ottengono mediante 
il cosidetto passaggio dei parametri per variabile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#18,18,"Programmazione orientata agli oggetti
Riferimenti per Valore (2)
typedef struct { 
 int base; … 
} Rettangolo;
Rettangolo *r = malloc(sizeof(Rettangolo));
setBase(r, 15);
●Similarmente a quanto avviene in C, passando (per valore) 
il puntatore  ad un’area di memoria  allocata con  malloc
—è possibile cambiare il contenuto della memoria  il cui 
indirizzo  è fornito come argomento
—non è possibile cambiare il contenuto della variabile che 
ospita tale indirizzo  al momento dell’invocazione
anche in Java, passando un riferimento  ad un oggetto
—è possibile cambiare lo stato dell’ oggetto il cui riferimento  è 
fornito come argomento
—non è possibile cambiare il contenuto della variabile che 
ospita tale riferimento  al momento dell’invocazionevoid setBase(struct Rettangolo * this, int b) {
this->base = b;      
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#19,19,"Programmazione orientata agli oggetti
Passaggio di Riferimenti (1)
public class MainPassRef {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    Stanza n12 = new Stanza();
    n11.setStanzaAdiacente(n12);
  }
}
public class Stanza {
  // ...
  public void setStanzaAdiacente(Stanza stanza) {
    this.stanzaAdiacente = stanza;
  }
}n11:Stanza
nome
stanzaAdiacente
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#2,2,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti (1)
●La creazione di un nuovo oggetto in memoria 
avviene tramite l'operatore new
●L'operatore new restituisce un 
riferimento ad un oggetto 
appena creato 
●Ad esempio: Stanza n11 = new Stanza();
●La variabile locale n11 NON contiene l'oggetto 
creato, ma bensì un riferimento  ad esso (>>)
n11:Stanza
nome
attrezzoContenuto
...
n11Questa freccia entrante 
in un oggetto è la nostra 
rappresentazione grafica 
dei riferimenti!Questa rettangolo è 
la nostra 
rappresentazione 
grafica degli oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#20,20,"Programmazione orientata agli oggetti
Passaggio di Riferimenti (2)
public class MainPassRef {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    Stanza n12 = new Stanza();
    n11.setStanzaAdiacente(n12);
  }
}
public class Stanza {
  // ...
  public void setStanzaAdiacente(Stanza stanza) {
    this.stanzaAdiacente = stanza;
  }
}n11:Stanza
nome
stanzaAdiacente
...
n12:Stanza
nome
stanzaAdiacente
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#21,21,"Programmazione orientata agli oggetti
Passaggio di Riferimenti (3)
public class MainPassRef {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    Stanza n12 = new Stanza();
    n11.setStanzaAdiacente(n12);
  }
}
public class Stanza {
  // ...
  public void setStanzaAdiacente(Stanza stanza) {
    this.stanzaAdiacente = stanza;
  }
}n11:Stanza
nome
stanzaAdiacente
...
n12:Stanza
nome
stanzaAdiacente
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#22,22,"Programmazione orientata agli oggetti
Passaggio di Riferimenti (4)
public class MainPassRef {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    Stanza n12 = new Stanza();
    n11.setStanzaAdiacente(n12);
  }
}
public class Stanza {
  // ...
  public void setStanzaAdiacente(Stanza stanza) {
    this.stanzaAdiacente = stanza;
  }
}n11:Stanza
nome
stanzaAdiacente
...
n12:Stanza
nome
stanzaAdiacente
..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#23,23,"Programmazione orientata agli oggetti
Riferimenti & Valore Restituito
●Quando un riferimento viene restituito  da un 
metodo
—Viene restituita una copia del riferimento
—L'oggetto a cui si riferisce NON viene copiato
public class Stanza {
  // ...
  public Stanza getStanzaAdiacente() {
     return stanzaAdiacente;
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#24,24,"Programmazione orientata agli oggetti
Esercizio ( con Eclipse )
●Assumiamo che:
—la classe Rettangolo  non disponga del metodo 
sposta()
—la classe Punto invece disponga del metodo trasla()
●Trovare un modo alternativo per spostare gli 
oggetti Rettangolo
●Vediamo due soluzioni:
N.B. nessuna delle due è raccomandabile (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#25,25,"Programmazione orientata agli oggetti
Esercizio (2)
●Prima soluzione
public static void main(String[] args) {
Punto origine = new Punto();
origine.setX(0);
origine.setY(0);
Rettangolo rect = new Rettangolo();
rect.setVertice(origine);
origine.trasla(1, 1);
}
●Se spostiamo l’oggetto istanza della classe Punto che 
utilizziamo come vertice dell’oggetto istanza della classe 
Rettangolo , spostiamo, come effetto collaterale , il 
rettangolo stesso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#26,26,"Programmazione orientata agli oggetti
Esercizio (3)
●Seconda soluzione
public static void main(String[] args) {
Punto origine = new Punto();
origine.setX(0);
origine.setY(0);
Rettangolo rect = new Rettangolo();
rect.setVertice(origine);
Punto verticeRect = rect.getVertice();
verticeRect.trasla(1, 1);
}
●Si ottiene una copia del riferimento  all’oggetto istanza della 
classe Punto che figura come vertice dell’oggetto istanza 
della classe Rettangolo  che spostato produce, ancora come 
effetto collaterale , lo spostamento del rettangolo stesso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#27,27,"Programmazione orientata agli oggetti
Esercizio (4)
●Entrambe le soluzioni sono poco raccomandabili, 
perché non rendono affatto evidente la reale 
intenzione di spostare il rettangolo
●Nessuna invocazione diretta  di un metodo della classe 
Rettangolo  induce a pensare che lo si sta spostando
●Il rettangolo viene spostato solamente come risultato 
dell’effetto collaterale dello spostamento di un punto 
(il vertice) di cui conservava un riferimento
●E’ preferibile dotare la classe Rettangolo  di un  
apposito metodo trasla() la sua implementazione 
può fare affidamento ad un metodo (anche con lo 
stesso nome) di Punto
●Gli effetti collaterali risultano difficili da tracciare"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#28,28,"Programmazione orientata agli oggetti
Riferimento Nullo
●In Java esiste un solo letterale di tipo 
riferimento ad oggetto: null
●Un valore speciale e distinto da tutti gli altri 
valori, il riferimento  nullo
●Indica l’assenza di un reale riferimento ad un 
oggetto esistente
—N.B. In Java non esiste alcuna relazione particolare 
tra il valore null e 0 (letterale di tipo int)
—In C, la macro NULL è invece un alias per il valore 0
●Un po’ come già accadeva per i booleani, la 
tipizzazione Java è più stringente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#29,29,"Programmazione orientata agli oggetti
Utilizzo del Riferimento Nullo
●Il riferimento nullo è utile
—come valore speciale restituito da un metodo 
per segnalare un caso speciale. Ad es.:
Persona cercata = rubrica.trova(“Alice”);
restituisce null se non esiste alcuna persona 
di nome “Alice”  nella rubrica
—per fornire un valore di default a variabili che 
contengono riferimenti ad oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#3,3,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti (2)
●Proviamo a stampare il valore di variabili che 
contengono riferimenti
public class MainRiferimenti {
public static void main(String[] args) {
Stanza n11 = new Stanza();
System.out.println(n11);
}
}
●Stampa:  Stanza@ 15db9742
—Ma ovviamente dipende dalla particolare esecuzione
—Possiamo per il momento semplificare il significato di questa 
stampa: è [ un numero che dipende dal ]l’indirizzo in memoria  
dell’oggetto referenziato
—In realtà non è esattamente così, ma per i nostri presenti scopi 
questa semplificazione fa molto comodo (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#30,30,"Programmazione orientata agli oggetti
Uso di null: Esempio 
public class MainNull {
public static void main(String[] args) {
Stanza n12 = new Stanza();
     n12.setNome(“aula n12”);
n12.setStanzaAdiacente( null );
}
}
:Stanza
nome“aula n12”
stanzaAdiacente
...Si intende 
rappresentare che 
la stanza n12 NON 
possiede stanze 
adiacenti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#31,31,"Programmazione orientata agli oggetti
NullPointerException (1)
public class MainNullPointerException {
public static void main(String[] args) {
Stanza n12 = new Stanza();
     n12.setNome(“aula n12”);
n12.setStanzaAdiacente( null );
Stanza adiacenteN12 = n12.getStanzaAdiacente();
System.out.println( adiacenteN12.getNome()) ;
}
}●Cosa succede se si invoca un metodo su un 
riferimento nullo?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#32,32,"Programmazione orientata agli oggetti
NullPointerException (2)
●null rappresenta l’assenza di un riferimento 
ad un oggetto
—Si genera un errore a tempo di esecuzione, 
un’eccezione  ( runtime-exception >> )
NullPointerException
$ java MainNullPointerException
Exception in thread ""main"" 
java.lang.NullPointerException
at MainNullPointerException.main(MainNullPointerException.java: 10)Tipologia
eccezione
Numero di linea del codice in cui si è verificata"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#33,33,"Programmazione orientata agli oggetti
NullPointerException: Diagnostica
●Java, ancora una volta, fornisce una 
diagnostica efficace 
●Cosa accadrebbe utilizzando il linguaggio di 
programmazione C?
struct Punto {
int x;
int y;
}; 
int main() {
struct Punto *origine = NULL;
origine->x = 0;
}
Segmentation fault !  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#34,34,"Programmazione orientata agli oggetti
Inizializzazione delle 
Variabili di Istanza e null
●Il compilatore forza l’inizializzazione di tutte le 
variabili di istanza 
●Quelle dichiarate come contenenti un riferimento 
ad oggetto sono inizializzate a null
Rettangolo rect = new Rettangolo();
System.out.println(rect.getBase()); // 0
System.out.println(rect.getVertice()); // null
System.out.println( rect.getVertice() .getX());
✔Il valore restituito da getVertice()  è null, 
invocando un metodo sul suo risultato si 
genera una NullPointerException"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#35,35,"Programmazione orientata agli oggetti
Evitare NullPointerException
●Se è noto che una funzione può ritornare 
null come valore speciale è necessario 
predisporre un controllo sul valore restituito
…
Persona cercata = rubrica.trova(“Alice”);
if (cercata!=null)
System.out.println(cercata.getEta());
else
System.out.println(“non trovato”);
●In C: if (cercata!=0)
—In Java non compilerebbe"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#36,36,"Programmazione orientata agli oggetti
Campo d’Azione 
delle Variabili e dei Parametri
●Se il metodo setX()  venisse così dichiarato?
public class Punto {
private  int x;
private int y;
public void setX( int x) {
x = x;
}
…
}
Punto unoUno = new Punto();
unoUno.setX(1);
System.out.println(unoUno.getX()); // Stampa 0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#37,37,"Programmazione orientata agli oggetti
Shadowing  
●Si è verificato il cosiddetto shadowing:
—Il parametro formale x ha lo stesso nome della 
variabile di istanza x
—Il parametro formale ha però uno scope (>>) più 
ristretto e quindi ha precedenza
—Nel contesto del corpo del metodo, l’identificatore 
’x’ viene considerato un riferimento al 
parametro formale (e non alla var. di istanza)
●Si dice anche che il parametro formale offusca (“ fa 
ombra” ) la variabile di istanza
●x = x; è un'espressione che assegna al parametro 
formale x il suo stesso valore (inutile!)
✔Alcuni IDE moderni (come Eclipse) possono essere 
configurati per segnalare il problema"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#38,38,"Programmazione orientata agli oggetti
La Parola Chiave this (1)
●All'interno di ogni metodo è possibile 
ottenere un riferimento all’oggetto corrente  
●La parola chiave this
—Conserva un riferimento all'oggetto sul quale il 
metodo in corso di esecuzione è stato invocato
—Tramite questo riferimento è quindi possibile:
●modificare le variabili di istanza dell’oggetto
●fare invocazioni di metodo nidificate sullo stesso 
oggetto
●passare un riferimento all’oggetto corrente  come 
argomento di altre invocazioni di metodo…"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#39,39,"Programmazione orientata agli oggetti
La Parola Chiave this (2)
●Si risolve anche il problema dello shadowing
… 
public void setX(int x) {
this.x = x;
}
… 
Punto unoUno = new Punto();
unoUno.setX(1);
System.out.println(unoUno.getX());// Stampa  1
●All'interno del corpo del metodo setX() , this è 
un riferimento allo stesso oggetto a cui si riferisce 
anche unoUno  Parametro
Variabile 
di istanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#4,4,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti (3)
●Una stessa variabile può contenere, in 
momenti diversi, riferimenti ad oggetti 
distinti dello stesso tipo. Ad esempio:
public class MainRiferimenti {
    public static void main(String[] args) {
        Stanza n11 = new Stanza();
        System.out.println(n11);  // Stampa Stanza@15db9742
   n11 = new Stanza();
      System.out.println(n11); // Stampa Stanza@ 6d06d69c 
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#40,40,"Programmazione orientata agli oggetti
this in C?
●T alvolta può far comodo pensare a this come ad un 
parametro aggiuntivo passato automaticamente (ed 
implicitamente)  ad ogni metodo
●Ad esempio il metodo  setX()  verrebbe tradotto in C 
con la seguente funzione
void setX(struct Punto *this, int x) {
this -> x = x;      // Codice C
}
●Quindi l’invocazione di  unoUno.setX(1); diverebbe:
struct Punto unoUno;   // Codice C
setX(&unoUno, 1);      // Codice C"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#41,41,"Programmazione orientata agli oggetti
Accedere 
le Variabili di Istanza con this
●this può essere usato per accedere alle variabili di istanza 
ma può anche essere omesso in assenza di ambiguità
… 
public int getX() {
return this.x;
  }
… 
●Equivale a
… 
public int getX() {
return x;
  }
… ●Il compilatore risolve 
l’identificatore x come 
variabile di istanza 
dell'oggetto su cui il 
metodo è stato invocato
●In un certo senso, è 
come se aggiungesse 
this. automaticamente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#42,42,"Programmazione orientata agli oggetti
this : Convenzione di Stile
●Adottiamo comunque la convenzione di 
usare sempre e comunque  this per 
referenziare variabili di istanza
●Con le seguenti motivazioni:
—si evita lo shadowing
—si favorisce la leggibilità del codice
✔si favorisce l’apprendimento di questi concetti 
di base"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#43,43,"Programmazione orientata agli oggetti
Invocare Metodi Mediante this (1)
●La parola chiave this può essere usata per 
invocare metodi sullo stesso oggetto su cui 
il metodo corrente è stato invocato
—Se this viene omesso il compilatore lo 
considera comunque presente
●Ad esempio è possibile scrivere il metodo 
setXY()  usando gli altri due metodi della 
classe Punto : setX()  e setY()"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#44,44,"Programmazione orientata agli oggetti
Invocare Metodi Mediante this (2)
public void setXY(int x, int y) {
  this.setX(x);
  this.setY(y);
}
●Anche per alcune  invocazioni di metodi è 
consigliabile usare this per aumentare la 
leggibilità
●Ad esempio quando si vuole evidenziare l’utilizzo 
di altri metodi della stessa classe nella scrittura di 
un primo metodo  (passo top-down )"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#45,45,"Programmazione orientata agli oggetti
Esercizio
Fare le verifiche disponibili sul sito del 
corso:
•Studente.java
•Tesi.java
•Sommatore.java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#5,5,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti (4)
public class MainRiferimenti {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    System.out.println(n11); // stampa Stanza@ 15db9742
    n11 = new Stanza();
    System.out.println(n11); // stampa Stanza@ 6d06d69c  
  }
}
nome
attrezzoContenuto
...0x15db9742 :Stanza
n11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#6,6,"Programmazione orientata agli oggetti
Riferimenti ad Oggetti (5)
public class MainRiferimenti {
  public static void main(String[] args) {
    Stanza n11 = new Stanza();
    System.out.println(n11); // stampa Stanza@ 15db9742
n11 = new Stanza();
System.out.println(n11); // stampa Stanza@ 6d06d69c  
  }
}0x15db9742 :Stanza
nome
attrezzoContenuto
...6d06d69c  :Stanza
nome
attrezzoContenuto
...n11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#7,7,"Programmazione orientata agli oggetti
Molteplici Riferimenti verso 
lo Stesso Oggetto (1)
n11 :Stanza
nome“aula n11”
stanzaAdiacente
...
n10:Stanza
nome“aula n10”
stanzaAdiacente
...n12:Stanza
nome“aula n12”
stanzaAdiacente
...●In alcuni casi più variabili contengono un 
riferimento allo stesso oggetto
●Ad esempio due stanze adiacenti la 
medesima:"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#8,8,"Programmazione orientata agli oggetti
Molteplici Riferimenti verso 
lo Stesso Oggetto (2)
public class MainStanzeRiferimenti {
public static void main(String[] args) {
Stanza n12 = new Stanza();
n12.setNome(“aula n12”);
Stanza n11 = new Stanza();
n11.setNome(“aula n11”);
n11.setStanzaAdiacente(n12);
Stanza n10 = new Stanza();
n10.setNome(“aula n10”);
n10.setStanzaAdiacente(n12);
}
}●La configurazione appena vista si può 
ottenere con il seguente codice"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-03-oggetti-riferimenti.pdf#9,9,"Programmazione orientata agli oggetti
Molteplici Riferimenti verso 
lo Stesso Oggetto (3)
public class MainStanzeRiferimenti {
public static void main(String[] args) {
Stanza n12 = new Stanza();
n12.setNome(“aula n12”);
Stanza n11 = new Stanza();
n11.setNome(“aula n11”);
n11.setStanzaAdiacente(n12);
Stanza n11Alias = n11;
}
}
●Ora sia n11 sia n11Alias  fanno riferimento allo stesso oggetto●Un altro esempio:"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#0,0,"Programmazione
Orientata agli Oggetti
Gestione della Memoria"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
Allocazione di Oggetti
–L’operatore new
–Costruttori
–Costruttore di default
Stack e Heap
–Stack e Record di Attivazione
–Stack-Overflow
–Heap
Equivalenza di oggetti ed identicità dei riferimenti
Riferimenti in Java vs Puntatori in C
Gestione della Memoria
–Garbage Collection"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#10,10,"Programmazione orientata agli oggetti
Costruttore di Default (1)
●Tutte le classi devono avere almeno un 
costruttore, sempre
●Se non viene esplicitamente dichiarato, ne 
viene aggiunto uno implicitamente
●E’ un costruttore senza parametri
(costruttore no-args )
●Anche senza dichiarare esplicitamente il 
costruttore senza argomenti di Punto :
Punto punto = new Punto(); // COMPILA"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#11,11,"Programmazione orientata agli oggetti
Costruttore di Default (2)
●Appena viene definito esplicitamente un costruttore, 
il costruttore no-args  non viene più generato 
automaticamente e non è più possibile invocarlo
●Ad esempio:
—Dopo aver dichiarato un primo costruttore (con parametri) 
nella classe Rettangolo :
public class MainNoArgs {
    public static void main(String[] args) {
        Rettangolo rect = new Rettangolo(); //NON COMPILA
    }
}
Exception in thread ""main"" java.lang.Error: Unresolved compilation 
problem: 
The constructor Rettangolo() is undefined
at MainNoArgs.main( MainNoArgs.java:4 )"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#12,12,"Programmazione orientata agli oggetti
Variabili di Istanza: 
Valore di default e null
●È fortemente consigliato l'uso di un costruttore 
che inizializzi le variabili di istanza di tipo 
riferimento
—Onde evitare NullPointerException
—Se non specificato altrimenti, le variabili di istanza 
di tipo riferimento sono inizializzate a null
●Altro possibile costruttore per la classe  Rettangolo :
   …
public Rettangolo(int base, int altezza) {
  this.vertice = new Punto(0, 0);
  this.base = base;
  this.altezza = altezza;
}
… "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#13,13,"Programmazione orientata agli oggetti
Costruttori Alternativi
●Se il vertice non viene specificato, questo 
costruttore suppone che sia nell’origine
—è poi possibile usare la variabile di istanza 
vertice  senza sollevare NullPointerException
●Spesso si definiscono molteplici costruttori con 
diversi parametri
—Utili per costruire oggetti
●a partire da informazioni diverse. Ad es. per i rettangoli
●base, altezza, vertice alto a sx
●vertice alto a sx, vertice basso a dx
●senza essere costretti a specificare tutti i parametri  
—Per ora: unico costruttore, il più generico possibile 
(>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#14,14,"Programmazione orientata agli oggetti
Gestione della Memoria:
Stack e Heap
●Durante l’esecuzione, un programma ha accesso 
ad almeno due distinte aree di memoria
●Stack
Per la memorizzazione delle informazioni necessarie 
per l’esecuzione dei metodi, anche nidificati
—Conserva:
●Stato dell’esecuzione
●Variabili locali e loro valore
●Heap
Per la memorizzazione di oggetti creati tramite 
l’operatore new 
—Conserva:
●Oggetti e loro stato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#15,15,"Programmazione orientata agli oggetti
Stack
●Area di memoria assegnata dalla JVM all’inizio 
dell’esecuzione 
—dimensione massima prefissata (qualche mb)
●Adibita a conservare quanto serve per mantere lo 
stato dell’esecuzione (tranne lo stato degli oggetti 
>>)
—È una struttura dati gestita secondo una disciplina LIFO
●Last In Fist Out
●Per gestire le invocazioni di metodo, comunque 
nidificate, a cominciare dal main()
●Contiene i Record di Attivazione (RDA)
—Struttura dati che contiene tutte le informazioni 
necessarie all'invocazione ed all’esecuzione dei metodi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#16,16,"Programmazione orientata agli oggetti
Record di Attivazione
●Ogni volta che un metodo viene invocato, il 
corrispondente RDA viene creato ed inserito 
in cima allo stack
●Quando il metodo termina, il suo RDA viene 
rimosso
●La gestione dello stack avviene in modo 
automatico e trasparente da parte della JVM "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#17,17,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (1)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
StackRDA main"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#18,18,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (2)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
StackRDA mainRDA metodo1"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#19,19,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (3)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
StackRDA mainRDA metodo1RDA metodo2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#2,2,"Programmazione orientata agli oggetti
Operatore new (1)
●La creazione di oggetti in Java è permessa dall’operatore 
new
—richiede la specifica della classe di cui si vuole creare una nuova 
istanza
—ovvero, più precisamente, di uno dei costruttori  di tale classe
—restituisce un riferimento  all’oggetto appena creato
●Punto origine = new Punto();
public class Punto {
  private int x;
  private int y;
  public Punto() {
    this.x = 0;
    this.y = 0;
  }
  …
}
●Attenzione: origine contiene un riferimento;  NON contiene l’oggetto 
appena creatoDefinizione del Costruttore
(sintassi: stesso nome della classe)
File Punto.javaCorpo del costruttore {…}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#20,20,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (4)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
StackRDA mainRDA metodo1"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#21,21,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (5)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
StackRDA main"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#22,22,"Programmazione orientata agli oggetti
Metodi e Record di Attivazione (6)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
oggetto2.metodo2();
}
…
Stack"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#23,23,"Programmazione orientata agli oggetti
Contenuto di un RDA
●Un Record di Attivazione  contiene:
—parametri attuali
—eventuale riferimento all'oggetto corrente per 
invocazione  ( this)
—variabili locali
—valore di ritorno del metodo (se non è void)
—il punto di ritorno dell’invocazione di metodo: 
l’istruzione successiva all’invocazione nel 
metodo chiamante"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#24,24,"Programmazione orientata agli oggetti
Variabili Locali dentro il RDA
●Il record di attivazione ospita anche le variabili 
locali di ogni metodo
●Lo scope delle variabili locali è il metodo in cui 
sono definite, ed il ciclo di vita è chiaramente 
quello dell’invocazione di metodo
●L’identificatore  di una variabile locale è un alias 
(gestito dal compilatore e dall’ambiente di 
esecuzione) di un indirizzo di memoria relativo 
(sullo stack) in cui è conservato il suo valore
—Attenzione: Nulla a che fare con i riferimenti 
—Gli identificatori (ad es. origine ) sono decisamente 
più facili da ricordare rispetto ad un indirizzo di 
memoria!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#25,25,"Programmazione orientata agli oggetti
Stack & Variabili Locali (1)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA main"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#26,26,"Programmazione orientata agli oggetti
Stack & Variabili Locali (2)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA mainRDA metodo1
contat: 0x34fa09b1
contat è in realtà un alias per un indirizzo di 
memoria relativo nel record di attivazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#27,27,"Programmazione orientata agli oggetti
Stack & Variabili Locali (3)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA mainRDA metodo1
contat:3"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#28,28,"Programmazione orientata agli oggetti
Stack & Variabili Locali (4)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA mainRDA metodo1
contat:3RDA metodo2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#29,29,"Programmazione orientata agli oggetti
Stack & Variabili Locali (5)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA mainRDA metodo1
contat:5"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#3,3,"Programmazione orientata agli oggetti
Operatore new (2)
●Solo la JVM può creare oggetti
—l’operatore new consente di chiederne i servizi
●Per inizializzare nuovi oggetti, sinora:
—invocazione del cosidetto costruttore senza 
argomenti
new Punto();
—invocazione dei vari metodi setter
●Ad esempio:
Punto zeroUno = new Punto();
zeroUno.setX(0);
zeroUno.setY(1);
●Si possono definire costruttori  che ricevono parametri "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#30,30,"Programmazione orientata agli oggetti
Stack & Variabili Locali (6)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA main"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#31,31,"Programmazione orientata agli oggetti
Stack & Variabili Locali (7)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
StackRDA main"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#32,32,"Programmazione orientata agli oggetti
Stack & Variabili Locali (8)
public static void main(String[] args) {
…
oggetto1.metodo1();
}
// … (nella classe di “oggetto1”)
public void metodo1() {
int contat = 3;
oggetto2.metodo2();
contat = 5;
}
…
Stack"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#33,33,"Programmazione orientata agli oggetti
Scope delle Variabili Locali
●Il primo record di attivazione è sempre 
quello del metodo main()
●Quando  un RDA viene rimosso dallo stack le 
variabili locali e i parametri non sono più 
utilizzabili
—Lo scope di queste informazioni è limitato al 
solo metodo di appartenenza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#34,34,"Programmazione orientata agli oggetti
Stack Overflow (1)
●Lo stack ha una dimensione limitata
➢non può contenere troppi RDA 
●Ad esempio
public class SommatoreRicorsivo {
public int sommaDaZeroA(int n) {
return n + sommaDaZeroA(n-1);
}
}
// ERRORE! manca il caso base!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#35,35,"Programmazione orientata agli oggetti
Stack Overflow (2)
●L'esecuzione del metodo sommaDaZeroA(1) 
genera il seguente errore
(indipendentemente dal suo argomento)
Exception in thread ""main"" 
java.lang. StackOverflowError
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
...
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
at SommatoreRicorsivo.sommaDaZeroA( SommatoreRicorsivo.java:3 )
...N.B. La diagnostica 
riporta nomi delle 
classi e dei metodi i cui 
RDA sono nello stack al 
momento del trabocco"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#36,36,"Programmazione orientata agli oggetti
Heap
●Tutti gli oggetti creati con l'operatore new 
possiedono uno stato che viene conservato 
in un’area di memoria denominata Heap
—Letteralmente “mucchio”,  si tratta di un’area di 
memoria assegnata dalla JVM
—NON è gestito come lo stack (LIFO)
●la sua dimensione può crescere e decrescere 
dinamicamente anche durante l'esecuzione
●gli oggetti sono creati e deallocati in ordine sparso
●spesso e volentieri l’occupazione dell’heap risulta molto 
frammentata"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#37,37,"Programmazione orientata agli oggetti
new vs malloc
●new sta ad una classe (quasi) come malloc  
sta ad una struct
—malloc
●alloca memoria nello heap
●restituisce l’indirizzo di tale area di 
memoria
—new
●alloca memoria nello heap
●restituisce il riferimento all’oggetto 
appena allocato
●invoca un costruttore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#38,38,"Programmazione orientata agli oggetti
Heap e Stack (1)
●Il valore restituito dall'operatore new è il 
riferimento all'oggetto appena creato
Punto unitario = new Punto(1, 1)
●La variabile locale unitario  contiene il 
riferimento all'oggetto creato, NON l'oggetto 
stesso
●unitario  è un alias per
l’indirizzo 0xef11d34f  
Stack0x15db9742 0xef11d34f:
Heap0x15db9742 :Punto
    x
1     y1
Variabile 
unitario"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#39,39,"Programmazione orientata agli oggetti
Heap e Stack (2)
●È possibile stampare anche il contenuto di 
una variabile che contiene un riferimento ad 
oggetto usando il metodo println()
System.out.println(unitario);
●println()  stampa una stringa che dipende 
solamente dall'indirizzo di memoria e dalla 
classe di appartenenza
Stampa: Punto@15db9742
(è possibile alterare questo comportamento>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#4,4,"Programmazione orientata agli oggetti
Costruttori
●Ogni classe ha sempre  (almeno) un 
costruttore che viene eseguito ogni volta 
che un oggetto di tale classe viene creato
✔altrimenti non sarebbe possibile creare oggetti
●Il corpo del costruttore costruisce lo stato 
iniziale di un nuovo oggetto
—riceve informazioni sullo stato iniziale da 
costruire tramite i parametri
—fissa i valori iniziali delle variabili di istanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#40,40,"Programmazione orientata agli oggetti
Assegnazione di Riferimenti (1)
●L'assegnazione di una variabile che contiene 
un riferimento copia il riferimento
—NON si crea un nuovo oggetto 
Punto unitario = new Punto(1, 1);
Punto copia = unitario;
Stack0xef11d34f:
Heap0x15db9742 :Punto
    x
1     y1
0xef11d381:0x15db9742
0x15db9742unitario
copia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#41,41,"Programmazione orientata agli oggetti
Assegnazione di Riferimenti (2)
●unitario  e copia sono due variabili locali distinte
●Possiedono valori in posizioni distinte sullo S tack…
—0xef11d34f  e 0xef11d381
...ma fanno riferimento allo stesso oggetto dentro 
l’heap, quello di indirizzo
—0x15db9742
Heap0x15db9742 :Punto
    x
1     y1
0xef11d34f:
0xef11d381:0x15db9742
0x15db9742unitario
copia
Stack"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#42,42,"Programmazione orientata agli oggetti
Molteplici Riferimenti Stesso Oggetto
●Se due variabili contengono un riferimento 
al medesimo oggetto, ogni modifica operata 
ad un oggetto tramite un riferimento è 
anche visibile tramite l’altro riferimento
●Ad esempio:
Punto unitario = new Punto(1, 1);
Punto copia = unitario;
System.out.println( copia.getX()); // Stampa 1
copia.setX( 2);
System.out.println( unitario .getX()); // Stampa 2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#43,43,"Programmazione orientata agli oggetti
Side-Effect e Metodi  
●I metodi che aggiornano lo stato di oggetti di 
cui ricevono un riferimento (tra i parametri) 
producono effetti collaterali ( side-effect ) 
public class ModificatoreDiPunti {
public void azzera(Punto p) {
p.setX( 0); p.setY(0);
}
}
…
public static void main(String[] args) {
  ModificatoreDiPunti m = new ModificatoreDiPunti();
  Punto unitario = new Punto( 1, 1);
  m.azzera(unitario);
  System.out.println(unitario.getX()); // Stampa 0
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#44,44,"Programmazione orientata agli oggetti
Equivalenza tra Oggetti  vs 
Identicità dei Riferimenti
Punto origine = new Punto(0, 0);
Punto zeroZero = new Punto(0, 0);
if (origine == zeroZero)
System.out.println(“uguali”);
else
System.out.println(“diversi”);
●Stamperà “ uguali ” o “diversi ”?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#45,45,"Programmazione orientata agli oggetti
Identicità dei Riferimenti (1)
●L'operatore == verifica se il contenuto delle 
due variabili è identico
—origine  e zeroZero  contengono però 
riferimenti diversi verso due oggetti distinti 
(con diversi indirizzi di memoria)
—Sono quindi considerati diversi
Stack0x15db76fa origine:
Heap0x15db76fa :Punto
    x
0     y0
zeroZero: 0x15dbb7c2 :Punto
    x
0     y00x15dbb7c2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#46,46,"Programmazione orientata agli oggetti
Identicità dei Riferimenti (2)
●L'operatore ==, quando applicato a variabili che contengono 
riferimenti ad oggetti, verifica se i riferimenti raggiungono lo 
stesso oggetto
Punto origine = new Punto(0, 0);
Punto copiaDelRif = origine;
if (origine == copiaDelRif)
System.out.println(“uguali”);
else
System.out.println(“diversi”);
●Può essere applicato anche ad espressioni di tutti i tipi 
primitivi, con la semantica più naturale: identicità di valori
●Invece, per verificare se due oggetti distinti sono equivalenti 
in base al loro stato ( non in base ai riferimenti) è necessario 
implementare un criterio di equivalenza  tra oggetti di un 
certo tipo (>> )"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#47,47,"Programmazione orientata agli oggetti
Equivalenza fra Stringhe
●Molte classi offrono un metodo equals()  che definisce un 
criterio di equivalenza basato sullo stato
—verifica l'uguaglianza con un altro oggetto passato come 
parametro 
—segnatura niente affatto scontata (>>)
●Per il momento conviene vedere esempi di criteri di equivalenza 
già definiti nelle librerie standard, come per la classe String
●In Java le stringhe sono oggetti a tutti gli effetti
—è possibile confrontarle con il loro metodo equals()
—equivalenza carattere-per-carattere
String nome1 = new String(“alice”);
String nome2 = new String(“alice”);
System.out.println(nome1 == nome2);      // Stampa: false
System.out.println(nome1. equals(nome2)); // Stampa: true"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#48,48,"Programmazione orientata agli oggetti
Metodo equals()
●Il metodo equals()  si usa quando si vuole 
verificare l’ equivalenza  tra due oggetti distinti 
secondo un criterio definito dal programmatore 
(e dipendente dalla classe)
—In effetti vedremo che il metodo equals()  è 
offerto, sempre,  da tutte le classi (>>)
—Ma se non viene esplicitamente implementato 
(>>) ha la stessa semantica dell’operatore == 
per il confronto tra riferimenti
●Se lo scopo è quello di controllare se due 
variabili fanno riferimento allo stesso oggetto 
meglio usare, sempre e comunque, il più 
esplicito operatore =="
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#49,49,"Programmazione orientata agli oggetti
Uguaglianza con null
●L’uguaglianza di un riferimento ad oggetti con il 
valore null si verifica tramite l’operatore ==
—null è un valore speciale che può essere utilizzato 
per rapprensentare l’assenza di un oggetto (di un 
qualsiasi tipo )
●Tipica istruzione condizionale:
if (varRif!=null) {
  <operazioni su varRif non null>
  }
●Attenzione: valutando varRif.equals(null)  si 
ottiene
—false se varRif!=null
—NullPointerException  se varRif==null"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#5,5,"Programmazione orientata agli oggetti
Sintassi dei Costruttori
●I costruttori si denotano con lo stesso nome della 
classe in cui compaiono
●A differenza dei metodi, NON possono né devono 
specificare il tipo del valore restituito
—N.B. NON è nemmeno possibile usare void
public class Punto {
private int x;
private int y;
public Punto(int x, int y)  {
  this.x = x;
  this.y = y;
}
}
✔N.B. I costruttori NON sono niente affatto metodi
—Le differenze non sono limitate al solo tipo restituito"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#50,50,"Programmazione orientata agli oggetti
Null Simmetria dell’Equivalenza
✔  Quindi: a.equals(b)  non è, in generale, pari a 
b.equals(a)
●Comportamento atteso se a e b possono anche assumere 
valori null
●Se invece sia a sia b sono
●non nulle
●riferimenti ad oggetti dello stesso tipo
●È necessario che valgano le proprietà tipiche delle 
relazioni di equivalenza, come: 
–a.equals(a)                   ( riflessiva )  
–( a.equals(b) ) == ( b.equals(a) )  ( simmetrica )
–(altre seguiranno >>) "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#51,51,"Programmazione orientata agli oggetti
Riferimenti  in Java vs Puntatori  C
●Nel linguaggio C il concetto più simile a quello di 
riferimento Java è sicuramente quello di puntatore 
ad una cella di memoria
●N.B. sono e rimangono comunque concetti molto 
diversi, i cui costrutti, nei due linguaggi, 
supportano un insieme di operazioni ben diverse
—In C tale insieme di operazioni è molto più ampio
—In Java non esiste l'aritmetica dei puntatori come in 
C o C++
—In Java non è possibile referenziare nulla che non 
sia un oggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#52,52,"Programmazione orientata agli oggetti
Diagnostica: Riferimenti  vs Puntatori
●Per colpa di un errore di programmazione, spesso si 
finisce per produrre puntatori “impazziti” in C
—Questi a loro voltano, causano errori a tempo di esec.
—In buona parte i puntatori sono alla base della 
pessima diagnostica a tempo di esecuzione: non si 
può prevedere a cosa si finisce per accedere
✔risulta difficile risalire alla vera causa di un problema se 
gran parte degli errori viene diagnosticato con un 
generico Segmentation fault !"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#53,53,"Programmazione orientata agli oggetti
Riferimenti  vs Puntatori
●In Java i riferimenti sono stati progettati proprio per 
superare i limiti ed i difetti tipici dei puntatori in C
●In Java è stato deciso di evitare alla radice i rischi 
tipici dei puntatori
—Non è possibile referenziare nulla che non sia un 
oggetto
●Si “nasconde” al programmatore l'esistenza stessa 
del concetto di puntatore sostituendolo con il ben 
più “sicuro” riferimento ad oggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#54,54,"Programmazione orientata agli oggetti
Gestione della Memoria
●In Java l’operatore new (che serve ad allocare 
oggetti) è il costrutto più simile alla funzione (C) 
malloc
—entrambi allocano un’area di memoria nell’heap
●Ad ogni chiamata della funzione malloc  deve però 
corrispondere una chiamata ad una funzione free 
per deallocare l’area di memoria occupata 
nell’heap e restituirla ai successivi utilizzi
●In Java NON è necessario
—finora non è stata scritta neanche una operazione 
per liberare la memoria occupata con le new
●La deallocazione della memoria a carico della JVM
—specificatamente di un componente, il  Garbage Collector"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#55,55,"Programmazione orientata agli oggetti
Deallocazione della Memoria in C
●Deallocazione della memoria a carico del 
programmatore
●Possibili errori che ne conseguono, ad es.:
—malloc senza corrispondente free
Memory leak : perdita di memoria utilizzabile
—free senza porre il puntatore a NULL
Dangling Pointer : rimane disponibile un puntatore verso 
un’area di memoria non più disponibile
●N.B. è possibile avere la stessa problematica ancor più 
semplicemente (senza malloc) anche creando puntatori ad  
aree di memoria sullo stack non più in uso!
struct Punto *origine;
origine = malloc(sizeof(struct Punto));
free(origine);
origine->x = 0; // Comportamento indefinito "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#56,56,"Programmazione orientata agli oggetti
Deallocazione della Memoria in Java
●La piattaforma Java solleva il 
programmatore dalla responsabilità di 
deallocare esplicitamente la memoria
—La JVM si occupa, a tempo di esecuzione, di 
trovare gli oggetti inutilizzati e non più 
utilizzabili e recupera la loro memoria 
—Il componente della JVM che si occupa di 
questo compito si chiama Garbage Collector
●Alcuni esperti ritengono che questa sia la 
differenza tra i linguaggi C/Java che da sola, ed in 
assoluto, contribuisce in maggiore misura 
all’incremento di produttività dei programmatori 
Java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#57,57,"Programmazione orientata agli oggetti
Attenzione!
●Per prevenire fraintendimenti, meglio precisare 
subito che la gestione della memoria, ed un suo 
utilizzo appropriato, rimane comunque tra le più 
importanti responsabilità anche di un 
programmatore Java
●Il fatto che non è necessario fare esplicitamente le 
chiamate alla free non significa affatto che non si 
stia occupando memoria!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#58,58,"Programmazione orientata agli oggetti
Il Garbage Collector (1)
●Il ruolo del garbage collector è quello di identificare 
gli oggetti non utilizzati e non più utilizzabili
—Questi oggetti devono essere marcati come 
reclamabili
—la loro memoria recuperata per fare spazio 
all’allocazione di nuovi oggetti
●Come può succedere che un oggetto diventa 
reclamabile ? Semplice:
Punto origine = new Punto(0,0); // occupa mem.
origine = null;
// da qui in poi la memoria dell’oggetto può essere 
recuperata perché l’oggetto appena creato non è più 
raggiungibile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#59,59,"Programmazione orientata agli oggetti
●Dal punto di vista del Garbage Collector, un 
oggetto può essere:
—IN_USO : raggiungibile tramite una catena di 
riferimenti  
—RECLAMABILE : oggetto non più raggiungibile, non 
esiste alcuna catena di riferimenti  che vi arrivi 
●Catena di riferimenti: sequenza di riferimenti che 
parte dallo stato dell’esecuzione corrente e 
conduce ad un oggetto
—eventualmente passando attraverso diversi 
oggetti intermedi 
●Come di creano queste catene?
●Da dove iniziano? Il Garbage Collector (2)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#6,6,"Programmazione orientata agli oggetti
Invocazione dei Costruttori
●Attraverso l’operatore new è possibile invocare 
il costruttore e specificare degli argomenti
●Ad esempio:
Punto origine = new Punto(0, 0) ;
System.out.println(origine.getX()); // Stampa 0Parametri attuali del costruttore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#60,60,"Programmazione orientata agli oggetti
Il Garbage Collector: 
Catene di Riferimenti (1)
●I riferimenti costituiscono un grafo orientato
—Si pensi ad una possibile classe Persona
:Persona
nome
figlio“Adamo”
padre:Persona
nome
figlio“Caino”
padre
:Persona
nome
figlio“Enoch”
padre"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#61,61,"Programmazione orientata agli oggetti
HeapIl Garbage Collector: 
Catene di Riferimenti (2)
●Se la prima persona ( Adamo ) è raggiungibile 
tutte le altre mostrate nello schema sono allora 
raggiungibili (indirettamente tramite la prima)
●Riferimento iniziale  (>>):
●Se la prima persona non fosse raggiungibile,
nessuna delle altre lo sarebbe 
:Persona
nome
figlio“Adamo”
padre:Persona
nome
figlio“Caino”
padre
:Persona
nome
figlio“Enoch”
padreadamo
Stack"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#62,62,"Programmazione orientata agli oggetti
Il Garbage Collector: 
Catene di Riferimenti (3)
●Per interrompere una catena di riferimenti è  
sufficiente porre a null una variabile (di istanza o 
locale) che contiene il riferimento ad un oggetto
adamo.setFiglio(null);
:Persona
nome
figlio“Adamo”
padre:Persona
nome
figlio“Caino”
padre
:Persona
nome
figlio“Enoch”
padreX
●Adesso, Caino e 
Enoch non saranno
più raggiungibili e
quindi la loro memoria
può essere recuperataadamo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#63,63,"Programmazione orientata agli oggetti
Il Garbage Collector: 
Catene di Riferimenti (4)
●In questo modo il Garbage Collector rileva che 
gli oggetti Caino ed Enoch  non saranno più 
utilizzati
—verranno marcati come reclamabili
●Mettendo a null il riferimento verso Caino non 
è più possibile raggiungerli
:Persona
nome
figli
p“Adamo”
padre:Persona
nome
figli
o“Caino”
padre
:Persona
nome
figli
o“Enoch”
padreX
—Quando il Garbage
Collector entrerà in
azione marcherà la loro
memoria come reclamabile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#64,64,"Programmazione orientata agli oggetti
Il Garbage Collector: 
Catene di Riferimenti (5)
●Un oggetto può diventare irraggiungibile anche 
sovrascrivendo  un riferimento
Persona abele = new Persona(“Abele”);
adamo.setFiglio(abele);
:Persona
nome
figlio“Adamo”
padre:Persona
nome
figlio“Caino”
padre
:Persona
nome
figlio“Enoch”
padreX
:Persona
nome
figlio“Abele”
padre●Enoch e Caino 
non sono più 
raggiungibili, la 
loro memoria 
verrà marcata 
come reclamabile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#65,65,"Programmazione orientata agli oggetti
Inizio delle Catene di Riferimenti
●Sinora si supponeva che il primo oggetto 
Adamo  fosse raggiungibile
—è necessario avere un primo riferimento per 
iniziare le catene
—sia gli oggetti sia le variabili di istanza 
contenenti i riferimenti si trovano nell’heap
●Quali oggetti sono però raggiungibili da fuori 
dell’heap, e con quali riferimenti iniziali?
—Quelli referenziati dalle variabili locali o dai 
parametri dei metodi i cui RDA sono nello 
Stack"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#66,66,"Programmazione orientata agli oggetti
Garbage Collection (1)
●L’algoritmo lavora inseguendo i riferimenti a 
cominciare da quelli contenuti dentro i RDA (var. 
locali e parametri attuali) nello Stack 
—esplora il grafo dei riferimenti dentro l’Heap
—continua con quelli conservati nelle var. di istanza 
degli oggetti conservati nell’ Heap
—se un oggetto è 
●Raggiungibile : allora viene mantenuto in memoria
●Non raggiungibile : la sua memoria viene marcata 
reclamabile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#67,67,"Programmazione orientata agli oggetti
Garbage Collection (2)
●Successivamente  (quando serve memoria e non 
necessariamente subito) la memoria reclamabile 
viene recuperata per poter allocare nuovi oggetti
●Abbiamo discusso solo i problemi ed i concetti 
basilari di una semplice implementazione 
dell’Algoritmo di Garbage Collection
—Enorme interesse per questi algoritmi
—Quelli utilizzati sono il risultato di decadi di ricerca 
(accademica ed industriale)
—Una delle classi di algoritmi più studiate in assoluto: 
sempre più veloci ed ottimizzati"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#68,68,"Programmazione orientata agli oggetti
Garbage Collection:
Vantaggi e Svantaggi
●Facilitano lo sviluppo rapido di applicazioni
●Tuttavia esistono alcuni importanti svantaggi:
—La visita del grafo dei riferimenti è un’operazione 
onerosa che limita le prestazioni
—Il garbage collector è fuori dal controllo diretto del 
programmatore
●può intervenire in momenti non facilmente 
prevedibili e talvolta inopportuni
●non adatto in tutte le situazioni in cui i tempi di 
risposta devono essere prevedibili con certezza
●Un programmatore esperto può sicuramente ottenere 
prestazioni migliori gestendo la memoria 
manualmente ma specificatamente per la sua 
applicazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#7,7,"Programmazione orientata agli oggetti
Oggetti in Corso di Costruzione
●Il corpo del costruttore è adibito alla costruzione 
dello stato iniziale dell’oggetto creato
●Dal momento dell’invocazione dell’operatore  per 
la creazione  di un nuovo oggetto
—new Punto()
al momento in cui l’esecuzione del corpo del 
costruttore è completamente terminata, 
l’inizializzazione dello stato non è completa
●Durante la costruzione l'oggetto transita per una 
serie di stati intermedi, ovvero è inconsistente
—è buona regola  non farsi mai “sfuggire” riferimenti ad 
oggetti in uno stato potenzialmente inconsistente (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#8,8,"Programmazione orientata agli oggetti
Esempio (con Eclipse)
●Implementare il costruttore della classe 
Rettangolo
—I parametri servono a specificare
●vertice
●base
●altezza
dell’oggetto appena creato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-04-gestione-memoria.pdf#9,9,"Programmazione orientata agli oggetti
Esempio  (2)
public class Rettangolo {
 private Punto vertice;
 private int base;
 private int altezza;
 public Rettangolo(Punto v, int base, int altezza) {
  this.vertice = v;
  this.base = base;
  this.altezza = altezza;
 }
// soliti getter
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#0,0,"Programmazione
Orientata agli Oggetti
Overloading, Costruttori, 
Stringhe e Array"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
Overloading
Costruttore primario e costruttori secondari
La classe String
–Il metodo  toString()
Diagramma degli oggetti
Array
Costanti
Variabili e metodi di classe"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#10,10,"Programmazione orientata agli oggetti
Esempio (2)
public class Rettangolo {
  private int base;
  private int altezza;
  // …
  public void scala(float fattore) {
     this.scala(fattore, fattore);
  } 
   public void scala(float fattoreBase,
                     float fattoreAltezza) {
      this.base *= fattoreBase;
      this.altezza *= fattoreAltezza;
   }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#11,11,"Programmazione orientata agli oggetti
Esempio (3)
●Notare come il metodo
scala(float fattore)
faccia uso del metodo
scala(float fattoreBase, float fattoreAltezza)
...per evitare la duplicazione del codice (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#12,12,"Programmazione orientata agli oggetti
Risoluzione Metodi Sovraccarichi (1)
●In assenza di una corrispondenza perfetta tra
—lista dei parametri attuali di una invocazione
—segnatura di un metodo
il compilatore applica un algoritmo di risoluzione che 
prima di fermare la compilazione cerca di capire se 
semplici conversioni di tipo permettono la chiamata
—Ad es. int → float
●L’algoritmo è intriso di dettagli per coprire l’ampia 
casistica; in pratica basta quasi sempre limitarsi a 
ricordare che:
—sono ammesse semplici promozioni di tipo se necessarie 
a rendere un’invocazione confacente con una delle 
segnature disponibili
—sono preferite le promozioni più “conservative”, ovvero 
quelle al tipo immediatamente più grande"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#13,13,"Programmazione orientata agli oggetti
Risoluzione Metodi Sovraccarichi (2)
•Più nel dettaglio:
–Argomento di tipo intero
•se esiste un metodo che prende come parametro 
formale int, allora viene usato quel metodo
•altrimenti viene promosso al tipo di dato più piccolo tra 
quelli disponibili (ma “capaci di contenere” un int): 
long, float, double
–Argomento in virgola mobile
•Si cerca il metodo che ha come parametro formale un 
double
–Argomento di tipo carattere
•Se non trova una corrispondenza con char, si prova la 
promozione a int"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#14,14,"Programmazione orientata agli oggetti
Risoluzione Metodi: Esempio
Motivo di confusione è la promozione implicita  di tipo 
per i tipi primitivi. Ad esempio:
public class Prova {
   void f(long i)   { System.out.println(""long"");   }
   void f(float i)  { System.out.println(""float"");  }
   void f(double i) { System.out.println(""double""); }
   public static void main(String[] args) {
     f(5); // ???
   }
}
public class Prova {
   void f(long i)   { System.out.println(""long"");   }
   void f(float f)   { System.out.println(""float"");   }
   void f(double i) { System.out.println(""double""); }
   public static void main(String[] args) {
     f(5);  // ???
     f(5f); // ???
   }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#15,15,"Programmazione orientata agli oggetti
Con Riferimenti: Cosa Stampa?
public class Boo {
  void f(String n) {
    System.out.println(""stringa"");
  }
  void f(int n) {
    System.out.println(""intero"");
  }
  public static void main(String[] args) {
    Boo b = new Boo();
    String s = new String(""pppp"");
    int i = 0;
    b.f(s);
    b.f(i);
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#16,16,"Programmazione orientata agli oggetti
Overloading di Operatori
●L'overloading è una caratteristica comoda ma usata in 
maniera decisamente controllata in Java
●Anche l'operatore + è sovraccarico: così come già accade 
in C, risulta più agevole la manipolazione di tipi numerici
—Somma interi ( int, long)
—Somma numeri in virgola mobile ( float, double)
●Invece specifica del linguaggio Java è la sua applicazione 
ad una classe con un supporto particolare: String 
—Concatenazione di stringhe; Ad es.:
—System.out.println(""Ciao""+"" ""+""Mondo "");
●In C++ (ed in Scala) c’è anche la possibilità di 
sovraccaricare tutti gli altri operatori, in Java 
(fortunatamente) NO
—per il pessimo rapporto costi/benefici"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#17,17,"Programmazione orientata agli oggetti
Costruttori ed Overloading
●Anche i costruttori possono essere sovraccarichi
●Ad esempio la classe Rettangolo  potrebbe 
avere i seguenti costruttori
—Un costruttore no-args . Quindi
●base = 0; altezza = 0, vertice = (0, 0)
—Un costruttore che ha come parametri base e 
altezza. Quindi:
●vertice = (0, 0)
—Un costruttore generico
●vertice
●base
●altezza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#18,18,"Programmazione orientata agli oggetti
Esempio ( con Eclipse )
●Realizzare i costruttori della classe Rettangolo  
appena descritti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#19,19,"Programmazione orientata agli oggetti
Esempio (2)
public class Rettangolo {
  private int altezza;
  private int base;
  private Punto vertice;
  public Rettangolo(Punto vert, int base, int altezza) {
    this.vertice = vert;
    this.base = base;
    this.altezza = altezza;
  }
  public Rettangolo(int base, int altezza) {
    this.vertice = new Punto(0, 0);
    this.base = base;
    this.altezza = altezza;
  }
  public Rettangolo() {
    this.vertice = new Punto(0, 0);
    this.base = 0;
    this.altezza = 0;
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#2,2,"Programmazione orientata agli oggetti
Overloading (1)
●Caratteristica che permette ad un linguaggio di 
programmazione di definire molteplici 
metodi/funzioni/procedure con lo stesso nome 
●Una classe Java può ospitare due o più versioni  
dello stesso metodo (ovvero, con lo stesso nome)
●T ale metodo si dice sovraccarico
●Le versioni sovraccariche dello stesso metodo 
devono comunque risultare distinguibili
●Devono differire per la lista di parametri formali
—per numero di parametri, e/o
—per il tipo di uno o più parametri, e/o
—per l’ordine dei parametri"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#20,20,"Programmazione orientata agli oggetti
Esempio (3)
public class MainOverloading {
  public static void main(String[] args) {
   // base 0, altezza 0, vertice in (0, 0) 
Rettangolo r1 = new Rettangolo();
// base 3, altezza 5, vertice in (0, 0)
Rettangolo r2 = new Rettangolo(3, 5);
Punto vertice = new Punto(4, 9);
Rettangolo r3 = new Rettangolo(vertice, 3, 5);
  }
}
 "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#21,21,"Programmazione orientata agli oggetti
Costruttore “Primario”
●Costruttori definiti ripetendo molto codice,  come 
appena fatto sono... sconsigliabili!
●Le ripetizioni nel codice causano problemi (>>)
●Meglio eleggere un costruttore al ruolo di 
“primario” , il più generico possibile
●Eccolo per la classe Rettangolo :
public Rettangolo(Punto vertice, int base, int altezza) {
this.vertice = vertice;
this.base = base;
this.altezza = altezza;
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#22,22,"Programmazione orientata agli oggetti
Costruttori “Secondari”
●A questo punto, gli altri costruttori ( “secondari” ) 
possono affidarsi a quello più generico
●Per invocare un costruttore da un costruttore:
this(<lista di argomenti>)
—L'invocazione di un altro costruttore deve essere la 
prima istruzione  nel corpo del costruttore secondario
●Altrimenti: errore di compilazione
●I costruttori secondari finiscono per fissare dei 
fissare dei valori predefiniti per tutti i parametri 
che non ricevono esplicitamente
●In Scala esiste una sintassi apposita per 
distinguere costruttori primari  dai secondari , in 
Java NO"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#23,23,"Programmazione orientata agli oggetti
Costruttori Chiamati dai Costruttori
public class Rettangolo {
  private int altezza;
  private int base;
  private Punto vertice;
  public Rettangolo(Punto vert, int base, int altezza) {
    this.vertice = vert;
    this.base = base;
    this.altezza = altezza;
  }
  public Rettangolo(int base, int altezza) {
    this(new Punto(0, 0), base, altezza);
  }
  public Rettangolo() {
    this(new Punto(0, 0), 0, 0);
  }
}Crea un nuovo 
oggetto Punto ed 
invoca un altro 
costruttore entro 
un’unica (la prima) 
riga di codice"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#24,24,"Programmazione orientata agli oggetti
La Classe String (1) 
●In Java esiste la classe String  per rappresentare 
sequenze di caratteri immutabili
—Le stringhe sono oggetti, String è la classe a cui 
appartengono le sue istanze
●Una variabile dichiarata di tipo String  contiene 
quindi un riferimento  ad un oggetto istanza della 
classe String
●String favorita = new String( ""Sono la favorita ""!);
●Pur essendo una classe come tutte le altre, spesso 
si ha la tentazione di pensare che non lo sia 
affatto…
●Il motivo è che ha un supporto molto particolare sia 
nel linguaggio che da parte del compilatore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#25,25,"Programmazione orientata agli oggetti
La Classe String (2)
●Per rendere il linguaggio più semplice ed attraente per nuovi 
sviluppatori, all’epoca si decisero trattamenti decisamente 
“di favore” per questa classe
●Prima di Java 5 era (>>)
—l’unica classe che possiede dei letterali appositi
—l’unico tipo di oggetto che si può creare senza fare una new 
esplicita
●String favorita = ""Sono la favorita! "";
equivale a 
●String favorita = new String( ""Sono la favorita! "");
●L’inserimento dell’invocazione della new è operata 
direttamente dal compilatore
●Anche il fatto che l’operatore + sia sovraccarico per gestire 
la concatenazione conferma il trattamento di favore…
●Sicuramente tutto questo “opacizza” il codice (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#26,26,"Programmazione orientata agli oggetti
Equivalenza di Stringhe (1)
●Dato che le stringhe sono oggetti veri e propri, 
l’equivalenza deve essere valutata mediante il  
metodo appositamente previsto dalla classe equals()
Infatti:
—String nome = new String( ""Alice"");
—String omonimo = new String( ""Alice"");
System.out.println(nome == omonimo);
// Stampa false"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#27,27,"Programmazione orientata agli oggetti
Equivalenza di Stringhe (2)
String nome = new String(…);
:String oggetto
String omonimo = new String(…);
:String●Si sta in realtà verificando che i riferimenti  risultino 
identici
—falso: nome e omonimo  contengono riferimenti diversi, 
ovvero restituiti da due distinte invocazioni della new
“Alice”“Alice”
oggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#28,28,"Programmazione orientata agli oggetti
Equivalenza di Stringhe (3)
●Invece, utilizzando:
String nome = new String(“Alice”);
String omonimo = new String(“Alice”);
System.out.println(nome.equals(omonimo)); 
// stampa true
il metodo equals()  controllerà l’equivalenza della 
sequenza di caratteri che compone le stringhe, 
carattere per carattere "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#29,29,"Programmazione orientata agli oggetti
Immutabilità della Classe String
●Gli oggetti String  usati per rappresentare 
stringhe in Java sono immutabili
—Non è possibile modificare i caratteri all’interno di 
una stringa una volta creata
—Non si possono aggiornare: bisogna sempre crearne 
di nuove per memorizzare la modifica
●Ad esempio per concatenare due stringhe:
String s1 = “ciao ”; // = new String(“ciao ”);
String s2 = “mondo”; // = new String (“mondo”);
s1 = s1 + s2; // → Si sta creando un nuovo oggetto  
  // String  e si sta sovrascrivendo il vecchio 
riferimento
System.out.println(s1); // ciao mondo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#3,3,"Programmazione orientata agli oggetti
Overloading (2)
●La classe Sommatore  può avere più metodi di stesso nome 
per sommare due interi o tre interi
public class Sommatore {
public int add(int a, int b)  { return a + b; }
public int add(int a, int b, int c)  {
return a + b + c;
}
}
●Il tipo e l’ordine dei parametri è significativo:
public double add(int a, double b)  {
return a + b;
}
… è un metodo distinto da:
public double add(double a, int b)  {
return a + b;
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#30,30,"Programmazione orientata agli oggetti
Metodi della Classe String (1)
●String s = ""POO "";
—Lunghezza della stringa
s.length();  restituisce 3
—Ottenere un carattere in una certa posizione
s.charAt(0);  restituisce ‘ P’ 
●Indicizzazione base 0
●come per gli array il primo carattere ha indice 0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#31,31,"Programmazione orientata agli oggetti
Metodi della Classe String (2)
●String s = ""una stringa "";
—Indice di un carattere
s.indexOf(‘s’);  restituisce 4
—Indice di una stringa
—s.indexOf( ""ring""); restituisce 6
Il metodo indexOf()  è sovraccarico
—Restituisce -1 se non trova il carattere o la stringa 
cercata
s.indexOf(‘z’);  restituisce -1"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#32,32,"Programmazione orientata agli oggetti
Metodi della Classe String (3)
●String s = ""una stringa "";
—Rimpiazzare caratteri
●String s2 = s.replace( ""stringa "", ""stringa lunga "");
System.out.println(s);  // Stampa ‘una stringa’
System.out.println(s2); // Stampa ‘una stringa lunga’
—Le stringhe sono immutabili: in realtà si crea un 
nuovo oggetto String  il cui riferimento finisce in s2
—molti e molti altri metodi ancora….
https://docs.oracle.com/javase/7/docs/api/java/lang/String.html"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#33,33,"Programmazione orientata agli oggetti
Stampare Descrizioni di Oggetti
●Se si esegue  println() su un riferimento ad un 
oggetto verrà stampato il valore di tale riferimento
// un attrezzo di nome spada e peso 7 kg
●Attrezzo spada = new Attrezzo( ""spada"", 7);
System.out.println(spada);
●Stampa, ad es.:  Attrezzo@70dea4e
—Non descrive affatto il contenuto e lo stato dell’oggetto, 
ma il riferimento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#34,34,"Programmazione orientata agli oggetti
Il Metodo toString()  (1)
●È possibile cambiare questo comportamento 
implementando di segnatura:
   public String toString()
per tutte le classi in cui si vuole specificare come 
trasformare gli oggetti in stringhe
●Il metodo toString()  restituisce la 
rappresentazione dell’oggetto sotto forma di 
stringa
●Addirittura fondamentale per rendere agevole il 
debugging  ed il tracing"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#35,35,"Programmazione orientata agli oggetti
Il Metodo toString()  (2)
●Ad esempio in Attrezzo
public class Attrezzo {
  private String nome;
  private int peso;
  public Attrezzo(String nome, int peso) {
this.nome = nome; this.peso = peso;
  }
  // getter
  public String toString()  {
return ""Attrezzo di nome ""+ this.getNome() + 
       "". Peso: ""+ this.getPeso();
  }
}  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#36,36,"Programmazione orientata agli oggetti
Il Metodo toString()  (3)
public class MainToString {
public static void main(String[] args) {
●Attrezzo spada = new Attrezzo(""spada "", 7);
System.out.println( spada);
}
}
●Stampa
Attrezzo di nome spada. Peso: 7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#37,37,"Programmazione orientata agli oggetti
Il Metodo toString()  (4)
●Stesso comportamento concatenando un 
riferimento ad un oggetto con un  letterale 
stringa:
public class MainToString {
  public static void main(String[] args) {
    Attrezzo spada = new Attrezzo( ""spada"", 7);
    String descr = ""attrezzo posseduto: "" + spada;
System.out.println(descr);
}
}
Stampa:
  attrezzo posseduto: Attrezzo di nome spada. Peso: 7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#38,38,"Programmazione orientata agli oggetti
println() & toString()
●Il metodo toString()  (come equals() ), anche 
è  presente in tutti gli oggetti che creiamo (>>)
●Tuttavia:
—Se non esplicitamente implementato stampa [un 
numero che dipende dal]l’indirizzo di memoria 
dell’oggetto su cui è invocato
—L’invocazione del metodo  toString() , è inserita 
direttamente dal compilatore, nelle istruzioni di 
stampa (anche se non esplicitamente richiesta!):
●System.out.println(oggRef)  
stampa il risultato di oggRef.toString()  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#39,39,"Programmazione orientata agli oggetti
Diagramma delle Classi
•Diagrammi UML
–Ne esistono diversi tipi
•Sono un utile e comodo strumento a supporto (e non in 
sostituzione) della comunicazione
–Tempo dinamico: abbiamo già utilizzato 
rappresentazioni diagrammatiche degli oggetti
–Tempo statico: diagrammi delle classi
•Il diagramma delle classi illustra le caratteristiche 
principali (variabili di istanza, costruttori e metodi) delle 
classi che compongono la applicazione
•L’enfasi è sulla relazione tra le classi, quindi sugli 
aspetti “statici”"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#4,4,"Programmazione orientata agli oggetti
Overloading: in C?
●Il linguaggio C non supporta l’overloading
—Non si possono definire due funzioni con lo stesso nome
●A conferma che questa possibilità offerta dal linguaggio 
Java è avvertita come una viva esigenza da molti 
programmatori, basta osservare la convenzione adottata da 
molti programmatori C per gestire situazioni simili, ovvero:
—double add_id(int a, double b)
—double add_di(double a, int b)
✔I nomi sono resi sintatticamente diversi, con un prefisso 
comune che rende evidente l’esistenza di una radice 
comune"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#40,40,"Programmazione orientata agli oggetti
Esempio
•Supponiamo
   public class Stanza {
   private String nome;
   private Attrezzo attrezzo;
   public Stanza(String nome) {
    this.nome = nome;
   }   
   
   public void setAttrezzo(Attrezzo attrezzo) {
   this.attrezzo = attrezzo;
   }
   … altri metodi
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#41,41,"Programmazione orientata agli oggetti
Diagramma delle Classi: Esempio
Stanza
String 
Attrezzo
 
Per modellare le adiacenze"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#42,42,"Programmazione orientata agli oggetti
Diagramma degli Oggetti (1)
•Per avere un’idea della evoluzione di un 
programma è utile rappresentare lo stato delle 
istanze: a tal fine usiamo una rappresentazione 
grafica, chiamata diagramma degli oggetti
•Il diagramma degli oggetti mostra gli oggetti 
istanziati in memoria durante l’esecuzione 
dell’applicazione 
•L’enfasi è sullo stato interno degli oggetti e sugli 
aspetti dinamici
–ogni oggetto ha un indirizzo di memoria
–le variabili di tipo riferimento ad oggetto 
memorizzano l'indirizzo dell'oggetto referenziato
–una rappresentazione grafica efficace basata sull’uso 
di frecce..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#43,43,"Programmazione orientata agli oggetti
Esempio
…
       public static void main(String[] args) {
       Attrezzo spada = new Attrezzo(""spada"", 10);
       Stanza n10 = new Stanza(""Aula N10"");
       n10.addAttrezzo(spada);
       // < ---
       /* disegnare il diagramma degli oggetti 
          in questo punto dell’esecuzione */
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#44,44,"Programmazione orientata agli oggetti
Diagramma degli Oggetti: Esempio (1)
@01:Stanza @21:String
""Aula N10""
@32:Attrezzo@21nome
attrezzo
…@32
@67:String
""spada""nome
peso     10  @67"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#45,45,"Programmazione orientata agli oggetti
Diagramma degli Oggetti (2)
•Una rappresentazione grafica efficace dei 
valori memorizzati nelle variabili riferimento 
prevede l'uso di frecce che collegano 
–la variabile riferimento 
–all'oggetto referenziato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#46,46,"Programmazione orientata agli oggetti
Diagramma degli Oggetti: Esempio (2)
:Stanza :String
""Aula N10""
nome
attrezzo
:Attrezzo
nome
peso     10  
:String
""Spada"""
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#47,47,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti
•Dal diagramma degli oggetti notiamo che le 
variabili (di istanza) possono memorizzare 
–tipi primitivi
–riferimenti ad oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#48,48,"Programmazione orientata agli oggetti
Tipi Primitivi in Java
boolean  vero (true) o falso ( false)
char caratteri Unicode 2.1 (16-bit) 
byte  interi a 8 bit (con segno e in C2)
short interi a 16 bit (con segno in C2)
int interi a 32 bit (con segno in C2)
long interi a 64 bit (con segno in C2)
float numeri in virgola mobile a 32-bit
double  numeri in virgola mobile a 64-bit"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#49,49,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (1)
32
OggettoTipo primitivo
Stanza s;int i;
:StanzaRiferimento ad Oggetto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#5,5,"Programmazione orientata agli oggetti
Risoluzione Chiamate in Overloading
●Per ciascuna invocazione di metodo (sovraccarico) 
si confrontano:
—tutte le segnature  del metodo, ed in particolare
●tipo e numero dei parametri formali
—con la lista dei parametri attuali
●In presenza di una lista di parametri formali in 
perfetto accordo con la segnatura di un metodo 
(per numero e tipo di parametri), la scelta è 
semplice:
—Si utilizza la versione di un metodo sovraccarico 
che segue fedelmente il numero ed il tipo dei 
parametri attuali"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#50,50,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (2)
•La variabile s non  memorizza un oggetto 
(nell'esempio, una istanza della classe 
Stanza ), ma un riferimento all’oggettooggettoStanza s = new Stanza(…);
:Stanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#51,51,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (3)
•Nel caso dei tipi primitivi, il valore è 
memorizzato direttamente nella variabile32Tipo primitivoint i;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#52,52,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (4)
32Tipi primitiviMiaClasse a;
int a;
MiaClasse b;
32int b;a = b;Oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#53,53,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (5)
int i1 = 0;
int i2 = 5;
i1 = i2;
i1
i20
55"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#54,54,"Programmazione orientata agli oggetti
String  nei Diagrammi ad Oggetti
●Come il compilatore Java, anche noi 
riserviamo un trattamento di favore agli 
oggetti istanza della classe String
:Stanza
nome
:String
""Atrio""
:Stanza
nome""Atrio"""
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#55,55,"Programmazione orientata agli oggetti
Tipi Primitivi e Oggetti (6)
Stanza s1;
s1 = new Stanza(""atrio"");
Stanza s2;
s2 = new Stanza(""bar"");
s1 = s2;
s1
s2:Stanza
nome
:Stanza
nome""Bar""""Atrio"""
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#56,56,"Programmazione orientata agli oggetti
Esercizio
•Disegnare il diagramma degli oggetti che 
rappresenta lo stato degli oggetti 
referenziati dalle variabili a, b, c del 
seguente programma al termine della 
esecuzione della istruzione in linea 3
1.Attrezzo a = new Attrezzo(""spada"", 40);
2.Attrezzo b = new Attrezzo(""scudo"", 30);
3.Attrezzo c = new Attrezzo(""lancia"", 10);
4.a = b;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#57,57,"Programmazione orientata agli oggetti
Esercizio
•Disegnare il diagramma degli oggetti che 
rappresenta lo stato degli oggetti 
referenziati dalle variabili a, b, c del 
seguente programma al termine della 
esecuzione della istruzione in linea 4
1.Attrezzo a = new Attrezzo(""spada"", 40);
2.Attrezzo b = new Attrezzo(""scudo"", 30);
3.Attrezzo c = new Attrezzo(""lancia"", 10);
4.a = b;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#58,58,"Programmazione orientata agli oggetti
Esercizio
•Disegnare il diagramma degli oggetti che 
rappresenta lo stato del seguente programma al 
termine della esecuzione della istruzione in linea 5
•Quale valore ha il peso dell'attrezzo che si trova 
nella stanza referenziata dalla variabile s al termine 
della istruzione 4? E al termine della istruzione 5? 
1.Attrezzo a = new Attrezzo(""spada"", 40);
2.Attrezzo b = new Attrezzo(""lancia"", 10);
3.Stanza s = new Stanza(""N10"");
4.s.setAttrezzo(a);
5.a = b;
6.System.out.println(s.toString()); //quale attrezzo è 
7.                            //presente nella stanza s?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#59,59,"Programmazione orientata agli oggetti
Array (1)
•Un array definisce una struttura di dati che 
memorizza un insieme di valori dello stesso tipo
•Dichiarazione di una variabile array:
int[] a;
•L'oggetto array va creato, specificando il numero di 
elementi
a = new int[10];
•Un array può essere inizializzato esplicitamente al 
momento della creazione:
int[] a = {21,12,23,34,15,21,7,80,1,-21};
•In ogni caso verrà inizializzato con dei valori di 
default"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#6,6,"Programmazione orientata agli oggetti
Chi Risolve le Chiamate 
Sovraccariche?
•Quando viene operata la scelta?
–a tempo statico (durante la compilazione ) 
oppure 
–a tempo dinamico (durante l’ esecuzione ) 
•E’ il compilatore  a decidere  quale versione di un 
metodo sovraccarico invocare
–Già durante la compilazione (a tempo statico)
–La scelta è definitiva, scritta nei . class generati
–Operata esclusivamente sulla base dell’analisi dei 
tipi della lista di parametri attuali (nell’invocazione 
di metodo) effettuata durante la compilazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#60,60,"Programmazione orientata agli oggetti
Array (2)
•Le sintassi 
int[] array  e int array[]
sono equivalenti.
•int[] array  forse più esplicita:
–già dal prefisso della dichiarazione si capisce che la 
variabile seguente è un array"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#61,61,"Programmazione orientata agli oggetti
Array (3)
•È possibile accedere a ciascun valore dell'array 
mediante un indice
int[] a;
int i;
a = new int[10];
i = a[4];
a[6] = 3*i;
•Attenzione: gli array in Java (come in C) usano base-0: 
l'indice del primo elemento è 0
•Per avere la dimensione di un array: .length
•Scansione degli elementi di un array:
for (int i = 0; i< a.length; i++)
System.out.println(a[i]);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#62,62,"Programmazione orientata agli oggetti
Array (4)
•A partire da Java 5 è stata introdotta una variante 
del costrutto for (chiamata for-each ) che consente 
di scorrere gli elementi di un array (e, come 
vedremo, anche di altre tipologie di collezioni) 
senza gestire esplicitamente l'indice di iterazione:
int a[];
a = new int[100];
for (int elemento : a)
System.out.println(elemento);
equivale a:
for (int i=0; i<a.length; i++)  {
int elemento = a[i];
System.out.println(elemento);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#63,63,"Programmazione orientata agli oggetti
Array: Diagramma degli Oggetti
int[] a;
a = new int[10];
int[]
a [0]
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9] 0
 0
 0
 0
 0
 0
 0
 0
 0 0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#64,64,"Programmazione orientata agli oggetti
Array: Diagramma degli Oggetti
int[] a;
a = new int[10];
a[0] = 5;
:int[]
a [0]        5
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9] 0
 0
 0
 0
 0
 0
 0
 0
 0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#65,65,"Programmazione orientata agli oggetti
Array: Diagramma degli Oggetti
Attrezzo attrezzi[];
attrezzi = new Attrezzo[10];
:Attrezzo[] attrezzi
[0]
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#66,66,"Programmazione orientata agli oggetti
Array: Diagramma degli Oggetti
Attrezzo attrezzi[];
attrezzi = new Attrezzo[10];
attrezzi[0] = new Attrezzo(""vite"",1);
attrezzi[5] = new Attrezzo(""dado"",2);
:Attrezzo[]
[0]
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
:Attrezzo
nome""vite""
peso  1  
:Attrezzo
nome""dado""
peso  2  attrezzi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#67,67,"Programmazione orientata agli oggetti
Array: Diagramma degli Oggetti
Attrezzo[] attrezzi;
attrezzi = new Attrezzo[10];
attrezzi[0] = new Attrezzo(""vite"",1);
attrezzi[5] = new Attrezzo(""dado"",2);
attrezzi[3] = attrezzi[0];
:Attrezzo[]
a[0]
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
:Attrezzo
nome""vite""
peso  1  
:Attrezzo
nome""dado""
peso  2  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#68,68,"Programmazione orientata agli oggetti
Esercizio
•Disegnare il diagramma degli oggetti che 
rappresenta lo stato del seguente programma al 
termine della esecuzione della istruzione in linea 7
•Quale valore ha il peso dell'attrezzo referenziato 
dalla variabile con indice 0 dell'array al termine 
della istruzione 6? E al termine dell’istruzione 7? 
1.Attrezzo[] attrezzi;
2.attrezzi = new Attrezzo[5];
3.Attrezzo a = new Attrezzo(""spada"", 40);
4.Attrezzo b = new Attrezzo(""scudo"", 30);
5.attrezzi[0] = a;
6.attrezzi[1] = b;
7.a = b;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#69,69,"Programmazione orientata agli oggetti
Esercizio
•Disegnare il diagramma degli oggetti che 
rappresenta lo stato del seguente programma al 
termine della esecuzione della istruzione in linea 7
•Quale valore ha il peso dell'attrezzo referenziato 
dalla variabile con indice 0 dell'array al termine 
della istruzione 6? E al termine della istruzione 7? 
1.Attrezzo[] attrezzi;
2.attrezzi = new Attrezzo[5];
3.Attrezzo a = new Attrezzo(""spada"", 40);
4.Attrezzo b = new Attrezzo(""scudo"", 30);
5.attrezzi[0] = a;
6.attrezzi[1] = b;
7.attrezzi[0] = attrezzi[1];"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#7,7,"Programmazione orientata agli oggetti
Overloading
public class ProvaOverloading {
 public void metodo(int a) {
  System.out.println(“parametro int”);
 }
 public void metodo(double a) {
  System.out.println(“parametro double”);
 }
}
ProvaOverloading prova = new ProvaOverloading();
prova.metodo(3);    // Stampa “parametro intero”
prova.metodo(3.0d); // Stampa “parametro double”"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#70,70,"Programmazione orientata agli oggetti
Esercizio ( con Eclipse )
●Riscrivere la classe Stanza  in modo che 
contenga un array di Attrezzi
—Implementare quindi il metodo:
boolean  addAttrezzo(Attrezzo attrezzo)
aggiunge un attrezzo nella stanza. 
—Se c’è spazio restituisce true; altrimenti 
restituisce false
—quindi aggiungere il metodo 
boolean hasAttrezzo(String nomeAttrezzo)
Controlla che nella stanza ci sia un attrezzo di nome 
nomeAttrezzo:
—Se presente restituisce  true; altrimenti  false"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#71,71,"Programmazione orientata agli oggetti
Esercizio
public class Stanza {
private Attrezzo[] attrezzi;
private int numeroAttrezzi;
private String nome;
public Stanza(String nome) {
this.nome = nome;
this.attrezzi = new Attrezzo[10]; // per ora solo 10 attrezzi
this.numeroAttrezzi = 0;
}
public boolean addAttrezzo(Attrezzo attrezzo) {
if (this.numeroAttrezzi < 10) { // massimo 10 attrezzi
 this.attrezzi[numeroAttrezzi] = attrezzo;
 this.numeroAttrezzi++;
 return true;
} else {
 return false;
}
}
      // … continua …"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#72,72,"Programmazione orientata agli oggetti
Esercizio
…
public boolean hasAttrezzo(String nomeAttrezzo) {
boolean trovato;
trovato = false;
for (Attrezzo attrezzo : this.attrezzi) {
if (attrezzo.getNome().equals(nomeAttrezzo))
trovato = true;
}
return trovato;
    }
} // fine classe Stanza
●L’equivalenza di stringhe viene controllata con il 
metodo  equals()"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#73,73,"Programmazione orientata agli oggetti
Esercizio
●Scrivere il metodo
Attrezzo getAttrezzo(String nomeAttrezzo)
che restituisce l’attrezzo di nome nomeAttrezzo  se 
esiste, null altrimenti
●Scrivere il metodo
String toString()
che restituisca una descrizione della stanza compresa 
una lista di tutti gli oggetti in essa contenuti
●Conviene scrivere un metodo toString()  anche nella 
classe Attrezzo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#74,74,"Programmazione orientata agli oggetti
Costanti
•Talvolta, vogliamo imporre che i valori di alcune 
variabili di istanza non possano essere cambiati
–definiamo valori costanti
•A tal fine si usa la parola chiave final 
final double NUMERO_MASSIMO_DIREZIONI = 4;
NUMERO_MASSIMO_DIREZIONI = 20; // ERR. COMPILAZIONE
•Convenzione di stile: gli identificatori delle costanti 
si scrivono in maiuscolo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#75,75,"Programmazione orientata agli oggetti
Variabili di Classe
•Talvolta è utile avere variabili che devono essere 
condivise da tutti gli oggetti della stessa classe: 
variabili di classe
•A tal fine si usa la parola chiave static
private static int perTutti;
•ATTENZIONE: Esistono importanti motivazioni 
didattiche per limitarne il più possibile l’uso
•Per il momento limitiamoci ad usare questa parola 
chiave solo ed esclusivamente per
–dichiarare il metodo main()
–definire costanti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#76,76,"Programmazione orientata agli oggetti
Costanti e Variabili di Classe
•È ragionevole che una costante sia anche un 
variabile di classe. Perché?
•Per questo le dichiarazioni delle costanti di 
solito sono come segue:
final static double NUMERO_MASSIMO_DIREZIONI = 4;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#77,77,"Programmazione orientata agli oggetti
Metodi di Classe (Statici)
•Attenzione: nella POO i metodi di classe sono una  
vera e propria anomalia
–Durante l’apprendimento del paradigma OO sono 
quasi “pericolose”!
•Un metodo di classe corrisponde ad una operazione 
che può essere svolta senza utilizzare lo stato 
dell'oggetto (oppure usando solo variabili di classe, 
condivise da tutti gli oggetti)
•Tipicamente si usano per realizzare funzioni pure 
(es. i metodi di java.lang.Math )
•Sono come il freno a mano di un'automobile: 
–Molto utile da fermi...
–...ma non usatelo mai per frenare in corsa!!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#78,78,"Programmazione orientata agli oggetti
Ancora su final  (1)
•Attenzione:
final int a = 10;
a = 3; // ERRORE DI COMPILAZIONE
final int a = 10;
int b = 4;
a = b; // ERRORE DI COMPILAZIONE"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#79,79,"Programmazione orientata agli oggetti
Ancora su final  (2)
•Attenzione:
final Stanza ds1 = new Stanza(""Aula DS1"");
Stanza n7 = new Stanza(""Aula N7"");
ds1 = n7; // ERRORE DI COMPILAZIONE
final Stanza ds1 = new Stanza(""Aula DS1"");
Stanza n7 = new Stanza(""Aula N7"");
Attrezzo v = new Attrezzo(""vite"",1);
ds1.setAttrezzo(v);  // LECITO! PERCHE'?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#8,8,"Programmazione orientata agli oggetti
Overloading e Tipo Restituito
●Versioni sovraccariche dello stesso metodo possono 
differire anche per il tipo del valore restituito:
int add(int a, int b);
double add(double a, int b);
●NON è però possibile distinguere due metodi con gli 
stessi parametri formali (stesso numero, tipo e ordine 
dei parametri) usando solamente il tipo di ritorno
int f(int a, int b);    // Non Compila
double f(int a, int b); // Non Compila
✔Non compila: il compilatore non sarebbe in grado di 
capire quale versione si dovrebbe invocare (in generale)…
Si usa anche dire che 
il tipo restituito non fa parte della segnatura di un metodo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#80,80,"Programmazione orientata agli oggetti
Ancora su final  (3)
•In sostanza, quando final  si usa su
–primitivi: rende costante la variabile
–riferimenti: rende costante il riferimento, ma non 
il contenuto dell’oggetto referenziato, che rimane 
libero di cambiare"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#81,81,"Programmazione orientata agli oggetti
Studio di Caso (1)
•Il gioco di ruolo diadia
–In questa versione iniziale ci concentriamo su 
poche classi
–La prima versione, oltre ad essere molto 
semplice, ha un codice scritto piuttosto male:
•Ci sono errori (a tempo di esecuzione)
•È di difficile manutenzione 
•È poco riutilizzabile
–Il primo aspetto (errori) lo verificherete 
immediatamente eseguendo il programma
–Capire come ovviare agli altri due aspetti è uno 
degli obiettivi formativi del corso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#82,82,"Programmazione orientata agli oggetti
Studio di Caso (2)
•Scaricare  lo studio di caso versione base:
–https://sites.google.com/view/rm3-poo/materiale-didattico
•Eseguire il metodo main() nella classe DiaDia
•Digitare alcuni comandi
–aiuto per avere un elenco dei comandi
–vai nord|sud|est|ovest  per cambiare stanza
•Spostandoci da una stanza all'altra noteremo presto 
errori (uno porta alla terminazione del programma)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#83,83,"Programmazione orientata agli oggetti
Esercizio
•Studiare a fondo il codice della classe Stanza
–a che cosa serve la variabile numeroDirezioni ?
–che cosa fanno i metodi 
impostaStanzaAdiacente(String, Stanza)  e 
getStanzaAdiacente(String)?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#84,84,"Programmazione orientata agli oggetti
Esercizio
•Scrivere una classe StanzaTest1  con il 
metodo main()  con le istruzioni per:
–Definire due oggetti Stanza : bar e mensa
–Impostare le uscite dei due oggetti affinché:
•L'uscita nord del bar porti nella mensa
•L'uscita sud della mensa porti nel bar
–Stampare la descrizione della stanza dietro la 
porta nord del bar
–Stampare la descrizione della stanza dietro la 
porta sud della mensa
√Controllare che le stampe siano quelle attese"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#85,85,"Programmazione orientata agli oggetti
Esercizio
•Scrivere una classe StanzaTest2  con un metodo 
main() :
–Definire due oggetti Stanza: bar e mensa
–Definire due oggetti Attrezzo : tazzina e piatto
–Impostare le uscite dei due oggetti Stanza affinché:
•L'uscita nord del bar porti nella mensa
•L'uscita sud della mensa porti nel bar
–Aggiungere nel bar l'oggetto Attrezzo  tazzina
–Aggiungere nella mensa l'oggetto Attrezzo  piatto
–Stampare il nome e il peso dell'attrezzo presente nella 
stanza dietro la porta nord del bar
–Stampare il nome e il peso dell'attrezzo presente nella 
stanza dietro la porta sud della mensa
Controllare che le stampe siano quelle attese"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-05-costruttori-string-array.pdf#9,9,"Programmazione orientata agli oggetti
Esempio (con Eclipse)
●All’interno della classe Rettangolo  scrivere 
i metodi
—void scala(int fattore)
deve modificare l’oggetto Rettangolo  di modo che
base = base * fattore
altezza = altezza * fattore
—void scala(int fattoreBase, fattoreAltezza)
deve modifica l’oggetto Rettangolo  di modo che
base = base * fattoreBase
altezza = altezza * fattoreAltezza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Qualità del codice:
Java Base Library
Documentazione
Package"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
•Java Base Libraries
•Consultare la documentazione
•Produrre la documentazione delle 
proprie classi
•Package"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#10,10,"Programmazione orientata agli oggetti
Produrre Documentazione (2)
•Un’idea tanto semplice quanto efficace
–Documentazione in formato ipertestuale
•pagine web
–La documentazione viene generata dai 
commenti immersi direttamente nel codice
–Basta usare una semplice sintassi pensata 
allo scopo
–e l’utility javadoc"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#11,11,"Programmazione orientata agli oggetti
Commenti di Documentazione
•Tutti i comandi javadoc si trovano solo 
entro commenti /** … */
•Speciali marcatori (immersi nei 
commenti) permettono di definire 
aspetti specifici della documentazione
•Per l’elenco completo dei marcatori 
javadoc si consulti la documentazione:
http://docs.oracle.com/javase/1.5.0/docs/tooldocs/solaris/javadoc.html#javadoctags"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#12,12,"Programmazione orientata agli oggetti
Documentazione delle Classi
•Forma generale
/**
 * Nome-classe : commento che descrive 
 * scopo e caratteristiche generali della classe
 *
 * @author nome-autore
 * @see riferimento ad altra classe
 * @see riferimento ad altra classe
 * @version  versione
 */
public class Nome-classe {"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#13,13,"Programmazione orientata agli oggetti
Esempio
/**
 * Una semplice classe che modella un attrezzo.
 * Gli attrezzi possono trovarsi all'interno delle stanze
 * del labirinto.
 * Ogni attrezzo ha un nome ed un peso.
 *
 * @author   docente di POO
 * @see Stanza
 * @version 0.9
 *
 */
 public class Attrezzo {
  …
 }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#14,14,"Programmazione orientata agli oggetti
Documentazione dei Costruttori
•Forma generale
/**
 * Commento che descrive scopo e caratteristiche 
 * generali del costruttore
 *
 * @param nome-parametro breve descrizione
 */
Nome-classe(…) {"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#15,15,"Programmazione orientata agli oggetti
Esempio
 /**
   * Crea un attrezzo
   * @param nome il nome che identifica l'attrezzo 
   * @param peso il peso dell'attrezzo 
   */
   public Attrezzo(String nome, int peso) {
      this.peso = peso;
      this.nome = nome;
   }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#16,16,"Programmazione orientata agli oggetti
Documentazione dei Metodi
•Forma generale
/**
 * Commento che descrive scopo e caratteristiche 
 * generali del metodo
 *
 * @param nome-parametro breve descrizione
 * @return valore di ritorno, breve descrizione
 */
public type nome-metodo(…) {"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#17,17,"Programmazione orientata agli oggetti
Esempio
 /**
   * restituisce il nome identificatore dell'attrezzo
   * @return identificatore dell'attrezzo
   */
   public String getNome() {
      return this.nome;
   }
 /**
   * restituisce il peso dell'attrezzo
   * @return peso dell'attrezzo
   */
   public int getPeso() {
      return this.peso;
   }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#18,18,"Programmazione orientata agli oggetti
Generare Documentazione
•Si usa il tool javadoc
•Per dettagli 
javadoc -h
•Per generare la documentazione
javadoc *.java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#19,19,"Programmazione orientata agli oggetti
Package
•Le classi sono raggruppate in package
•Questo raggruppamento consente di:
–Mantenere assieme classi concettualmente 
e logicamente correlate 
–Creare spazi di nomi che evitino conflitti
–Definire un dominio di protezione
(cfr modificatori di accesso)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#2,2,"Programmazione orientata agli oggetti
Java Base Libraries
•Migliaia di classi
•Decine di migliaia di metodi
•Molte classi utili che ci semplificano 
drasticamente la vita
•Un programmatore competente deve 
essere in grado di lavorare con le librerie"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#20,20,"Programmazione orientata agli oggetti
Import
•Una classe può usare tutte le classi dello stesso 
package e tutte le classi pubbliche di altri package
•Si può accedere alle classi pubbliche di un altro 
package in due modi
–Usando il nome completamente qualificato di una classe, cioè 
anteponendo il nome del pacchetto alla classe:
java.util.Scanner  s = 
new java.util.Scanner (input);
–Importando la classe e scrivendone direttamente il nome
import java.util.Scanner;
…
Scanner s = new Scanner(input);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#21,21,"Programmazione orientata agli oggetti
Package
•È bene organizzare il proprio codice 
organizzando le classi in package
•Le classi che appartengono ad un package 
devono dichiarare la propria appartenenza al 
package tramite la dichiarazione
package nome-package ;
•La dichiarazione di appartenenza ad un 
package deve comparire all’inizio del file
•Una classe può appartenere al più ad un 
package"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#22,22,"Programmazione orientata agli oggetti
Package, Convenzioni sui Nomi
•Il nome di un package deve essere univoco.
•A tal fine di solito il nome del package 
comprende il nome del dominio Internet 
dell’organizzazione, scritto in ordine inverso
package it.uniroma3.diadia;"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#23,23,"Programmazione orientata agli oggetti
Package e Classi Pubbliche
•Una classe può essere usata al di fuori del 
package solo se è dichiarata pubblica
•Esempio:
package it.uniroma3.diadia;
public class Stanza {
  …
}
la classe Stanza può essere usata al di fuori del 
package it.uniroma3.diadia (importandola)
•Se invece scrivessimo:
package it.uniroma3.diadia;
class Stanza {
  …
}
la classe Stanza non potrebbe essere usata fuori dal 
package it.uniroma3.diadia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#24,24,"Programmazione orientata agli oggetti
Package
•Il nome di un package possiede una struttura 
gerarchica
•Tale struttura deve trovare corrispondenza 
diretta nel file system
•Ad esempio le classi del package 
it.uniroma3.diadia
devono  essere memorizzate nella cartella
it/uniroma3/diadia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#25,25,"Programmazione orientata agli oggetti
Compilazione ed Esecuzione 
di Classi nei Package
•Per compilare le classi di un package si deve far riferimento alla 
gerarchia fisica
•Con un buon IDE (ad es. Eclipse: cfr. source folders ) il processo è quasi 
completamente trasparente
•Da riga di comando questo può essere un po' articolato:
–Supponiamo di mettere tutto il nostro codice nella directory C:\src
–La versione base di diadia è nel package:
 it.uniroma3.diadia
      quindi le classi Java sono nella directory
 src/it/uniroma3/diadia
–Per compilare una classe (ad esempio la classe Stanza.java)  del package: 
•dalla radice del package, cioè dalla directory che contiene la directory it (supponiamo C:\
src)
javac it/uniroma3/diadia/Stanza.java
•oppure, dalla directory in cui si trovano le classi da compilare
javac –classpath ""C:\src\"" Stanza.java
(supponendo che la directory it sia nella directory src del volume C:)
–Per eseguire una classe di un package si deve far riferimento alla gerarchia logica
•dalla radice del package (cioè dalla directory che contiene la directory it) 
java it.uniroma3.diadia.DiaDia
•oppure da una qualunque directory 
java –classpath ""C:\src"" it.uniroma3.diadia.DiaDia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#26,26,"Programmazione orientata agli oggetti
Ricapitolazione
•Java offre un insieme estremamente vasto e ricco di 
librerie
•Le librerie sono documentate in un formato standard
•Nella definizione delle nostre classi è possibile creare 
automaticamente documentazione standard
–Usando opportunamente i commenti javadoc
•Le librerie (e le applicazioni) sono organizzati in 
package
–Creazione di uno spazio univoco dei nomi
–Raggruppamento delle classi
–Definizione di un nuovo livello di visibilità"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#27,27,"Programmazione orientata agli oggetti
Esercizio
•Mettere tutte le classi dello studio di 
caso (versione base) in un package 
diadia
•Compilare ed eseguire il programma"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#3,3,"Programmazione orientata agli oggetti
Java Base Libraries
•Un programmatore competente dovrebbe saper 
costruire le proprie classi, ma anche sapere 
quando è inutile scriverne di nuove
•Per poter usare efficacemente una libreria, 
bisogna:
–Conoscere alcune sue importanti classi per nome
–Sapere come trovare e usare altre classi
•Importante:
–Serve conoscere solo l’interfaccia, non 
l’implementazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#4,4,"Programmazione orientata agli oggetti
Documentazione di Librerie (1)
•La documentazione delle librerie Java è 
in formato HTML
–javadoc
•Si può leggere agevolmente con un 
browser
•Class API: Application Programmers’ 
Interface
–Descrizione delle interfacce per tutte le 
classi della libreria"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#5,5,"Programmazione orientata agli oggetti
Documentazione di Librerie (2)
•La documentazione include
–Il nome della classe
–Una descrizione generale della classe
–Una lista dei costruttori e dei metodi
–Valori di ritorno e parametri per costruttori e metodi
–Una descrizione dello scopo di ciascun costruttore e 
di ciascun metodo
•Come si usa la classe: tutto quello che 
serve al 
programmatore-utilizzatore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#6,6,"Programmazione orientata agli oggetti
Documentazione di Librerie (3)
•La documentazione non include
–Campi privati 
(tutti i campi dovrebbero essere privati)
–Metodi privati
–Il corpo dei metodi e dei costruttori
•Dettagli sull'implementazione: non servono al 
programmatore-utilizzatore
•Anzi: potrebbe risultare controproducente 
doverli necessariamente conoscere"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#7,7,"Programmazione orientata agli oggetti
Produrre Documentazione (1)
•Le classi che progettiamo dovrebbero essere 
documentate come le classi della libreria
•Altri programmatori devono essere in grado di 
usare le nostre classi senza conoscere 
l’implementazione di dettaglio"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#8,8,"Programmazione orientata agli oggetti
Elementi della Documentazione
•La documentazione di una classe dovrebbe 
includere
–Il nome della classe
–Un commento che descriva lo scopo e caratteristiche 
generali della classe
–Un numero di versione
–Il nome degli autori
–Riferimenti ad altre classi
–Documentazione per ciascun costruttore e per ciascun 
metodo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-06-documentazione-package.pdf#9,9,"Programmazione orientata agli oggetti
Documentare Costruttori e Metodi
•La documentazione di ciascun costruttore / 
metodo dovrebbe includere
–Nome e tipo di ciascun parametro
–Una breve descrizione di ciascun parametro
–Una descrizione dello scopo e della funzione del 
costruttore/metodo
–Il nome del metodo
–Il tipo di ritorno
–Una descrizione del valore ritornato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Qualità del codice:
Coesione e Accoppiamento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#1,1,"Programmazione orientata agli oggetti
Contenuti 
•Accoppiamento
•Coesione 
•Introduzione a: 
–Testing
–Refactoring"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#10,10,"Programmazione orientata agli oggetti
Coesione ed Accoppiamento
•Sono le due facce della stessa medaglia
–L’alta coesione di una classe si ottiene 
perseguendo lo scarso accoppiamento di 
quella classe verso altre classi
–Lo scarso accoppiamento di una classe 
verso le altre classi si ottiene perseguendo 
la sua alta coesione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#11,11,"Programmazione orientata agli oggetti
Localizzare le Modifiche
•Basso accoppiamento e alta coesione 
portano ad una localizzazione delle 
modifiche
•Quando è necessario operare una 
modifica, il minor numero possibile di 
classi dovrebbero essere coinvolte
•La qualità del proprio codice si osserva 
proprio quando sorge l’esigenza di fare 
modifiche"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#12,12,"Programmazione orientata agli oggetti
Pensare in Avanti
•Quando progettiamo una classe dovremmo 
sforzarci di pensare a 
–quali cambiamenti potranno essere richiesti in 
futuro
–come verrà usata la nostra classe dal 
programmatore-utilizzatore
•Le nostre scelte iniziali potrebbero facilitare 
l’evoluzione futura (su questo aspetto faremo 
esperienza nello studio di caso ed in altri 
esercizi)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#13,13,"Programmazione orientata agli oggetti
Qualità Interna vs Qualità Esterna
del Codice
•La qualità del codice può essere osservata da 
molti punti di vista ben distinti
•Due particolarmenti interessanti per noi
–Quello degli utilizzatori finali:   qualità esterna
–Quello degli sviluppatori:     qualità interna
•Gli utilizzatori finali possono fornire un giudizio 
di merito sulla capacità di un applicativo di 
rispondere ai requisiti ed alle proprie esigenze
•Solo gli sviluppatori possono valutare la 
manutenibilità del codice nel momento in cui 
nasce la necessità di modificarlo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#14,14,"Programmazione orientata agli oggetti
“Refactoring”
•La manutenzione del software spesso richiede 
l’aggiunta di nuovo codice
•Le classi e i metodi tendono così a diventare più 
lunghi, a perdere in coesione, ad aumentare 
l’accoppiamento versi altre porzioni di codice
•A seguito delle modifiche, per mantenere un’alta 
coesione ed un basso accoppiamento, classi e metodi 
dovranno essere riorganizzate
•Questo processo di riorganizzazione del codice viene 
definito “refactoring”
E’ il principale strumento che uno sviluppatore 
possiede per controllare la qualità interna  del codice
–Modifiche del codice che non alterano il funzionamento
–Ma preparano il codice ad accogliere le modifiche future"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#15,15,"Programmazione orientata agli oggetti
Refactoring e Testing
•Quando modifichiamo il codice, è necessario 
isolare le conseguenze del refactoring da altri 
fattori
•Quindi la riorganizzazione delle classi e dei metodi 
(il refactoring) deve essere effettuata prima di 
introdurre nuove funzionalità
•Come contrastare la naturale paura di fare 
modifiche su un base di codice che si considerava 
funzionante?
•Per assicurarci di non aver introdotto nuovi errori, 
eseguiamo i test prima e dopo ogni azione di 
refactoring
–Vedremo come organizzare metodicamente refactoring 
e testing"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#16,16,"Programmazione orientata agli oggetti
Linee Guida (1)
•Domande comuni
–Quanto dovrebbe essere lunga una classe?
–Quanto dovrebbe essere lungo un metodo?
•Possiamo rispondere in termini di 
coesione e accoppiamento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#17,17,"Programmazione orientata agli oggetti
Linee Guida (2)
•Un metodo è troppo lungo se è responsabile di 
più di un compito logico
•Una classe è troppo complessa se rappresenta 
più di un concetto, se ha più di una 
responsabilità
●Nota: queste sono linee guida – solo attraverso 
l’esperienza si riescono a concretizzare"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#18,18,"Programmazione orientata agli oggetti
Caso di Studio: 
le classi Diadia  e Partita
•Le classi Diadia  e Partita  sono 
particolarmente lunghe
•Se guardiamo il loro codice ci accorgiamo che 
hanno diverse (troppe!) responsabilità
–Diadia implementa la logica di tutti i possibili 
comandi
–Partita  gestisce lo stato del gioco e crea il 
labirinto
•Questa miriade di responsabilità è indice di 
poca coesione
19"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#19,19,"Programmazione orientata agli oggetti
Aumentiamo la Coesione
•Possiamo iniziare a migliorare la coesione 
della classe Partita  togliendole qualche 
responsabilità 
•Iniziamo a togliere la responsabilità di creare e 
gestire il labirinto
•Affidiamo questa responsabilità ad una nuova 
classe appositamente introdotta: Labirinto
20"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#2,2,"Programmazione orientata agli oggetti
Il Software Evolve
•Il software evolve in continuazione
•…inevitabilmente…
•Viene esteso, corretto, mantenuto, 
portato su altre piattaforme, adattato, …
•Molte persone, in tempi diversi 
partecipano a questo processo
•Se il costo dell’evoluzione è troppo alto, 
il software viene gettato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#20,20,"Programmazione orientata agli oggetti
Esercizio
•Creare la classe Labirinto  e modificare la 
classe Partita  affinché non abbia la 
responsabilità della creazione del labirinto
–Un labirinto ha una entrata (stanza di ingresso) 
ed una uscita (stanza vincente)
–La classe Labirinto  ha un metodo privato 
init()  che inizializza il labirinto
•Provare ad eseguire il codice del gioco prima e 
dopo le modifiche e verificare che il 
comportamento sia rimasto invariato
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#21,21,"Programmazione orientata agli oggetti
Refactoring …
•Un programmatore OO deve avere forte senso 
critico, evidenziare i limiti delle proprie 
soluzioni sia in termini di funzionalità che di 
qualità del codice per risolverli attraverso 
disciplinati passi di refactoring 
–N.B. con un pizzico di attenzione al pericolo della 
sovra-ingegnerizzazione
bisogna risolvere i problemi di oggi del progetto! 
Poi, se c’è la possibilità, anche quelli che si 
prevedono
mai compromettere le soluzioni di oggi per 
bisogni che forse avremo in futuro
22"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#22,22,"Programmazione orientata agli oggetti
Refactoring …
•Concludiamo citando alcune problematiche risolvibili 
efficacemente solo dopo aver studiato il 
polimorfismo
–Forte accoppiamento tra l’insieme dei comandi disponibili e la 
classe Diadia: risolvendo il primo homework è evidente che 
ogni volta che aggiungiamo/modifichiamo un comando 
dobbiamo agire su questa classe
•Anche dopo i passi di refactoring precedenti la classe Diadia continua ad 
addossarsi diverse (troppe!) responsabilità
–Implementa la logica del gioco 
–Implementa la logica di tutti i possibili comandi
–Ma è possibile che la struttura del labirinto sia cablata 
all’interno della classe Labirinto ? E pensando ad un gioco a 
più livelli di difficoltà con diversi labirinti?
–Se volessi cambiare labirinto o comunque riutilizzare un 
oggetto istanza della classe Partita con diversi labirinti, 
potrei farlo?
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#23,23,"Programmazione orientata agli oggetti
Ricapitoliamo
•I programmi SW sono in continua evoluzione
•E’ importante facilitare e prevedere questa 
evoluzione
•La qualità del codice richiede molto più del 
corretto funzionamento di un programma in un 
preciso momento 
–“funziona!”… condizione necessaria, ma non sufficiente
–in altri termini: 
•se funziona non è detto che vada bene
•se non funziona certamente non va bene
•Il codice deve essere comprensibile e 
manutenibile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#24,24,"Programmazione orientata agli oggetti
Ricapitoliamo
•Codice di buona qualità: “no copia e incolla”, alta 
coesione, basso accoppiamento
•Anche lo stile di codifica (identificatori, 
indentazione, spaziatura) è fondamentale (il 
programma è uno strumento di comunicazione)
–codice ben scritto non ha bisogno di commenti!
•Il costo di manutenzione del software dipende 
fortemente dalla qualità del codice ed è ormai da 
tempo noto essere la voce di costo preponderante 
sul medio/lungo termine"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#3,3,"Programmazione orientata agli oggetti
Qualità del Codice
•La qualità del codice dipende da 
due fattori importanti:
–Accoppiamento (coupling)
–Coesione (cohesion)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#4,4,"Programmazione orientata agli oggetti
Accoppiamento
•Due o più unità di un programma si dicono 
accoppiate quando è impossibile modificare 
una senza dover modificare anche le altre
•L’accoppiamento si riferisce ai legami tra unità 
separate e distinte di un programma
•Se due classi dipendono strettamente e per 
molti dettagli l’una dall’altra, diciamo che sono 
strettamente accoppiate
•Per un codice di qualità dobbiamo puntare ad 
un basso accoppiamento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#5,5,"Programmazione orientata agli oggetti
Duplicazione del Codice
•“Codice Copia e Incolla”
•La duplicazione del codice 
–è sintomo di un cattivo progetto
–porta facilmente alla propagazione di errori 
durante lo sviluppo
–rende difficile la manutenzione
–porta inevitabilmente alla introduzione di errori 
nelle attività di manutenzione
•E’ una forma elementare di accoppiamento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#6,6,"Programmazione orientata agli oggetti
Basso Accoppiamento
•Un basso accoppiamento permette di:
–Capire il codice di una classe senza leggere i 
dettagli delle altre
–Modificare una classe senza che le 
modifiche comportino conseguenze sulle 
altre classi
•Quindi un basso accoppiamento migliora 
la manutenibilità del software"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#7,7,"Programmazione orientata agli oggetti
Coesione
•La coesione fa riferimento al numero e alla 
eterogeneità dei compiti di cui una singola 
unità è responsabile
•Se ciascuna unità è responsabile di un singolo 
compito, diciamo che tale unità possiede una 
alta coesione
•La coesione si applica alle classi e ai metodi 
(ed anche ai package!)
•Perseguiamo l’alta coesione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#8,8,"Programmazione orientata agli oggetti
Alta Coesione
•Un’alta coesione favorisce:
–La comprensione dei compiti di una classe o 
di un metodo
–L’utilizzo di nomi appropriati, efficaci, 
comunicativi
–Il riuso delle classi e dei metodi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-07-coesione-accoppiamento.pdf#9,9,"Programmazione orientata agli oggetti
Coesione
•Coesione dei metodi
–Un metodo dovrebbe essere responsabile di 
un solo compito ben definito
•Coesione delle classi
–Ogni classe dovrebbe rappresentare un 
singolo concetto ben definito"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#0,0,"Programmazione
Orientata agli Oggetti
Qualità del Codice:
Introduzione Unit-Testing"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#1,1,"Programmazione orientata agli oggetti
 2
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#10,10,"Programmazione orientata agli oggetti
Costo di un Bug e “Località”
C h is s à
Q u a n d oD o p o  T a n t oD o p o  U n
P o 'S u b it oP o c h eAlc u n eT a n t eT r o p p e
11TempoLineeCosto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#11,11,"Programmazione orientata agli oggetti
Tipologie di Test
12
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#12,12,"Programmazione orientata agli oggetti
Le Tre Fasi di un Test
•Tutte le tipologie di test di un qualsiasi 
sistema prevedono la costruzione di uno 
scenario di testing che si articola sempre in tre 
fasi strettamente sequenziali
1.mettere il sistema in un stato iniziale ben noto
2.inviare una serie di sollecitazioni
3.controllare che alla fine il sistema si trovi nello 
stato atteso
•I test possono fallire od avere successo
13"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#13,13,"Programmazione orientata agli oggetti
Obiettivi del Testing
•Se ben progettati e mantenuti, i test 
aiutano a confinare i bug nella “zona 
verde”, ovvero con spiccata località
–i bug si manifestano immediatamente e 
palesemente
–la ricerca del bug è confinabile in poche 
linee facilmente localizzabili
•Le esecuzioni che palesano un bug non 
sono mai troppo lunghe e complesse
14"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#14,14,"Programmazione orientata agli oggetti
Il Valore Aggiunto dal Testing
•Se il test ha successo: 
–si possiede una garanzia sul comportamento 
dinamico del codice (assenza di bug)
•Se il test non ha successo:
–il bug dovrebbe risultare facilmente 
localizzabile nell’unità di codice sollecitata 
dal test
•In entrambi  i casi c’è un significativo 
valore aggiunto
15"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#15,15,"Programmazione orientata agli oggetti
Testing vs Regressione
•Se il test 
–funzionava subito prima di effettuare un 
modifica
–ma smette di funzionare subito dopo aver 
effettuato la modifica
•E’ altamente probabile che l’errore è stato 
appena introdotto con la modifica
–Ricerca «locale» e quindi economica
•E’ possibile prevenire la regressione
16"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#16,16,"Programmazione orientata agli oggetti
Esercizio
•Supponiamo di voler testare il metodo max() 
della classe Sequenza  (quiz di benvenuto al corso)
–Scriviamo in un documento di testo (.txt) diverse istanze 
dell'array di interi, per ogni sequenza scriviamo il 
massimo atteso
–facciamo girare il programma su ciascuna sequenza e 
verifichiamo che il risultato sia quello atteso
•Osservazione:
–possiamo scrivere i test senza preoccuparci 
dell'algoritmo per il calcolo del massimo (ovviamente è 
necessario scegliere con cura gli array di test) 
•Conseguenza: 
–possiamo scrivere i test prima di scrivere il programma!
17"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#17,17,"Programmazione orientata agli oggetti
Testo QUIZ
•Scrivere il codice del metodo massimo() che 
deve restituire il più grande valore presente 
nella variabile di istanza sequenza , un array:
18public class Sequenza {
    private int[] sequenza;
    
    public Sequenza(int n){
        sequenza = new int[n];
    }
    
    public int massimo(){
// scrivere il codice di questo metodo:
// deve restituire il valore piu' grande 
// presente nell'array sequenza
    }    
    public void setElemento(int indice, int valore) {
        sequenza[indice] = valore;
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#18,18,"Programmazione orientata agli oggetti
Codice di Test
•Nella pratica, accanto al codice di produzione 
si sviluppa sempre del codice di test  
•Unico motivo di esistere del codice di test è 
quello di verificare la correttezza a tempo di 
esecuzione del codice principale
•Il codice di test accompagna e supporta lo 
sviluppo del codice di produzione ma non fa 
parte del codice consegnato a fine progetto
19"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#19,19,"Programmazione orientata agli oggetti
Test Unitari Automatici
•Esistono diverse tipologie di test
•Nostra attenzione è limitata ad una in 
particolare: unit-testing automatico
–test che si focalizzano su frammenti (unità)  del 
sistema 
–senza alcun intervento umano (tranne la richiesta di 
esecuzione)
•Praticamente i test unitari si codificano nel 
medesimo linguaggio di programmazione 
utilizzato per lo sviluppo (Java)
20"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#2,2,"Programmazione orientata agli oggetti
Sommario
•Errori nel software
–errori di compilazione vs bug
–località dei bug
•Testing
–motivazioni
–le tre fasi di un test
•Unit-Testing
•Introduzione a JUnit
•Qualità dei test
•Testing Continuo
•TDD
3"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#20,20,"Programmazione orientata agli oggetti
Test Unitari – Unit Testing
•Test su frammenti  di un sistema piuttosto che 
sull’intero sistema
•Concettualmente un test unitario si articola in 
questi passi
1)mettere uno o più oggetti da testare in un 
stato iniziale ben noto
2)invocare i metodi degli oggetti
3)controllare che alla fine gli oggetti si trovino 
nello stato atteso
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#21,21,"Programmazione orientata agli oggetti
Automazione dei Test
•Abbiamo già eseguito test manuali 
(cfr. Esercizi precedenti)
–basta riportare i valori di ingresso ed i valori di 
output attesi in un documento di testo e 
verificare che ogni esecuzione produca quanto 
atteso
•Chiaramente o gni esecuzione manuale 
richiede uno sforzo sia per inserire l’input che 
per ispezionare visivamente i risultati
✔Difficilmente si è disposti a ripetere l’operazione troppe volte
•L’automazione dei test è fondamentale
–altrimenti viene meno la loro economicità
22"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#22,22,"Programmazione orientata agli oggetti
Automazione Artigianale
•Una possibile soluzione 
–molto artigianale
–automatica
   chiarisce il funzionamento dei test unitari
•Scriviamo un programma in cui
–inizializziamo un certo numero di oggetti con 
sequenze di interi su cui basare il test ( fixture )
–invochiamo il metodo da testare e verifichiamo che 
il risultato restituito sia uguale a quello atteso
•Successivamente  vedremo un framework (JUnit) 
che rende l’automazione ancora più spedita>>
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#23,23,"Programmazione orientata agli oggetti
Esempio Soluzione Artigianale (1)
24public static void main(String[] args){
Sequenza positivi;
Sequenza negativi;
Sequenza negEpos;
Sequenza negEzero;
Sequenza inPrimaPos;
Sequenza inUltimaPos;
positivi = new Sequenza(5);
positivi.setElemento(0,1);
positivi.setElemento(1,5);
positivi.setElemento(2,8);  // MAX!
positivi.setElemento(3,3);
positivi.setElemento(4,4);
negativi = new Sequenza(5);
negativi.setElemento(0,-6);
negativi.setElemento(1,-1); // MAX!
negativi.setElemento(2,-8);
negativi.setElemento(3,-13);
negativi.setElemento(4,-10);"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#24,24,"Programmazione orientata agli oggetti
Esempio Soluzione Artigianale (2)
25negEpos = new Sequenza(5);
negEpos.setElemento(0,100);
negEpos.setElemento(1,-5);
negEpos.setElemento(2,-80);
negEpos.setElemento(3,1000); // MAX!
negEpos.setElemento(4,10);
negEzero = new Sequenza(5);
negEzero.setElemento(0,-1);
negEzero.setElemento(1,0); // MAX!
negEzero.setElemento(2,-80);
negEzero.setElemento(3,-10);
negEzero.setElemento(4,-10);
inPrimaPos = new Sequenza(5);
inPrimaPos.setElemento(0, 1000); // MAX!
inPrimaPos.setElemento(1, 0);
inPrimaPos.setElemento(2, 80);
inPrimaPos.setElemento(3,-10);
inPrimaPos.setElemento(4,-10);
inUltimaPos = new Sequenza(5);
inUltimaPos.setElemento(0, 1);
inUltimaPos.setElemento(1, 0);
inUltimaPos.setElemento(2, 80);
inUltimaPos.setElemento(3,-10);
inUltimaPos.setElemento(4, 1000);  // MAX! "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#25,25,"Programmazione orientata agli oggetti
Esempio Soluzione Artigianale (3)
26    boolean esito = true;
    esito &= (positivi.massimo() == 8);
    System.out.println(positivi.massimo() == 8);
    esito &= (negativi.massimo() == -1);
    System.out.println(negativi.massimo() == -1);
    esito &= (negEpos.massimo() == 1000);
    System.out.println(negEpos.massimo() == 1000);
    esito &= (negEzero.massimo() == 0);
    System.out.println(negEzero.massimo() == 0);
    esito &= (inPrimaPos.massimo() == 1000);
    System.out.println(inPrimaPos.massimo() == 1000);
    esito &= (inUltimaPos.massimo() == 1000);
    System.out.println(inUltimaPos.massimo() == 1000);
    System.out.println(esito);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#26,26,"Programmazione orientata agli oggetti
Soluzione Artigianale
•La soluzione presentata, benché chiaramente 
artigianale , è completamente automatica
–dopo ogni modifica al metodo sotto test possiamo 
velocemente far rigirare il programma di test e 
verificare se ci sono cambiamenti (regressioni) nei 
risultati
–in presenza di fallimenti la ricerca degli errori risulta 
fortemente semplificata dalle informazioni 
desumibili già dal test fallito stesso
27"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#27,27,"Programmazione orientata agli oggetti
Automazione del Testing
•I test devono essere:
–automatici  (per mantenere rapido il ciclo di 
feedback)
•devono essere eseguiti molte volte al giorno
–efficienti
•devono essere convenienti rispetto alle ispezioni manuali
–isolati e che garantiscano la località degli errori
•dal fallimento di un test alla rimozione del bug deve 
trascorre poco tempo grazie alle caratteristiche di forte 
località del test per gli errori che rilevano
–ed inoltre:
•separati dal codice applicativo
•eseguibili e verificabili separatamente
28"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#28,28,"Programmazione orientata agli oggetti
Automazione del Testing: JUnit
•Esistono vari strumenti per assistere il 
programmatore nel testing, ed in particolare 
nello unit-testing
•JUnit: http://www.junit.org
•Il più noto ed utilizzato framework (insieme di 
classi e convenzioni d'uso) per la scrittura di 
test unitari
•Fortemente integrato con gli ambienti di 
sviluppo più diffusi come Eclipse>>
29"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#29,29,"Programmazione orientata agli oggetti
JUnit: Test del Metodo massimo()
import static org.junit.jupiter.api.Assertions..*;
import org.junit.jupiter.api.Test;
public class SequenzaTest  {
  @Test
  public void testMassimoPositivi() {
      Sequenza seq = new Sequenza(5);
      seq.setElemento(0,1);
      seq.setElemento(1,5);
      seq.setElemento(2,8);
      seq.setElemento(3,3);
      seq.setElemento(4,4);
      assertEquals(8, seq.massimo());
  }
  @Test
  public void testMassimoegativi() {
    …
    …
  }…}
30test-caseimport di classi ed
annotazioni Junit 5 
Annotazione di metodo come test-case
Asserzionenome
test-case"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#3,3,"Programmazione orientata agli oggetti
Software ed Errori 
•I primi errori con i quali ci scontriamo di solito 
sono errori di sintassi
–Ci vengono indicati dal compilatore 
•Successivamente incorriamo in errori logici
–Il compilatore non ci può aiutare 
–Sono noti anche come “bug” (bachi)
•Alcuni errori logici non si manifestano 
immediatamente
–Il software è estremamente complesso
–Anche il software commerciale non è affatto privo di 
errori
4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#30,30,"Programmazione orientata agli oggetti
JUnit: Struttura Classi di Test (1)
•Tutte le classi di test che scriveremo avranno 
questa struttura
•Ovviamente le classi di test vanno progettate 
sulla base delle peculiarità della classe testata
•Collochiamo la classe di test nello stesso 
package della classe che si sta testando
•Convenzione sui nomi basata sul suffisso: 
   Classe 
   Sequenza → SequenzaTest  
  Classe di Test
31"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#31,31,"Programmazione orientata agli oggetti
JUnit: Struttura Classi di Test (2)
•import static org.junit.jupiter.api.Assertions.*;
Serve per importare vari metodi statici del 
framework che permettono di fare asserzioni >> 
•import org.junit.jupiter.api.Test;
Serve per importare l’ annotazione del framework
@Test utile a marcare i metodi i test-case
•Non è (più) necessario ma è (tuttora) buona 
norma usare ‘ test’ come prefisso del nome dei 
test-case
 @Test
public void testCostruzioneComandiInvalidi() {
…
}
32"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#32,32,"Programmazione orientata agli oggetti
JUnit: Asserzioni
•Asserzione: 
affermazione che può essere vera o falsa
•I risultati attesi sono documentati con delle 
asserzioni  esplicite, non mediante stampe 
–richiederebbero dispendiose ispezioni visuali
•Se l’asserzione è
–vera : il test ha avuto successo, è andato a buon fine
–falsa : il test è fallito ed il codice testato non si comporta 
come atteso, quindi c’è un errore a tempo dinamico
33"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#33,33,"Programmazione orientata agli oggetti
JUnit: Metodi assert XYZ()  
•Una asserzione non vera fa fallire il test-case
–assertEquals(Object expected ,Object actual): 
afferma l’«uguaglianza» degli argomenti (>>)
–assertNull(Object object) : afferma che il suo 
argomento è nullo (fallisce se non lo è)
–molte altre varianti
•assertNotNull()
•assertTrue()
•assertFalse()
•assertSame()…  
tutte sovraccariche … e talvolta facilmente 
intercambiabili...
•Usare sempre la versione più pertinente! 
–meglio assertFalse(b ) di assertTrue(b==false), 
–meglio assertNotNull(o ) di assertTrue(o!=null)
34"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#34,34,"Programmazione orientata agli oggetti
JUnit: assertEquals()
•assertEquals(Object expected, Object actual)
«expected»  è il valore atteso, che ci si aspetta normalmente
«actual»  è il valore effettivo, reale, quello ottenuto
–afferma che il suo secondo argomento è uguale al primo 
argomento
–va a buon fine se e solo se expected.equals(actual ) 
restituisce true
•Una variante, spesso preferibile
  assertEquals( String message , Object expected, Object actual)
–un messaggio diagnostico da stampare solo in caso di fallimento
–se ben ideato, dovrebbe permettere di comprendere il motivo del 
fallimento senza nemmeno aprire il debugger
35"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#35,35,"Programmazione orientata agli oggetti
Le “Tre Fasi” in Pratica
 @Test
  public void testMassimoPositivi() {
      Sequenza seq = new Sequenza(5);
      seq.setElemento(0,1);
      seq.setElemento(1,5);
      seq.setElemento(2,8);
      seq.setElemento(3,3);
      seq.setElemento(4,4);
      assertEquals(8, seq.massimo());
  }
1) mettere un “frammento” del sistema in un stato 
iniziale noto
•il frammento comprende un solo oggetto Sequenza 
opportunemente popolato di valori (nell’es. si tratta di interi 
tutti positivi)
2) inviare una serie di sollecitazioni ( seq.massimo() )
3) controllare  tramite asserzioni che si raggiunga lo stato 
finale atteso ( assertEquals(...) )
36"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#36,36,"Programmazione orientata agli oggetti
JUnit: Compilare i Test
Per compilare ed eseguire i test:
•Nel classpath devono essere presenti le 
librerie di JUnit  
Eclipse snellisce molti di questi passaggi sino 
a renderli quasi trasparenti
–ed arriva a suggerire di aggiungere la libreria 
nel build path del vostro progetto non appena 
ne nota l’utilizzo
37"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#37,37,"Programmazione orientata agli oggetti
JUnit ed Eclipse
•JUnit è talmente popolare da venire fornito già  
integrato e fortemente supportato negli IDE
•Nel caso di Eclipse:
–per creare una classe di test 
click con tasto destro del mouse sulla classe
new-> JUnit Test Case  (spuntare new JUnit 5)
–per eseguire una classe di test
click con tasto destro del mouse sulla classe di test
run as -> JUnit test
•barra verde: il test è andato a buon fine
•barra blue: il test è fallito violando una asserzione
•barra rossa: il test è fallito causando un errore
38"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#38,38,"Programmazione orientata agli oggetti
JUnit ed Eclipse
•Le classi di test devono essere nello stesso 
package delle classi da testare. Scomodo!
•Si pensi ad una consegna del solo codice di produzione 
•Ma in Eclipse possiamo collocare uno stesso 
package anche in directory ( source folder) diverse
–In ogni progetto, 
•nella source folder src mettiamo il codice di produzione
•nella source folder test mettiamo le classi di test (organizzate 
con gli stessi package delle classi di produzione)
–per creare una source folder: tasto destro del mouse sul 
progetto, quindi new->Source Folder
•dentro la source folder test creiamo una copia “parallela” dei 
package del codice di produzione (new->package)
39"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#39,39,"Programmazione orientata agli oggetti
 40Source folder src (qui vanno le classi del codice di produzione)
Source folder test (qui vanno le classi del codice di test)src vs test  Cartella/Folder"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#4,4,"Programmazione orientata agli oggetti
Errori di Compilazione
•Il compilatore ci dà indicazioni precise e 
molto utili a correggere l'errore
•Il messaggio di errore del compilatore 
VA LETTO E CAPITO
Diadia.java:27:invalid method declaration; 
return type required 
private creaStanze() {
                       ^
1 error
5LINEA DI CODICE  IN CUI E' STATO RISCONTRATO L'ERRORE
ERRORE RISCONTRATO"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#40,40,"Programmazione orientata agli oggetti
JUnit: Fixture
•Per facilitare la scrittura dei test-case, è 
spesso comodo creare degli oggetti in uno 
stato iniziale noto e «pronto» per l’utilizzo da 
parte di tutti i test-case
•Può convenire fattorizzare il codice di 
creazione di questi oggetti. Ad es.
•utilizzando metodi setUp()
•mediante i cosidetti factory methods 
•Le fixture  sono oggetti in uno stato iniziale 
noto ed ospitati in variabili d’istanza che le 
classi di test predispongono allo scopo
41"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#41,41,"Programmazione orientata agli oggetti
Fixture e JUnit
•Attraverso l’annotazione @BeforeEach  è possibile 
indicare quali metodi eseguire prima di ciascuna 
invocazione di un test-case
•Tipicamente questi metodi inizializzano le fixture
•Spesso, ma non più obbligatoriamente,  questi 
metodi vengono tuttora denominati setUp() 
•perché con le versioni di JUnit pre-annotazioni Java (JUnit 
3.x) era un nome imposto per convenzione
42"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#42,42,"Programmazione orientata agli oggetti
Fixture e Metodo setUp() (1)
import static org.junit.jupiter.api.Assertions.*;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
public class SequenzaTest {
private Sequenza positivi;
private Sequenza negativi;
@BeforeEach
public void setUp() {
this.positivi = new Sequenza(5);
this.positivi.setElemento(0,1);
this.positivi.setElemento(1,5);
this.positivi.setElemento(2,8);
this.positivi.setElemento(3,3);
this.positivi.setElemento(4,4);
this.negativi = new Sequenza(5);
this.negativi.setElemento(0,-6);
…
   }
   @Test
public void testMassimoPositivi() {…}
   @Test
public void testMassimoNegativi() {…}
}
43Metodo eseguito prima di ogni 
invocazione di test-caseFixture"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#43,43,"Programmazione orientata agli oggetti
Fixture e Metodo setUp() (2)
…
public class SequenzaTest {
…
@Test
public void testMassimoPositivi() {
assertEquals(8, this.positivi.massimo());
}
@Test
public void testMassimoNegativi() {
assertEquals(-1, this.negativi.massimo());
}
…
}
44"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#44,44,"Programmazione orientata agli oggetti
setUp() e l’Importanza dei Nomi
•Dopo diverso tempo dalla prima scrittura , a meno 
che il nome della fixture this.positivi  sia 
perfettamente indicativo di “sequenza non vuota 
di interi tutti positivi” si finirà per dover leggere il 
corpo del metodo setUp() per poterne 
comprendere appieno il significato
•Una situazione migliore:
…
public class SequenzaTest {
…
@Test
public void 
testMassimoDi SequenzaNonVuotaDiInteriTuttiPositivi () {
assertEquals(8, this.positivi.massimo());
}
…
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#45,45,"Programmazione orientata agli oggetti
setUp(): Controindicazioni
•Se nel setUp()  si accumulano le fixture di diversi 
test-case (seq. positive, negative ecc. ecc. …)  si 
creano tanti oggetti che non hanno nulla a che 
vedere con il singolo test appena fallito, ad es. 
testMassimoPositivi()
•Si è costretti a leggere un lungo setUp() solo 
per comprendere un breve test-case
•Mettendo a fattor comune tutte le fixture 
utilizzate una sola volta si sta ledendo la 
leggibilità dei test-case rendendoli meno 
autocontenuti
•Tramite il setUp()  si finisce per creare impliciti 
ma sottili accoppiamenti tra test-case"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#46,46,"Programmazione orientata agli oggetti
setUp(): Indicazioni
•In genere, nel setUp() ha senso fattorizzare solo 
la creazione di oggetti che vengano utilizzati da 
almeno due test-case distinti
•In tutti gli altri casi meglio non distribuire il 
codice di uno scenario di test in due distinti 
metodi test() + setUp() . Altrimenti:
•Il test non è isolato: per comprenderne uno si 
finisce per dover capire (almeno una parte) di tutti
•Il test non è autocontenuto : per ricostruire lo 
scenario di test bisogna cercare ben oltre il corpo 
del test-case stesso
•In definitiva, la località del test potrebbe risentirne"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#47,47,"Programmazione orientata agli oggetti
Qualità dei Test-Case (1)
•ATTENZIONE: la qualità di un test si avverte in 
particolare quando il test smette di funzionare e 
bisogna trovare l’errore all’origine del fallimento
–può capitare anche dopo molto tempo  dalla scrittura 
iniziale del codice
–quando oramai lo stesso non risulta affatto “familiare”
–magari subito dopo avere effettuato un refactoring...
Lo sforzo necessario per rimuovere un errore 
appena introdotto è uno dei più importanti 
indicatori della qualità dei test che smettono di 
funzionare
Questo sforzo, abbiamo già visto, dipende 
largamente dalla località  di un test"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#48,48,"Programmazione orientata agli oggetti
Qualità dei Test-Case (2)
Qual’è la lunghezza ottimale di un test-case?
–1 (dicesi UNA) – linea di codice totale!
•E’ possibile perseguire questo obiettivo 
utilizzando alcuni accorgimenti
–fixtures
–factory methods
–minimalità >>
N.B. per la località dei test non è solo utile conseguire 
il risultato di aver test monolinea, ma è forse ancora 
più importante ricordarsi di perseguirlo
–meno linee possibili per test-case
–molto meglio 10 test-case con 1 asserzione ciascuno che 
1 test-case con 10 asserzioni!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#49,49,"Programmazione orientata agli oggetti
Factory Methods
•Per favorire la semplicità dei test si può 
pensare di fattorizzare il codice di creazione 
della fixture…
public class SequenzaTest {
…
   private Sequenza sequenza(int... array) {
       Sequenza risultato = new Sequenza(array.length);
       for(int i=0; i<array.length; i++) {
           risultato.setElemento(i,array[i]);
    }
    return risultato;
   }
@Test
public void testMassimoDiSequenzaNonVuotaDiInteriTuttiPositivi() {
assertEquals(8, sequenza(1,5,8,3,4 ).massimo());
}
…
}Equivale a 
private Sequenza sequenza(int[] array)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#5,5,"Programmazione orientata agli oggetti
Errori a Tempo di Esecuzione
•Anche in questo caso abbiamo 
informazioni molto precise (dalla 
macchina virtuale)
Exception in thread ""main"" 
java.lang.NullPointerException
        at Diadia.vaiNellaStanza(Gioco.java:176)
        at Diadia.processaComando(Gioco.java:117)
        at Diadia.gioca(Gioco.java:71)
        at Diadia.main(Gioco.java:209)
6"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#50,50,"Programmazione orientata agli oggetti
Testing - Punto di Vista di un 
Programmatore-Utilizzatore (1)
•Il factory method sequenza()  ha reso evidente 
quanto sia “faticoso” creare una sequenza per gli 
utilizzatori della classe
•la classe di test è solo una delle possibili classi 
utilizzatrici/clienti
•A ben vedere anche altri utilizzatori della classe 
possono convidere la stessa esigenza
•Se cambiamo Sequenza  per facilitare il testing, 
rendiamo più semplice l’uso della classe da parte 
anche di tutti gli altri utilizzatori
•Basta aggiungere il costruttore Sequenza(int[] e) ?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#51,51,"Programmazione orientata agli oggetti
Autocontenimento dei Test
…
public class SequenzaTest {
…
@Test
public void testMassimoDi SequenzaNonVuotaDiInteriTuttiPositivi () {
assertEquals(8, new Sequenza(1,5,8,3,4).massimo());
}
…
@Test
public void testMassimoDi SequenzaNonVuotaDiInteriTuttiNegativi () {
assertEquals(-1, new Sequenza(-6,-1,-8,-13,-10).massimo());
}
…
@Test
public void testMassimo InPrimaPosizione () {
assertEquals(1000, new Sequenza(1000,0,80,-10,-10).massimo());
}
…
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#52,52,"Programmazione orientata agli oggetti
Minimalità (1)
•I test visti sinora non sono minimali
•E’ possibile esprimere lo stesso scenario di 
testing con test-case più brevi, e che fanno 
uso di oggetti di stato meno complesso
•Quale di questi test-case preferire? perché?
@Test
public void testMassimoDiSequenzaNonVuotaDiInteriTuttiPositivi () {
    assertEquals(8, new Sequenza(1,5,8,3,4) .massimo());
}
…oppure…
@Test
public void testMassimoDiSequenzaNonVuotaDiInteriTuttiPositivi () {
    assertEquals(2, new Sequenza(1,2) .massimo());
}
???"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#53,53,"Programmazione orientata agli oggetti
Minimalità (2)
•L’uso di test minimali rende molto più 
semplice la ricerca degli errori
•Nulla è più minimale di una sequenza vuota!
   
@Test
   public void testMassimoDiSequenzaVuota () {
   assertEquals( ???, new Sequenza().massimo());
   }
•Qual’è il massimo di una sequenza vuota?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#54,54,"Programmazione orientata agli oggetti
Testing - Punto di Vista di un 
Programmatore-Utilizzatore (2)
•Di nuovo il testing ha evidenziato un 
problema nel contratto di utilizzo che il 
metodo massimo()  espone agli utilizzatori
   @Test(expected = java.util.NoSuchElementException )
   public void testMassimoDiSequenzaVuota () {
   new Sequenza().massimo();
   }public class Sequenza {
…
   public int massimo() {
     if (this.sequenza.length==0)
        throw new java.util.NoSuchElementException();
     // …
}    
}
@Test(expected = java.util.NoSuchElementException.class)
   public void testMassimoDiSequenzaVuota() {
   new Sequenza().massimo();
   }JUnit 4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#55,55,"Programmazione orientata agli oggetti
“Si nasce minimali, non ci si diventa”
Conviene sempre partire dai test più semplici, 
perché sono quelli che permetteranno di 
rimuovere la maggior  parte dei bug il minor 
sforzo possibile
E’ poi naturale aumentare, via via, la 
complessità degli scenari di testing
per aumentare la propria confidenza sulla 
correttezza del proprio codice
Ad esempio, se ipotizziamo di ordinare tutti i 
test-case secondo la complessità dello 
scenario di testing trattato…"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#56,56,"Programmazione orientata agli oggetti
Scenari di Testing di Complessità Crescente
…
public class SequenzaTest {
@Test(expected = java.util.NoSuchElementException.class)
   public void testMassimoDiSequenzaVuota() {
   new Sequenza().massimo();
   }
   @Test
public void testMassimoDiSequenzaSingleton() {
  assertEquals(1, new Sequenza(1).massimo());
}
@Test
public void testMassimoInPrimaPosizione() {
  assertEquals(2, new Sequenza(2,1).massimo());
}
@Test
public void testMassimoInSecondaPosizione() {
  assertEquals(2, new Sequenza(1,2).massimo());
}
   @Test
public void testMassimoDiSequenzaNonVuotaDiInteriTuttiNegativi() {
  assertEquals(-1, new Sequenza(-2,-1).massimo());
}
…
} Fixture di complessità 
crescente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#57,57,"Programmazione orientata agli oggetti
Quando Scrivere i Test?
•Uno dei più gravi e purtroppo frequenti errori di 
chi viene introdotto allo unit-testing è aspettare 
la fine della scrittura di tutto il codice principale 
per cominciare a scrivere il codice di test
•E’ la scelta peggiore! si massimizzano i costi di 
scrittura dei test e si minimizzano i benefici
potranno esistere contemporaneamente molteplici errori, 
anche correlati, e se tanti test falliscono, non è più chiaro da 
dove cercarli… in due parole: scarsa località
Risulta più conveniente scriverli 
continuativamente, durante  o addirittura prima 
della scrittura del codice principale (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#58,58,"Programmazione orientata agli oggetti
Testing Continuo
•Il testing deve essere una attività associata ed 
affiancata all’ordinario sviluppo del codice 
principale: avviene progressivamente e 
continuativamente
•Principali motivazioni legate ai costi
–la rimozione precoce degli errori riduce i costi di sviluppo
–si costruisce contestualmente al codice principale un 
ambiente di test
–si accumulano batterie di test   molto utili per lo sviluppo 
e la manutenzione efficace del codice principale
–i test possono essere riutilizzati durante la manutenzione 
del software ad esempio per evitare regressioni
59"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#59,59,"Programmazione orientata agli oggetti
•Chi scrive test si costringe nel ruolo del 
Programmatore-Utilizzatore  e si focalizza sulla 
semplicità di utilizzo del proprio codice
•Per questo motivo il testing aiuta a cambiare 
la prospettiva di visione sul proprio codice, a 
concentrarsi sulle interfacce delle proprie 
classi e sulla distribuzione delle responsabilità
•Tipicamente il codice di qualità è più testabile  
e viceversa
•Esistono metodologie di sviluppo che portano 
all’estremo questa attitudine: T.D.D.
60Testing - Punto di Vista di un 
Programmatore-Utilizzatore (3)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#6,6,"Programmazione orientata agli oggetti
Motivazioni del Testing
•I programmi sono descrizioni “statiche” a cui possono 
corrispondere molteplici esecuzioni “dinamiche”
•I compilatori moderni sono in grado di indicare esattamente 
posizione e motivo degli errori di compilazione
–addirittura già mentre si scrive! (compilazione 
incrementale )
•Al contrario i compilatori NON possono prevedere come 
evolverà l’esecuzione di un programma e non sono in grado 
di individuare gli errori dei programmatori (né possono 
sapere cosa intendessero esprimere con il proprio codice)
•In sintesi:
–il compilatore ci aiuta sugli aspetti statici (ad es. analizzando i tipi)
–il compilatore non dice nulla di nuovo sugli aspetti dinamici (più di 
quanto non sia già implicato dagli aspetti statici)
7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#60,60,"Programmazione orientata agli oggetti
Test Driven Development
•Promuove l’uso dei test anche come 
strumento di progettazione 
–i test guidano lo sviluppo verso codice che sia 
semplice, facilmente testabile e di qualità
•Predica la scrittura dei test-case prima  della 
scrittura del codice testato
•anticipa nel tempo ed evidenzia il punto di 
vista del Programmatore-Utilizzatore
•predilige micro-iterazioni
testing-coding-testing-coding ... 
che incentivano la minimalità dei test
61"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#61,61,"Programmazione orientata agli oggetti
Sviluppo Guidato dai Test
•Se scriviamo il codice di test prima del 
codice stesso siamo incentivati a:
–precisare i metodi visibili all’esterno in 
quanto il codice di test è codice cliente
•esterno alla classe alla stregua di tutte le 
altri classi clienti del codice testato
–chiarire la semantica dei metodi
–cercare di semplificare al massimo 
l’utilizzo del codice
–Individuare i casi limite e chiarire la 
gestione delle situazioni anomale
62"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#62,62,"Programmazione orientata agli oggetti
Motivazioni del Testing: Conclusioni
•La rimozione precoce degli errori riduce i costi 
di sviluppo e migliora la qualità del codice
•I test inducono ad assumere anticipatamente 
il punto di vista del Programmatore-
Utilizzatore e spingono gli sviluppatori verso 
soluzioni più semplici per gli utilizzatori
•Si documenta in maniera formale e precisa il 
funzionamento del codice
63"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#63,63,"Programmazione orientata agli oggetti
Jupiter - JUnit 5 vs JUnit 4
●Molti miglioramenti, nessuna rivoluzione, perché già JUnit 4 funzionava benissimo
●Alcune rendono il testing più facile in particolari scenari
─test parametrici (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#64,64,"Programmazione orientata agli oggetti
JUnit 5 vs JUnit 4: In Pratica
●Nella pratica serve conoscere entrambe le versioni
─“Greenfield” project: usare Jupiter – JUnit 5
─“Brownfield” project: continuare ad usare JUnit 4
●Conviene cambiare?
─Soprattutto per un uso basico, JUnit 4 già funzionava benissimo
─Per utilizzi più avanzati, le soluzioni Junit 4 risultano, in genere, sensibilmente 
più “macchinose” delle equivalenti in JUnit 5
●Un project “brownfield” su tutti: il SISTEMA QUIZ
─Si basa su JUnit 4 e non vale la pena di aggiornarlo, al momento…
●Se di decide di aggiornare un progetto, come prima cosa ricordarsi di cambiare gli 
import…
─Da JUnit 4:
•import static org.junit.Assert.*;  // Asserzioni  assertXYZ… 
•import org.junit.*;                // Annotazioni @… 
─A JUnit 5:
•import static org.junit.jupiter.api.Assertions.*; // assertXYZ…
•import org.junit.jupiter.api.*;    // Annotazioni @… "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#65,65,"Programmazione orientata agli oggetti
Esercizi
•Scrivere (con Eclipse) una classe di test JUnit per la classe 
Persone (dal Quiz di preparazione alla prima verifica)  
•In particolare testare il metodo int contaOmonimiDi(String nome)
•Scrivere il codice del metodo int contaOmonimiDi(String nome)
•Eseguire la classe di test JUnit (se il test fallisce, correggere il 
metodo sotto test e far girare nuovamente la classe di test)
66public class Persone {
    private String[] nomi;
    
    public Persone(int n) {
        this.nomi = new String[n];
    }
    
    public int contaOmonimiDi(String nome) {
        // metodo da scrivere
    }
    
    public void aggiungiNome(int indice, String nome){
        this.nomi[indice] = nome;
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#7,7,"Programmazione orientata agli oggetti
I Bug
•I bug sono errori nell’evoluzione 
dinamica di un programma su cui il 
compilatore non ha potuto prevedere e 
dire nulla
•Il debugging è completamente a carico 
del programmatore
•Il costo di debugging è ritenuto di gran 
lunga la componente principale nel costo 
dei moderni progetti software
8"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#8,8,"Programmazione orientata agli oggetti
Ciclo di Debugging
•Come si effettua il debugging di un 
programma che compila? Con estenuanti 
cicli:
 
     
        esecuzione
        controllo manuale dei risultati
       
      ricerca del bug
      modifiche al codice
      compilazione
      
          rimozione errori di compilazione
          compilazione
      
9A sua volta può richiedere:
sessioni di tracing/logging
sessioni con il debugger"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-08-testing.pdf#9,9,"Programmazione orientata agli oggetti
Costo del Debugging
•Debugging del codice: operazione molto 
costosa (nonostante gli ausili dell'IDE)
•E’ noto che il costo della correzione di bug 
dipende da almeno due grandezze che ne 
determinano la località :
–le “dimensioni” del contesto
numero di linee di codice in cui il bug può annidarsi
–il “tempo” che il bug impiega  per manifestarsi
misura temporale di quanto dista la causa del bug ( durante 
un’esecuzione del codice ) ed il rilevamento dei suoi effetti 
10"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Interfacce e Polimorfismo 
Upcasting e Downcasting"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#1,1,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding
•Tipo statico e tipo dinamico
•Interfacce come ruolo
2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#10,10,"Programmazione orientata agli oggetti
Java Interface (3)
•Nelle interface specifichiamo solo le segnature 
(e il tipo restituito) dei metodi che un tipo può 
offrire
•In una interface  non c'è nessun dettaglio 
relativo alla implementazione 
–Niente variabili
–Niente costruttori
–Niente corpo dei metodi
•Le interface non si possono istanziare
•Ma una classe può implementare una (o più) 
interface
•Una classe che implementa una interface  
garantisce che le sue istanze rispettino il tipo 
specificato nella interface  11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#11,11,"Programmazione orientata agli oggetti
Classi ed Interface (1)
•La parola chiave implements  serve a 
specificare che la classe Tamburo  
implementa l'interfaccia Strumento
•Questo significa che gli oggetti Tamburo  
sono in grado di offrire i metodi del tipo 
Strumento
12public class Tamburo implements Strumento  {
  public void produciSuono() {
    System.out.println(""bum-bum-bum"");   
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#12,12,"Programmazione orientata agli oggetti
Classi ed Interface (2)
•Una classe che implementa una interface  
può avere altri metodi (oltre a quelli della 
interface ) specifici della classe
13public class Chitarra implements Strumento  {
  private int[] corde;
  public Chitarra(){
    corde = new int[6];
  }
  public void produciSuono() {
    System.out.println(""dlen-dlen-dlen"");   
  }
  public int accorda(int corda, int val) {
    return corde[corda] += val;
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#13,13,"Programmazione orientata agli oggetti
Esempio
14public class Tamburo implements Strumento  {
  public void produciSuono()  {
    System.out.println(""bum-bum-bum"");   
  }
}
public class Chitarra implements Strumento  {
  private int[] corde;
  public Chitarra(){
    corde = new int[6];
  }
  public void produciSuono()  {
    System.out.println(""dlen-dlen-dlen"");   
  }
  public int accorda(int corda, int val) {
    return corde[corda] += val;
  }
}public class Tromba implements Strumento  {
  public void produciSuono()  {
    System.out.println(""pe-pe-re-pe-pe"");
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#14,14,"Programmazione orientata agli oggetti
Diagramma delle Classi
15
<<interface>>
Strumento
void produciSuono()<<interface>>
Strumento
void produciSuono()
Tromba
Tromba
Tamburo Tamburo<<implements>><<implements>>
Chitarra
corde int[]
Chitarra
corde int[]<<implements>>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#15,15,"Programmazione orientata agli oggetti
Tipi, Sottotipi & Supertipi
•Abbiamo detto che una interface  definisce 
un tipo
•Se la classe C implementa una interface I  
diciamo che: 
–C è un sottotipo di I
e che 
–I è un supertipo  di C
•Ad esempio
•Tamburo  è un sottotipo di Strumento
•Strumento  è un supertipo di Tamburo
16"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#16,16,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding 
•Tipo statico e tipo dinamico
•Interfacce come ruolo
17"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#17,17,"Programmazione orientata agli oggetti
Principio di Sostituzione (1)
•In Java vale il principio di sostituzione  (di Liskov) : 
un sottotipo può essere usato al posto di un suo supertipo
•Rivediamo il metodo suona(Strumento s)  della classe 
Musicista:
•Se invochiamo il metodo suona(Strumento s), per il 
principio di sostituzione, possiamo passargli anche un 
riferimento ad un oggetto istanza di una qualunque 
classe che implementi l'interfaccia Strumento
18public void suona( Strumento s ){
s.produciSuono();
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#18,18,"Programmazione orientata agli oggetti
Principio di Sostituzione (2)
•Esempio:
•Nelle chiamate al metodo suona(Strumento s) 
abbiamo usato un riferimento ad un oggetto 
Chitarra  (e poi un riferimento ad un oggetto 
Tamburo ) al posto di un riferimento a Strumento
19public static void main(String[] args){
  Chitarra c = new Chitarra();
  Strumento t = new Tamburo();
  Musicista ludovico = new Musicista(""Ludovico"");
  ludovico.suona(c);
  ludovico.suona(t);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#19,19,"Programmazione orientata agli oggetti
Principio di Sostituzione (3)
•Per il principio di sostituzione, un riferimento 
ad un sottotipo può essere assegnato ad un 
riferimento ad un suo supertipo
•Esempio:
    Strumento s;
    Chitarra c;
    c = new Chitarra();
    s = c;
20"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#2,2,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding 
•Tipo statico e tipo dinamico
•Interfacce come ruolo
3"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#20,20,"Programmazione orientata agli oggetti
Principio di Sostituzione (4)
•Commentiamo le precedenti istruzioni
Strumento s;
–Abbiamo definito una variabile s: contiene un riferimento ad 
un oggetto che rispetta il tipo Strumento
Chitarra c;
–Abbiamo definito una variabile c: contiene un riferimento ad 
un oggetto che rispetta il tipo Chitarra
c = new Chitarra();
–Abbiamo creato un oggetto Chitarra  e ne abbiamo 
assegnato il riferimento alla variabile c
s = c;
–Abbiamo assegnato il riferimento all'oggetto c alla variabile s
•È tutto lecito perché l'oggetto c è istanza della classe 
Chitarra  che implementa il supertipo Strumento
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#21,21,"Programmazione orientata agli oggetti
Upcasting
•La promozione da un tipo ad un suo supertipo 
viene chiamata upcasting
•upcasting  : un riferimento ad un oggetto è 
“promosso” in un riferimento ad un suo 
supertipo
•Il termine (“Up”=”verso l’alto”) è 
tradizionalmente legato al modo in cui vengono 
espresse graficamente le dipendenze 
supertipo/sottotipo 
(vedi diagramma delle classi)
22
<<interface>>Strumentovoid produciSuono()<<interface>>Strumento
void produciSuono()
Tromba
Tromba
Tamburo Tamburo<<implements>><<implements>>
Chitarra
corde int[]
Chitarra
corde int[]<<implements>>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#22,22,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding
•Tipo statico e tipo dinamico
•Interfacce come ruolo
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#23,23,"Programmazione orientata agli oggetti
Polimorfismo e Late Binding (1)
•Consideriamo la classe Musicista
24public class Musicista {
private String nome;
public Musicista(String nome){
this.nome = nome;
} 
public void suona(Strumento s){
s.produciSuono();
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#24,24,"Programmazione orientata agli oggetti
Polimorfismo e Late Binding (2)
•Cosa succede a tempo di esecuzione, quando al 
parametro s è legato un oggetto?
•Sappiamo che il metodo produciSuono()  viene 
invocato da un oggetto la cui classe implementa 
l'interfaccia Strumento  
•Ma il codice da eseguire non è noto se non a tempo di 
esecuzione
•Il collegamento tra segnatura e corpo del codice da 
eseguire per produciSuono()  viene stabilito solo a 
tempo di esecuzione ( late binding )
•C'è un comportamento polimorfo  del parametro 
formale Strumento s  
–può assumere forme/comportamenti diversi: tutti quelli dei 
suoi sottotipi
25"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#25,25,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding
•Tipo statico e tipo dinamico
•Interfacce come ruolo
26"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#26,26,"Programmazione orientata agli oggetti
Tipo Statico e Tipo Dinamico
•Consideriamo la seguente istruzione:
Strumento s = new Chitarra();
•È lecita, per il principio di sostituzione
•Qual è il tipo della variabile s?
•Dobbiamo distinguere tra
–Tipo statico
–Tipo dinamico
27"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#27,27,"Programmazione orientata agli oggetti
Tipo Statico
•Il tipo statico è quello che viene usato nella 
dichiarazione della variabile
•Ad esempio, nella istruzione:
Strumento s = new Chitarra();
il tipo statico di s è Strumento  
•Il tipo statico è determinato a tempo di compilazione
•Il compilatore permette di applicare i metodi del tipo 
statico (ovvero verifica che su una variabile siano 
invocati i metodi del suo tipo statico)
•Nel nostro esempio possiamo invocare su s solo i 
metodi di Strumento  
    Strumento s = new Chitarra();
    s.produciSuono();// CORRETTO
    s.accorda(2,1);  // ERRATO: il tipo Strumento non 
// possiede il metodo accorda(int, int)
28"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#28,28,"Programmazione orientata agli oggetti
Tipo Dinamico
•Il tipo dinamico è quello dell'oggetto realmente 
istanziato e quindi referenziato in memoria
•Ad esempio, nella istruzione:
Strumento s = new Chitarra();
il tipo dinamico di s è Chitarra
•Il tipo dinamico stabilisce quale sarà 
l'implementazione usata 
•Nel nostro esempio:
Strumento s = new Chitarra();
s.produciSuono();
•A tempo di esecuzione il codice del metodo 
produciSuono()  che viene usato è quello definito 
nella classe Chitarra
29"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#29,29,"Programmazione orientata agli oggetti
Tipo Statico e Tipo Dinamico
•Capire la differenza tra tipo statico e tipo 
dinamico è fondamentale
•Il tipo statico viene assegnato dal compilatore 
e determina l'insieme dei metodi che possono 
essere invocati
•Il tipo dinamico interviene a tempo di 
esecuzione e determina l'implementazione che 
viene eseguita 
30"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#3,3,"Programmazione orientata agli oggetti
Riferimenti Tipati (1)
•In Java i riferimenti sono tipati, ovvero 
specificano il tipo dell'oggetto referenziato
•La definizione:
Strumento s;
afferma  che s è un riferimento ad un oggetto 
di tipo Strumento
•Questo significa che attraverso s possiamo 
invocare i servizi del tipo Strumento
–ovvero che è possibile chiedere di eseguire i 
metodi offerti dal tipo Strumento all’oggetto 
referenziato da s
4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#30,30,"Programmazione orientata agli oggetti
Tipo Statico vs Tipo Dinamico (1)
31Chitarra c = new Chitarra();Qual'è il tipo di c?
Strumento s = new Chitarra();Qual'è il tipo di s?Tipo Dinamico Tipo Statico
Tipo Dinamico Tipo Statico"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#31,31,"Programmazione orientata agli oggetti
Tipo Statico vs Tipo Dinamico (2)
•Il tipo dichiarato di una variabile è il suo tipo 
statico
•Il tipo dell'oggetto a cui una variabile si 
riferisce è il suo tipo dinamico
•Il compilatore si preoccupa di verificare 
violazioni del tipo statico
  Strumento strumento = new Chitarra();
  strumento.accorda(2,1);// ERRORE a tempo di compilazione
•accorda()  non è tra i metodi di Strumento  
(tipo statico della var. locale strumento )
32"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#32,32,"Programmazione orientata agli oggetti
Tipo Statico vs Tipo Dinamico (3)
•A tempo di esecuzione viene eseguito il 
metodo del tipo dinamico
✔d’altronde i metodi definiti nelle interfacce 
non possiedono implementazione se non 
quella delle classi che le implementano
•Nota che il compilatore non solo non 
conosce , ma neanche può prevedere , in 
generale , i tipi dinamici >>
33"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#33,33,"Programmazione orientata agli oggetti
Imprevedibilità dell’Esecuzione (1)
import java.util.Random;
public class OrchestraCausale {
public static void main(String[] args){
  Strumento[] orchestra = new Strumento[10];
  Random r = new Random();
  for(int i=0; i<orchestra.length; i++) {
  int numeroAcaso = r.nextInt(3);
  if (numeroAcaso==0)
  orchestra[i] = new Chitarra();
  if (numeroAcaso==1)
  orchestra[i] = new Tamburo();
  if (numeroAcaso==2)
  orchestra[i] = new Tromba();
   }
  for(int i=0; i<orchestra.length; i++)
orchestra[i].produciSuono();
}
}
34"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#34,34,"Programmazione orientata agli oggetti
Imprevedibilità dell’Esecuzione (2)
•Nell'esempio precedente l'array è riempito 
casualmente a tempo di esecuzione: non 
sappiamo a priori quali strumenti vengono 
assegnati ai vari elementi dell'array
•A tempo di esecuzione, ogni elemento 
dell'array produce il suono corrispondente al 
tipo dinamico
•A tempo di compilazione, ogni elemento 
dell’array possiede tipo statico Strumento
Il compilatore non può prevedere il tipo dinamico degli 
oggetti effettivamente utilizzati a tempo di esecuzione  
35"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#35,35,"Programmazione orientata agli oggetti
Tipo Statico e Tipo Dinamico: 
Overloading (1)
•L'overloading dei metodi viene risolto dal 
compilatore, quindi staticamente
•In particolare: 
–se abbiamo un metodo sovraccarico il 
compilatore guarda il tipo statico dei parametri 
per decidere qual’è il metodo da invocare
•Vedi esercizio seguente 
36"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#36,36,"Programmazione orientata agli oggetti
Tipo Statico e Tipo Dinamico: 
Overloading (2)
interface  Edificio {
     public int altezza();
}
public class Palazzo implements Edificio {
private int altezza;
public Palazzo(int altezza) {this.altezza = altezza;}
public int altezza() {return this.altezza;}
}
public class Coloratore {
     public void colora(Edificio e) {
System.out.println(""Colorato Edificio"");
     }
     public void colora(Palazzo p) {
System.out.println(""Colorato Palazzo"");
     }
     public static void main(String args[]) {
Palazzo p = new Palazzo(4);
Edificio e = new Palazzo(3);
        Coloratore c = new Coloratore();
        c.colora(p);
c.colora(e);
     }
}
37Tipo statico di p è Palazzo
Tipo statico di e è Edificio"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#37,37,"Programmazione orientata agli oggetti
Tipo Statico e Tipo Dinamico: 
Esempio
interface  Veicolo {
     public void func(Veicolo v);
     public void func(Autotreno a);
}
public class Autotreno implements Veicolo {
     public void func(Veicolo v) {
System.out.println(""Autotreno.func(Veicolo) "");
     }
     public void func(Autotreno a) {
System.out.println(""Autotreno.func(Autotreno) "");
     }
     public static void main(String args[]) {
 Veicolo a = new Autotreno();
        Autotreno b = new Autotreno();
        a.func(b);
        a.func(a);
     }
}
38Tipo statico di b è 
Autotreno
Tipo statico di a è Veicolo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#38,38,"Programmazione orientata agli oggetti
Esercizi
•Fare le verifiche
–L.java
–Olimpiadi.java
–Villa.java
39"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#39,39,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding
•Tipo statico e tipo dinamico
•Interfacce come ruolo
40"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#4,4,"Programmazione orientata agli oggetti
Riferimenti Tipati (2)
•Consideriamo la seguente classe Musicista
5public class Musicista {
private String nome;
public Musicista(String nome) {
this.nome = nome;
} 
public void suona(Strumento s) {
s.produciSuono();
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#40,40,"Programmazione orientata agli oggetti
Interface come Ruolo (1)
•Una classe può implementare più di una 
interface
•Potremmo dire che ciascuna interface 
implementata da una classe rappresenta uno 
specifico ""ruolo"" che la classe può assumere
•Ragionare sui ruoli (ed usare le potenzialità 
del polimorfismo) ci aiuta a produrre codice 
altamente riutilizzabile
41"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#41,41,"Programmazione orientata agli oggetti
Interface, Ruoli e Riuso (1)
•Consideriamo un problema noto che si presta 
naturalmente ad un comportamento polimorfo 
degli oggetti interessati: l'ordinamento
•Supponiamo di avere una classe che modella 
un ""orario"", espresso in ore e minuti
•Supponiamo di avere una collezione (per 
semplicità un array) di oggetti orario
•Supponiamo di voler ordinare questa 
collezione
42"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#42,42,"Programmazione orientata agli oggetti
Esempio: La Classe Orario
public class Orario {
   private int ore;
   private int minuti;
   public Orario(int ore, int minuti) {
       this.ore = ore;
       this.minuti = minuti;
   }
   public int getOre() {
       return this.ore;
   }
   public int getMinuti() {
       return this.minuti;
   }
public boolean minoreDi(Orario o) {
    if (this.getOre() > o.getOre()) 
           return false;
       if (this.getOre() == o.getOre()) 
           return (this.getMinuti() < o.getMinuti());
    return true;
}
   public String toString() {
       return this.getOre()+"":""+this.getMinuti();
   }
}
43"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#43,43,"Programmazione orientata agli oggetti
Interface, Ruoli e Riuso (2)
•Per ordinare la collezione creiamo una opportuna 
classe che offre questa funzionalità attraverso il 
metodo ordina(Orario[])
•Scriviamo il codice 
(usiamo un qualsiasi algoritmo di ordinamento, 
cfr. corso Fondamenti, ad esempio il «selection 
sort»)
•vedi classe OrdinatoreOrari
44"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#44,44,"Programmazione orientata agli oggetti
La Classe OrdinatoreOrari
public class OrdinatoreOrari {
  public static void ordina(Orario[] lista) {
   int imin;
   for (int ord=0; ord<lista.length-1; ord++) {
     imin = ord;
     for (int i=ord+1; i<lista.length; i++)
       if (lista[i].minoreDi(lista[imin])) {
          Orario temp=lista[i];
          lista[i]=lista[imin];
          lista[imin]=temp;
       }
     }
   }
 }
45"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#45,45,"Programmazione orientata agli oggetti
Interface, Ruoli e Riuso (3)
•Osserviamo bene il codice di 
OrdinatoreOrari
•Affinché gli oggetti dell'array possano essere 
ordinati, l'unica proprietà che questi oggetti 
devono avere è quella di possedere un metodo 
minoreDi(Orario)
•In altri termini l'ordinamento funziona su 
oggetti che sappiano interpretare il ruolo di 
«essere confrontati» 
•Questo ruolo lo possiamo esplicitare in una 
opportuna interface
46"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#46,46,"Programmazione orientata agli oggetti
“Confrontabilità”, come Ruolo
•Creiamo l'interface Comparabile : gli 
oggetti delle classi che la implementano 
sono in grado di essere confrontati 
tramite il metodo 
minoreDi(Comparabile)
47"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#47,47,"Programmazione orientata agli oggetti
L'interface Comparabile
public interface Comparabile {
public boolean minoreDi(Comparabile c);
}
48"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#48,48,"Programmazione orientata agli oggetti
Interface, Ruoli e Riuso (4)
•Possiamo ora generalizzare la nostra classe 
Ordinatore (e il relativo algoritmo di 
ordinamento) affinché funzioni su tutte le 
classi che sappiano interpretare il ruolo 
Comparabile
49"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#49,49,"Programmazione orientata agli oggetti
La Classe Ordinatore
public class Ordinatore {
 public static void ordina( Comparabile [] lista){
   int imin;
   for (int ord=0; ord<lista.length-1; ord++){
     imin = ord;
     for (int i=ord+1; i<lista.length; i++)
       if (lista[i]. minoreDi (lista[imin])){
          Comparabile temp=lista[i];
          lista[i]=lista[imin];
          lista[imin]=temp;
       }
     }
   }
 }50"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#5,5,"Programmazione orientata agli oggetti
Riferimenti Tipati (3)
•Il metodo suona(Strumento s)  prende 
come parametro un riferimento ad un 
oggetto il cui tipo è Strumento
•Nel corpo del metodo è possibile 
invocare su s tutti i metodi offerti dal 
tipo Strumento
–intuiamo che Strumento  offre il metodo 
public void produciSuono()
6"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#50,50,"Programmazione orientata agli oggetti
La Classe Orario  (rivisitata)
public class Orario implements Comparabile  {
   private int ore;
   private int minuti;
   public Orario(int ore, int minuti) {
     this.ore = ore;
     this.minuti = minuti;
   }
   public int getOre() {
     return this.ore;
   }
   public int getMinuti() {
     return this.minuti;
   }
   public boolean minoreDi(Comparabile c)  {
     Orario o;
     o = (Orario)c;
     if (this.getOre() > o.getOre()) 
        return false;
     if (this.getOre() == o.getOre()) 
        return (this.getMinuti() < o.getMinuti());
     return true;
   }
   public String toString() {
     return this.getOre()+"":""+this.getMinuti();
   }
}
51 public boolean minoreDi(Comparabile c)  {
     Orario o;
     o = (Orario)c;
     if (this.getOre() > o.getOre()) 
        return false;
     if (this.getOre() == o.getOre()) 
        return (this.getMinuti() < o.getMinuti());
     return true;
   }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#51,51,"Programmazione orientata agli oggetti
Interface, Ruoli e Riuso (5)
•Per rispettare l'interface Comparabile  il 
metodo minoreDi()  deve prendere come 
parametro un oggetto Comparabile 
   
   public boolean minoreDi(Comparabile c)
•Quando però scriviamo il codice, dobbiamo 
poter usare i metodi specifici della classe 
Orario (altrimenti non potremmo 
implementare il metodo!)
•Il compilatore non ce lo permette: il tipo 
statico del parametro è Comparabile
52"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#52,52,"Programmazione orientata agli oggetti
Downcasting (1)
•È necessaria  allora una “forzatura” sul tipo 
del parametro
•In particolare forziamo l’utilizzo (a tempo 
statico ed anche dinamico>>) del sottotipo
•Questa operazione viene chiamata 
downcasting (in opposizione all’ upcasting )
53
<<interface>>
Strumentovoid produciSuono()<<interface>>Strumento
void produciSuono()
Tromba
Tromba
Tamburo Tamburo<<implements>> <<implements>>
Chitarra
corde int[]
Chitarra
corde int[]<<implements>>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#53,53,"Programmazione orientata agli oggetti
Downcasting (2)
•Quando si opera il downcasting: 
•Informiamo il compilatore che vogliamo 
“forzarlo” ad usare un certo tipo statico
•Lo stesso introduce (a tempo statico, durante la 
compilazione) nel codice oggetto un controllo 
da eseguirsi a tempo dinamico, durante 
l’esecuzione: la macchina virtuale verifica che 
l'operazione sia lecita e possibile
•Ovvero verifica che l'oggetto sia di un tipo dinamico 
effettivamente sottotipo del tipo statico forzato
•In caso contrario il programma abortisce 
sollevando una eccezione di tipo 
java.lang.ClassCastException
54"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#54,54,"Programmazione orientata agli oggetti
Esercizio
1)Scrivere con JUnit test-case minimali  per 
confermare il corretto funzionamento del 
metodo minoreDi()  come implementato nella 
classe Orario
2)Scrivere con JUnit un test-case per:
–definire e creare un array di 5 oggetti Orario
–creare 5 oggetti orario, che rappresentino i seguenti 
orari: 12:30, 21:40, 9:20, 4:00, 1:35
–mettere i riferimenti ai 5 oggetti creati negli elementi 
dell'array
–Ordinare l'array
–Verificare che sia correttamente ordinato  
55"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#55,55,"Programmazione orientata agli oggetti
Esercizio
•Scrivere una classe Studente , che contenga i 
campi nome (una stringa), età (un intero), un 
costruttore con due parametri, e i metodi 
accessori
•La classe Studente deve implementare 
l'interfaccia Comparabile , descritta in precedenza 
(vedi codice di Orario )
•Scrivere un metodo che crei un array di oggetti 
Studente e lo ordini (per età) usando il metodo 
Ordinatore.ordina () 
•Scrivere con JUnit una classe di test per verificare 
che l’array sia effettivamente ordinato, dopo 
l'invocazione del metodo Ordinatore.ordina ()
56"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#56,56,"Programmazione orientata agli oggetti
Esercizio
•Introdurre nell'interfaccia Comparabile  un nuovo metodo
 int compara(Comparabile c)  
che restituisce un valore negativo, pari a 0, positivo, se 
l'oggetto su cui è chiamato il metodo è rispettivamente 
minore, uguale, maggiore del valore del parametro
•Nella classe Ordinatore , scrivere il codice del metodo:
public static int  
   ricercaBinaria(Comparabile[] v, Comparabile cercato)
che implementa l'algoritmo di ricerca binaria (cfr. corso di 
Fondamenti di Informatica); questo metodo restituisce un 
intero il cui valore corrisponde alla posizione dell'elemento 
cercato  nell'array v oppure a -1 se tale elemento non è 
presente
•Scrivere, utilizzando JUnit, una classe di test per verificare il 
corretto funzionamento del metodo
57"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#6,6,"Programmazione orientata agli oggetti
Costrutti Java per la 
Definizione di Nuovi Tipi
•Fino ad ora abbiamo visto un solo modo 
per definire nuovi tipi: la definizione di 
nuove classi (mediante il costrutto 
class )
•In Java (e in altri moderni linguaggi OO, 
come ad esempio C#, Scala) esistono 
molteplici costrutti per definire nuovi tipi 
•È il costrutto interface
7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#7,7,"Programmazione orientata agli oggetti
Contenuti 
•Riferimenti tipati
•Java Interface
•Principio di sostituzione
•Polimorfismo e late binding
•Tipo statico e tipo dinamico
•Interfacce come ruolo
8"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#8,8,"Programmazione orientata agli oggetti
Java Interface (1)
•Possiamo dire che una interface  specifica un 
tipo in termini dei servizi, ovvero dei metodi, 
che questi può offrire
•Una interface  non specifica i dettagli 
implementativi dei vari servizi, specifica 
solamente in che modo i servizi possono 
essere invocati (nome, parametri, tipo 
restituito)
•In definitiva una interface  consiste in una 
specifica delle segnature (e dei tipi restituiti) 
dai metodi che il tipo può offrire
9"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-09-polimorfismo-interfacce.pdf#9,9,"Programmazione orientata agli oggetti
Java Interface (2)
•Esempio:
public interface Strumento {
public void produciSuono();
 }
✔L'interface Strumento  definisce il tipo di 
oggetti che possono offrire il metodo 
produciSuono()
10"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Esercitazione:
Interfacce, Polimorfismo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#1,1,"Programmazione orientata agli oggetti
Esercitazione FormeGeometriche
(TRATTO DALL'ESAME DEL GIUGNO 2003)
•Una software house sta sviluppando una libreria per la 
gestione di forme geometriche. Allo stato attuale nella 
libreria ci sono le classi Punto, Cerchio  e Rettangolo  
(vedi codice)
•Sono già date le seguenti classi:
–Punto 
–Cerchio
–Rettangolo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#10,10,"Programmazione orientata agli oggetti
Esercizio 3: Testing su 
GruppoDiForme
•Creare una classe di test per GruppoDiForme  e 
scrivere test-case minimali del metodo trasla()  
che eseguano le seguenti istruzioni
•Distinguere almeno questi scenari di testing a 
complessità crescente, nell’ordine:
–un gruppo vuoto
–un gruppo semplice , con una sola forma non 
ulteriormente decomponibile
–un gruppo composito , ovvero di un gruppo contenente 
un gruppo semplice
–un gruppo complesso, ovvero di un gruppo contenente 
un gruppo composito
•Scrivere diversi test-case minimali  per ciascun 
scenario"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#11,11,"Programmazione orientata agli oggetti
Esercizio 4: Downcasting per 
assertEquals()  nel Metodo equals()
Il metodo (di JUnit) assertEquals()  si basa 
sull'esecuzione del metodo equals()  sugli oggetti 
passati come argomento
La segnatura esatta del metodo equals DEVE essere:
   @Override
   public boolean equals( Object o )
Per accorciare i test-case già prodotti:
–munire la classe Punto di un metodo equals()
–Oggetti istanza della classe Punto distinti ma di pari coordinate 
eguali sono considerati equivalenti
–assicurarsi che i test usino assertEquals() passandogli 
oggetti istanza di Punto
–controllare che risulti effettivamente invocato il metodo 
Punto.equals (Object o)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#2,2,"Programmazione orientata agli oggetti
La Classe Punto
public class Punto {
private int x,y;
public Punto (int x, int y) {
this.x = x;
this.y = y;
}
public void setX(int x){ 
this.x = x; 
}
public void setY(int y){ 
this.y = y; 
}
public int getX(){ 
return this.x; 
}
public int getY(){ 
return this.y; 
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#3,3,"Programmazione orientata agli oggetti
La Classe Cerchio
public class Cerchio {
private int raggio;
private Punto centro;
public Cerchio(Punto centro, int raggio) {
this.raggio = raggio;
this.centro = new Punto(centro.getX(), centro.getY());
}
public void trasla(int deltaX, int deltaY) {
this.centro.setX(this.centro.getX() + deltaX);
this.centro.setY(this.centro.getY() + deltaY);
}
public Punto getCentro() { return this.centro; }
public int getRaggio() { return this.raggio; }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#4,4,"Programmazione orientata agli oggetti
La Classe Rettangolo
public class Rettangolo {
private int altezza, base;
private Punto vertice;
public Rettangolo(Punto vertice, int altezza, int base) {
     this.altezza = altezza;
     this.base = base;
     this.vertice = new Punto(vertice.getX(), vertice.getY());
}
public void trasla(int deltaX, int deltaY) {
     this.vertice.setX(this.vertice.getX() + deltaX);
     this.vertice.setY(this.vertice.getY() + deltaY);
}
public Punto getVertice() { return this.vertice; }
public int getBase()      { return this.base;    }
public int getAltezza()   { return this.altezza; }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#5,5,"Programmazione orientata agli oggetti
Esercizio 1: Polimorfismo
•Si vuole introdurre una classe GruppoDiForme  che 
rappresenta un raggruppamento di forme. In particolare, le 
forme di un raggruppamento possono essere rettangoli, 
cerchi e altri raggruppamenti.  Un gruppo di forme può 
essere traslato (vengono traslate tutte le forme che lo 
compongono)
•La classe GruppoDiForme  deve offrire i metodi:
–void trasla(int deltaX, int deltaY)
trasla tutto il raggruppamento (cioè tutti gli oggetti che 
compongono il raggruppamento)
–void aggiungiForma(Forma forma)
   aggiunge una forma al raggruppamento"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#6,6,"Programmazione orientata agli oggetti
Esercizio 1: Polimorfismo (Continua)
•Suggerimento : astrarre i concetti di forma 
geometrica (rettangolo, cerchio, gruppo) in una 
interfaccia Forma. Quindi, nell’ordine:
1.Scrivere l’interfaccia Forma
2.Rendere Cerchio  e Rettangolo  specializzazioni di 
Forma
3.Scrivere le classi di test CerchioTest  e 
RettangoloTest
4.Scrivere la classe GruppoDiForme: Un gruppo di forme 
è composto da un array di riferimenti a oggetti che 
implementano Forma. Per semplicità si supponga che 
un gruppo di forme possa essere composto al massimo 
da 10 forme.
5.Scrivere la classe GruppoDiFormeTest"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#7,7,"Programmazione orientata agli oggetti
Un GruppoDiForme"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#8,8,"Programmazione orientata agli oggetti
Un GruppoDiForme traslato()
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-10-polimorfismo-esercitazione.pdf#9,9,"Programmazione orientata agli oggetti
Esercizio 2: Testing sulle Forme Semplici
•Utilizzando JUnit creare classi di test per Cerchio  
e Rettangolo . 
•Aggiungere una serie di test-case minimali relativi 
al metodo trasla()
•Ad esempio, un primo test-case testTrasla()  di 
Cerchio :
–istanzia un cerchio unitario (r=1) di centro sull’origine 
(0,0)
–trasla di (+0, +0)
–asserisce che dopo la traslazione il cerchio non si è 
spostato
•Un secondo test-case potrebbe traslare di (+1,+0)
•Un terzo test-case potrebbe ..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Polimorfismo:
Studio di caso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#1,1,"Programmazione orientata agli oggetti
Riprendiamo lo Studio di Caso
•Nelle lezioni precedenti abbiamo già individuato (e 
rimosso) alcuni problemi nel codice dello studio di 
caso:
–La responsabilità di gestire il labirinto deve essere assegnata 
ad una classe opportuna (la classe Labirinto )
–Analogamente la responsabilità di gestire le informazioni 
relative al giocatore (borsa, CFU) devono essere assegnate ad 
una classe opportuna (la classe Giocatore ): da fare per 
esercizio!
•La qualità del codice rimane bassa
–La classe DiaDia implementa tutti(!) i possibili comandi 
del gioco
–Analizziamo le conseguenze di quest'ultimo punto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#10,10,"Programmazione orientata agli oggetti
La classe  ComandoVai  (2)
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#11,11,"Programmazione orientata agli oggetti
Osservazioni (1)
•Chi ha la responsabilità di creare gli oggetti Comando ?
•Questa responsabilità è ragionevole sia affidata non ad un 
metodo della classe DiaDia, ma ad una classe dedicata 
•Una classe che fabbrica comandi 
–FabbricaDiComandi
–fabbrica un oggetto Comando a partire dall’istruzione digitata
•Rimangono alcuni problemi (per ora ci accontentiamo…)
–In particolare:
•accoppiamento forte con la gestione dell'I/O
•il codice a fisarmonica non viene definitivamente 
eliminato, è stato solamente confinato dentro  
FabbricaDiComandi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#12,12,"Programmazione orientata agli oggetti
Osservazioni (2)
•I comandi possono avere un parametro
•Come facciamo ad impostarne il valore?
–attraverso il costruttore 
Es. ComandoVai(String direzione)
–oppure, introducendo (nella interface) un metodo setter 
setParametro(String parametro)
•La seconda soluzione impone che tutte le classi che 
implementano Comando  abbiano questo metodo
–anche quelle che rappresentano comandi senza parametri 
(come «aiuto» o «fine»)
✔Non necessariamente un problema (il corpo del metodo sarà 
vuoto); sicuramente poco elegante
•Le due soluzioni sono equivalenti. Preferiamo 
comunque la seconda 
–(per motivi evidenti solo in seguito >>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#13,13,"Programmazione orientata agli oggetti
L'Interface Comando  (rivista)
public interface Comando {
 /**
    * esecuzione del comando
    */
    public void esegui(Partita partita);
 /**
    * set parametro del comando
    */
    public void setParametro(String parametro);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#14,14,"Programmazione orientata agli oggetti
La Classe  ComandoVai  (rivista)
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#15,15,"Programmazione orientata agli oggetti
Creazione di Oggetti Comando
public class FabbricaDiComandi {
public Comando costruisciComando(String istruzione) {
      Scanner scannerDiParole = new Scanner(istruzione);
  String nomeComando = null;
  String parametro = null;
  Comando comando = null;
  if (scannerDiParole.hasNext())
    nomeComando = scannerDiParole.next(); // prima parola: nome del comando
  if (scannerDiParole.hasNext())
    parametro = scannerDiParole.next();   // seconda parola: eventuale parametro
  if (nomeComando == null) 
    comando = new ComandoNonValido();
  else if (nomeComando.equals( ""vai""))
    comando = new ComandoVai();
  else if (nomeComando.equals( ""prendi""))
    comando = new ComandoPrendi();
  else if (nomeComando.equals( ""posa""))
    comando = new ComandoPosa();
  else if (nomeComando.equals( ""aiuto""))
    comando = new ComandoAiuto();
  else if (nomeComando.equals( ""fine""))
    comando = new ComandoFine();
  else if (nomeComando.equals( ""guarda""))
    comando = new ComandoGuarda();
  else comando = new ComandoNonValido();
  comando.setParametro(parametro);
  return comando;
    }            
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#16,16,"Programmazione orientata agli oggetti
Osservazioni
•Abbiamo migliorato significativamente la qualità 
del codice della classe DiaDia
–risulta ora più coesa (con quali responsabilità?)
–non è più accoppiata ai dettagli dei singoli comandi
–abbiamo rimosso il codice a fisarmonica
•ora confinato nella classe FabbricaDiComandi  (anche se in una 
forma molto più semplice e pulita): non deteriora la qualità del 
codice di DiaDia
•questa anomalia sarà completamente risolta in seguito (>>)
–Predisponiamo il codice a questa prevedibile evoluzione:
•creiamo una interface FabbricaDiComandi , 
•ridenominiamo la classe attuale (che implementa tale 
interface) FabbricaDiComandiFisarmonica
–In pratica astraiamo dai dettagli implementativi della fabbrica, 
in attesa di una implementazione alternativa (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#17,17,"Programmazione orientata agli oggetti
Creazione di Oggetti Comando
public interface FabbricaDiComandi {
    public Comando costruisciComando(String istruzione);
}
public class FabbricaDiComandiFisarmonica implements FabbricaDiComandi {
  @Override
  public Comando costruisciComando(String istruzione) {
    Scanner scannerDiParole = new Scanner(istruzione);
    String nomeComando = null;
    String parametro = null;
    Comando comando = null;
    if (scannerDiParole.hasNext())
       nomeComando = scannerDiParole.next(); // prima parola:   nome del comando
    if (scannerDiParole.hasNext())
       parametro = scannerDiParole.next();  // seconda parola: eventuale param.
    if (nomeComando == null) 
…
 return comando;
  }
         
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#2,2,"Programmazione orientata agli oggetti
Introdurre Nuovi Comandi
•Per introdurre un nuovo comando dobbiamo: 
–aggiungere un elemento nell'array 
ElencoComandi
–aggiungere un metodo nella classe DiaDia
–modificare il metodo 
processaIstruzione(String)
•Ma proviamo a ragionare in termini di 
responsabilità ed a ""pensare in avanti"""
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#3,3,"Programmazione orientata agli oggetti
Pensiamo in Avanti
•È ragionevole supporre che in futuro nel 
nostro gioco possano essere introdotti nuovi 
comandi
•Se per ogni comando introdotto dobbiamo 
modificare la classe DiaDia  come abbiamo 
appena descritto, tale classe crescerà a 
dismisura"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#4,4,"Programmazione orientata agli oggetti
Una Soluzione (1)
•Il problema nasce dal fatto che la classe DiaDia 
conosce e realizza i dettagli di tutti i comandi
–dovrebbe limitarsi a chiamare l'esecuzione di un 
comando, senza conoscerne i dettagli
•Le operazioni corrispondenti all'esecuzione di ogni 
comando dovrebbero essere codificate 
direttamente da un oggetto Comando
–ma abbiamo tanti diversi comandi, ognuno con le sue 
peculiarità …
•Per ovviare al problema un programmatore 
esperto ci suggerisce di sfruttare le potenzialità 
del polimorfismo, ristrutturando il codice come 
indicato di seguito"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#5,5,"Programmazione orientata agli oggetti
Una Soluzione (2)
•La classe Comando  va trasformata in una interface, che 
rappresenti un generico comando
•L'interface Comando  deve offrire il metodo 
public void esegui(Partita partita)
•Tutti i comandi del gioco saranno realizzati da oggetti 
istanze di classi che implementano l'interface Comando : 
–l'implementazione del metodo esegui(Partita partita)  
codifica la semantica del comando specifico
•(Per ora) la classe DiaDia sulla base delle istruzioni 
lette da tastiera istanzia l'implementazione opportuna 
del comando
•Al comando istanziato chiederà quindi di eseguire il 
metodo esegui(Partita partita) , senza preoccuparsi 
di come avverrà l'esecuzione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#6,6,"Programmazione orientata agli oggetti
La Classe DiaDia
private boolean processaIstruzione(String istruzione) {
Comando comandoDaEseguire;
   FabbricaDiComandi factory = new FabbricaDiComandi()
comandoDaEseguire = factory.costruisciComando(istruzione);
comandoDaEseguire.esegui( this.partita); 
if (this.partita.vinta())
System.out.println (""Hai vinto!"" );
if (!this.partita.giocatoreIsVivo())
System.out.println (""Hai esaurito i CFU..."" );
return this.partita.isFinita();
}
•L'oggetto factory (istanza di FabbricaDiComandi ) ha la responsabilità 
di creare un oggetto Comando. Non ci interessano le specificità di ogni 
singolo comando disponibile
–vedremo in seguito (>>) come è fatta la classe FabbricaDiComandi
•Invochiamo semplicemente il metodo esegui() (che è polimorfo): in 
sostanza lasciamo al comando la responsabilità di eseguire il comando
•Spariscono dalla classe tutti i metodi che implementano i comandi. 
✔Per disporre di un nuovo comando basta introdurre la sua classe, 
senza dover modificare la classe DiaDia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#7,7,"Programmazione orientata agli oggetti
L'Interface Comando
public interface Comando {
 /**
    * esecuzione del comando
    */
    public void esegui(Partita partita);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#8,8,"Programmazione orientata agli oggetti
La Classe ComandoVai
•Proviamo a creare una implementazione (la 
classe ComandoVai )
•La classe ComandoVai  implementa il comando 
che permette di cambiare stanza
•Scriviamone il codice"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-11-polimorfismo-studio-di-caso.pdf#9,9,"Programmazione orientata agli oggetti
Implementazione di Comando
public class ComandoVai implements Comando {
private String direzione;
public ComandoVai(String direzione) {
  this.direzione = direzione;
}
 /**
    * esecuzione del comando
    */
  @Override
  public void esegui(Partita partita) {
   // qui il codice per cambiare stanza …
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Approfondimenti Interface
Estensione (prima parte)
La classe Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
•Estensione di Interfacce
•Estensione di Classi (prima parte)
•La classe Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#10,10,"Programmazione orientata agli oggetti
Meccanismi per la Creazione di Tipi
•Attraverso l’estensione delle interfacce è possibile 
definire nuovi tipi a partire da tipi già esistenti
•Riassumiamo tutti i meccanismi visti sinora per 
introdurre nuovi tipi in Java annunciando le linee 
guida per il loro utilizzo 
–Esistono altri meccanismi (classi astratte, tipi 
enumerativi, classi nidificate) che per ragioni di 
natura prettamente didattica conviene rimandare
✔Sfruttiamo invece l’occasione per introdurre la 
classe Object , che al contrario conviene 
comprendere il prima possibile"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#11,11,"Programmazione orientata agli oggetti
Creazione di Tipi Ex-Novo
•Le Interfacce
–permettono di definire nuovi tipi senza definire 
l’implementazione dei metodi che formano la 
specifica di tipo
•Le Classi
–permettono di definire nuovi tipi ma richiedono 
l’implementazione di tutti i metodi che formano la 
specifica di tipo
•Le Classi Astratte (>>)
–strumento “intermedio”: permette di lasciare 
qualche metodo astratto, ovvero senza 
implementazione, pur consentendone la definizione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#12,12,"Programmazione orientata agli oggetti
Definizione di Nuovi Tipi per 
Estensione
•Estensione di interfacce
–nuove interfacce definite come estensione di altre
–nessun metodo nelle due interfacce possiede 
implementazione 
•Estensione di classi
–nuove classi definite come estensione di altre già 
esistenti 
–i metodi ereditano anche l’implementazione, che se 
necessario può essere sovrascritta ( override )
•Per entrambe:
–l’insieme dei metodi del tipo esteso comprende 
quelli pubblici del tipo base, più altri di nuova 
definizione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#13,13,"Programmazione orientata agli oggetti
Sommario
•Estensione di Interfacce
•Estensione di Classi (prima parte)
•La classe Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#14,14,"Programmazione orientata agli oggetti
Estensione di Classi: Introduzione
•Uno dei meccanismi più caratteristici (e più 
difficili da usare correttamente ) dei linguaggi 
OO è l'estensione (o ereditarietà)
•Con l'estensione possiamo definire una nuova 
classe a partire da una classe esistente
–aggiungendo  campi (variabili e/o metodi) a 
quelli della classe originale
–sovrascrivendo metodi della classe originale"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#15,15,"Programmazione orientata agli oggetti
Estensione di Classi: Terminologia
•La classe di partenza viene chiamata superclasse , 
o classe base , o classe genitore
•La classe definita per estensione a partire da una 
classe base viene chiamata classe estesa , o 
classe derivata , o sottoclasse , o classe figlia
nell'ambito del corso preferiamo usare i termini 
classe base  e classe estesa/derivata
•Siccome la classe derivata può a sua volta essere 
utilizzata come classe base di una nuova classe, si 
dice anche che le classi sono organizzate in una 
gerarchia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#16,16,"Programmazione orientata agli oggetti
Estensione di Classi: 
Caratteristiche Generali
•La classe estesa conserva (""eredita"") tutti i 
campi della classe base
•Rispetto alla classe base, la classe estesa di 
solito:
–può avere qualche membro (campo e/o metodo) in 
aggiunta
–può ridefinire il comportamento di qualche metodo
•La classe base viene considerata un supertipo 
della classe estesa
–Quindi vale il principio di sostituzione:  un'istanza 
della classe estesa può essere considerata anche 
come un'istanza della superclasse"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#17,17,"Programmazione orientata agli oggetti
Estensione di Classi: Esempio (1)
public class Persona {
private String nome;
  public Persona(String nome) {
this.nome = nome;
}
public void setNome(String nome) {
this.nome = nome;
}
public String getNome() {
return this.nome;
}
 public String toString() {
return this.getNome();
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#18,18,"Programmazione orientata agli oggetti
Definizione di una Classe estesa
•In Java per indicare la definizione di una nuova 
classe per estensione di una già esistente si 
usa la parola chiave extends
 class Studente extends Persona  {
  
    // metodi e campi
  
 }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#19,19,"Programmazione orientata agli oggetti
Ereditarietà: 
Caratteristiche Generali (1)
•Tutte le variabili e tutte le operazioni definite nella 
classe base sono «ereditate»  nella classe estesa
•Rispetto alla classe base, la classe estesa 
–può avere qualche membro (campo e/o metodo) in più
–può sovrascrivere il comportamento di qualche metodo
•La classe base viene considerata un supertipo 
della classe estesa
–vale il principio di sostituzione: un'istanza della classe 
estesa può essere considerata anche come un'istanza 
della superclasse"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#2,2,"Programmazione orientata agli oggetti
Sommario
•Estensione di Interfacce
•Estensione di Classi (prima parte)
•La classe Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#20,20,"Programmazione orientata agli oggetti
Estensione di Classi: Esempio (2)
public class Studente extends Persona {
private String matricola;
public Studente(String nome, String matricola) {
// vediamo dopo
}
public void setMatricola (String matricola) {
this.matricola = matricola;
}
public String getMatricola() {
return this.matricola;
}
  @Override
public String toString() {
// vediamo dopo
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#21,21,"Programmazione orientata agli oggetti
Definizione di una Classe Estesa (1)
•La classe Studente rispetto alla classe Persona 
possiede un nuova variabile di istanza: 
–matricola
... e i corrispondenti due nuovi metodi accessori
–void setMatricola(String)  
–String getMatricola()
•Le variabili di istanza e i metodi vengono ereditati: 
–le istanze della classe estesa hanno le stesse variabili della 
classe base più quelle eventualmente aggiunte
–tutti i metodi pubblici della classe base sono disponibili nella 
nuova classe, senza necessità di ridefinirli
✔N.B.: esattamente come per tutte le altre classi esterne alla 
classe base, anche la classe estesa può accedere ai membri 
(variabili di istanza o metodi) pubblici della classe base ma 
non a quelli privati "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#22,22,"Programmazione orientata agli oggetti
Definizione di una Classe Estesa (2)
•I nuovi membri della classe estesa non hanno 
nulla di particolare
•Se si dispone di un oggetto Studente è possibile 
invocare i metodi della classe base Persona
–esempio: se si dispone di un riferimento ad un oggetto 
Studente è possibile invocare i metodi della classe base
  Studente anonimo = new Studente("""","""");
anonimo.setNome(""Paolo"");
•In generale, possiamo usare tutti i metodi pubblici 
della classe base (ereditati) oltre quelli della 
classe estesa"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#23,23,"Programmazione orientata agli oggetti
Estensione e Polimorfismo (1)
•Una classe estesa è un sottotipo della classe base 
(la classe base è un supertipo della classe estesa) 
•Infatti la classe estesa offre l'interfaccia 
(e l'implementazione di alcuni) dei metodi della 
classe base
•Quindi, in base al principio di sostituzione, la 
classe estesa può essere usata sempre laddove è 
richiesto un oggetto della classe base 
✔N.B.: esattamente come nel caso di una classe che 
implementa un’interfaccia fornendone un sottotipo 
concreto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#24,24,"Programmazione orientata agli oggetti
Estensione e Polimorfismo (2)
•Studente automaticamente possiede tutti i 
metodi di Persona , senza bisogno di definirli
•La classe estesa ha quindi l'interfaccia e  
l'implementazione  dei metodi della classe 
base
•Studente  è un sottotipo di Persona : può 
essere usata al posto di Persona"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#25,25,"Programmazione orientata agli oggetti
Estensione di Classi (1)
•Vale il principio di sostituzione: il sottotipo può 
certamente essere usato al posto di un 
supertipo
public class ProvaPersona {
    public static void main(String[] args) {
        Persona p = new Studente(""Paolo"", ""123456"");
        p.setNome(""Anna"");
        System.out.println(p.getNome());
        Studente s = new Studente(""Luigi"",""654321"");
        s.setNome(""Antonio"");
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#26,26,"Programmazione orientata agli oggetti
Estensione di Classi (2)
•Attenzione: possono essere invocati solo 
i metodi (pubblici) del tipo statico
public class RiProvaPersona {
    public static void main(String[] args) {
        Persona p = new Studente(""Paolo"", ""123456"");
        p.setNome(""Anna"");
        p.setMatricola(""33333""); // NON COMPILA!
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#27,27,"Programmazione orientata agli oggetti
Ereditarietà: 
Caratteristiche Generali (2)
•Tutte le variabili e tutte le operazioni definite nella 
classe base sono ""ereditate""  nella classe estesa
•Rispetto alla classe base, la classe estesa
–ha qualche membro (campi e/o metodi) in più 
–può sovrascrivere il comportamento di qualche metodo 
•La classe base viene considerata un supertipo 
della classe estesa
–vale il principio di sostituzione: un'istanza della classe 
estesa può essere considerata anche come un'istanza 
della superclasse ed usata al suo posto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#28,28,"Programmazione orientata agli oggetti
Overriding (“Riscrittura”)
•Alcune implementazioni dei metodi offerti nella classe 
base possono essere non adatte alla classe estesa
•Tipico esempio il metodo 
String toString() 
la stampa dovrebbe permettere di distinguere le 
istanze della classe base da quelle della classe estesa
Ad es. nella stringa restituita per gli studenti vogliamo che 
compaia anche la matricola (che non ha senso per tutte le 
persone)
•Questo comportamento si ottiene facendo l' overriding  
( sovrascrittura ) del metodo
Attenzione: non confondere overriding  ed overloading"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#29,29,"Programmazione orientata agli oggetti
Estensione di Classi: Esempio (3)
public class Studente extends Persona {
private String matricola;
public Studente(String nome, String matricola) {
// vediamo dopo
}
public void setMatricola (String matricola) {
this.matricola = matricola;
}
public String getMatricola() {
return this.matricola;
}
  @Override
public String toString() {
return this.nome + "" "" + this.matricola;
}
}  NON COMPILA: si prova ad accedere
  a campi privati (la variabile di istanza nome)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#3,3,"Programmazione orientata agli oggetti
Estensione di Interface (1)
•Talvolta può essere utile definire una nuova 
interface a partire da una interface esistente
•Questo significa definire una nuova interface 
che offre qualche servizio (metodo) 
aggiuntivo rispetto ad una interface nota"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#30,30,"Programmazione orientata agli oggetti
Estensione: Overriding
•La soluzione precedente non è praticabile perché i 
metodi della classe estesa ( Studente ) non 
possono accedere ai campi privati della classe 
base (Persona ) 
–anche se ogni oggetto Studente  ha ereditato una 
variabile di istanza in cui viene memorizzata la 
stringa che rappresenta il nome, non è accessibile!
•Se i metodi della classe estesa vogliono accedere 
ai campi della classe base devono  usare 
l'interfaccia pubblica della classe base come tutte 
le altri classe esterne  alla stessa"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#31,31,"Programmazione orientata agli oggetti
Estensione di Classi: Esempio (4)
public class Studente extends Persona {
private String matricola;
public Studente(String nome, String matricola) {
// vediamo dopo
}
public void setMatricola (String matricola) {
this.matricola = matricola;
}
public String getMatricola() {
return this.matricola;
}
  @Override
public String toString() {
return this.getNome() + "" "" + this.getMatricola();
}
}Accesso al metodo pubblicoPreferire sempre e comunque l’utilizzo
dei metodi accessori rispetto all’uso 
diretto delle variabili di istanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#32,32,"Programmazione orientata agli oggetti
Overriding e Polimorfismo (1)
•Un'istanza della classe estesa può essere usata al 
posto di una istanza della classe base
•Anche qui, si manifesta il polimorfismo (già visto 
per le interfacce) e il legame al codice avviene a 
tempo di esecuzione ( late binding ). Rispetto alle 
interfacce:
–se il metodo non è ridefinito, si utilizza (si eredita) 
l'implementazione della superclasse
–se il metodo è ridefinito (overriding) si utilizza 
l'implementazione della classe estesa
•In definitiva si sceglie sempre  l'implementazione 
del tipo dinamico"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#33,33,"Programmazione orientata agli oggetti
Overriding e Polimorfismo (2)
public class AltraProvaStudente{
    public static void main(String[] args) {
 
        Studente studente = new Studente(""Paolo"", ""123456"");
        Persona persona = new Studente(""Anna"", ""654321"");
     
        System.out.println(studente.toString()); 
        System.out.println(persona.toString());
    }
}
Il tipo dinamico della variabile locale persona è Studente, 
all'invocazione di toString() viene eseguito il codice del
corpo del metodo presente nella classe StudenteIl tipo dinamico della variabile locale studente risulta essere
Studente, all'invocazione di toString() viene eseguito il 
codice del corpo del metodo presente nella classe Studente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#34,34,"Programmazione orientata agli oggetti
Estensione: Creazione di Istanze
•Nella creazione di oggetti istanze di una classe estesa 
bisogna tener presente la relazione esistente con le 
istanze della classe padre
ogni istanza della classe estesa  è  anche una istanza 
della superclasse
•Alcuni meccanismi offerti dal linguaggio Java nella 
gestione dei costruttori per classi estese si 
comprendono meglio tenendo a mente che
ciascuna classe deve essere l’unica responsabile 
dell’inizializzazione delle proprie istanze
per creare una istanza di una classe estesa bisogna prima 
creare l’istanza della classe base «che è in lei»
bisogna concludere la creazione e l’inizializzazione di una 
istanza prima di fare qualsiasi altra cosa con la stessa
A ben vedere, il servizio di creazione di Object (>> e 
derivati) può essere offerto solo dalla JVM"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#35,35,"Programmazione orientata agli oggetti
Estensione: Costruttori (1)
•Il costruttore di una classe estesa deve inizializzare:
–direttamente  le proprie variabili di istanza
–indirettamente  quelle ereditate dalla classe base
•Per il principio dell'information hiding, la classe estesa 
non può avere la responsabilità di inizializzare 
direttamente le variabili di istanza della classe base
•Per non violarlo, il costruttore della classe estesa deve 
poter delegare l'inizializzazione delle variabili di istanza 
della classe base ad un costruttore della stessa
–questa operazione in Java si effettua chiamando dal corpo del 
costruttore della classe estesa il costruttore della classe base 
mediante la parola chiave super() e specificando i parametri 
attuali del costruttore della classe base tipicamente sulla base 
dei parametri formali ricevuti (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#36,36,"Programmazione orientata agli oggetti
Estensione: Costruttori (2)
public class Studente extends Persona {
private String matricola;
public Studente(String nome, String matricola) {
super(nome);
     this.matricola = matricola;
}
public void setMatricola (String matricola) {
this.matricola = matricola;
}
public String getMatricola() {
return this.matricola;
}
  @Override
public String toString() {
return this.getNome() + "" "" + this.getMatricola();
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#37,37,"Programmazione orientata agli oggetti
Estensione: Costruttori (3)
•Il corpo dei costruttori di una classe estesa deve 
sempre  avere una chiamata al costruttore della classe 
base mediante l’uso della parola chiave super come 
prima istruzione
•In assenza di una chiamata esplicita, il compilatore ne 
inserisce automaticamente  una al costruttore no-arg 
della superclasse
–Attenzione: solo  in assenza di tale costruttore nella 
superclasse si verifica un errore a tempo di compilazione
•La chiamata al costruttore della classe base deve 
essere la prima istruzione  nel corpo del costruttore 
della classe estesa
Come già per i metodi, ricordiamo che anche per i costruttori è 
possibile definire diverse versioni sovraccariche; valgono le 
regole già viste per l’overloading di metodi"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#38,38,"Programmazione orientata agli oggetti
Estensione (Prima Parte): 
Ricapitoliamo
•La classe estesa:
–ha tutte le proprietà della classe base
–è in grado di eseguire tutti i metodi (pubblici) della 
classe base
–non ha accesso ai membri privati della classe base 
(nessuna eccezione al principio dell'information hiding) 
•Inoltre:
–può possedere variabili di istanza proprie, oltre a quelle 
ereditate dalla classe base
–può avere metodi propri
–può specializzare il comportamento di alcuni metodi 
della classe base
–può avere versioni sovraccariche del costruttore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#39,39,"Programmazione orientata agli oggetti
Sommario
•Estensione di Interfacce
•Estensione di Classi (prima parte)
•La classe Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#4,4,"Programmazione orientata agli oggetti
Estensione di Interface (2)
•Esempio: data l'interface A
public interface A {
public void a1(int i);
public String a2();
}
•Supponiamo di dover definire l'interface B, che 
debba offrire gli stessi metodi di A, ed in più il 
metodo b1()"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#40,40,"Programmazione orientata agli oggetti
La Classe Object
•Tutte le classi estendono (direttamente od 
indirettamente) la classe Object
–si usa dire che Object è la radice della gerarchia dei 
tipi Java
•Object  è una classe predefinita, che viene 
automaticamente estesa da ogni nuova classe 
(direttamente o indirettamente)
•La classe Object  ha un insieme di metodi molto 
generici, ereditati e (volendo sovrascritti) da 
ogni nuova classe
–tra questi metodi ce ne sono alcuni già noti (ed altri che lo 
saranno presto)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#41,41,"Programmazione orientata agli oggetti
•Tutte le classi estendono automaticamente la 
classe Object
•E' una classe predefinita, che viene 
automaticamente ed implicitamente estesa da 
ogni nuova classe (direttamente o indirettamente)
✔Scrivere:
public class MiaClasse {
}
è del tutto equivalente a scrivere:
public class MiaClasse extends Object  {
}… extends Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#42,42,"Programmazione orientata agli oggetti
Classe Object : Alcuni Metodi
•Vedere documentazione javadoc
–String toString()
–boolean equals(Object o)
–…
•Di tutti questi metodi le nostre classi ereditano 
l’implementazione, oltre che la segnatura
•Le nostre classi possono ridefinirne 
l’implementazione (ma a tal fine devono  
rispettarne la segnatura)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#43,43,"Programmazione orientata agli oggetti
Metodo String toString()  (1)
•Questo è il motivo per il quale non è strettamente 
necessario definire il metodo toString()  dentro 
le classi di nostra definizione per poterlo usare
•Se non lo definiamo, verrà comunque ereditata la 
definizione del metodo toString()  propria della 
classe java.lang.Object
•Questa si preoccupa di stampare un messaggio 
testuale che dipende dall’indirizzo in memoria 
dell’oggetto sul quale viene invocato
•Di solito risulta poco esplicativo ed utile, e perciò 
conviene quasi sempre ridefinirlo sulla base delle 
specificità della classe definita"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#44,44,"Programmazione orientata agli oggetti
Metodo String toString()  (2)
public class Persona {
private String nome;
  …
public void setNome(String nome){
this.nome = nome;
}
public static void main(String[] args) {
Persona p = new Persona(""Paolo"");
System.out.println(p.toString());
  }
}
Stampa (qualcosa simile a): Persona@10b62c9
Il metodo toString()  viene ereditato da Object : 
vale l'implementazione di Object"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#45,45,"Programmazione orientata agli oggetti
Metodo String toString()  (3)
public class Persona {
private String nome;
…
public void setNome(String nome){
this.nome = nome;
}
   @Override
public String toString() {
return this.nome;
}
public static void main(String[] args) {
Persona p = new Persona();
p.setNome(""Antonio"");
System.out.println(p.toString());
  }
}Stampa : Antonio
Il metodo toString()  è stato sovrascritto: 
vale l'implementazione riscritta"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#46,46,"Programmazione orientata agli oggetti
Metodo boolean equals(Object o)
•Analogamente non è strettamente necessario 
definire il metodo equals()  dentro le classi di 
nostra definizione per poterlo usare
•Anche in questo caso, se non lo definiamo, verrà 
comunque ereditata la definizione del metodo 
equals()  propria della classe java.lang.Object
–questa confronta l’indirizzo in memoria dell’oggetto sul 
quale viene invocato con il riferimento passato come 
parametro (analogamente all’operatore  == )
–di solito non è questa la semantica desiderata
–definisce il criterio di equivalenza di oggetti distinti ma 
istanza della stessa classe (specie se le istanze saranno 
utilizzate dentro collezioni >>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#47,47,"Programmazione orientata agli oggetti
Metodo equals() & Testing
public class TestPersona {
@Test
public void testEquals() {
Persona p1 = new Persona(""Paolo"");
Persona p2 = new Persona(""Paolo"");
assertEquals(p1, p2);
  }
}
✔}Il metodo  equals()  viene ereditato da Object : 
✔ vale l'implementazione del metodo nella classe ObjectFALLISCE"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#48,48,"Programmazione orientata agli oggetti
Metodo equals() : Esempio
public class Persona {
private String nome;
…
public void setNome(String nome){
this.nome = nome;
}
  @Override // overrides toString() di java.lang.Object
public String toString() {
return this.nome;
}
  @Override // overrides equals(Object o) di java.lang.Object
public boolean equals(Object o) {
Persona that = (Persona)o; // ← (downcast)
return this.getNome().equals(that.getNome());
}
}
Il metodo equals(Object o)  è stato ridefinito: 
 il precedente test ora va a buon fine!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#49,49,"Programmazione orientata agli oggetti
Metodo equals() :
Downcast Necessario
•Attenzione alla segnatura 
boolean equals( Object o )
•L’argomento è di tipo Object !
•Per questo abbiamo dovuto fare un cast 
(tecnicamente un downcast:  abbiamo forzato il 
tipo statico al sottotipo atteso a tempo dinamico) 
Persona that = (Persona)o;
•Senza questo downcast non potremmo invocare i 
metodi propri della classe ( Persona nell'esempio) su 
cui si basa il confronto (l’uguaglianza degli oggetti 
String ottenute invocando getNome()  nell’es.)
N.B. A sua volta String ridefinisce equals() ... "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#5,5,"Programmazione orientata agli oggetti
Estensione di Interface (3)
•Potremmo definire la nuova interface in questo modo
public interface B {
public void a1(int i);
public String a2();
public int b1();
}
•Ma le due interface non avrebbero alcuna relazione 
esplicita (soprattutto, i tipi che definiscono non la 
possiedono affatto)
•Di conseguenza non potremmo referenziare con un 
oggetto B un riferimento ad A, anche se 
concettualmente sembrerebbe sensato
A a = new ClasseCheImplementa_A(); 
B b = new ClasseCheImplementa_B(); 
a=b; // ERRORE"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#50,50,"Programmazione orientata agli oggetti
Metodo equals() :
Un Errore Troppo Frequente (1)
•Un errore è quello di usare come parametro 
formale un riferimento ad un oggetto della classe 
sulla quale si sta ridefinendo il metodo
    boolean equals( Persona  persona) // ERRORE
•Questa non è una sovrascrittura  del metodo  
    boolean equals( Object persona)  
Utilizzare sempre  l'annotazione @Override per 
ribadire al compilatore che si sta eseguendo una 
sovrascrittura
segnalerà questo tipo di problemi già in fase di 
compilazione ed eviterà che si debba ricercarli sulla 
base degli effetti (non sempre evidenti) in fase di 
esecuzione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#51,51,"Programmazione orientata agli oggetti
Metodo equals() :
Un Errore Troppo Frequente (2)
public class Persona {
private String nome;
…
public void setNome(String nome){
this.nome = nome;
}
public String toString() {
return this.nome;
}
   
public boolean equals( Persona that) {
return this.getNome().equals(that.getNome());
}
}
public class TestPersona {
@Test
public void testEquals() {
Persona p1 = new Persona(""Paolo"");
Persona p2 = new Persona(""Paolo"");
assertEquals(p1, p2);
  }
}FALLISCE
perché viene invocato il metodo 
equals(Object  o): non essendo 
stato sovrascritto  per l’errata 
segnatura, viene invece usato quello 
ereditato da Object che confronta 
gli indirizzi in memoria degli 
oggetti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#52,52,"Programmazione orientata agli oggetti
Conclusioni
•Molti altri dettagli nell’estensione di classi 
meritano nuovamente uno spazio dedicato più 
avanti nel corso
•E’ tuttavia utile capire già ora come tutte le nostre 
classi estendono e sono sottotipi di 
java.lang.Object , la radice della gerarchia dei 
tipi in Java, dal quale ereditano alcuni metodi di 
pubblica e generale utilità come
•String toString()
•boolean equals(Object o)
✔Questi metodi vengono frequentemente 
sovrascritti nelle nostre classi per adattarli alle 
loro peculiarità"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#6,6,"Programmazione orientata agli oggetti
Estensione di Interface (4)
•Sarebbe utile e sensato riuscire a specificare che 
B è un sottotipo di A
•In Java (e analogamente in altri linguaggi) questo 
è possibile definendo una interface come una 
estensione di un'altra interface
•Relativamente al nostro esempio possiamo 
scrivere
public interface B extends A  {
public int b1();
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#7,7,"Programmazione orientata agli oggetti
Estensione di Interface (5)
•In questo modo stiamo definendo una nuova 
interface ( B) a partire da una già esistente ( A)
•In particolare stiamo dicendo che:
–B è un sottotipo di A
–B offre tutti i metodi di A più il metodo b1()  
•Quindi vale il principio di sostituzione
•In questo caso le istruzioni:
A a = new ClasseCheImplementa_A(); 
B b = new ClasseCheImplementa_B(); 
a = b; // OK B è un sottotipo di A
sono corrette"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#8,8,"Programmazione orientata agli oggetti
Estensione di Interface: 
Corrette Motivazioni
•L'estensione di interfacce non è una 
scorciatoria per non ripetere la scrittura di 
metodi
•E' invece un sofisticato meccanismo per 
definire sottotipi con effetti importanti sulla 
modellazione del dominio (vedi corso APS >>)
•Usare correttamente l'estensione delle 
interface richiede esperienza
–Il legame tra le due interface (tipo/sottotipo) è forte 
e deve essere ben giustificato dal dominio"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-12-polimorfismo-interface-estensione-object.pdf#9,9,"Programmazione orientata agli oggetti
Utilizzo dell’Estensione di Interface
•In questo corso non arriveremo praticamente 
mai a far utilizzo dell'estensione delle interface 
già in fase di progettazione
•Però dobbiamo essere in grado di capirne la 
semantica, perché useremo  spesso e volentieri 
molte interface definite per estensione di altre
–Sono infatti frequentemente utilizzate in alcune 
delle API di Java approfondite in seguito, come ad 
es. nelle collezioni>>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Estensione (Seconda Parte)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#1,1,"Programmazione orientata agli oggetti
Esercizio
public class C {
  public void dim(C c) {
System.out.println(""C.dim(C) "");
  }
  public void dim(L l) {
System.out.println(""C.dim(L) "");
  }
  public void dim(K k) {
System.out.println(""C.dim(K) "");
  }
}
public class K extends C {
  public void dim(C c) {
System.out.println(""K.dim(C) "");
  }
  public void dim(L l) {
System.out.println(""K.dim(L) "");
  }
  public void dim(K k) {
System.out.println(""K.dim(K) "");
  }
}public class L extends C {
  public void dim(C c) {
   System.out.println(""L.dim(C) "");
  }
  
  public void dim(L l) {
   System.out.println(""L.dim(L) "");
  }
  public void dim(K k) {
   System.out.println(""L.dim(K) "");
  }
  public static void main(String args[]) {
      C a = new K();
      C b = new L();
      a.dim(b);
      L a1 = new L();
      a1.dim(a);
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#10,10,"Programmazione orientata agli oggetti
Overriding
•Alcuni metodi della classe base possono 
essere ridefiniti  (sovrascritti) nella classe 
estesa
•Per modificare il comportamento 
(l'implementazione) di un metodo si effettua 
un overriding   ( sovrascrittura ) del metodo
•Nel nostro esempio:
   @Override
   public boolean addAttrezzo(Attrezzo attrezzo)
11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#11,11,"Programmazione orientata agli oggetti
Overriding (Tentativo 1)
  class StanzaMagica extends Stanza {
      private int contatoreAttrezziPosati;
      private int sogliaMagica;
…
      @Override
      public boolean addAttrezzo(Attrezzo attrezzo) {
         this.contatoreAttrezziPosati++;
         if (this.contatoreAttrezziPosati>this.sogliaMagica) 
            attrezzo = this.modificaAttrezzo(attrezzo);
         if (this.numeroAttrezzi <this.attrezzi .length) {   
            this.attrezzi[this.numeroAttrezzi] = attrezzo;
            this.numeroAttrezzi++;
            return true;
  }
  else return false;
      }
      private Attrezzo modificaAttrezzo(Attrezzo attrezzo) {
         …
      }
  }le variabili attrezzi e  
numeroAttrezzi  sono ereditate dalla 
classe base ma non sono accessibili (in 
quanto private)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#12,12,"Programmazione orientata agli oggetti
Estensione: Overriding
•La soluzione precedente non compila: i metodi della 
classe estesa StanzaMagica  non possono accedere ai 
campi privati della classe base Stanza 
–N.B. anche se ogni oggetto StanzaMagica  
implicitamente possiede le variabili di istanza per 
rappresentare gli attrezzi contenuti nella stanza
•La classe estesa può  accedere solo ai membri 
pubblici della classe base come tutte le altre classi 
esterne
✔Coerentemente con il principio dell’ information hiding
•Nel nostro caso possiamo però pensare di limitarci a 
riutilizzare il metodo pubblico reso disponibile dalla 
superclasse Stanza:  
boolean addAttrezzo(Attrezzo attrezzo)  
13"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#13,13,"Programmazione orientata agli oggetti
Overriding (Tentativo 2)
 
 class StanzaMagica extends Stanza {
    private int contatoreAttrezziPosati;
    private int sogliaMagica;
… 
    @Override
    public boolean addAttrezzo(Attrezzo attrezzo) {
       this.contatoreAttrezziPosati++;
       if (this.contatoreAttrezziPosati > this.sogliaMagica) 
          attrezzo = this.modificaAttrezzo(attrezzo);
       return this.addAttrezzo( attrezzo);
    }
    private Attrezzo modificaAttrezzo(Attrezzo attrezzo) {
 …
    }
}  NON FUNZIONA: viene chiamato 
  ricorsivamente (all'infinito) il metodo  
  addAttrezzo(Attrezzo attrezzo)   !"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#14,14,"Programmazione orientata agli oggetti
Overriding (Tentativo 2)
•La soluzione precedente non funziona perché il 
metodo addAttrezzo(Attrezzo attrezzo)  chiama 
se stesso!
–java.lang.StackOverflowError
✔come implicato dal late-binding: per l’esecuzione si usa 
l’implementazione del tipo dinamico, ovvero il corpo 
dello stesso metodo che si sta definendo
•E' necessario indicare che vogliamo usare il 
metodo della superclasse
•Questo è reso possibile usando nuovamente la 
parola chiave super
✔ma con un nuovo significato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#15,15,"Programmazione orientata agli oggetti
Estensione: Overriding
 class StanzaMagica extends Stanza {
    private int contatoreAttrezzi Posati;
    private int sogliaMagica;
…
    @Override
    public boolean addAttrezzo(Attrezzo attrezzo) {
       this.contatoreAttrezziPosati++;
       if (this.contatoreAttrezziPosati>this.sogliaMagica) 
          attrezzo = this.modificaAttrezzo(attrezzo);
       return super.addAttrezzo(attrezzo);
    }
    private Attrezzo modificaAttrezzo(Attrezzo attrezzo) {
        …
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#16,16,"Programmazione orientata agli oggetti
Esercizio
•Scrivere una classe di test 
StanzaMagicaTest per testare la classe 
StanzaMagica che preveda anche test-
case per verificarne il comportamento 
“magico”
•Implementare StanzaMagica  usando 
l'ereditarietà secondo le linee guida 
discusse in queste dispense
17"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#17,17,"Programmazione orientata agli oggetti
Visibilità protected (1)
•I membri private  della classe base non sono 
accessibili dall'esterno nemmeno da una 
sottoclasse
•In Java esiste un altro modificatore di accesso, 
che consente di definire campi a cui sia 
consentito l’accesso da sottoclassi
–È il modificatore di accesso protected
•Un membro di una superclasse con accesso 
protetto è visibile a tutte le sottoclassi
✔Indipendentemente dal package di 
appartenenza
18"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#18,18,"Programmazione orientata agli oggetti
Visibilità protected (2)
class Stanza {
    private String descrizione;
    protected  Attrezzo[] attrezzi;
    protected  numeroAttrezzi;  
…
}
•In questo modo, qualsiasi classe che estenda 
Stanza può accedere alle sue variabili di istanza 
attrezzi  e numeroAttrezzi
•Si rende possibile una definizione alternativa del 
metodo addAttrezzo(Attrezzo attrezzo)  di 
StanzaMagica , con accesso diretto ai campi 
ereditati da Stanza
19"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#19,19,"Programmazione orientata agli oggetti
Accesso ai Membri dalla Classe Estesa
 class StanzaMagica extends Stanza {
    private int contatoreAttrezziPosati;
    private int numeroPassaggi;
…
    @Override
    public boolean addAttrezzo(Attrezzo attrezzo) {
       this.contatoreAttrezziPosati++;
       if (this.contatoreAttrezziPosati > this.sogliaMagica) 
          attrezzo = this.modificaAttrezzo(attrezzo);
       if (this.numeroAttrezzi <this.attrezzi .length) {   
          this.attrezzi[this.numeroAttrezzi] = attrezzo;
          this.nomeroAttrezzi++;
          return true;
}
else return false;
    }
  …
}
20La classe estesa StanzaMagica ha la possibilità  di 
accedere ai membri protetti  (attrezzi e numeroAttrezzi )
della classe base Stanza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#2,2,"Programmazione orientata agli oggetti
Sommario
•Estensione nel caso di studio
•Chiamate a metodi della superclasse
•Accesso protetto ai membri
•Overriding di metodi 
•Ancora sull'ereditarietà multipla
•La gerarchia dei tipi
•Considerazioni finali sui tipi
•Esercizio: Overriding for Overloading"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#20,20,"Programmazione orientata agli oggetti
Visibilità protected (3)
•Più precisamente, è possibile accedere ad un 
membro protected :
–da tutte le classi estese
–da tutte le classi dello stesso package!
•I membri protetti sono una violazione (seppur 
controllata e voluta) dell'information hiding
–vanno pertanto usati con molta accortezza
–se possibile, meglio evitare il loro utilizzo
•L’utilizzo più appropriato è nella progettazione di 
framework, ovvero librerie che consentano 
agevolmente l’estensione da parte di sviluppatori 
esperti
… ben oltre i nostri obiettivi formativi
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#21,21,"Programmazione orientata agli oggetti
Livelli di visibilità in Java
scontato. comprensibile... da ricordare!
–Il livello di visibilità ottenuto senza modificatore viene anche 
denominato «package-private»
–Il livello di visibilità «protected » è più permissivo del livello 
«package-private» ed è il livello più permissivo in assoluto dopo 
«public»
–Il livello di visibilità «package-private» è il meno permessivo in 
assoluto dopo «private»
22"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#22,22,"Programmazione orientata agli oggetti
Esercizio
•Reimplementare StanzaMagica  anche utilizzando 
l'estensione tra classi, impostando il modificatore 
di accesso delle variabili attrezzi  e 
numeroAttrezzi della classe base Stanza  a 
protected  (anziché  private )
•Le successive evoluzioni del nostro studio di caso 
saranno un’occasione per vedere quali problemi 
la violazione dell'information hiding può 
comportare durante la manutenzione del codice…
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#23,23,"Programmazione orientata agli oggetti
•Solo i metodi pubblici e protetti della classe base 
possono essere sovrascritti
•Se proviamo a ridefinire un metodo private della 
classe base quello che otteniamo è un nuovo metodo 
–N.B. il nuovo metodo «nasconde» l’omonimo metodo 
offerto nella superclasse ma non lo sovrascrive affatto
•In generale è possibile sovrascrivere un metodo e 
cambiare il modificatore di accesso, ma solo 
mantenendo od ampliandone  la visibilità
–Perche? Sugg.: pensare al principio di sostituzione
•Quindi per sovrascrivere un metodo, i livelli di visibi-
lità permessi sono:
–sovrascritto  → sovrascrivente  
–protected → protected
–protected → public
–public → public24Overriding ed Information Hiding"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#24,24,"Programmazione orientata agli oggetti
•Pertanto il seguente codice è corretto:
public class Superclasse {
protected void metodo() {}
}
public class Sottoclasse extends Superclasse {
@Override
public void metodo() {}   // da protected  a public OK
}
•mentre  invece il seguente non compila:
public class Superclasse {
public void metodo() {}
}
public class Sottoclasse extends Superclasse {
@Override
protected void metodo() {}   // da public a protected  ERRORE
}25Visibilità dei Metodi Sovrascritti"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#25,25,"Programmazione orientata agli oggetti
Cambiare Segnatura in Override
•Permettere di sovrascrivere un metodo solo 
mantenendone od ampliandone  la visibilità, è la scelta 
più sensata? 
✔Rispondere applicando il p.d.s.: 
–un metodo che sovrascrive e rimpiazza un altro metodo 
deve certamente permettere tutti gli utilizzi originali
–Al più, può consentirne anche di nuovi
✔Ampliare la visibilità è coerente con il p.d.s.!
•Finora abbiamo solo visto casi di metodi sovrascritti con 
ampliamento della visibilità, ma della stessa identica segnatura. 
Ad es. in Stanza e StanzaMagica :
public boolean void addAttrezzo(Attrezzo a) ;
•Applichiamo lo stesso ragionamento per capire se ha senso 
cambiare il tipo restituito e/o quello dei parametri dei metodi 
sovrascritti
26"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#26,26,"Programmazione orientata agli oggetti
  
•Consideriamo questi due metodi
–public Studente immatricola()
–public Persona immatricola ()
con Persona  supertipo di Studente
•Quale di questi due metodi in una classe estesa può 
sovrascrivere l’altro collocato nella classe base? 
Perché?
–Sugg.: applicare il principio di sostituzione che deve 
restare valido
✔Scriviamo due classi Organizzazione  ed Universita,  
con la classe Universita  che estende la classe 
Organizzazione ...Overriding: Metodi di Risultato Polimorfo (1)
27"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#27,27,"Programmazione orientata agli oggetti
public class Persona {
}
public class Studente extends Persona {
  public String getMatricola() {…} 
}
public class Organizzazione {
    public Studente immatricola() {
      return new Studente();
    }
}
public class Universita extends Organizzazione {
    @Override
    public Persona immatricola() {
      return new Persona();
    }
}Overriding: Metodi di Risultato Polimorfo (2)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#28,28,"Programmazione orientata agli oggetti
Overriding: Metodi di Risultato Polimorfo (3)
public class Persona { 
}
public class Studente extends Persona {…
  public String getMatricola() {…} 
}
public class Organizzazione {
    public Persona immatricola() {
      return new Persona()
    }
}
public class Universita extends Organizzazione {
    @Override
    public Studente immatricola() {
      return new Studente();
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#29,29,"Programmazione orientata agli oggetti
Overriding: 
Metodi con Parametri Polimorfi (1)
30•Consideriamo questi due metodi
–public void immatricola(Studente s)
–public void immatricola (Persona p)
con Persona  supertipo di Studente
•Quale di questi due metodi in una classe derivata 
può sovrascrivere l’altro collocato nella classe 
base e… perché?
✔Scriviamo due classi Organizzazione  ed 
Universita , con la classe Universita  che 
estende la classe Organizzazione ..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#3,3,"Programmazione orientata agli oggetti
Introduzione
•Riprendiamo lo studio di caso diadia
–supponiamo di voler inserire nel labirinto delle 
stanze particolari, stanze ""magiche"", il cui 
comportamento differisce da quello usuale
•Una stanza magica, esattamente come la 
stanza ordinaria, ha una descrizione, possiede 
una collezione di uscite, e può ospitare una 
collezione di attrezzi
4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#30,30,"Programmazione orientata agli oggetti
Overriding: 
Metodi con Parametri Polimorfi (2)
public class Persona { 
}
public class Studente extends Persona { 
}
public class Organizzazione {
    public void immatricola( Persona p) {
      // ...
    }
}
public class Universita extends Organizzazione {
    @Override
    public void immatricola( Studente s) {
      // ...
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#31,31,"Programmazione orientata agli oggetti
Overriding: 
Metodi con Parametri Polimorfi (3)
public class Persona { 
}
public class Studente extends Persona { 
}
public class Organizzazione {
    public void immatricola( Studente s) {
      // ...
    }
}
public class Universita extends Organizzazione {
    @Override
    public void immatricola( Persona p) {
      // ...
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#32,32,"Programmazione orientata agli oggetti
Overriding: 
Metodi con Parametri Polimorfi (4)
public class Persona { 
}
public class Studente extends Persona { 
}
public class Organizzazione {
    public void immatricola( Studente s) {
       System.out.println(""Organizzazione.immatricola(Studente)"" );
    }
}
public class Universita extends Organizzazione {
    
    public void immatricola( Persona p) {
       System.out.println(""Universita.immatricola(Persona)"" );
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#33,33,"Programmazione orientata agli oggetti
Un Overriding che Diventa Overloading
static public void main(String args[]) {
  Persona p = new Persona();
  Persona ps = new Studente();
  Studente s = new Studente();
  Organizzazione org = new Organizzazione();
  Organizzazione studi = new Universita();
  Universita rm3 = new Universita();
//org.immatricola(p);   // ERRORE: NON COMPILA
//org.immatricola(ps);  // ERRORE: NON COMPILA
  org.immatricola(s);
//studi.immatricola(p) ; // ERRORE: NON COMPILA
//studi.immatricola(ps); // ERRORE: NON COMPILA
  studi.immatricola( s);
  rm3.immatricola( p);
  rm3.immatricola(ps);
  rm3.immatricola( s);
}L’esecuzione stampa:
Organizzazione.immatricola(Studente)
Organizzazione.immatricola(Studente)
Universita.immatricola(Persona)
Universita.immatricola(Persona)
Organizzazione.immatricola(Studente)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#34,34,"Programmazione orientata agli oggetti
Studente
Persona
Riassunto: 
Covarianza & Controvarianza
Organizzazione
Università
protected Persona immatricola(Studente)
public Studente immatricola(Persona)
covarianza controvarianzaSpecializzando ↑ il tipo che ospita un metodo, 
affinché si possa sovrascrivere:
visibilità↓ – tipo restituito ↑ – tipo parametro ↓@Override
tipo + generale
tipo + speciale"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#35,35,"Programmazione orientata agli oggetti
La Gerarchia delle Classi Java:
La Classe Object
•Abbiamo già visto che in Java tutte le classi 
estendono automaticamente la classe Object
•E' una classe predefinita, che viene 
automaticamente estesa da ogni nuova classe 
(direttamente o indirettamente)
•N.B. scrivere:
public class MiaClasse {
}
è del tutto equivalente a scrivere:
public class MiaClasse extends Object  {
}
36"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#36,36,"Programmazione orientata agli oggetti
Gerarchie di Classi
•In Java una classe può essere estesa da molte 
classi, ma ogni classe estende sempre una ed 
una sola  classe
–tranne Object , che è la radice predefinita della 
gerarchia di classi
•Non ci può essere «ereditarietà multipla»  delle 
implementazioni 
37"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#37,37,"Programmazione orientata agli oggetti
La Gerarchia delle Classi Java
•Un'unica radice: Object
•Ogni classe* ha una e una sola superclasse
•Ogni classe può avere zero o più sottoclassi 
38* con l'eccezione di ObjectClasse1 Classe2
Classe3 Classe4Object
Classe5"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#38,38,"Programmazione orientata agli oggetti
Ereditarietà Multipla non Ammessa
•Se Classe4  ereditasse sia da Classe1  
che da Classe2
N.B. In Java non è possibile!
•Quali problemi?
39Classe1 Classe2
Classe3 Classe4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#39,39,"Programmazione orientata agli oggetti
Problemi con l'Ereditarietà Multipla: 
l'Ereditarietà a Diamante
40Classe1 Classe2
Classe4Classe0"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#4,4,"Programmazione orientata agli oggetti
La Stanza Magica (1)
•Una stanza magica ha delle particolarità, che la 
rendono diversa dalla stanza ordinaria:
–dopo N volte che in tale stanza viene posato (aggiunto) 
un qualsiasi attrezzo da parte del giocatore, la stanza 
inizierà a comportarsi «magicamente»
–quando la stanza si comporta magicamente, ogni volta 
che posiamo un attrezzo, la stanza ""inverte"" il nome 
dell'attrezzo e ne raddoppia il peso. Ad esempio: se 
posiamo (togliamo dalla borsa e aggiungiamo alla 
stanza) l'attrezzo con nome ' chiave' e peso 2, la stanza 
memorizza un attrezzo con nome ' evaihc' e peso 4
–quando la stanza non si comporta magicamente, il 
comportamento rimane quello usuale
5"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#40,40,"Programmazione orientata agli oggetti
La gerarchia del Frogosauro
class Animal {
   void talk() {
      System.out.println(""…"");
}
class Frog extends Animal {
   void talk() {
      System.out.println(""Ribit, ribit."");
   }
}
class Dinosaur extends Animal {
   void talk() {
      System.out.println(""I'm a dinosaur: I'm cool! "");
   }
}
41Dinosaur Frog
FrogosaurAnimal"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#41,41,"Programmazione orientata agli oggetti
Il Frogosauso
// NON COMPILA
class Frogosaur extends Frog, Dinosaur {
} 
✔ Cosa dovrebbe fare la seguente chiamata a 
talk() ?
Animal animal = new Frogosaur();
animal.talk();
42"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#42,42,"Programmazione orientata agli oggetti
Problemi di Ereditarietà Multipla (1)
•Se un membro (metodo o campo) è definito in 
entrambe le classi base, da quale delle due la classe 
estesa «eredita» l’implementazione?
•E se le due classi base a loro volta estendono una 
superclasse comune ?
•Il problema è legato alle implementazioni, che 
vengono ereditate e potenzialmente «confuse»
✔Per questo motivo, in Java si adotta una scelta molto 
conservativa:
–una classe può implementare tante interfacce
–ma può estendere sempre e solo una unica superclasse
43"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#43,43,"Programmazione orientata agli oggetti
Problemi di Ereditarietà Multipla (2)
•In realtà il problema di quale implementazione 
scegliere, anche in questi casi, è perfettametne 
risolvibile e risolto in alcuni linguaggi di 
programmazione
–(C++, Scala, in una forma molto limitata anche Java 8+)
•Il Problema del Frogosauro  fa quasi parte del folklore 
oramai, quasi impossibile non parlarne!
✔Ma solo lascamente chiarisce il vero problema:
–“mischiare” due implementazioni diverse è estremamente 
complicato e quasi sempre non necessario
–comodo in pochi e particolari casi (implementazioni che sono 
sostanzialmente ortogonali: per i più interessati vedere 
mixin’) ben oltre gli obiettivi formativi di questo corso
✔Rapporto  costi benefici opinabile44"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#44,44,"Programmazione orientata agli oggetti
Implementazione di più Interfacce
●Al contrario in Java è possibile che una classe 
implementi molteplici interface, una politica molto 
permissiva:
public interface Persona {
  …
}
public class Dirigente  implements Impiegato, Persona  {
  …
}
✔ Una classe già ampiamente utilizzata implementa tre 
interfacce: java.lang.String
public final class String implements 
       Serializable, Comparable<String>, CharSequence
public final class String
   extends Object
   implements Serializable, 
              Comparable<String>, 
              CharSequence45"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#45,45,"Programmazione orientata agli oggetti
Java Interface ed 
Ereditarietà Multipla (1)
•Il problema dell'ereditarietà multipla (delle 
implementazioni) non sussiste affatto con le 
interface
•Consideriamo infatti una classe che 
implementa più di una interface
•Per essere concreta e risultare instanziabile:
–è costretta a fornire direttamente tutte le 
implementazioni di tutti metodi implementati
✔si evitano così alla radice tutti i problemi legati 
all’eredità multipla delle implementazioni
46"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#46,46,"Programmazione orientata agli oggetti
Java Interface ed 
Ereditarietà Multipla (2)
•Abbiamo anche visto che una interface può 
essere definita per estensione da un'altra 
interface
•In generale una interface può estendere anche 
più di una interface scrivendo direttamente:
public interface A {}
public interface B {}
public interface C {}
public interface I extends A,B,C {}
•Pertanto la gerarchia dei tipi è più articolata di 
quella delle classi in quanto contempla anche i 
tipi definiti tramite le interface...
47"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#47,47,"Programmazione orientata agli oggetti
La Gerarchia dei Tipi Java
✔Un'unica radice: Object
•Ogni classe* ha una ed una sola superclasse
•Ogni classe può avere zero o più sottoclassi
•Ogni classe può implementare zero o più interface
•Ogni interface può estendere zero o più interface 
Classe1 Classe2
Classe3 Classe4Object
Classe5
* con l'eccezione di ObjectInterface2 Interface1
Interface3
48"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#48,48,"Programmazione orientata agli oggetti
Gerarchia delle Classi Lineare
•Ogni classe estende sempre una ed una sola 
classe
•Tranne Object , che è la radice predefinita della 
gerarchia di classi (e tipi)
•Ma una classe può essere estesa da molte classi
•Non ci può essere ereditarietà multipla delle 
implementazioni
•Si usa dire che la gerarchia delle classi è lineare
le implementazioni di tutti i metodi di una classe si trovano 
in una  sequenza lineare di classi e superclassi che 
conducono sino alla radice Object
Attenzione: non più perfettamente vero in Java 8+
•metodi di interface con implementazioni di default
49"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#49,49,"Programmazione orientata agli oggetti
L’importanza dei Tipi (1)
•La scelta dei corretti tipi da definire in un programma 
è un delicato esercizio di modellazione 
•Si può affrontare a ragion veduta solo dopo studio, 
pratica ed interi corsi specificatamente dedicati alla
Analisi & Progettazione  (come APS)
•E’ opportuno cercare subito di prevenire alcuni degli 
errori più ricorrenti nei primi utilizzi dei meccanismi di 
definizione dei tipi 
–Non considerare gli aspetti dinamici 
(il comportamento degli oggetti)
–Ovvero considerare solo gli aspetti statici
( dati che modellano)50"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#5,5,"Programmazione orientata agli oggetti
La Stanza Magica (2)
•Vogliamo introdurre questa variante  nel nostro gioco
•Una stanza magica deve poter essere usata in 
qualsiasi punto in cui usiamo oggetti Stanza
•La classe della stanza magica pur essendo molto 
simile a quella della stanza ordinaria, differisce per:
–alcuni dati in più da gestire
–alcuni metodi in più che può offrire
–il comportamento di un metodo
✔Possiamo usare l'estensione e sfruttare il polimorfismo 
per introdurre questa caratteristica nel gioco
6"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#50,50,"Programmazione orientata agli oggetti
L’importanza dei Tipi (2)
•Su altri errori tipici dovuti alla mancanza di pratica 
meglio tornarci in seguito (>>)
•Tra i più rilevanti la tipizzazione anemica
–possono scherzosamente chiamarsi sulla base del 
nome di un tipo di cui si ha un’irrefrenabile 
tendenza ad abusare, quasi fosse una «malattia »
•La «stringhite » (>>)
•La «mappite » (>>)
•Sono «sintomi» dell’incapacità di scegliere 
correttamente i tipi da definire
51"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#51,51,"Programmazione orientata agli oggetti
Considerazioni Finali:
Tipi e Sottotipi
•Un frequente errore è sicuramente legato alla tendenza a 
fissare le relazioni tra tipi concentrandosi solo sugli aspetti 
statici delle classi e trascurando invece quelli dinamici
•Domanda : Ma... Quadrato  è sottotipo di Rettangolo ?
Farsi sempre guidare dal principio di sostituzione:  ogni 
qualvolta mi aspetto un Rettangolo  posso utilizzare al suo 
posto un Quadrato ?
•Risposta : dipende!   Se devo calcolarne il perimetro si, ma 
se devo raddoppiarne l’altezza senza cambiarne la base 
sicuramente no!
Il p.d.s. deve valere anche a tempo dinamico, anche dopo i 
cambiamenti di stato degli oggetti coinvolti
52"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#52,52,"Programmazione orientata agli oggetti
Tipi e Sottotipi: 
String  vs StringBuilder  (1)
●Altro esempio; cfr.  String  vs StringBuilder :
• String si usa per oggetti immutabili:
–Una volta creato un oggetto java.lang.String , non è poi più 
possibile cambiarne lo stato
✔(E’ tuttavia possibile creare nuovi oggetti stringhe sulla base del 
primo)
●Per costruire progressivamente stringhe particolarmente lunghe, 
è spesso preferibile utilizzare la versione modificabile delle 
stringhe: classe java.lang.StringBuilder
●StringBuilder  si usa per oggetti mutabili:
 public final class StringBuilder …???… {
    StringBuilder append(String str);
    …
    String toString();
}
●StringBuilder  deve essere sottotipo di String ???
53"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#53,53,"Programmazione orientata agli oggetti
Tipi e Sottotipi: 
String  vs StringBuilder  (2)
✔Cfr.  String/StringBuilder/CharSequence :
public final class String extends Object 
  implements
  Serializable,Comparable<String>, CharSequence {…}
public final class StringBuilder  extends Object
implements Serializable, CharSequence  {…}
public interface CharSequence {
   public char charAt(int index);
   public int length();
   public CharSequence subSequence(int start, int end);
   public String toString();
}
StringBuilder NON è un sottotipo (né potrebbe esserlo) 
di String ma di un loro supertipo comune CharSequence ; 
si prevede esplicitamente la convertibilità degli oggetti 
StringBuilder a String tramite toString()
54"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#54,54,"Programmazione orientata agli oggetti
Esercizio: 
Overriding for Overloading  (1)
•Rafforziamo  la comprensione del legame tra 
l’overloading e l’overriding in Java svolgendo un 
particolare esercizio
•Vogliamo invocare un metodo sovraccarico proprio 
sulla base del tipo dinamico del suo parametro e 
NON sulla base del suo tipo statico
•N.B. NON è possibile farlo con i meccanismi offerti 
direttamente dal linguaggio Java
–In Java i metodi sovraccarichi sono risolti sulla base del tipo 
STATICO e mai sulla base del tipo DINAMICO!
•Mostriamo come mediante l’overriding di un metodo 
polimorfo ed il late-binding sia possibile «simulare» la 
risoluzione di un metodo sovraccarico sulla base del 
tipo dinamico di un parametro
55"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#55,55,"Programmazione orientata agli oggetti
Esercizio: 
Overriding for Overloading  (2)
•Consideriamo un semplice esempio: è data una 
gerarchia di tipi avente come radice l’interface 
Forma e sottotipi concreti Quadrato , Cerchio ,…  
ma non è possibile cambiarne il codice
✔Per quanto l’esempio sia volutamente stilizzato, nella 
pratica questa situazione si presenta non di rado
•ad es. durante l’uso di gerarchie di tipi definite da 
librerie esterne il cui codice risulta immodificabile
•ad es. quelle che gestiscono composizioni  di oggetti tutti 
di uno stesso supertipo comune ma di diversi sottotipi 
concreti
56"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#56,56,"Programmazione orientata agli oggetti
Esempio: Una Gerarchia di Tipi
(Sorgente Non Modificabile)
public interface Forma {
}
public class Cerchio implements  Forma {
  private int raggio;
  public Cerchio(int r)  { this.raggio = r;    }
  public int getRaggio() { return this.raggio; } 
}
public class Quadrato implements  Forma {
  private int lato;
  public Quadrato( int l) { this.lato = l;    }
  public int getLato()   { return this.lato; }
}
•Si vuole calcolare l’area delle forme, che dipende dal tipo, ma NON 
è possibile modificare l’interface Forma per aggiungere il metodo
  public float getArea();
e quindi non è possibile implementarlo in Quadrato , Cerchio,  …
57"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#57,57,"Programmazione orientata agli oggetti
Risoluzione Tramite Overriding (1)
public class CalcolatoreDiArea {
    public float areaDi(Cerchio c) {
       int r = c.getRaggio();
       return 3.14f * r * r;
    }
    public float areaDi(Quadrato q ) {
       int l = q.getLato();
       return l * l;
    }
    public static void main(String args) {
      CalcolatoreDiArea calcolatore = new CalcolatoreDiArea();
      Cerchio cerchio = new Cerchio(1);
      Quadrato quadrato = new Quadrato(2);
      System.out.println(calcolatore.areaDi(cerchio));          
      System.out.println(calcolatore.areaDi(quadrato)); 
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#58,58,"Programmazione orientata agli oggetti
Risoluzione Tramite Overriding (2)
public class CalcolatoreDiArea {
   public float areaDi(Cerchio c) {
       int r = c.getRaggio();
       return 3.14f * r * r;
   }
   public float areaDi(Quadrato q) {
       int l = q.getLato();
       return l * l;
   }
   public static void main(String args) {
      CalcolatoreDiArea calcolatore = new CalcolatoreDiArea();
      Forma cerchio = new Cerchio(1);
      Forma quadrato = new Quadrato(2);
      System.out.println(calcolatore.areaDi(cerchio)); // ERRORE: NON COMPILA
      System.out.println(calcolatore.areaDi(quadrato)); // ERRORE: NON COMPILA
   }
}
•Si supponga invece di voler calcolare l’area totale di una 
collezione di forme di cui non sia possibile prevedere il tipo a 
tempo dinamico…"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#59,59,"Programmazione orientata agli oggetti
Risoluzione Tramite Overriding (3)
public class CalcolatoreDiArea {
   public float areaDi(Cerchio c) {
       int r = c.getRaggio();
       return 3.14f * r * r;
   }
   public float areaDi(Quadrato q) {
       int l = q.getLato();
       return l * l;
   }
   static public float sommaAll(CalcolatoreDiArea calcolatore, Forma[] forme) {
       float acc = 0;
       for(Forma forma : forme) {
          acc += calcolatore.areaDi( forma); // ERRORE: NON COMPILA
       }
       return acc;
   }
   public static void main(String args) {
      CalcolatoreDiArea calcolatore = new CalcolatoreDiArea();
      Forma[] forme = { new Cerchio(1), new Quadrato(2) } ;
      System.out.println( sommaAll(calcolatore, forme));      
   }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#6,6,"Programmazione orientata agli oggetti
Definizione di Classe Estesa (1)
•La classe StanzaMagica  rispetto alla classe Stanza 
–possiede nuove variabili: 
–contatoreAttrezziPosati: memorizza il numero di attrezzi 
posati (aggiunti)
–sogliaMagica : memorizza il numero di attrezzi da posare prima 
che si attivi il comportamento «magico» della stanza
–SOGLIA_MAGICA_DEFAULT:  valore di default per la soglia  
–possiede un nuovo metodo privato
private Attrezzo modificaAttrezzo(Attrezzo attrezzo)  che 
restituisce un attrezzo a partire dall'attrezzo passato come 
parametro
–ridefinisce il metodo addAttrezzo(Attrezzo attrezzo)  per 
implementare l'effetto magico
–ha due costruttori: uno prende nome e soglia, l'altro solo il nome (e 
imposta la soglia al valore di default)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#60,60,"Programmazione orientata agli oggetti
Overriding for Overloading  (1)
●Una libreria che pubblica una gerarchia di tipi (con sorgente 
immodificabile) può essere predisposta per la definizione di codice 
cliente che sappia specializzare i propri comportamenti sulla base del 
tipo dinamico
●L’interface Forma  viene cambiata per ospitare un metodo che 
permetta a tutti i tipi di forme di «accettare»  un generico 
Calcolatore:
public interface  Forma { 
public float  accetta(Calcolatore c);
}
●Questo deve saper distinguere tutti i tipi di forme della gerarchia 
public interface  Calcolatore {
    public float calcola(Cerchio c);
    public float calcola(Quadrato q);
}  
✔Parliamo di «generici» calcoli; il calcolo dell’area è solo un 
esempio di uno dei loro possibili «instanziamenti »..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#61,61,"Programmazione orientata agli oggetti
Overriding for Overloading  (2)
●Il metodo calcola()  trova questa implementazione nei sottotipi 
concreti Cerchio e Quadrato :
public class Cerchio    // lo stesso dicasi per Quadrato
       implements Forma {
   @Override
   public float accetta(Calcolatore c) { // N.B. il tipo statico
           //  di this è quello della classe corrente, qui Cerchio
      return c.calcola( this); // tipo statico  Cerchio
   }
}
✔La chiamata al metodo polimorfo float accetta(Calcolatore)   
di Forma come sovrascritto (overload) in Cerchio finisce per 
servire a fissare il tipo statico dell’argomento alla chiamata al 
metodo sovraccarico (override) Calcolatore.calcola(Cerchio) !
✔In Quadrato  servirà per chiamare l’altro metodo sovraccarico 
Calcolatore.calcola(Quadrato)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#62,62,"Programmazione orientata agli oggetti
Overriding for Overloading  (3)
public interface Forma {
  public float accetta(Calcolatore c);
}
public class Cerchio implements Forma {…
  @Override
  public float accetta(Calcolatore c) {
    return c.calcola( this);
  }
}
public class Quadrato implements Forma {…
  @Override
  public float accetta(Calcolatore c) {
    return c.calcola( this);
  }
}
public interface Calcolatore {
    public float calcola(Cerchio c);
    public float calcola(Quadrato q);
}Tipo statico Cerchio
Tipo statico Quadrato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#63,63,"Programmazione orientata agli oggetti
Overriding for Overloading  (4)
public class CalcolatoreDiArea implements Calcolatore  {
    @Override
    public float calcola(Cerchio c) {
       return 3.14f * c.getRaggio() * c.getRaggio();
    }
    @Override
    public float calcola(Quadrato q) {
       return q.getLato() * q.getLato();
    }
    static public float sommaAll(Calcolatore calc, Forma[] forme) {
       float acc = 0;
       for(Forma forma : forme) {
          acc += forma.accetta(calc) ; // COMPILA!
       }
       return acc;
    }
 
   public static void main(String args) {
      Calcolatore calcAree = new CalcolatoreDiArea();
      Forma[] forme = { new Cerchio(1), new Quadrato(2) } ;
      System.out.println( sommaAll(calcAree, forme));      
   }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#64,64,"Programmazione orientata agli oggetti
Ulteriori Calcolatori 
(Dipendenti dal Tipo Dinamico)
●E’ banalmente possibile implementare altre tipologie 
di Calcolatore. Ad es.:
public class CalcolatoreDiPerimetro implements Calcolatore {
    @Override
    public float calcola( Cerchio c ) {
       Return 2 * 3.14f * c.getRaggio();
    }
    @Override
    public float calcola( Quadrato q ) {
       return 4 * q.getLato();
    }
}
●Il metodo statico sommaAll()  continua a funzionare:
   public static void main(String args) {
      Calcolatore calcPerim = new CalcolatoreDiPerimetro();
      Forma[] forme = { new Cerchio(1), new Quadrato(2) } ;
      System.out.println( sommaAll(calcPerim , forme));      
   }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#65,65,"Programmazione orientata agli oggetti
Conclusioni:
Overriding for Overloading  (1)
●Riassumendo: si è aggiunto un livello di indirezione 
affinché il corpo del metodo polimorfo 
accetta(Calcolatore)  di Forma fissi il tipo statico 
dell’argomento della chiamata al metodo sovraccarico 
calcola(…)  di Calcolatore
●Per ottenere una chiamata sovraccarica risolta (a 
tempo di esec.) sulla base del tipo dinamico  del suo 
unico parametro vengono fatte:
✔prima, una chiamata polimorfa  risolta dinamicamente
✔poi, una chiamata sovraccarica  risolta staticamente"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#66,66,"Programmazione orientata agli oggetti
Conclusioni:
Overriding for Overloading  (2)
●Lo scopo di questo esercizio era chiarire i legami (ma anche 
ribadire le significative differenze) esistenti tra due 
meccanismi tipici della programmazione orientata agli oggetti
✔Overriding  vs Overloading
●Si potrebbe ripetere lo stesso esercizio anche per metodi che 
ricevono DUE o più parametri polimorfi (ad es. 2+ forme)
✔Il numero di varianti di metodo in overload si moltiplica ad ogni 
parametro aggiuntivo per ogni possibile tipo contemplato nella gerarchia
✔Sino a risolverli tutti tramite una sequenza di chiamate polimorfe, una per 
ciascun parametro
●Il risultato sarebbe significativamente più lungo e meno 
leggibile, ma non per questo concettualmente più complicato
●Nella pratica, anche grazie a questi meccanismi alternativi, la 
mancanza in Java della risoluzione dei metodi sovraccarichi 
sulla base del tipo dinamico di uno o più parametri non viene 
percepita come una significativa carenza"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#7,7,"Programmazione orientata agli oggetti
Esempio: StanzaMagica
 class StanzaMagica extends Stanza {
    final static private int SOGLIA_MAGICA_DEFAULT = 3;
    private int contatoreAttrezziPosati ;
    private int sogliaMagica;
  public StanzaMagica(String nome) {
        this(nome, SOGLIA_MAGICA_DEFAULT);
  }
   public StanzaMagica(String nome, int soglia) {
        super(nome);
        this.contatoreAttrezziPosati  = 0;
        this.sogliaMagica = soglia;
  }
    @Override
    public boolean addAttrezzo (Attrezzo attrezzo) {  
        …
    }
    private Attrezzo modificaAttrezzo (Attrezzo attrezzo) {
        … // (>>)
    }
 }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#8,8,"Programmazione orientata agli oggetti
Esempio: StanzaMagica
●Un nuovo metodo privato modificaAttrezzo():
  class StanzaMagica extends Stanza {
    … … …
    
    private Attrezzo modificaAttrezzo(Attrezzo attrezzo) {
       StringBuilder nomeInvertito;
       int pesoX2 = attrezzo.getPeso() * 2;
       nomeInvertito  = new StringBuilder(attrezzo.getNome());
       nomeInvertito = nomeInvertito.reverse();
       attrezzo = new Attrezzo(nomeInvertito.toString(),
                               pesoX2);
       return attrezzo;
    }
 }
9"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-13-estensione-protected.pdf#9,9,"Programmazione orientata agli oggetti
Definizione di Classe Estesa (2)
•Con oggetti StanzaMagica  è comunque possibile 
usare i metodi pubblici definiti nella superclasse 
quali getDescrizione() , getStanzeAdiacenti()
  
  StanzaMagica labIA = …
String s = labIA.getDescrizione();
•Questi metodi non sono definiti esplicitamente in 
StanzaMagica , ma vengono ereditati
•Allo stesso modo vengono ereditate le variabili di 
istanza
–(ma solo quelle non private solo visibili nella 
sottoclasse)
10"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Generics: Concetti Base"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#1,1,"Programmazione orientata agli oggetti
Obiettivi della Lezione
•I generics sono uno strumento per scrivere classi 
(e metodi) parametriche rispetto ad un tipo
•Ci concentriamo soprattutto su come usare classi 
generiche
–Al temine del corso lo studente dovrà essere in grado di 
usare classi generiche (in particolare quelle del package  
java.util relative alla gestione di collezioni di oggetti)
•La progettazione di classi generiche va oltre gli 
obiettivi del corso
–Anche se, da un punto di vista puramente didattico, 
risulta invece utile introdurre i Generics  progettando una 
semplice classe contenitrice di oggetti: Coppia"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#10,10,"Programmazione orientata agli oggetti
Controllo sui Tipi Statici vs Dinamici
•Il problema nasce dal controllo a tempo dinamico 
operato dal downcast esplicito: 
–nell'oggetto coppia è atteso come primo elemento 
un oggetto di tipo dinamico Persona
•Invece vi si trova un riferimento ad un oggetto di 
tipo dinamico String
•Tutto perfettamente lecito per il compilatore che 
effettua verifiche solo sul tipo statico:
–l’istruzione coppia.setPrimo(pippo) riceve come 
parametro attuale la variabile locale pippo, di tipo 
statico String , sottotipo del tipo Object atteso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#11,11,"Programmazione orientata agli oggetti
Tipizzazione Lasca
•A ben vedere sono tutte conseguenze di una 
tipizzazione lasca
obiettivo : coppie di oggetti dello stesso tipo
•A differenza di come originariamente desiderato, 
per ovviare alla scarsa espressività del sistema 
dei tipi Java, siamo finiti per progettare una classe 
che può ospitare un coppia di oggetti qualsiasi
risultato : coppie di oggetti non necessariamente 
dello stesso tipo!
•Solo un’approssimazione del tipo desiderato
–pratica frequentemente utilizzata precedentemente 
all’introduzione dei Java Generics nella piattaforma Java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#12,12,"Programmazione orientata agli oggetti
Conseguenze della Tipizzazione Lasca
•Un controllo lasco dei tipi a tempo di compilazione 
comporta almeno le seguenti conseguenze:
–Costringe ad inserire downcast ogni volta che accediamo ad 
un elemento della coppia
Prima di Java 5 molti sviluppatori consideravano i downcasting 
quantomeno ineleganti, ma pochi lo consideravano un 
sostanziale limite, nella pratica, del linguaggio
–Rimanda a tempo di esecuzione alcuni errori che 
risulterebbero facilmente rilevabili già a tempo di 
compilazione con una migliore analisi dei tipi statici
Questo è il vero problema! riconsiderare il costo dei bug 
rispetto al costo degli errori di compilazione>>
•In fase di definizione della coppia, si vorrebbe poter 
specificare un unico tipo per entrambi  i riferimenti ad 
oggetti che la coppia è destinata a memorizzare"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#13,13,"Programmazione orientata agli oggetti
Tipi e Metodi Generici
•I generics sono uno strumento per scrivere classi, 
ed interfacce, il cui tipo diventa parametrico 
rispetto ad uno o più tipi
•Si applica anche ai metodi per renderne 
parametrica la segnatura
•Nella definizione di un tipo generico, il codice 
viene scritto in maniera parametrica rispetto ad 
un tipo formale
•Nell'uso di un tipo generico, il tipo formale  deve 
essere istanziato con un tipo attuale per renderlo 
effettivamente utilizzabile e completamente 
definito"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#14,14,"Programmazione orientata agli oggetti
La Classe Generica Coppia<T>  (1) 
•La definizione di una classe generica prevede la 
dichiarazione del parametro formale di tipo racchiuso 
tra parentesi acute
public class Coppia <T> {
…
}
•In questo modo si specifica che all'interno della 
definizione della classe  Coppia , il simbolo T indica il 
tipo sulla base del quale la definizione di classe è 
parametrica
•Convenzione sul nome del parametro formale di tipo 
–Singola lettera maiuscola: T, E, V …"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#15,15,"Programmazione orientata agli oggetti
La Classe Generica Coppia<T>  (2) 
•Nella definizione di campi e metodi all'interno della 
classe T viene usato come una dichiarazione di tipo:
public class Coppia< T> {
    private T primo;
    private T secondo;
    public Coppia( T primo, T secondo) {
        this.primo = primo;
        this.secondo = secondo;
    }
    public T getPrimo() {
        return this.primo;
    }
    public T getSecondo() {
        return this.secondo;
    }
    …
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#16,16,"Programmazione orientata agli oggetti
Oggetti Coppia<T>  Mutabili
public class Coppia<T> {
private T primo;
private T secondo;
public Coppia(T primo, T secondo) {
    this.primo = primo;
    this.secondo = secondo;
}
public T getPrimo() {
    return this.primo;
}
public T getSecondo() {
    return this.secondo;
}
public void setPrimo(T primo) {
    this.primo = primo;
}
public void setSecondo(T secondo) {
    this.secondo = secondo;
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#17,17,"Programmazione orientata agli oggetti
Usare una Classe Generica ( T=Persona )
•Quando  usiamo una classe generica, dobbiamo 
istanziarne completamente il tipo  fornendo il tipo 
attuale di tutti i tipi formali di cui fa uso
•Ad esempio, usiamo la nostra classe generica 
Coppia<T> , per gestire coppie di oggetti Persona
public class CoppiaTest {
   @Test
   public void testCoppiaDiPersone() {
       Coppia<Persona>  coppia;
       Persona p1 = new Persona(""Stanlio"");
       Persona p2 = new Persona(""Olio"");
       coppia = new Coppia<Persona>(p1, p2);
       assertSame(p1,coppia.getPrimo());
       assertSame(p2,coppia.getSecondo());
   }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#18,18,"Programmazione orientata agli oggetti
Usare una Classe Generica ( T=Color )
•Vediamo la classe parametrica Coppia<T>  
istanziata su un altro tipo qualsiasi (ad es. 
java.awt.Color )
import java.awt.Color;
… 
public class CoppiaTest {
   @Test
 public void testCoppiaDiColori() {    
        Coppia<Color>  colori;
      Color rosso = new Color(255,0,0);
      Color blue = new Color(0,0,255);
      colori = new Coppia<Color>(rosso, blue);
     assertSame(rosso,colori.getPrimo());
     assertSame(blue,colori.getSecondo());
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#19,19,"Programmazione orientata agli oggetti
Controllo sui Tipi, con Generics
•Riconsideriamo il codice di prima, quello che 
avremmo voluto non compilasse affatto:
public class CoppiaTest {
  @Test
  public void testCheSmetteDiCompilare() {
Coppia<Persona> coppia = new Coppia<Persona>();
String pippo = new String(""Pippo"");
String pluto = new String(""Pluto"");
Persona p1 = new Persona(pippo);
Persona p2 = new Persona(pluto);
coppia.setPrimo(pippo);
coppia.setSecondo(pluto);
assertSame(pippo,
         ((Persona)coppia.getPrimo()).getNome());
  }
}NON COMPILA!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#2,2,"Programmazione orientata agli oggetti
Introduzione
•Notare che le coppie sono una forma molto 
rudimentale di collezione
•In effetti i Generics  furono introdotti in Java 5 
proprio per migliorare il JCF, la libreria dedicata 
alle collezioni già presente sin da Java 2 (ovvero 
1.2)
•Obiettivo: una classe generica rispetto al tipo dei 
due oggetti ospitati, purché sia lo stesso per 
entrambi. Ad esempio la classe dovrà gestire:
–Coppie di stringhe (istanze della classe String)
–Coppie di attrezzi (istanze della classe Attrezzo )
–Coppie di URL (istanze della classe URL)
–… "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#20,20,"Programmazione orientata agli oggetti
Tipo Formale – Tipo Attuale
•Non è difficile trovare una similitudine tra
–il concetto di parametro formale/attuale inerente 
l’invocazione dei metodi
–il concetto di tipo formale/attuale inerente la 
tipizzazione di classi generiche
•Solo superficialmente sono concetti simili: tra le 
tante differenze, non dimenticare mai la prima e 
più importante:
–il legame tra parametri formali/attuali è operato 
dalla JVM a tempo di esecuzione
–il legame tra tipi formali/attuali è operato dal 
compilatore a tempo di compilazione solo sulla 
base dei tipi statici"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#21,21,"Programmazione orientata agli oggetti
Generics a più Parametri
•È possibile definire classi, interfacce e metodi 
generici con più parametri di tipo
–Sintatticamente, si separano i vari parametri 
con una virgola
public class Esempio<T, S> {…}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#22,22,"Programmazione orientata agli oggetti
Generics e Tipi Primitivi
•Java è un linguaggio ibrido ci sono informazioni che si 
rappresentano senza utilizzare oggetti, ad es. int
•Non è possibile istanziare i tipi di una classe, di una 
interfaccia o di un metodo generico con tipi primitivi 
•Per ovviare al problema è possibile rappresentare i 
tipo primitivi mediante le cosidette classi wrapper
public class TestCoppia {
   @Test
public void testCheNonCompila() {
   Coppia<int>  coppia;      // ERRORE: NON COMPILA!
   int i1 = 100;
   int i2 = 200;
   coppia = new Coppia<int> (i1, i2);  // ERRORE
}
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#23,23,"Programmazione orientata agli oggetti
Classi Wrapper  (1)
•Per ogni tipo primitivo esiste una corrispondente 
classe wrapper  che consente di «oggettificare» il 
dato primitivo, costruendoci un oggetto 
«attorno», per ospitarlo:
–int →Integer
–double →Double
–float → Float
–char →Character
–boolean →Boolean
24"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#24,24,"Programmazione orientata agli oggetti
Classi Wrapper  (2)
25int i; 
i = 18;
Integer iwrap = new Integer(i);  
…
int value = iwrap.intValue();
 …il valore della variabile 
int è “avvolto” in un 
oggetto Integer
""scarto"" il 
valore"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#25,25,"Programmazione orientata agli oggetti
Classi Wrapper  (3)
•Le classi wrapper sono definite nel package 
java.lang
–quindi non è necessario importarle esplicitamente
–per approfondimenti sui dettagli dei loro metodi è 
sufficiente vedere la documentazione
•Metodi più frequentemente usati:
–metodi xxxValue()
–metodi valueOf()  e parseXxx()
–metodo equals()
26"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#26,26,"Programmazione orientata agli oggetti
Generics e Tipi Primitivi
•Esempio:
public class TestCoppia {
   @Test
 public void testCheCompila() {
   Coppia<Integer>  coppia;      // OK
   Integer i1 = new Integer(100);
   Integer i2 = new Integer(200);
   coppia = new Coppia<Integer>(i1, i2);  // OK
}
}
Decisamente prolisso"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#27,27,"Programmazione orientata agli oggetti
Boxing/Unboxing
•Per ovviare alla eccessiva verbosità,  dalla versione 5 
di Java (non a caso la stessa dell’introduzione dei 
generics ), la gestione di oggetti wrapper è 
semplificata dalle funzionalità di boxing e unboxing
•In sostanza una tecnica di conversione automatica di 
tipi primitivi nei corrispondenti oggetti di un tipo 
wrapper  e viceversa
–per certi aspetti simile alla promozione di tipi che già si 
opera ad es. da int a float 
–per altri ancora, differente: sono coinvolti sia tipi che 
non sono oggetti, sia tipi che invece lo sono
28"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#28,28,"Programmazione orientata agli oggetti
Boxing
•Boxing:  è possibile assegnare direttamente tipi 
primitivi a oggetti wrapper
•Le seguenti istruzioni sono equivalenti:
int i = 0;        int i = 0;
Integer iWrap;    Integer iWrap;
iWrap = i;        iWrap = new Integer(i);
iWrap = 5;        iWrap = new Integer(5);
•È il compilatore che inserisce automaticamente le 
istruzioni per gestire boxing/unboxing!
29"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#29,29,"Programmazione orientata agli oggetti
Unboxing
•Unboxing:  è possibile assegnare direttamente 
oggetti wrapper a tipi primitivi
•Le seguenti istruzioni sono equivalenti:
int i = 0;        int i = 0;
Integer iWrap;    Integer iWrap;
iWrap = 5;        iWrap = new Integer(5);
i = iWrap;        i = iWrap.intValue();
•È il compilatore che inserisce automaticamente le 
istruzioni per gestire boxing/unboxing!
30"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#3,3,"Programmazione orientata agli oggetti
La Classe Generica Coppia
•La classe Coppia  deve offrire dei servizi per 
gestire una coppia di oggetti del medesimo  
tipo:
–Metodi per ottenere/cambiare
•il primo elemento della coppia
•il secondo elemento della coppia
–Un costruttore che riceve come parametri due 
riferimenti ad oggetti del medesimo tipo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#30,30,"Programmazione orientata agli oggetti
Boxing, Unboxing e Collezioni
•Grazie a boxing e unboxing, anche la gestione 
di collezioni che memorizzano informazioni 
riconducibili a tipi primitivi risulta semplificata
•Le seguenti operazioni sono lecite (sempre 
grazie a boxing e unboxing):
31Coppia<Integer> c;
c = new Coppia<Integer>();
int i = 4;
c.setPrimo(i);
c.setSecondo(5);
c.setPrimo(new Integer(i));
c.setSecondo(new Integer(5));"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#31,31,"Programmazione orientata agli oggetti
Attenzione allo Zucchero (Sintattico) 
•Le versioni più recenti del linguaggio hanno 
semplificato la gestione dei tipi primitivi nascondendo 
alcune conversioni di tipo
•Tuttavia, è necessario comprendere a fondo
la differenza tra il concetto di tipo primitivo e la loro 
controparte ad oggetti, i wrapper
quali operazioni non sono necessarie solo grazie ai servizi 
offerti dalle ultime versioni del compilatore Java (sarebbero 
necessarie con versioni precedenti)
quali operazioni il compilatore inserisce per conto nostro
•Perché conviene avere queste competenze?
–per stimare meglio il numero di oggetti creati dalle nostre 
applicazioni
–per migliorare la nostra capacità di ricerca delle origine degli 
errori sia a tempo di compilazione che di esecuzione
–per riuscire ad usare versioni precedenti del compilatore
32"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#32,32,"Programmazione orientata agli oggetti
Generics: 
Rappresentazione Diagrammatica
•Rappresentazione diagrammatica di una 
classe generica
•oppure 
AT
A<T>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#33,33,"Programmazione orientata agli oggetti
Generics: Wildcard (1)
•A seguire approfondiamo alcuni concetti più 
avanzati relativi ai generics per mezzo di esempi 
•N.B. In questo corso ci concentriamo sull'uso di 
classi generiche e non sulla loro progettazione
–Ma l’utilizzo di alcune librerie pressuppone la 
capacità di comprendere alcun tipi e segnature 
di metodi generici
✔sviluppare la propria capacità di astrazione è comunque 
sempre importante nella programmazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#34,34,"Programmazione orientata agli oggetti
Generics: Wildcard (2)
•Aggiungiamo alla classe Coppia<T>  il metodo 
copyAll()  
–copia nella coppia corrente gli elementi di un'altra 
coppia che viene passata come parametro
•La coppia che passiamo come parametro per 
«fornire» gli elementi da copiare deve essere 
istanziata su un qualunque sottotipo degli oggetti 
della coppia corrente che finirà per ospitarli
•Questa particolarità si esprime con il carattere 
jolly ? e (di nuovo) con la parola chiave extends"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#35,35,"Programmazione orientata agli oggetti
Generics: Upper-Bounded Wildcard (1)
•Vediamone la segnatura del metodo di istanza 
contenuto della classe generica Coppia<T> : 
 public class Coppia<T> {
  …  
    public void copyAll(Coppia<? extends T>  c)
     …
   }
✔Cosa significa questa segnatura?
✔Di che tipo deve essere il parametro?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#36,36,"Programmazione orientata agli oggetti
Generics: Upper-Bounded Wildcard (2)
Coppia<? extends T> c 
•Significa: un riferimento ad un oggetto (qui usato come 
parametro di un metodo) del tipo generico Coppia 
istanziato sullo stesso tipo T, o su un suo sottotipo, su cui è 
istanziata la coppia/oggetto corrente  Coppia<T> 
•Esempio di utilizzo:
Coppia<Strumento> strumenti;
Coppia<Chitarra> chitarre;
…
strumenti.copyAll(chitarre); // OK!   T = ???
•Definizione del metodo copyAll()  (nella classe Coppia<T> ):
public void copyAll(Coppia<? extends T> coppia) {
this.setPrimo(coppia.getPrimo());
this.setSecondo(coppia.getSecondo());
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#37,37,"Programmazione orientata agli oggetti
Metodi Statici Generici
•È possibile definire anche metodi statici generici 
(cioè parametrici rispetto ad un tipo formale)
•Un metodo generico definisce i tipi formali nella 
segnatura del metodo, subito prima del tipo 
restituito. Ad es.:
  public static <T> int metodoGenerico(
          Coppia<T> c, 
          T e
           ) 
Anche in questo caso, come già per le classi generiche, è 
possibile invocare il metodo solo dopo aver fornito (a 
tempo statico, in fase di compilazione) tutti i tipi attuali 
necessari a completare definitivamente la segnatura"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#38,38,"Programmazione orientata agli oggetti
Metodi Generici: Wildcard
•Definiamo ora la classe Coppias, classe contenitrice 
per ospitare metodi generici e di utilità generale per 
manipolare oggetti di tipo Coppia 
•In particolare la classe Coppias  offre alcuni metodi 
(statici), di cui stiamo per definire le segnature, 
perseguendo la loro generalità rispetto al tipo degli 
oggetti ospitati nelle coppie:
–??? reverse(??? coppia) 
prende come parametro una coppia e ne inverte gli elementi 
(il primo elemento diventa il secondo e viceversa)
–??? fill (??? coppia, ??? e ) 
prende due parametri: una coppia ed un elemento; riempie 
entrambi gli elementi della coppia con l'elemento ricevuto"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#39,39,"Programmazione orientata agli oggetti
Metodi Generici: Esempio
public class Coppias {
public static <T> void reverse(Coppia< T> c) {
T tmp;
tmp = c.getPrimo();
c.setPrimo(c.getSecondo());
c.setSecondo(tmp);
}
  …
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#4,4,"Programmazione orientata agli oggetti
Una Possibile Soluzione Basata sul 
Polimorfismo
•Una possibile soluzione (l’unica possibile prima 
dell’introduzione dei Generics  in Java 5) consiste 
nello sfruttare il polimorfismo, ed in particolare il 
principio di sostituzione
•Definiamo una classe che gestisce una coppia di 
oggetti istanza di Object
–per il principio di sostituzione (e per la gerarchia dei 
tipi Java a singola radice in Object) la nostra classe 
può gestire coppie di oggetti istanza di qualsiasi 
classe (in quanto sottotipo di Object)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#40,40,"Programmazione orientata agli oggetti
Generics: Lower-Bounded Wildcard (1)
•Il metodo fill(??? coppia , ??? e)
–imposta entrambi gli elementi della coppia che viene 
passata come primo parametro, con lo stesso 
riferimento ad oggetto nel secondo parametro
•E' un metodo parametrico: il tipo del secondo 
parametro deve essere un qualunque sottotipo del 
tipo istanziato dalla coppia
ovvero: il tipo su cui la coppia è instanziata deve essere 
un supertipo del tipo del parametro
•Si esprime così:
static <T> void fill(Coppia<? super T>  coppia,
         T elemento)  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#41,41,"Programmazione orientata agli oggetti
Generics: Lower-Bounded Wildcard (2)
Coppia<? super T>
✔Significa: un riferimento ad un oggetto Coppia  
istanziato su T o su un qualsiasi supertipo di T
•Esempio di utilizzo:
Coppia<Strumento> strumenti;
Chitarra fender;
…
Coppias.fill(strumenti, fender); // OK!   T = ???
•Definizione:
public static <T> void fill( Coppia<? super T> coppia, 
     T elemento) {
coppia.setPrimo(elemento);
coppia.setSecondo(elemento);
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#42,42,"Programmazione orientata agli oggetti
Generics: Bounded Wildcard
static <T> void copy(Coppia<? super T> dest,
                     Coppia<? extends T> src)
✔Attenzione a non confonderlo con copyAll()
•Esempio di utilizzo:
Coppia<Strumento> strumenti = new Coppia<Strumento>();
Coppia<Chitarra> chitarre = new Coppia<Chitarra>();
…
Coppias.copy(strumenti, chitarre); // OK T = ???
•Definizione:
static <T> void copy(Coppia<? super T> dest,
                     Coppia<? extends T> src) {
dest.setPrimo(src.getPrimo());
dest.setSecondo(src.getSecondo());
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#43,43,"Programmazione orientata agli oggetti
La Regola Mnemonica PECS
•Semplice regola per ricordare il tipo dei parametri 
formali nelle segnature di collezioni
Producer Extends Consumer Super
•Utilizzare <? extends T>  per i parametri di 
collezioni che “producono” elementi 
–ad es. il parametro del metodo copyAll()
•Utilizzare <? super T>  per i parametri di 
collezioni che “consumano” elementi
–ad es. il parametro del metodo fill()
•Esempio di utilizzo contestuali di entrambi: i due 
parametri del metodo statico copy()"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#44,44,"Programmazione orientata agli oggetti
Personaggi ed Interpreti
•Ogni riferimento ad API esistenti o a metodi realmente 
esistenti NON è affatto puramente casuale
–Coppia nel ruolo di Collection , List…
–Coppias  nel ruolo di Collections (>>)
•Dentro java.util.Collections  si trovano :
static <T> void fill(List<? super T> list, T obj)
static <T> boolean addAll(Collection<? super T> c, 
                T... elements)
static <T> void copy(List<? super T> dest,
                     List<? extends T> src)
static void reverse(List<?> list)
Preferibile quando non è 
strettamente necessario dare 
un nome al tipo formale"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#45,45,"Programmazione orientata agli oggetti
Esercizi
•Scrivere il codice della classe generica Coppia<T>
•Scrivere il codice della classe Coppias  
•Scrivere, utilizzando JUnit, classi di test per le 
classi Coppia<T>  e Coppias
•Cercare di capire sino al dettaglio quante più 
possibili segnature generiche dei metodi statici 
fornite nella classe  java.util.Collections"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#46,46,"Programmazione orientata agli oggetti
Esercizi
Supponendo che Studente  sia sottotipo di 
Persona , è vero che Coppia<Studente > risulta 
essere sottotipo di Coppia<Persona >?
•Ripetere l’esercizio di sopra, nel caso di coppie 
immutabili , ovvero prive dei metodi setXXX()
•Il tipo di Coppia<T> è covariante  o controvariante 
rispetto al tipo T?
–Nel caso di coppie mutabili ?
–Nel caso di coppie immutabili ?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#47,47,"Programmazione orientata agli oggetti
Riferimenti ed Approfondimenti
•Alcuni articoli spiegano molti altri dettagli:
http://www.oracle.com/technetwork/java/javase/generics-tutorial-159168.pdf
•Per sapere (quasi) tutto  sui java generics:
http://www.angelikalanger.com/GenericsFAQ/JavaGenericsFAQ.html"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#5,5,"Programmazione orientata agli oggetti
La Coppia  di Object  
public class Coppia {
 private Object primo;
 private Object secondo;
 public Coppia(){}
 public Coppia( Object primo, Object secondo) {
        this.primo = primo;
        this.secondo = secondo;
 }
 public Object getPrimo() {
 return this.primo;
 }
       
 public Object getSecondo() {
 return this.secondo;
 }
 public void setPrimo( Object primo) {
 this.primo = primo;
 }
 public void setSecondo( Object secondo) {
 this.secondo = secondo;
 }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#6,6,"Programmazione orientata agli oggetti
Tipo degli Elementi Ospitati
•Considereremo di seguito del codice che fa 
riferimento alla semplice classe Persona
class Persona {
  private String nome;
  public Persona(String nome) {
    this.nome = nome;
  }
  public String getNome() {
    return this.nome;
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#7,7,"Programmazione orientata agli oggetti
Controllo sui Tipi Senza Generics:
Scomodi (ed Inutili?) Downcast
•Il seguente codice compila, e funziona 
correttamente:
public class CoppiaSenzaGenericsTest {
    @Test
    public void testCheCompilaEdEsegue() {
        Coppia coppia = new Coppia();
        String pippo = new String(""Pippo"");
        String pluto = new String(""Pluto"");
        Persona p1 = new Persona(pippo);
        coppia.setPrimo(p1);
        Persona p2 = new Persona (pluto);
        coppia.setSecondo(p2);
        Persona persona = (Persona)coppia.getPrimo();
        assertSame(pippo, persona.getNome()));
    }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#8,8,"Programmazione orientata agli oggetti
•Per un utilizzo più semplice delle coppie, 
vorremmo poter scrivere il seguente codice:
public class CoppiaSenzaGenericsTest {
@Test
public void testCheNonCompila() {
Coppia coppia = new Coppia();
String pippo = new String(""Pippo"");
String pluto = new String(""Pluto"");
Persona p1 = new Persona(pippo);
coppia.setPrimo(p1);
Persona p2 = new Persona(pluto);
coppia.setSecondo(p2);
assertSame(pippo, coppia.getPrimo() .getNome());
}
}NON COMPILA!
Il tipo statico 
Object
non possiede il 
metodo getNome()Controllo sui Tipi Senza Generics:
non Compila Quando Vorremmo..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-14-generics.pdf#9,9,"Programmazione orientata agli oggetti
Controllo sui Tipi Senza Generics: 
non Vorremmo che Compilasse!
•Al contrario, il seguente codice compila 
correttamente ma l’esecuzione fallisce:
public class CoppiaSenzaGenericsTest {
@Test
public void testCheCompilaMaNonEsegue() {
Coppia coppia = new Coppia();
String pippo  = new String(""Pippo"");
String pluto = new String(""Pluto"");
Persona p1 = new Persona(pippo);
Persona p2 = new Persona(pluto);
coppia.setPrimo(pippo);
coppia.setSecondo(pluto);
assertSame(pippo,( (Persona)coppia.getPrimo() ).getNome());
}
}
ClassCastException  a tempo di esecuzione!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Collezioni
Liste"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#1,1,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E>
–Iterare una collezione: Iterator<E>
–Rimuovere elementi da una collezione
•Liste
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#10,10,"Programmazione orientata agli oggetti
Un Primo Sguardo: Implementazioni
•List<E>
–ArrayList<E>
–LinkedList<E>
•Set<E>
–HashSet<E>
–TreeSet<E>
•Map<K,V>  
–HashMap<K,V>
–TreeMap<K,V>
... le più diffusamente utilizzate, ma ne esistono 
molte altre di uso più specifico
11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#11,11,"Programmazione orientata agli oggetti
Un Primo Sguardo: Collections
•La classe java.util.Collection s 
(al plurale: attenzione alla ‘s’ finale!)
–offre un vasto insieme di metodi (statici) generici 
che implementano utili e diffusi algoritmi per la 
manipolazione di liste quali:
•ordinamento
•ricerca max e min
•shuffle (mescolamento casuale)
•reverse 
•fill…
A meno di forti (anzi fortissime) motivazioni in senso contrario, 
implementare funzionalità equivalenti a questi (o ad uno degli 
altri) metodi statici offerti da Collections  è solo una perdita di 
tempo12"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#12,12,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E>
–Iterare una collezione: Iterator<E>
–Rimuovere elementi da una collezione
•Liste
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
13"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#13,13,"Programmazione orientata agli oggetti
Interface Collection<E>
•L'interface Collection<E>  dichiara i metodi di 
una collezione generica 
•Questi metodi permettono di svolgere 
operazioni di tre categorie:
–Manipolazione di base
–Bulk
–Conversione da e verso array
14"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#14,14,"Programmazione orientata agli oggetti
Interface Collection<E>
public interface Collection<E> extends Iterable<E> { 
//Basic operations 
int size(); 
boolean isEmpty(); 
boolean contains(Object element); 
boolean add(E element); //optional 
boolean remove(Object element); //optional 
Iterator<E> iterator(); 
//Bulk operations 
boolean containsAll(Collection<?> c); 
boolean addAll(Collection<? extends E> c); //optional 
boolean removeAll(Collection<?> c); //optional 
boolean retainAll(Collection<?> c); //optional 
void clear(); //optional 
//Array operations 
Object[] toArray(); 
<T> T[] toArray(T[] a);
}
15?"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#15,15,"Programmazione orientata agli oggetti
Collection<E> : Metodi Base
Consultare i Javadoc! In sintesi:
●boolean isEmpty(); 
ritorna true se la collezione è vuota
●int size();  
ritorna il numero di elementi presenti nella collezione
●boolean contains(Object element); 
ritorna true se la collezione contiene un elemento uguale a quello passato come 
parametro (l'uguaglianza è verificata dal metodo equals())
●boolean add(E element); 
aggiunge alla collezione l'elemento passato; ritorna true se la collezione è 
cambiata dopo la chiamata a questo metodo
●boolean remove(Object element); 
rimuove dalla collezione gli elementi uguali all'oggetto passato come parametro 
(l'uguaglianza è verificata dal metodo equals()). Ritorna true se la collezione è 
cambiata dopo l'invocazione del metodo
•Iterator<E> iterator(); 
restituisce un oggetto Iterator, per iterare sugli elementi della collezione
16"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#16,16,"Programmazione orientata agli oggetti
Collection<E> : Metodi Bulk
Consultare i Javadoc! In sintesi:
●boolean containsAll(Collection<?> c);  
ritorna true se la collezione contiene tutti gli elementi della collezione passata 
come parametro
●boolean addAll(Collection<? extends E> c); 
aggiunge alla collezione tutti gli elementi d ella collezione passata come parametro; 
ritorna true se la collezione è cambiata dopo l'invocazione di questo metodo
●boolean removeAll(Collection<?> c); 
rimuove dalla collezione tutti gli elementi uguali (l'uguaglianza è verificata dal 
metodo equals()) che sono contenuti nella collezione passata come parametro; 
ritorna true se la collezione è cambiata dopo l'invocazione di questo metodo
•boolean retainAll(Collection<?> c);  
rimuove dalla collezione tutti gli elementi che non sono presenti nella collezione 
passata come  parametro; ritorna true se la collezione è cambiata dopo l'invocazione di 
questo metodo
•void clear();
rimuove tutti gli elementi dalla collezione
17"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#17,17,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E>
–Iterare una collezione: Iterator<E>
–Rimuovere elementi da una collezione
•Liste
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
18"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#18,18,"Programmazione orientata agli oggetti
Iterazione: Interface  Iterator<E>
•L'iterazione di una collezione avviene attraverso 
un oggetto iteratore dedicato allo scopo
•Gli iteratori sono creati invocando il factory 
method iterator()  sulla collezione che si vuole 
scandire
•L’oggetto ottenuto implementa l'interface 
Iterator<E> , munita dei metodi
–boolean hasNext()
–E next()
–void remove()>>
Solo i primi due metodi sono considerati strettamente 
caratterizzanti gli iteratori
19"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#19,19,"Programmazione orientata agli oggetti
Semantica degli Iteratori
•Nella sostanza, un cursore   che scandisce la 
collezione sottostante ricordando la sua posizione 
nella scansione
•Posizioni lecite: subito prima o subito dopo un 
elemento della collezione che si sta iterando 
N.B. mai “sopra” un elemento
20"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#2,2,"Programmazione orientata agli oggetti
Introduzione
•Molte applicazioni richiedono di gestire 
collezioni di oggetti
•Gli array sono uno strumento di basso livello
–La dimensione di una collezione in genere non è 
nota a priori e può variare notevolmente
–Negli esercizi fatti finora abbiamo ipotizzato un 
numero massimo di elementi proprio per facilitarne 
l’utilizzo
•un indicatore di riempimento serve a ricordarsi il 
numero di elementi già memorizzati nell'array 
–Possiamo avere bisogno di molte modalità di 
accesso
•(non solo indicizzato; ad es. LIFO, FIFO, ecc. ecc.)
–Ci può essere la necessità di mantenere gli 
elementi ordinati
3"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#20,20,"Programmazione orientata agli oggetti
Collezioni di Tante Tipologie, 
un Unico Modo per Enumerarle
L’iterazione si effettua sempre nello stesso 
identico modo indipendentemente dal tipo di 
collezione sottostante che lo ha generato
➢Con notevole “economia di pensiero”
•Per questo motivo è possibile discuterli ancora 
prima delle implementazioni che sanno generarli,  
con riferimento all’interface  Collection<E>
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#21,21,"Programmazione orientata agli oggetti
Iterator<E> : Metodi
•boolean hasNext (); 
ritorna true se e solo se esiste un altro 
elemento da scandire
•E next(); 
restituisce il prossimo elemento della 
collezione nella scansione corrente ed avanza
22"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#22,22,"Programmazione orientata agli oggetti
Iterator<E> : Iterazione
•La chiamata ripetuta di next() permette di scorrere 
gli elementi della collezione uno alla volta
•Se si raggiunge la fine della collezione viene sollevata 
una eccezione (che interrompe il programma) 
java.util.NoSuchElementException
•Per evitare questa situazione, prima di chiamare 
next() si usa il metodo  hasNext() , che ritorna  true 
se e solo se esiste un altro elemento su cui iterare
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#23,23,"Programmazione orientata agli oggetti
Esercizio: 
la Semantica di Iterator
•Per comprendere la semantica dei metodi di 
una classe non esiste metodo migliore di una 
batteria di test-case che la documenti 
precisamente
•Per Iterator<E>  scriviamo test per i due 
metodi principali dell’interfaccia Iterator<E>
•Utilizziamo come implementazione concreta 
della collezione   ArrayList<E> (>>)
24"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#24,24,"Programmazione orientata agli oggetti
Unit-Testing per Documentare la 
Semantica di Iterator<E>
import …
public class IteratorTest {
  private List<String> vuota;
  private List<String> singoletto;
  private String solitario;
  @Before
  public void setUp() {
    this.vuota = new ArrayList <>();
    this.singoletto = new ArrayList<String>();
    this.solitario = new String(""solitario"");
    this.singoletto.add(this.solitario);
  }
  @Test … … … 
}
25// da Java 7  
ArrayList <>();
Diamond Operator"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#25,25,"Programmazione orientata agli oggetti
Test di Iterator.hasNext()
@Test 
public void testHasNext_noListaVuota() {
  Iterator<String> it = this.vuota.iterator();
  assertNotNull(it);
  assertFalse( it.hasNext() );
}
@Test 
public void testHasNext_primaSiPoiNoSuSingoletto() {
  Iterator<String> it = this.singoletto.iterator();
  assertNotNull(it);
  assertTrue( it.hasNext() );
  it.next();
  assertFalse( it.hasNext() );
}
26"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#26,26,"Programmazione orientata agli oggetti
Test di Iterator.next()
@Test 
public void testNext_singoletto() {
  Iterator<String> it =
 this.singoletto.iterator();
  assertNotNull(it);
  assertTrue(it.hasNext());
assertSame(this.solitario,  it.next() );
}
27"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#27,27,"Programmazione orientata agli oggetti
Test di Iterator.next()
@Test 
public void testNext_suListaDiDueElementi() {
  List<String> doppietta = new ArrayList<>();
doppietta.add(new String(""primo""));
doppietta.add(new String(""secondo""));
 Iterator<String> it = doppietta.iterator();
 assertNotNull(it);
 assertTrue(it.hasNext());
assertEquals(""primo"", it.next() );
 assertTrue(it.hasNext());
assertEquals(""secondo"", it.next() );
assertFalse(it.hasNext());
}
28"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#28,28,"Programmazione orientata agli oggetti
Test di Iterator.next()
@Test(expected  = NoSuchElementException. class)
public void testNext_oltreLaFineSollevaEccezione() {
 Iterator<String> it = this.vuota.iterator();
it.next();
}
29•Posizioni lecite: subito prima o subito dopo un 
elemento della collezione che si sta iterando
raggiunto l’ultimo elemento non si può andare 
oltre: il metodo Iterator.next()  solleva una 
eccezione (>>)
NoSuchElementException!"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#29,29,"Programmazione orientata agli oggetti
Iterazione di Array – Ciclo for
public class Borsa {
    private Attrezzo[] attrezzi;
    private int numeroAttrezzi ;
    …
    public int getPeso(){
        int pesoTotale = 0;
        for(int i=0; i<this.numeroAttrezzi; i++) {
           Attrezzo a = this.attrezzi[i];
           pesoTotale += a.getPeso();
        }
      return pesoTotale;  
    }
    …
}
30"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#3,3,"Programmazione orientata agli oggetti
Le Collezioni del Package  java.util
•Nella libreria di base di Java abbiamo un package 
che ci offre un vasto insieme di interfacce e di 
classi per la gestione di collezioni di oggetti
•Introdotte già in Java 2:
•ma sostanzialmente rivisitate in seguito alla 
introduzione dei Generics in Java 5
N.B. I Generics di Java 5 sono stati introdotti 
principalmente per il loro utilizzo nelle collezioni 
preesistenti
• significativamente estese nelle versioni successive
per coprire scenari di utilizzo via via conclamatesi 
come importanti
–ad es. java.util.concurrent : collezioni concorrenti 
Certamente tra le librerie più utilizzate in assoluto
4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#30,30,"Programmazione orientata agli oggetti
Iterazione Mediante Iteratori
import java.util.List;
import java.util.ArrayList;
public class Borsa {
    private List<Attrezzo>  attrezzi;
    …
    public int getPeso(){
        int pesoTotale = 0;
        Iterator<Attrezzo> iteratore =
            this.attrezzi.iterator();
        while (iteratore.hasNext ()) {
            Attrezzo a = iteratore.next ();
            pesoTotale += a.getPeso();
        }
        return pesoTotale;
    }
    …
}
31"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#31,31,"Programmazione orientata agli oggetti
Esercizio List<E> : Iterazione
•L’utilizzo degli iteratori è decisamente ripetitivo
•Sempre le stesse identiche operazioni:
–Iterator<Attrezzo> iteratore = 
this.attrezzi.iterator();
Abbiamo chiesto alla lista di creare un oggetto per 
gestire l'iterazione su una collezione di oggetti 
Attrezzo …
–while (iteratore.hasNext())
…fintanto che ci sono ancora elementi da scandire …
–Attrezzo a = iteratore.next();
…attraverso il metodo next() otteniamo dall'iteratore il 
prossimo elemento della scansione
•E’ ben motivata una forma sintattica abbreviata...
32"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#32,32,"Programmazione orientata agli oggetti
Iterazione : for-each  (1)
•Per iterare su tutti gli elementi di una collezione 
è possibile usare la forma ""for-each"" 
dell'istruzione for
for( Tipo elemento : iterable  )
<<blocco_di_operazioni_su_elemento>>
•Dove iterable   è un qualsiasi sottotipo di 
java.lang.Iterable<E> , una interface che offre 
il factory method:
–Iterator<E> iterator()
La sintassi for-each è conveniente solo se non è 
necessario accedere all’indice di iterazione
33"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#33,33,"Programmazione orientata agli oggetti
Iterazione : for-each  (2)
Si tratta solo di “zucchero sintattico”: il compilatore traduce
   for( E elemento  : iterable  )
<<blocco_di_codice_su elemento>>
… in …
for (Iterator<E> iter = iterable.iterator();
   iter.hasNext(); ) {
E elemento = iter.next();
 <<blocco_di_codice_su elemento>>
}
•Tutte le collezioni del JCF sono già Iterable
–Si può usare il for-each su qualunque classe, anche di nuova 
definizione,  purché implementi Iterable<E>
–Ed anche sugli array che pure non lo sono affatto (sottotipi di 
Iterable<E> )
✔grazie ad una gestione peculiare e specifica da parte del 
compilatore
34"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#34,34,"Programmazione orientata agli oggetti
Esercizio:
Scansione di Liste con for-each
import java.util.List;
import java.util.ArrayList;
public class Borsa {
  private List<Attrezzo> attrezzi ;
…
  public int getPeso(){
   int pesoTotale = 0;
     for(Attrezzo a : this.attrezzi)
         pesoTotale += a.getPeso();
   return pesoTotale;
  }
…
}
35"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#35,35,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E >
–Iterare una collezione: Iterator<E >
–Rimuovere elementi da una collezione
•Liste
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
36"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#36,36,"Programmazione orientata agli oggetti
Legame Iterator / Collezione
•Tra un iteratore e la collezione che lo ha creato 
permane un legame anche successivamente alla 
sua creazione
–Interessante anche per i meccanismi di costruzione dei 
tipi utilizzati nell’occasione (>>)
•L’esistenza di un terzo metodo nell’interface 
Iterator<E> per la rimozione di elementi rende  
più evidente la natura di questo legame:
void remove(); 
–rimuove dalla collezione l'ultimo elemento che è stato 
restituito da una precedente chiamata di next()
attraverso l’iteratore vengono operate modifiche sulla 
collezione sottostante
37"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#37,37,"Programmazione orientata agli oggetti
Test di Iterator.remove()
@Test 
public void testRemove() {
    Iterator<String> it = 
this.singoletto.iterator();
  String solitario = it.next();
  assertFalse(this.singoletto.isEmpty());
  it.remove();
    assertTrue(this.singoletto.isEmpty());
}
38"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#38,38,"Programmazione orientata agli oggetti
Il Metodo remove()  di Iterator
•Il metodo remove()  rimuove l'elemento restituito 
dall'ultima chiamata di next()  
•Non è ammesso chiamare remove()  a meno che 
prima non si sia provveduto ad invocare next()
•Ad es. per eliminare due elementi consecutivi:
it.next();
it.remove();
it.remove();   // ERRORE
prima bisogna richiamare next():
it.next();
it.remove();
it.next();
it.remove();  // OK
39"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#39,39,"Programmazione orientata agli oggetti
Rimuovere Elementi da una Collezione
•Pertanto esistono due diversi modi per 
rimuovere un elemento da una collezione, 
ciascuno dettato da specifiche esigenze:
–per la rimozione di un elemento uguale (secondo 
quanto stabilito dal metodo boolean 
equals(Object o) ) ad un elemento dato (passato 
come parametro) si usa il metodo remove(Object 
o) di Collection
–per la rimozione di un elemento durante la 
scansione si usa il metodo remove()  di Iterator
40"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#4,4,"Programmazione orientata agli oggetti
Il Java Collection Framework (JCF)
5
<<interface>>
Collection
<<interface>>
Set
<<interface>>
SortedSet
<<interface>>
List
<<interface>>
Map
<<interface>>
SortedMap
E E
K,VK,VE
E
Collections
<<interface>>
IterableE
+ iterator()
<<interface>>
IteratorE
"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#40,40,"Programmazione orientata agli oggetti
Il Metodo remove(Object o)
di Collection<E>
boolean remove(Object o) 
Removes a single instance of the specified element from 
this collection, if it is present (optional operation). More 
formally, removes an element e such that 
(o==null ? e==null :  o.equals(e) ), if this collection contains 
one or more such elements. Returns true if this collection 
contained the specified element (or equivalently, if this 
collection changed as a result of the call). 
–Parameters:
•o - element to be removed from this collection, if present 
–Returns:
•true if an element was removed as a result of this call
(dalla documentazione)
41"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#41,41,"Programmazione orientata agli oggetti
Il Metodo remove() di Iterator<E>
•void remove() 
–Removes from the underlying collection the last 
element returned by the iterator (optional 
operation). This method can be called only once 
per call to next. The behavior of an iterator is 
unspecified if the underlying collection is 
modified while the iteration is in progress in 
any way other than by calling this method .
(dalla documentazione)
42"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#42,42,"Programmazione orientata agli oggetti
Come Rimuovere Elementi?
•Attenzione: è un errore cercare di rimuovere elementi 
da una collezione con il metodo
–boolean remove(Object o)  
di Collection proprio mentre si sta ancora visitando 
la stessa collezione con un iteratore
–la collezione verrebbe modificata ""sotto i piedi"" 
dell'iteratore che la sta ancora scandendo
•Se si stanno cercando elementi da rimuovere 
attraverso un iteratore, deve poi essere usato il 
metodo remove() dell'iteratore stesso per renderlo 
«consapevole» dei cambiamenti alla «sua» collezione
43"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#43,43,"Programmazione orientata agli oggetti
java.util.ConcurrentModificationException
import java.util.*;
public class ConcurrentModificationMain {
  public static void main(String args[]) {
    List<Object> list = new ArrayList<>();
    Iterator it = list.iterator();
    list.add(new Object());
    it.next(); // Qui solleva  ConcurrentModificationException
  }
} 
L’eccezione è sollevata solo alla prima occasione utile 
(semantica fail-fast , vedere Javadoc)
Exception in thread ""main“
java.util.ConcurrentModificationException
  at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:448)
  at java.util.AbstractList$Itr. next(AbstractList.java:419)
  at ConcurrentModificationMain.main(ConcurrentModificationMain.java:9)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#44,44,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E >
–Iterare una collezione: Iterator<E >
–Rimuovere elementi da una collezione
•Liste
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
45"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#45,45,"Programmazione orientata agli oggetti
Liste: Interface List<E>  (1)
•Una lista è una collezione che mantiene gli 
elementi ordinati secondo l'ordine di 
inserimento (il primo elemento aggiunto alla 
lista, è in prima posizione, il secondo in 
seconda posizione, …, l'ultimo elemento 
aggiunto è in ultima posizione)
•Cfr. ASD (<<)
46"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#46,46,"Programmazione orientata agli oggetti
Liste: Interface List<E>  (2)
•L'interface List<E>  estende l'interface 
Collection<E>
•Oltre ai metodi della interface Collection<E> , 
List<E>  offre specifici metodi che consentono 
accesso e inserimento indicizzati degli 
elementi. Ad esempio:
–E get(int index):  Returns the element at the 
specified position in this list
–int indexOf(Object o) : Returns the index of 
the first occurrence of the specified element in 
this list, or -1 if this list does not contain the 
element
47"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#47,47,"Programmazione orientata agli oggetti
Esercizio (per Casa)
•Analizzare, compilare ed eseguire la classe di 
test ListTest  riportata subito di seguito.
–Aggiungere opportuni metodi di test per 
verificare e comprendere la semantica dei 
metodi:
–indexOf(Object o); in particolare cerca la stessa 
istanza in memoria od un oggetto equals()  ???
–contains(Object  o); idem...
–retainAll(Collection<?> c)
–containsAll(Collection<?> c)
48"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#48,48,"Programmazione orientata agli oggetti
Esercizio (per Casa, continua )
public class ListTest {
private Collection<Integer> c;
private Collection<Integer> t; 
@Before
public void setUp () {
      c = new LinkedList<Integer>();
      t = new ArrayList<Integer>();
      c.add(1);
      c.add(2);
      c.add(3);
      t.add(1);
      t.add(2);
}
  
@Test
public void testRemoveAll() {
      assertTrue(c.removeAll(t));
      Iterator<Integer> it = c.iterator();
      assertTrue(it.hasNext());
      assertEquals(3,it.next().intValue());
      assertFalse(it.hasNext());
}
}
49"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#49,49,"Programmazione orientata agli oggetti
Implementazioni di List<E>
•Il package java.util  offre due diverse 
implementazioni di List<E>
–ArrayList<E>
–LinkedList<E>
50•Forniamo qualche (grossolana) indicazione su 
come scegliere l'implementazione più 
opportuna
NOTA: Questi aspetti sono stati già approfonditi 
nel corso ""Algoritmi e Strutture Dati"""
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#5,5,"Programmazione orientata agli oggetti
Un Primo Sguardo: Collection<E> (1)
•L'interface Collection<E>  dichiara i metodi di 
una generica collezione:
•Generalizza sia List<E>  sia Set<E>
List<E>:
–Collezioni sequenziali i cui elementi possiedono 
una posizione
–Senza gestione dei duplicati
Set<E>:
–Collezioni che non ammettono duplicati
–Gli elementi non possiedono posizione 
6"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#50,50,"Programmazione orientata agli oggetti
ArrayList<E> : Implementazione
•Gli elementi sono memorizzati in un contenitore 
rappresentato con array ed indicatore di riempimento
•Al momento della creazione, la dimensione dell'array 
(ovvero la capacità della collezione) è inizializzata ad 
un valore prestabilito 
•Quando il numero di elementi è prossimo alla capacità 
dell'array, viene istanziato un nuovo array di 
dimensione maggiore (ad esempio doppia) nel quale 
vengono travasati tutti gli elementi dell'array 
originario
NOTA: Questi aspetti sono stati approfonditi nel corso 
""Algoritmi e Strutture Dati""
51"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#51,51,"Programmazione orientata agli oggetti
LinkedList<E> : Implementazione
•Gli elementi sono memorizzati in una lista 
concatenata
•Ogni elemento della lista contiene 
–un riferimento all'elemento successivo 
–un riferimento all'oggetto memorizzato
•Non è necessario stabilire una capacità iniziale
NOTA: Questi aspetti sono stati approfonditi nel 
corso ""Algoritmi e Strutture Dati""
52"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#52,52,"Programmazione orientata agli oggetti
LinkedList<E>  o ArrayList<E> ?
•Molto schematicamente:
–ArrayList<E>  conviene se:
•la dimensione è abbastanza stabile
•è necessario un accesso indicizzato (la classe ArrayList  
offre un metodo opportuno)
–LinkedList<E>  conviene se:
•la dimensione può variare anche significativamente
•gli accessi sono perlopiù sequenziali
•Nella pratica la complessità delle JVM moderne rende 
le differenze spesso impercettibili e/o comunque molto 
difficilmente prevedibili
Basare le ottimizzazioni sempre su misurazioni sperimentali 
che ne palesino ed accertino la reale necessità
53"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#53,53,"Programmazione orientata agli oggetti
Implementazioni di List<E>:  
Costruttori
•I costruttori sono sovraccarichi. In particolare facciamo 
osservare che esiste un costruttore che permette la 
creazione di una lista a partire da una collezione
•Costruttori di ArrayList<E>
–ArrayList<E>()  Constructs an empty list with an initial 
capacity of ten
–ArrayList( Collection<? extends E>  c) Constructs a list 
containing the elements of the specified collection, in the order 
they are returned by the collection's iterator 
–ArrayList<E>(int initialCapacity) Constructs an empty 
list with the specified initial capacity
•Costruttori di LinkedList<E>
–LinkedList<E> Constructs an empty list
–LinkedList<E>( Collection<? extends E>  c) Constructs a 
list containing the elements of the specified collection, in the 
order they are returned by the collection's iterator
54"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#54,54,"Programmazione orientata agli oggetti
Esercizio: List<E>
•La classe ArrayList<E>  implementa l'interfaccia 
List<E>  (e quindi è sottotipo anche di 
Collection<E> )
•Proviamo a rivedere il codice della classe Borsa 
nello studio di caso:
–anziché usare un array per memorizzare l'insieme 
di attrezzi, usiamo un ArrayList<E>
•Vediamo come gestiamo
–aggiunta di un elemento
–scansione della lista
55"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#55,55,"Programmazione orientata agli oggetti
Esercizio List<E> : Aggiunta di  Elementi
public class Borsa {
    private Attrezzo[] attrezzi;
    private int numeroAttrezzi;
    public Borsa() {
        this.numeroAttrezzi = 0;
        this.attrezzi = new Attrezzo[10];
    }
    public boolean addAttrezzo(Attrezzo attrezzo){
        if (numeroAttrezzi == 10)
            return false;
        this.attrezzi[this.numeroAttrezzi] = attrezzo;
        this.numeroAttrezzi++;
        return true;
    } …
}
import java.util.List;
import java.util.ArrayList;
public class Borsa {
    private List<Attrezzo> attrezzi;
    public Borsa() {
        this.attrezzi = new ArrayList<Attrezzo>();
    }
    public boolean addAttrezzo(Attrezzo attrezzo) {
        return this.attrezzi.add(attrezzo);
    }…
}
56array
ArrayList"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#56,56,"Programmazione orientata agli oggetti
Esercizio List<E> : Osservazioni
•Dobbiamo importare:
java.util.List
java.util.ArrayList
•Principali benefici rispetto all’uso degli array
–non ci dobbiamo preoccupare di stabilire a priori le 
dimensioni massime della collezione
–non ci dobbiamo preoccupare di gestire l'indicatore 
di riempimento, che memorizza il numero di 
elementi effettivamente memorizzati nell'array
57"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#57,57,"Programmazione orientata agli oggetti
Esercizio List<E> :
Aggiunta di Elementi
•L'aggiunta di elementi in un ArrayList<E>  viene 
realizzata tramite il metodo  add(E el)
•Questo metodo aggiunge un riferimento ad oggetto 
(istanza di tipo E) nell'ultima posizione della collezione
•Gli elementi della lista rimangono ordinati secondo 
l'ordine di inserimento
–l'oggetto inserito per primo è nella prima posizione
–l'oggetto inserito per secondo è nella seconda posizione
–… 
–l'oggetto inserito per ultimo è in ultima posizione
58"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#58,58,"Programmazione orientata agli oggetti
Esercizio List<E> : Osservazioni
•La lista aumenta la sua capacità se necessario
•Mantiene un conteggio del numero di elementi 
•Il metodo int size() restituisce questo valore
I dettagli di come tutto ciò viene realizzato ci 
viene nascosto
–È importante? 
–Non conoscere questi dettagli ci impedisce di usare la 
collezione?
Quanto  risulta difficile cambiare la scelta 
dell’implementazione?
–Ad es. passare da ArrayList  a LinkedList … 
59"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#59,59,"Programmazione orientata agli oggetti
Metodi Specifici di LinkedList<E>
LinkedList<E>  offre anche alcuni metodi “fuori” dalla 
interface List<E> e quindi non offerti anche da ArrayList<E>
Similarmente ArrayList<E>  offre costruttori (basati sulla 
capacità ) che LinkedList<E>  non offre
Sono metodi tesi ad evidenziare l’accesso efficiente da parte 
delle LinkedList<E>  in testa ed in coda
Ad es. 
addFirst()/Last()
getFirst()/Last()
removeFirst()/Last()
… 
Attenzione: utilizzarli rende meno intercambiabili le due 
implementazioni
Per questo si consiglia di dichiarare i tipi, a meno di forti 
motivazioni in senso contrario, utilizzando sempre le interface"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#6,6,"Programmazione orientata agli oggetti
Un Primo Sguardo: Collection<E> (2)
•L'interface Collection<E>  dichiara i metodi di 
una generica collezione
•Questi metodi permettono di svolgere 
operazioni quali:
–aggiungere un elemento alla collezione
–verificare la dimensione della collezione
–verificare se la collezione è vuota
–aggiungere tutti gli elementi di un'altra 
collezione
–ottenere un iteratore  con cui scandire la 
collezione
7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#60,60,"Programmazione orientata agli oggetti
Esercizio List<E> : 
Rimozione di un Elemento
61import java.util.List;
import java.util.ArrayList;
public class Borsa {
    private List<Attrezzi> attrezzi;
    …
    public Attrezzo removeAttrezzo(String nomeAttrezzo) {
        Attrezzo a = null;
        Iterator<Attrezzo> iteratore =
            this.attrezzi.iterator();
        while (iteratore.hasNext()) {
            a = iteratore.next();
            if (a.getNome().equals(nomeAttrezzo)) {
         iteratore.remove();
         return a;
         }
        }
       return null;
     }
    …
}Con ArrayList"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#61,61,"Programmazione orientata agli oggetti
Esercizio: ListIterator<E>
In realtà l’interface List affianca al factory method 
iterator()  di Collection  un metodo specifico per le 
liste (e non esistente per tutte le generiche collezioni)
Il metodo List<E>.listIterator()  restituisce un 
ListIterator<E>
ListIterator  estende Iterator
Studiare (consultando i javadoc) le differenze tra le due 
interface Iterator  e ListIterator
Scrivere dei test di unità sulla semantica dei metodi di 
ListIterator  verificando che continuino ad aver 
successo anche i test-case già scritti per il suo 
supertipo Iterator"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#62,62,"Programmazione orientata agli oggetti
Liste: Diagramma degli Oggetti
•Nel seguito introduciamo una notazione 
grafica per la rappresentazione di oggetti 
ArrayList  e LinkedList
–la rappresentazione proposta è una astrazione 
(molto semplificata, ma utile a fini didattici) 
della rappresentazione interna delle due 
implementazioni
63"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#63,63,"Programmazione orientata agli oggetti
ArrayList : Diagramma degli Oggetti 
64
:Attrezzo[]List<Attrezzo> lista;
lista = new ArrayList<Attrezzo>();
lista.add(new Attrezzo(""vite"",1);
lista.add(new Attrezzo(""dado"",2);
// DIAGRAMMA DA DISEGNARE QUANDO L’ESECUZIONE RAGGIUNGE QUESTO PUNTO
[0]
[1]
[2]
[3]
[4]
[…]
:Attrezzo
nome""vite""
peso  1  
:Attrezzo
nome""dado""
peso  2  lista
:ArrayList"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#64,64,"Programmazione orientata agli oggetti
LinkedList : Diagramma degli Oggetti 
65
:NodeList<Attrezzo> lista;
lista = new LinkedList<Attrezzo>();
lista.add(new Attrezzo(""vite"",1);
lista.add(new Attrezzo(""dado"",2);
// DIAGRAMMA IN QUESTO PUNTO
next
value
:Attrezzo
nome""vite""
peso  1  
nome""dado""
peso  2  lista
:LinkedList
 :Node
next
valuefirst
:Attrezzo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#65,65,"Programmazione orientata agli oggetti
Sommario
•Introduzione alle Collezioni
–Interface Collection<E>
–Iterare una collezione: Iterator<E>
–Rimuovere elementi da una collezione
•Liste Generiche
–aggiungere elementi
–iterare sugli elementi della lista
•Ordinamento di liste
–Comparable , Comparator
66"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#66,66,"Programmazione orientata agli oggetti
Ordinamenti e Ricerche
•Il JCF (in particolare la classe Collections ) 
include metodi che implementano algoritmi 
efficienti per 
–ordinare una lista
–ricercare la posizione di un elemento in una lista 
ordinata
–ricercare il min/max in una lista
67"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#67,67,"Programmazione orientata agli oggetti
Relazione d’Ordine
•Queste operazioni sono possibili solo se esiste 
una relazione d'ordine per il tipo degli 
elementi ospitati nella collezione
–in altri termini, gli elementi della lista devono 
sapersi confrontare
–oppure ci deve essere un oggetto esterno che sa 
come confrontare due oggetti della lista
Anche una relazione d’ordine su un supertipo 
degli elementi ospitati va bene
68"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#68,68,"Programmazione orientata agli oggetti
Definizione di un 
Criterio di Ordinamento
•La responsabilità di modellare il criterio di 
ordinamento può essere affidata, in alternativa:
–alla stessa classe degli oggetti contenuti, che deve 
implementare una apposita interfaccia 
java.lang.Comparable<T> 
(il cosidetto ordinamento «naturale » o  «interno»)
–ad una classe esterna alle classe degli oggetti 
contenuti;  tale classe esiste solo con l’obbiettivo di 
confrontarli, si chiama comparatore   e rispetta 
l’interfaccia java.util.Comparator<T> 
(il cosidetto ordinamento «esterno » )
69"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#69,69,"Programmazione orientata agli oggetti
L'Interface java.lang. Comparable<T>
•L'interface java.lang.Comparable<T>   consiste di 
un solo metodo:
public int compareTo(T that)
•Restituisce un valore che è: 
–minore, uguale, maggiore di zero a seconda che 
l'oggetto corrente this sia rispettivamente: 
–minore, uguale, maggiore dell'oggetto il cui riferimento 
è ricevuto come parametro formale that
70"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#7,7,"Programmazione orientata agli oggetti
Un Primo Sguardo:  Set<E>
•L'interface Set<E>  estende Collection<E> : è una 
collezione che non può contenere duplicati
•Offre tutti e soli i metodi della interface 
Collection , con la restrizione che le classi che la 
implementano si impegnano a non ammettere la 
presenza di elementi duplicati
–sarà necessario utilizzare un meccanismo di 
modellazione del criterio di equivalenza tra 
elementi dell’insieme
–bisognerà utilizzarlo per definire un criterio di 
equivalenza tra gli elementi ospitati nell'insieme
8"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#70,70,"Programmazione orientata agli oggetti
Utilizzi di java.lang.Comparable<T>
•Molte importanti classi della libreria standard già 
implementano l’interfaccia 
java.lang.Comparable<T> , adottando una 
semantica più o meno scontata. 
•Ad es.
–java.lang.String
–java.util.Calendar
–java.util.Date
–java.io.File
–java.net.URI
–tutte le classi wrapper
… e molte altre ancora
71"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#71,71,"Programmazione orientata agli oggetti
L'interface Comparable<T> : Esempio
public class Persona implements Comparable< Persona> {
private String nome;
private int eta;
public Persona(String nome, int eta) {
this.nome = nome;
this.eta = eta;
}
public String getNome() {
return this.nome;
}
public int getEta() {
return this.eta;
}
  @Override
public int compareTo( Persona that) {
return this.nome.compareTo(that.getNome());
}
}
72"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#72,72,"Programmazione orientata agli oggetti
Test di Persona.compareTo()
public class PersonaTest {
  @Test
public void testCompareTo() {
  Persona p1 = new Persona(""Paolo"", 10);
  Persona p2 = new Persona(""Valter"", 5);
    assertTrue(p1.compareTo(p2) < 0); // <0
  Persona p3 = new Persona(""Paolo"", 10);
  assertEquals(0, p1.compareTo(p3)); // 0 
  Persona p4 = new Persona(""Anna"", 8);
  assertTrue(p1.compareTo(p4) > 0); // >0 
}
}
73"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#73,73,"Programmazione orientata agli oggetti
Ordinamento «Naturale»
•Un ordinamento naturale di oggetti è definito dalla 
relazione d'ordine implementata dal metodo 
compareTo()  nell’interface Comparable<T>
•E’ possibile quindi operare su una  List<T> 
contenente oggetti che implementano Comparable<T> 
con metodi che utilizzino tale criterio di ordinamento:
–si possono effettuare ricerche efficienti
–si può calcolare il massimo e il minimo
–si può effettuare l'ordinamento
mediante i metodi offerti da Collections
74"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#74,74,"Programmazione orientata agli oggetti
Ordinamento di Liste: 
Collections.sort()
•Metodo statico Collections.sort() , in due 
versioni sovraccariche corrispondenti ai due 
diversi modi («naturale» vs «esterno») di fornire 
un criterio di ordinamento
•Segnatura per l’ordinamento naturale:
public static <T extends Comparable<? super T>>  
void sort(List<T> list)
75"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#75,75,"Programmazione orientata agli oggetti
Test dell’Ordinamento «Naturale»
public class OrdinamentoNaturaleTest {
  @Test
public void testSort() {
  List<Persona> l = new LinkedList<>();
  l.add(new Persona(""Valter"", 5));
  l.add(new Persona(""Paolo"", 10));
  l.add(new Persona(""Giacomo"", 7));
  l.add(new Persona(""Alessandro"", 8));
  Collections.sort(l);
    assertEquals(""Alessandro"", l.get(0).getNome());
    assertEquals(""Giacomo"",  l.get(1).getNome());
  assertEquals(""Paolo"", l.get(2).getNome());
    assertEquals(""Valter"", l.get(3).getNome());
}
76Se Persona non implementasse Comparable<Persona> ,  
si solleverebbe un errore già a tempo di compilazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#76,76,"Programmazione orientata agli oggetti
Ottenere Min & Max di una Lista
•Data una lista List<T>  i cui elementi implementino 
l'interface Comparable<T>,  può essere calcolato 
l'elemento massimo/minimo (rispetto all'ordinamento 
naturale) mediante i metodi statici di Collections : 
•Collections.mix()
•Collections.max()
public static < T extends Object &  Comparable<? super T>>
            T min/max(Collection<? extends T> coll)
…che semplifichiamo in:
public static <T extends Comparable<? super T>>
        T min/max(Collection<? extends T> coll)
77"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#77,77,"Programmazione orientata agli oggetti
Test del Calcolo Min & Max
di una Lista 
public class MinMaxTest {
  @Test
public void testMinMax() {
    List<Persona> l = new LinkedList<>();
 
    l.add(new Persona(""Valter""), 5);
    l.add(new Persona(""Paolo""), 10);
    l.add(new Persona(""Giacomo""), 7);
    l.add(new Persona(""Alessandro""), 8);
  
 assertEquals(""Alessandro"",Collections. min(l).getNome());
 assertEquals(""Valter"", Collections. max(l).getNome());
  }…
}
78✔ Se Persona non implementasse Comparable<Persona> ,  
si solleverebbe un errore a tempo di compilazione"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#78,78,"Programmazione orientata agli oggetti
Ordinamento «Naturale»: Limiti (1)
L’ordinamento naturale può essere definito al più 
una sola volta in ogni classe
In effetti può essere utilizzata una sola volta per 
ogni intera gerarchia di tipi !
Per capire perché, consideriamo due classi, 
Persona  e Studente , ove Studente  estende 
Persona , e prevediamo per entrambe un 
ordinamento «naturale»
–le persone sono ordinate per nome
–gli studenti sono ordinati per matricola"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#79,79,"Programmazione orientata agli oggetti
Ordinamento «Naturale»: Limiti (2)
public class Persona implements Comparable<Persona>  { 
  private String nome;
  public Persona(String nome) {  this.nome = nome; }
  public String getNome() {   return this.nome; }
  @Override
  public int compareTo(Persona that) {
    return this.getNome().compareTo(that.getNome());
  }
}
public class Studente extends Persona implements Comparable<Studente>  {
  private String matricola;
  public Studente(String nome, String matricola) {
    super(nome);
    this.matricola = matricola;
  }
  public String getMatricola() {  return this.matricola; }
  @Override
  public int compareTo(Studente that) {
    return this.getMatricola().compareTo( that.getMatricola());
  }
}
Persona
+getNome()
Studente
+getMatricola()
NON COMPILA!
The interface Comparable  
cannot be implemented 
more than once with 
different arguments: 
Comparable<Persona>  and 
Comparable<Studente>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#8,8,"Programmazione orientata agli oggetti
Un Primo Sguardo:  List<E>
•L'interface List<E>  estende Collection<E>  e 
corrisponde ad una sequenza, ovvero una 
collezione ordinata di elementi 
•Le liste, rispetto agli insiemi, possono contenere 
elementi duplicati
•Oltre alle operazioni offerte dal supertipo 
Collection<E> , l’interface List<E>  include altre 
operazioni specifiche, quali: 
–Accesso posizionale:  permette di accedere agli elementi 
di tipo E in base alla loro posizione nella lista (in maniera 
simile a quanto avviene per gli array)
–Ricerca: permette di ricercare la posizione di un 
elemento nella lista
9"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#80,80,"Programmazione orientata agli oggetti
Limitazioni dei Java Generics (1)
Alla stessa classe/interface (in generale tipo) non è 
permesso implementare la stessa interface generica 
più di una volta con tipi attuali distinti!
Chiaramente controintuitivo; contraddice almeno 
questi aspetti che lasciavano sperare altrimenti:
–una classe Java può implementare diverse interface
–si possono definire metodi sovraccarichi di stesso nome ma 
diversa segnatura per l’uso di tipi polimorfi (anche se pescati 
dalla medesima gerarchia)
In effetti è come se la piattaforma si rifiutasse di 
considerare diversi due tipi generici validi se differiscono 
solo per uno dei tipi attuali utilizzati
✔Ed è esattamente così..."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#81,81,"Programmazione orientata agli oggetti
Limitazioni dei Java Generics (2)
java.lang.Comparable  presente sin da Java 1.0
ovviamente non utilizzava i generics: introdotti solo in Java 5
Si basava su Object: Comparable .boolean compareTo(Object o)
L’irrinunciabile  retrocompatibilità ha imposto forti assunzioni 
sull’uso dei generics: in particolare NON risultò possibile cambiare 
le informazioni sui tipi (dinamici) disponibili a tempo di esecuzione 
rispetto alle versioni pre-generics
–Detto diversamente, ciascun tipo deve essere sempre distinguibile a 
tempo dinamico anche se cancelliamo i tipi attuali utilizzati nella 
definizione dei tipi generici e finalizzati a tempo statico
–A tempo dinamico non rimane traccia dei generics, che sono sempre 
risolti in un tipo non generico (chiamato «erasure») già a tempo di 
compilazione
✔Per motivazioni similari, non è possibile creare array generics
–Per es. T[] ag = new T[10]; // T tipo  NON COMPILA"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#82,82,"Programmazione orientata agli oggetti
Limitazioni dell’Ordinamento 
«Naturale» o «Interno» 
A causa di questa sfortunata interazione con le 
limitazioni dei generics, l’ordinamento naturale può 
essere definito in uno solo dei tipi di una gerarchia
–nell’es. di prima,  dentro Studente  oppure dentro Persona, 
ma non in entrambe
Pertanto, considerando:
–la necessità di definire molteplici criteri di ordinamento su 
oggetti dello stesso tipo (o della stessa gerarchia di tipi)
–nonché la necessità di disaccoppiare la definizione del criterio 
di ordinamento da quella della classe le cui istanze 
risulteranno ordinate
✔risulta ben motivato  l’utilizzo di soluzioni (per la definizione 
di un criterio di ordinamento) «esterne» alla classe"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#83,83,"Programmazione orientata agli oggetti
Ordinamento «Esterno»
•Se vogliamo ordinare una lista secondo un criterio 
diverso dall'ordinamento naturale?
•Segnatura per l’ordinamento esterno :
public static <T> void sort(
         List<T> listaDaOrdinare, 
 Comparator<? super T> comparatore
  )
•Si affida ad un oggetto esterno , passato come 
parametro,  per effettuare i confronti necessari 
all'ordinamento
✔unica soluzione possibile quando serve più di un 
criterio di ordinamento
84"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#84,84,"Programmazione orientata agli oggetti
L'Interface 
java.util. Comparator<T>
•L'interfaccia java.util.Comparator<T>  consiste 
di un solo metodo:
public int compare(T o1, T o2)
che deve restituire un valore che è 
–minore, uguale, maggiore di zero a seconda che 
l'oggetto riferito da o1 sia… 
–minore, uguale, maggiore dell'oggetto riferito dal 
parametro o2
✔(per ricordarselo: “come fosse o1 – o2 per un ord. crescente” )
✔N.B. la segnatura è simile ma non identica a quella del 
metodo compareTo()  di Comparable<T>
85"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#85,85,"Programmazione orientata agli oggetti
Esercizio (cont.)
import java.util.Comparator;
public class ComparatorePerEta
           implements Comparator<Persona> {
  @Override
  public int compare(Persona p1, Persona p2) {
return p1.getEta() - p2.getEta();
  }
}•Supponiamo di voler ordinare una lista di oggetti 
Persona  per età
•Introduciamo un opportuno comparatore esterno:
86"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#86,86,"Programmazione orientata agli oggetti
Test di 
Comparator<Persona>.compare()
// import omessi
public class ComparatorePerEtaTest {
@Test
public void testCompare() {
Persona paolo = new Persona(""Paolo"", 61);
Persona anna = new Persona(""Anna"", 55);
ComparatorePerEta comparator =
new ComparatorePerEta();
assertTrue(comparator.compare(paolo, anna) > 0);
assertTrue(comparator.compare(anna, paolo) < 0);
assertEquals(0,comparator.compare(paolo, paolo));
assertEquals(0,comparator.compare(anna, anna));
}
}
87"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#87,87,"Programmazione orientata agli oggetti
Test dell’Ordinamento «Esterno»
public class OrdinamentoEsternoTest {
  @Test
public void testSort() {
  List<Persona> l = new LinkedList<>();
  l.add(new Persona(""Valter"", 5));
  l.add(new Persona(""Paolo"", 10));
  l.add(new Persona(""Giacomo"", 7));
  l.add(new Persona(""Alessandro"", 8));
    ComparatorePerEta comparatore = 
new ComparatorePerEta();
  Collections.sort(l, comparatore);
    assertEquals(""Valter"", l.get(0).getNome());
    assertEquals(""Giacomo"", l.get(1).getNome());
  assertEquals(""Alessandro"", l.get(2).getNome());
    assertEquals(""Paolo"", l.get(3).getNome());
  }
88"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#88,88,"Programmazione orientata agli oggetti
Note Finali 
●L'interface Comparable<T>   è nel package java.lang , 
quindi non è necessario importarla
•L'interface java.util.Comparator<T>  è nel package 
java.util , quindi va importata esplicitamente
•In Collections  esistono anche i metodi per il calcolo 
del min/max secondo l’ordinamento esterno. 
Ad es.:
static <T>  T min(Collection<? extends T> coll, 
  Comparator<? super T> comp)
89"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#89,89,"Programmazione orientata agli oggetti
Esercizio
● Senza cambiare la classe  Libro (riportata di 
seguito), scrivere il metodo 
elencoOrdinatoPerPagine () della classe 
Biblioteca  affinché restituisca l'elenco dei 
libri ordinato per numero di pagine
90"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#9,9,"Programmazione orientata agli oggetti
Un Primo Sguardo: Map<K,V>
•L'interface Map<K,V>  offre le operazioni di una 
mappa, o dizionario: una mappa è una 
collezione di coppie chiave-valore
•L'interface Map<K,V>  dichiara i metodi per 
operazioni quali:
–Accesso per chiave: ottenere il valore associato ad 
una chiave
–Cancellare una coppia in cui compare una chiave
–Inserire una nuova coppia nella mappa
–Ottenere una collezione contente tutte le chiavi o 
tutti i valori
10"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#90,90,"Programmazione orientata agli oggetti
Esercizio (cont.)
public class Libro implements Comparable<Libro> {
    private String titolo;
    private int pagine;
    public Libro(String titolo, int pagine) {
        this.titolo = titolo;
        this.pagine = pagine;
    }
    public String getTitolo() {
        return this.titolo;
    }
    public int getPagine() {
        return this.pagine;
    }
    @Override
    public int compareTo(Libro libro) {
        return this.getTitolo().compareTo(libro.getTitolo());
    }
}
91"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#91,91,"Programmazione orientata agli oggetti
Esercizio (cont.)
import java.util.List;
import java.util.ArrayList;
public class Biblioteca {
    private List<Libro> elenco;
    public Biblioteca() {
        this.elenco = new ArrayList<>();
    }
    public void aggiungiLibro(Libro libro) {
        this.elenco.add(libro);
    }
    public List<Libro> elencoOrdinatoPerPagine() {
ComparatorePerPagine comp = new ComparatorePerPagine(); 
Collections.sort(this.elenco, comp);
    return this.elenco;
    }
}
92"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#92,92,"Programmazione orientata agli oggetti
Esercizio (cont.)
public class ComparatorePerPagine
 implements Comparator<Libro> {
 @Override
 public int compare(Libro l1, Libro l2) {
  return l1.getPagine() – l2.getPagine();
 }
}
93"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-15-collezioni-liste-generiche.pdf#93,93,"Programmazione orientata agli oggetti
Conclusioni
•Introduzione alle Collezioni
–Interacce principali
–Principali implementazioni
–Iteratori, e for-each
•Java Collection Framework
•Liste
•Ordinamento di liste
–Ordinamento Naturale
–Ordinamento Esterno
–Generics nelle gerarchie di tipi
94"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#0,0,"Programmazione 
Orientata agli Oggetti
Classi Astratte e 
Costanti Enumerative"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#1,1,"Programmazione orientata agli oggettiContenuti
•Classi astratte
•Metodi astratti
•Classi astratte o interface?
•Metodi e Classi finali
•Costanti enumerative
•Pre-Java 5
•Java 5 Enum
•Quando usarli
•Enum e Collezioni
2"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#10,10,"Programmazione orientata agli oggettiEsempio: Caratteristiche Generali
•Tutte le tipologie di personaggi condividono una parte 
della implementazione 
–le variabili per memorizzare nome e descrizione
–metodi accessori
–costruttori
–il codice che gestisce la risposta al saluto
•Tutte le tipologie di personaggi hanno un metodo 
(astratto) per modellare l'azione: 
abstract public String agisci(Partita partita);
•Tuttavia non ha senso definire sino al dettaglio il 
comportamento di un generico personaggio
il comportamento dipende infatti dalle specificità di 
ogni particolare personaggio
11"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#11,11,"Programmazione orientata agli oggettiEsempio (cont.)
•Ogni personaggio ha un comportamento specifico
–il mago ci dona un attrezzo
–la strega ci sposta in una stanza
–il cane morde
•Il codice che implementa l'azione è specifico del 
personaggio: ogni tipologia di personaggio ha la 
propria, specifica, implementazione
•In altri termini, il personaggio è definibile 
prescindendo da alcuni suoi dettagli che lo 
differenziano da tutti gli altri
–alcune sue proprietà possono essere «concrete» (fornite 
anche di una implementazione) 
–altre solo «astratte» (ovvero senza l’implementazione)
12"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#12,12,"Programmazione orientata agli oggettiEsempio: la Classe Astratta 
Personaggio  (1)
package it.uniroma3.personaggi;
import …
public abstract class AbstractPersonaggio {
private String nome;
private String presentazione;
private boolean haSalutato;
public AbstractPersonaggio(String nome, String presentaz) {
this.nome = nome;
this.presentazione = presentaz;
this.haSalutato = false;
}
public String getNome() {
return this.nome;
}
public boolean haSalutato() {
return this.haSalutato;
}
…13"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#13,13,"Programmazione orientata agli oggettiEsempio: la Classe Astratta 
Personaggio  (2)
public String saluta() {
StringBuilder risposta = 
new StringBuilder(""Ciao, io sono "");
risposta.append( this.getNome()+"".""); 
if (!haSalutato)
risposta.append(this.presentazione);
else
risposta.append(""Ci siamo gia' presentati!"");
this.haSalutato = true;
return risposta.toString();
}
abstract public String agisci(Partita partita);
@Override
public String toString() {
return this.getNome();
}
}
14"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#14,14,"Programmazione orientata agli oggettiLa Classe ComandoInteragisci
package it.diadia.comandi;
import ... 
public class ComandoInteragisci implements Comando {
private static final String MESSAGGIO_CON_CHI = 
                              ""Con chi dovrei interagire? ..."";
private String messaggio;
   private IO io;
@Override
public void esegui(Partita partita) {
AbstractPersonaggio personaggio;
personaggio = partita.getStanzaCorrente().getPersonaggio();
if (personaggio!=null) {
this.messaggio = personaggio.agisci(partita);
io.mostraMessaggio(this.messaggio);
    } else io.mostraMessaggio(MESSAGGIO_CON_CHI);
}
public String getMessaggio() {
return this.messaggio;
}
@Override
public void setParametro(String parametro) {}
}15"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#15,15,"Programmazione orientata agli oggettiEsempio: la Classe Mago
public class Mago extends AbstractPersonaggio  {
private static final String MESSAGGIO_DONO = "" Sei un vero simpaticone, "" +
""con una mia magica azione, troverai un nuovo oggetto "" +
""per il tuo borsone!"";
private static final String MESSAGGIO_SCUSE = ""Mi spiace, ma non ho piu' nulla... "";
private Attrezzo attrezzo;
public Mago(String nome, String presentazione, Attrezzo attrezzo) {
super(nome, presentazione);
this.attrezzo = attrezzo;
}
@Override
public String agisci(Partita partita) {
String msg;
if (this.attrezzo!=null) {
partita.getStanzaCorrente().addAttrezzo(this.attrezzo);
this.attrezzo = null;
msg = MESSAGGIO_DONO;
}
else {
msg = MESSAGGIO_SCUSE;
}
return msg;
}
}16"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#16,16,"Programmazione orientata agli oggettiClassi e Metodi Astratti
•Le classi astratte:
–utilizzano il modificatore abstract nella definizione
–non possono essere istanziate direttamente  (sebbene devono avere, 
anche solo implicitamente, almeno un costruttore!)
–definiscono implementazioni poi ereditate dalle sottoclassi
•I metodi astratti:
–utilizzano abstract nella segnatura
–non possiedono corpo
•La presenza anche di un solo metodo astratto rende 
necessaria la dichiarazione della classe come astratta
•ma una classe può essere dichiarata astratta anche se non possiede 
alcun metodo astratto (e non potrà essere istanziata)
•Le sottoclassi, per essere concrete ed istanziabili, devono 
completare l’implementazione sovrascrivendo tutti i metodi 
astratti (oppure, a loro volta, devono dichiararsi astratte…)
17"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#17,17,"Programmazione orientata agli oggettiClassi Astratte
•Servono a definire implementazioni parziali che 
verranno completate nelle classi concrete che le 
estendono
•Rispetto alle interface ?
–come le interface non possono essere istanziate
–diversamente dalle interface riportano una 
implementazione parziale e vengono estese
•Molto usate nei framework, ma la progettazione di 
framework va (ben!) oltre gli obiettivi formativi di 
questo corso...
18"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#18,18,"Programmazione orientata agli oggettiClassi Astratte vs Interface
•Classe astratta
–pro: permette di riutilizzare l’implementazione
–contro: limita fortemente le possibilità di estensione
la gerarchia delle implementazioni Java è lineare
•Interface
–pro: nessun limite di estensione
ereditarietà multipla delle interfacce
–contro: nessun meccanismo di riutilizzo del codice
•Come scegliere? 
–preferire le interface, meno vincolanti
–Valutare l’alternativa solo in presenza di codice e soprattutto 
logica da riutilizzare: per es. con i framework
19"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#19,19,"Programmazione orientata agli oggettiTesting di Classi Astratte (1)
•Qual è l’obiettivo del testing di classi astratte?
✔testare i metodi implementati direttamente nella 
classe astratta 
•Conviene definire una sua estensione concreta 
solo ai fini del testing
✔fornisce una implementazione concreta (e minimale ) dei 
metodi astratti per permettere la creazione dell’oggetto 
da testare
✔ad es. implementa i metodi astratti restituendo costanti 
•Si testano i metodi concreti della superclasse
20"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#2,2,"Programmazione orientata agli oggettiContenuti
•Classi astratte
•Metodi astratti
•Classi astratte o interface?
•Metodi e Classi finali
•Costanti enumerative
•Pre-Java 5
•Java 5 Enum
•Quando usarli
•Enum e Collezioni
3"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#20,20,"Programmazione orientata agli oggettiTesting di Classi Astratte (2)
public class FakePersonaggio extends AbstractPersonaggio {
public FakePersonaggio (String nome, String presentazione) {
super(nome, presentazione);
}
  @Override
public String agisci(Partita partita) {
return “done”; 
}
}
•Scriviamo la classe di test AbstractPersonaggioTest  
che verifichi il comportamento dei metodi concreti 
ereditati da AbstractPersonaggio
21"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#21,21,"Programmazione orientata agli oggettiEsercizi (1)
•Definire la classe Cane, che estende la classe 
AbstractPersonaggio : quando interagiamo con un cane, 
questi morde, togliendoci CFU!
•Definire il comando interagisci
•Introdurre AbstractComando  per eliminare i metodi 
replicati nelle implementazioni dell’interface Comando  e 
relativi alla gestione del nome e del parametro del 
comando
•Utilizzarla anche per ospitare l’oggetto IO per la gestione 
dell’input/output. Come offrire l’accesso alle sottoclassi?  
✔N.B. quest’ultimo utilizzo delle classi astratte risulta utile 
per esercitarsi con l’uso dello strumento ma è in nitido 
contrasto con la raccomandazione di limitare il loro utilizzo 
al caso di sufficiente logica duplicata
22"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#22,22,"Programmazione orientata agli oggettiEsercizi (2)
•Definire la classe Strega  come riportato nella 
descrizione precedente
è anche un buon esercizio sulle collezioni...
•Definire ed organizzare i test-case per tutte le 
classi appena introdotte; rifattorizzare i test-
case già prodotti per le classi modificate
23"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#23,23,"Programmazione orientata agli oggettiContenuti
•Classi astratte
•Metodi astratti
•Classi astratte o interface?
•Metodi e Classi finali
•Costanti enumerative
•Pre-Java 5
•Java 5 Enum
•Quando usarli
•Enum e Collezioni
24"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#24,24,"Programmazione orientata agli oggetti
Metodi e Classi final (1)
•Per evitare che un metodo possa essere ridefinito 
si usa il modificatore final
  public class ClasseConMetodoFinale {
    public final int nonMiPoteteSovrascrivere() {…}
  }
•In questo modo il metodo non può essere ridefinito 
nelle classi che estendono  ClasseConMetodoFinale
–viene sollevato un errore a tempo di compilazione
public class EstendeClasseConMetodoFinale
             extends ClasseConMetodoFinale {
  @Override                          
  public int nonMiPoteteSovrascrivere(){…}// ERRORE
}
25"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#25,25,"Programmazione orientata agli oggetti
Metodi e Classi final (2)
•E' possibile dichiarare final intere classi
public final class NonMiPoteteEstendere {
  …
}
•La classe NonMiPoteteEstendere  non può essere 
estesa
✔anche in questo caso errore a tempo di 
compilazione
public class EstendeClasseFinale 
    extends NonMiPoteteEstendere { // ERRORE
  …
 }
•Molte classi della libreria standard sono dichiarate 
final, un esempio per tutti: java.lang.String
26"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#26,26,"Programmazione orientata agli oggettiContenuti
•Classi astratte
•Metodi astratti
•Classi astratte o interface?
•Metodi e Classi finali
•Costanti enumerative
•Pre-Java 5
•Java 5 Enum
•Quando usarli
•Enum e Collezioni
27"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#27,27,"Programmazione orientata agli oggetti
Java Enum e Costanti Enumerative
•I metodi e le classi final sono stati inizialmente motivati da 
questioni legate alle sicurezza
•Hanno conosciuto un altro diffuso utilizzo, ma forse meno noto 
perché nascosto da un consistente strato di zucchero sintattico
•Costanti Enumerative:  valori costanti raccolti in insiemi finiti e stabili. Es.:
−i 12 mesi dell’anno ed i 7 giorni della settimana
−i 7 tipi di tetramino nel gioco T etris! 
−i 4 punti cardinali (>>)
•I Java Enum (da Java 5) consentono di modellare efficacemente 
insiemi di «costanti enumerative » usando opportunamente
–Classi astratte
–Classi final
–Costruttori privati"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#28,28,"Programmazione orientata agli oggetti
Enumerazioni (pre Java 5)
•Per capire il loro funzionamento, ed apprezzarne i vantaggi, 
conviene descrivere come venivano realizzati prima di Java 5,  
(versione in cui ne fu introdotto il supporto)
✔In effetti è la pratica tuttora utilizzata in C
•In assenza di un meccanismo dedicato, la modellazione di costanti 
enumerative ripiegava spesso nell’uso di generiche costanti di un 
tipo «preso in prestito »
•Ad esempio, mediante semplici numeri interi:
public interface Direzione {
   // Da NORD in senso orario
   static final public int NORD  = 0;
   static final public int OVEST = 1;
   static final public int SUD   = 2;
   static final public int EST   = 3;
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#29,29,"Programmazione orientata agli oggetti
Enumerazioni (pre Java 5)
•Principale vantaggio: semplicità ed immediatezza
•Importanti conseguenze negative, fra tutte una 
tipizzazione piuttosto lasca:
int direzione = 5; // COMPILA! Ma non dovrebbe… 
•Ne derivano molti svantaggi, ad es. Metodi con 
segnature di non immediata interpretazione:
 public int direzioneOpposta(int arg) { … }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#3,3,"Programmazione orientata agli oggettiIntroduzione (1)
•Abbiamo visto come l'estensione può essere 
uno strumento utile per il riuso del codice
•Le classi estese ereditano anche 
l'implementazione della classe base
–La classe estesa può avere variabili di istanza e 
metodi aggiuntivi a quelli ereditati dalla classe base 
–La classe estesa può ridefinire metodi della classe 
base
•La classe estesa è un sottotipo della classe 
base, quindi, vale il principio di sostituzione:
possiamo usare istanze di una classe estesa al 
posto delle istanze della classe base 
4"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#30,30,"Programmazione orientata agli oggetti
Enumerazioni Tipate (pre Java 5)
•Soluzioni più articolate prevedono infatti almeno la creazione 
di un tipo dedicato, per rendere i controlli a tempo statico e 
la tipizzazione più stringenti
•Una soluzione diffusamente utilizzata:
–classi final
–costruttori privati
public final class Direzione {
  private int ordinal;
  private Direzione(int index) { this.ordinal = index; }
  public int getOrdinal()      { return this.ordinal;  }
  static public final Direzione NORD  = new Direzione(0);
  static public final Direzione EST   = new Direzione(1);
  static public final Direzione SUD   = new Direzione(2);
  static public final Direzione OVEST = new Direzione(3);
  static private final Direzione[] cardinali = 
                                     { NORD, EST, SUD, OVEST };
  static public Direzione[] values() { return cardinali; } 
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#31,31,"Programmazione orientata agli oggetti
Enumerazioni Tipate (pre Java 5)
•Risolti i problemi legati alla tipizzazione lasca:
Direzione dir = new Direzione(5); // NON COMPILA
public Direzione direzioneOpposta(Direzione arg) {…}
•Nuove possibilità, ad es. cicli for-each:
for(Direzione dir : Direzione.values()) { … }
•Si può anche pensare di affiancare metodi (polimorfi) alle 
costanti. Ad es. per il calcolo della direzione opposta() :
import static Direzione.*;
assertEquals(SUD, NORD.opposta());
•Si rende però necessario creare un sottotipo per ogni 
costante della stessa enumerazione>>"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#32,32,"Programmazione orientata agli oggetti
Enumerazioni Polimorfe (pre Java 5)
public abstract class Direzione {
  private int ordinal;
  private Direzione(int index) { this.ordinal = index; }
  public int getOrdinal()      { return this.ordinal;  }
  abstract public Direzione opposta();
  static public final Direzione NORD  = new NORD();
  static public final Direzione EST   = new EST();
  static public final Direzione SUD   = new SUD();
  static public final Direzione OVEST = new OVEST();
  static final class NORD  extends Direzione   {
    private NORD()  { super(0); }
    @Override public Direzione opposta() { return SUD; }
  }
  // …similarmente per EST, SUD…  
  … 
  static final class OVEST extends Direzione   {…}
}Permette di dichiarare una
nuova classe interna (>>) e di 
invocare il costruttore privato"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#33,33,"Programmazione orientata agli oggetti
Limitazioni dell’Enumerazioni 
pre Java 5: Perché i Java 5+ Enum
•Efficace: ma per N costanti è necessario creare N+1 classi...
✔Decisamente macchinoso, anche con l’aiuto di un IDE evoluto
•I Java Enum introdotti in Java 5 sostanzialmente adottano 
questa stessa soluzione, ma in aggiunta offrono:
•Una sintassi meno verbosa; ad es. per  enum senza metodi 
aggiuntivi basta scrivere: 
  public enum Direzione {
      NORD, EST, SUD, OVEST;
  }
•Una superclasse astratta java.lang.Enum  condivisa da tutti i tipi 
enumerati
–con metodi condivisibili da tutti i tipi enumerati (es. ordinal() ) 
•Un generoso aiuto da parte del compilatore
–definisce alcuni metodi statici aggiuntivi (>>)"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#34,34,"Programmazione orientata agli oggetti
Java Enum: Sintassi
•In presenza di metodi aggiuntivi, la sintassi dei Java Enum in 
caso di enumerazioni polimorfe è più prolissa, ma comunque 
più compatta della soluzione “manuale”:
public enum Direction {
  NORD() { 
     @Override  public Direction opposta() {
        return SUD; 
     }
  },
  …
  OVEST() {
     @Override  public Direction opposta() { 
        return EST;
     }
  };
  public abstract  Direction opposta();
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#35,35,"Programmazione orientata agli oggetti
java.lang.Enum : Gerarchia
•Per ogni Enum dichiarato il compilatore genera
•Una sottoclasse (ad es. Direzione ) della classe astratta 
generica java.lang.Enum che modella il tipo enumerato
•Una sua sottoclasse per ciascun valore costante (ad es. NORD)
  public abstract class Enum< E extends Enum<E> >
                        implements Comparable<E>
java.lang.Enum
NORD
DirezioneDirezioneDirezione
OVEST
SUD
EST"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#36,36,"Programmazione orientata agli oggetti
java.lang.Enum : Costruttore
•La classe java.lang.Enum accentra funzionalità per 
tutti i tipi enumerati
•Ad es. metodi per gestire i numeri ordinali ( ordinal() ) ed il 
nome del tipo enumerato ( name())
•Unico costruttore:
Enum protected  Enum(String name, int ordinal)
Sole constructor. Programmers cannot invoke this constructor. It 
is for use by code emitted by the compiler in response to enum 
type declarations .
Parameters :
name - The name of this enum constant, which is the identifier 
used to declare it.
ordinal - The ordinal of this enumeration constant (its position 
in the enum declaration, where the initial constant is assigned 
ordinal 0)."
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#37,37,"Programmazione orientata agli oggetti
Java Enum: 
Costruttori delle «Costanti Enumerative »
•I valori costanti possono avere uno o più costruttori ed uno stato
•Si dichiara un costruttore privato solo nel tipo enumerato (es. 
Direzione )
•Lo stato deve essere immutabile (>>)
✔è preferibile dichiarare tutte le variabili di istanza final
public enum Direzione {
    NORD(0) {     @Override
                  public Direzione opposta() { return SUD; }
    },…,
    OVEST(270 ) {  @Override
                  public Direzione opposta() { return EST; }
    };  
    private final int gradi;
    private Direzione(int gradi)  { 
       this.gradi = gradi;
    }
    public int getGradi() { return this.gradi; }
    public abstract Direzione opposta();
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#38,38,"Programmazione orientata agli oggetti
java.lang.Enum : Metodi (1)
●Documentiamo la semantica degli altri metodi di 
java.lang.Enum
–tramite qualche test di unità, per es. sul tipo Direzione
–metodo ordinal( )
import static org.junit.Assert.*;
import org.junit.Test;
import static Direzione.*;
public class EnumTest {
    @Test
    public void testOrdinal() {
        assertEquals(0, NORD.ordinal());
        assertEquals(1, EST.ordinal());
        assertEquals(2, SUD.ordinal());
        assertEquals(3, OVEST.ordinal());
    }
… // altri test-case a seguire
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#39,39,"Programmazione orientata agli oggetti
java.lang.Enum : Metodi (2)
●Ogni tipo enumerativo è associato ad una classe per l’intero tipo più 
un oggetto-singleton/classe per ciascuno dei valori costanti del tipo 
●Le costanti ricordano la classe del loro supertipo (ed associato a 
tutta la collezione di costanti enumerative) mediante il metodo
Class<E> getDeclaringClass()
●returns the Class object corresponding to this enum constant's enum type.
public class EnumTest {… 
    @Test
    public void testGetDeclaringClass() {
        assertSame(Direzione.class, NORD.getDeclaringClass());
        assertNotSame(Direzione.class, NORD.getClass());
        assertNotSame(EST.getClass(), NORD.getClass());
        … // similarmente per le altre direzioni  
    }
…} "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#4,4,"Programmazione orientata agli oggettiIntroduzione (2)
•Abbiamo visto che anche le interface 
favoriscono il riuso del codice
•Grazie al principio di sostituzione possiamo 
scrivere codice con metodi polimorfi
–accettano come parametro formale un riferimento 
ad un tipo (statico) astratto
–il parametro attuale sarà un riferimento ad un 
sottotipo (dinamico) concreto di tale tipo
•Talvolta, classi diverse che implementano una 
medesima interface possono voler condividere 
anche una significativa porzione 
dell'implementazione
5"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#40,40,"Programmazione orientata agli oggetti
java.lang.Enum : Metodi (3)
●Ad ogni valore costante è associato un singolo oggetto (singleton)
●Evidente con un test sul metodo valuesOf() , che consente di 
creare gli oggetti associati alle costanti di un tipo enumerato anche 
senza scomodare la più “pesante” API sull’introspezione (>>)
public class EnumTest {… 
     @Test
     public void testTuttiSingleton() {
         assertSame(NORD, Direzione.valueOf(""NORD""));
         final Direzione singleton = Direzione.valueOf(""NORD"");
         assertSame(singleton, NORD);
         …
         assertNotSame(EST, NORD);
        … // similarmente per le altre direzioni  
     }
 }"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#41,41,"Programmazione orientata agli oggetti
Enumerazioni: Criterio di Equivalenza (1)
●Quindi riassumendo:
–ogni tipo enumerato di N valori costanti genera N+1 classi
–di queste N sono singleton (classi a singola istanza) che 
modellano i valori
–ad ogni valore corrisponde quindi una sola classe che 
possiede una sola istanza 
●Tutto questo si riflette sul criterio di equivalenza dei 
tipi enumerati che risulta essere quello più naturale
●Ciascuno dei valori costanti è un oggetto che  
–è equivalente solo a se stesso
–non è equivalente a nessuno degli altri  "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#42,42,"Programmazione orientata agli oggetti
Enumerazioni: Criterio di Equivalenza (2)
●equals()  e l’operatore  ==  finiscono per modellare lo stesso 
criterio di equivalenza
✔ATTENZIONE! NON è affatto vero in generale: vale solo per i tipi 
enumerativi!
●hashCode()  ritorna il valore restituito dal metodo ordinal()
✔HashSet ed HashMap su tipi enumerativi possiedono prestazioni 
ottimali (non esistono conflitti!)
public class EnumTest {… 
   @Test
   public void testCriterioDiEquivalenza() {
       assertEquals(NORD, NORD);
       assertNotEquals(NORD, EST);
       assertNotEquals(NORD, SUD);//…
        … // similarmente per le altre direzioni  
   }…
} "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#43,43,"Programmazione orientata agli oggetti
Enumerazioni: Ordinamento
●E’ direttamente quello basato sul valore ordinale
✔N.B. Induce anche un criterio di equivalenza basato 
sull’identicità degli oggetti
✔Ovvero come l’operatore == 
public class EnumTest {… 
   @Test
   public void testCompareTo() {
     assertTrue(NORD.compareTo(EST)<0);
     assertTrue(EST.compareTo(SUD)<0);
     assertTrue(SUD.compareTo(OVEST)<0);
     assertTrue(OVEST.compareTo(NORD) >0);
   }  
…} "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#44,44,"Programmazione orientata agli oggetti
Enum.toString() / name()
●Non è necessario ridefinire un metodo toString()  
in quanto è naturalmente definito sulla base del 
nome stesso della costante
String name()
–Returns the name of this enum constant, as declared in its enum declaration.
String toString()
–Returns the name of this enum constant, as contained in the declaration.
public class EnumTest {… 
   @Test
   public void testToStringAndName() {
     assertEquals(""NORD"", NORD.toString());
     assertEquals(""NORD"", NORD.name());
    … // similarmente per le altre direzioni  
   }…
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#45,45,"Programmazione orientata agli oggetti
Java Enum e Metodi «Fantasma » (1)
●I Java Enum introducono «zucchero sintattico »: la controparte nei sorgenti 
di codice oggetto generato non risulta osservabile
✔si pensi a boxing-unboxing (<<)
●Sorprendentemente, anche alcuni metodi appaiono, in particolare il 
metodo statico values() ed anche valueOf()  
✔Metodi di cui non esiste il codice sorgente!
✔Eclipse non fornisce meta-informazioni ! (e javadoc)
●Il compilatore genera automaticamente questi metodi adottando un 
comportamento particolare per tutte le classi che estendano  
java.lang.Enum :
public class EnumTest {… 
   @Test
   public void testValues() {
      final Direzione[] expected = { NORD, EST, SUD, OVEST } ;
      assertArrayEquals (expected , Direzione. values());
   }…
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#46,46,"Programmazione orientata agli oggetti
Java Enum e Metodi «Fantasma » (2)
●Per avere documentazione è necessario riferirsi 
direttamente alla Java Language Specification
/**
* Returns an array containing the constants of this enum 
* type, in the order they're declared.  This method may be
* used to iterate over the constants as follows:
*    for(E c : E.values())
*        System.out.println(c);
* @return an array containing the constants of 
* this enum type, in the order they're declared */
public static E[] values();
/**
* Returns the enum constant of this type with the specified name.
* The string must match exactly an identifier used to declare
* an enum constant in this type.  (Extraneous whitespace 
* characters are not permitted.)
* @return the enum constant with the specified name
* @throws IllegalArgumentException if this enum type has no
* constant with the specified name */
public static E valueOf(String name);Il metodo statico 
values()  rende 
possibile usare cicli 
«for-each» sopra tipi 
enumerati"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#47,47,"Programmazione orientata agli oggetti
Java Enum e «Switch-Statement »:
●E’ possibile usare tipi enumerati direttamente negli 
«switch statement »;  in precedenza era possibile farlo 
solo per le costanti letterali
import static Direzione.*;
public class DirezioneUtils {
  public static Direzione opposta(Direzione direzione) {
    switch (direzione) {
      case NORD:  return SUD;
      case EST:   return OVEST;
      case SUD:   return NORD;
      case OVEST: return EST;
      default:    return null;
    }
  }
}"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#48,48,"Programmazione orientata agli oggetti
Conclusioni:
Costanti Enumerative - Quando Usarle? (1)
•Quando è opportuno utilizzare costanti 
enumerative?
•Quando l’insieme di elementi da modellare:
✓è finito
✓tutti i suoi elementi siano già noti
✓è «stabile»: molto difficilmente cambierà nel tempo
•Quando per gli elementi ospitati:
✓ne conosciamo i nomi... «propri»
•ad es. “NORD”, “GENNAIO”
✓possono anche avere uno stato, purché immutabile
•inutile/impossibile crearne diverse «istanze»"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#49,49,"Programmazione orientata agli oggetti
Conclusioni:
Costanti Enumerative - Quando Usarle? (2)
•Ed inoltre:
–Il dominio suggerisce
•una tipizzazione forte (concetto di “primo ordine”)
•un tipo dedicato alla collezione di costanti
–Anche per  l’esigenza di aggiungere metodi (polimorfi) 
alle costanti 
•Ad es. Direzione.opposta()"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#5,5,"Programmazione orientata agli oggettiMotivazioni
•Nella pratica, capita di voler definire classi base 
pensate solo per essere estese e non per essere 
direttamente istanziate
✔allo scopo di evitare duplicazioni nel codice
✔Per favorire la qualità interna (<<) 
•Queste classi contengono una parziale 
implementazione da condividere con le sottoclassi
–variabili di istanza
–implementazione di alcuni metodi
•cosidetti metodi «concreti»
–segnatura di altri metodi
•cosidetti metodi «astratti»
•I metodi che rimangono privi di implementazione 
nella classe base possono poi essere «completati » 
nelle classi derivate6"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#50,50,"Programmazione orientata agli oggetti
Esercizio (Studio di Caso)
●Introdurre l’enumerazione Direzione  nello studio 
di caso per modellare con un tipo dedicato le 
direzioni degli spostamenti e delle adiacenze tra 
oggetti Stanza
✔Attualmente si «prende in prestito» il tipo String
✔Ma attenzione, è un sintomo di cattiva 
«modellazione »:
http://c2.com/cgi/wiki?StringlyTyped"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#51,51,"Programmazione orientata agli oggetti
Esercizio (Tetris)
●Studiare il codice dell’esercitazione «T etris», in 
particolare nel package tetris.tetramino
●Perché si è deciso di separare la modellazione del 
tetramino (classe tetris.tetramino.Tetramino ) da 
quella del suo tipo ( enum tetris.tetramino.Tipo )?
●Suggerimento:
–Da quale campi è composto lo stato degli oggetti istanza dei due 
tipi? 
–Quali sono o possono essere dichiarati final?
–Quale dei due tipi possiede uno stato mutabile?
●Cosa accadrebbe se fondessimo le due classi 
addossando le responsabilità di Tipo alla classe 
Tetramino ? "
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#52,52,"Programmazione orientata agli oggetti
Enum e Collezioni
●Le costanti enumerative finiscono per costituire un 
tipo  di collezione di caratteristiche particolari
●Sono possibili rappresentazioni ancora più compatte 
ed efficienti rispetto alle generiche collezioni (che già 
sono particolarmente efficienti sui tipi enumerativi)
●Dai javadoc di java.util.EnumSet
–Implementation note: All basic operations execute in 
constant time. They are likely (though not guaranteed) to 
be much faster than their HashSet counterparts. Even bulk 
operations execute in constant time if their argument is 
also an enum set.
●Vedere anche java.util.EnumMap
–Specializzazione di java.util.Map  che utilizza come chiavi 
un tipo enumerativo"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#53,53,"Programmazione orientata agli oggetti
Conclusioni
●L’insieme dei meccanismi offerti da un linguaggio per 
la modellazione dei tipi è uno degli aspetti più 
caratterizzanti lo stesso
●Con le classi astratte abbiamo coperto l’insieme dei 
principali meccanismi per la definizione dei tipi:
●Interface
●Classi
●Classi astratte
●Generics
●Esistono ancora altri meccanismi:
●Tipi enumerativi
●Classi nidificate (>>)
meno importanti dei precedenti, ma che 
contribuiscono alla richezza del sistema dei tipi in Java"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#6,6,"Programmazione orientata agli oggettiClassi Astratte
•Una classe astratta contiene una definizione parziale della 
implementazione
•Una classe astratta non può essere istanziata , ma possono 
essere istanziate le classi (concrete) che la estendono
•Ovviamente vale la relazione sottotipo-supertipo, e quindi il 
principio di sostituzione
i riferimenti alle istanze delle classi che estendono una classe 
astratta possono essere usate quando è atteso un riferimento 
ad una istanza della classe base
✔Analogie con le interface: 
–le interface non possono essere istanziate, ma possono essere istanziati 
oggetti di classi che le implementano
–vale il principio di sostituzione
✔Differenze  con le interface:
–le interface NON contengono implementazione (non più vero da Java 8+!!!)
7"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#7,7,"Programmazione orientata agli oggettiEsempio (Caso di Studio)
•Supponiamo di voler introdurre nel nostro gioco dei 
personaggi (es. mostri, maghi, ecc.)
•I personaggi sono nelle stanze del gioco (per semplicità 
accontentiamoci di un singolo personaggio per stanza)
import … 
public class Stanza {    
private String nome;    
private Map<String, Stanza> uscite;    
private Map<String, Attrezzo> nome2attrezzo;
private AbstractPersonaggio personaggio;
… … …
public void setPersonaggio(AbstractPersonaggio personaggio) {
this.personaggio = personaggio;
}
public AbstractPersonaggio getPersonaggio() {
return this.personaggio;
}
…
}
8"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#8,8,"Programmazione orientata agli oggettiEsempio (Caso di Studio)
•I personaggi hanno un nome (una stringa) ed una 
descrizione (una stringa)
•I personaggi possono rispondere al saluto del 
giocatore
ointroduciamo il comando saluta per salutare il 
personaggio presente nella stanza
•I personaggi possono agire
ointroduciamo il comando interagisci : provoca 
l’interazione del giocatore con il personaggio presente
9"
data_test\rootfolder\università\ProgrammazioneOggetti\POO-20-classi-astratte-enum.pdf#9,9,"Programmazione orientata agli oggettiEsempio: i «Personaggi»
•Possiamo introdurre diverse tipologie di 
personaggi. Ad esempio potremmo avere:
–Mago: possiede un attrezzo che può donare
–Strega: se interagiamo con una strega questa ci 
trasferisce in una stanza tra quelle adiacenti. 
Siccome è permalosa:
•se non l’abbiamo ancora salutata, ci «trasferisce» nella 
stanza adiacente che contiene meno attrezzi
•altrimenti in quella che contiene più attrezzi
–Cane: morde! Ogni morso diminuisce i CFU del 
protagonista
10"
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#0,0," 
 
 
 
 
 
 
POSITION PAPER  
Alimentazione e sost enibilità  
Quale relazione e quali sfide p er i prossimi anni  
Dialoghi Italo -Francesi per l’Europa , 20 giugno 2019 , Science s Po – Parigi  
 
 
 
Perché oggi è importante parlare di 
sostenibilità  
1. Il Position Paper  ha l’obiettivo di 
sostanziare la crescente rilevanza 
dell’alimentazione per lo sviluppo 
sostenibile. Verranno declinati gli impatti 
dell’adozione di abitudini alimentari sane e 
sostenibili  sul benessere individuale e 
collettivo  (salute e qualità della vita e 
sostenibilità economica per i sistemi 
sanitari nazionali) e sull’ ambiente . Il 
Position Paper  rientra nell’ambito 
dell’ iniziativa “ Dialoghi Italo -Francesi per 
l’Europa ”: la re lazione tra alimentazione e 
sostenibilità e i relativi impatti saranno  
quindi  contestualizzati per l’Italia e la 
Francia, all’interno del lo scenario  europeo.   
2. Il contesto socio -economico attuale è 
caratterizzato da grande velocità e 
accelerazione del cambi amento . Per poter 
perseguire un continuo miglioramento in 
termini di competitività economica, 
innovazione e prestazioni ambientali, i 
sistemi -Paese devono affiancare ai propri 
percorsi di crescita una nuova dimensione , 
                                                 
1 Fonte: elaborazione The European House – Ambrosetti 
su dati Global Footprint Network, 2019.  quella della  sostenibilità . Ciò implica  che 
i processi di cambiamento devono essere 
tali per cui lo sfruttamento delle risorse, la 
direzione degli investimenti, lo sviluppo 
tecnologico e i processi decisionali delle 
Istituzioni siano orientati a  garantire i 
bisogni del le generazioni future , oltre che 
di quelle attuali.  
3. La sfida dello sviluppo sostenibile deve fare 
i conti con  una popolazione mondiale in 
rapida crescita:  secondo le Nazioni Unite,  
la popolazione globale raggiungerà  i 9,8 
miliardi  entro il 2050  (+27%  rispetto ad 
oggi) . In aggiunta, l’attuale regime  di 
sfruttamento delle risorse ambientali  sta 
compromettendo la capacità naturale di 
rigenerazione necessaria dell’ ecosistema: 
basti pensare  che nel 2018 l’ Earth 
Overshoot Day , il giorno in cui la 
popolazione mondiale ha consumato tutte 
le risorse terrestri disponibili per l’anno, è 
stato raggiunto il 1° agosto , oltre 150  giorni  
prima di quanto accadeva 40 anni fa .1 
 La sostenibilità ha impatto a 360˚ sull'industria , le imprese e la vita di tutti i giorni ed è diventata una 
priorità strategica per le aziende. Nel settembre 2015, l’Organizzazione delle Nazioni Unite ha varato 
l’Agenda 2030 per lo Sviluppo Sostenibile, introducendo 17 Obiettivi di Sviluppo Sostenibile  (SDGs)  che 
riguardano tutte le dimensioni della vita umana e del pianeta.  
Una sana e corretta alimentazione ha un impatto diretto su 7 dei 17 SDGs  e può contribuire allo sviluppo 
sostenibi le attraverso due leve fondamentali: salute  e benessere individuale e collettivo  e 
sostenibilità ambientale . Abitudini alimentari sane ed equilibrate contribuiscono a ridurre il rischio di 
contrarre alcune patologie ( tra le quali diabete, tumori, malattie cardiovascolari), con impatti positivi anche 
sulla sostenibilità economica dei sistemi sanitari nazionali. In aggiunta, una dieta equilibr ata è associata 
anche ad un minor impatto sull’ecosistema ambientale, con effetti positivi sulla sostenibilità del pianeta.  
In questo contesto, una solida partnership  tra Italia e Francia  può dare un contributo significativo 
allo sviluppo sostenibile . I due Paesi , caratterizzati da una tradizione alimentare consolidata, potrebbero 
farsi ambasciatori dei benefici della dieta mediterranea nel mondo e promuovere  un dibattito sui benefici 
associati a stili alimentari sani e sostenibili anche nelle sedi europe e di riferimento.  
 
 
  
"
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#1,1,"2 
 4. Il benchmark su cui governi, imprese e 
società civile devono fondarsi per costruire 
processi decisionali attuativi aperti e 
partecipati verso un sentiero di 
sostenibilità  sono i Sustainable 
Development Goals . Il 25 settembre 
2015 l’Assemblea Generale delle Nazioni 
Unit e ha adottato l’Agenda 2030 per lo 
Sviluppo Sostenibile , introducendo  17 
Obiettivi di Sviluppo Sostenibile  
(Sustainable Development Goals  – SDGs) , 
declinati in  169 target  che riguardano a 
360° tutte le dimensioni della vita umana e 
del pianeta.  
5. Riconoscendo l’importanza della titolarità 
nazionale degli SDGs, le Nazioni Unite 
incoraggiano i Paesi a sviluppare una 
propria strategia basata sui 17 indicatori di 
riferimento.  
6. In Italia , il progresso verso lo sviluppo 
sostenibile viene monitorato attra verso gli 
indicatori BES  (Indicatori di Benessere 
Equo e Sostenibile): l’Istat ha sviluppato 
un approccio multidimensionale per 
misurare le fondamentali dimensioni del 
benessere del Paese, corredando dati di 
attività economiche c on misure relative a 
disegu aglianze , aspetti sociali, di 
innovazione  e di sostenibilità.  Sono stati 
individuati 130 indicatori, raggruppati in 
12 domini del benessere considerati di 
maggior rilievo  per il sistema -Paese . Dal 
2016 , il Governo italiano ha posto questi 
temi al centro de lla propria politica di 
programmazione economica, includendo 
un set di indicatori del BES nel Documento 
di Economia e Finanza, in cui  annualmente  
viene elaborata un’analisi sul loro 
andamento e una valutazione d’impatto 
delle politiche proposte sulle dimen sioni 
chiave dello sviluppo sostenibile . 
7. La Francia ha deciso di intraprendere un 
percorso analogo , definendo una serie di 
indicatori che consentono  di monitorare le 
politiche pubbliche nazionali  che 
contribuiscono alla sostenibilità. 
Nell’ambito del Conseil National de 
l’Information Statistique (CNIS) , sono 
stati istituiti 98 indicatori di sostenibilità al 
2030  che entreranno a far parte della 
programmazione economica del Governo 
entro giugno 201 9, insieme alla definizione 
di una “tabella di marcia verso la 
sostenibilità ”.  
8. L’alimentazione può dare un contributo 
significativo allo sviluppo sostenibile,  in 
quanto trasversale ad una pluralità di 
dimensioni  fondamentali per il benessere 
delle persone , degli ecosistemi ambientali 
e dei sistemi economici . 
                                                 
2 Fonte: elaborazione The European House – Ambrosetti  
su dati FAO, OMS e Nazioni Unite, 2019.    
9. Ad oggi  esistono ancora  grandi paradossi 
che ostacolano il raggiungimento di 
modelli sostenibili  e che legano cibo, salute 
e sostenibilità ambientale . Tra principali : 
— la denutrizione colpisce 821 milioni 
di persone  e allo stesso tempo quasi 
2 miliardi di persone  sono in 
condizioni di sovrappeso o obesità ; 
— i decessi causati  da obesità , 30 milioni 
ogni anno, stanno gradualmente 
raggiungendo quell i causa ti da 
denutrizione  (35 milioni) ;2 
— denutrizione e obesità sono spesso 
strettamente correlate , soprattutto nei 
Paesi in via di sviluppo . Alcune  
ricerche in campo medico hanno 
messo in evidenza  come la 
denutrizione infantile possa  essere uno 
dei fattori predittivi dell’obesità da  
adulti e dei disturbi ad essa correlati ;3 
3 Fonte: elaborazione The European House – Ambrosetti 
su dati The Lancet, 2019.  
Figura 1. I 17 Obiettivi di Sviluppo Sostenibile 
dell’Organizzazione delle Nazioni Unite e quelli 
direttamente influenzati da un’alimentazione sostenibile 
(riquadrati in rosso). Fonte: elaborazione The European 
House – Ambrosetti su dati Nazioni Unite, 2019 . "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#10,10,"11 
 69. I benefici di un’alimentazione 
corretta in termini di costi evitati  
sarebbero notevoli : ipotizzando che tutta la 
popolazione  europea segua  i dettami della 
dieta mediterranea, e che quindi le quote 
percentuali correlate alla malnutrizione tra 
i fattori di rischio si annullino , l’ordine di 
grandezza ammonterebbe a decine di 
miliardi di Euro  risparmiati, anche a livello 
di singolo  sistema -Paese . Un caveat  da 
considerare nell’interpretazione di questi 
risultati è  che la correlazione tra 
l’abbattimento del fattore di rischio ed un  
eventuale costo non più sostenuto, però, 
non è 1:1 .  
Il contributo dell’alimentazione alla 
sostenibilità ambientale  
70. La seconda leva attraverso la  quale 
l’alimentazione ha un impatto 
considerevole  sulla sostenibilità  è quella 
ambientale : basti pensare che un 
quarto  dei gas serra generati ogni anno 
dagli esseri umani proviene dal sistema 
alimentar e. La filiera agroalimentare 
produce numerose esternalità sia a monte, 
con le attività del settore dell’agricoltura, 
sia a valle, attraverso l’uso alimentare 
domestico o di operatori del settor e.  
71. Diverse analisi sulla correlazione tra cibo e 
ambiente hanno fatto emergere come gli 
alimenti per cui i nutrizionisti 
suggeriscono un consumo maggiore in una 
dieta salutare  siano anche quelli che 
generano il minor impatto sull’ecosistema 
ambientale . In altre parole, “ ciò che fa 
bene all’uomo fa bene anche al 
pianeta ”.  
72. Nel capitolo precedente è  stato descritto 
come la rappresentazione triangolare su 
più livelli della piramide alimentare abbia 
la funzione di illustrare con quale 
                                                 
18 Le proiezioni delle Nazioni Unite sono ulteriormente al 
rialzo, secondo cui il consumo di carne aumenterà del 76%.  frequenza è preferibile il consumo degli 
alimenti caratterizzanti le diete per uno 
stile di vita sano . Sulla base delle  scoperte 
che correlano alimentazione e ambiente, la 
stessa piramide può essere rovesciata  
(Figura 19) per illustrare questo assunto: 
l’impatto  ambientale degli alimenti che 
fanno bene alla salute (base della piramide 
alimentare ) è il più limitato  e rappre senta  
la punta della piramide alimentare 
rovesciata, mentre l’impatto del consumo 
degli alimenti più dannosi per la salute 
(vertice  della piramide alimentar e) è il più 
elevato, dove troviamo la base della 
piramide alimentare rovesciata.  
 
73. L’impatto ambienta le dei singoli alimenti è 
quantificabile tramite l’analisi del ciclo 
di vita , utilizzando tre dimensioni:  
— water footprint , che quantifica i 
consumi e le modalità di utilizzo delle 
risorse idriche , ed è misurato in volumi 
d’acqua (litri) ; 
— ecological footprint , che calcola la 
quantità di terra (o mare) 
biologicamente produttiva necessaria 
per fornire le risorse al sistema ed 
assorbire le emissioni associate a un 
sistema produttivo ; 
— carbon footprint , che misura le 
emissioni di gas serra responsabili dei 
cambiamenti climatici in termini di 
massa di CO 2 equivalente .  
74. Gli ecosistemi sono sottoposti ad un a forte 
pressione  a causa del  costante aumento 
della popolazione  e del reddito pro-capite , 
soprattutto in quei Paesi  dove la carne 
rappresenta l’elemento portante della dieta 
delle popolazioni residenti. Secondo la 
FAO, le proiezioni  sul consumo di carne 
vedono un incremento del 70% entro il 
2050  rispetto ai livelli odierni18: gli 
allevamenti intensivi  – così dannosi per il 
benessere degli animali oltre che per le 
esternalità negative provocate – nei Paesi 
Figura 19. La piramide alimentare rovesciata.  Fonte: 
elaborazione The European House – Ambrosetti per Barilla 
Center for Food and Nutrition, 2019.  
Figura 20. Consumi di carne annui pro -capite nel 
mondo per macro -area geografica (kg), 2015.  Fonte: 
elaborazione The European House – Ambrosetti su dati 
FAO, 2019. 
95,7
65,3
50
41,3
31,6
28,6
10,9Paesi industrializzati
America Latina
Sud-Est Asiatico
Mondo
Paesi in via di sviluppo
Nord Africa/Medio Oriente
Africa Sub-Sahariana"
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#11,11,"12 
 in via di sviluppo risultano cruciali per 
sfamare una popolazione in continua 
espansione.   
75. Non solo le popolazioni in via di sviluppo 
stanno aumentando in numeri e 
potere  d’acquisto, ma stanno anche 
evolvendo la  loro dieta verso abitudini 
“occidentalizzate”. Ad oggi, però, il  
consumo pro-capite  di carne dei Paesi  
industrializzati è estremamente superiore 
a quello delle altre macro -regioni  (Figura 
20), e non sarebbe quindi da utilizzare 
come benchmark  per una dieta corretta.  
76. I trend  futuri accendono un forte 
campanello d’allarme per i sistemi 
produttivi, in quanto per produr re proteine 
animali è necessario un ammontare di 
risorse notevolmente superiore se 
raffrontato alla produzione della stessa 
quantità di proteine vegetali : 
appezzamenti di terreno più grandi, più 
energia e più acqua.  
77. Guardando alle risorse idriche necessarie 
alla produzione degli alimenti – il water 
footprint  – in Figura 2 2 si evince come la 
produzione di carne abbia un impatto di 
gran lunga maggiore rispetto ad ogni altro 
tipo di  alimento  e come invece i prodotti 
                                                 
19 Fonte: elaborazione The European  House – Ambrosetti 
su dati FAO, Barilla Center for Food and Nutrition e The 
European House – Ambrosetti, 2019.  alla base della piramide alimentare (o alla 
punta della piramide alimentare 
rovesciata) siano quelli che necessitano  di 
ridotti volumi di risorse idriche.  
78. L’Organizzazione delle Nazioni Unite ha 
stimato un range  tra 20 e 50 litri d’acqua 
quale fabbisogno minimo giornaliero pro-
capite  necessario ad assicurare i bisogni 
primari legati all’alimentazione e all’igiene. 
Dai dati sull’ impronta idrica degli alimenti , 
emerge come l’acqua necessaria per 
produrre solamente un kg di carne di 
manzo sarebbe sufficiente a garantire il 
fabbisogno idr ico medio di una persona per 
310 giorni.  
79. Oltre a d ingenti volumi d’acqua , la 
produzione di un kg di carne bovina 
necessita anche di 7 -8 kg di grano: in media, 
per ogni caloria di origine animale 
prodotta , ci vogliono ben 7 calorie di cereali. 
Di conseguen za, un aumento dei consumi 
di carne sta contemporaneamente 
richiedendo un incremento del fabbisogno 
di terreni agricoli  destinati esclusivamente 
agli allevamenti di bestiame. Il paradosso è 
che se la quantità di cereali destinata 
all’allevamento di bestiam e venisse 
impiegata nell’alimentazione umana, 
teoricamente si potrebbero nutrire 2,5 
miliardi di persone.19 
80. Il settore dell’allevamento rappresenta il 
maggiore fattore di uso antropico 
delle terre  a livello mondiale. Secondo le 
ultime stime, il 71%  dei terreni agricoli in 
UE è utilizza to per gli allevamenti di 
bestiame, di cui solo l’8% destinato alle 
aree di pascolo e agli stabilimenti ; la 
restante parte diventa terra arabile 
destinata alla coltivazione di mangime per 
gli animali.20 Allo stesso modo, la 
considerevole crescita dell’allevamento in 
atto dagli anni ’80 ha determinato un 
significativo fenomeno di deforestazione  e 
di perdita di ettari di aree incontaminate , 
soprattutto in America Latina.  
81. Ne consegue che l’ ecological  footprint  di 
queste attività in termini di consumi di 
suolo ed erosione degli habitat  assume un 
valore significativo in un contesto in cui la 
capacità di rigenerazione degli ecosistemi 
ambienta li è sempre più messa a rischio.  
82. La tutela degli ecosistemi può essere 
garantita da lla tracciabilità in ogni fase del 
ciclo di vita dei prodotti. Oltre ad 
assicurare maggiore food security , le 
certificazioni ambientali  possono 
20 Fonte: elaborazione The European House – Ambrosetti 
su dati Eurostat e Commissione Europea, 2019.  
673,6
359,8
294,1
241,6
187,2
162,8
135,450150250350450550650
1965 1975 1985 1995 2005 2015 2030
Sud-Est Asiatico Paesi in via di sviluppo Nord Africa/Medio Oriente
America Latina Mondo Paesi industrializzati
Africa Sub-Sahariana100
Figura 21. Trend  dei consumi di carne nel mondo per 
macro -area geografica (1965 = 100), 1965 -2030E. Fonte: 
elaborazione The European House – Ambrosetti su dati 
FAO, 2019.  
15.500 
6.000 
3.900 
1.800 
1.300 
1.000 
700 
460 
180 
130 1kg di carne bovina
1kg di carne suina
1kg di pollo
1kg di zucchero di canna
1kg di pane
1l di latte
1kg di mele
1kg di arance
1kg di pomodori
1kg di insalata
Figura 22. Water footprint  per tipologia di alimento 
(valori in litri), 2019.  Fonte: elaborazione The European 
House – Ambrosetti su dati Water Footprint Network, 
2019 . "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#12,12,"13 
 sostenere pratiche agricole e di 
allevamento efficienti e sostenibili, in 
grado di tutelare la salvaguardia e il 
benessere degli animali e degli ecosistemi 
ambientali in terra e in mare (si pensi non 
solo all’allevamento di bestiame, ma anche 
all’importanza delle acquacolture per la 
tutela dell’ecosistema marino).  
83. L’ultimo impatto rilevante del settore 
agroalimentare sull’ambiente è quello 
relativo alle emissioni di gas inquinanti. 
Anche in questo caso, l’impronta più 
elevata è data dalla produzione di carne 
rossa, come presentato  in Figura 2 3. Il 
bestiame è infatti  responsabile del 14,5% 
dei gas serra  generati ogni anno  a livello 
globale .21 
84. Anche con riferimento alla relazione tra 
sana alimentazione e sostenibilità 
ambientale,  occorre  considerare la 
dieta nel suo insieme  e non l’impatto 
del singolo alimento . Come le proteine 
animali possiedono il loro apporto proteico 
utile per un maggior equilibrio nutrizionale 
all’interno di una dieta, così dal punto di 
vista ambientale gli allevamenti di 
bestiame sono in grado di fornire un 
contributo positivo, ad esempio  
eliminando gli sprechi di residui colturali e 
producendo concime da usare come 
fertilizzante naturale.  
85. Nella filiera agroalimentare a valle u n 
paradosso legato alle ricadute ambientali  è 
legato allo spreco alimentare . La FAO 
stima che un terzo della prod uzione 
annuale mondiale di cibo, equivalente a 1,3 
miliardi di tonnellate , finisca nella 
spazzatura, pari a quattro volte la quantità 
necessaria per nutrire gli 821 milioni di 
                                                 
21 Per fornire un ordine di grandezza compar abile, la stessa 
quota delle emissioni totali di auto, camion, aeroplani e 
navi. Fonte: elaborazione The European House – 
Ambrosetti su dati FAO, 2019.  persone affette da denutrizione . 
86. Ogni anno, in Unione Europea, vengono 
gettate 8 8 milioni di tonnellate di cibo  a 
livello domestico , 98 kg per nucleo 
familiare. In Italia, il dato per nucleo 
familiare ammonta a 85kg, mentre in 
Francia a 99kg.22  
87. Lo spreco provoca inoltre specifiche 
emissioni di gas inquinanti  che 
incrementano ulteriorm ente il carbon 
footprint  del settore : il gas metano 
generato  dal cibo che finisce in discarica è 
circa 21 volte  più dannoso della CO 2.  
Il contributo dell’alimentazione ad una 
terza dimensione di sviluppo sostenibile , 
la riduzione delle disuguaglianze  
88. Le food inequalities  rappresentano uno 
dei principali  gap di accessibilità 
nell’odierna società . Un’alimentazione 
sana è spesso associata a costi più elevati , 
con il rischi o di accentuare le 
diseguaglianze  nell’accesso a cibi sani e con 
il corretto apporto nutrizionale . Abitudini 
alimentari sane e sostenibili  (e accessibili) 
sono in grado di ridurre t ali diseguaglianze, 
spezzando quella che può essere definita la 
“spirale socio -ecologica ” entro la quale 
rischiano di essere confinate le fasce di 
popolazione a basso potere di spesa.   
89. Uno studio dell’Università di Cambridge  
ha dimostrato come 1 .000 calorie derivanti 
da alimenti sani costino oggi intorno ai 9 
Euro , contro i 3 Euro  necessari per 
ottenere l’equivalente apporto calorico dal 
cosiddetto “ cibo spazzatura ”, influenzando 
automaticamente le scelte dei consumatori 
più vulnerabili dal punto di vista 
economico  e sociale . 
22 Fonte: elaborazione The European House – Ambrosetti 
su dati Coldiretti, FAO e altre fonti, 2019.  
39,2
27,0
12,1
6,9
6,1
4,8
2,7
2,0
1,9
1,11kg di agnello
1 kg di carne bovina
1kg di carne suina
1kg di pollo
1kg di tonno
1kg di uova
1kg di riso
1kg di verdura (media)
1l di latte
1kg di frutta (media)
Figura 23.  Carbon footprint  per tipologia di alimento (kg 
di CO 2 equivalenti), 2019. Fonte: elaborazione The 
European House – Ambrosetti su dati EPA e 
Environmental Working Group, 2019.  
SITUAZIONE DI
VULNERABILITÀ
SOCIO -
ECONOMICAABITUDINI ALIMENTARI
SCORRETTEEFFETTI NEGATIVI SU
SALUTE , AMBIENTE E
SISTEMA SANITARIOAGGRAVARSI
DELLA SITUAZIONE
DIVULNERABILITÀ
SITUAZIONE DI
VULNERABILITÀ
SOCIO -
ECONOMICAABITUDINI ALIMENTARI
SANE ESOSTENIBILIEFFETTI POSITIVI SU
SALUTE , AMBIENTE E
SISTEMA SANITARIO
ATTENUARSI
DELLA SITUAZIONE
DIVULNERABILITÀ
Figura 24. La spirale socio -ecologica dell’alimentazione.  
Fonte: elaborazione The European House – Ambrosetti, 
2019. "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#13,13,"14 
 90. Abitudini  alimentari scorrette provocano a 
loro volta effetti negativi sul benessere 
individuale e collettivo,  incrementando le 
spese per cure mediche e 
conseguentemente quelle del sistema  
sanitario , oltre ad essere generalmente 
associate ad un maggior impatto 
ambientale . Tale condizione  porta 
all’aggravarsi della situazione di 
vulnerabilità iniziale , creando così un 
circolo vizioso .  
91. Il secondo schema in Figura 2 4 testimonia 
come una sana e corretta 
alimentazione , a prezzi accessibili,  
sia in grado di spezzare in parte 
questo circolo vizioso , con ricadute 
positive per i singoli individui e la società 
nel complesso . 
Quale contributo della ristorazione 
collettiva e quali proposte d’azione 
per il raggiungimento degli Obiettivi 
di Sviluppo Sostenibile  
92. La ristorazione collettiva ha un ruolo 
chiave nella  promozione di scelte 
alimentari sane e sostenibili.  
93. Gli operatori de l settore svolgono un ruolo 
cruciale poiché  spesso si interfacciano 
con le fasce di popolazione più 
vulnerabili e strategiche per favorire  
abitudini alimentari corrette, quali 
bambini  e anziani . La possibilità di 
sostenere un buono stato di salute per 
queste categorie di individui rafforza 
indirettamente la sostenibilità economica 
dei sistemi sanitari nazionali, per esempio 
contrastando l’incremento del fenomeno 
dell’obesità infantile o favorendo una 
minor incidenza delle spese sanitarie per 
gli anziani . 
94. La ristorazione collettiva può farso garante 
di una “ democratizzazione” di stili 
alimentari sani e sostenibili , 
contribuendo significativamente alla 
riduzione delle disparità sociali.   
95. La garanzia di affidabilità e qualità di tale 
servizio, che ogni gior no in Europa è 
offerto a 67 milioni di persone, è messa 
però a dura prova dal contesto in cui il 
settore sta operando, caratterizzato da tagli 
e strategie di spending review  in settori 
collegati.   
96. Il caso italiano è emblematico in tal senso: 
le imprese della ristorazione collettiva del 
Paese servono annualmente 1,65 miliardi 
di pasti, di cui 657 milioni destinati agli 
                                                 
23 Fonte: elaborazione The European House – Ambrosetti 
su dati Angem e Anac, 2019.  oltre un milione e mezzo di ammalati e 
anziani nelle strutture sanitarie.  Da anni gli 
investimenti in ristorazione sanitaria sono 
sottoposti a forti contrazioni , anche a 
causa di interventi di spending review  che 
hanno ridotto del 10% il  corrispettivo sui 
contratti della sanità e , di conseguenza , 
proporzionalmente ridotto la quantità e 
qualità dei pasti serviti nelle strutture. A 
questi tagli si è aggiunto l’obbligo di 
adeguamento dei prezzi alle direttive 
stabilite dall’autorità nazionale di 
riferimento: il prezzo medio per un menù 
composto da colazione, pranzo e cena è 
stato fissato a 11,74 Euro, inferiore 
dell’8,2% rispetto alla me dia nazionale 
attuale  (12,70 Euro).23  
97. La ristorazione collettiva – quale operatore 
a valle della filiera alimentare – può fornire 
un importante sostegno  anche dal punto di 
vista della riduzione dell’impatto 
ambientale, attraverso la lotta allo 
spreco alime ntare , la promozione di 
buone pratiche di economia circolare  e 
la riduzione dell’utilizzo di packaging  
non riciclabile.  
98. Considerata la  relazione esistente tra sana 
alimentazione e sostenibilità, sia da un 
punto di vista socio -economico sia da un 
punto di vista ambientale, sono state 
formulate alcune proposte d’azione, 
nell’ambito dei dialoghi italo -francesi, per 
la promozione di corretti  stili alimentari.  
Proposta d’azione 1. Fare rete tra Italia e 
Francia per affermarsi come “Paesi 
ambasciatori” di una alimentazione 
sana e sostenibile  
99. Italia e Francia sono due Paesi dalla forte 
tradizione alimentare , entrambi 
aderenti ai principi della d ieta 
mediterranea, allo stesso tempo con 
peculiarità proprie anche a livello regionale 
che ne aumentano l’attrattività 
internazionale.   
100. In questo contesto, i due Paesi hanno 
l’opportunità  di assumersi il ruolo di 
portavoce di un’alimentazione sana 
e sostenibile, facendosi 
ambasciatori dei benefici della dieta 
mediterranea nel mond o.  
101. Si riportano di seguito alcune linee 
d’azione per l ’implementazione di questa 
proposta:  
— stimolare il dialogo tra Italia e Francia 
sui temi dell’alimentazione e della 
sostenibilità, anche attraverso la 
creazione di “progetti pilota” "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#14,14,"15 
 cross -border  con il coinvolgimento 
di aziende della filiera agrifood  
estesa  (agricoltura, industria di 
trasforma zione, distribuzione e 
ristorazione), università e centri di 
ricerca;  
— farsi portavoce dell’importanza di 
un’alimentazione sana e sostenibile 
presso le principali sedi decisionali 
europee  in materia, come ad 
esempio la Direzione Generale di 
Health and Food Safety della 
Commissione Europea, l’Autorità 
Europea per la Sicurezza Alimentare – 
EFSA, l’ High Level Group on 
Nutrition and Physical Activity . 
Proposta d’azione 2. Definire una 
strategia di comunicazione e 
sensibilizzazione congiunta sui benefici 
di un’al imentazione sana e sostenibile  
102. Spesso una significativa quota di 
popolazione non ha piena consapevolezza 
delle ricadute negative di una dieta 
scorretta sulla propria salute e 
sull’ecosistema  ambientale,  una limitazione  
spesso correlat a all’appartenenza a 
categorie con bassi livelli di educazione.  
103. Italia e Francia potrebbero promuovere  
una cultura diffusa sull’importanza di 
un’alimentazione sana e sostenibile, 
attraverso il lancio di una strategia multi -
livello di comunicazione e sensib ilizzazione.  104. Le linee d’azione inerenti a tale strategia 
comprendono:  
— promuovere, con la guida del Governo 
italiano e francese e il coinvolgimento 
della filiera agroalimentare estesa, 
un’azione strutturata di 
sensibilizzazione, informazione 
ed educazione , verso:  
o l’opinione pubblica, con una 
campagna nazionale di 
comunicazione  nei due Paesi 
(“Pubblicità Progresso”), sui media  
tradizionali e sui social network  per 
diffondere la consapevolezza dei 
benefici – per la salute individuale 
ed il benessere del pianet a – 
associati ad un’alimentazione sana 
e sostenibile e/o eventi -bandiera  
ad alta visibilità mediatica;  
o la filiera agroalimentare integrata, 
attraverso partnership  
pubblico -private  (ad esempio, 
consorzi sulla Ricerca e Sviluppo) 
ed iniziative di comunicazione 
mirate  (ad esempio, roadshow  
territoriali e /o workshop  tematici 
settoriali).  
 
 
 
 
 
Un ringraziamento a:  
— Eloi Laurent, Professore Ordinario di alimentazione e sostenibilità e Senior Economist e 
Consigliere Scientifico, Observatoire français des conjonctures économiques , SciencesPo  
— Matteo Caroli, Professore Ordinario di Economia, Universi tà LUISS  
 
 
 
 
 
 "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#2,2,"3 
 — nonostante la produzione mondiale di 
cibo sia in costante aumento, le 
persone denutrite hanno r ipreso ad 
aumentare dal 2015, evidenziando 
quanto sia rilevante il fenomeno dello 
spreco alimentare;  
— il 60%  della popolazione vive in aree 
con elevato stress  idrico e 1 miliardo 
di persone  non ha ancora accesso ad 
acqua potabile;  
— ogni anno, 8 milioni di tonnellate 
di plastica finiscono negli oceani. A 
questo ritmo, la quantità di plastica in 
mare supererà quella dei pesci entro i 
prossimi 30 anni.4 
10. Questi aspetti sono un  importante  fattore 
di rischio per la sostenibilità e la 
resilienza del settore 
agro alimentar e. I cambiamenti  climati ci 
determinano crescente insicurezza 
alimentare e rischio di denutrizione nelle 
fasce più vulnerabili della popolazione, 
soprattutto nei Paesi a reddito medio -
basso: si pensi alla  perdita delle colture, ad 
eventi metereologici estremi che 
producono siccità o alluvioni , ad epidemie 
legate a patogeni nel cibo.5  
11. Diventa fondamentale garantire la 
resilienza a 360°  a livello di sistema 
economico, energetico, infrastrutturale, 
tecnologico, ma anche di ecosistema 
ecologico e di ambiente urbano. È proprio 
in questi ultimi due ambiti che la resilienza 
può essere assicurata e rafforzata da 
modelli di alimentazione sosten ibili, in 
grado di contribuire  positivamente alla 
capacità degli ambienti e degli ecosistemi 
di resistere a shock  esogeni, di ridurre la 
dipendenza da altri territori e di rispondere 
ai cambiamenti climatici e all’esaurimento 
delle risorse.  
                                                 
4 Fonte: elaborazione The European House – Ambrosetti 
su dati OMS, IPCC, World Bank e ONU, 2019.  
5 Basti pensare che , nel solo 2018 , il settore agroalimentare 
italiano ha perso 1,5 miliardi  di Euro  a causa degli effetti 
del cambiamento climatico. Fonte: elaborazione The 
European House – Ambrosetti su dati Coldirett i, 2019.  Il ruolo dell’alimentazione verso lo 
sviluppo sostenibil e 
12. Come illustrato nel capitolo precedente, 
sono diverse le dimensioni della 
sostenibilità correlate direttamente o 
indirettamente all’alimentazione .  
13. Una corretta alimentazione contribuisce 
allo sviluppo soste nibile (e alla resilienza 
degli ambienti urbani ed ecosistemi 
ambientali) attraverso due leve 
fondamentali:  
— salute e benessere  individuale e 
collettivo ; 
— sostenibilità ambientale .  
Il contributo dell’alimentazione alla 
salute e al benessere individuale e 
collettivo  
14. Divers i studi medico -scientifici pubblicati 
negli ultimi anni hanno dimostrato  come 
esista una forte correlazione tra una dieta 
sana ed equilibrata e il mantenimento di un  
buono stato di salute. Secondo i dati del 
Global Burden of Disease , la 
malnutrizione  è stata la 1° causa di 
morte  a livello mondiale nel 2017 (161 
morti ogni 100.000 abitanti ). Allo stesso 
modo, la malnutrizione si posiziona come 
2° fattore di rischio  correlato al 
DALY6 (nel 1990 era il 5°).  
15. Il modello alimentare  indicato come 
fondamento delle principali diete  è la 
piramide alimentare , intes a come 
l’insieme di regole nutrizionali volte a 
gestire l’alimentazione  nel suo insiem e.  
6 Disability -Adjusted Life Years : misura della gravità 
globale di una patologia , espressa come il numero di anni 
persi a causa della malattia in virtù di un cattivo stato di 
salute, di disabilità o di morte prematura.  
BASSO
Carne bovina
Formaggio
Uova
Carne avicola
Pesce
Biscotti
Latte
YogurtDolci
Olio
Frutta secca
Pane, Pasta
Patate, Riso
Legumi
Frutta
Ortaggi
ALTO
Figura 3. La piramide alimentare. Fonte: elaborazione  
The European  House – Ambrosetti per Barilla Center for 
Food and Nutrition, 2019.  
9,910,110,410,710,911,211,511,812,112,512,813,113,414,5
13,8
13,1
12,6
12,2
11,8
11,3
11,0
10,710,610,810,9
2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017
Persone affette da obesità Persone affette da malnutrizione
Figura 2. Persone affett e da obesità e malnutrizione nel 
mondo (% sul totale della popolazione), 2005 -2017.  Fonte: 
elaborazione The European House – Ambrosetti su dati 
OMS e FAO, 2019.  "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#3,3,"4 
 16. Il valore della piramide alimentare è 
duplice: oltre a rappresentare una sintesi 
delle principali conoscenze acquisite dalla 
scienza nutrizionale, è uno strumento 
efficace per l’educazione ai consumi 
alimentari.  
17. È importante sottolineare il concetto di 
dieta  come assunto sottostante alle analisi 
del presente capitolo. Il dibattito odierno  in 
sedi tecniche quali organismi di controllo e 
regolatori internazionali  è spesso 
incentrato  sul singolo alimento e 
sull’analisi del suo contenuto per la salute 
delle perso ne. Per quanto gli standard  di 
alcuni alimenti siano essenziali  in termini 
di apporto di  ingredienti  più o meno 
salutari, un’analisi focalizzata sul tipo di 
dieta da seguire risulta l’approccio più 
indicato per ottenere una visione d’insieme 
sulla sana e c orretta alimentazione , anche  
per evitare di demonizzare singole 
categorie di  alimenti.7 
18. Il modello di dieta basato sui dettami della 
piramide alimentare e considerato come il 
benchmark  di riferimento per la salute 
degli individui è quello mediterraneo. La 
dieta mediterranea  si distingue per il 
suo equi librio nutrizionale, sia in termini di 
quantità consumate sia di proporzioni 
degli alimenti assunti. La rigorosa 
aderenza alle raccomandazioni medico -
scientifiche e l’elevata conformità con i 
requisiti nutrizionali del  modello della 
piramide alimentare fa di questa dieta la 
più efficace in termini di prevenzione di 
alcune importanti  malattie croniche  
e di mantenimento di uno stato di 
benessere . Il modello dietetico 
mediterraneo , attraverso un sano profilo di 
assunzione dei grassi, una bassa 
percentuale di carboidrati, un basso indice 
glicemico, un elevato contenuto di fibre 
alimentari, di composti antiossidanti ed 
effetti antinfiammatori, riduce il rischio di 
contrarre alcune patologie, come verrà 
analizzato nei paragrafi successivi.  
19. Lungo il  bacino mediterraneo europeo, 
Italia  e Francia  rappresentano i Paesi in 
cui le tradizioni alimentari nazionali hanno 
maggiore aderenza  con la dieta 
mediterranea , insieme a Spagna e Grecia . 
Prima di entrare nel dettaglio dell’impatto 
generato dall’alimentaz ione sui sistemi 
sanitari nazionali , è essenziale sviluppare 
due ulteriori premesse , che riguardano 
l’evoluzione demografica  della popolazione  
                                                 
7 Il tipico esempio in questo senso è la carne. La filiera della 
carne rischia troppo spesso di essere danneggiata da 
campagne che ne co ndannano l’assunzione, mentre il suo e la sostenibilità  economica dei sistemi 
sanitari .  
20. Tra i grandi cambiamenti che stanno 
mutando gli scenari di riferimento per la 
business community  e le Istituzioni  non si 
possono non considerare  i trend  
demografici  che stanno sostanzialmente 
modificando la struttura dell a popolazion e 
dei Paesi sviluppati e , di conseguenza , le 
esigenze da considerare prioritarie per lo 
sviluppo sostenibile.  
21. Analizzando il  caso italiano, il Paese sta 
assistendo ad un progressivo 
invecchiamento della popolazione, un 
trend  destinato a d acuirsi nei prossimi 
anni a fronte  dell’innalzamento della 
speranza di vita ( 82,7  anni nel 2017, vs. 
69,1 nel 1960 ) e dei bassi tassi di natal ità 
(1,35 figli per donna nel 2017, vs. 2,37 nel 
1960).  Nel 2018, per la prima volta nella 
storia italiana, la popolazione over -60 
(28,7%  vs. 21,2% nel 1990) ha superato 
quella dei giovani under -30 (28,4%  vs. 
39,6% nel 1990).8  
22. La ragione per cui è importante guardare a 
questo tipo di trend  demografici in uno 
studio sull’alimentazione e la salute delle 
persone risiede nelle differenti esigenze 
nutrizionali che gli individui detengono  al 
variare delle fasce  d’età  di appartenenza , 
soprattutto guardando alle categorie più 
vulnerabili, a partire da bambini ed anziani. 
L’invecchiamento della popolazione 
italiana è quindi un aspetto da tenere in 
considerazione, in quanto le persone 
anziane necessitano di un fabbisogno 
calorico  – e di co nseguenza di un modello 
dietetico – diverso e più limitato . 
23. In Francia si riscontrano trend  demografici 
simili, anche se meno marcati rispetto al 
caso italiano. La piramide demografica di 
consumo – se equilibrato  – è presente e caldamente 
consigliato nella piramide alimentare.  
8 Fonte: elaborazione The European House – Ambrosetti 
su dati Istat e World Bank, 2019.  
8,6%
9,5%
10,3%
11,9%
15,5%
15,2%
12,1%
9,7%
5,7%
1,2%0-9
10-19
20-29
30-40
40-49
50-59
60-69
70-79
80-89
90+9,9%
13,5%
16,2%
14,0%
13,0%
12,4%
11,1%
6,6%
3,1%
0,3%
Figura 4. Popolazione italiana per fascia d’età (% sul 
totale), 1990 (a sinistra) e 2018 (a destra).  Fonte: 
elaborazione The European  House – Ambrosetti su dati 
Istat, 2019. "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#4,4,"5 
 Figura 5 mostra  come la quota di under -30 
sul totale della popolazione sia diminuit a 
dal 42,5%  del 1990 al 35,4%  del 2018; gli 
over -60, invece, costituivano il 19,1% della 
popolazione nel 1990, mentre ad oggi 
pesano per il 26,2% . 
24. Questa tendenza, comunemente 
conosciuta come  Ageing Society , è 
destinat a a continuare nel prossimo futuro, 
incrementando la pressione per la  
sostenibilità economica dei sistemi 
sanitari  nazionali . È indubbio che una 
popolazione sempre più anziana 
rappresenti già oggi una sfida molto 
significativa in ambito sanitario (oltre che 
in quello previdenziale), considerando  che 
l’allungamento della vita media sta 
modificando la natura epidemiologica 
della popolazione. Nella maggior parte dei 
Paesi OCSE, oltre il 50%  degli over -65 è 
affett o da una malattia cronica  e l’età 
media dalla quale si manifestano le prime 
patologie è in costante calo. Q uesto 
influisce profondamente sulla qualità della 
vita media di u na popolazione : in Italia, da 
inizio secolo , sono stati persi  2,5 anni  
vissuti in buona salute, che ad oggi sono 
circa  62.9 
25. L’insieme di questi fattori rappresenta un 
serio rischio per i sistemi sanitari nazionali , 
gravati negli ultimi anni da costi crescenti. 
In Italia e in Francia la spesa sanitaria  
(pubblica e privata) ha registrato un 
aumento rispettivamente del 6,4% e del 
17,3%  dal 2010 al 2017, un trend  
confermato anche negli altri “ Big Five ” 
dell’Unione Euro pea (Figura 6).  
26. L’alimentazione gioca un ruolo chiave in 
questo contesto , poiché strettamente 
correlata allo stato di salute delle persone e 
ai costi ad esso associati .  
                                                 
9 Fonte: elaborazione The European House – Ambrosetti 
su dati  OECD e  XIII Rapporto Meridiano Sanità  di The 
European House – Ambrosetti , 2019.  27. La cattiva alimentazione si posiziona tra i 
primi cinque fattori di rischio  nella 
contrazione delle  tre malattie croniche non 
trasmissibili più impattanti  per i sistemi 
nazionali  in quanto responsabili del 94% 
dei decessi  globali :  
— i tumori , per i quali  la malnutrizione  
è la 2° causa di morte a livello globale, 
la 4° in Italia e in Fran cia, e la 1° causa 
di DALY nel mondo, 2° in Italia e in 
Francia;  
— le malattie cardiovascolari , per le 
quali è la 2° causa di morte a livello 
globale, così come in Italia e in Francia, 
e la 2° causa di DALY al mondo, la 4° 
in Italia e in Francia;  
— il diabete , dove è la 5° causa di morte 
a livello mondiale, così come in Italia 
e in Francia, e la 4° causa di DALY 
globalmente, terza in Italia e in 
Francia.10 
28. Si tratta di malattie ad altissimo impatto 
per il sistema sanitario , sia per il numero di 
persone che ne sono affette , sia per i costi 
sanitari e sociali associati .11  
29. Alla base di queste tre malattie croniche ci 
sono due tipi di fattori di rischio:  
— non modificabili  (età e predisposizione  
ereditaria );  
— modi ficabili (tra i quali  rientrano 
dieta scorretta e ipercalorica , 
insufficiente attività fisica e consumo 
di tabacco ).  
30. All’intern o dei fattori modificabili, le 
abitudini che incorporano una dieta 
scorretta e ipercalorica – talvolta unit e ad 
un’insufficiente attività fisica – aumentano 
le probabilità dell’insorgere di condizion i 
fisic he di sovrappeso o obesità .  
10 Fonte: elaborazione The European House – Ambrosetti 
su dati Global Burden on Disease, 2019.  
11 In Italia, ad esempio, le tre patologie rientrano tra le 
prime cinque voci di costo per il sistema sanitario nazionale.  
11,7%
12,4%
11,3%
12,4%
12,9%
13,2%
12,0%
8,1%
4,8%
1,3%0-9
10-19
20-29
30-40
40-49
50-59
60-69
70-79
80-89
90+13,3%
13,9%
15,3%
15,0%
12,8%
10,5%
10,1%
5,3%
3,2%
0,5%
Figura 5. Popolazione francese per fascia d’età (% sul 
totale), 1990 (a sinistra) e 2018 (a destra).  Fonte: 
elaborazione The European House – Ambrosetti su dati 
Insee, 2019.  
146,8
129,6
117,3
106,4
105,5
90100110120130140150
2010 2011 2012 2013 2014 2015 2016 2017
Regno Unito Germania Francia Italia Spagna
Figura  6. Spesa sanitaria pubblica e privata nei Paesi “ Big 
Five ” dell’UE (2010 = 100), 2010 -2017.  Fonte: 
elaborazione The European House – Ambrosetti su da ti 
OECD, 2019. "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#5,5,"6 
 31. L’Organizzazione Mondiale della Sanità 
definisce l’obesità e il sovrappeso 
attraverso il Body Mass Index  – BMI, un 
dato biometrico che mette a co nfronto peso 
e altezza: sono considerati affetti da obesità  
i soggetti con un BMI maggiore di 30 kg/m2, 
mentre gli individui con un BMI compreso 
tra 25 e 30 kg/m2 sono ritenuti in 
condizioni di sovrappeso.   
32. L’eccesso di peso può portare effetti 
negativi  sulla salute e sull’aspettativa di 
vita degli individui : l’OCSE ha stimato 
come una persona gravemente obesa perda 
in media dagli 8 ai 10 anni di vita  e come 
per ogni 15 kg in eccesso, il rischio di 
decesso increment i del 30% .  
33. L’Italia è uno dei Paesi dell’Unione 
Europea  con la più bassa incidenza di 
persone sovrappeso/obese, anche se la 
quota rimane elevata: il 31,7%  della 
popolazione italiana adulta (età uguale o 
superiore a 15 anni) è in sovrappeso, contro 
il 46,1% della medi a UE, mentre il 10,7% è 
affetto da obesità.  
34. In Francia l’incidenza delle persone 
sovrappeso sale al 48,9%  (+2,8 punti 
percentuali rispetto alla media dell’Unione 
Europea ), mentre l’obesità colpisce il 
                                                 
12 Fonte: elaborazione The European House – Ambrosetti 
su dati Università Tor Vergata, 2019.  15,3%  della popolazione adulta (+4,6 
punti percentuali al di sopra della media 
UE).  
35. Oltre alle conseguenze negative sulla salute, 
le condizioni di obesità/sovrappeso 
conducono a numerose problematiche in 
termini economici a diversi livelli, a partire 
da quello del singolo individuo affetto dalla 
patologia (e d el suo nucleo familiare), fino 
alle imprese e ai governi, che si ritrovano 
ad affrontare ingenti spese sanitarie . È 
stato stimato infatti come una persona 
affetta da obesità  con un BMI compreso tra 
35-40 kg/m2 costi annualmente in media il 
50%  in più  al sistema sanitario  rispetto a 
una persona normopesa , fino a 
raggiungere il 100% in più per le persone 
con un BMI maggiore di 40 kg/m2.12  
36. I bambini e gli adolescenti sono le categorie 
di popolazione maggiormente esposte ai 
rischi derivanti da un’alimentazione 
scorretta  poiché  facilmente influenzabili 
dalle cattive abitudini delle persone vicine 
a loro : i bambini con almeno uno dei due 
genitori affetti da obesità , infatti, 
presentano probabilità 3-4 volte superiori 
di essere affetti da obesità  rispetto ai 
bambini con genitori normopeso. Circa  il 
70%  dei bambini obesi rimarrà  in questa 
condizione anche da adulto.13  
37. L’obesità infantile in Italia è un fenomeno 
di assoluta rilevanza: nel 2016 , il 14% delle 
bambine e il  21% dei bambini  tra i 6 -9 anni 
risulta essere in sovrappeso o obeso , 
rispettivamente 4 e 8 punti percentuali 
sopra la media dell’Unione Europea .  
 
38. In Francia, il fenomeno è presente in 
misura minore, e colpisce il 6% delle 
bambine e il  9% dei bambini  (4 punti 
percentuali  sotto la media UE).  
13 Fonte: elaborazione The European House – Ambrosetti 
su dati OMS, 2019.  
44%
7-41%
23%Diabete
Tumori
Malattie
cardiocircolatorie
Figura  7. Malattie croniche attribuibili a condizioni di 
obesità/sovrappeso (% sul totale), 2015.  Fonte: 
elaborazione The Euro pean House – Ambrosetti su dati 
OMS e XIII Rapporto Meridiano Sanità di The European 
House - Ambrosetti, 2019.  
10,7%
12,3%
12,8%
14,7%
14,9%
15,3%
15,9%
16,6%
16,7%
17,0%
18,6%
23,0%
23,6%
24,8%
26,9%Italia
Svezia
Paesi Bassi
Austria
Danimarca
Francia
UE-28
Portogallo
Spagna
Grecia
Belgio
Irlanda
Germania
Finlandia
Regno Unito
Figura  8. Tasso di obesità nella popolazione adulta in 
alcuni Paesi selezionati UE e media UE (% sul totale della 
popolazione), 2017.  Fonte: elaborazione The European 
House – Ambrosetti su dati Eurostat e OECD, 2019.  
17%
14%
14%
11%
10%
9%
6%
7%
6%
5%
5%19%
21%
20%
12%
13%
11%
12%
10%
9%
9%
5%Spagna
Italia
Grecia
Portogallo
UE-28
Finlandia
Austria
Svezia
Francia
Irlanda
Danimarca
Femmine MaschiFigura 9.  Sovrappeso/obesità in età infantile nei 
principali Paesi UE e media UE (% sul totale dei bambini 
tra i 6 -9 anni), 2016.  Fonte: elaborazione The European 
House – Ambrosetti  su dati OMS , 2019.  "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#6,6,"7 
 39. La prevenzione , sottoforma di 
educazione alla sana alimentazione , 
assume  un ruolo fondamentale in questo 
ambito.  Da analisi di diversi  studi in campo 
medico è stato  dimostrato come un 
aumento dell’1% del ratio  della spesa in 
prevenzione  – in cui possono rientrare 
investimenti per il miglioramento delle 
abitudini nutrizionali delle persone – sul 
totale della spesa sanitaria pubblica si 
correli ad una riduzione del 3% della spesa 
in servizi terapeutici e di riabilitazione.   
40. Una sana e corretta alimentazione ha un 
ruolo fondamentale anche come fattore 
di prevenzione .  Come illustrato ad 
inizio capitolo, la piramide alimentare 
rappresenta il benchmark  su cui basare 
una di eta salutare ed equilibrata: alla base 
della piramide – e di conseguenza alla base 
della dieta mediterranea – troviamo 
frutta e verdura , il cui consumo 
quotidiano è il prerequisito fondamentale 
per uno stile di vita sano.  
41. Secondo l’Organizzazione Mondiale della 
Sanità, con un consumo di 600 grammi 
di frutta e verdura al giorno – equivalente 
a oltre  5 porzioni – si eviterebbero soltanto 
in Unione Europea 135.000 decessi, 1/3 
delle malattie coronariche e l’11% degli 
ictus.  
42. Si registra  una correlazione positiva  
tra aspettativa di vita e consumo di 
frutta/verdura  nei Paesi dell’Unione 
Europea .  
43. Da questa elaborazione  si evince come la 
quasi totalità dei Paesi UE che adottano la 
dieta mediterranea come modello 
nutrizionale di riferimento  risieda nel 
quadrante in alto a destra: Italia, Francia, 
                                                 
14 Fonte: elaborazione The European House – Ambrosetti 
su dati Sorveglianza Passi, Istituto Superiore di Sanità  e 
Eurostat, 2019.  Spagna, Grecia, Portogallo . Oltre alla 
posizione geografica lungo il bacino 
mediterraneo, esiste un dato oggettivo che 
convalida  le abitudini alimentari comuni 
tra i Paesi in oggetto: dal 2010 l’Unesco ha 
riconosciuto la dieta mediterranea come 
bene protetto e inserito nella lista dei 
patrimoni orali e immateriali dell’umanità , 
grazie alla sua unicità nel prevenire 
malattie croniche . 
44. Le raccomandazioni sull’apporto 
giornaliero di frutta e verdura 
dell’Organizzazione Mondiale della Sanità 
e d ei singoli Ministeri della Salute 
nazionali sono di assumerne 5 porzioni al 
giorno, equivale nti a circa 400 grammi . La 
quota di popolazione  che raggiung e i 
consumi suggeriti  è però risibile: i n Italia  
solo il 9,6%  della popolazione consuma 5 e 
più porzioni di frutta e verdura, mentre in 
Francia la percentuale sale al 14,9% . 
45. I consumi di frutta e verdura sono correlati 
alle caratteristiche sociodemografiche ed 
economiche della popolazione. Il consumo 
delle 5 porzioni raccomandate  cresce 
solitamente con l’avanzare dell’età, è 
maggiore nelle donne e tra le persone  con 
un maggior livello di istruzione o maggiore 
disponibilità economica .14 
46. Anche per i Paesi più virtuosi nelle 
abitudini alimentari , si sta gradualmente 
assistendo ad una minor aderenza  alla 
dieta mediterranea (persino in Italia) a 
favore di cibi pronti, più veloci da cu cinare 
ma meno salutari  e con un alto contenuto 
di grassi .  
47. La concomitante presenza di quest a 
molteplicità di  elementi  rappresenta una 
significativa fonte di stress  per i sistemi 
sanitari nazionali,  sia a livello gestionale -
operativo sia economico . 
48. Sebbene calcolare il peso economico totale 
del fenomeno  sia complesso , diversi studi 
hanno fornito delle stime sui costi  associati 
a condizioni di obesità/sovrappeso : 
— in Unione Europea, il costo è stimato 
intorno ai 70 miliardi  di Euro  
annui , tra spesa dei sistemi sanitari e 
costi indiretti;  
— la spesa  totale dell’obesità/sovrappeso 
per il sistema di sanità pubblica 
italiano si attesta tra i 6 e i 16 
miliardi di Euro all’anno  (4-10% 
della spesa sanitaria del Paese), di cui 
la metà impiegati direttamente nella 
Figura 10. Correlazione tra speranza di vita alla nascita e 
consumo di frutta e verdura nei Paesi UE (età (asse y) e quota % 
di popolazione che consuma almeno una volta al giorno una 
porzione di frutta e/o verdura (asse x)), 2018.  Fonte: 
elaborazione The European House – Ambrosetti su dati 
Eurostat, 2019.  
BelgioPortogallo
Regno UnitoItaliaSpagna
Slovenia
CroaziaGreciaAustriaCipro
Polonia
UngheriaIrlanda
UE-28Francia
EstoniaMalta
LussemburgoSvezia
Danimarca
LituaniaFinlandia
GermaniaPaesi Bassi
Rep. Ceca
Slovacchia
Lettonia Bulgaria
7475767778798081828384
40,0 45,0 50,0 55,0 60,0 65,0 70,0 75,0 80,0 85,0Speranza di vita alla nascita
Quota di popolazione che consuma frutta e/o verdura quotidianamente"
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#7,7,"8 
 cura dei problemi di salute correlati a 
tali condizioni, cui si sommano 
ulteriori 3 -8 miliardi di Euro per i costi 
indiretti non sanitari, quali perdita di 
produttività, assenteismo e mortalità 
precoce ;15 
— in Francia, il dato di costo sociale 
(diretto + indiretto) è stato stimato dal 
Tesoro intorno a 20 miliardi  di 
Euro .  
49. Nei prossimi paragrafi verranno invece 
analizzate l e ricadute negative  della 
malnutrizione  per la sostenibilità 
economica dei sistemi sani tari nazionali 
attraverso un focus sulle  principali 
malattie croniche ad essa correlate. Il 
dettaglio riguarderà gli impatti di  diabete, 
malattie cardiovascolari e tumori per i 5 
principali Paesi UE (Italia, Francia, 
Germania, Spagna e Regno Unito) e a 
livello comunitario.  
50. Il diabete è una malattia cronica legata al 
metabolismo, quindi strettamente 
correlata alle  abitudini alimentari degli 
individui . Obesità/sovrappeso e dieta 
squilibrata, insieme a insufficiente attività 
fisica e pressione alta, sono condizioni che 
aumentano esponenzialmente le 
probabilità di contrarre tale patologia. 
Oltre ad essere una malattia  ad alto 
impatto per la salute della persona, la 
presenza del diabete può favorire lo 
sviluppo di altre patologie non trasmissibili, 
come le malattie cardiovascolari.  
51. Secondo l’International Diabetes 
Federation , ad oggi 425 milioni di 
adulti (20-79 anni) ne sono affetti  nel 
mondo , proporzione destinata ad 
aumentare a quasi 650 milioni entro il 
2050. In Unione Europea, sono circa 60 
milioni  le persone affette da diabete.  
                                                 
15 Fonte: elaborazione The European House – Ambrosetti 
su dati  European  Center for International Political 52. In Italia, la prevalenza del diabete è in 
continuo aumento: nel 2002 la patologia 
colpiva il 3,9% della popolazione, mentre 
nel 2017 il dato è salito al 5,7%  (3,4 milioni 
di persone), che diventa 7,6%  
considerando la sola popolazione adulta . 
53. I casi di diabete in Francia nel 2017 sono 
invece 3,3 mi lioni, con una prevalenza del 
7,3%  sul totale della popolazione.  
54. La patologia  rappresenta un problema 
sanitario molto diffuso in Europa anche 
considerati gli elevati costi di 
trattamento  associati, solitamente 
sostenuti per ospedalizzazioni, farmaci, 
moni toraggio e prestazioni specialistiche.  
55. Tali costi sono soggetti a grandi variazioni 
da Paese a Paese. Come illustrato in Figura 
12, le spese medie per paziente in Unione 
Europea sono di 2.834  Euro , in Italia il 
dato è leggermente superiore ( 2.934  Euro ), 
mentre in Francia le spese sostenute sono 
estremamente al di sopra della media, 
raggiugendo un importo di 5.342  Euro .  
56. Al fine di quantificare  in modo completo gli 
impatti economici derivanti da  tale 
patologi a, è necessario includere  anche 
quei costi che non rientrano nel computo 
delle voci direttamente imputabili al 
sistema sanitario , ma che producono 
importanti ricadute sui sistemi nazionali 
dovuti alla perdita di produzione  
causata dalla malattia.  La dimensione 
indiretta, non facilmente identificabile a 
livello quantitativo poiché  include aspetti 
quali perdita di produttività o assenze 
lavorative, detiene un peso ugualmente 
significativo per la sostenibilità economica 
di un Paese.  
57. Prendendo in esam e il caso italiano del 
diabete, il cui costo diretto cumulato 
ammonta a 9,6 miliardi  di Euro , la 
Economy,  Fondazione Polic linico Tor Vergata  e 
Sorveglianza  Passi , 2019.  
7.476.800
3.584.5003.809.1193.402.300 3.276.40012,2% 10,4%
8,1%7,6%7,3%
01. 000. 00 02. 000. 00 03. 000. 00 04. 000. 00 05. 000. 00 06. 000. 00 07. 000. 00 08. 000. 00 0
0, 0%2, 0%4, 0%6, 0%8, 0%10, 0%12, 0%14, 0%
Germania Spagna Regno Unito Italia Francia
Numero malati Prevalenza nella popolazione adulta
Figura 11. Popolazione affetta da diabete e prevalenza 
nella popolazione adulta nei P aesi “ Big Five ” dell’UE 
(numero persone e % sul totale della popolazione adulta), 
2018.  Fonte: The European House – Ambrosetti su dati 
International Diabetes Federation e Diabetes UK, 2019.  
5.899 
5.342 5.107 
2.934 2.834 
2.362 
Germania Francia Regno
UnitoItalia UE-28 Spagna€17,5 mld €9,6 mld €8,5 mld €18,9 mld €44,1 mldValori 
cumulati€170 mld
Figura 12. Costi diretti del diabete per paziente e cumulati 
nei Paesi “ Big Five ” dell’UE e media UE (valori in €), 2016.  
Fonte: elaborazione The European  House – Ambrosetti su 
dati XIII Rapporto Meridiano Sanità di The European 
House – Ambrosetti, International Diabetes Federation e 
London School of Economics, 201 9. "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#8,8,"9 
 stima  di costi indiretti associati alla 
patologia raggiunge un valore di 10,7 
miliardi  di Euro , pesa ndo per il 53% 
dell’ intero impatto economico sul sistema -
Paese (20,3 miliardi  di Euro ). 
58. Come evidenziato, la presenza di diabete 
può essere un campanello d’allarme per 
l’insorgere di altre malattie non 
trasmissibili, ad esempio  le malattie 
cardiovascolari. A livello UE, le malattie 
cardiovascolari rappresentano la 1° causa 
di morte  (37% sul totale dei decessi  – 
oltre 1,8 milioni)  e la 2° in Italia (37,1% dei 
decessi) e in Francia  (24,5% dei decessi) .  
59. Oltre  al diabete, tra i principali fattori di 
rischio di queste malattie vi sono elevati 
livelli di colesterolo , condizioni di 
obesità/sovrappeso16 e, più in generale, 
stili di vita inadeguati, come elevato 
consumo di alcool e tabacco , dieta 
squilibrata  e ridott a attività fisica . Molti  
fattori sono  influenzati da un elemento 
comune, cioè abitudini alimentari  
scorrette . Tra le più diffuse, elevati 
consumi di sale e zucchero incrementano 
notevolmente le probabilità di contrarre 
tali patologie .  
60. Una corretta dieta f unge sia da strumento 
di prevenzione per le malattie 
cardiovascolari sia da principale linea 
guida per la convalescenza post -operatoria 
                                                 
16 L’Organizzazione Mondiale della Sanità stima come il 
23% delle malattie ischemiche del cuore siano provocate da 
eccesso ponderale.  e la successiva quotidianità del paziente. 
Nella convalescenza post -infarto , ad 
esempio, è stato dimostrato come una 
regolare e costante aderenza ai principi 
della dieta mediterranea riduca del 18% il 
rischio di decesso  correlato all’occorrenza 
di tale evento patologico .   
61. Le malattie cardiovascolari sono una 
problematica molto rilevante in termini 
epidemiologici e sociali,  che si traduce 
anche in costi economici per i sistemi 
sanitari e previdenziali. Le stime a  livello 
europeo  attestano  l’ammontare di tali costi 
oltre i 200 miliardi  di Euro , di cui circa 
113 miliardi di Euro direttamente associati 
al trattamento patologico e la restante 
parte legata alla perdita di produttività e 
alle spese sostenute dal sistema 
previdenziale responsabile di fornire 
prestazioni assistenziali sottoforma di 
pensioni di inabilità e assegni di inv alidità . 
Quest’ultima voce di costo è estremamente 
onerosa per i sistemi previdenziali 
nazionali: a titolo di esempio, secondo 
un’analisi condotta dall’Università Tor 
Vergata di Roma in collaborazione con 
l’INPS, l’istituto previdenziale italiano ha 
erogat o il 19% delle proprie prestazioni dal 
2009 al 2015 per malattie del sistema 
cardiocircolatorio (seconda voce di costo 
dopo i tumori) , per un totale di 13,7 
miliardi  di Euro  ed una spesa annua di 
oltre 1,9 miliardi  di Euro . 
62. Guard ando alle spese dirette (Fi gura 1 5), 
l’impatto economico delle malattie 
cardiovascolari in Europa ha quindi un 
peso molto rilevante: in Italia, il costo 
medio pro-capite  per il loro trattamento 
ammonta a 235  Euro , valore che scende a 
207 Euro per il sistema sanitario francese.  
€ 20,3 mld
€ 9,6 mld€ 10,7 mldCosti indiretti
53%
Costi diretti
47%
Voce di costo
▪Ospedalizzazioni = €5,1 mld
▪Farmaci = €2,1 mld
▪Monitoraggio = €1,3 mld
▪Prestazioni specialistiche = €1,1 mldVoce di costo
▪Pensionamento 
anticipato = €9,1 mld
▪Assenza dal lavoro = 
€1,6 mld
Figura 13. Dettaglio dei costi diretti e indiretti del diabete 
in Italia (valori in €), 2017.  Fonte: elaborazione The 
European  House – Ambrosetti su dati XIII Rapporto 
Meridiano Sanità di The European House – Ambrosetti, 
2019. 
357.788 
238.460 
157.690 145.291 123.384 38,6%37,1%
26,3%24,5%29,3%
 - 5 0. 000 1 00. 000 1 50. 000 2 00. 000 2 50. 000 3 00. 000 3 50. 000 4 00. 000
0, 0%5, 0%10, 0%15, 0%20, 0%25, 0%30, 0%35, 0%40, 0%45, 0%
Germania Italia Regno Unito Francia Spagna
Numero decessi % sul totale dei decessi
Figura 14. Numero decessi causati da malattie 
cardiovascolari e quota sul totale dei decessi nei Paesi “ Big 
Five ” dell’UE (numero e % sul totale), 2015.  Fonte: 
elaborazione The European House – Ambrosetti su dati 
Eurostat, 2019.  
413
313
235 223207
130
Germania Regno
UnitoItalia UE-28 Francia Spagna€20,7 mld €113,3 mld €6,1 mld €14,2 mld €34,2 mldValori 
cumulati€13,9 mld
Figura 15. Costo pro -capite e cumulati delle malattie 
cardiovascolari nei Paesi “ Big Five ” dell’UE e media UE 
(valori in €), 2016.  Fonte: elaborazione The European 
House – Ambrosetti su dati O MS, Center for Economic 
and Business Research e XIII Rapporto Meridiano Sanità 
di The European House – Ambrosetti, 2019.  "
data_test\rootfolder\varie\Alimentazione\Alimentazione-e-sostenibilità-Quale-relazione-e-quali-sfide-per-i-prossimi-anni.pdf#9,9,"10 
 63. La terza patologia cronica non 
trasmissibile in analisi  sono i tumori. 
Nonostante il tasso di mortalità stia 
gradualmente diminuendo, i tumori 
restano la seconda causa di morte in UE, 
con circa 1,3 milioni di decessi (26,4% sul 
totale), e la quarta in Ital ia e in Francia.  
64. Al contrario di altre patologie per le quali i 
fattori di rischio sono più facilmente 
identif icabili, non esistono quasi mai 
singole cause che possono spiegare 
l’insorgenza di un particolare tipo di 
tumore, in quanto sono diversi i fattori  – 
talvolta sovrapposti – che concorrono al 
suo sviluppo, alcuni dei quali non 
modificabili . Oltre ad età e pr edisposizione 
ereditaria (“familiarità”), elementi sui 
quali non è possibile intervenire, i fattori 
modificabili sono maggiormente legati 
anche in questo caso agli stili di vita .  
65. Come mostrato in Figura 1 7, nella lista dei 
principali fattori di rischio per i tumori, 
sono tre quelli strettamente correlati 
all’alimentazione, ancora una volta 
elemento  fondamentale  per il benessere 
personale . 
                                                 
17 Fonte: elabor azione The European House – Ambrosetti 
su dati Associazione Italiana Registri Tumori , Ligue Contre 
le Cancer  e Cancer Organisation Soutien, 2019.  66. Nonostante la mortalità per tumore sia in 
lenta ma graduale  diminuzione  grazie alla 
scoperta di cure sempre più adeguate   
(-0,7% annuo in Italia e -0,3% in Francia) , 
il numero di malati è in costante 
aumento : 
— negli ultimi decenni si è registrato in 
Italia un trend  in rialzo della 
prevalenza di pazienti con una storia 
di cancr o, da 2,2 milioni nel 2006 a 
circa  3,4 milioni nel 201 8. Ogni anno 
il numero di malati oncologici cresce 
di oltre 90.000 persone (+3%);  
— nel periodo 2007 -2016, in Francia, 
sono stati diagnosticati in media oltre 
356.000 nuovi casi di tumore ogni 
anno , ma ne l 2016 le nuove diagnosi 
sono state 385.000.17 
67. I trend  evidenziati sono da un lato dovuti 
all’intensificazione di fattori quali 
invecchiamento demografico, peggiora -
mento negli stili di vita quotidiani e 
aggravarsi della situazione ambientale e , 
dall’altro , ai progressi ottenuti nelle terapie, 
che migliorano la sopravvivenza nei 
pazienti e cronicizzano la malattia. Questi  
fattori incrementa no lo stress  economico 
dei sistemi sanitari in termini di costi 
diretti, soprattutto dovuti alla durata delle 
terapie e dei successivi controlli periodici.  
68. I dati di spesa pro-capite  diretta sostenut a 
per il trattamento dei tumori in Figura 1 8 
restituiscono un valore di 114  Euro  per 
l’Italia e di 110  Euro  per la Francia, 
leggermente al di sopra della media UE di 
102 Euro , il cui costo cumulato diretto 
ammonta a 51,8 miliardi  di Euro . 
226.662 
169.835 164.411 162.045 
107.083 24,4%26,4%27,4% 27,3%
25,4%
 - 5 0. 000 1 00. 000 1 50. 000 2 00. 000 2 50. 000
20, 0%22, 0%24, 0%26, 0%28, 0%30, 0%
Germania Italia Regno Unito Francia Spagna
Numero decessi % sul totale dei decessi
Figura 16. Numero decessi causati da tumori e qu ota sul 
totale dei decessi nei Paesi “ Big Five ” dell’UE (numero e % 
sul totale), 2015.  Fonte: elaborazione The European House 
– Ambrosetti su dati Eurostat, 2019.  
Fattore di rischio Valore
Tabacco 33%
Dieta 5%
Sovrappeso e obesità 20%
Inattività fisica 5%
Abuso di bevande alcoliche 3%
Fattori occupazionali 5%
Infezioni 8%
Radiazioni ionizzanti e esposizione a raggi UV 2%
Inquinamento ambientale 2%
Figura 17. Principali fattori di rischio per i tumori (% sul 
totale), 2017.  Fonte: elaborazione The European House – 
Ambrosetti su dati American Associations for Cancer 
Research, 2019.  
182
114 11010290 85
Germania Italia Francia UE-28 Spagna Regno
Unito€6,9 mld €51,8 mld €5,6 mld €7,4 mld €15,0 mldValori 
cumulati€4,2 mld
Figura 18. Costi pro -capite e cumulati dei tumori nei 
Paesi “ Big Five ” dell’UE e media UE (valori in €), 2016.  
Fonte: elaborazione The European House – Ambrosetti su 
dati XIII Rapporto Meridiano Sanità di The European 
House – Ambrosetti, ministeri nazionali della salute  e 
OMS, 2019.   "
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#0,0,
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#1,1,"Una sana alimentazione rappresenta il 
primo intervento di prevenzione a tutela 
della salute e dell’armonia fisica.
“La salute è uno stato di completo benessere fisico, 
mentale e sociale e non la semplice assenza di 
malattia o infermità”
Organizzazione Mondiale della Sanità"
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#10,10,
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#2,2,"LINEE GUIDA PER UNA SANA ALIMENTAZIONE ITALIANA
( MIPAAF -INRAN )
1.Più cereali, legumi, ortaggi e frutta
2.I grassi: scegli la qualità e limita la quantità
3.Zuccheri, dolci e bevande zuccherate: nei giusti limiti
4.Bevi ogni giorno acqua in abbondanza
5.Il sale? Meglio poco
6.Bevande alcoliche: se si, solo in quantità controllata
7.Controlla il peso e mantieniti sempre attivo
8.Varia speso le tue scelte a tavola
9.Consigli speciali per persone speciali
10.La sicurezza dei tuoi cibi dipende anche da te
"
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#3,3,"L’ORGANISMO È UNA MACCHINA BIOCHIMICA CHE CONSUMA CARBURANTE
Anche se a riposo, il corpo umano impiega comunque energia 
per il funzionamento di organi ed apparati, per il mantenimento
della temperatura corporea, per il continuo ricambio delle cellule
Che si rinnovano (pelle, sangue, intestino)
L’energia necessaria si ricava dagli 
alimenti
"
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#4,4,"E’ la somma dei nutrienti necessari contenuti nel cibo,
capaci di assicurare all’organismo uno stato di salute
ottimale e di assicurare al bambino un accrescimento
corrispondente al suo potenziale genetico ed alla sua etàFABBISOGNO ALIMENTARE
LIVELLI DI ASSUNZIONE RACCOMANDATI
Sono le quantità di alimenti sufficienti a coprire i bisogni 
nutrizionali di una persona sana."
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#5,5,"LE SOSTANZE NUTRITIVE
sono divise in  3 gruppi fondamentali
(funzione energetica )
(funzione plastica )
(funzione energetica e plastica )
Anche ACQUA , SALI MINERALI , VITAMINE e OLIGOELEMENTI
sono indispensabili per la vita: pur non fornendo energia essi sono
utilizzati per un corretto funzionamento di tutto l’organismo "
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#6,6,"GLI ALIMENTI CONTENGONO:
❖PROTEINE (liberano 4 cal. al gr.)
Pane, pesce, legumi, latte, formaggio, uova;
❖GLUCIDI/CARBOIDRATI (liberano 4 cal. al gr.)
Pane, pasta, riso, mais, orzo, patate;
❖GRASSI (liberano 9 calorie al gr.)
Olio, burro, margarina, panna, lardo …;
❖VITAMINE, SALI MINERALI E FIBRE
Frutta, ortaggi, legumi freschi "
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#7,7,"SANA ALIMENTAZIONE:
PIÙ CEREALI, LEGUMI, ORTAGGI E FRUTTA
Gli alimenti vegetali (cereali, legumi, ortaggi e frutta) sono molto 
importanti nella nostra alimentazione, perché contengono amido, fibra, 
vitamine, minerali e altre sostanze preziose per la salute. Cereali e legumi 
contengono anche proteine.
Mangiare prodotti vegetali aiuta a ridurre le calorie, saziando senza 
appesantire. L'ideale, quindi, è ricordarci di consumare tutti i giorni 
diverse porzioni di frutta e verdura (almeno 5 porzioni ).
Ogni giorno dovremmo mangiare anche pane, pasta o altri prodotti a base di 
cereali, meglio se integrali.
Gli alimenti vegetali costituiscono la base 
dell’alimentazione mediterranea"
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#8,8,"LA PIRAMIDE ALIMENTARE
«DIETA MEDITERRANEA»"
data_test\rootfolder\varie\Alimentazione\Educazione-Alimentare.pdf#9,9,"LA PIRAMIDE ALIMENTARE
«DIETA DELLO SPORTIVO»"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#0,0,"Fondamenti della Scienza
dell’Alimentazione
Via Icilio, 7 - 00153 Roma - www.onb.it
Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#1,1,"1
Fondamenti della Scienza
dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#10,10,10
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#100,100,"Le proprietà chimico-fisiche degli acidi grassi dipendono sostanzialmente dal
numero di atomi di carbonio presenti e dal loro grado di insaturazione. Tantopiù corta è la catena e più elevato è il grado d’insaturazione, tanto più è bassala temperatura di fusione. Per esempio, l’olio d’oliva, è liquido a temperaturaambiente e contiene principalmente acidi grassi monoinsaturi, come l’acidooleico (~ 65 %), e solo una piccola percentuale di acidi grassi saturi (~ 16 %).Al contrario il burro o la margarina, costituiti principalmente da acidi grassisaturi, sono solidi a temperatura ambiente.Gli acidi grassi presenti nei tessuti e nelle cellule dell’uomo possono essere diderivazione alimentare o generati attraverso sintesi endogena, a partire daprecursori più semplici ottenuti, per esempio, dalla decomposizione deglizuccheri. Il nostro organismo è in grado di sintetizzare, grazie all’azione dienzimi quali l’acido grasso sintasi, acidi grassi contenenti non più di 16 atomidi carbonio (acido palmitico, C16:0). Alcuni enzimi (elongasi) presenti sulversante citosolico del reticolo endoplasmatico, sono in grado di addizionareunità bicarboniose all’acido palmitico, favorendo così l’allungamento degliFigura 2: formula di struttura di un acido grasso saturo (A), acido grasso monoinsaturo con
doppi legami in configurazione “cis” (B), acido grasso monoinsaturo con doppi legami inconfigurazione “trans”.
100Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#101,101,"acidi grassi. Altri enzimi (desaturasi) provvedono poi ad inserire doppi legami,
generando così acidi grassi insaturi quali l’acido palmitoleico (C16:1 Δ9) e
l’acido oleico (C18:1 Δ9). Tuttavia l’uomo non possiede gli enzimi in grado
di introdurre, in un acido grasso, doppi legami oltre l’atomo di carbonio inposizione 9. Per tale motivo molecole quali l’acido linoleico (C18:2 Δ
9Δ12),
l’acido α-linolenico (C18:3 Δ9Δ12Δ15) e l’acido arachidonico (C20:4
Δ5Δ8Δ11Δ14) devono essere necessariamente introdotti con l’alimentazione e
vengono definiti acidi grassi essenziali (Essential Fatty Acid, EFA). L’acidolinoleico e linolenico possono essere convertiti nell’organismo in altri acidigrassi polinsaturi definiti essenziali di derivazione , indispensabili per la
biosintesi di prostaglandine, prostacicline, trombossani e leucotrieni,metaboliti attivi in molte importanti funzioni, tra cui la contrazione dellamuscolatura liscia, l’aggregazione piastrinica, la risposta infiammatoria, ecc(Figura 3).
Negli alimenti, la maggior parte degli acidi grassi si trova esterifica con altri
componenti, originando molecole complesse quali i triacilgliceroli, le cere, ifosfolipidi ed i glicolipidi. 
4.3 I triacilgliceroli
I triacilgliceroli o trigliceridi, sono esteri del glicerolo con tre acidi grassi,
generalmente differenti per il numero di atomi di carbonio (acidi a catena corta,media o lunga), per la presenza di doppi legami e per la loro posizioneall’interno della catena idrocarburica (Figura 4). Figura 3: formula di struttura di alcuni derivati di acidi grassi a 20 atomi di carbonio
(eicosanoidi)
101Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#102,102,"Essi sono sostanzialmente apolari, molto meno solubili dei singoli acidi grassi,
e vengono generalmente accumulati in cellule specializzate, gli adipociti,largamente presenti nei depositi sottocutanei, nelle cellule mammarie e nellacavità addominale. Dal momento che vengono conservati in forma pressochéanidra, essi occupano, da un punto di vista fisico, poco spazio. In un soggettodi 1,75 m di altezza e 70 Kg di peso (soggetto normopeso), i triacilglicerolicostituiscono circa 10-12 Kg del peso corporeo e rappresentano una importanteriserva di energia. Una volta ossidati forniscono circa 9 kcal/gr, una quantitàdi energia circa doppia rispetto a quella ricavata dall’ossidazione deicarboidrati (4 kcal/gr). Ciò è dovuto principalmente al fatto che gli acidi grassiin essi contenuti sono molecole fortemente ridotte e quindi maggiormenteossidabili rispetto a glucidi ed amminoacidi. In un soggetto normopeso, lariserva di energia presente sotto forma di triacilgliceroli ammonta a circa 100-130.000 kcal, quantità sufficiente, in caso di digiuno protratto, a garantirne lasopravvivenza per molti giorni. 
4.4 I lipidi di membrana: i fosfolipidi
I fosfolipidi sono molecole strutturalmente simili ai trigliceridi ma a differenza
di questi ultimi derivano dal fosfatidato o diacilglicerolo-3-fosfato, una
molecola contenete glicerolo in cui due gruppi ossidrilici (generalmente quelliin posizione C1 e C2) sono esterificati con acidi grassi ed il terzo gruppoossidrilico è esterificato con una molecola di acido fosforico. A differenza deitrigliceridi, i fosfolipidi possiedono generalmente una porzione polare,rappresentata dalla molecola legata al gruppo fosfato (Figura 5).Figura 4: formula di struttura generica di un triacilglicerolo. R1, R2e R3, rappresentano acidi
grassi di varia lunghezza e differente grado di insaturazione
102Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#103,103,"In molti casi il gruppo polare è costituito da un composto azotato, quali serina,
etanolammina o colina; in altri casi esso è costituito da un polialcol, come ilglicerolo o l’inositolo. Alcuni fosfolipidi non contengono glicerolo mamolecole complesse come la sfingosina, un aminoalcol che presenta una lungacatena idrocarburica insatura (Figura 6). In questo caso, i derivati prendono ilnome di sfingolipidi. 
Se disciolti in ambiente acquoso, i fosfolipidi si dispongono a formare un
doppio strato lipidico, una struttura lamellare estesa in cui le porzioniidrofiliche dei fosfolipidi sono esposte verso l’ambiente acquoso e quelleidrofobiche verso la parte interna del doppio strato, dalla quale le molecole diacqua vengono escluse (Figura 7). A volte tali strutture si ripiegano formandostrutture vescicolari chiuse (liposomi). La stabilità di tali strutture è garantitadalle numerose interazioni idrofobiche e legami di Van der Walls che siinstaurano tra le molecole di acidi grassi che formano i fosfolipidi. 
Figura 7: disposizione dei fosfolipidi in una membrana a doppio strato
Figura 5: formula di struttura di un fosfolipide generico. Il simbolo “X” indica il gruppo
sostituente polare
Figura 6: formula di struttura della sfingosina
103Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#104,104,"Grazie a tale tipo di organizzazione, i doppi strati lipidici risultano assai poco
permeabili a ioni o molecole polari. I fosfolipidi rivestono una funzione moltoimportante dal momento che sono i principali costituenti delle membranebiologiche, strutture formate da un doppio strato fosfolipidico contenenteproteine di membrana (Figura 8). 
4.5 Il colesterolo
Oltre a fosfolipidi, glicolipidi e proteine, le membrane biologiche contengono
anche colesterolo , un alcol a struttura complessa, caratterizzata da un anello
tetraidro-pentano-peridro-fenantrenico (Figura 9). Il colesterolo è presentenelle membrane di tutte le cellule eucariotiche ed in particolare nellemembrane plasmatiche dove può arrivare a rappresentare il 25% dei lipiditotali. Esso, grazie alla sua catena idrocarburica e alla sua struttura steroidea,sprofonda all’interno del doppio strato fosfolipidico, dove forma legamiidrofobici con gli acidi grassi che compongono i fosfolipidi. Il gruppoidrossilico del colesterolo invece sbuca sul lato esterno della membrana doveforma legami ad idrogeno con la componente idrofilica dei fosfolipidi.
Figura 9: formula di struttura del colesterolo
Figura 8: schema semplificato di una membrana plasmatica. Nel doppio strato fosfolipidico
sono immerse proteine di membrana (colore rosso e verde). Le porzioni idrofiliche deifosfolipidi, in grigio scuro, sono esposte verso l’ambiente acquoso mentre gli acidi grassi, ingrigio chiaro, sono disposti verso la parte più interna del doppio strato
104Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#105,105,"Formando un ampio network di legami con i fosfolipidi, il colesterolo riduce
la fluidità delle membrane biologiche; è ben noto che un eccesso di colesterolopuò arrivare a compromettere la funzionalità cellulare. Il colesterolo può essereintrodotto con gli alimenti (colesterolo esogeno), oppure essere sintetizzato alivello epatico (colesterolo endogeno). Un complicato meccanismo permettedi regolare la sintesi endogena epatica, controllando così anche i livelli dicolesterolo ematico (colesterolemia). Il colesterolo è un precursore essenzialeper la sintesi degli acidi biliari (i principali sono glicocolato e taurocolato),essenziali per la assicurare la corretta digestione intestinale degli acidi grassialimentari (Figura 10). 
In aggiunta il colesterolo è il precursore di tutti gli ormoni steroidei quali il
progesterone, l’aldosterone, il cortisolo, il testosterone e l’estradiolo oltre chedella vitamina D, ormone essenziale per la regolazione dell’accrescimentoosseo (Figura 11). La sintesi della vitamina D inizia grazie all’azione fotoliticadei raggi ultravioletti che convertono il colesterolo in previtamina D3; questaviene poi isomerizzata a vitamina D3 e poi convertita in calcitrolo (1,25-Diidrossicolecalciferolo), la forma biologicamente attiva della vitamina D. Lacarenza di vitamina D causa, nei bambini, il rachitismo, e l’osteomalacia, negliadulti.
Figura 10: formula di struttura dei principali sali biliari
105Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#106,106,"4.6 Digestione ed assorbimento dei lipidi
I lipidi sono costituenti essenziali di quasi tutti gli alimenti, sia di quelli di
origine animale che di quelli di origine vegetale. La frazione lipidica deglialimenti comprende i trigliceridi, i più rappresentati (circa il 90-95 % dei lipiditotali), i fosfolipidi, il colesterolo, la maggior parte del quale in formaesterificata, e le vitamine liposolubili. La quota di lipidi presenti negli alimentipuò variare molto. Per esempio il burro e l’olio sono costituiti quasiesclusivamente da lipidi; la maionese contiene quasi il 70% di lipidi, la fruttasecca il 60%, e la cioccolata il 35%. Le carni suine ed i salumi contengonocirca il 30 % di lipidi, le uova il 15%, vitello, pollo e coniglio il 12%, mentreil latte vaccino solo il 4-5%. Per evitare un eccessivo accumulo di acidi grassi,fenomeno che predispone ad un maggior rischio di sviluppare patologiecardiovascolari o il diabete, si raccomanda di un’assunzione giornaliera diacidi grassi non superiore ai 60 gr, di cui circa 25 preferibilmente di originevegetale e i rimanenti 35 di origine animale. A causa della loro natura idrofobica, il processo di digestione dei lipidi è unfenomeno abbastanza complesso. In soluzione acquosa i lipidi, oltre ai doppistrati, possono formare piccole micelle sferiche. Gli enzimi coinvolti nelladigestione dei lipidi, le lipasi, sono molecole idrofile; questo implica che ilprocesso di digestione dei lipidi debba avvenire all’interfaccia lipide-acqua.Per tale motivo più elevata è la superficie dell’interfaccia, maggiore è lavelocità di digestione dei lipidi. I continui movimenti peristaltici dello stomacoe dell’intestino favoriscono l’idratazione, l’estrazione dei lipidi dagli altricomponenti e la loro dispersione in piccole gocciole lipidiche contenentiprevalentemente triacilgliceroli. Tuttavia per ottenere una perfetta emulsionei soli movimenti peristaltici non sono sufficienti. Ciò è dovuto al fatto che, insoluzioni acquose, le goccioline lipidiche tendono ad aggregare rapidamente,Figura 11: principali funzioni del colesterolo
106Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#107,107,"formando complessi di maggiori dimensioni, difficilmente attaccabili dalle
lipasi. Perciò, per ottenere un’adeguata emulsione dei lipidi è necessaria anchela presenza dei sali biliari, molecole anfipatiche derivate dal colesterolo,sintetizzate dal fegato e accumulate nella cistifellea. I sali biliari, insieme aglienzimi digestivi, vengono secreti nel momento in cui il chimo inizia il suopercorso all’interno dell’intestino. Questi si organizzano in micelle di piccoledimensioni (micelle biliari, contenenti altri agenti surfattanti quali acidi grassie fosfolipidi) che interagiscono con la superficie delle gocciole lipidiche,impedendo a queste ultime, una volta disperse nella soluzione acquosa, diaggregare nuovamente (Figura 12). Per tale motivo si è soliti affermare che isali biliari hanno azione detergente e contribuiscono ad emulsionare i lipididisperdendoli in gocciole di piccole dimensioni, facilitando così l’azione dellelipasi. 
L’uomo possiede diversi lipasi: una lipasi linguale, una lipasi gastrica ed una
pancreatica. Sebbene la lipasi linguale e quella gastrica contribuiscano alladigestione dei lipidi, quella più importante è, senza dubbio, quella pancreatica.Tuttavia tale enzima non riesce, a causa della presenza delle micelle biliari,ad interagire facilmente con le gocciole lipidiche. Per poter agire efficacementeesso necessita dell’intervento di una colipasi, una proteina in grado, da unaparte, di legare saldamente la lipasi, e dall’altra, di scalzare le micelle biliaridalla superficie delle gocciole lipidiche ed interagire con i lipidi che lecompongono, permettendo alla lipasi di venire a contatto con il suo substrato.La lipasi pancreatica idrolizza i legami estere in posizione 1 e 3 dei
Figura 12: goccia lipidica circondata da micelle biliari
107Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#108,108,"triacilgliceroli, liberando due molecole di acidi grassi e una molecola di 2-
monoacilglicerolo. I prodotti dell’idrolisi vengono estratti dalle gocciolelipidiche e trasferiti sulle micelle biliari (Figura 13). 
In tal modo il contenuto di triacilgliceroli all’interno delle gocciole lipidiche
si riduce velocemente mentre gli acidi grassi e le molecole di 2-monoacilglicerolo vengono trasportati in prossimità delle cellule intestinalidalle micelle biliari e poi assorbiti dagli enterociti. In maniera simile, il colesterolo esterificato presente negli alimenti verrà idro-lizzato dalla colesterolo esterasi pancreatica e trasformato in colesterolo libero,il quale verrà poi veicolato dalle micelle biliari fino agli enterociti, che lo as-sorbiranno. Una volta esaurita la loro funzione, la maggior parte dei sali biliariviene riassorbita nell’ileo distale (solo il 2% viene perso con le feci), per poiessere trasportati al fegato attraverso la vena porta. Dal fegato i sali biliari ven-gono trasferiti nuovamente nella cistifellea dove vengono accumulati fino alpasto successivo. Tale meccanismo viene descritto come circolazione ente-roepatica degli acidi biliari. Una volta all’interno degli enterociti, la maggiorparte degli acidi grassi vengono nuovamente esterificati per originare trigli-ceridi. Una quota minore di acidi grassi, generalmente quelli a catena corta,passa direttamente nel sangue dove si lega all’albumina la quale provvede aFigura 13: idrolisi dei trigliceridi presenti nelle gocce lipidiche da parte della lipasi gastrica. La
colipasi spiazza le micelle biliari e si lega ai trigliceridi, veicolando la lipasi gastrica in corrispondenzadel proprio substrato. Gli acidi grassi liberati, ed il 2-monoacilglicerolo, insolubili nell’ambienteacquoso, vengono trasferiti sulle micelle biliari le quali li trasportano fino agli enterociti
108Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#109,109,"trasportarli ai vari tessuti. I triacilgliceroli, così come il colesterolo, gli esteri
del colesterolo ed i fosfolipidi, sono fortemente insolubili e non potrebberomai essere riversati, come tali, nel torrente circolatorio. Il trasporto di tali mo-lecole è assicurato dalle lipoproteine. 
4.7 Il trasporto dei lipidi: le lipoproteine
Le lipoproteine plasmatiche sono sostanzialmente aggregati lipido-proteici incui la componente proteica, chiamata apolipoproteina, è in grado di associarsiai trigliceridi, ai fosfolipidi, al colesterolo e agli esteri del colesterolo. Nellelipoproteine i gruppi polari degli amminoacidi, dei fosfolipidi e del colesterololibero sono rivolti all’esterno della molecola, mentre i lipidi non polari (esteridel colesterolo e trigliceridi) sono situati al centro della molecola (Figura 14).Le lipoproteine trasportano anche le vitamine liposolubili. 
La concentrazione plasmatica delle lipoproteine raggiunge valori di circa 500
mg/dl; il loro contenuto è tuttavia variabile, a seconda dell’età, sesso, fattoriormonali e dietetici. Si conoscono diverse classi di lipoproteine le qualipossono essere classificate in base alla loro densità; queste sono i chilomicroni,le very low density lipoprotein, VLDL, le intermediate density lipoprotein,IDL, le low density lipoprotein, LDL e le high density lipoprotein, HDL. Ogni
Figura 14: struttura delle lipoproteine plasmatiche. La porzione più esterna è costituita da
lipidi polari e proteine, mentre la porzione più interna da lipidi idrofobici ed esteri delcolesterolo
109Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#11,11,11Capitolo I Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#110,110,"particella lipoproteica contiene la quantità sufficiente di proteine, fosfolipidi
e colesterolo per formare, sulla sua superficie, un monostrato di questicomponenti di circa 20 Ǻngstrom di spessore. La densità delle lipoproteineaumenta con il diminuire del diametro della particella, in quanto la densità delrivestimento più esterno è maggiore di quella del nucleo più interno. Così, leHDL, che sono le lipoproteine a maggiore densità, sono anche le particellepiù piccole. I chilomicroni vengono sintetizzati nell’intestino, le VLDLnell’intestino e nel fegato, le HDL nel fegato; le IDL e le LDL derivano invecedalle VLDL. Il contenuto ed il tipo di lipidi varia molto tra le varielipoproteine: i chilomicroni contengono prevalentemente triacilgliceroli diorigine alimentare, le VLDL triacilgliceroli, fosfolipidi ed esteri del colesterolodi sintesi endogena, le IDL triacilgliceroli e fosfolipidi, le LDL esteri delcolesterolo e fosfolipidi, le HDL, colesterolo e fosfolipidi. In aggiunta,ciascuna classe contiene differenti tipi di apolipoproteine; esse sono statedenominate: A, B
48, B100, C, E, A-1, A-2, A-4 (vedi Tabella 1). La componente
proteica è in genere rivolta verso la superficie della molecola, ed è costituitada segmenti, in parte a-elicoidali, in parte a foglietti β antiparalleli. 
I chilomicroni sono sintetizzati nella mucosa intestinale ed i triacilgliceroli
in essi contenuti derivano dai lipidi della dieta: vengono rilasciati nel circolo
linfatico per poi defluire nel circolo sanguigno; attraverso il sistemacircolatorio raggiungono tutti gli altri tessuti. Prevalentemente a livello deltessuto adiposo e muscolare, i trigliceridi contenuti nei chilomicroni vengonoidrolizzati dalla lipoproteina lipasi, ancorata agli endoteli dei capillari. Gli
acidi grassi rilasciati possono essere ossidati nel muscolo o essere depositaticome trigliceridi nel tessuto adiposo. In seguito al rilascio progressivo deitrigliceridi, i chilomicroni si restringono fino a formare particelle chiamateChilomicroni VLDL IDL LDL HDL
Origine Intestino Fegato, VLDL VLDL Fegato
Intestino
Densità < 0.95 0.95-1.006 1.006-1.019 1.019-1.063 1.019-1.20
Composizione in Trigliceridi Trigliceridi, Colesterolo, Colesterolo Fosfolipidi
lipidi (prevalenti) Fosfolipidi Trigliceridi Colesterolo
Apoproteine C-III, C-II, C-I, B-100, C-III, B-100, B-48, E B-100 A-I, A-II, D,
B48, E, A-I, E, C-II, C-I, C-III, C-I, EA-II A-II, A-ITabella 1: proprietà delle lipoproteine plasmatiche
110Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#111,111,"chilomicroni residui, ricchi di colesterolo, che vengono trasportati al fegato,
dove, in seguito all’interazione con recettori specifici presenti sugli epatociti,vengono internalizzati, per endocitosi, all’interno delle cellule epatiche. Le
VLDL sono sintetizzate nel fegato per trasportare trigliceridi, colesterolo e
fosfolipidi di derivazione endogena (neosintesi); anch’esse sono substrato dellalipoproteina lipasi presente nei capillari del tessuto adiposo e del muscolo. Gliacidi grassi rilasciati sono assorbiti dalle cellule e ossidati per produrre energiaoppure sono utilizzati dagli adipociti per sintetizzare trigliceridi. Dopo averceduto i loro trigliceridi, le VLDL residue che hanno perso una parte delle
loro apolipoproteine compaiono nel circolo sanguigno come IDL e
successivamente come LDL. Queste interagiscono con i recettori presenti sulla
membrana plasmatica di varie cellule, per poi essere internalizzate perendocitosi e idrolizzate dagli enzimi lisosomiali. Le LDL sono coinvolte nel
trasporto del colesterolo esterificato ai vari tessuti. Le HDL hanno una
funzione opposta rispetto alle LDL: rimuovono il colesterolo dai tessuti e lo
trasportano al fegato. Si formano nel sangue da componenti ottenuti per lamaggior parte dalla degradazione di altre lipoproteine. Le HDL circolanti
probabilmente assumono il colesterolo dalle membrane della superficiecellulare e lo convertono in esteri del colesterolo grazie all’enzima lecitina
colesterolo acil tranferasi plasmatica, che trasferisce acidi grassi dalle lecitine
al colesterolo. Le HDL sono internalizzate nel fegato per endocitosi e
idrolizzate dagli enzimi lisosomiali. Una volta nel fegato, gli esteri delcolesterolo vengono idrolizzati ed il colesterolo libero può essere inserito nelleVLDL o convertito in sali biliari. In conclusione, il colesterolo esterificato è
legato sia alle HDL (per il 25%) che alle LDL (per il 75%), con le quali è
trasportato ai vari tessuti, dove si trovano recettori soprattutto per le LDL; il
fegato, oltre a possedere i recettori per le IDL e LDL, possiede anche quelliper le HDL (Figura 15). 
111Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#112,112,"4.8 La biosintesi dei lipidi
Nell’uomo, ed in molti animali, un eccesso di nutrienti, ed in particolare di
carboidrati, viene generalmente convertito in acidi grassi, e poi in trigliceridi,i quali vengono accumulati nel tessuto adiposo. La sintesi degli acidi grassi èparticolarmente attiva nel fegato, nell’intestino, nella ghiandola mammaria enel tessuto adiposo. Nel fegato, dopo un pasto abbondante, l’afflusso diglucosio permette di saturare rapidamente le riserve epatiche di glicogeno;l’ulteriore eccesso viene così trasformato in acidi grassi. L’insulina svolge unafunzione essenziale in questo processo: essa stimola la conversione delglucosio in piruvato, il quale viene poi trasformato in acetil-CoA, precursoreessenziale per la sintesi degli acidi grassi. A sua volta, l’acetil-CoA è ancheun potente attivatore allosterico dell’enzima piruvato carbossilasi il qualeconverte il piruvato in ossalacetato. Piruvato ed ossalacetato sono entrambisubstrati dell’enzima citrato sintasi. Di conseguenza, dopo un pastoabbondante, nei mitocondri la quantità di citrato sintetizzato aumenta molto,e parte di esso viene esportato nel citoplasma. Una volta nel citoplasma, ilcitrato viene scisso in acetil-CoA ed ossalacetato ad opera dell’enzima citratoliasi. Nel citoplasma, l’acetil-CoA agisce da attivatore allosterico dell’enzimaacetil-CoA-carbossilasi il quale catalizza la sintesi del malonil-CoA,precursore fondamentale per la sintesi degli acidi grassi (Figura 16). Figura 15: funzioni delle lipoproteine plasmatiche 
112Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#113,113,"Il malonil-CoA è un potente inibitore dell’enzima acil-CoA: carnitina
aciltranferasi ed è in grado di bloccare il trasporto degli acidi grassi nelmitocondrio, inibendo così anche il loro processo di degradazione. In tal modo,sintesi e degradazione degli acidi grassi risultano reciprocamente regolati:l’abbondanza di zuccheri attiva la sintesi dei lipidi ma blocca la lorodegradazione. Nel fegato, i livelli di espressione di enzimi quali la piruvato deidrogenasi, lacitrato liasi, l’acetil-CoA carbossilasi e quelli appartenenti al complessodell’acido grasso sintasi aumentano in seguito alla presenza di glucosio edinsulina. In aggiunta l’insulina è in grado di stimolare l’attività della citratoliasi e dell’acetil-CoA carbossilasi, incrementando così la sintesi degli acidigrassi a catena lunga quali l’acido palmitico. Al contrario, il glucagone stimolala fosforilazione, e quindi l’inibizione, dell’enzima acetil-CoA carbossilasi,bloccando la sintesi degli acidi grassi. La sintesi di acidi grassi è un processocomplesso che richiede energia.
8 acetil-CoA + 7ATP + 14 NADPH + 14 H
+Palmitato + 
8 CoA + 7 ADP + 7 Pi + 14 NADP++ 6 H2O
Nelle cellule epatiche, il NADPH necessario alla sintesi degli acidi grassi vieneFigura 16: regolazione della sintesi degli acidi grassi
113Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#114,114,"generato attraverso il ciclo dei pentosi fosfati o grazie all’azione dell’enzima
malico, altro enzima la cui sintesi è stimolata dall’insulina. Nell’uomo,l’enzima acido grasso sintasi produce molecole non più lunghe di 16 atomi dicarbonio: per tale motivo il palmitato è il principale prodotto dell’attività delcomplesso multienzimatico dell’acido grasso sintasi. Il complessomultienzimatico denominato acido grasso elongasi, localizzato nel reticoloendoplasmatico, contribuisce poi ad allungare la catena degli acidi grassisintetizzati fino ad ottenere, come avviene nel cervello, acidi grassi a catenamolto lunga (22-24 atomi di carbonio) che poi verranno utilizzati per la sintesidegli sfingolipidi. Altri enzimi, le desaturasi, sono in grado di inserire doppilegami nella struttura degli acidi grassi saturi generando acidi grassi mono- epolinsaturi. Spesso l’inserimento di doppi legami avviene tra gli atomi dicarbonio in posizione 9 e 10, generando così molecole quali l’acidopalmitoleico (C16:1Δ
9) e l’acido oleico (C18:1Δ9). 
In caso di necessità, le cellule del nostro organismo, ed in particolare le celluleepatiche, possono sintetizzare anche il colesterolo. La sintesi di questo steroloinizia con la condensazione di due molecole di acetil-CoA, per ottenereacetoacetil-CoA. Un’ulteriore molecola di acetil-CoA viene utilizzata pergenerare il 3-idrossi-3-metilglutaril-CoA (HMG-CoA), il quale viene poiridotto a mevalonato, il primo intermedio specifico della via di sintesi delcolesterolo. Attraverso una complessa serie di reazioni, il mevalonato vieneconvertito in un composto con 30 atomi di carbonio, lo sqalene, il quale vienepoi trasformato, attraverso altre reazioni, in colesterolo. In condizioni ideali,
esiste una diretta correlazione tra la quota di colesterolo sintetizzato e quellaassunta attraverso la dieta: maggiore è la quota di colesterolo proveniente dalladieta, tanto minore sarà la quota sintetizzata dalle stesse cellule. Tra i fattoriche contribuiscono a regolare la sintesi endogena di colesterolo vi è la quantitàdi colesterolo libero presente all’interno delle cellule e l’azione di ormoni qualil’insulina ed il glucagone. Quando i livelli di colesterolo intracellularidiminuiscono, le proteine che legano gli elementi di regolazione degli steroli(Sterol Regulatory Element-Binding Protein, SRBEP) vengono attivate,migrano nel nucleo dove stimolano la trascrizione dei numerosi geni, tra cuiquello dell’enzima che sintetizza il mevalonato, l’HMG-CoA reduttasi. Alcontrario, un aumento della quantità intracellulare di colesterolo liberodetermina la riduzione dell’attività della HMG-CoA reduttasi, una riduzionedi espressione del recettore per le LDL, un aumento dell’attività dell’enzimaacil-CoA colesterolo aciltransferasi (ACAT) il quale favorisce l’accumulo dicolesterolo esterificato all’interno delle cellule. L’insulina stimola la glicolisi,
114Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#115,115,"la conversione del piruvato in acetil-CoA e attiva la HMG-CoA riduttasi,
favorendo la sintesi di colesterolo; questo spiega perché una dieta ricca inglucidi possa determinare un aumento dei livelli di colesterolo circolante,incrementando il rischio di insorgenza di patologie a carico dell’apparatocardiocircolatorio. Il glucagone, al contrario, inattiva l’enzima HMG-CoAriduttasi, inibendo così la sintesi del colesterolo (Figura 17). La mancataespressione dei recettori per le LDL o difetti del loro funzionamento sonoimportanti fattori di rischio per patologie quali l’aterosclerosi. Con una certafrequenza nella popolazione si manifestano mutazioni genetiche a carico deigeni responsabili della sintesi del recettore per le LDL o a carico di geni cheesprimono proteine coinvolte nella regolazione di tali recettori. I soggettiportatori di tali mutazioni soffrono di ipercolesterolemia familiare, unapatologia caratterizzata da un costante eccesso di colesterolo circolante chedifficilmente può essere ridotto, anche se i pazienti vengono sottoposti ad unrigido controllo della dieta.
La maggior parte delle volte, la causa è proprio una mutazione del gene per il
recettore delle LDL. I pazienti portatori di queste mutazioni presentano unbasso numero di recettori per le LDL e, di conseguenza, la loro captazione da
Figura 17: regolazione ormonale della sintesi del colesterolo
115Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#116,116,"parte del fegato e dei tessuti periferici è fortemente compromessa. Individui
omozigoti per la mutazione mostrano elevati livelli di LDL e IDL circolanti,e livelli di colesterolo tre volte superiori alla norma; depositi di colesteroloappaiono sulla pelle, sui tendini e su altri tessuti, ma l’accumulo più pericolosoè quello a livello dell’endotelio arterioso. L’accumulo di colesterolo causadisturbi cardiaci, alterazioni della circolazione periferica, ed infartomiocardico. Gli individui omozigoti per questo tipo di mutazione, muoionogeneralmente per patologie coronariche durante l’infanzia; al contrario, isoggetti eterozigoti presentano disturbi più moderati con prognosi variabile.Le ricerche effettuate hanno permesso di identificare differenti tipi dimutazione che possono contribuire all’insorgenza di tale patologia. Alcune diqueste determinano la perdita della capacità di sintetizzare il recettore, mentrein altri casi il recettore viene sintetizzato ma non può essere trasferito sullamembrana plasmatica delle cellule. In altri casi ancora, il recettore sintetizzatoha difetti strutturali e non è in grado di riconosce in maniera appropriata, equindi legare, le LDL. Infine vi sono soggetti in cui il recettore riconosce leLDL ma non è in grado di modulare la loro internalizzazione. In ogni caso,l’unica opzione terapeutica per gli individui omozigoti per laipercolesterolemia familiare è il trapianto di fegato. Al contrario, per i soggettieterozigoti, è disponibile oggi un trattamento farmacologico (statine) in gradodi migliorare la loro condizione. Dal momento che l’espressione dei recettoriper le LDL riflette la necessità di colesterolo della cellula stessa, negli individuieterozigoti l’approccio farmacologico è destinato ad abbassare i livellicitoplasmatici di colesterolo attraverso specifici inibitori della sua biosintesi.Le statine (Simvastatina, Pravastatina e Lovostatina) sono molecole simili almevalonato, ed agiscono da inibitori competitivi di uno degli enzimi chiaveper la sintesi del colesterolo, l’enzima HMG-CoA reduttasi. Lasomministrazione di statine è associata ad una riduzione dei livelli dicolesterolo circolante ed, in molti casi, ciò comporta anche un’aumentataespressione di recettori per le LDL per poter captare il colesterolo in essecontenuto.
4.9 Il catabolismo dei lipidi
In caso di digiuno o attività fisica prolungata, i lipidi, ed in particolare i
trigliceridi, possono soddisfare la richiesta di energia anche per lunghi periodi.Ormoni quali il glucagone e adrenalina si legano a recettori specifici presenti
116Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#117,117,"sulla membrana degli adipociti, innescando una via di segnalazione che
culmina con l’attivazione della lipoproteina lipasi ormone-dipendente. Taleenzima è in grado d’idrolizzare tutti i legami estere dei triacilgliceroli,producendo acidi grassi liberi e glicerolo che vengono poi espulsi dagliadipociti. Il glicerolo, molecola solubile, attraverso il sangue raggiunge ilfegato, dove viene trasformato in diidrossiacetonefosfato che verrà poiutilizzato come intermedio per sintetizzare glucosio. Gli acidi grassi, una voltariversati nel sangue si legano all’albumina e, attraverso questa, vengonoveicolati alle cellule del nostro organismo che necessitano di substrati daossidare per produrre energia. Grazie a trasportatori di membrana specifici(CD36, FAT, FABP) gli acidi grassi riescono ad entrare all’interno delle celluledove divengono substrati degli enzimi coinvolti nel loro catabolismo. Tutte lecellule, ad eccezione delle cellule nervose e degli eritrociti, sono in grado dimetabolizzare gli acidi grassi. Una volta nel citoplasma delle cellule, gli acidigrassi divengono substrato di un enzima, l’Acil-CoA sintetasi, in grado diesterificare l’acido grasso con una molecola di CoA; tale reazione vienegeneralmente definita come reazione di attivazione degli acidi grassi dalmomento che, solo se legati al CoA, gli acidi grassi a catena lunga potrannoessere metabolizzati. La reazione richiede il consumo di due molecole di ATP. 
Acido grasso + ATP + CoA Acil-CoA + AMP + PPi
Una volta attivati, gli acidi grassi devono essere trasportati all’interno delmitocondrio, dove si trovano gli enzimi in grado di catalizzare la lorodegradazione. Gli acidi grassi a catena corta, a contrario di quelli a catenalunga, non hanno bisogno di trasportatori per entrare all’interno delmitocondrio. Al contrario, gli acidi grassi a catena lunga vengono trasportatiall’interno del mitocondrio attraverso uno specifico trasportatore, la carnitina
(Figura 18).
                                                                                   
L’enzima acil-CoA: carnitina aciltranferasi I catalizza il trasferimento della
Figura 18: struttura chimica della carnitina
117Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#118,118,"molecola di acido grasso sulla carnitina.
Acil-CoA + carnitina Acil-carnitina + CoA
A questo punto, grazie all’intervento di un trasportatore specifico presente
sulla membrana mitocondriale interna, il complesso acil-carnitina vienetrasferito all’interno del mitocondrio, mentre, una molecola di carnitina vieneportata all’esterno del mitocondrio. Una volta nella matrice mitocondriale,l’enzima carnitina aciltranferasi II provvede a liberare l’acido grasso e
rigenerare la carnitina nella forma libera
Acil-carnitina + CoA Acil-CoA + carnitina
A questo punto inizia il vero e proprio processo di degradazione degli acidigrassi, definito β-ossidazione. Tale processo consiste in quattro reazioni,
catalizzate da altrettanti enzimi, grazie alle quali due atomi di carboniovengono staccate dalla struttura dell’acido grasso e liberate sotto forma diacetil-CoA (Figura 19). 
Figura 19: schema della β-ossidazione
118Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#119,119,"4.10 Sintesi e funzione fisiologica dei corpi chetonici
Nel fegato, il destino metabolico dell’acetil-CoA generato attraverso la
degradazione degli acidi grassi dipende fondamentalmente dalla disponibilitào meno di ossalacetato. In condizioni di moderata disponibilità di glucosio,l’enzima citrato sintasi utilizza ossalacetato e acetil-CoA, per sintetizzare unamolecola di citrato, indirizzando così l’acetil-CoA proveniente dalladegradazione degli acidi grassi nel ciclo degli acidi tricarbossilici (ciclo diKrebs). L’ossalacetato necessario viene sintetizzato a partire dal piruvato,grazie all’azione dell’enzima piruvato carbossilasi, il quale, a sua volta, vieneattivato dall’ acetil-CoA. Quindi, elevate concentrazioni di acetil-CoAstimolano la produzione di ossalacetato, intermedio utile ad assicurare latrasformazione dell’acetil-CoA prodotto dalla degradazione degli acidi grassiin citrato (Figura 20). 
In condizioni di digiuno prolungato, il glucagone, legandosi ai recettori
presenti sulla membrana delle cellule epatiche, inibisce la glicolisi e stimolala gluconeogenesi, la quale sottrae molecole di ossalacetato al ciclo di Krebs,destinandole alla sintesi del glucosio. In tal modo gran parte dell’acetil-CoA
Figura 20: Metabolismo degli acidi grassi in condizioni di moderata disponibilità di glucosio
119Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#12,12,"MANUALE
I Fondamenti della Scienza dell’Alimentazione
CAPITOLO I
I MACRO e MICRONUTRIENTI
RiassuntoIn questo capitolo si forniranno cenni su alcuni micro e macro nutrienti, questiultimi verranno approfonditi nei capitoli III, IV e V . I micronutrienti, sali minerali e vitamine, sono sostanze ingerite con gli alimenti(frutta e verdura), la cui funzione non è direttamente correlata alla produzione dienergia e alla crescita, ma necessari al mantenimento delle funzioni dell’organismo. Per garantire un corretto sviluppo e mantenimento dell’organismo, oltre aduna alimentazione equilibrata e una regolare attività fisica, l’OMS promuovel’assunzione di almeno 400 g al giorno per persona, di frutta e verdura (con-tenenti principalmente vitamine e sali minerali), quantità che corrisponde acirca cinque porzioni.Secondo gli studi dell’Ufficio Regionale Europeo dell’OMS, l’assunzione difrutta e verdura è in quasi tutti i paesi a livelli ben più bassi di quanto racco-mandato. A rischio, in particolare i ragazzi tra i 9 e i 16 anni, per uno scarsoconsumo quotidiano di frutta e verdura.Un’alimentazione equilibrata, in cui sono presenti tutti i gruppi di alimenti, risultafondamentale, insieme ad un’adeguata attività fisica (camminata a passo veloce,ballo, palestra e altro), per la prevenzione di diverse condizioni patologiche.I processi di cottura riducono la quantità di questi micronutrienti, quindi sarebbeopportuno utilizzare, ad esempio, la cottura a vapore, o l’assunzione di frutta everdura fresca di stagione, e possibilmente proveniente da agricoltura biologicae appena raccolta. L’unità di misura utilizzata per queste sostanze è il milligrammo o microgrammo.I macronutrienti sono princìpi alimentari introdotti in grandi quantità, poichérappresentano la più importante fonte energetica per l’organismo, utile siaper la crescita sia per mantenere il metabolismo. Appartengono a questa categoria i carboidrati o glucidi, i grassi o lipidi e leproteine o protidi.L’unità di misura utilizzata per queste sostanze è il grammo. Ognuna di queste sostanze, assunte con la dieta quotidianamente, ha funzionidifferenti e viene gestita in modo diverso dal nostro organismo.
12Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#120,120,"prodotto dalla degradazione degli acidi grassi non entra nel ciclo di Krebs, ma
piuttosto viene utilizzato per la sintesi dei corpi chetonici. La sintesi dei corpichetonici inizia con la condensazione di due molecole di acetil-CoA, pergenerare acetoacetil-CoA. Una terza molecola di acetil-CoA vienesuccessivamente addizionata per ottenere l’HMG-CoA. Quest’ultimo vienepoi scisso dall’enzima HMG-CoA liasi in acetil-CoA e acetoacetato.L’acetoacetato può avere due differenti destini: andare incontro ad un processodi decarbossilazione spontanea, generando acetone, oppure essere ridotto a 3-idrossibutirrato. Acetone, acetoacetato e 3-idrossibutirrato sono le molecoleche vengono comunemente chiamate corpi chetonici (Figura 21).
I soggetti che seguono una dieta bilanciata producono solo una piccola quantità
di corpi chetonici dal momento che la quantità di ossalacetato disponibile èsufficiente ad indirizzare l’acetil-CoA prodotto nel ciclo di Krebs. Al contrario,in condizione di digiuno prolungato, nel caso di diete povere in carboidrati enel diabete non trattato, le quantità di ossalacetato disponibili non sonosufficienti a compensare il forte incremento dei livelli di acetil-CoA,determinando, specialmente nel fegato, un rapido aumento della produzioneFigura 21: Sintesi dei corpi chetonici nelle cellule epatiche in condizioni di digiuno
prolungato. In queste condizioni, l’abbondante presenza di NADH causa l’inibizionedell’isocitrato deidrogenasi, della piruvato deidrogenasi, forzando, inoltre, la conversione diossalacetato in malato. Questo può uscire dal mitocondrio ed essere nuovamente ossidato adossalacetato, il quale verrà indirizzato nella gluconeogenesi. A causa della carenza diossalacetato, l’acetil-CoA prodotto viene utilizzato per sintetizzare corpi chetonici
120Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#121,121,"dei corpi chetonici. Questi ultimi svolgono una funzione molto importante dal
momento che, una volta rilasciati nel sangue, sono in grado di soddisfare larichiesta energetica di molti tessuti extraepatici quali il muscolo scheletrico,il cuore ed il cervello. Quest’ultimo usa esclusivamente glucosio per ricavareenergia per il proprio sostentamento; in condizioni di ristrettezze (digiuno), ilcervello è in grado di sostituire buona parte del glucosio con i corpi chetonici,utilizzando l’acetoacetato ed il 3-idrossibutirrato per alimentare il ciclo diKrebs e ricavare ATP. E’ stato calcolato che in condizioni di digiuno prolungato, i corpi chetonicisoddisfano circa il 75% della richiesta energetica del cervello. In tal modo ilfegato può continuare a degradare acidi grassi anche se l’acetil-CoA non vieneindirizzato all’interno del ciclo di Krebs, ed i tessuti periferici possonocompensare la carenza di glucosio, utilizzando i corpi chetonici per ricavareenergia, riducendo così la richiesta di glucosio. L’acetone, generalmenteprodotto in piccole quantità rispetto agli altri due metaboliti, viene quasicompletamente allontanato dal sangue con la respirazione. 
121Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#122,122,"Bibliografia
• Saliprandi & Tettamanti Biochimica Medica Edizioni Piccin 1010 pp 2011
• D. V oet, J.G. V oet, C.W. Pratt. Fondamenti di Biochimica. Edizioni Zanichelli. 3 Ed. 1200
pp. 2013
• John W. Baynes, Marek H. Dominiczak Biochimica per le discipline biomediche. Edizioni
Elsevier. 653 pp. 2011
• G. Zubay, W.W. Parson, D.E. Vance. Principles of Biochemistry. Edizioni McGraw-Hill
Education, 992 pp. 1995
• David L. Nelson, Michael M Cox I principi di Biochimica di Lehninger, Edizioni Zanichelli,
V Ed. 1288 pp. 2010
• Giuseppe Arienti Le basi molecolari della nutrizione Edizioni Piccin. Terza edizione 1111
pp. 2011
122"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#123,123,123Capitolo V Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#124,124,"CAPITOLO V
LE PROTEINE
Riassunto
Le Proteine sono macromolecole costituite da amminoacidi che si legano con
legame peptidico in lunghe catene polipeptidiche. Esse svolgono funzioni es-senziali per tutti i processi biologici, quali quelle strutturali, di catalisi enzi-matica, di trasporto e deposito, di movimento coordinato, di protezioneimmunitaria. Nelle Proteine possiamo individuare una struttura primaria, unasecondaria, una terziaria ed una quaternaria. Possono essere distinte in P .semplici e Proteine coniugate. La digestione delle Proteine consiste nella di-sgregazione meccanica, chimica ed enzimatica delle proteine contenute neicibi che vengono ridotte a unità più piccole, fino a ridurle in aminoacidi o di-e tripeptidi prima che possa aver luogo l’assorbimento. In questo processointervengono enzimi proteolitici quali endo ed esopeptidasi. Seguono processidi deaminazione, transaminazione e trans-desaminazione che portano all’eli-minazione del gruppo amminico NH
2sotto forma di ammoniaca NH3nel ciclo
dell’urea.
124Fondamenti della Scienza dell’Alimentazione Capitolo V"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#125,125,"5.1 Proteine
Le Proteine sono sostanze organiche con un alto grado di complessità, macro-
molecole costituite da una, o diverse, lunghe catene polipeptidiche (detteanche protidi). Le proteine sono la classe di molecole organiche più abbondanti in tutti gli or-ganismi viventi; si trovano in tutte le cellule e costituiscono più della metà delloro peso secco. Si stima che esistano più di 50.000 proteine mane e che il numero di proteinedistinte all’interno di una cellulari tra le 3.000 e le 5.000.Nel solo siero possono essere identificate più di 1.400 proteine.Le proteine sono essenziali per tutti i processi biologici legati alle funzioni vi-tali. Le loro funzioni sono molteplici:- intervengono come componenti primari nella struttura e nelle funzioni cellulari- svolgono un ruolo fondamentale nei processi di catalisi enzimatica, infatti
tutti gli enzimi sono proteine 
- sono deputate a funzioni di trasporto e deposito, come l’ emoglobina , la mio-
globina, la transferrina, la ferritina.
- permettono le funzioni di movimento coordinato, come l ’actina-miosina , la
tubulina-dineina
- costituiscono basi di supporto meccanico, come il collagene , la cheratina
- esercitano funzioni di protezione immunitaria, infatti gli anticorpi sono pro-
teine altamente specifiche
- sono in grado di esercitare la funzione di generazione e trasmissione del-
l’impulso nervoso, come la rodopsina, presente nei bastoncelli della retina,
proteina in grado di funzionare come recettore della luce
- svolgono azioni di controllo della crescita e della differenziazione in grado
di stimolare la proliferazione e il differenziamento cellulare, come il growth
factor
- permettono la comunicazione tra le cellule di un organismo, come le cito-
chine, molecole infiammatorie o gli ormoni che si legano a specifici recettorisulla membrana cellulare dei loro target, come insulina e glucagone
- hanno azione aggressiva, come le esotossine batteriche, t. botulinica , t.te-
tanica, t. carbonchiosa, e come alcuni veleni di serpente che rappresentano
una complessa secrezione proteica costituita da neurotossine ad azione pre-
sinaptica o post-sinaptica
- svolgono la funzione essenziale di sintesi proteica da parte degli organismi
viventi, detta protidopoiesi .
125Capitolo V Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#126,126,"5.2 Struttura
Le Proteine sono polimeri (macromolecole costituite da numerosi gruppi mo-
lecolari) costituite da un insieme di molecole di a-amminoacidi (detti ancheresidui amminoacidici), legate fra loro mediante legami peptidici tra il gruppocarbossilico di una molecola e il gruppo amminico della successiva, costi-tuendo nel loro insieme una catena polipeptidica (Figura 1). 
Il peso molecolare delle proteine può variare da circa 5000-10.000 in quelle
più piccole (40-80 amminoacidi) sino ad alcuni milioni per quelle più grandie complesse. Gli amminoacidi costituenti le proteine sono 20, tutti L-isomeri.Nelle proteine possiamo individuare una struttura primaria, una secondaria,una terziaria ed una quaternaria.
5.2.1 La struttura primariaE’ determinata dalla sequenza dei diversi amminoacidi che costituiscono la
catena polipeptidica (Figura 2).Figura 1: struttura chimica di un amminoacido
Figura 2: esempio di catena polipeptidica. I singoli amminoacidi sono legati tra loro da un
legame peptidico
126Fondamenti della Scienza dell’Alimentazione Capitolo V"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#127,127,"La struttura primaria, cioè tipo e sequenza degli aminoacidi, condiziona la
configurazione spaziale e la forma globale della molecola, dalle quali dipen-dono le proprietà biologiche.
5.2.2 La struttura secondariaSi distinguo principalmente due tipi di struttura secondaria: la struttura ad a-
elica e quella a b-foglietto. Queste strutture sono stabilizzate da legami a idro-geno tra gli amminoacidi appartenenti a una stessa catena, o tra gliam mi noacidi di catene diverse (Figura 3). Le l’α-cheratine, proteine che costituiscono i capelli, la lana e le unghie, hannocome struttura prevalente proprio quella dell’ α-elica.
Nella struttura β-foglietto si ha una disposizione di catene proteiche l’una ac-canto all’altra.La β-cheratina, proteina che costituisce la seta, ha fondamentalmente questastruttura.
                                            
5.2.3 La struttura terziaria
E’ la forma stereoisomerica della proteina e determina la sua disposizione spa-
ziale (Figura 4). Scaturisce dall’interazione tra le catene laterali degli ammi-noacidi della proteina, che assume così una ben definita conformazionetridimensionale. Tali interazioni sono determinate dalle cariche elettriche at-trattive e repulsive, da ponti idrogeno e ponti salini, da interazioni idrofobiche,da ponti disolfuro, che ripiegano ad ansa la proteina. Quindi la successioneamminoacidica della struttura primaria determina la disposizione tridimensio-
Figura 3: struttura dell’a-elica, a sinistra, e del b-foglietto, a destra
127Capitolo V Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#128,128,"nale della proteina, che a sua volta definisce l’attività funzionale della proteina
stessa.
5.2.4 La struttura quaternaria
Si tratta di una più complessa composizione strutturale in presenza di più ca-
tene amminoacidiche all’interno della proteina determinata dalle interazioninon covalenti o da legami covalenti trasversali (Figura 5).
5.3 Proteine semplici e proteine coniugate.
Una delle più importanti classificazioni delle proteine è quella che distingue
fra proteine semplici e proteine coniugate. Figura 4: organizzazione di una catena polipeptidica nello spazio. Gli amminoacidi apolari
(in verde) formano il core idrofobico della proteina. Quelli polari, in rosso, si dispongono aformare le porzioni più esterne della proteina stessa
Figura 5: proteina con struttura quaternaria, formata da quattro catene polipeptidiche, uguali
a due a due.
128Fondamenti della Scienza dell’Alimentazione Capitolo V"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#129,129,"Le proteine vengono dette semplici se sono costituite soltanto da aminoacidi,
mentre si parla di proteine coniugate e a esse è legato un gruppo non proteico(detto anche gruppo prostetico); le proteine coniugate possono essere distintein diverse classi a seconda del tipo di gruppo prostetico. Le diverse tipologiedi proteine coniugate sono le seguenti:• glicoproteine• lipoproteine• nucleoproteine• emoproteine • metalloproteine• fosfoproteine• flavoproteine. 
5.3.1 Funzioni La classe più numerosa delle proteine è costituita dagli enzimi con funzione
regolatrice, che influenzano la velocità dei cicli metabolici.Gli ormoni regolano l’attività cellulare fisiologica, come l’adrenalina che mo-dula la trasmissione degli impulsi nervosi, come la tiroxina che accelera le os-sidazioni intracellulari, come l’insulina regolatrice del metabolismo glucidico.Ci sono proteine che fungono da materiale di riserva, come l’albumina del-l’uovo, la caseina del latte e la ferritina, che permette l’accumulo di ferro nellamilza.Anche la gliadina e la zeina presenti rispettivamente nel seme di grano e di
mais, hanno la stessa funzione di riserva.Altre proteine hanno funzione di trasporto, legando e trasportando sia attra-
verso le membrane cellulari sia nel flusso sanguigno ioni o molecole com-plesse, come l’ emoglobina presente negli eritrociti, come la mioglobina nel
tessuto muscolare, le lipoproteine nel sangue
Ci sono ancora proteine che servono da elementi strutturali , come le glico-
proteine del collagene e l’ elastina nei legamenti o la cheratina nei capelli e
nelle unghieAlcune proteine hanno una funzione protettiva o difensiva, come la trombina
ed il fibrinogeno nel sistema di coagulazione del sangue, come la catalasi e
la glutationeperossidasi, che svolgono azione di difesa dei radicali liberi, come
le immunoglobuline del sistema immunitario.
129Capitolo V Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#13,13,"1.1 I Micronutrienti
1.1.1 I Sali Minerali
I Sali minerali, sostanze inorganiche, hanno assunto notevole importanza nu-trizionale negli ultimi anni poiché, grazie a raffinate tecniche analitiche, è statopossibile evidenziare le svariate funzioni che esercitano.I sali minerali rappresentano circa il 6.2% del peso corporeo e sono costituitiin prevalenza, da composti di fosforo, calcio, sodio e potassio, di cui la mas-sima parte è localizzata nello scheletro sotto forma di fosfato e carbonato dicalcio. I macro ed i microminerali svolgono funzioni essenziali per la vita dell’uomo,entrano nella costituzione delle cellule e dei tessuti dell’organismo, come laformazione di denti e ossa, sono coinvolti nella regolazione dell’equilibrioidrosalino, nell’attivazione di numerosi cicli metabolici e costituiscono fattorideterminanti per la crescita e lo sviluppo di tessuti e organi.Non forniscono energia e durante la cottura o il riscaldamento degli alimenti,non si alterano, ma possono disperdersi nell’acqua utilizzata per la cottura. L’organismo umano non è in grado di sintetizzarli e li assume tramite gli ali-menti e l’acqua. Altro elemento da tenere in considerazione, per la salute del-l’organismo umano, è la loro biodisponibilità , intesa come “la quota di
elementi ingerita che è effettivamente assorbita, trasportata al sito di azione econvertita nella forma fisiologicamente (o tossicologicamente) attiva. Pertantoun alimento è in grado di coprire il fabbisogno di un oligoelemento se questoè presente non solo in quantità corretta ma anche in forma biodisponibile”(Fonte SINU-Minerali LARN 1996). L’assorbimento dipende dallo stato fi-siologico del soggetto e dalla interazione con altri componenti della dieta,come, ad esempio, fitati ed ossalati.Il fabbisogno giornaliero è basso, una corretta ed equilibrata alimentazione èsufficiente ad reintegrarli, anche quando vengono persi con sudore, urine efeci. Si possono classificare in: • Macroelementi o elementi presenti in discrete quantità nell’organismo: Ca,
P, Mg, S, Na, K, Cl, il cui bisogno giornaliero è dell’ordine di grammi o didecimi di grammo.
• Microelementi o oligoelementi o elementi presenti in tracce nell’organismo,
il cui bisogno giornaliero è dell’ordine di milligrammi o microgrammi, aloro volta classificati in :
- Essenziali: Fe, Cu, Zn, I, Se, Cr, Mn, Mo, Co per i quali è dimostrabile
che una loro carenza può compromettere funzioni fisiologiche importanti,
13Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#130,130,"5.4 Digestione delle proteine
5.4.1 Enzimi pancreatici
La digestione delle proteine consiste nella disgregazione meccanica, chimicaed enzimatica delle proteine contenute nei cibi che vengono ridotte a unità piùpiccole. La digestione comprende diversi passaggi, tra cui l’estrazione meccanica delleproteine dal cibo, la denaturazione delle proteine e l’idrolisi dei legami pepti-dici. La proteina viene estratta meccanicamente dal cibo nel processo di mastica-zione e dall’azione dello stomaco. Il basso pH dello stomaco svolge un ruolofondamentale nella denaturazione della proteina estratta, rendendola così piùaccessibile agli enzimi proteolitici dell’intestino. 
Nell’intestino tenue enzimi provenienti da tale tratto intestinale e dal pancreas
scindono le proteine alimentari in peptidi e in aminoacidi singoli. Le proteine devono essere digerite fino a ridurle in aminoacidi o di- e tripeptidiprima che possa aver luogo l’assorbimento, sebbene a volte possano essereassorbiti peptidi di dimensioni maggiori.Per le prime fasi della digestione delle proteine sono importanti quattro tipi dienzimi:- pepsine (secrete dalle ghiandole gastriche sierose dello stomaco), 
- tripsina, - elastasi- chimotripsine (tutte prodotte dagli acini pancreatici).
Il prodotto dell’azione di questi enzimi proteolitici è una serie di peptidi di di-verse dimensioni. Oltre alle endopeptidasi esistono delle esopeptidasi pancreatiche o carbossi-
peptidasi A e B che staccano l’amminoacido all’estremità carbossi-terminale
del peptide.Le carbossi-peptidasi, prodotte in forma inattiva come procarbossi-peptidasi,sono attivate per azione della tripsina.Per completare la liberazione degli amminoacidi delle proteine alimentari ènecessario l’intervento di proteasi prodotte delle cellule dell’epitelio intesti-nale, le ammino-peptidasi o eso-peptidasi. Questi enzimi staccano gli amminoacidi all’estremità ammino-terminale deipeptidi.La digestione viene completata per l’intervento delle di- e tri-peptidasi presentisui villi dell’orletto a spazzola delle cellule intestinali.
130Fondamenti della Scienza dell’Alimentazione Capitolo V"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#131,131,"Gli amminoacidi sono assorbiti dalle cellule epiteliali intestinali ed immessi
nel circolo sanguigno.
5.4.2 Deaminazione
La rimozione del gruppo NH2(deaminazione) può avvenire in tre modi di-
versi:-Deaminazione ossidativa : consiste nella rimozione del gruppo amminico –
NH
2mediante deidrogenazione dell’amminoacido, seguita da un’idrolisi.
Un esempio di deaminazione ossidativa è quella catalizzata dalla glutammicodeidrogenasi presente nel fegato, rene, cuore, muscolo, cervello.Con questa reazione, l’amminoacido acido glutammico è trasformato in acidoalfa-chetoglutarico ed ammoniaca. La reazione è reversibile.
5.4.3 Transaminazione
I processi di transaminazione consistono in uno scambio di un gruppo ammi-nico NH2 da un amminoacido (donatore) ad un chetoacido (accettore)
Gli amminoacidi donatori si trasformano in chetoacidi, ed i chetoacidi accettorisi trasformano in amminoacidi.I chetoacidi accettori sono solo:- acido piriuvico , che si trasforma nell’amminoacido alanina
-acido alfa-chetoglutarico, che si trasforma nell’amminoacido acido glutam-mico 
- acido ossalacetico , che si trasforma nell’amminoacido acido aspartico
Le reazioni sono catalizzate da enzimi che prendono il nome di transaminasi
5.5 Transaminasi
Le transaminasi sono presenti in grandi quantità soprattutto nel fegato e la loro
determinazione nel plasma è utilizzata nello studio delle malattie epatiche.ALT (alanina transaminasi) o GPTL- alanina + 2-chetoglutarico piruvato + L-glutammatoAST (aspartato transaminasi) o GOTL-aspartato + 2-chetoglutarato ossalacetato + L-glutammato
5.5.1 Trans-desaminazione
L’acido alfa-glutarico è l’accettore principale delle reazioni di transaminazionecon formazione dell’amminoacido acido glutammico.
131Capitolo V Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#132,132,"Quest’ultimo, se non è impegnato in particolari destini metabolici, viene at-
taccato dall’enzima glutammico-deidrogenasi, riformando l’acido alfa-cheto-glutarico.Questa combinazione di transaminazione e deamminazione ossidativa prendeil nome di trans-desaminazione
5.6 Ciclo dell’urea
Il gruppo amminico NH
2degli amminoacidi può essere trasferito ad un che-
toacido tramite la transaminazione, dando origine a nuovi amminoacidi, ma
alla fine con la trans-desaminazione o la deaminazione ossidativa, è sempreliberato sotto forma di ammoniaca NH
3.
L’ammoniaca è tossica per l’organismo, perché è una base relativamente forte.Questo fa sì che nel nostro organismo l’ammoniaca si trovi in forma protonatacome ione ammonio NH
4+
L’ammoniaca prodotta in tutti i tessuti è trasformata in urea nel fegato.Solo in piccola parte viene usata per sintetizzare l’amminoacido glutammina.La formazione di urea è un processo ciclico
5.7 Destino dello scheletro carbonioso degli amminoacidi
I processi di deaminazione ossidativa, transaminazione, transdesaminazione,
decarbossilazione, permettono la degradazione degli amminoacidi con libera-zione del gruppo NH
2.
Vie metaboliche specifiche comportano la formazione di intermedi metabolici,che possono essere convertiti in glucosio o in Acetil CoA.Pertanto gli aminoacidi si dividono in:- aminoacidi glucogenici (che formano acido piruvico o intermedi del ciclo
di Krebs)
- aminoacidi chetogenici (che formano Acetil CoA o corpi chetonici)
132Fondamenti della Scienza dell’Alimentazione Capitolo V"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#133,133,"Bibliografia
• Christopher K. Mathews, Kensal Edward Van Holde, Biochemistry: Guide, Benjamin-Cum-
mings Publishing Company, 1996, p. 1159, ISBN 978-0-8053-3931-4.
• David L. Nelson, Michael M. Cox,  I Principi di Biochimica di Lehninger, 3ª  ed.,
Bologna, Zanichelli, febbraio 2002. ISBN 8808090353
• Campbell, Neil A. (2003), Biologia, Edizione Italiana, Zanichelli
• T.W.G. Solomons. Amminoacidi e Proteine. In Chimica Organica. Ed. Editoriale Grasso.
Bologna.
• H. Hart, L.E. Craine and D.J. Hart. Amminoacidi, Peptidi e Proteine. In:Chimica Organica,
quarta edizione italiana. Ed. Zanichelli. (2003).
• Lodish H, Berk A, Matsudaira P, Kaiser CA, Krieger M, Scott MP, Zipurksy SL, Darnell
J, Molecular Cell Biology, 5th, New York, New York, WH Freeman and Company, 2004.
133Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#134,134,"CAPITOLO VI
RIPARTIZIONE DEI MACRONUTRIENTI:
IL CONCETTO DI DIETA EQUILIBRATA
Riassunto
L’equilibrio di una dieta deve essere garantito dall’armonica integrazione e
giusta proporzione dei diversi alimenti, tenendo conto della loro quantità equalità. La dieta quindi, intesa come la corretta alimentazione razionale edequilibrata che un soggetto sano deve assumere quotidianamente in funzionedelle proprie necessità biologiche e nutrizionali al fine di assicurare e man-tenere un buono stato di salute, deve soddisfare sua etimologia greca“
διαιτα ”, che significa “stile di vita e quindi anche alimentare”. Così, una
volta stabilito il fabbisogno energetico, la quota calorica deve essere ripartitatra i nutrienti fondamentali (proteine, lipidi, glucidi). Nel soggetto adulto e incondizioni fisiologiche normali, si considera ottimale una ripartizione ener-getica quotidiana che preveda il 10-15% di proteine, 25-30% di lipidi ed il45-60% di carboidrati, come risulta anche dal rapporto dell’Organizzazioneper l’Alimentazione e l’Agricoltura delle Nazioni Unite (F AO) insieme conl’Organizzazione Mondiale della Sanità (OMS). Le principali Linee Guidadelle più importanti associazioni scientifiche mondiali sulla base dei sempremaggiori e recenti studi epidemiologici e delle continue evidenze scientifichesono concordi nel riconoscere nella dieta mediterranea, un modello alimen-tare bilanciato, equilibrato e corretto, da anni illustrato attraverso la figuradi una piramide, che ha un ruolo fondamentale nella prevenzione di malattiemetaboliche, cardiovascolari e tumorali. 
134Fondamenti della Scienza dell’Alimentazione Capitolo VI"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#135,135,"6.1 Il concetto di dieta.
E’ largamente diffuso nel linguaggio comune identificare il concetto di “ dieta”
con svariati significati tra cui: “l’evitare di mangiare un alimento o più di uno
per perdere peso” oppure “l’astinenza dal cibo per motivi di salute” e così via.Quindi il termine dieta viene utilizzato per indicare un regime alimentare par-
ticolare, quale una dieta dimagrante per soggetti in soprappeso o obesi oppureuna dieta speciale indicata in determinate situazioni patologiche. Ma prima diassumere un tale significato nella patologia, è importante identificare in questoconcetto di dieta, il significato derivante dalla sua etimologia greca “
διαιτα ”,
che significa “ stile di vita e quindi anche alimentare ”. Di conseguenza la dieta
deve essere intesa come la corretta alimentazione razionale ed equilibrata cheun soggetto sano deve assumere quotidianamente in funzione delle proprie ne-cessità biologiche e nutrizionali al fine di assicurare e mantenere un buonostato di salute. La dieta dunque, deve avere i requisiti dell’ “adeguatezza”:
deve cioè, consistere essenzialmente nella qualità e nella quantità degli ali-menti consumati in misura tale da assicurare il soddisfacimento dei bisogni dienergia e nutrienti, rispettando combinazioni e proporzioni tali da non arrecarerischi potenziali per la salute.Ne consegue che non esiste una alimentazione standard che vada bene pertutti, in quanto le esigenze biologiche del proprio organismo variano da indi-viduo a individuo. Nella sua più ampia e concreta accezione, la dieta non com-
prende solo la cosiddetta razione alimentare, cioè il quantitativo alimentare insenso stretto, ma anche ogni possibile variazione della razione stessa in rela-zione alle modalità di cottura e di preparazione dei cibi, al numero e ritmo deipasti nell’arco della giornata. L’alimentazione è dunque un fenomeno dina-mico e vitale, che si diversifica nei giorni, nelle diverse età rappresentandoanche un momento di piacere nella percezione cosciente dei sapori. Per questomotivo, gli alimenti possiedono due importanti proprietà: un valore nutritivoe un valore edonistico. Quindi il cibo e gli alimenti in senso lato non rappre-sentano unicamente l’oggetto dei nostri bisogni metabolici, la modalità attra-verso la quale possano essere soddisfatti i diversi fabbisogni, ma ancheun’esperienza sensoriale in grado di trasformare lo stato d’animo di una per-sona, di influenzare comportamenti oltre che modulare o anche condizionaremolte funzioni nervose e fisio-biologiche. L’ alimentazione è dunque stile di
vitanell’accezione più completa e vasta del termine. Alimentarsi implica sce-
gliere, preparare, condividere con l’ambiente circostante e quindi l’atto delmangiare non è solo un’esperienza sensoriale o un processo fisio-biologico
135Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#136,136,"correlato ai bisogni nutrizionali, ma rappresenta anche un atto culturale in cui
stimoli ambientali di varia origine e natura, meccanismi complessi, ormonalie neurosensoriali, le abitudini familiari e tutto ciò che comprende la storia e ilvissuto si intrecciano determinando e condizionando il nostro stile di vita equindi la nostra
διαιτα .C’è da precisare comunque, che la modifica della
dieta fisiologica in relazione allo stato nutrizionale e metabolico del soggettoal fine di correggere gli errori alimentari e gli squilibri metabolici assume ilsignificato di dietoterapi a. La dietoterapi a ha lo scopo di eliminare i sintomi
e i segni di malattie correlabili ad errori dietetici o causati dall’alimentazionestessa, minimizzare o ritardare l’evoluzione di molte malattie degenerativecroniche, correggere o prevenire la malnutrizione, fornire un supporto nutri-zionale nelle condizioni patologiche caratterizzate da deficienze nutritive cheidentificano uno stato più o meno evidente di malnutrizione. Quindi, risultafondamentale che l’elaborazione di una dieta tenga conto della valutazione
dello stato nutrizionale, che in base alle funzioni svolte dai nutrienti (strutturali,energetiche e regolatrici) può essere considerato come la risultante di tre va-riabili: composizione corporea, bilancio energetico e funzionalità corporea.Per il tramite di queste variabili, lo stato nutrizionale è strettamente correlatoallo stato di salute. 
6.2 Caratteristiche di una dieta varia ed equilibrata.
Alimentazione e prevenzione agiscono in sinergia definendo una nutrizione
ottimale, che abbia come obiettivo quello di potenziare le funzioni fisiologichein modo tale da garantire uno stato di benessere e di salute ottimale, ponendoparticolare attenzione su determinati alimenti in base alle loro peculiari carat-teristiche. La dieta diventa il mezzo più idoneo per prevenire malattie, disor-dini metabolici e disturbi funzionali e la sua composizione, intesa come sceltarazionale di alimenti e come ripartizione armonica dei vari nutrienti, prevedel’utilizzo dei LARN (Livelli di Assunzione di Riferimento di energia e Nu-trienti per la popolazione italiana, Revisione 2012). La dieta quindi, non èuguale per tutti: il bisogno energetico e nutrizionale di un bambino in fase diaccrescimento è sicuramente diverso da quello di un adulto che non ha neces-sità di crescere più, ma che deve mantenere un corretto funzionamento dellesue strutture biologiche; allo stesso modo, una donna in gravidanza o che al-latta, ha dei bisogni energetici e nutrizionali maggiori rispetto alla propria dietain condizioni normali; così, una persona con un livello di attività fisica mode-
136Fondamenti della Scienza dell’Alimentazione Capitolo VI"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#137,137,"rato o pesante, nonché lo sportivo a livello amatoriale o agonistico, non può
avere la stessa dieta di un’altra persona dello stesso sesso ed età, ma sedentaria.E quindi, una volta stabiliti i presupposti fisiologici e teorici di un interventodietetico, un’alimentazione è razionale e capace di rispettare i gusti e le abi-tudini personali e di corrispondere in pieno alle esigenze reali dell’organismo,se presenta le caratteristiche di: - assicurare un’idonea introduzione di energia mediante una corretta propor-
zione dei vari nutrienti
- prevenire carenze o eccessi nutrizionali (assoluti o relativi per un determinato
nutriente), che in un certo arco di tempo possono provocare disturbi o malattie.
Un’alimentazione è razionale solo se è completa ed adeguata, cioè quando lascelta degli alimenti è quanto più possibile varia. Variare opportunamente ladieta, aumenta la probabilità di assumere regolarmente e nelle giuste quantitài nutrienti per coprire i relativi fabbisogni, che servono a garantire una nutri-zione ottimale e a proteggere il proprio equilibrio metabolico e psicofisico.Un’alimentazione variata ha inoltre il “potenziale obiettivo” di ridurre al mi-nimo i rischi correlati all’incompletezza di alcuni alimenti e talora, i pericoliconseguenti all’assunzione ricorrente di sostanze potenzialmente nocive pre-senti in certi cibi, o naturalmente o come conseguenza di manovre tecnologi-che di conservazione e/o di manipolazione industriale. Non esiste dunque,l’alimento completo in grado di fornire tutti i nutrienti nelle giuste quantità enei giusti rapporti, ad eccezione del latte nell’alimentazione del neonato neiprimi mesi di vita. La varietà di un’alimentazione razionale è strettamente le-gata anche alla moderazione nelle porzioni. L’equilibrio di una dieta deve essere garantito dall’armonica integrazione egiusta proporzione dei diversi alimenti, tenendo conto della loro quantità equalità.Quindi, una dieta per essere definita equilibrata deve considerare: - una necessità energetica individuale- un apporto ideale dei macronutrienti (carboidrati, proteine, grassi) che serve
a coprire il fabbisogno calorico quotidiano
- una necessaria presenza nelle quantità raccomandate, di vitamine e sali mi-
nerali, bioregolatori dei processi metabolici, nonché di acqua per il mante-nimento dell’equilibrio idro-salino
- una buona presenza di fibra alimentare - una razionale distribuzione dei pasti nell’arco della giornata- una scelta di metodi di cottura più idonei al fine di preservare al meglio il
valore nutrizionale degli alimenti 
137Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#138,138,"6.3 Dieta e attività fisica
Nessuna dieta, per quanto equilibrata e corretta, non sarà mai abbastanza ef-
ficace da sola nel controllare il peso corporeo o combattere l’eccesso di grassosenza un adeguato stile di vita attivo, che preveda un programma di attivitàfisica associato. La dieta di per sé, comporta sempre una perdita più o menorilevante di massa magra. Solo aumentando la quantità di movimento praticatospontaneamente (attività della vita di tutti i giorni) e/o in forma organizzata(sport, programmi di allenamento ecc.) possiamo incrementare quindi, in ma-niera significativa la spesa energetica del nostro organismo, consumare le ca-lorie che introduciamo con gli alimenti ed ottenere un mantenimento o, aseconda del grado di allenamento, indurre un aumento della massa metaboli-camente attiva. Secondo le principali organizzazioni scientifiche e come evi-denziato anche dal rapporto FAO/OMS, che fornisce raccomandazioni generaliin merito all’assunzione di nutrienti e agli obiettivi relativi all’attività fisicarispetto alla prevenzione delle principali patologie croniche, lo stile di vita at-tivo riduce il rischio di sviluppare una condizione di soprappeso e obesità el’insorgenza di malattie cardiovascolari e di molte altre patologie cronico-de-generative, quali ipertensione arteriosa, diabete di tipo II, osteoporosi e di al-cune forme di neoplasie. Per la riduzione del rischio di queste malattie, leindicazioni prevedono un impegno di tutti i giorni di almeno 30 minuti nellosvolgere qualunque attività fisica capace di indurre un impegno di entità mo-derata-intensa e di almeno 60 minuti, per mantenere un opportuno peso cor-poreo. 
6.4 Principi generali per impostare un profilo nutrizionale: ripartizione
dei macronutrienti
Nella formulazione di una dieta individuale, in base ai parametri dell’età, del
sesso, dello stile di vita e dell’attività fisica e del metabolismo basale, deveessere determinato il fabbisogno energetico giornaliero, definito sulla base distime del dispendio energetico che tenga presente informazioni relative al pesoreale o ideale e al profilo il più possibile esatto delle attività svolte. Una volta stabilito il fabbisogno energetico, la quota calorica deve essere ri-partita tra i nutrienti fondamentali (proteine, lipidi, glucidi). Nel soggetto adulto e in condizioni fisiologiche normali, si considera ottimaleuna ripartizione energetica quotidiana che preveda il 10-15% di proteine, 25-
138Fondamenti della Scienza dell’Alimentazione Capitolo VI"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#139,139,"30% di lipidi ed il 45-60% di carboidrati, come risulta anche dal rapporto
dell’Organizzazione per l’Alimentazione e l’Agricoltura delle Nazioni Unite(FAO) insieme con l’Organizzazione Mondiale della Sanità (OMS). Tale rap-porto è stato elaborato da vari esperti mondiali per esaminare e valutare lostato delle conoscenze sul ruolo dei vari nutrienti nell’alimentazione umana,in modo da fornire a tutti i Paesi informazioni aggiornate e raccomandazionipratiche relative al loro uso. 
proteine 10-15%
grassi 25-30%carboidrati 45-60%
Le proteine non devono essere superiori ai valori raccomandati dai LARN per
kg di peso corporeo (LARN, Revisione 2012) che corrispondono al 10-15%dell’energia totale e di queste 2/3 devono essere di origine vegetale e 1/3 diorigine animale. Questa quota dovrà aumentare solo in condizioni fisiologichedi accrescimento, gravidanza e allattamento. L’apporto di lipidi non deve superare il 30% delle kcal totali: questa quotacome livello di assunzione adeguata (AI) raggiunge il 40% nei lattanti, mentrein un’età compresa tra 1-3 anni, l’intervallo di riferimento per l’assunzionedei di macronutrienti (RI) è compresa tra 35-40% e dai 4 anni in poi, scendea 20-35%. La quota accettabile nell’adulto e nell’anziano, come pure in gra-vidanza e allattamento, è del 25% con un intervallo di riferimento per l’assun-zione dei di macronutrienti (RI) compreso tra 20-35%. La ripartizione suggerita della qualità dei lipidi prevede che: - gli acidi grassi saturi rappresentino il 10% delle kcal totali- gli acidi grassi monoinsaturi, in particolare l’acido oleico, rappresentino fino
al 20% delle kcal totali
- gli acidi grassi polinsaturi siano compresi tra il 5 -10% delle kcal totali: di
questi, il 4-8% deve essere rappresentato da n-6 PUFA, l’0.5-2% da n-3PUFA 
gli acidi grassi idrogenati trans non più dell’1% delle kcal totaliPer quanto riguarda i carboidrati, la loro assunzione fornisce il restante fabbi-sogno calorico, compreso tra il 45-60% dell’energia totale e di questi, gli zuc-cheri semplici devono rappresentare una quota inferiore al 15% dell’energiatotale. L’importanza di rispettare questi quantitativi è legata a varie ragioni:essi forniscono energia facilmente disponibile per il metabolismo ossidativo,aiutano a mantenere la glicemia in omeostasi e una buona funzionalità ga-
139Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#14,14,"oppure che fanno parte di strutture organiche preposte a ruoli vitali
nell’organismo;
- Probabilmente essenziali : Si, V , Ni, B;
- Potenzialmente tossici , alcuni dei quali svolgono forse funzioni essenziali
a basse concentrazioni: As, Al, Pb, Cd, Hg, Li, Sn, F;
Occorre chiarire che la tossicità è una caratteristica di tutti gli elementi e di-pende solo dalla quantità del minerale che perviene all’organismo. Gli ioni di alcuni elementi metallici in particolare Fe, Ca, Mg, Mn, Zn, Cuhanno rilevante importanza come cofattori (ioni o molecole non proteiche),
la cui presenza è indispensabile perché l’enzima possa svolgere la sua attivitàcatalitica. Ad esempio, tutti gli enzimi che utilizzano ATP richiedono la pre-senza di ioni Mg
2+.
MacroelementiIl Calcio è il minerale presente in maggiore quantità nell’organismo, tanto da
essere fondamentale per la costruzione di scheletro e denti (99%). Ma svolgealtre importanti funzioni quali la determinazione della regolazione della con-trazione muscolare, la conduzione dell’impulso nervoso, la coagulazione delsangue, regola la permeabilità cellulare e l’attività di numerosi enzimi. Una sua carenza può comportare rachitismo, crisi tetaniche, osteoporosi, dolorimuscolari, irritabilità, sindrome premestruale, spasmofilia. Possono verificarsianche condizioni da eccesso che portano a sonnolenza, nausea, vomito, statoconfusionale.Gli alimenti che principalmente lo contengono sono legumi, latte e derivati,uova e pesci, alghe di mare, basilico, maggiorana, timo. Le acque mineralicon residuo fisso di almeno 500 mg/l e tenore di Ca superiore a 150 mg/l. Leacque mediominerali (acque bicarbonato-calciche, ricche di calcio, povere disodio), assieme alle acque potabili a più alto tasso di Ca (200-300 mg/l), pos-sono concorrere alla copertura del fabbisogno di calcio, ad esempio, durantela menopausa e la senilità, in questo caso a causa della riduzione dell’assorbi-mento di circa il 50% di calcio e della diminuita capacità di sintesi endogenadella vitamina D. Solo il 35 - 45 % del calcio apportato dagli alimenti viene assorbito. La vita-mina D esercita un ruolo importante, in qualità di ormone, sull’omeostasi delcalcio. Con diete povere di calcio si attiva il meccanismo di assorbimento di-pendente dalla vitamina D. Alcuni costituenti dei vegetali possono diminuireil suo assorbimento come ad esempio ossalati e fitati. Lo stesso accade peraltri sali minerali. Il fabbisogno giornaliero varia a seconda del periodo di vita,
14Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#140,140,"strointestinale e contribuiscono a mantenere sotto controllo il peso corporeo.
Inoltre, anche il rapporto FAO/OMS evidenzia come il consumo di carboidrati,con un basso indice glicemico, tenda a ridurre le possibilità di sovra-consumoed il rischio di obesità, soprattutto in età evolutiva.Particolare attenzione viene posta alla fibra alimentare, il cui livello ottimaledi introito di deve raggiungere i 25 g/die anche in caso di apporti energetici <2000 kcal/die. L’intervallo di riferimento per l’assunzione dei di macronu-trienti (RI) negli adulti indica 12.6-16.7 g/1000 kcal. Un consumo costante difrutta, verdura, legumi, cereali integrali può assicurare questo apporto e comeindica il documento FAO/OMS, può essere raggiunto con un quantitativo difrutta e verdura ≥ 400 g/die. In questo modo, anche l’apporto di vitamine, oli-goelementi e minerali è garantito.Inoltre, come i LARN (Revisione del 2012) evidenziano, è importante che cisia un’adeguata assunzione di acqua, che nell’adulto corrisponde a 2.0 L perle femmine, 2.5 L per i maschi. Per una idonea strategia preventiva dell’ipertensione arteriosa, come indicatodalle Linee Guida di una Sana Alimentazione (2003) anche dal rapportoFAO/OMS, viene indicato un quantitativo di sale discrezionale non superiorea 5 g/die . L’EFSA (European Food Safety Authority) nel 2010 ha aggiornato i precedentipareri europei in questo settore, tenendo conto delle nuove evidenze scienti-fiche e delle recenti raccomandazioni emanate a livello nazionale e interna-zionale. Sono stati presentati così, i primi pareri sui valori dietetici diriferimento (DRV) per i carboidrati, le fibre alimentari, i grassi e l’acqua chesono del tutto simili a quanto già sostenuto e acclarato negli ultimi anni dallacomunità scientifica internazionale. Così come risulta anche dalla revisione2012 dei nostri LARN, particolare attenzione viene posta all’assunzione di250 mg/die di n-3PUFA per il loro ruolo fondamentale nella riduzione del ri-schio di cardiopatie. Una dieta equilibrata e bilanciata prevede anche una corretta distribuzionedelle calorie durante la giornata: le Linee Guida Italiane per una Sana Alimen-tazione (2003) suggeriscono di assumere con la prima colazione circa il 15-20% delle calorie giornaliere (il 15% se la colazione è abbinata ad unospuntino di metà mattina, il 20% se lo spuntino non c’è), con il pranzo il 45%(il 40% si può raggiungere se nel pomeriggio è abbinato uno spuntino del 5%)e con la cena il 35%.
140Fondamenti della Scienza dell’Alimentazione Capitolo VI"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#141,141,"Tale distribuzione può subire delle variazioni in funzione dello stato nutrizio-
nale e delle abitudini del soggetto senza che queste siano necessariamentecausa di danno o disordini metabolici rilevanti. Numerose evidenze scientifiche sottolineano l’importanza della prima cola-zione: l’abitudine a consumare regolarmente la prima colazione, si associa admigliore stato di salute e benessere a tutte le età e soprattutto, può esercitareeffetti positivi sui parametri metabolici correlati al rischio cardiovascolare in-fluenzando sia direttamente che indirettamente, la composizione della dieta.Una serie sempre più numerosa di studi osservazionali, conferma i benefici diuna prima colazione consumata regolarmente, specie se ricca di cereali ed abase di carboidrati a basso indice glicemico: si assumono macro e micronu-trienti in quantità più adeguate rispetto a chi non ha questa abitudine. Più fibra,calcio, vitamine, minerali e meno grassi, colesterolo e calorie totali sembranocaratterizzare nello specifico, il profilo nutrizionale di chi fa regolarmente laprima colazione. 
6.5 Esempio di schema dietetico secondo i LARN
Per esprimere i fabbisogni energetici e in nutrienti indicati dai LARN in quan-
tità di alimenti, si rende necessario quantificare in modo standardizzato le porzioni di alimenti. Per questo motivo,si definisce porzione la quantità standard di alimento espressa in g, che si as-
sume come unità di misura da utilizzare per un’alimentazione equilibrata, chesi è cercato di ricavare sulla base dei consumi medi di alimenti della popola-zione italiana, degli alimenti e pietanze tipici della nostra tradizione e delle
141Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#142,142,"grammature di alcuni prodotti confezionati.
Al di là del contenuto in nutrienti, la porzione deve essere innanzitutto di di-mensioni “ragionevoli”; deve cioè soddisfare le aspettative edonistiche delconsumatore ed essere conforme alla tradizione alimentare. Le quantità digrammi proposte per ciascuna porzione assumono perciò il significato di“unità pratica di misura della quantità di alimento consumata”.
Porzioni standard nell’alimentazione italiana e numero di porzioni per
comporre una razione alimentare giornaliera di circa 2000 kcal
142Fondamenti della Scienza dell’Alimentazione Capitolo VI
"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#143,143,"Per impostare uno schema dietetico è necessario indicare il numero di porzioni
di alimenti di ciascun gruppo, da consumare in una giornata per un determinatofabbisogno di energia. Nella composizione di uno schema dietetico giornalierodi circa 2000 kcal (la scelta di tale fabbisogno è esemplificativa e non limital’applicazione di questo metodo ad altre situazioni fisiologiche) prevede che:- il pane va consumato tutti i giorni nelle porzioni indicate. I prodotti da forno
possono essere consumati a colazione o fuori pasto. 
- per i secondi piatti, si consigliano nell’arco della settimana, le seguenti fre-
quenze di consumo: 3-4 porzioni di carne, 2-3 porzioni di pesce, 3 porzionidi formaggio, 2 porzioni di uova, 1-2 porzioni di salumi. Almeno 1-2 voltela settimana, il secondo piatto va sostituito con un piatto unico a base di pastaN°GRUPPO DI ALIMENTI ALIMENTI PORZIONE (g)PORZ/DIE
LATTE E DERIV ATI • latte • 125 (un bicchiere) 2
• yogurt • 125 (un vasetto)
• formaggio fresco • 100 0-1
• formaggio stagionato • 50
CARNE, PESCE, UOV A - carne fresca • 100 (a crudo) 
- carne conservata (salumi) • 50 1
- pesce • 150 (a crudo)
- uova • un uovo 0-1
(circa 50 g a crudo)
LEGUMI •legumi freschi • 100 (a crudo) 0-1
• legumi secchi • 30 (a crudo)
CEREALI E TUBERI • pane • 50 3-4
• prodotti da forno • 50 0-1
• pasta o riso (*) • 80 (a crudo)
• pasta fresca all’uovo (*) • 120 (a crudo) 1
• pasta fresca ripiena (*) • 180 (a crudo)
• patate  200 (a crudo) 0-1
ORTAGGI E FRUTTA • insalate • 50
• ortaggi • 250 (a crudo) 2-4
• frutta o succo • 150 
CONDIMENTI •olio • 10 3
• burro • 10 0-1
• margarina • 10
(*) in minestra, la porzione è dimezzata. (tabella adattata dai LARN, 1996)
143Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#144,144,"o riso con legumi, nelle porzioni indicate per ognuno dei due alimenti. 
- il latte e/o lo yogurt vanno consumati tutti i giorni (due porzioni). Una tazza
di latte equivale a circa due bicchieri. 
- tra le porzioni di verdure e ortaggi (2-4) viene inclusa una eventuale porzione
di minestrone o passato di verdure, nonché una porzione utilizzata quale
condimento per pasta e riso (zucchine, melanzane, funghi, pomodori freschi,carciofi, asparagi, ecc.). 
- le porzioni di frutta e succo di frutta si possono consumare anche fuori pasto. - per i grassi da condimento preferire sempre il consumo di olio di oliva; burro
o margarina sono ammessi saltuariamente. 
Tenendo conto così, della corretta distribuzione dei tre pasti durante la giornatasecondo le combinazioni del numero di porzioni e alternando gli alimenti dellostesso gruppo, la valutazione nutrizionale su di uno schema dietetico di 2000kcal di 7 giorni, mostra che:- le proteine sono 75 g e rappresentano circa il 15%dell’ energia totale (ET)- i carboidrati sono 290 g (220g di amido e 70 g di carboidrati solubili) e
rappresentano circa il 55%dell’ ET
- i lipidi sono 65 g e rappresentano circa il 30%dell’ ET, di cui i saturi sono il
7%, i monoinsaturi il 18% e i polinsaturi il 4%
- la fibra è presente in 23 g- il colesterolo in 255 mgPer quanto riguarda i minerali, i quantitativi sono riportati quanto segue:- il calcio è presente in 876 mg, il fosforo in 1200 mg, il ferro in 11 mg, il
sodio in 2270 mg, il potassio in 3042 mg 
Per quanto riguarda le vitamine, i quantitativi sono riportati quanto segue:- la vit B
1è presente in 1,02 mg, la vit B2è presente in 1,6 mg, la vit C è
presente in 163 mg, la vit PP è presente in 29 mg, la vit A è presente in 935mg
Si evince che la copertura dei LARN è soddisfacente per quanto riguarda imacronutrienti, mentre non sempre lo è per alcuni micronutrienti. Quindi,anche in vista della nuova e prossima revisione dei LARN, è necessario porreparticolare attenzione e fare le dovute valutazioni del caso.
6.6 Piramide alimentare e dieta mediterranea
Al fine di orientare la popolazione verso comportamenti alimentari più salutari,
il Ministero della Salute ha affidato ad un Gruppo di esperti (D.M. del
144Fondamenti della Scienza dell’Alimentazione Capitolo VI"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#145,145,"1.09.2003) il compito di elaborare un modello di dieta di riferimento che sia
coerente con lo stile di vita attuale e con la tradizione alimentare del nostroPaese. La Piramide Alimentare è la “chiave grafica” per visualizzare il modellomediterraneo e capire come adottarlo. Nasce così la piramide settimanale dellostile di vita italiana che si basa sulla definizione di Quantità Benessere (QB)sia per il cibo che per l’attività fisica. Da questo modello di dieta scaturisce lapiramide alimentare italiana, che elaborata dall’Istituto di Scienza dell’Ali-mentazione dell’Università di Roma “La Sapienza”, indica i consumi alimen-tari giornalieri consigliati. Vengono date indicazioni sulle quantità di cibo daconsumare ogni giorno secondo il criterio della quantità benessere QB (por-zioni di alimenti in grammi). Le QB di cibo e di movimento, se opportuna-mente adattate alle esigenze del singolo individuo, consentono di orientare lostile di vita verso un equilibrio tra consumo alimentare e spesa energetica. Le caratteristiche di questo tipo di alimentazione le ritroviamo nella dieta me-diterranea, che nella sua concezione generale adotta pienamente la definizionedi 
διαιτα in quanto non rappresenta soltanto un insieme di indicazioni sul re-
gime alimentare da seguire, ma racchiude in sé un vero e proprio stile di vita. La dieta mediterranea infatti, affianca ad un’alimentazione bilanciata, com-posta essenzialmente da prodotti freschi locali e di stagione, lo svolgimentodi una moderata ma costante attività fisica, il rispetto per il territorio e per labiodiversità e una quotidianità fatta di pasti conviviali, feste e tradizioni in unclima di accoglienza che la rendono un eccellente modello, unico nel suo ge-nere. Il riconoscimento nel 2010 da parte dell’UNESCO come patrimonio im-materiale dell’umanità, ne dimostra l’importanza nella vita delle popolazionimediterranee e il suo potenziale impatto sulla vita e la salute delle popolazionidi tutto il mondo.Sulla base di più recenti studi epidemiologici e delle continue evidenze scien-tifiche sul ruolo fondamentale della dieta mediterranea nella prevenzione dimalattie metaboliche, cardiovascolari e tumorali, è stata presentata nel 2011dalla Mediterranean Diet Foundation, in associazione con il Forum on Medi-terranean Food Cultures la piramide alimentare mediterranea. 
La nuova Piramide della Dieta Mediterranea si basa su una dieta mediterranearivisitata all’insegna della modernità e del benessere, che tiene conto dellediverse tradizioni culturali e religiose e le differenti identità nazionali, maanche dell’evoluzione dei tempi e della società, evidenziando l’importanzabasilare dell’attività fisica, della convivialità a tavola e dell’abitudine di bereacqua e suggerendo poi, di privilegiare il consumo di prodotti locali su base
145Capitolo VI Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#146,146,"stagionale. Si rivolge a tutti gli individui sani di età compresa tra i 18 e i 65
anni. La piramide alimentare della dieta mediterranea fornisce tutti gli elementiper poter seguire un’alimentazione equilibrata.
Bibliografia 
• Shils M.E., Olson J.A., Shike M., Modern NUTRITION in health and disease, eighth edi-
tion, Lea & Febiger 
• Willet CW (1994) Diet and health: what should we eat? Science, 264, 532-537, 1994
• OMS-WHO Global recommendations on physical activity for health. Geneva: WHO, 2010• INRAN, Linee Guida per una sana alimentazione italiana” (revisione 2003), Roma • LARN “Livelli di Assunzione Raccomandati di Energia e Nutrienti per la Popolazione Ita-
liana SINU (Revisione 1996) EDRA
• LARN “Livelli di Assunzione di Riferimento di Nutrienti ed energia per la popolazione ita-
liana SINU (Revisione 2012)
• The Joint WHO/FAO Expert Consultation on diet, nutrition and the prevention of chronic
disease: process, product and policy implications Public Health Nutrition: 7 (1A), 245-2502003, DOI: 10.1079/PHN2003592 
• EFSA, Scientific Opinion on establishing Food-Based Dietary Guidelines, 2010• Marangoni F., Poli A. et al Documento di consenso sul ruolo della prima colazione nella ri-
cerca e nel mantenimento della buona salute e del benessere, Nutrition Foundation of Italy(NFI) 2009
• Vannozzi, Leandro. Lineamenti di Dietoterapia e nutrizione clinica. Pensiero Scientifico
Editore 
• www.piramideitaliana.it• Keys A. Coronary heart disease in seven countries. Circulation 1970; 41• Bach-Faig A, Berry EM, Lairon D et al. Mediterranean diet pyramid today. Science and
cultural updates. Public Health Nutr 2011; 14(12A): 227-84
146"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#147,147,147Capitolo VII Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#148,148,"CAPITOLO VII
V ALUTAZIONE DELLO STATO NUTRIZIONALE: 
CENNI DI ANTROPO-PLICOMETRIA
Riassunto
Lo stato nutrizionale definisce gli effetti dei nutrienti e degli altri componenti
degli alimenti sulle funzioni corporee, nonché l’integrità anatomica dei tessuti,organi e apparati del corpo. Questa affermazione è corretta per tutti gliindividui, tuttavia occorre tener presente altre variabili che influenzanoulteriormente lo stato di nutrizione. La variabile biologica, cioè lecaratteristiche intrinseche e peculiari di ciascun individuo (composizionecorporea) e la funzionalità corporea. La valutazione dello stato nutrizionalesi propone di identificare problemi legati ad una cattiva alimentazione inindividui che richiedono un intervento specifico. Questo capitolo fornirà indicazioni nella valutazione dello stato nutrizionalee metodi di studio nella popolazione adulta.
148Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#149,149,"7.1 Valutazione dello stato nutrizionale
La valutazione dello stato si propone di identificare in modo più certo gli in-
dividui con problemi nutrizionali sia per eccesso che per difetto, alcuni deiquali richiedono un intervento specifico. Il metodo ideale per la valutazionedello stato nutrizionale deve possedere caratteristiche quali, semplicità, mo-desto impiego di tempo, costo contenuto.La sua utilità può essere giudicata in termini di precisione, accuratezza, sensi-bilità e specificità. La precisione corrisponde alla riproducibilità, in altre parolealla capacità di ottenere un valore dato costante nella misurazione di una datavariabile. L’accuratezza indica quanto la misura ottenuta è vicina (fino a corri-spondere) al valore reale. La sensibilità rappresenta nel caso specifico la ca-
pacità di identificare gli individui che rientrano in una malnutrizione perdifetto e per eccesso, mentre la specificità è la capacità nel discriminare inmaniera corretta individui malnutriti con un normale stato di nutrizione.Lo stato di nutrizione di un uomo è la condizione biologica presente all’atto
dell’osservazione , considerata come risultante dell’equilibrio dinamico che,
in ciascun momento, si instaura fra bisogni di nutrienti e di energia ed illoro soddisfacimento, in dipendenza della disponibilità dei nutrienti e dellaloro corretta utilizzazione .
Fatte queste premesse dobbiamo considerare che, ormai da diversi anni, l’Or-ganizzazione Mondiale della Sanità (OMS/WHO) sottolinea la relazione uni-voca esistente tra stato di salute e stato nutrizionale. Si definisce stato di salute: “Uno stato di completo benessere fisico, mentale e sociale e non la semplice
assenza dello stato di malattia o infermità ”
Possiamo quindi affermare che il deterioramento, per eccesso o per difetto,dello stato di nutrizione influenzi lo stato di salute e viceversa. Questo ci per-mette di superare la definizione iniziale di stato di nutrizione che mostra uncontenuto limitato per quanto riguarda gli aspetti pratici della valutazione dellostato nutrizionale. Possiamo così elaborare una definizione “operativa” fondatasulla relazione esistente tra composizione corporea, funzionalità corporea, bi-lancio energetico, stato nutrizionale e stato di salute.Nel soggetto sia in condizioni fisiologica (adolescente, sportivo, gravidanza e allat-tamento) che patologica, la relazione univoca tra stato di salute e stato di nutrizionesi sta imponendo in tutta la sua importanza in quanto si assiste a rapide modificazionimetaboliche che possono essere monitorate e quantificate attraverso lo studio dellostato nutrizionale. Diventa quindi di fondamentale importanza saper cogliere, nellemetodiche che gli specialisti hanno a disposizioni, i relativi vantaggi e svantaggi.
149Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#15,15,"adolescenza, gravidanza e allattamento. In generale, per l’adulto sono neces-
sari 800 mg/die di calcio.Lo zolfo si trova nell’organismo in numerosi composti organici come gli am-
minoacidi solforati, metionina e cisteina (e quindi nelle proteine e negli ormonipolipeptidici), vitamine e coenzimi (tiamina, biotina, acido pantotenico, co-enzima A), alcuni mucopolisaccaridi (eparina, condroitinsolfati), nel glutatione(importante sistema redox delle cellule), nei solfatidi e negli acidi biliari (acidotaurocolico), nell’insulina.E’ assorbito nel tenue soprattutto sotto forma di amminoacidi (un adeguatoapporto di proteine con la dieta soddisfa anche il bisogno di zolfo) e di solfatiinorganici. Lo zolfo viene in gran parte utilizzato dall’organismo per la sintesidella cisteina, dei mucopolisaccaridi, dei solfatidi. Sottoforma di solfato faci-lita l’eliminazione urinaria di sostanze fenoliche e di ormoni, legandosi adesse e rendendole più solubili. Entra a far parte della composizione della car-tilagine, del sistema di detossicazione epatico, della composizione di cute, un-ghie e capelli. Si trova in alimenti di origine vegetale, quali germe e crusca di grano, semi dilino, aglio, cipolla, cavoli e in alimenti di origine animale quali ostriche, trota,caciotta, coniglio, tacchino, uova, formaggi.È difficile riscontrare carenze da zolfo se la dieta contiene quantità adeguatedi proteine animali: è per questo che non è stato stabilito uno specifico valoreper il fabbisogno di questo minerale. Una sua carenza può provocare artrosi,dolori alle articolazioni, fragilità di unghie e capelli, intossicazioni da alcol edinquinanti. È invece provato che l’assunzione eccessiva di aminoacidi solforaticausa problemi di sviluppo fisico e una crescita scarsa.
Microelementi o oligoelementi
Il Ferro è il costituente dell’emoglobina, della mioglobina, componente di nu-
merosi sistemi enzimatici (sintesi e degradazione di amine quali dopamina e se-rotonina), dei citocromi, per il trasferimento di elettroni nella catena respiratoria. L’organismo umano adulto contiene generalmente 3-4 grammi di ferro, distri-buiti tra emoglobina, mioglobina, fegato, milza e midollo osseo. “Il ferro cheassumiamo è contenuto negli alimenti in due forme distinte: in pesce, carne ealcuni vegetali è presente il ferro emico, mentre nelle uova e nei prodotti lat-tiero caseari si trova il ferro non emico (più difficilmente metabolizzabile)”(Fonte http://www.epicentro.iss.it).Una sua carenza può provocare astenia, affaticabilità, facilità alle infezioni,anemia ferropriva, fragilità delle unghie e dei capelli; un suo eccesso, danni
15Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#150,150,"7.2 Composizione corporea 
Nello svolgimento di un’indagine antropometrica si procede selezionando, tra
quelli opportunamente studiati e documentati, un modello standard adatto altipo di indagine desiderata. Dopodiché sarà possibile considerare singolar-mente e incrociare tra loro i parametri caratterizzanti il modello selezionato,traendone le opportune conclusioni. Ovviamente ogni tipo di modello saràstrutturato in funzione del tipo di indagine svolta, quindi ci si potrebbe trovarea considerare per modelli di indagine differenti parametri estremamente dif-ferenti, come il diametro di un’articolazione, la circonferenza di un distrettocorporeo o lo spessore di una plica cutanea e così via.La valutazione della composizione corporea significa studio della strutturadell’organismo. Le informazioni possono essere stratificate secondo 5 livelli.1) Modello atomico. La somma di tutti gli elementi presenti nel corpo fornisce
massa corporea, quindi: Massa corporea totale = O+C+H+N+Ca+ piùelementi presenti in minor concentrazione (Fe, Mg, Cu, K, ecc.). Questo tipo di misure viene effettuato generalmente su un cadavere oppuresu campioni isolati di tessuto. Nell’ambito di questo tipo di misura è pos-sibile infatti determinare il potassio totale, il sodio, il cloro, il fosforo, ilcalcio, l’azoto e infine il carbonio. Le tecniche impiegate per il dosaggiodi questi elementi sono decisamente sofisticate: richiedono complesse ap-parecchiature e competenze estremamente specialistiche.
2) Modello molecolare. Gli elementi appena visti, si organizzano nel formare
molecole. Nell’organismo sono presenti più di 100.000 diverse molecole.Le componenti derivate da questa ulteriore organizzazione sonoprincipalmente: acqua, lipidi, glicidi, proteine e minerali. Gli elementipossono essere generalmente identificati mediante tecniche di marcaturacon specifici isotopi. Inoltre, tramite particolari tecniche di eccitazione deinuclei dei minerali, è possibile definire la componente minerale ossea(considerando che le ossa contengono più del 99% del calcio e dell’86%del fosforo presenti nell’intero organismo) e non ossea.
3) Modello cellulare . A livello cellulare, l’organismo può essere suddiviso in
tre principali compartimenti corporei: liquido intracellulare, liquidoextracellulare e componente solida extracellulare. Queste tre componentipossono essere determinate mediante l’utilizzo di traccianti radioattivi etecniche di diluizione.
4) Modello anatomico . A questo livello vengono identificati dieci diversi
sistemi: circolatorio, respiratorio, nervoso, tegumentario, muscolare,
150Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#151,151,"endocrino, linfatico, digestivo, scheletrico e riproduttivo. Dal punto di vista
della composizione corporea questa suddivisione viene semplificataindividuando quattro componenti principali di interesse: tessuto adiposo,tessuto muscolare, tessuto osseo e sangue. Tecniche quali l’ecografia, latomografia assiale computerizzata e la risonanza magnetica nuclearepossono essere impiegate con successo per determinare queste quattrocomponenti.
5)Nel quinto livello sono studiate le caratteristiche proprie dell’essere umanoquali taglia corporea, in termini pratico applicativi, la valutazione dellacomposizione corporea risponde all’idea che l’organismo sia suddiviso indifferenti compartimenti con specifico significato fisiologico e nutrizionale.
151Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#152,152,"Il modello bi compartimentale distingue fra depositi adiposi dell’organismo
(massa adiposa) e tessuti non adiposi (massa magra).
7.2.1 Grasso essenziale e grasso di depositoNell’ambito della composizione corporea il grasso viene identificato secondo
due criteri funzionali diversi. Con il termine “grasso essenziale” (o primario)si identifica la frazione di grasso contenuta in alcuni distretti come midolloosseo, miocardio, polmone, milza, reni, intestino, muscolo scheletrico e alcuneparti del sistema nervoso. Il grasso essenziale è soggetto a un continuo utilizzometabolico da parte dei tessuti. Esistono differenze legate al sesso per quantoriguarda il grasso primario. Per esempio nei maschi a livello cardiaco è
Grassi
Massa metab. attivaMassa MagraAltri componenti
N, Ca, P, K, S,
Na, etc.
Idrogeno
Carbonio
Ossigeno
ATOMICOLipidi
Acqua
Proteine
Minerali
MOLECOLARELipidi
Liquidi extracellulari
Liquidi
intracellulari
Solidi
intracellulari
Solidi  extracellulari
CELLULARESangue
Tessuto adiposo sottocutaneo
Tessuto adiposo addominale
Muscolatura scheletrica
Muscolatura non scheletrica
(organi)
Ossa
ANATOMICO
152Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#153,153,"presente una quantità di circa 18,4 g di grasso, ovvero circa il 5,3% della massa
del miocardio, che in media è di 349 g; nelle femmine il grasso cardiaco è dicirca 22,7 g, ovvero l’8,6 % su una massa media di 256 g.Con il termine “grasso di deposito” si identifica la restante quota di grassocorporeo: nello specifico si tratta del grasso che ricopre i visceri, come lamaggioranza degli organi contenuti nella cavità addominale, proteggendolidal punto di vista meccanico e del grasso sottocutaneo. Esaminando datistatistici riferiti ai valori medi, rilevati su un campione di soggetti in buonasalute, si riscontra che il livello percentuale di grasso corporeo èsostanzialmente simile nei due sessi: 12% circa nei maschi e 15% circa nellefemmine, mentre la percentuale di grasso primario si rivela quattro voltesuperiore nelle donne rispetto agli uomini. Si ritiene che il maggiorquantitativo di grasso primario nella donna sia attribuibile alle specificheesigenze correlate alla maternità, dipendendo quindi dal complesso quadroormonale che la governa. Non è tuttora chiaro in quale misura il grasso dideposito possa direttamente rappresentare una effettiva riserva energetica dalpunto di vista calorico per i tessuti che lo contengono.
7.2.3 Massa magra e free fat mass Spesso i concetti di “massa magra” e “ free fat mass” vengono erroneamente
ritenuti dei sinonimi, ma le cose stanno molto diversamente. La cosiddetta
“massa magra” comprende nella sua composizione il 3% circa di grassoprimario, principalmente contenuto, come si è visto, a livello del sistemanervoso centrale, del midollo osseo e negli organi parenchimali. Con il terminedi “massa fat free” ci si riferisce a massa corporea a cui è stata completamentesottratta la massa grassa. Secondo quanto proposto da Behnke con il suomodello, la free fat mass rappresenta un valore determinabile esclusivamente
tramite la misura diretta della composizione chimica effettuata su un cadavere.La massa magra invece è considerata una variabile misurabile in vivo, capacedi conservare nel corso della vita una costanza relativa, soprattutto per quantoriguarda la componente acquosa, la componente organica e quella inorganica.È quindi possibile affermare che in un soggetto adulto, normale e con normalelivello di idratazione, l’unica differenza tra massa fat free e massa magra èrappresentata dalla frazione di grasso primario. Nel calcolo della massa magrabisogna quindi ricordare che la quota di grasso primario rimane inclusa, quotaa cui si aggiungono la massa proteica, la massa ossea e la massa d’acquacontenuta nei tessuti.
153Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#154,154,"Le metodiche più semplici nella pratica quotidiana per lo studio della
composizione corporea sono l’antropometria, la psicometria e labioimpedenziomentria, mentre quelle più complesse, si ricordano:
Tecniche monocompartimentali 
La distribuzione selettiva di traccianti introdotti dall’esterno o naturalmentepresenti in specifici compartimenti dell’organismo, che permette, misurandola diluizione dei traccianti stessi di calcolare le dimensioni del rispettivo pooldi distribuzione. Le tecniche che si valgono di questo principio sono definitetecniche della diluizione e misurano singoli componenti da cui vengono poiestrapolati altri compartimenti.
Monocompartimentali 
• Misura dell’acqua corporea • diluizione di traccianti (isotopi radioattivi, isotopi freddi, sostanze chimiche) • impedenza bioelettrica• conduttanza magnetica • Misura del potassio corporeo (K40 spontaneamente presente o K40 iniettato) 
Tecniche pluricompartimentali 
Le differenti proprietà fisico-chimiche dei componenti corporei quali pesospecifico, conduttività elettrica e magnetica, attenuazione di energia di raggiX o fotoni, risonanza magnetica nucleare o attivazione neutronica. Su questebasi è possibile misurare contemporaneamente più compartimenti
Pluricompartimentali
• Analisi chimica diretta su cadavere • Peso specifico per pesata subacquea • Tomografia assiale computerizzata • Densitometria a doppio raggio fotonico • Risonanza magnetica nucleare • Attivazione neutronica• Pletismografia 
la idrodensitometra, dilutometria, determinazione dell’azoto corporea, DXA,
TAC e NMR. Queste ultime utilizzate in ambito di ricerca. Fra le tecniche più utilizzate va subito citata l’antropometria (termine che
154Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#155,155,"significa misurazione dell’uomo). Nel caso specifico essa prevede la
determinazione di grandezze quali il peso, l’altezza, lunghezze segmentali,pliche adipose e sottocutanee e circonferenze. Il peso rappresenta un indicesemplice ed immediato nella valutazione dello stato nutrizionale, presentamodifiche e variazioni casuali nell’arco delle 24 ore (modifiche dell’acquacorporea). Nel caso dell’altezza la sua determinazione è fondamentale percalcolare l’IMC (indice di massa corporea) dato dal peso in kg e diviso per ilquadrato dell’altezza in metri). Questo indice nasce nel 1 9° secolo ad opera
del matematico belga da Lambert Adolphe Jacques Quetelet , il quale ha
inventato la formula del calcolo del BMI per fornire un modo semplice eveloce il grado di obesità della popolazione ed assistere quindi il governo
nella ripartizione delle risorse. Benché in modo approssimato, l’IMC nontiene conto dello sviluppo delle masse muscolari, esso fornisce delleindicazioni indirette sulle riserve adipose dell’organismo, definendo il soggettoin esame in sottopeso, normopeso, sovrappeso, obeso in diversi livelli.
Antropometria 
Il peso, la statura e l’IMC rappresentano i parametri antropometrici piùutilizzati nella valutazione dello stato nutrizionale. Si riportano le tecniche di rilevazione più diffuse:
Peso
Definizione: Si definisce fisiologico il peso che in relazione alle esigenzeenergetico-metaboliche, meccaniche, termoregolatrici è associato ad unaquantità di massa grassa ottimale e fisiologica e quindi ad un rapportoarmonico tra questa e la massa magra. Il peso corporeo è un indicatore grossolano della composizione corporea e delbilancio energetico. Rappresenta la somma di TBW, PM, MM, Gn e FM. Per-tanto, al livello molecolare, una modificazione del peso corporeo può dipen-dere dalla modificazione di uno o più di cinque compartimenti corporei. Poiché
PM, Gn e FM hanno anche un significato energetico, BW è pure un indicatoregrossolano del bilancio energetico. Un bilancio energetico a lungo negativocausa infatti la contrazione di PM, Gn e FM ed uno a lungo positivo la loroespansione. La natura grossolana di BW come indicatore della composizionecorporea e del bilancio energetico deve essere tenuta ben presente per la pos-sibilità che le modificazioni di un compartimento corporeo mascherino quelledi un altro compartimento. La presenza di edema può infatti mascherare unaperdita di FM e PM e la rialimentazione di un paziente malnutrito per difetto
155Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#156,156,"può produrre un aumento di BW dovuto all’espansione di ECW piuttosto che
all’incremento di PM e FM. Un rapido incremento ponderale (ore o giorni)suggerisce l’occorrenza di un’espansione di ECW. Un lento aumento di BW(settimane o mesi) suggerisce invece l’occorrenza di un’espansione di FM.D’altro canto, è sempre necessario interrogarsi sulla composizione del calo
ponderale di un soggetto sovrappeso sottoposto a trattamento dietetico: la con-dizione ideale è ch’esso consista prevalentemente di FM e risparmi il più pos-sibile PM. Diete fortemente ipocaloriche o sbilanciate possono produrre unacontrazione di PM il cui risultato finale è la perdita di massa metabolicamente
attiva , documentata dalla riduzione di BEE. Il controllo seriato di BEE può
essere in effetti utilizzato come indicatore della massa metabolicamente attivanel paziente obeso in trattamento dietetico. Inoltre, prima di prescrivere untrattamento ad un paziente sovrappeso che ha praticato numerose diete forte-mente ipocaloriche o sbilanciate, è utile stabilire la sua “dotazione” attuale dimassa metabolicamente attiva attraverso la misurazione di BEE. La calorime-tria indiretta è l’unica tecnica suscettibile di applicazione clinica che consentadi seguire nel tempo la massa metabolicamente attiva ed il suo impiego è net-tamente superiore a quello di formule predittive, sempre sconsigliabile nel sin-
golo individuo .
BW = peso corporeo; FM= massa grassa; TBW = acqua totale corporea; PM = massa proteica; 
MM = massa minerale; BCM massa = cellulare corporea; ECF = fluidi extracellulari; ECS = solidiextracellulari
156Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#157,157,"Misurazione
Il peso corporeo viene misurato impiegando una bilancia. Le bilance consi-gliate sono quella a bascula e quella elettronica. Per la misurazione del pesocon bilancia a bascula, l’operatore si pone di fronte al soggetto da misurare(dopo minzione). Questi sale sulla bilancia indossando solo la biancheria in-tima, sistema i piedi al centro della piattaforma di misurazione e distribuisceil peso uniformemente su di essi. Il peso viene approssimato a 0,1 kg. 
Statura
Utilizzata congiuntamente al peso, la statura o altezza (BH, body height) con-sente di valutare le dimensioni corporee. La combinazione di peso e statura
nella forma degli indici pondero-staturali consente una prima valutazione
obiettiva della malnutrizione per eccesso o difetto e delle turbe dell’accresci-mento. La statura viene misurata con lo stadiometro. Al momento della misurazioneil soggetto è scalzo e pochi abiti cosicché l’operatore possa controllare costan-temente la posizione. I piedi poggiano su una superficie piana sistemata adangolo retto rispetto alla tavola verticale dello stadiometro ed il peso è egual-mente distribuito su di essi. La testa si trova nel piano orizzontale di Franco-forte (linea ideale tracciata tra il margine posteriore dell’orbita sx e il tragoomolaterale); le braccia pendolano liberamente ai lati del tronco con il palmodelle mani rivolto verso le cosce; i calcagni, uniti, poggiano contro il basa-mento della tavola verticale ed i margini mediali dei piedi formano un angolodi circa 60°. Le scapole e le natiche devono essere in contatto con la tavolaverticale. Si chiede al soggetto di fare un’inspirazione profonda mentre man-tiene la posizione eretta. Si porta quindi la barra mobile dello stadiometro incorrispondenza del punto più alto del capo esercitando una pressione suffi-ciente a comprimere i capelli. La misura viene approssimata al più vicino 0,1cm e si annota l’ora del giorno a cui è stata effettuata.IMC = peso in Kg diviso altezza in metri al quadrato (m
2)
Sottopeso < 18,5
Normopeso 18,5 – 24,9
Sovrappeso 25,0 – 29,9
Obesità I livelli 30,0 – 34,9
Obesità II livello 35,0 – 39,9
Obesità III livello > 40
157Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#158,158,"FORMULE PER LA V ALUTAZIONE del peso corporeo fisiologico Kg
Pfis= 50 + (statura cm–150) x 0.75 Van Der Vael
Pfis= statura cm– 100 Broca
Pfis= statura cm– 104 corretta per il sesso femminile Broca 
Pfis= 0.8 x (statura cm–100) + etàanni/ 2 Bertheam
Maschi Pfis= cm – 100 – cm-150/4 Lorentz
Femmine Pfis= cm – 100 – cm-150/2 Lorentz 
Circonferenze e diametri corporei
Essi sono l’espressione delle dei vari segmenti corporei, inoltre sono indiciriconosciuti per la valutazione della distribuzione della massa grassa. Glistrumenti presenti in questa tecnica sono il calibro ed il metro flessibile edanelastico che aderisca alla cute senza comprimere i tessuti. Per ognicirconferenza il piano deve essere perpendicolare all’asse longitudinale dellaregione corporea in esame.
Diametro del gomito
Il diametro del gomito è il principale indicatore della taglia corporea.
La misurazione può essere effettuata con un calibro estensibile o fisso. La pro-cedura illustrata di seguito è quella da utilizzare con il calibro estensibile. Ilsoggetto, che si trova in posizione eretta, flette il braccio di 90° in modo cheildorso della mano sia rivolto anteriormente. L’operatore localizza palpatoria-mente gli epicondili mediale e laterale dell’omero e applica le barre del calibroin loro corrispondenza 
Diametro del polso
Il diametro del polso è utilizzato principalmente come indicatore della tagliacorporea.La misurazione viene effettuata con un calibro estensibile. Il soggetto, che sitrova in posizione eretta, flette l’avambraccio di 90° sul gomito, tenendo il brac-cio vicino al torace. L’operatore localizza palpatoriamente i processi stiloideiulnare e radiale e sistema le estremità del calibro in corrispondenza di essi 
Circonferenza vita
Indicatore del tessuto adiposo sottocutaneo addominale, correlato al grassoviscerale e al rischio di morte.
158Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#159,159,"Il soggetto è in posizione eretta, l’addome è rilassato, le braccia pendono ai
lati del corpo ed i piedi sono uniti. L’operatore, che si trova di fronte alsoggetto, sistema un metro a livello della vita, la parte più stretta dell’addome.
Si richiede l’aiuto di un secondo operatore il quale deve accertarsi che il metrosia in posizione orizzontale.Se il soggetto è obeso si misura la circonferenza orizzontale più piccolanell’area compresa tra le coste e la cresta iliaca. 
Valutazione delle circonferenze addominali : 
uomini >
94 cm (aumentata) 
>102 cm ( sostanzialmente aumentato)
donne > 80 cm (aumentata)
>88 cm ( sostanzialmente aumentato)
Circonferenza addominale
E’ un indicatore del tessuto adiposo sottocutaneo addominale. Essa differisceda WC per essere la circonferenza massima dell’addome.
Il soggetto è in posizione eretta, con i piedi uniti, l’addome rilassato e le brac-cia pendenti ai lati del corpo. L’operatore misura la circonferenza massimadell’addome. Questo livello corrisponde spesso, ma non sempre, a quello
nell’ombelico. (Idealmente, un secondo operatore dovrebbe controllare il cor-retto posizionamento del metro sul lato non visibile al primo operatore.) Lamisurazione viene effettuata al termine di una normale espirazione
Circonferenza dei fianchi
La circonferenza dei fianchi (HC, hip circumference) è un indicatore di adi-posità, muscolarità e struttura ossea della regione dei fianchi. Utilizzata con-giuntamente a WC, nella forma del rapporto vita:fianchi (WHR, waist-hipratio = WC/HC), essa consente di valutare il rischio metabolico associato alsovrappeso. Valori di WHR > 1.0 nell’uomo e >0.85 nella donna segnalano un aumento del rischio delle complicanze meta-boliche.Il soggetto è in posizione eretta, con i piedi uniti, e le braccia pendenti ai latidel corpo. L’operatore misura la circonferenza massima dei glutei. (Ideal-mente, un secondo operatore dovrebbe controllare il corretto posizionamentodel metro mente al di sopra degli epicondili femorali.
159Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#16,16,"agli organi in cui viene depositato (ad esempio nel fegato a causa dell’emo-
cromatosi).Il fabbisogno giornaliero è di circa 10 mg, nell’uomo, e 18 mg nella donna,durante il periodo dell’età fertile. Il fabbisogno aumenta nei bambini e negliadolescenti.Per il ferro è raccomandata la supplementazione solo in situazioni di carenzaaccertata, poiché una dieta anche se equilibrata, non sempre permette la co-pertura nel caso di aumentato fabbisogno di ferro. Situazioni carenziali di ferrosi osservano piuttosto frequentemente nelle donne in età fertile, con perditemestruali abbondanti o polimenorrea. Scegliere alimenti di origine animalequali crostacei, pesce, carne, interiora (fegato, rene, cuore), consumare ali-menti vegetali a foglia (broccoli, spinaci, indivia, radicchio verde), legumi,insieme a discrete quantità di vitamina C, che aumenta la biodisponibilità delferro non-eme. Sono comunque i comportamenti da suggerire anche perchétalvolta possono essere sufficienti per assicurare la copertura dei fabbisognisenza dover ricorrere a specifici integratori.LoZinco è cofattore di numerosi enzimi coinvolti nel metabolismo delle pro-
teine e degli acidi nucleici, in cui svolge un ruolo catalitico e strutturale di re-golazione. Favorisce la maturazione delle gonadi, interviene nel correttofunzionamento del gusto e dell’olfatto; potenzia la risposta immunitaria, è im-portante nella riproduzione cellulare.Lo zinco dell’organismo umano è pari a circa 2 g, distribuito in tutti i tessuti,ma in particolare modo nella muscolatura striata, nelle ossa e, in piccola per-centuale, nella pelle. Situazioni da carenza di zinco possono verificarsi in pazienti trattati a lungocon nutrizione parenterale, in portatori di by-pass intestinali o in soggetti an-ziani. Rischi da carenza possono aversi in coloro che fanno un gran consumodi cereali integrali, legumi, prodotti a base di crusca, nei vegetariani stretti, acausa dell’alto contenuto di fitati, ossalati e fosfati che si comportano da che-lanti, limitando l’assorbimento dei sali minerali. La dieta media italiana assi-cura ampiamente un’assunzione totale di zinco che soddisfa la quotaraccomandata (10 mg/die per gli uomini, 7 mg/die per le donne).Le maggiori fonti alimentari sono rappresentate da carne bovina ovina, suina,uova, pesce, ostriche, latte e derivati, cereali, funghi, cacao, noci. LoIodio è il principale costituente degli ormoni tiroidei (tirosina e triiodioti-
ronina), regolatori di alcune funzioni metaboliche quali l’accrescimento cor-poreo e lo sviluppo del sistema nervoso centrale. E’ importante per laregolazione della termogenesi, nel metabolismo dei macronutrienti; per la fis-
16Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#160,160,"Circonferenza braccio
AC è una componente standard della valutazione dello stato nutrizionale , è
un indicatore della dimensione traversale del braccio, usata per il calcolodell’AMA, e AFA e AMC. È un predittore di mortalità e malnutrizione perdifetto.Il soggetto è in posizione eretta flette il gomito a 90° l’operatore localizza ilpunto medio tra il processo coraco-acromiale della scapola e il margine
inferiore dell’ulna.
Circonferenza dell’avambraccio
La circonferenza dell’avambraccio è utile per una miglior definizione delledimensioni dell’arto superiore ma è meno impiegata di AC. Il soggetto è in posizione eretta, con le braccia leggermente distanti dal troncoe il palmo della mano rivolto anteriormente. Il metro viene fatto scorrere sullaparte prossimale dell’avambraccio fino ad identificarne la circonferenza mas-sima.
Circonferenza del polso
La circonferenza del polso viene utilizzata principalmente come indicatoredella taglia corporea, poiché questa regione è relativamente priva di tessutoadiposo e muscolare.Il soggetto è in posizione eretta, con il braccio flesso e il palmo della manosul lato non visibile al primo operatore
Tipo costituzionale Grant Circonferenza del polso (cm)
Circonferenza coscia
La circonferenza mediana (MThC) della coscia è un indicatore di adiposità
e muscolarità , consente la stima di TFA, TMA e TMC.
Il punto di repere della circonferenza mediana della coscia è localizzato tra il
punto medio tra la piega inguinale e il margine prossimale della rotula , più
facilmente localizzabile a ginocchio flessoM > 20a F >20a
Brevilineo >20 >18
Normolineo 16-20 14-18
Longilineo <16 <14
160Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#161,161,"Plicometria 
Il termine plica (pannicolo adiposo) si riferisce allo spessore di una piega dellacute e del tessuto adiposo sottocutaneo sollevata in posizioni standardizzatedel corpo. Le pliche forniscono una buona misura del grasso sottocutaneo; poiché esisteuna relazione fra il grasso sottocutaneo ed il grasso corporeo totale, si ritieneche il risultato della misura delle pliche sia un buon indicatore dellacomposizione e della densità corporea. Alcuni autori ritengono infatti che lasomma delle varie pliche possa essere utilizzata per la stima del grassocorporeo totale. L’utilizzo della somma viene ritenuto utile per ridurre l’errore nella misura eper compensare possibili differenze nella distribuzione del grasso sottocutaneotra soggetti della stessa età, gruppo etnico e sesso. Lo spessore del pannicolo adiposo varia con l’età, il sesso e l’etnia. Le equazioni che associano i valori delle pliche sottocutanee al grasso corporeototale sono state sviluppate utilizzando modelli di regressione, per lo piùmultipla, sia lineari (popolazione-specifici) sia quadratici (generalizzati) delledimensioni, considerando come variabili dipendenti i valori di densità, massagrassa e massa magra valutati su base densitometrica e pliche, o somma dellestesse, o diametri o perimetri o statura come variabili indipendenti. Esistononumerosissime equazioni popolazione-specifiche per predire la densitàcorporea (D) da varie combinazioni di pliche, circonferenze e diametri ossei(Jackson and Pollock, 1985. Slaughter et al. 1988. Lohman 1986). Leequazioni specifiche sono state sviluppate per popolazioni relativamenteomogenee e si assume che siano valide solo per individui aventi caratteristichesimili rispetto ad età, genere, etnia e livello di attività fisica. Ottenuto il valore della densità corporea è possibile calcolare la percentualedi grasso corporeo attraverso diverse formule 
Dove: 
BD = densità corporea in kg/dm3. Conosciuta la percentuale di grasso è possibile determinare la massa di grasso corporeo conla seguente equazione: FM (kg) = (FM% x BW) / 100 Per differenza è quindi possibile ottenere la massa magra: Autore Equazione 
Siri %FM = [ (4.95/BD) – 4.5] x 100 
Brozek %FM = [ (4.57/BD) – 4.142] x 100 
Rathbun & Pace %FM = [ (5.548/BD) – 5.044] x 100 
161Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#162,162,"FFM (kg) = BW – FM (kg) 
Dove: BW = peso corporeo. 
La misura delle pliche si effettua per mezzo di un plicometro (Figura 2).
Esistono vari tipi di plicometri. Un plicometro è un particolare tipo di calibro,nel quale la pressione che agisce sulla piega cutanea sollevata, è costante econtrollata per non provocare lo schiacciamento del tessuto adiposo. Nel casodel plicometro Lange, ad esempio si hanno brevi branche foggiate a chela,solidali con una molla a pressione che tende a mantenerle unite alle loroestremità; la pressione esercitata è compresa tra 2 g/mm2 e 15 g/mm2. (20kPa e 150 kPa). 
Metodologia Plicometrica
Sollevamento della plica : 
- palpare il sito prima della misurazione in modo tale da predisporre il soggetto
al contatto con lo strumento
- con il pollice e l’indice della mano sinistra viene sollevato un doppio strato
di cute e sottocute 1 cm al di sopra del sito di misurazione
- poi separare le dita dal sito di misurazione in maniera tale da non alterare la
misurazione con la pressione esercitata dalle dita stesse. 
- la plica viene sollevata in modo tale da essere perpendicolare alla superficie
del corpo.
Applicazione del plicometro - mentre la mano sinistra serve a sollevare la plica la mano destra tiene il
plicometro. 
- esercitare una pressione per separare le estremità dello strumento e
posizionare il suo braccio fisso su di un lato della plica 
- infine, rilasciare il plicometro gradualmente, in modo tale da non far sentire
sensazioni fastidiose al soggetto sotto esame. 
Lettura della misura : 
La misura viene rilevata 4 secondi dopo aver rilasciato il plicometro. La mi-surazione deve essere effettuata 3 volte e si assume il valore medio come ilreale
162Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#163,163,"Plica tricipitale
E’ un indicatore dei depositi adiposi sottocutanei della regione posteriore delbraccio. Essa è un riferimento, al valore prognostico nella malnutrizione perdifetto.La plica viene sollevata sulla faccia posteriore in corrispondenza del puntomedio tra il margine laterale del processo coraco-acromiale e il margine infe-riore del processo oleocranico dell’ulna 
Plica bicipitale
La plica bicipitale è un indicatore dei depositi adiposi sottocutanei della re-gione anteriore del braccio.La plica viene sollevata sulla faccia del braccio 1 cm al di sopra del punto con-trassegnato per la misurazione della plica tricipitale, su una linea verticale checongiunge il margine anteriore dell’acromion e il centro della fossa anticubi-tale.
Plica sottoscapolare
La plica sottoscapolare è un indicatore dei depositi adiposi sottocutanei dellaregione posteriore del torace.La plica viene sollevata su una linea diagonale a indicazione infero-laterale, a45° rispetto al piano orizzontale della scapola.
Plica soprailiaca
E’ un indicatore dei depositi adiposi sottocutanei della regione addominale.La plica viene sollevata sulla linea medio-ascellare, immediatamente al disopra della cresta iliaca a 45° rispetto al piano orizzontale.
Plica anteriore coscia
E’ un indicatore dei depositi adiposi sottocutanei della regione mediana dellacoscia.La plica viene misurata sulla faccia anteriore della coscia in corrispondenzadel punto medio di una linea tracciata tra la piega inguinale e il margine pros-simale della rotula.
163Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#164,164,"Equazioni con 4 pliche Durnin e Womersley
P = somma bicipitale, tricipitale, sottoscapolare, soprailiaca
Contenuto in grasso corporeo, espresso come percentuale del peso, corrispondente ai diversi
valori della somma di 4 pliche cutanee (bicipitale, tricipitale, sottoscapolare, sovrailiaca) dimaschi e femmine a differenti età . (Durnin e Womersley 1974) Maschi 
(20-29a) D = 1,1631 -0,0632 logP 
(30-39a) D = 1,1422 – 0,0544 logP 
(40-49a) D = 1,1620 – 0,0700 logP 
(> 50a) D = 1,1715 – 0,0779 logP 
(17-72a) D = 1,1765 – 0,0744 logP Femmine 
(20-29a) D = 1,1599 -0,0717 logP 
(30-39a) D = 1,1423 – 0,0632 logP 
(40-49a) D = 1,1333 – 0,0612 logP 
(> 50a) D = 1,1339 – 0,0645 logP (17-72a) D = 1,1567 – 0,0717 logP
Somma  
pliche Femmine (età in anni)
(mm)
16-29 30-39 40-49 50+
20 14,10 17,00 19,80 21,40
30 19,30 21,80 24,50 26,60
40 23,40 25,90 28,20 30,20
50 26,50 28,20 31,00 33,40
60 29,10 30,60 33,20 35,70
70 31,20 32,50 35,00 37,70
80 33,10 34,30 36,70 39,80
90 34,80 35,80 38,30 41,20
100 36,40 37,20 39,70 42,60
110 37,80 38,60 41,70 43,90
120 39,00 39,80 42,00 45,10
130 40,20 40,60 43,00 46,20
140 41,30 41,60 44,00 47,20
150 42,30 42,60 45,00 48,20
160 43,30 43,60 45,80 49,20
170 44,10 44,40 46,60 50,00
180 , 45,20 47,40 50,80
190 , 45,90 48,20 51,60
200 , 46,50 48,80 52,40210 , , 49,40 53,00Somma  
pliche Maschi (età in anni)
(mm)
17-29 30-39 40-49 50+
20 8,10 12,20 12,20 12,60
30 12,90 16,20 17,70 18,60
40 16,40 19,20 21,40 22,90
50 19,00 21,50 24,60 26,50
60 21,20 23,50 27,10 29,20
70 23,10 25,10 29,30 31,60
80 24,80 26,60 31,20 33,80
90 26,20 27,80 33,00 35,80
100 27,60 29,00 34,40 37,40
110 28,80 30,10 35,80 39,00
120 30,00 31,10 37,00 40,40
130 31,00 31,90 38,20 41,80
140 32,00 32,70 39,20 43,00
150 32,90 33,50 40,20 44,10
160 33,70 34,30 41,20 45,10
170 34,50 34,80 42,00 46,10
180 35,30 - , ,
190 35,90 - , ,
200 - - , ,210 - - , ,
164Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#165,165,"AMA (Arm Muscle Area) AFA (Arm Fat Area) 
Le aree muscolo-adipose e le circonferenze muscolari degli arti vengono cal-colate dalla circonferenza e dalla plica di un arto. Dalla combinazione di dueindicatori antropometrici, una plica e una circonferenza, la loro performancenella valutazione dello stato nutrizionale è generalmente migliore rispetto allasingola plica o circonferenza.
Maschi 
AMA corretta (AMA - osso) = (MAC-πxTSF)
2/4π-10
FemmineAMA corretta (AMA - osso) = (MAC-πxTSF)
2/4π-6.5
Heymsfield et al.. Am J Clin Nutr, 1982
Impedenziometria 
L’analisi dell’impedenza biolelettrica (BIA) è un metodo rapido e non invasivoper valutare la composizione corporea. In questo metodo una corrente alternataa bassa tensione attraversa il corpo del soggetto, viene misurata in questo modol’impedenza (Z), cioè la resistenza al passaggio della corrente. Il passaggiodella corrente avviene per attivazione degli elettroliti presenti nell’acqua. Laresistenza al passaggio della corrente elettrica è maggiore nel tessuto adiposoe minore nella massa magra. I tessuti biologici si comportano infatti comeconduttori o come isolanti; la massa magra contiene grande quantità di acquaed elettroliti rendendola migliore, rispetto alla massa grassa, nella conduzionedella corrente elettrica. La misura viene effettuata con apparecchi che iniettanocorrente alternata di 800 μA (micro Ampere) a diverse frequenze (1-1000kHz). L’impedenza è il rapporto tra la differenza di potenziale (V olt) e l’in-tensità di corrente (Ampere), la sua unità di misura è l’Ohm. Considerando il corpo umano come un cilindro con differenza di potenzialetra base inferiore e base superiore, l’impedenza che si oppone al passaggiodella corrente elettrica nel corpo è direttamente proporzionale alla sua lun-ghezza (statura) ed inversamente proporzionale all’area della sezione trasver-sale del corpo. I tessuti biologici agiscono come conduttori o isolanti ed il flusso di correntesegue un percorso di minima resistenza. L’uso della bioimpedenziometria pervalutare la composizione corporea si basa su diverse proprietà conducenti edielettriche dei tessuti biologici al variare della frequenza riferita alla correnteelettrica; i tessuti che contengono acqua ed elettroliti come il liquido cerebro-
165Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#166,166,"spinale, il sangue ed i muscoli sono buoni conduttori, mentre il grasso, l’osso
e gli spazi pieni d’aria come i polmoni sono tessuti dielettrici. Nel corpoumano, il volume (V) di questi tessuti può essere dedotto dalla misura dellaloro resistenza (R).L’impedenza è una funzione di resistenza (R) e reattanza (Xc):  Z = R
2+ Xc2
L’impedenza (Z) è l’opposizione dipendente dalla resistenza di un conduttoreal flusso di una corrente elettrica alternata ed è scomponibile in due membri:resistenza (R) e reattanza (Xc). La resistenza (R) è la misura pura di opposi-zione al flusso di corrente elettrica ed è inversa alla conduttanza. La reattanza(Xc) è l’opposizione al flusso di corrente causato dalle massa corporea (MC)ed è il reciproco della capacitanza; nella bioimpedenziometria, resistenza (R)e impedenza (Z) sono intercambiabili perché la reattanza (Xc) è molto bassa(<4%). A 50Hz, la resistenza (R) è maggiore della reattanza (Xc) perciò la re-sistenza (R) è il miglior predittore della impedenza (Z).
L’indice di resistenza corrisponde a:  statura (S)
2/resistenza (R), mentre il mi-
glior predittore di acqua extra cellulare (ECW) è:  statura (H)2/ reattanza (Xc).
La resistenza (R) tra due punti è definita dalla legge di Ohm:  resistenza (R) =
distanza tra due punti (V) / intensità di corrente (I). Come già anticipato, per un conduttore cilindrico isotropo, la resistenza (R) èdirettamente proporzionale alla lunghezza (L) ed inversamente proporzionalealla sua sezione (A), pertanto, la resistività ( ρ) specifica del tronco è 2 o 3
volte superiore rispetto alla resistività ( ρ) di quella delle estremità. Anche la
resistività ( ρ)degli adulti è maggiore che nei bambini e la resistività ( ρ)
degli obesi è maggiore che nei normopeso.
resistenza = espressione dell’acqua corporea totale (TBW)
reattanza = espressione della cellularità corporea
L’analisi dell’impedenza bioelettrica si esegue sul lato destro del corpo con il
soggetto disteso supino. Si posizionano 4 elettrodi, di cui 2 sull’arto superioree 2 sull’arto inferiore. A livello dell’arto superiore si pone un elettrodo prossimale a livello delprocesso stiloideo di radio e ulna ed un altro distale, alla base dell’articolazionedella seconda o terza articolazione metacarpo-falangea nella mano. Nell’arto inferiore gli elettrodi vanno posizionati prossimamente a livello deimalleoli mediale e laterale della caviglia e distalmente a livellodell’articolazione metatarso-falangea nel piede. Il livello di errore “accettabile” per un’analisi della CC previa bioimpe -
166Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#167,167,"denziometria è < 3,5kg per gli uomini e < 2,5kg per le donne. 
Il livello di accuratezza e precisione del metodo bioimpedenziometrico è
influenzato soprattutto dalle variabilità intra-strumentali (taratura) e dallevariabilità inter-strumentali. Negli impedenziometri a monofrequenza puòvariare sensibilmente l’intensità della corrente alternata (800:500 μA) anchecon la stessa frequenza 50KHz, così come l’equazione di predizione (diversitàdei software) e il tipo di calibrazione (interna o esterna). Attraverso le misurazioni effettuate dalle apparecchiature, è possibile ottenerevari parametri:• Acqua corporea totale (TBW -  total body water );
• Acqua extracellulare (ECW -  extra cell water );
• Acqua intracellulare (ICW -  intra cell water );
• Massa cellulare (BCM -  body cell mass);
• Massa magra (FFM - fat free mass);• Massa grassa (FM - fat mass);• Massa muscolare (MM - muscle mass);• Metabolismo basale correlato alla massa cellulare
Angolo di Fase
Valore bioelettrico che indica il rapporto tra Reattanza e Resistenza, ovverotra volumi intra ed Extracellulari. Se un corpo fosse costituito solo damembrane cellulari, quindi senza fluidi (impossibile) si otterrebbe un Angolodi Fase di 90 gradi. Se viceversa fosse composto esclusivamente da fluidi(impossibile) si otterrebbe un Angolo di Fase di 0 gradi. In un essere umanosano il valore dell’Angolo di Fase oscilla tra 6 ed 8 gradi. Un angolo di fasebasso (3/4 gradi) è un indice prognostico molto negativo.Attenzione: massa magra, massa cellulare e massa muscolare non sonosinonimi. Ognuno di essi corrisponde ad un determinato compartimentocorporeo, ognuno dei quali è costituito da specifici elementi.Esso rappresenta il ritardo che subisce la corrente elettrica nell’attraversareun conduttore biologico (elettrico).Esprime la ripartizione dell’acqua corporea ed in particolare del rapportotra acqua intracellulare ed acqua extracellulare. Tale rapporto può essere
considerato un indice dello stato di nutrizione dell’individuo esaminato. Essoviene misurato a 50 kHz (clinico).
Sodio potassio scambiabile
Sodio, soluto extracellulare: un aumento di quest’elemento segue in genere
167Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#168,168,"un aumento dell’acqua extracellulare. Il potassio è invece il principale catione
intracellulare. Il mantenimento dell’equilibrio di questi due soluti èd’importanza vitale.
Range di normalità: 0.9 – 1.0Per un’esecuzione attendibile dell’analisi è consigliata una temperatura
ambiente attorno ai 22 °C, è necessario non mangiare né bere nelle quattro oreprecedenti il test, non avere praticato attività fisica nelle ultime dodici ore,non indossare oggetti metallici (anelli, orecchini) non avere assunto diureticinell’ultima settimana, e svuotare la vescica almeno trenta minuti prima deltest. Nelle donne è indicato considerare la fase mestruale. La precisionedell’analisi può essere influenzata da vari fattori, i principali comprendono:la strumentazione, le capacità dell’operatore, fattori ambientali (temperaturaesterna) e fattori che alterano lo stato di idratazione del paziente (mangiare,bere, etc.). Anche per questo metodo sono presenti equazioni per il calcolo degli elementidella composizione corporea a partire da resistenza, reattanza.
Fattori che influenzano l’individuo da studiare
Temperatura ambientale: la temperatura ambientale dove avviene lamisurazione deve essere tra i 24 e i 26 °C. Temperature basse o più altepossono modificare il risultato per i motivi spiegati in precedenza.
Temperatura cutanea: basse temperatura della pelle portano ad una
vasocostrizione con innalzamento artificioso dell’impedenza, viceversa
temperatue alte (febbre) portano ad una vasodilatazione con una riduzionedell’impedenza.
Preparazione della cute: la conducibilità elettrica migliora trattando la pelle
con alcool etilico in quanto elimina secrezioni e cellule desquamate chepossono causare specifiche interferenze.
Cibo e bevande: Si consiglia che il soggetto sia a digiuno da liquidi e solidi
da almeno 5-8 oreOggetti metallici: Togliere tutti gli oggetti metallici a contatto con la pelle
168Fondamenti della Scienza dell’Alimentazione Capitolo VII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#169,169,"Esercizio fisico: si consiglia di noneffettuare esercizio fisico il giorno prima
dell’esame in quanto potrebbe portare ad una disidratazione che altera il dato
impedenziometrico.
Alcool: l’assunzione di bevande alcoliche prima dell’esame può alterare il
valore di impedenza.Ciclo mestruale: nelle donne in età fertile l’esame deve essere effettuato tra
il 5-15° giorno del ciclo mestruale, al di fuori di questo intervallo si possono
avere variazioni dell’acqua corporea che portano variazioni artificiosedell’impedenza. L’impiego di contraccettivi orali non modifica la valutazioneimpedenziometrica.
Protesi: placche metalliche, protesi mammarie etc… 
In conclusione possiamo affermare:
1) L’analisi bioimpedenziometrica è una tecnica valida per valutare la
composizione corporea quando eseguita in maniera standardizzata
2) La composizione corporea (massa magra e massa grassa) è valutata in
maniera accurata quando la distribuzione dell’acqua corporea è fisiologicae non vi è una distribuzione anomala dell’acqua extracellulare.
3) Da un punto di vista clinico l’angolo di fase sembra essere un parametro
capace di dare delle informazioni sulla distribuzione dell’acqua corporea(rapporto acqua extra/intracellulare) e quindi sullo stato di nutrizione
169Capitolo VII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#17,17,"sazione del calcio nelle ossa. Lo iodio viene assunto tramite diversi alimenti
che lo contengono come alcune specie di pesci (merluzzo, tonno, sgombro),molluschi (cozze), uova, derivati del latte, carne, cereali, frutta e verdura (aseconda dei terreni di coltivazione), acqua potabile e alghe marine essiccate.La cottura riduce il contenuto in iodio degli alimenti, con perdite di circa il58% con la bollitura (WHO, 1996).Gli ultimi dati dell’OSNAMI (Osservatorio Nazionale per il monitoraggiodella iodoprofilassi in Italia) mostrano il persistere di una condizione di iodo-carenza lieve o moderata nel nostro Paese. Le patologie della tiroide sono fre-quenti nella popolazione generale, soprattutto tra le donne, e possono colpiretutte le età, compresa l’età fetale e neonatale. La carenza provoca gozzo en-demico, cretinismo, mixedema, disturbi della memoria, mastodinia. E’ statostimato che in Italia circa 6 milioni di persone soffrono di gozzo ovvero piùdel 10% della popolazione (Fonte http://www.salute.gov.it).Pertanto l’OSNAMI, in collaborazione con il Ministero della Salute ed altriesperti di settore, ha messo in atto una campagna che sensibilizza gli italianialla prevenzione del gozzo e di altri disordini da carenza iodica, con il ricorsoall’uso regolare di sale arricchito con iodio (sale iodurato/iodato) nell’alimen-tazione giornaliera. La quantità di iodio aggiunto al sale da cucina (30 mg diiodio per chilo) consente di contribuire al fabbisogno giornaliero di iodio chenell’adulto, in condizioni fisiologiche, è di 150 μg. Particolarmente elevato èil fabbisogno nelle donne in gravidanza e nei bambini.L’attuazione della profilassi iodica non è però in contrapposizione con la cam-pagna a favore della riduzione del consumo di sale (non più di 4-5 g al giorno)per la prevenzione dell’ipertensione e delle malattie cardiovascolari.Il Selenio è un antiossidante, co-fattore della glutatione perossidasi, protegge
le membrane cellulari, il DNA dai danni dei radicali liberi. È dimostrato unsuo ruolo coenzimatico anche nel metabolismo degli ormoni tiroidei; contri-buisce al normale funzionamento del sistema immunitario e della spermato-genesi (http://www.efsa.europa.eu/it/efsajournal/pub/1220.htm).Gli alimenti ricchi di selenio sono soprattutto le frattaglie (fegato, rognone),pesci, frutti di mare, carne, cereali, frutta a guscio. Il livello del minerale neivegetali è proporzionale alla sua abbondanza nel terreno.Gli apporti giornalieri assunti attraverso una dieta varia, secondo i LARN, ga-rantiscono i livelli raccomandati per l’adulto (55 μg). L’Istituto Superiore diSanità riporta che ”L’Italia è una regione selenifera a basso contenuto e quindil’apporto di questo elemento con la dieta è piuttosto scarso”. La sindrome da carenza di selenio comporta cardiopatie, ipertensione, anemieemolitiche, cirrosi, neoplasie, sclerosi multipla, invecchiamento precoce, ar-
17Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#170,170,"Bibliografia
• Fidanza F., Liguori G., Nutrizione Umana. Idelson Editore, 1988 
• Bedogni G., Borghi A., Battistini N.C., Manuale di valutazione dello stato nutrizionale
ERDA 2001
• Del Toma E. Prevenzione e terapia dietetica Pensiero Scientifico Editore, 2005
• Binetti P., Marcelli M., Baisai R. Manuale di nutrizione clinica e scienze dietetiche applicate
Seu Editrice Universo 2006. 
• Cozzani I., Dainese E., Biochimica degli alimenti e della nutrizione. Piccin Editore, 2006• Riccardi, Pacioni, Giacco, Tivellese. Manuale di Nutrizione Applicata, Sorbona, III Edizione
• Costantini A. M., Cannella C., Tomassi G. Alimentazione e nutrizione umana Pensiero
Scientifico Editore, 2011
• Amerio M. L., Fatati G. Dietetica e nutrizione Pensiero Scientifico Editore, 2012
170"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#171,171,171Capitolo VIII Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#172,172,"CAPITOLO VIII
FABBISOGNO ENERGETICO
Riassunto
Nell’uomo, così come in tutti gli esseri viventi, il mantenimento delle funzionivitali è assicurato dal continuo svolgimento delle reazioni anaboliche e cata-boliche che assicurano la costruzione e il rinnovamento delle strutture cellu-lari e la produzione di energia necessaria allo svolgimento del metabolismodi sintesi e al mantenimento delle molteplici forme di attività vitale (mecca-nica, osmotica, elettrica, ecc).La valutazione del fabbisogno energetico è di fondamentale importanza perla determinazione di un programma nutrizionale personalizzato.
172Fondamenti della Scienza dell’Alimentazione Capitolo VIII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#173,173,"Per fabbisogno energetico di un individuo si intende la quantità di energia ali-
mentare necessaria a compensare il suo dispendio energetico, risultante dalmetabolismo basale, termogenesi indotta dalla dieta e livello di attività fisica.Si definisce FABBISOGNO ENERGETICO l’apporto di energia di origine
alimentare necessario a compensare il dispendio energetico di individui chemantengono un livello di attività fisica sufficiente a partecipare attivamentealla vita sociale ed economica e che abbiano dimensioni e composizione cor-poree compatibili con un buono stato di salute a lungo termine.Nel caso di bambini o di donne in gravidanza o allattamento, il fabbisognodeve comprendere la quota energetica necessaria per sostenere la deposizionedi nuovi tessuti o per la secrezione di latte (WHO,1985).Il fabbisogno energetico si calcola sulla base del dispendio energetico che èla risultante di tre componenti:• METABOLISMO BASALE ( M.B.)• TERMOGENESI INDOTTA DALLA DIETA ( TID )• COSTO ENERGETICO ATTIVITA’ FISICA ( LAF )
8.1 METABOLISMO BASALE ( M.B.)
Rappresenta la quantità di energia necessaria a garantire l’integrità funzionale
e morfologica delle cellule e dei tessuti e a mantenere una temperatura corpo-rea costante.La misurazione viene effettuata sul soggetto a digiuno da 12 ore, in condizionidi neutralità termica, sveglio e in totale rilassamento.Rappresenta il 65-75% del dispendio energetico totale ed è correlato al pesocorporeo, al sesso, all’età e alla massa magra e varia in particolari condizionifisiologiche come gravidanza, allattamento e accrescimento. Può essere misurato attraverso specifiche tecniche calorimetriche oppure pre-detto attraverso equazioni che tengono conto del peso corporeo, del sesso edell’età.
8.1.1 CALORIMETRIA DIRETTAMisura il calore prodotto da un individuo collocato all’interno di una camera
metabolica; tiene conto della quantità di ossigeno consumato, della CO2 pro-dotta e della quantità di azoto secreta attraverso le urine e le feci.
173Capitolo VIII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#174,174,"8.1.2 CALORIMETRIA INDIRETTA
Si basa sul principio che i processi ossidativi metabolici richiedono un deter-
minato consumo di O2. Noto il coefficiente termico dell’02 in condizioni ba-sali (4,825 Kcal/l) e misurata la quantità utilizzata in un determinato periododi tempo è possibile misurare la spesa energetica dell’individuo.
Harris Benedict ( 1919)
UOMINI: 
KCAL/24 ORE= 66, 473 + (13,7516 X P ) + ( 5, 0033 X h) – (6,7550 X ETÀ)
DONNE: 
KCAL 24 ORE = 655,0955 + (9,5634 X P ) + ( 1,8496 X h) – ( 4,6756 X ETÀ)
P = peso in kg; h = altezza in cm;In queste equazioni si utilizza il valore del peso corporeo osservato se si vuoleun calcolo di tipo conservativo, il valore riferito al peso desiderabile ( bmi 20-25 per gli uomini e 18,7- 25,8 per le donne ) se si vuole una stima del fabbi-sogno per realizzare una perdita o un aumento di peso.
8.2 TERMOGENESI INDOTTA DALLA DIETA ( TID )
Dopo l’assunzione di un pasto si assiste ad un incremento della spesa energe-
tica che varia tra i differenti substrati nutritivi.Questo fenomeno è stato definito ADS (Azione Dinamico Specifica). La causaeffettiva di tale aumento non è chiara, la ADS delle proteine sembra legataalle trasformazioni metaboliche a cui vanno incontro gli aa ( deamminazione,gluconeogenesi e sintesi proteica ), la ADS dei glucidi forse in relazione aimeccanismi di glicogenosintesi epatica post-prandiale, la ADS dei lipidi allaliposintesi dei grassi di deposito.Corrisponde al 7-15% del dispendio energetico totale; le proteine concorronoalla spesa energetica per il 10-35%, i glucidi per il 5-10% e i lipidi per il 2-5%.
8.3 COSTO ENERGETICO ATTIVITA’ FISICA ( LAF )
E’ strettamente dipendente dal tipo, dalla frequenza e dall’intensità delle atti-
vità svolte dall’individuo. Viene espresso in kcal o kj per unità di tempo (mi-nuto, ora, giorno) oppure come multiplo del Metabolismo Basale e può variare
174Fondamenti della Scienza dell’Alimentazione Capitolo VIII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#175,175,"dal 15% del MB in soggetti con attività piuttosto sedentarie fino a valori pari
al 3-4 volte il MB per attività pesanti o negli atleti. Ogni attività viene espressaattraverso il cosiddetto Indice Energetico Integrato (IEI) e dalla somma dei
costi energetici di tutte le attività svolte nella giornata si calcola il livello diattività fisica di un individuo (LAF) che rappresenta il dispendio energeticodi un soggetto durante un’intera giornata.Sono stati anche elaborati LAF medi divisi per tipologia di attività.Livelli di attività fisica (espressi in LAF) da utilizzare per stimare il fabbisognoenergetico per sesso e classi di età.
Per attività fisiche auspicabili si intendono le attività consigliate ai soggetti
sedentari per il mantenimento del tono muscolare e cardiocircolatorio.- attività leggere: corrispondono allo stare seduti o in piedi senza spostamenti
(casalinghe, impiegati, liberi professionisti, operai)
- attività moderate: comportano spostamenti del corpo, flessioni del tronco,
intenso lavoro di braccia, per periodi non troppo prolungati (giardinieri,collaboratori domestici)
- attività pesanti: sono quelle eseguite con movimenti di tutto il corpo e
l’impegno di tutta la forza muscolare (zappare, picconare o trasportare pesinotevoli).
Moltiplicando il LAF medio per il MB del soggetto si ottiene il dispendio ener-COMPRESE LE ESCLUSE LECLASSE DI ETÀATTIVITÀ ATTIVITÀLIVELLO DIFISICHE FISICHEATTIVITÀAUSPICABILI* AUSPICABILI*
LAF LAF
Uomini 18-59 anni leggero 1,55 1,41
moderato 1,78 1,70
pesante 2,10 2,01
60-74 anni 1,51 1,40
>=75 anni 1,51 1,33
Donne 18-59 anni leggero 1,56 1,42
moderato 1,64 1,56
pesante 1,82 1,73
60-74 anni 1,56 1,44
>=75 anni 1,56 1,37
175Capitolo VIII Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#176,176,"getico totale espresso come quantità di energia per unità di tempo.
Esempio di stima del fabbisogno energetico:soggetto di sesso maschile, età anni 35, peso Kg 75, h cm 170, BMI 22
Kg/mxm , impiegato (attività fisica leggera)MB = 66, 473 + (13,7516 X 75) + (5, 0033 X 170) – (6,7550 X 35) = 1711Kcal/giornoLAF attività fisica leggera 1,55
FABBISOGNO ENERGETICO = 1711 x 1,55 = 2652 Kcal/ giorno
176Fondamenti della Scienza dell’Alimentazione Capitolo VIII"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#177,177,"Bibliografia
• Manuale di Nutrizione Applicata” Riccardi Pacioni Rivellese Ed. Sorbona
• Nutrizione Clinica Magnati Russo Dazzi EdiSES• Nutrizione umana F. Fidanza G. Liguori Ed. IDELSON• Basi metodologiche dell’approccio psiconutrizionale Paolo De Cristofaro Ed. SEE FI-
RENZE
177Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#178,178,"CAPITOLO IX
STRUMENTI DI INDAGINE ALIMENTARE
Riassunto
La rilevazione dei consumi alimentari costituisce un ottimo indicatore indiretto
dello stato nutrizionale. Per le indagini nutrizionali possono essere utilizzatemetodologie diverse a seconda degli obiettivi. Le metodologie si basano so-stanzialmente sulla registrazione o sul ricordo. I principali metodi di rileva-zione della dieta sono il diario, il ricordo delle 24 ore e i questionari difrequenza. Non esiste un metodo di indagine alimentare che sia migliore inassoluto, ciascun metodo ha i suoi vantaggi e svantaggi e sta nelricercatore/operatore scegliere il più o i più adatti per la valutazione dellostato di nutrizione.
178Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#179,179,"9.1 Strumenti di indagine alimentare
La valutazione dello stato di nutrizione è molto importante in quanto permette
a livello individuale di rilevare gli eventuali problemi nutrizionali nei singolisoggetti e quindi consente di porvi rimedio attraverso un corretto riequilibriodietetico. A livello di gruppo permette di elaborare statistiche di prevalenza oincidenza di forme di malnutrizione, fornendo elementi essenziali per pianifi-care interventi istituzionali di recupero. La valutazione dello stato nutrizionalecostituisce quindi uno strumento di fondamentale importanza nella sorve-glianza nutrizionale.Oltre che mediante metodi diretti quali le misurazioni antropometriche e bio-chimiche, la rilevazione dello stato nutrizionale può avvenire tramite misura-zioni indirette quali la raccolta delle informazioni sui consumi alimentari. In generale, quattro sono i principali usi dei dati sui consumi alimentari:• Misurazione e sorveglianza del consumo di alimenti e nutrienti (Stima del-
l’adeguatezza dell’assunzione alimentare di individui e gruppi di soggetti)
• Formulazione e valutazione delle politiche governative sanitarie e agricole (pia-
nificazione della produzione e distribuzione degli alimenti, definizione di re-golamenti sugli alimenti e nutrizione, creazione di programmi di educazionealimentare e di riduzione delle malattie, valutazione del successo e dei costi-benefici dei programmi di educazione alimentare e di riduzione delle malattie)
• Conduzione degli studi epidemiologici per studiare le relazioni tra dieta e
salute e per identificare gruppi a rischio per lo sviluppo di alcune patologielegate alla dieta
• Fini commerciali
La misura dei consumi alimentari permette di tracciare il profilo dietetico di:
• singoli individui
• gruppi di individui (bambini, gruppi a rischio, pazienti, anziani etc.)• popolazioni o gruppi di popolazioni (coorti, gruppi rappresentativi etc.)
Per la rilevazione dei consumi alimentari possono essere utilizzate metodolo-
gie diverse a seconda degli obiettivi.È importante sottolineare che non esiste un metodo di indagine alimentare chesia migliore in assoluto e che la misurazione della dieta è sempre accompa-gnata da un certo grado di errore. Ciascun metodo ha i suoi vantaggi e svan-taggi e sta nel ricercatore/operatore scegliere il metodo migliore in base alproprio scopo.
179Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#18,18,"teriosclerosi e facilità alle infezioni.
1.1.2 Vitamine
Le vitamine (Tabella 1) sono un insieme molto eterogeneo di sostanze chimi-che, richieste in quantità pari a milligrammi o microgrammi per soddisfare ifabbisogni dell’organismo. Per la maggior parte, devono essere introdotte conla dieta, poichè non vengono sintetizzate o solo in parte dall’organismo. Nonvengono usate per produrre energia né per usi strutturali, ma sono precursoridi ormoni, agiscono da antiossidanti, partecipano come substrati a reazionispecifiche, regolano una serie di reazioni metaboliche, spesso funzionanocome coenzimi. La maggior parte delle vitamine deve essere ulteriormentetrasformata per generare coenzimi, e prendere parte direttamente all’azionecatalitica dell’enzima. Possono manifestarsi delle ipovitaminosi, a causa di una insufficiente assun-zione con gli alimenti (ad esempio la vitamina B12), di un aumentato fabbi-sogno (ad esempio in gravidanza, con i folati), o per la presenza di alterazioniintestinali che ne impediscono l’assorbimento. In generale, oltre ad una ali-mentazione corretta ed equilibrata, l’utilizzo di specifici integratori può essereutile a coprire l’aumentato fabbisogno. 
Vitamine idrosolubili Vitamine liposolubili
Vitamina B1 (tiamina) Vitamina A (retinolo ed analoghi)
Vitamina B2 (riboflavina) Vitamina D (ergocalciferolo D2
e colecalciferolo D3)
Vitamina B3 o Vitamina PP Vitamina E (tocoferolo)
(niacina o acido nicotinico)
Vitamina B5 o Vitamina W Vitamina K (fillochinone e derivati)
(acido pantotenico)Vitamina B6 
(piridossina o piridossamina o piridossale)
Vitamina B8 o Vitamina H (biotina)Vitamina B9 o Vitamina Bc o Vitamina M 
(acido folico)
Vitamina B12 (cobalamina)Vitamina C (acido ascorbico)Tabella 1 - Classificazione delle vitamine in liposolubili ed idrosolubili sulla base della loro
insolubilità o solubilità in acqua
18Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#180,180,"Un punto molto importante da tener presente nella scelta della metodologia
da utilizzare è rappresentato dalla variazione della dieta nel tempo. In moltecircostanze il fattore tempo è estremamente importante dal momento che avolte sono necessari alcuni anni prima che si verifichi l’effetto della dieta sul-l’insorgenza di una patologia. In questi casi valutare le variazioni quotidianedella dieta è assolutamente necessario per indirizzare meglio la scelta di unmetodo più adatto di stima della dieta e per interpretare i dati raccolti. La va-riabilità individuale della dieta di una popolazione dipende dalla diversifica-zione quotidiana ed è legata a numerosissimi fattori tra cui la stagionalità dialcuni alimenti, il costo, il giorno della settimana (giorno lavorativo o fine set-timana, festività etc.), la condizione socioculturale. La variabilità è differenteper i macronutrienti e micronutrienti, in generale è minore per i primi e mag-giore per i secondi. Due sono sostanzialmente le metodologie della rilevazione dei consumi ali-mentari:La registrazione (dietary record): gli alimenti e le bevande vengono descritti
e/o quantificati al momento del consumo in un determinato intervallo ditempo:• Breve periodo (diario)
Ilricordo (dietary recall): viene chiesto al soggetto di ricordare gli alimenti
e le bevande consumati nel passato per certo intervallo di tempo :
• Breve periodo, ovvero la dieta abituale. 
A tal fine vengono utilizzate delle tecniche che siano in grado di misurare
con un buon grado di precisione le quantità di alimenti consumati (ricordodelle 24 ore, delle 48 ore o delle 72 ore)
• Medio periodo (settimana, mese precedente: questionario di frequenza (FFQ)• Lungo periodo (anno precedente, periodi della vita: FFQ, storia dietetica etc.)
9.2 Diario di registrazione degli alimenti
Registrazione dettagliata del tipo e della quantità di tutti gli alimenti e bevande
consumate ad ogni pasto durante un periodo di tempo, in genere da 3 a 7giorni. Gli alimenti e le bevande consumate possono essere quantificate tramiteporzioni standard (ad esempio modelli di porzioni, tazze, cucchiai o medianteil righello) oppure pesando gli alimenti. Tipicamente se sono registrati più
180Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#181,181,"giorni, sono consecutivi e non includono più di 3 o 4 giorni. La registrazione
di periodi più lunghi di 4 giorni risulta insoddisfacente dal momento che si hauna riduzione nei consumi dovuti alla fatica da parte dell’intervistato nel doverregistrare tutti gli alimenti consumati. Teoricamente l’informazione sui consumi alimentari deve essere registrata almomento del consumo, ma non è necessario scrivere su un foglio, ma si pos-sono utilizzare anche dei registratori oppure adesso sono disponibili delle ap-plicazioni per il computer o il tablet.L’utilizzo del diario necessita di un’accurata preparazione del soggetto circale modalità di registrazione, la descrizione della tipologia e della quantità dialimento consumato. In particolare, il soggetto deve essere istruito sul dettagliocon cui deve descrivere gli alimenti e la quantità consumata, includendo nomedell’alimento (la marca laddove possibile), metodo di preparazione, ricette pergli alimenti composti e la misura della porzione. In alcuni casi si implemental’addestramento del soggetto contattando e rivedendo il diario dopo il primogiorno di registrazione. Alla fine della registrazione il diario va accuratamentecontrollato da un operatore che insieme all’intervistato deve chiarire i puntioscuri e verificare eventuali dimenticanze. In alcuni casi altre persone oltre ilsoggetto possono compilare il diario e questo viene fatto ad esempio per i bam-bini o le persone nelle case di cura.Il diario solitamente è in una forma “aperta” (open-ended), cioè lasciando lalibertà all’intervistato di riportare gli alimenti consumati, anche se in alcunicasi sono state sviluppate anche delle versioni cosiddette “chiuse” (close-ended). Queste ultime consistono in una lista predefinita di gruppi di alimentie il soggetto deve scegliere quello consumato. Le porzioni possono essere chie-ste anch’esse in un formato “open-ended” o mediante categorie predefinite. Vantaggi di questo metodo di indagine alimentare:• Può fornire informazioni dettagliate sul consumo degli alimenti durante il
periodo registrato. Registrare il consumo degli alimenti intanto che vengonomangiati diminuisce il problema delle omissioni e fornisce informazioni piùaccurate sulla quantità di alimenti consumati in ogni singola occasione ri-spetto al dover ricordare le porzioni consumate precedentemente. 
• Può fornire informazioni sulle abitudini alimentari• Non dipende dalla memoria 
Limiti di questo metodo di indagine alimentare: 
• estremamente costoso • dispendioso in termini di tempo 
181Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#182,182,"• necessaria alta motivazione e buona scolarità, quindi può creare un problema
di selezione del campione
• può modificare il comportamento alimentare nel periodo di osservazione,
cioè il dover registrare quello che si è mangiato può influenzare sia ciò che
si mangia che la quantità consumata. La conoscenza richiesta per descriverel’alimento consumato e il fatto di doverlo registrare può alterare le abitudinialimentari che si intendono misurare con questo strumento 
• analisi dei dati è estremamente laboriosa. Anche se attualmente sono dispo-
nibili software che permettono un facile inserimento dei dati e quindi per-mettono un risparmio di tempo nella codifica degli alimenti, mantenere uncontrollo generale della qualità dei dati è difficile perché spesso le informa-zioni non sono registrate consistentemente da soggetto a soggetto.
Il diario è indicato per piccoli gruppi di soggetti con buon livello culturale emolto motivati. Studi che hanno valutato il consumo di energia e nutrientisomministrando il diario in piccoli campioni di soggetti adulti sottostimavanol’energia in un intervallo dal 4 al 37% se paragonati al dispendio energeticomisurato dall’acqua marcata o al consumo proteico misurato da azoto urinario.Quindi il diario viene considerato uno strumento “gold standard” imperfetto.La sottostima è il risultato sia dell’incompleta registrazione che dell’impattodi dover registrare quello che si è mangiato. Sono stati suggeriti diversi ap-procci per cercare di superare il problema della sottostima nel diario: alcunihanno suggerito di fare un rigoroso addestramento del soggetto, altri di inseriredelle domande psico-sociali note per essere associate alla sottostima in mododa poter valutare il livello di sottostima. Infine, altri hanno suggerito di cali-brare il diario alimentare con il dispendio energetico misurato dall’acqua mar-cata per meglio predire il consumo energetico individuale.
9.3 Il ricordo delle 24 ore
Ricordo del tipo e della quantità degli alimenti e bevande consumate nelle 24
ore precedenti. Un intervistatore ben addestrato, coadiuvato da supporti visivi(atlante fotografico, modelli di porzioni, tazze, fotografie di piatti pronti, ecc.)chiede al soggetto di descrivere con precisione tutto ciò che ha consumatonelle 24 ore precedenti per risalire alla quantità consumata di ogni alimento obevanda. Occasionalmente il periodo temporale riguarda le 48 ore precedenti,le 72 ore precedenti etc. Ovviamente i ricordi di quello che si è assunto pos-
182Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#183,183,"sono sbiadire piuttosto rapidamente al di là del giorno più recente o di due
giorni, per cui la perdita di precisione può superare il guadagno in termini dirappresentatività.L’intervista solitamente è strutturata con specifiche domande in modo da ri-cordare tutti gli alimenti consumati nella giornata. Una comune tecnica del-l’intervista sulle 24 ore precedenti prevede che le domande sul consumoinizino dalla prima cosa consumata al risveglio mattutino e ultima cosa con-sumata prima di andare a letto. L’intervista può essere condotta di persona, o telefonicamente. Idealmentel’intervistatrice dovrebbe essere una dietista o nutrizionista con una buona co-noscenza degli alimenti e della nutrizione; comunque anche non-nutrizionistiche sono stati formati per utilizzare uno strumento standardizzato possonoandar bene. Tutti gli intervistatori devono avere una buona conoscenza deglialimenti presenti sul mercato e dei diversi metodi di preparazione degli ali-menti includendo piatti regionali e alimenti etnici.Vantaggi di questo metodo di indagine alimentare:• non richiede un certo grado di scolarità dal momento che è un operatore che
somministra l’intervista 
• il grado di partecipazione è alto• non si alterano le abitudini alimentari in quanto l’intervista viene sommini-
strata dopo che la persona ha già consumato gli alimenti.
• due o più giorni forniscono dati sulla variabilità intra e inter-individuale• la ripetizione dell’intervista nell’anno può fornire dati attendibili sull’ali-
mentazione usuale di gruppi di popolazione, anche per alimenti non frequen-temente consumati o per tenere conto della stagionalità
Poco costoso e richiede un tempo di somministrazione non elevato (circa 30minuti). Ci sono dei software che permettono una codifica immediata deglialimenti durante l’intervista e quindi i costi di gestione dei dati raccolti sonoridotti e c’è una standardizzazione delle interviste. Questi sistemi variano sianel numero di alimenti presenti nel database che nel modo in cui viene chiestala porzione. Ad esempio l’Istituto per la Ricerca sul Cancro Americano (Na-tional Cancer Institute) ha sviluppato un’intervista delle 24 autosomministratavia internet.Limiti di questo metodo di indagine alimentare:- un solo ricordo delle 24 ore è poco rappresentativo del consumo abituale di
un soggetto data la variabilità giorno per giorno della dieta. Inoltre un solo24 ore non può essere usato per stimare la proporzione di una popolazione
183Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#184,184,"che abbia o meno una dieta adeguata (per esempio la proporzione di indivi-
dui che consumano meno del 30% di energia da grassi o che sono carenti invitamina C) 
- anche se diverse interviste delle 24 ore sono somministrate ad una singola
persona, è impossibile misurare alimenti consumati raramente come ad es.il fegato
- richiede buona memoria - i consumi fuori casa sono meno accurati- sottostima dei consumi di alcool e di altri alimenti considerati poco salutari- la validità può diminuire con l’aumentare dei giorni
Questo strumento è indicato per 
• stimare il consumo medio di campioni consistenti di popolazione, non indi-
cato per piccoli gruppi o singoli individui 
• confrontare il consumo ottenuto da metodiche più sofisticate e meno agili• verificare l’efficacia di un programma di intervento che prevede il confronto
con un gruppo di controllo
Anche per quanto riguarda il ricordo delle 24 ore, come per il diario, la sotto-stima è un grosso problema. Studi che hanno utilizzato marcatori biologicihanno evidenziato come l’intervista delle 24 ore sottostimi l’energia in un in-tervallo dal 3 al 26 % rispetto alla misurazione con l’acqua marcata e le pro-teine dall’11 al 28% rispetto alla misurazione con azoto urinario. 
9.4 Il questionario di frequenza degli alimenti
Questo strumento valuta la frequenza di consumo di determinati alimenti, ri-
ferita ad un determinato periodo di tempo. Il questionario consiste nella regi-strazione degli alimenti per frequenza di assunzione e mediante analisiquantitativa nel caso contengano foto o riferimenti a porzioni standard. Ov-viamente pochi dettagli sulle caratteristiche degli alimenti consumati vengonoraccolti come ad esempio il tipo di cottura o la combinazione di alimenti du-rante il pasto. L’intervallo di tempo a cui si riferisce il questionario può esserel’anno precedente o la settimana o il mese precedente. I questionari alimentari vengono utilizzati negli studi epidemiologici per met-tere in relazione la dieta con la prevalenza o incidenza di malattie cronico-de-generative (cancro, malattie cardiovascolari) in quanto valutano i consumi
184Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#185,185,"abituali, retrospettivi e relativi a lunghi periodi (anno, mese, etc.). 
La costruzione del questionario è estremamente importante, particolare atten-zione deve essere focalizzata sulla scelta degli alimenti e sulla tipologia di fre-quenza richiesta. Il questionario deve essere costruito, mediante un’opportuna analisi statistica,a partire da una base di dati rilevata con precisione su un campione simile aquello che si vuole studiare.Il questionario si compone di:• una lista di alimenti, scelti in base all’obiettivo della ricerca, con numerosità
adeguata, escludendo gli alimenti di scarso consumo al fine di rendere il que-stionario più gestibile e preciso. Gli alimenti nella lista devono essere con-sumati spesso e da un numero ragionevolmente grande di soggetti nellostudio, devono avere un contenuto sostanziale del nutriente o nutrienti og-getto dello studio ed il consumo di questi alimenti deve variare considere-volmente da un individuo all’altro per consentire di discriminare fra diversequantità consumate e/o modalità di assunzione. Di solito gli alimenti sonoraggruppati in categorie omogenee 
• una sezione con le risposte relative alle frequenze di consumo, nelle quali i
soggetti indicano quanto spesso un determinato alimento viene consumato.Le domande relative alla frequenza possono essere chiuse (prevedono unformato con risposte multiple, da 5 a 10, in relazione alla lista di alimenti,ad esempio: quanto spesso beve il latte? Mai, 1 volta al mese, 2-3 volte almese, 1 volta alla settimana ecc) oppure aperte (lasciano libertà di scelta al-l’intervistato, ad esempio quanto spesso beve il latte? 1,2,3 volte al giorno,alla settimana, al mese)
• informazioni sulla quantità di alimenti consumata possono non essere pre-
senti come ad esempio per i questionari di frequenza non quantitativi (in cuisi chiede ad esempio quante volte al giorno,/mese/anno mangia pane inte-grale o il gelato). Nei questionari di frequenza semi-quantitativi viene dataun’idea della porzione (quantificazione con unità standard vicino alla rispo-sta di frequenza ad esempio una fetta di pane) mentre nei questionari di fre-quenza quantitativi si prevede una quantificazione fatta dal soggettomediante unità standard e foto (si chiede al soggetto di descrivere la gran-dezza della sua porzione abituale come piccola, media o grande rispetto aduna porzione standard)
Vantaggi di questo metodo di indagine alimentare:• fornisce dati sui consumi alimentari abituali
185Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#186,186,"• non richiede una specifica preparazione dell’intervistatore
• può essere compilato direttamente dal soggetto in esame• non sono influenzati i consumi alimentari abituali• il tasso di risposta è alto• fornisce dati utilizzabili in epidemiologia nelle relazioni tra alimentazione e
malattie o fattori di rischio
• consente di raggruppare i soggetti esaminati in base ai consumi alimentari• poco costoso nella raccolta dei dati e nell’analisi 
Limiti di questo metodo di indagine alimentare:
• l’impegno richiesto al soggetto in esame dipende dalla numerosità e com-
plessità della lista di alimenti
• richiede buona memoria• molti dettagli dei consumi alimentari non vengono misurati • non è idoneo per segmenti di popolazione quali individui con consumi ali-
mentari atipici o non compresi nella lista
• i consumi possono essere misurati male quando più alimenti sono raggrup-
pati in una singola lista.
9.5 Strumenti brevi per valutare la dieta
Sono stati sviluppati diversi strumenti brevi per misurare la dieta che possono
essere molto utili quando si è interessati ad indagare un singolo aspetto delladieta e non la sua totalità. Questi strumenti sono molto utili ad esempio inquelle situazioni in cui l’obiettivo è la promozione della salute e l’educazionealla salute. Strumenti brevi per misurare ad esempio frutta e verdura sono uti-lizzati come strumenti di sorveglianza in studi di intervento sulla popolazione Questi strumenti possono essere mirati a misurare un singolo aspetto delladieta oppure degli specifici comportamenti (o pattern) alimentari. Di solito unquestionario di frequenza contiene 100 o più “food items” se si vuole indagareun singolo nutriente o un gruppo di alimenti 15-30 “food items” possono es-sere sufficienti.Sono stati sviluppati diversi strumenti orientati a misurare un singolo nutrientequali le proteine, il calcio, il ferro, i prodotti della soia o frutta e verdura. Ancheper i comportamenti alimentari sono stati sviluppati diversi questionari brevi.La brevità di questi strumenti creano un’allettante opzione per coloro che in-tendono misurare la dieta a basso costo. Sebbene abbiano molte applicazioni
186Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#187,187,"hanno anche diversi limiti. 
• Non misurano la dieta nel suo complesso• Le misure non sono quantitative e quindi una stima dell’introito dietetico
non si può fare
• Le stime non sono precise ed hanno un grande margine di errore
9.6 Storia dietetica
È un’intervista molto accurata che permette di valutare i consumi di alimentiin un periodo lungo e di avere informazioni sulle abitudini alimentari.Si procede in due fasi:• si definiscono le abitudini alimentari• si definiscono i consumi dei singoli alimenti. 
Viene discusso ogni pasto, considerando tutte le alternative settimanali e sta-
gionali. Le porzioni sono quantificate con foto e modelli.L’intervista prevede tutta una serie di domande circa il numero di pasti algiorno, l’appetito, la digestione, l’alvo, la storia ponderale, le allergie ed in-tolleranze alimentari, le interazioni farmaco-nutrizionali, la storia dieteticapregressa, l’attività fisica, la presenza di complicanze specifiche della malattiasuscettibili di trattamento dietetico e il supporto psico-sociale. Poi la sommi-nistrazione di un intervista sul consumo delle 24 ore precedenti circa le abitu-dini alimentari durante e tra i pasti ed infine la somministrazione di un diariodei 3 giorni che serve per aggiungere ulteriori informazioni all’intervista. Vantaggi di questo metodo di indagine alimentare:• fornisce un quadro abbastanza completo della dieta abituale• è utile negli studi epidemiologici su malattie che si sviluppano lentamente
negli anni
• non richiede un particolare livello di istruzione per i soggetti in esame• fornisce informazioni sia sulle abitudini alimentari che sul consumo di par-
ticolari alimenti
• può ben correlare con le misurazioni biochimiche
Limiti di questo metodo di indagine alimentare:
• richiede un buon addestramento dell’intervistatore• richiede una buona cooperazione dell’intervistato• è difficile riportare alla memoria, in modo accurato, il periodo da esaminare• richiede un grande impegno sia per l’intervistatore che per l’intervistato
187Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#188,188,"• richiede un tempo lungo di intervista
• sovrastima il consumo di nutrienti• il ricordo dell’alimentazione del passato può essere influenzato dalla dieta
presente
9.7 Elaborazione dei dati
La dieta rilevata in un’indagine alimentare può essere analizzata in termini di
comportamenti alimentari (Modelli alimentari), consumo di alimenti o introitodi nutrienti o combinazione di alimenti e nutrienti. • I modelli alimentari possono essere definiti a priori (cioè costruiti a partire
da alimenti e /o nutrienti importanti per la salute o specifici di un determinatocontesto culturale, che vengono quantificati e sommati per fornire una misuraglobale della qualità alimentare. Esempi: Indice Mediterraneo, Healthy Eating Index, DASH Index) oppurea posteriori (cioè vengono costituiti da modelli statistici a partire dai dati diconsumo. Esempi: pattern alimentare occidentale “Western” oppure patternVegetariano).
• Gli alimenti o i gruppi di alimenti vengono valutati in termini di frequenza
e/o quantità consumata
• I nutrienti possono essere valutati in termini di energia, macro- e micronu-
trienti e sono generalmente ricavati da tabelle di composizione degli alimentiLa traduzione in energia e nutrienti viene effettuata mediante l’uso di tabelledi composizione degli alimenti possibilmente nazionali. Le tabelle si riferi-scono per la maggior parte ad alimenti a crudo, per tale ragione il valore dialcuni nutrienti, in particolare quello delle vitamine, può non rispecchiarel’effettivo contenuto negli alimenti consumati dopo cottura. Le tabelle dicomposizione utilizzate per la traduzione in principi nutritivi sono determi-nanti agli effetti della validità dei risultati. In base alle esigenze e allo scopodello studio, devono essere revisionate, ampliate con la composizione deglialimenti locali e completate per tutte le voci necessarie ai fini dell’inchiestastessa. Ciò può essere fatto sia utilizzando valori ricavati da tabelle di altriPaesi con precisi criteri, sia campionando localmente e analizzando gli ali-menti di cui non si conosce la composizione. 
La scelta varia in funzione dello scopo che ci si propone. Ad esempio l’analisidi un’associazione tra l’alimentazione e una patologia prevede un’analisi della
188Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#189,189,"dieta sia in termini di nutrienti che di alimenti. In alcuni casi lo studio dell’as-
sociazione tra il consumo di un alimento ed una patologia può portare all’iden-tificazione di un nutriente potenzialmente responsabile. Ad esempio studiepidemiologici hanno evidenziato un’associazione protettiva tra il consumodi frutta gialla e verdure gialle e verdi nei confronti del tumore del polmone eda qui nacque l’ipotesi che il beta carotene potesse avere un effetto protettivosull’insorgenza di questa forma tumorale.Inoltre, i nutrienti possono poi essere confrontati con i relativi fabbisogni digruppi o individuali per valutare l’adeguatezza della dieta o di particolari nu-trienti. Accertata l’adeguatezza dei consumi si può desumere se la popolazionestudiata è esposta o meno al rischio di carenze o eccessi alimentari con riferi-mento a particolari nutrienti.
189Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#19,19,"Vitamine liposolubili 
La Vitamina D o calciferolo negli animali e nelle piante è presente come pro-
vitamina D, che si converte nella forma attiva mediante esposizione ai raggi
ultravioletti. La provitamina, il 7-deidrocoletserolo, negli animali, uomo com-preso, si converte in colecalciferolo o vitamina D3. Nelle piante, la provita-mina è l’ergosterolo, che si converte, con il sole, in ergocalciferolo o vitaminaD2. La vitamina D si trova nell’olio di fegato di merluzzo, nello sgombro, sal-mone, trote, sardine, aringhe, nel latte di mucca e capra, nel tuorlo d’uovo, nelfegato di pollo, nelle frattaglie in genere, in latte e derivati, nel germe di grano.La forma attiva della vitamina D ha la funzione, come ormone, di controllarel’omeostasi di calcio e fosforo. L’assorbimento a livello intestinale è indipen-dente dalla vitamina D se la dieta è ricca di calcio, ma il meccanismo si attivase si ingerisce poco calcio. La forma metabolicamente attiva è l’1,25-(OH)
2-colecalciferolo che agisce fa-
vorendo l’assorbimento del calcio a livello intestinale, il riassorbimento di cal-cio e fosforo nel tubulo contorto prossimale; la deposizione di calcio a livellodel tessuto osseo. Agisce all’interno del sistema paratormone (PTH) – calci-tonina in modo sinergico con il PTH o ormone paratiroideo con conseguenteomeostasi del sistema calcio – fosforo per una corretta mineralizzazione delloscheletro. La maggior parte della vitamina D viene sintetizzata dall’organismo,per azione del sole, soprattutto nei mesi estivi. In genere, la normale esposi-zione ai raggi del sole è sufficiente a coprire il fabbisogno di vitamina D negliadulti, sono sufficienti 10 minuti. Una integrazione è prevista in fase di accre-scimento, gravidanza e allattamento, quando il fabbisogno aumenta. Gli an-ziani in particolar modo sono a rischio di carenza di vitamina D, sia per lamancanza di esposizione alla luce solare, sia per la diminuita capacità di sintesiendogena, per cui si tende ad utilizzare specifici integratori alimentari, utili acoprirne i fabbisogni. Per l’adulto, il fabbisogno è pari a 10-15 μg/die, in re-lazione alla maggiore o minore sintesi endogena. Una sua carenza determinaun inadeguato assorbimento del calcio, provoca ritenzione di fosforo nei reni,demineralizzazione ossea con rachitismo nei bambini, osteomalacia negliadulti, osteoporosi, tensione nervosa, insonnia. Un eccesso di vitamina D, in-vece, può causare calcificazioni diffuse negli organi, contrazioni e spasmi mu-scolari, vomito, diarrea.LaVitamina K è presente in due forme, K1 o fillochinone e K2 o menachi-
none. La prima, di origine vegetale è contenuta in particolare nelle verdure afoglie verdi (crucifere), nel kelp, nel fegato, nel tè verde e costituisce la forma
19Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#190,190,"Bibliografia
• Ammerman AS, Haines PS, DeVellis RF, Strogatz DS et al. 1991. “A brief dietary assess-
ment to guide cholesterol reduction in low-income individuals: design and validation.” J
Am Diet.Assoc. 91:1385-1390.
• Beaton GH. 1994b. “Approaches to analysis of dietary data: relationship between planned
analyses and choice of methodology.” Am J Clin Nutr . 59:253S-261S.
• Black AE, Bingham SA, Johansson G, and Coward WA. 1997. “Validation of dietary intakes
of protein and energy against 24 hour urinary N and DLW energy expenditure in middle-
aged women, retired men and post-obese subjects: comparisons with validation against pre-sumed energy requirements.” Eur J Clin Nutr . 51:405-413.
• Block G, Hartman AM, Dresser CM, Carroll MD et al. 1986a. “A data-based approach to
diet questionnaire design and testing.” Am J Epidemiol. 124:453-469.
• Buzzard IM, Faucett CL, Jeffery RW, McBane L et al. 1996. “Monitoring dietary change
in a low-fat diet intervention study: advantages of using 24-hour dietary recalls vs foodrecords.” J Am Diet.Assoc. 96:574-579.
• Byers T, Marshall J, Fiedler R, Zielezny M, and Graham S. 1985. “Assessing nutrient intake
with an abbreviated dietary interview.” Am J Epidemiol. 122:41-50.
• Casey PH, Goolsby SL, Lensing SY , Perloff BP, and Bogle ML. 1999. “The use of telephone
interview methodology to obtain 24-hour dietary recalls.” J Am Diet.Assoc. 99:1406-1411.
• Coates RJ, Serdula MK, Byers T, Mokdad A et al. 1995. “A brief, telephone-administered
food frequency questionnaire can be useful for surveillance of dietary fat intakes.” J Nutr.
125:1473-1483.
• Eck LH, Klesges LM, and Klesges RC. 1996. “Precision and estimated accuracy of two
short-term food frequency questionnaires compared with recalls and records.” J Clin Epi-
demiol. 49:1195-1200.
• Field AE, Colditz GA, Fox MK, Byers T et al. 1998. “Comparison of 4 questionnaires for
assessment of fruit and vegetable intake.” Am J Public Health . 88:1216-1218.
• Gersovitz M, Madden JP, and Smiciklas-Wright H. 1978b. “Validity of the 24-hr. dietary
recall and seven-day record for group comparisons.” J Am Diet.Assoc. 73:48-55.
• Gersovitz M, Madden JP, and Smiciklas-Wright H. 1978a. “Validity of the 24-hr. dietary
recall and seven-day record for group comparisons.” J Am Diet.Assoc. 73:48-55.
• Gibson,R. 2005. Principles of Nutritional Assessment. Oxford University Press. New York.
• Goris AH, Westerterp-Plantenga MS, and Westerterp KR. 2000. “Undereating and under-
recording of habitual food intake in obese men: selective underreporting of fat intake.” Am
J Clin Nutr . 71:130-134.
• Green JH, Booth CL, and Bunning RL. 2002. “Assessment of a rapid method for assessing
adequacy of calcium intake.” Asia Pac.J Clin Nutr . 11:147-150.
• Hammond J, Nelson M, Chinn S, and Rona RJ. 1993. “Validation of a food frequency ques-
tionnaire for assessing dietary intake in a study of coronary heart disease risk factors inchildren.” Eur J Clin Nutr . 47:242-250.
• Hertzler AA and McAnge TR, Jr. 1986. “Development of an iron checklist to guide food
intake.” J Am Diet.Assoc. 86:782-786.
• Hill RJ and Davies PS. 2001. “The validity of self-reported energy intake as determined
using the doubly labelled water technique.” Br.J Nutr. 85:415-430.
190Fondamenti della Scienza dell’Alimentazione Capitolo IX"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#191,191,"• Kirk P, Patterson RE, and Lampe J. 1999. “Development of a soy food frequency question-
naire to estimate isoflavone consumption in US adults.” J Am Diet.Assoc. 99:558-563.
• Kohlmeier L, Mendez M, McDuffie J, and Miller M. 1997. “Computer-assisted self-inter-
viewing: a multimedia approach to dietary assessment.” Am J Clin Nutr. 65:1275S-1281S.
• Kushi LH. 1994. “Gaps in epidemiologic research methods: design considerations for stud-
ies that use food-frequency questionnaires.” Am J Clin Nutr . 59:180S-184S.
• Lillegaard IT, Loken EB, and Andersen LF. 2007. “Relative validation of a pre-coded food
diary among children, under-reporting varies with reporting day and time of the day.” Eur
J Clin Nutr . 61:61-68.
• Little P, Barnett J, Margetts B, Kinmonth AL et al. 1999. “The validity of dietary assessment
in general practice.” J Epidemiol.Community Health . 53:165-172.
• Maurer J, Taren DL, Teixeira PJ, Thomson CA et al. 2006. “The psychosocial and behavioral
characteristics related to energy misreporting.” Nutr Rev. 64:53-66.
• McDonald A, Van HL, Slattery M, Hilner J et al. 1991. “The CARDIA dietary history: de-
velopment, implementation, and evaluation.” J Am Diet.Assoc. 91:1104-1112.
• Morin P, Herrmann F, Ammann P, Uebelhart B, and Rizzoli R. 2005. “A rapid self-admin-
istered food frequency questionnaire for the evaluation of dietary protein intake.” Clin Nutr.
24:768-774.
• Pickle LW and Hartman AM. 1985. “Indicator foods for vitamin A assessment.” Nutr Can-
cer. 7:3-23.
• Probst YC and Tapsell LC. 2005. “Overview of computerized dietary assessment programs
for research and practice in nutrition education.” J Nutr Educ.Behav. 37:20-26.
• Rebro SM, Patterson RE, Kristal AR, and Cheney CL. 1998b. “The effect of keeping food
records on eating patterns.” J Am Diet.Assoc. 98:1163-1165.
• Rebro SM, Patterson RE, Kristal AR, and Cheney CL. 1998a. “The effect of keeping food
records on eating patterns.” J Am Diet.Assoc. 98:1163-1165.
• Rimm EB, Giovannucci EL, Stampfer MJ, Colditz GA et al. 1992. “Reproducibility and
validity of an expanded self-administered semiquantitative food frequency questionnaire
among male health professionals.” Am J Epidemiol. 135:1114-1126.
• Rothenberg E. 1994. “Validation of the food frequency questionnaire with the 4-day record
method and analysis of 24-h urinary nitrogen.” Eur J Clin Nutr . 48:725-735.
• Sawaya AL, Tucker K, Tsay R, Willett W et al. 1996. “Evaluation of four methods for de-
termining energy intake in young and older women: comparison with doubly labeled watermeasurements of total energy expenditure.” Am J Clin Nutr . 63:491-499.
• Seale JL. 2002. “Predicting total energy expenditure from self-reported dietary records and
physical characteristics in adult and elderly men and women.” Am J Clin Nutr. 76:529-534.
• Sempos CT, Liu K, and Ernst ND. 1999. “Food and nutrient exposures: what to consider
when evaluating epidemiologic evidence.” Am J Clin Nutr . 69:1330S-1338S.
• Slimani N, Bingham S, Runswick S, Ferrari P et al. 2003. “Group level validation of protein
intakes estimated by 24-hour diet recall and dietary questionnaires against 24-hour urinarynitrogen in the European Prospective Investigation into Cancer and Nutrition (EPIC) cali-bration study.” Cancer Epidemiol.Biomarkers Prev. 12:784-795.
• Subar AF, Kipnis V , Troiano RP, Midthune D et al. 2003a. “Using intake biomarkers to
evaluate the extent of dietary misreporting in a large sample of adults: the OPEN study.”Am J Epidemiol. 158:1-13.
191Capitolo IX Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#192,192,"• Subar AF, Thompson FE, Potischman N, Forsyth BH et al. 2007. “Formative research of a
quick list for an automated self-administered 24-hour dietary recall.” J Am Diet.Assoc.
107:1002-1007.
• Thompson FE, Midthune D, Subar AF, McNeel T et al. 2005. “Dietary intake estimates in
the National Health Interview Survey, 2000: methodology, results, and interpretation.” J
Am Diet.Assoc. 105:352-363.
• Trabulsi J and Schoeller DA. 2001a. “Evaluation of dietary assessment instruments against
doubly labeled water, a biomarker of habitual energy intake.” Am J Physiol
Endocrinol.Metab . 281:E891-E899.
• Vuckovic N, Ritenbaugh C, Taren DL, and Tobar M. 2000. “A qualitative study of partici-
pants’ experiences with dietary assessment.” J Am Diet.Assoc. 100:1023-1028.
• Zulkifli SN and Yu SM. 1992. “The food frequency method for dietary assessment.” J Am
Diet.Assoc. 92:681-685.
192"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#193,193,193Capitolo X Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#194,194,"CAPITOLO X
I LARN e le Linee Guida
Riassunto. I Livelli di Riferimento di Energia e Nutrienti (LARN) per la po-
polazione italiana e le Linee Guida per una sana alimentazione italiana sono
i più moderni ed efficaci strumenti di politica alimentare in Italia. Sono duedocumenti di consenso che rappresentano la posizione condivisa del mondodella scienza in tutte le sue accezioni, Accademia, Enti di Ricerca, SocietàScientifiche che operano nel campo degli alimenti e della nutrizione. I LARNsi riferiscono agli apporti raccomandati di energia e nutrienti in funzione dellastima dei relativi bisogni a livelli di sicurezza, tenendo conto di specifiche con-dizioni di età, sesso, ecc. La stesura dei LARN si basa sul concetto di adegua-tezza nutrizionale della dieta. Una dieta adeguata deve essere in grado di (i)prevenire carenze nutrizionali; (ii) consentire di avere adeguate riserve cor-poree dei nutrienti; (iii) mantenere le funzioni dell’organismo umano a livelliottimali; (iv) prevenire la insorgenza della patologie a componente nutrizio-nale. Le Linee Guida si propongono la tutela della salute in situazioni in cuifattori socio-economici abbiano determinato sovrabbondanza di risorse e con-seguenti effetti sulla salute dell’uomo. I due strumenti sono correlati: le LineeGuida che traducono in indicazioni pratiche come soddisfare i fabbisogni nu-trizionali fissati dai LARN.
194Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#195,195,"10.1 Premessa
Le raccomandazioni nutrizionali in Italia i LARN (SINU, 2012 in corso di
stampa) – sono il documento di consenso che fissa i valori di energia e nutrientinecessari ogni giorno per mantenere una salute ottimale e avere normali funzionifisiologiche. La traduzione delle raccomandazioni nutrizionali in indicazionidietetiche specifiche viene fatta attraverso le Linee Guida per una Sana Alimen-tazione Italiana (INRAN, 2003) che sono lo strumento di politica alimentare delPaese; le Linee Guida declinano le raccomandazioni nutrizionali in termini distile dietetico in grado di promuovere la salute. Questo percorso, raccomanda-zioni nutrizionali e strumenti di educazione alimentare per la loro messa in pra-tica, è quello che viene fatto in tutti i Paesi con la produzione della cosiddetteFood-based dietary guidelines stilate in maniera compatibile con la efficacia
territoriale e le tradizioni enogastronomiche delle varie aree geografiche.
10.2 Adeguatezza nutrizionale della dieta
Il concetto di adeguatezza della dieta si è evoluto nel corso degli anni. Tradi-
zionalmente una dieta adeguata corrispondeva ad una assunzione dietetica taleper cui la qualità e la quantità degli alimenti consumati era tale da assicurareil soddisfacimento dei bisogni di energia e nutrienti; poi sempre di più neltempo ha acquisito valore il rispetto delle combinazioni e proporzioni tramacro- e micro-nutrienti tali da non arrecare rischi potenziali per la salute. Inquesta ottica quindi, per copertura dei fabbisogni si deve considerare quantoè necessario in termini:• Biologici, per il soddisfacimento dei bisogni di energia e nutrienti• Epidemiologici per preservare da malattie legate ad errata e squilibrata ali-
mentazione
• Ecologici, per le caratteristiche ambientali dei singoli sistemi e siti di pro-
duzione agro-alimentare.
Mutuando il glossario della Federazione delle Società Italiane di Nutrizione(FeSIN, 2010), una alimentazione “sana” deve essere tale da:• Coprire i nostri fabbisogni di energia e di nutrienti essenziali.• Fornirci di sostanze protettive.• Minimizzare la nostra esposizione a contaminanti chimici e microbiologici
presenti negli alimenti.
195Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#196,196,"• Avere un impatto ambientale il più basso possibile cioè essere sostenibile.
Fabbisogno nutrizionale e adeguatezza delle dieta si sono dunque evoluti nel
tempo. Alla sicurezza nutrizionale ( food security ) si è via via aggiunto il focus
sulla sicurezza alimentare ( food safety ) oggi sempre di più declinato anche
come sostenibilità del sistemi agro-alimentari. Sostenibilità non solo ambien-tale ma anche economica e sociale.
10.3 I livelli di assunzione di riferimento di nutrienti e energia per la po-
polazione italiana
I LARN sono il documento di consenso che fissa i valori di riferimento per
energia e nutrienti per la popolazione italiana. I dati sono presentati per gruppidi popolazione omogenea, per fasce di età, sesso, stato fisiologico (es gravi-danza, allattamento). Come riportato nella revisione del 1996 (SINU, 1996),i LARN mirano essenzialmente a:• Proteggere l’intera popolazione dal rischio di carenze nutrizionali:• Fornire elementi utili per valutare l’adeguatezza nutrizionale della dieta
media della popolazione o di gruppi di essa rispetto ai valori proposti;
• Pianificare la politica degli approvvigionamenti alimentari nazionali, nonché
la alimentazione di comunità.
Diverse altre applicazioni delle raccomandazioni sono tuttavia possibili e sonostate finora realizzate, quale ad esempio quella della informazione ed educa-zione alimentare, quella della etichettatura nutrizionale dei prodotti alimentarie quella della formulazione di supplementi e alimenti dietetici. Va comunquechiarito che le quantità raccomandate anche se si riferiscono a valori per per-sona per giorno, non debbono essere necessariamente assunte ogni giorno, marappresentano una media dei consumi per un certo periodo di tempo. E’ inoltrebene sottolineare che le raccomandazioni si riferiscono ad individui in buonasalute e non possono essere applicate a soggetti con necessità specifiche deri-vanti da malattie, particolari terapie o diete speciali.Nella revisione 2012 (SINU, in corso di stampa) dei LARN si è stressato dipiù il concetto di valore di riferimento più che di raccomandazione nutrizio-nale. Pur confermando quanto detto sopra sulla raccomandazione, il concettodi valore di riferimento amplia e completa la raccomandazione che diventaquindi più articolata con una serie di ulteriori riferimenti utili a una migliore
196Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#197,197,"definizione degli apporti di nutrienti in grado di soddisfare i fabbisogni indi-
viduali e di gruppo.La definizione della raccomandazione si basa sulla definizione del fabbisogno.Nella revisione ’96 dei LARN (SINU, 1996) si individuavano 3 differenti li-velli di raccomandazione sulla base della distribuzione di frequenza dei fab-bisogni individuali di una popolazione o in un gruppo di popolazione: quellominimo al disotto del quale è praticamente impossibile mantenere l’integritàmetabolica per la maggior parte della popolazione; quello medio, che copre ilfabbisogno del 50% degli individui della popolazione e quello cosiddetto diriferimento per la popolazione, corrispondente al fabbisogno medio più duedeviazioni standard, in grado cioè di coprire i bisogni della maggior parte dellapopolazione. Naturalmente quanto maggior sarà la variazione nel fabbisognoindividuale del singolo nutriente, tanto più ampio deve essere il margine di si-curezza.Tutti questi concetti restano validi e vengono declinati nella revisione 2012con gli acronimi mutuati dalla lingua inglese e definiti dall’EFSA (2010).Nello specifico:•PRI (Population Reference Intake ) che è il livello di assunzione del nutriente
sufficiente a soddisfare il fabbisogno di quasi tutti (97,5%) i soggetti sani inuno specifico gruppo di popolazione.
Oltre al PRI, si indicano:• Il fabbisogno medio AR(Average Requirement) che è il livello di assunzione
del nutriente sufficiente a soddisfare il fabbisogno del 50% dei soggetti saniin uno specifico gruppo di popolazione.
Quando non si hanno sufficienti dati per calcolare il PRI e all’AR (ad esempionei bambini molto piccoli, ad es. al disotto dell’anno di età, oppure per alcuniminerali) si utilizza:• l’assunzione adeguata AI(Adequate Intake ) che si ricava dagli apporti medi
osservati in una popolazione esente da carenze manifeste.
E’ oramai concetto consolidato che per alcuni nutrienti, oltre al rischio di ca-renza può esserci un rischio di assunzione eccessiva con la dieta. Bisognaquindi stabilire un intervallo di sicurezza nell’ambito del quale è minimo sia ilrischio di eccesso che il rischio di inadeguatezza (INRAN, 2003). In questoquadro vale la pena ricordare l’approccio particolare che viene usato per l’ener-gia. Nel caso dell’energia il rischio per la salute aumenta anche se l’apporto
197Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#198,198,"giornaliero si discosta di pochissimo in eccesso (obesità) o in difetto (malnu-
trizione). Per l’energia quindi si definisce solo il fabbisogno medio, senza sta-
bilire il un apporto raccomandato che copra le due deviazioni standard dellapopolazione. Nel caso invece degli altri nutrienti, viene usato un approccio con-servativo di copertura del 97,5% (media più due deviazioni standard) di popo-lazione perché i rischi per la salute sono maggiormente legati ad una carenzache non ad un eccesso e questa copertura ampia consente di assicurare un mar-gine di sicurezza.Per lipidi e carboidrati si è provveduto a definire:• gli intervalli di riferimento per l’assunzione di macronutrienti ( Reference In-
take range for macronutrients, RI) con valori minimi e massimi espressi in
percentuale sull’energia totale della dieta.
In aggiunta, la necessità di incorporare nel documento l’evidenza scientificasulle relazioni fra stato di nutrizione e prevenzione delle patologie cronico-degenerative, al di la della semplice soddisfazione del ruolo biologico dei nu-trienti, ha portato in qualche caso, ad esempio acidi grassi saturi o gli zuccheri,all’introduzione di:• obiettivi nutrizionali per la prevenzione ( Suggested Dietary Target, SDT)
nonché di raccomandazioni qualitative sulle scelte fra diverse fonti alimen-tari.
Per completare il discorso dei macronutrienti vale la pena sottolineare che leproteine sono l’unico macronutriente che si comporta come un micronutriente;infatti per le proteine abbiamo un PRI a copertura di sicurezza di una ampiafascia di popolazione (97,5%). Inoltre in molti casi si è indicato anche:• il limite massimo tollerabile di assunzione ( tollerable Upper intake Level,
UL) che rappresenta l’apporto più elevato del nutriente che non si associa aeffetti avversi sulla salute.
Gli UL utilizzati sono quelli definiti a livello europeo dalla commissione SCF-EFSA (2006, 2012).La ragione della introduzione degli STD nella revisione 2012 dei LARN ha lasua ragion d’essere in relazione ai tanti dati che stanno emergendo nella lette-ratura internazionale sul ruolo preventivo di alcuni nutrienti. Infatti i fabbiso-gni individuali di nutrienti ed energia si possono definire sulla base dellemanifestazioni cliniche da carenza, del mantenimento sia delle riserve del nu-triente nell’organismo sia delle funzioni biochimico-fisiologiche (in presenza
198Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#199,199,"di una adeguata composizione corporea), e anche in relazione alla prevenzione
nutrizionale delle malattie e alle relazioni tra dieta e morbosità e mortalità. Laletterature degli ultimi anni, in particolare, sembra indicare il ruolo di diversinutrienti nella riduzione del rischio per patologie cronico-degenerative che vaoltre i loro effetti biologici e nutrizionali in senso stretto. Di fatto è in genereproblematico, se non impossibile, elaborare una precisa raccomandazionequantitativa rivolta alla prevenzione nutrizionale delle malattie cronico-dege-nerative, poiché il rischio di malattia risente fortemente di altri fattori legatialla dieta, come la presenza sinergica di più nutrienti e sostanze non-nutritivenegli alimenti e delle diverse abitudini alimentari in grado di oscurare l’even-tuale ruolo preventivo dello specifico nutriente. Inoltre, non sono in generedisponibili sufficienti dati dose-risposta che permettano l’identificazione diun valore soglia efficace in termini preventivi. Proprio per prendere in consi-derazione gli aspetti nutrizionali più propriamente preventivi, sono stati uti-lizzati gli RI per lipidi e carboidrati e gli STD per acidi grassi e zuccheri.
10.4 Come si usano i LARN
I LARN possono essere utilizzati con diversi obiettivi di ricerca e pianifica-
zione nutrizionale a livello sia individuale sia di gruppo o comunità. Offronoinoltre una necessaria base di conoscenze nella definizione di politiche sani-tarie e commerciali, ad esempio nella messa a punto di linee guida, nell’eti-chettatura nutrizionale o nello sviluppo di nuovi alimenti e integratorialimentari. I LARN vengono quindi tradotti nelle Linee Guida per dare indi-cazioni pratiche alla popolazione per come soddisfare i propri fabbisogni dienergia e nutrienti e per come proteggere il proprio stato di salute.
10.5 L’evoluzione delle linee guida per una sana alimentazione
Le Linee Guida per una sana alimentazione Italiana sono una serie di consigli
e indicazioni nutrizionali, periodicamente aggiornate, elaborate da un’appositacommissione scientifica che raccoglie prestigiosi studiosi del mondo dell’ali-mentazione oltre che una nutrita rappresentanza della comunità scientifica.L’Ente pubblico Italiano che secondo la sua legge istitutiva (Legge n.258/63;Legge n.70/75; D.lgs 454/99) fin dalla sua costituzione nel 1963, ha il compitospecifico di promuovere la sana alimentazione anche attraverso la revisione
199Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#2,2,"Editore
AIBAAssociazione Italiana Biologia ApplicataVia Icilio, 7 - 00153 RomaTel. 06/57090200Fax 06/57090235www.onb.itE-mail:igiene.qualita.sicurezza.ONB@gmail.com
Consiglio
dell’Ordine Nazionale dei BiologiPresidente, Ermanno Calcatelli;Vice Presidente, Antonio Costantini;Tesoriere, Pietro Sapia;Segretario, Luciano O. Atzori;Consiglieri, Domenico L. Laurendi,Pietro Miraglia, Pierluigi Pecoraro,Franco Scicchitano, Gianni Zocchi.
A cura
Commissione Permanente di Studio “Nutri-zione” dell’Ordine Nazionale dei Biologi
Autori
Gianni ZocchiPierluigi PecoraroLaura RossiSabina SieriRossella TrioFrancesca TommasiMarisa CampanilePatrizia ZulianiPaolo PaoliFilippo CarlucciRoberto CiandagliaSilvio MorettiCopertinaXXX
Grafica e impaginazione
Fotolito Moggio srl
Ufficio Stampa e redazione
Luca Mennuni, Claudia TancioniOrdine Nazionale dei Biologi, RomaTel. 06/57090205 - Fax 06/57090234
Segreteria
Pina ComandèOrdine Nazionale dei Biologi, RomaTel. 06/57090204 - Fax 06/57090235e-mail: segreteria@onb.it
Stampa e rilegatura
Fotolito Moggio srl
Finito di stampare nel mese di maggio 2015©copyright 2015 AIBA tutti i diritti sono ri-
servati
L’editore non si assume nessuna responsabi-
lità sui contenuti e sulle opinioni espresse
dagli autori dei testi.
2"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#20,20,"più presente nella dieta. La seconda, può essere di origine batterica, cioè sin-
tetizzata dai batteri simbionti normalmente presenti nella flora intestinale eu-biotica; o di origine alimentare, le cui fonti sono pollo, tuorlo d’uovo, prodottilattiero-caseari, fegato bovino. Il corretto assorbimento viene favorito dai grassi, in condizioni di normalefunzionalità biliare e pancreatica. Successivamente solo la vitamina K1 ver-rebbe inserita nei chilomicroni, poi nelle VLDL e LDL, per essere infine ce-duta ai tessuti. I menachinoni sarebbero riassorbiti nel colon.La forma attiva della vitamina K è il cofattore dell’enzima carbossilasi impor-tante per la cascata della coagulazione del sangue e interviene nella fissazionedel calcio. Una sua carenza porta a emorragie ed osteoporosi. Il fabbisogno dell’adulto è valutato intorno ai 1 μg per kg peso corporeo, cioècirca 60 μg al giorno, normalmente coperto dalla sintesi endogena a livello diflora intestinale.
Vitamine idrosolubili La Vitamine B12 è rappresentata da un gruppo di sostanze contenenti cobalto,
l´idrossicobalamina e la cianocobalamina. Tali sostanze sono coinvolte in
numerose reazioni biochimiche (metabolismo degli acidi grassi, degli ammi-
noacidi, degli acidi nucleici, del ferro). Una sua carenza, piuttosto rara, si ma-nifesta solo nei casi di dieta vegana, in particolare durante la gravidanza, conconseguenze per il nascituro di danni neurologici. La carenza può anche deri-vare dall’assenza del fattore intrinseco, secreto dalle cellule parietali del fondodello stomaco, che ne facilita l’assorbimento a livello intestinale, con conse-guenti disturbi a carico del sistema nervoso e della produzione delle celluledel sangue, fino a forme di anemia e neuropatie e, soprattutto nella terza età,di deterioramento delle capacità cognitive. Per tali ragioni si può consigliare l’integrazione di vitamina B12 anche neglianziani, con stati di carenza per dieta povera di alimenti di origine animale, acausa di cattiva masticazione. Fonti alimentari di tale vitamina, seppure in minime quantità, sono in partico-lare il fegato, la carne, il latte e derivati, le uova e il pesce. Gli alimenti vegetalinon ne contengono. E’ resistente alla cottura. Sono necessarie minime quantitàgiornaliere di vitamina B12, largamente coperta dalla dieta, pari a circa 2μg/die per l’adulto. La vitamina B12 viene immagazzinata nell’organismo,con un’emivita calcolata in 1-4 anni.Indicatori sensibili di diete carenti di vitamina B12 sono alti livelli di acido
20Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#200,200,"periodica delle Linee Guida è l’Istituto Nazionale della Nutrizione (INN) poi
diventato INRAN (Istituto Nazionale di Ricerca per gli Alimenti e la Nutri-zione) oggi CRA-NUT (Centro di Ricerca per gli Alimenti e la Nutrizione).La caratteristica delle Linee Guida è quella di essere un documento di con-senso, prodotto da una commissione multidisciplinare che si rivolge alla po-polazione generale in modo autorevole e scevro da interessi economici.Le Linee Guida sono uno strumento di politica alimentare in grado di tradurrele raccomandazioni nutrizionali in consigli diretti su come mangiare. Pratica-mente i LARN ci dicono di quanto ferro abbiamo bisogno o di quante proteine(ad esempio) e le Linee Guida ci dicono quanti e quali alimenti dobbiamo con-sumare per soddisfare i fabbisogni (di ferro, di proteine, ecc.) e per proteggerela nostra salute. In questa ottica infatti dobbiamo tenere presente che nel pas-sato sana alimentazione significava principalmente correggere le malattie dacarenza nutrizionale e quindi Linee Guida significava dare alla popolazionele indicazioni di quanta frutta mangiare perché non avesse lo scorbuto (carenzadi vitamina C). La scienza della alimentazione oggi chiede molto di più allanutrizione: oltre al soddisfacimento dei fabbisogni nutrizionali per non averecarenze oggi chiediamo alla sana alimentazione di proteggerci dalle malattiecronico-degenerative e garantirci salute e longevità. La nutrizione in otticamoderna è soprattutto prevenzione e le Linee Guida sono quindi uno strumentodi salute pubblica fondamentale nel quadro della politica alimentare di unPaese. Il raggiungimento dell’obiettivo, così importante, di un più correttocomportamento alimentare da parte del maggior numero possibile di italianipuò essere conseguito solo con una migliore informazione e con una miglioreconoscenza, basate su dati obbiettivi e scientificamente convalidati, da partedei consumatori.L’alimentazione sana ed equilibrata rappresenta oggi la maniera più efficacee alla portata di tutti per guadagnare salute, abbattere i costi legati alle più im-portanti patologie del nostro tempo, risparmiare anni di lavoro e di vita sanadi ognuno di noi. Mai come oggi, ove obesità e le malattie ad essa correlate(aterosclerosi, diabete, ipertensione e alcuni tipi di tumore) rappresentano uncosto altissimo in vite umane, in riduzione della qualità della vita, in ore lavo-rative perse e in spese sanitarie, si rendono improrogabili interventi mirati,forti e precisi di educazione alimentare nella popolazione che agiscano a piùlivelli e che siano capaci di orientare le politiche sanitarie verso un modellodi stile di vita virtuoso.Tali Linee Guida per una sana alimentazione sono costruite tutte sulla basedel modello alimentare mediterraneo, modello che ha ormai acquisito fama e
200Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#201,201,"onore del miglior modello attraverso il quale coniugare salute e piacere. Gli
alimenti a disposizione variano da Paese a Paese, così come le abitudini ali-mentari; molte sono quindi le possibilità per la realizzazione di una dieta sa-lutare nel quadro di uno stile di vita egualmente salutare. Ogni Paese declinai dettami della dieta mediterranea a seconda delle proprie possibilità di sceltealimentari e delle abitudini alimentari. Infatti gli alimenti di cui disponiamosono tantissimi, e molte sono anche le vie per realizzare una dieta salutare nelquadro di uno stile di vita egualmente salutare. Ognuno ha quindi ampia pos-sibilità di scelte.
10.6 Attualità e modernità delle linee guida per una sana alimentazione:
dalle carenze nutrizionali alla alimentazione come prevenzione.
In Italia la prima edizione delle “Linee Guida per una sana alimentazione” è
stata pubblicata dall’allora INN nel 1986; erano e sono tutt’ora dopo le varierevisioni, le uniche indicazioni istituzionalmente valide per indirizzare il cit-tadino ad un’alimentazione equilibrata. Per tale iniziativa, l’Istituto si è avvalsosia delle competenze interne, sia della collaborazione di numerosi rappresen-tanti della comunità scientifica nazionale. Nel 1997, a distanza quindi di 10anni dalla prima edizione è stata eseguita la prima revisione, cui è seguita unaseconda nel 2003. E’ in corso d’opera la revisione 2015 delle Linee Guida dicui possiamo anticipare qualche tematica.Dal 1997 al 2003 abbiamo avuto il primo ampliamento dei temi trattati, conl’inserimento di tre nuove Direttive destinate a rispondere all’esigenza di unamaggiore completezza rispetto ai problemi e alle domande che il consumatorecomune oggi si pone in tema di nutrizione. La prima delle tre “nuove” Diret-tive è quella che affronta la questione del bilancio idrico del nostro organismo,dei bisogni di acqua e delle funzioni che essa svolge, e anche delle numerosefalse credenze che circondano questo nutriente fondamentale. La seconda“nuova” Direttiva è quella che esamina problemi particolari dell’alimentazionedi alcuni gruppi di popolazione “speciali” in quanto caratterizzati da esigenzenutrizionali specifiche, e per questi motivi più “vulnerabili”. Si tratta di bam-bini, adolescenti, gestanti, nutrici, donne in menopausa, anziani, una quota dipopolazione, quest’ultima, in forte aumento. Sulle modalità di una corretta ali-mentazione di tutti questi soggetti esiste nella conoscenza comune una note-vole confusione di idee: da qui l’opportunità di parlarne in modoparticolareggiato nell’ambito delle Linee guida. La terza “nuova” Direttiva ri-
201Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#202,202,"guarda i problemi della sicurezza alimentare, con speciale riferimento a quella
domestica. Infatti, ferma restando la grande responsabilità delle Istituzionipubbliche nel formulare regole e prevedere controlli per tutta la filiera agro-alimentare (e la creazione di un Agenzia europea dedicata alla sicurezza ali-mentare ne è la prova), si è ritenuto utile e opportuno stimolare anche laresponsabilità e la partecipazione individuale, dal momento dell’acquisto deglialimenti alle fasi di preparazione e di conservazione degli stessi, poiché è pro-vato che gran parte degli incidenti e dei problemi di tipo igienico-sanitario siverificano proprio nella cucina di casa.In linea generale i concetti e le indicazioni presenti nelle Linee Guida del 2003sono tuttora valide, poiché le basi scientifiche che hanno portato alla loro for-mulazione continuano ad avere validità e anzi diventano ancora più valide allaluce delle ultime evidenze scientifiche, ma hanno bisogno di essere rivisitatealla luce delle mutate abitudini di vita degli italiani che sono ad esempio semprepiù sedentari, dello stato di salute, dei progressi delle conoscenze scientifiche,della disponibilità di nuovi prodotti che l’industria agroalimentare italiana haaffiancato ai prodotti tradizionali per migliorare ed aumentare la possibilitàdelle scelte del cittadino. La revisione del 2003 tenne concretamente conto dellaproblematica ancora attualissima per altro della sicurezza alimentare e dellaperdita del fiducia da parte dei consumatori nei confronti delle Autorità cheavrebbero dovuto garantirla. A fronte di minacce come la “mucca pazza” o l’in-fluenza aviaria o la più recente suina, e di una necessità da parte del consuma-tore di una informazione non “emotiva” ma autorevole, venne inclusa nellarevisione del 2003 la linee guida sulla sicurezza alimentare. E’ uno spazio cheverrà mantenuto e aggiornato anche nella revisione del 2015 delle linee guidaperché le tematiche sono ancora cogenti e perché c’è necessità di dare indica-zioni semplici e praticabili da parte della popolazione per garantire la sicurezzadei propri alimenti. Il consumatore italiano in particolare, gode oggi della di-sponibilità di una ampia gamma di prodotti dotati di ottime caratteristiche, tantoquelli della tradizione quanto quelli offerti da un settore produttivo agro-indu-striale che ha già dimostrato di volersi orientare in coerenza con le indicazionivia via fornite dalle precedenti Linee guida. È quindi fondamentale impararead usare gli alimenti disponibili nel modo più corretto, ed è proprio per questo,lo ribadiamo, che vengono predisposte le Linee guida. In questa ottica anche ilsettore della ristorazione collettiva può svolgere un ruolo di particolare impor-tanza, sia producendo e distribuendo pasti nel rispetto delle indicazioni delleLinee guida, sia diffondendo ai propri utenti una informazione alimentare coe-rente con i principi contenuti nelle stesse Direttive.
202Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#203,203,"Due dei temi caldi, imprescindibili per la revisione 2015 delle Linee Guida
saranno l’impatto ambientale dei consumi alimentari e il costo economico peril consumatore di una dieta sana. Queste tematiche verranno dunque affrontatenella revisione 2015 delle Linee Guida o in appositi capitoli su questi due temioppure affrontandoli a mano a mano che vengono dati consigli alimentari neldocumento. La povertà alimentare e le nuove fasce di popolazione vulnerabiliportano sempre di più gli operatori di salute pubblica a dare indicazioni chesiano anche commensurate alle possibilità economiche. Alcuni cibi possonoessere troppo costosi per larghe fette di popolazione; per contro ci sono mol-tissime scelte alimentari che sono sia salutari che affrontabili senza appesantireil bilancio familiare. Pane, cereali, riso, pasta e patate, vegetali e frutta di sta-gione o legumi, sono gli alimenti che dovrebbero costituire la base dell’ali-mentazione non sono particolarmente costosi. Riorganizzare le scelte edindirizzarle verso questi prodotti consente di guadagnare salute e risparmiaredenaro. La sostenibilità dei sistemi agroalimentari è un altro tema caldo cheverrà affrontato nelle revisione 2015 delle Linee Guida. Anche se attualmentec’è abbastanza cibo, la produzione di cibo sta creando problemi ambientali indiversi modi e la sostenibilità a lungo termine della produzione alimentare stadiventando un problema sempre più importante. Possiamo continuare a usarel’acqua e il suolo con il nostro modo abituale di produzione del cibo? La do-manda non è di stretta pertinenza nutrizionale ma è doveroso porsela e lenuove Linee Guida dovranno promuovere un modello non solamente sano maanche sostenibileAnche nella revisione 2015 continuerà l’aggiornamento e l’inserimento dinuove tabelle e dati su vari temi, compreso l’elenco di “porzioni standard ita-liane” la cui corretta valutazione da parte del singolo è di importanza fonda-mentale se si vuole riuscire a realizzare una buona alimentazione. Il capitolodelle “porzioni” è l’anello di congiungimento tra i LARN e le Linee Guida.Nei LARN vengono definite le porzioni per coprire i fabbisogni che nelleLinee Guida vengono declinate il rapporto dalla sana alimentazione. Il rag-giungimento dell’obiettivo, così importante, di un più corretto comportamentoalimentare da parte del maggior numero possibile di italiani può essere con-seguito solo con una migliore informazione e con una migliore conoscenza daparte dei consumatori. Il consumatore italiano, in particolare, gode oggi delladisponibilità di un’ampia gamma di prodotti dotati di ottime caratteristiche,tanto quelli della tradizione quanto quelli offerti da un settore produttivo agro-industriale che ha già dimostrato di volersi orientare in coerenza con le indi-cazioni via via fornite dalle precedenti Linee Guida. È quindi fondamentale
203Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#204,204,"imparare ad usare gli alimenti disponibili nel modo più corretto, ed è proprio
per questo che vengono predisposte le Linee guida. In questa ottica anche ilsettore della ristorazione collettiva può svolgere un ruolo di particolare im-portanza, sia producendo e distribuendo pasti nel rispetto delle indicazionidelle Linee guida, sia diffondendo ai propri utenti un’informazione alimentarecoerente con i principi contenuti nelle stesse Direttive.
10.7 Perché le revisioni periodiche delle Linee Guida?
La opportunità e la necessità di una periodica revisione delle Linee guida, pur
nel solco della continuità con le precedenti edizioni, sono facilmente spiega-bili. Il primo motivo è quello del necessario aggiornamento in base alla con-tinua evoluzione delle conoscenze scientifiche circa il ruolo dei singolinutrienti e di vari componenti minori e i relativi bisogni e rapporti reciprocinell’ambito di una dieta equilibrata. Il secondo motivo è certamente quello delmutamento dei consumi, delle abitudini e degli orientamenti alimentari e deglistili di vita, nel quadro di una società che dimostra sempre più attenzione allecorrelazioni fra alimentazione e salute, ma che contemporaneamente vede au-mentare sia le patologie legate ad una dieta abituale eccessiva e/o squilibratasia la confusione e la disinformazione circa ruoli e funzioni di alimenti e dinutrienti. E tutto ciò avviene nonostante l’impressionante crescita della massadi informazioni dirette al grande pubblico, veicolate da un sempre maggiornumero di canali, anche molto innovativi. Sono proprio questi motivi a rendereancora più pressante l’esigenza di mettere a disposizione del consumatore unostrumento, come le Linee guida, i cui contenuti siano approvati dalle istituzioniscientifiche, che sia aggiornato nei suoi contenuti ma anche sempre più fun-zionale rispetto ai tempi che cambiano, e che sia facilmente comprensibile eutilizzabile nonché capace di fornire, accanto a pratiche indicazioni anche in-formazioni di carattere più spiccatamente tecnico-scientifico.Gli alimenti di cui disponiamo sono tantissimi, e molte sono anche le vie perrealizzare una dieta salutare nel quadro di uno stile di vita egualmente salutare.Ognuno ha quindi ampia possibilità di scelte. Negli ultimi decenni Istituzionipubbliche e Organismi scientifici hanno dato vita, nei principali Paesi delmondo, a Linee guida o Direttive alimentari. E nella stessa direzione si sonomosse le principali Agenzie internazionali che si occupano di alimentazione esalute. Il motivo per il quale le Linee guida vengono compilate e diffuse inmilioni di copie è proprio quello di fornire al consumatore una serie di semplici
204Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#205,205,"informazioni alimentari del nostro Paese, proteggendo contemporaneamente
la propria salute. Per far questo sono chiamati a collaborare studiosi apparte-nenti a varie istituzioni scientifiche e accademiche italiane, in grado di affron-tare, con le loro differenti competenze, tutto l’arco delle varie problematicheriguardanti la nutrizione. Destinatario e ragion d’essere delle Linee Guida èquindi l’universo dei consumatori, al quale le Direttive sono indirizzate e dalquale devono poter essere agevolmente comprese e utilizzate, per realizzareun’alimentazione sana ed equilibrata, garantendosi più benessere e salute senzadover mortificare il gusto e il piacere della buona tavola. E tutto ciò evidente-mente è più facile per coloro che conservano abitudini alimentari tradizionalidel nostro Paese, vale a dire un uso frequente di cibi meno densi di energia epiù ricchi di sostanze utili.Proprio la esplosione di tanta informazione incontrollata rende ancora più pres-sante l’esigenza di mettere a disposizione del consumatore uno strumento,come le Linee guida, che sia garantito dalle istituzioni scientifiche, che sia ag-giornato nei suoi contenuti, ma anche sempre più funzionale rispetto ai tempiche cambiano, e che sia facilmente comprensibile e utilizzabile nonché capacedi fornire, accanto a pratiche indicazioni (riassunte particolarmente nei “comecomportarsi”, nelle “false credenze su…”, ecc.), anche informazioni di carat-tere più spiccatamente tecnico-scientifico. Le Linee Guida si rivolgono per-tanto sia a chi desidera avere semplici chiarimenti sugli aspetti-base dell’usodegli alimenti per la vita quotidiana, sia a chi si aspetta di trovare nelle nuoveLinee guida anche maggiori approfondimenti di tipo scientifico, senza esserecostretto a ricercarli consultando altre pubblicazioni. 
10.8 Le Linee Guida nei moderni strumenti di comunicazione
La declinazione delle linee guida in piattaforme informatiche moderne
(www.
SAPERMANGIARE .MOBI ) ha lo scopo di comunicare anche attraverso il
web le direttive della sana alimentazione e di un corretto stile di vita ai cittadiniitaliani. In questo caso il target di riferimento sono i più giovani (dai 14 ai 35anni), in quanto la fascia d’età più abituata all’uso di tecnologie di comunica-zione avanzate. Le dieci Linee Guida sono diventati dei filmati in cui una “fa-miglia normale” declina le indicazioni nutrizionali nella vita di tutti i giornianche con criticità ed errori con uno spirito leggero e non coercitivo. E’ in pro-grammazione il lancio di filmati brevi di un minuto e mezzo sulle tematichedelle Linee Guida che saranno lanciati in modo virale sui vari server con
205Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#206,206,"l’obiettivo di essere ripresi e ritrasmessi sulle varie piattaforme web, ad es
http://www.youtube.com. SAPERMANGIARE .MOBI è un servizio di tutoraggio
continuo nel tempo per il cittadino, ovvero quanto di più simile si possa im-maginare a un “assistente alimentare” che aiuti nel tempo l’utente a trovare ilsuoregime corretto. La piattaforma ha anche una raccolta organica delle
schede di approfondimento. Tra i servizi offerti basti ricordare: •ChiedoeMangio, un servizio di risposte brevi e secche alle domande più fre-quenti; 
•ContoeMangio, un servizio che, attraverso un software di facile utilizzo, per-mette di calcolare il contenuto in calorie e macronutrienti di un alimento(con la sua quantità), un piatto, una ricetta, un pasto o una dieta.
•SoBere?, un servizio per la determinazione personalizzata degli effetti del-l’alcool, che consente all’utente di calcolare gli effetti dell’alcool (fra i qualiquelli sulla guida) sulla base dei principali parametri che li influenzano(sesso, età, peso, distanza dall’ultimo pasto). La pagina del servizio proponeanche alcune schede di approfondimento sull’alcool nell’alimentazione.Questi servizi saranno accessibili anche via cellulare.
Nel solco della utilizzazione dei nuovi media, al sito istituzionale 
SAPERMAN -
GIARE .MOBI è legata una pagina facebook (https://www.facebook.com/saper-
mangiare.mobi?fref=ts) in cui oltre a pubblicizzare eventi e convegni sonoaperte discussioni sulle tematiche più calde emergenti dalla stampa. Ovvia-mente apertissimo è il canale della domanda/risposta dei frequentatori dellapagina, dietro cui c’è l’Istituzione e non i singoli.
10.9 Conclusioni
I LARN e le Linee Guida sono i due strumenti di politica alimentare che ven-
gono redatti e periodicamente aggiornati in Italia. Si basano entrambi sul con-cetto di fabbisogno nutrizionale e della sua evoluzione con la progressivaintroduzione dei concetti di sicurezza alimentare e sostenibilità ambientale,economica e sociale. LARN e Linee Guida sono documenti di consenso pre-parati da autorità pubbliche scevre da interessi commerciali che rappresentanonon solo l’Istituzione che li redige ma anche tutti i portatori di interesse nelcampo specifico di applicazione. I LARN sono un documento tecnico destinatia un pubblico di settore, sanitario, nutrizionistico in senso ampio, ministeriale,industrie e associazioni di produttori. Le Linee Guida sono destinate princi-
206Fondamenti della Scienza dell’Alimentazione Capitolo X"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#207,207,"palmente al consumatore e alle associazioni di tutela dei consumatori, sono
uno strumento di prevenzione che dovrebbe essere divulgato anche nellescuole così come nei servizi preventivi, nella medicina di base, e in tutte lestrutture che fanno nutrizione applicata. In chiusura e in conclusione è benerimarcare che benché sia un campo promettente dal punto di vista della ricercascientifica bisogna precisare che allo stato attuale delle conoscenze le racco-mandazioni nutrizionali sono basate sui fabbisogni di gruppi di popolazione;la informazione basata sulle raccomandazioni personalizzate tarate sui fabbi-sogni individuali non è ancora matura per essere gestita e ha orizzonti ancoratroppo limitati.
207Capitolo X Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#208,208,208
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#209,209,"Fondamenti della Scienza
dell’Alimentazione
Via Icilio, 7 - 00153 Roma - www.onb.it
Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#21,21,"metilmalonico e/o di omocisteina, che sono collegati ad anomalie cliniche. La
carenza di vitamina B12, insieme a quella di acido folico, piridossina, zincoed enzimi può provocare iper-omocisteinemia, con conseguente danno vasco-lare. L’OMS (Organizzazione Mondiale della Sanità) considera fino a 13μmoli/l un valore ematico normale. La Task Force Internazionale per la Pre-venzione della Malattia Cardiovascolare considera fino a 12 μmoli/l un valore
ematico normale . Quindi livelli n ormali di omocisteina sono considerati tra
5 e 9 μmol/l.L’acido folico oVitamina B9 o folacina è essenziale per la sintesi di DNA, nel
metabolismo degli aminoacidi e per la formazione dell’emoglobina e quindi deiglobuli rossi, rientra in numerosi processi enzimatici; riduce i livelli di omoci-steina, il cui eccesso è associato a rischio di malattie cardiovascolari e infarti.Il fabbisogno minimo di folacina viene valutato intorno ai 50-100 μg al giorno.I LARN ne raccomandano un’assunzione giornaliera di almeno 200 μg/die.Le necessità aumentano notevolmente durante la gravidanza, la crescita, l’al-lattamento ed in corso di alcune patologie (anemie, tumori). La supplementa-zione di folati è molto importante nelle prime fasi della gravidanza, per ilrischio di malformazioni nel feto, in particolare difetti del tubo neurale, spinabifida e anencefalia. In questo caso si raccomanda l’integrazione di acido fo-lico sino a 400 μg /die.I folati si trovano soprattutto nelle frattaglie (circa 500 microgrammi /100g),nei vegetali come brassicacee, asparagi, lattuga, pomodori, legumi, frutta come, arance, kiwi, fragole, cioccolato, frutta secca a guscio in forma più o menodisponibile, uova. La cottura distrugge gran parte dei folati presenti negli ali-menti, così pure gli antinutrienti contenuti, ad esempio nei legumi, ne riduconol’assorbimento a livello intestinale.La carenza di acido folico può portare ad anemia megaloblastica, ritardo del-l’accrescimento, disturbi della memoria, precoce ingrigimento dei capelli. E’spesso associata a carenza di altri nutrienti come vitamina B12 e zinco.
1.2 I Macronutrienti
1.2.1 Carboidrati
I carboidrati o saccaridi o glucidi o idrati di carbonio sono i composti chimici
più diffusi ed abbondanti sulla terra, poiché svolgono un gran numero di fun-zioni in tutte le forme di vita. Sono costituiti da C, H, O, in rapporto C
n(H2O)n, struttura da cui deriva il nome
21Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#22,22,"di carboidrati. Classicamente i glucidi vengono suddivisi in monosaccaridi,
disaccaridi, oligosaccaridi e polisaccaridi.Le piante verdi, attraverso il processo di fotosintesi clorofilliana, trasformanola CO
2in composti organici, per lo più glucidi con liberazione di O2.
I carboidrati comprendono anche le fibre, polisaccaridi cellulari e di riserva dellepiante (cellulosa, pectine, gomme, mucillagini), definite carboidrati indigeribili
in quanto non possono essere idrolizzati dagli enzimi digestivi dell’uomo.I carboidrati servono a conservare l’energia, come nutrienti e intermedi meta-bolici. L’amido, nelle piante ed il glicogeno, negli animali, sono i carboidratiche costituiscono la riserva energetica, facilmente disponibile per essere tra-sformata in glucosio.Il glucosio è lo zucchero biologico per eccellenza, monosaccaride, che puòessere considerato come la principale sostanza glucidica per la produzione dienergia (ATP).Gli zuccheri sono costituenti di un gran numero di molecole biologiche: ATP;DNA; RNA, oltre ad essere intermedi del metabolismo.Si suddividono in base al numero di atomi di C presenti ed al gruppo funzio-nale. Sono poliidrossialdeidi o poliidrossichetoni a seconda se il corbonile èaldeidico o chetonico.I monosaccaridi, unità strutturali più semplici, non scindibili per idrolisi, sonoaldeidi o chetoni che hanno due o più gruppi ossidrilici; la formula generale è(CH
2O)n, i più piccoli. L’aldoso più semplice è la gliceraldeide, mentre il che-
toso più semplice è il diidrossiacetone. Questi due zuccheri semplici vengonochiamati triosi in quanto contengono 3 atomi di carbonio. Ai monosaccaridi,sia aldosi che chetosi, vengono dati nomi generici che descrivono i gruppi fun-zionali importanti ed il numero totale di atomi di carbonio. I monosaccaridipiù semplici sono solubili in acqua ed hanno generalmente un sapore dolce.I disaccaridi sono formati da due monosaccaridi uniti insieme da un legameglicosidico. Gli oligosaccaridi sono formati da tre a 10 unità monosaccaridiche,unite insieme da legami glicosidici. I polisaccaridi, chiamati anche glicani, sono formati da unità monosaccaridi-che, fino a qualche milione, tenute insieme sempre da legami glicosidici. Pos-sono essere formati da un solo tipo di monosaccaride (omopolisaccaride) odiversi tipi di monosaccaridi (eteropolisaccaridi); assumono una struttura li-neare o ramificata in funzione del tipo di legami che si formano. I principali polisaccaridi sono l’amido, il glicogeno (polisaccaridi di riserva),la cellulosa, la chitina (polisaccaridi di struttura), i mucopolisaccaridi (acidoialuronico). La forma principale di polisaccaride di deposito negli animali è il
22Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#23,23,"glicogeno, che si trova principalmente nel fegato (fino al 10% della massa
epatica) e nel muscolo scheletrico (1-2% della massa). 
Nuova classificazione dei carboidratiNel 1981 David Jenkins propose una nuova classificazione dei carboidrati ba-
sata sulla velocità con cui i carboidrati contenuti negli alimenti determinavanol’aumento della glicemia dopo il pasto. L ’indice glicemico è un indicatore
standardizzato della capacità di un carboidrato presente in un cibo, di alzarela concentrazione di glucosio nel sangue.Gli alimenti contenenti carboidrati sono suddivisi secondo la velocità di dige-stione e di assorbimento in alimenti ad alto indice glicemico e alimenti a basso
indice glicemico . I primi sono digeriti e assorbiti velocemente, fanno alzare
molto il tasso del glucosio nel sangue (glicemia), di conseguenza viene secretauna quantità notevole d’insulina che causa un’altrettanto brusca diminuzionedella glicemia. Esempi di alimenti ad alto e medio indice glicemico sono ilpane bianco e integrale, pasta, biscotti e tutti i prodotti da forno, riso bianco,miglio, patate bianche, pizza, patate molto cotte e purè, fave bianche sgusciate,wafers, crepes, krafen e altri dolci, pop-corn, cereali soffiati da colazione. Glialimenti a basso indice glicemico sono digeriti e assorbiti lentamente, fannoalzare lentamente il tasso del glucosio nel sangue, di conseguenza viene secretauna quantità normale d’insulina che riporta gradualmente la glicemia ai livelliprecedenti l’assunzione di carboidrati. Esempi di alimenti ad basso indice gli-cemico: verdure, legumi, cereali integrali, frutta (ad eccezione di banane ma-ture, ananas, anguria ).L’indice glicemico è espresso in termini percentuali rispetto alla velocità concui la glicemia aumenta in seguito all’assunzione di un alimento di riferimento(IG 100), quale il glucosio oppure il pane bianco.
1.2.2 I Lipidi
I lipidi sono composti eterogenei di piante e animali. Variano tra loro moltis-simo per struttura chimica, alcuni sono esteri, altri idrocarburi; alcuni sonoaciclici, altri ciclici o anche policiclici. Costituiscono la maggiore riserva dienergia nell’organismo umano, hanno funzioni plastiche e bioregolatrici. Sono i costituenti principali delle membrane biologiche, del surfattante alveo-lare, degli ormoni steroidei, trasportano le vitamine liposolubili nel nostro or-ganismo. Gli acidi monocarbossilici hanno più di tre atomi di C; la catenaalifatica può essere satura, insatura, ramificata. Quelli più frequenti nei tessuti
23Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#24,24,"di mammifero hanno catena lineare e numero pari di atomi di carbonio.
Diverse sono le categorie di lipidi, acidi grassi, trigliceridi, colesterolo, fosfo-lipidi e sono tutti apolari, insolubili in ambienti acquosi e solubili nei solventiorganici.Gli acidi grassi rappresentano il materiale di costruzione delle membrane cel-lulari, si distinguono in saturi, monoinsaturi, polinsaturi a seconda della pre-senza o meno di doppi legami fra atomi di carbonio adiacenti. Gli insaturi sonodi solito in forma cis, le insaturazioni spesso cominciano dalla posizione C-9,a catena lineare, senza ramificazioni. La fluidità di membrana aumenta con ilgrado di insaturazione. Gli acidi grassi sono definiti essenziali, ciò significache queste molecole devono essere necessariamente introdotte con la dietaperchè l’organismo non è in grado di sintetizzarle, o non riesce a produrne unaquantità adeguata alle proprie necessità fisiologiche. L’organismo è in gradodi formare alcuni acidi grassi, ma solo a partire da altri acidi grassi. Acidigrassi essenziali sono, ad esempio, l’acido arachidonico, α-linolenico (C18:3ω-3) e linoleico (C18:2 ω-6). La loro deficienza nella dieta porta a disordinimetabolici e strutturali. 
Acidi grassi saturiAcido miristico e acido palimitico
L’acido miristico, a 14 atomi di carbonio, deriva il nome dall‘albero che pro-duce la noce moscata ( Myristica fragrans ) in cui rappresenta fino all‘80%
della frazione degli acidi grassi.E’ prodotto dal fegato a partire dai carboidrati ed è contenuto nei grassi di ori-gine animale. E particolarmente abbondante nella materia grassa dei prodottilattiero-caseari (panna, burro), olio di cocco. Può essere trasformato in acidopalmitico nel fegato. L’acido miristico svolge un ruolo importante nel funzio-namento dei recettori degli ormoni e nel trasporto delle proteine all’internodella cellula verso i mitocondri. Sembra aumentare i livelli di colesterolo econtribuire in maniera significativa allo sviluppo dell’aterosclerosi. Evidenzescientifiche dimostrano che l’acido miristico, insieme al palmitico (a 16 atomidi carbonio, contenuto in olio di palma, carne e prodotti caseari), agli acidigrassi trans, all’uso eccessivo di sodio, al sovrappeso e ad un uso eccessivo dialcool, contribuisce all’incremento del rischio cardiovascolare (CDV). L’acido palmitico è fra i più diffusi sia nel mondo animale che vegetale. Derivail suo nome dal fatto di essere il maggior costituente dell‘olio di palma, è im-portante perchè è il primo acido grasso prodotto nella sintesi degli acidi grassi.
24Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#25,25,"Recenti ricerche hanno evidenziato che l’acido palmitico è coinvolto nella re-
golazione degli ormoni. Gli acidi palmitico e miristico sono coinvolti nellacomunicazione tra cellule e nelle funzioni del sistema immunitario. L’acidomiristico può regolare la disponibilità di acidi grassi polinsaturi, come l’acidodocosaenoico (DHA), tuttavia ciò richiede ulteriori approfondimenti.
Acido Stearico 
E‘ un acido saturo a 18 atomi di carbonio, presente soprattutto negli animalie limitatamente nei vegetali, ad esempio nel burro di cacao e karitè. Tra gliacidi grassi saturi è il meno aterogeno.I salumi contengono più acidi grassi saturi rispetto alle altre carni, ma la per-centuale maggiore è rappresentata dall’acido stearico, un grasso che è sì saturo,ma che non fa aumentare il tasso di colesterolo. L’acido stearico ha infatti lacapacità di convertirsi in acido oleico per attività della delta-9-desaturasi.
Acidi grassi monoinsaturiGli acidi grassi monoinsaturi sono sintetizzabili dall’organismo umano a par-
tire dei glucidi.Acido oleicoL’acido oleico è un acido grasso monoinsaturo della famiglia degli omega 9.E il più abbondante degli acidi grassi monoinsaturi a catena lunga del nostroorganismo. Svolge un ruolo strutturale importante in quanto favorisce la flui-dità delle membrane cellulari ed è anche una fonte di energia mitocondriale.Influisce positivamente sul tasso di colesterolo sanguigno e aiuta a ridurre ilrischio di morbilità e mortalità cardiovascolare. 
Gli acidi grassi polinsaturi omega-3
Acido Alfa-linoleico
L’acido alfa-linoleico è il precursore degli acidi grassi polinsaturi della fami-glia omega 3. E un acido grasso essenziale, vale a dire che deve assolutamenteessere assunto con la dieta, in quanto l’organismo non è in grado di produrloa partire dal precursore. Poichè rende possibile la sintesi degli acidi grassiomega 3 allungati, in particolare dell’acido eicosapentaenoico (EPA) e del-l’acido docosaesaenoico (DHA), l’acido alfa linoleico è molto importante perla salute sia a livello strutturale, in quanto garantisce alle membrane cellulari
25Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#26,26,"una fluidità ottimale, sia a livello funzionale, in quanto fornisce i precursori
degli eicosanoidi della serie 3 (antinfiammatori, antiaggreganti piastrinici,miorilassanti della muscolatura liscia). 
Gli acidi grassi polinsaturi omega-6Acido linoleico 
L’acido linoleico, acido grasso essenziale, è il precursore degli acidi grassi po-linsaturi della famiglia omega 6. Poiché consente la sintesi degli acidi grassiomega 6 allungati, in particolare dell’acido diomo-gamma-linoleico (DGLA)e dell’acido arachidonico (AA), L’acido linoleico svolge un ruolo molto im-portante per la salute sia dal punto di vista funzionale, in quanto fornisce i pre-cursori degli eicosanoidi della serie 1 per il DGLA (antinfiammatori,antiaggreganti piastrinici, miorilassanti della muscolatura liscia) e della serie2 per l’AA (pro-infiammatori, pro-aggreganti piastrinici, pro costrittori dellamuscolatura liscia); sia dal punto di vista strutturale, in quanto favorisce lafluidità delle membrane cellulari.
Acidi Grassi TransLa configurazione cis è l’unica riconoscibile dal nostro organismo, e dun-
que è l’unica a poter essere metabolizzata. Gli oli di semi spremuti a freddosono di tipo cis. Quando l’olio è estratto mediante riscaldamento o mediantel’uso di solventi organici, come l’esano, l’olio ottenuto ha una configura-zione Trans.Questi trattamenti distruggono parte delle vitamine liposolubili e di altre com-ponenti utili presenti nel seme e creano dei grassi che non esistono in naturae risultano dannosi per il sistema cardiocircolatorio.Questi acidi grassi trans sembra che provochino la diminuzione del coleste-rolo HDL in modo dose dipendente, l’aumento dell’LDL-colesterolo inmodo dose dipendente e delle lipoproteine aterogeniche, aumenta il tasso dicolesterolo totale nel siero. I acidi grassi trans, quindi, potrebbero parteciparenotevolmente ai processi arterosclerotici e aumentare così i rischi per infartidel miocardio ed altri problemi correlati. Inibiscono la funzione degli enzimiassociati alle membrane, come la delta-6 desaturasi. Causano delle modifi-che della citocromo ossidasi P450, alterazioni nelle proprietà fisiologichedelle membrane biologiche, comprese la capacità di trasporto e flessibilitàdella membrana cellulare.
26Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#27,27,"Acido trans-vaccenico
L’acido trans-vaccenico è un acido grasso prodotto dalla trasformazione bat-terica degli acidi grassi insaturi nel rumine dei ruminanti. Gli acidi grassi transdetti « naturali » si possono perciò ritrovare nei prodotti lattiero-caseari (burro,panna, formaggi, latte) e nelle carni (bovine, ovine, e così via).E‘ considerato un MUFA (acidi grassi monoinsaturi) antidislipidemico.
Acido elaidico 
L’acido elaidico è un acido grasso trans presente soprattutto negli oli vegetaliidrogenati e negli oli di frittura, nella margarina (soprattutto nelle margarinedure), negli alimenti fritti di produzione industriale e nei prodotti da fornocontenenti shortening, margarina, oli o grassi parzialmente idrogenati comebiscotti, pane allo zucchero, frittelle, dolci, pasticcini, muffins, croissant, snacke alimenti fritti (in particolare patatine fritte e cibi pastellati), chips e crackers,confetteria. Ha degli effetti dannosi sulla salute quali ipercolesterolemia, ate-rogenicità, aumento del rischio cardiovascolare, alterazione della biosintesidegli AGPI a catena molto lunga e del metabolismo delle prostaglandine, pro-prietà cancerogene. 
TrigliceridiTriesteri del glicerolo, hanno importanza biologica come funzione di riserva
energetica, di isolamento e protezione.Il 95% del grasso della nostra alimentazione è sotto forma di trigliceridi che de-vono essere idrolizzati in monomeri. Quando si dosano i trigliceridi, non esistealcun modo di sapere se gli acidi grassi che li compongono sono saturi o insaturi. I carboni degli acidi grassi risultano molto ridotti, quindi possiedono moltaenergia chimica. I triacilgliceroli sono quindi delle molecole di stoccaggiodell’energia molto efficaci. La loro ossidazione produce circa 9 kcal/g., mentreper gli zuccheri l’ossidazione produce circa 4 kcal/g. I trigliceridi rappresentano la principale forma di trasporto nel sangue comelipoproteine. Si sottolinei il ruolo potente dei trigliceridi come indicatori di un rischio di in-farto del miocardio. Un’alimentazione ricca in grassi saturi può fare aumentarei trigliceridi sierici; importante è anche il ruolo di un eccesso di glucosio ema-tico, dovuto ad un eccesso di idrati di carbone che gioca un ruolo importantenel livello elevato di trigliceridi.
27Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#28,28,"Colesterolo
Scoperto nella bile nel 18° secolo, di cui è il maggiore costituente, è il più ab-
bondante degli steroli contenuto nei tessuti degli animali, o meglio lo si rin-viene in tutte le cellule animali (membrane cellulari), ma soprattutto nelcervello e nel midollo spinale. La quantità totale di colesterolo mediamentepresente nel corpo umano è di circa 200 g.E’ una molecola indispensabile alla vita delle cellule ed all’equilibrio degliorganismi. La stessa svolge molte funzioni biologiche di importanza capitale:• precursore degli acidi biliari, escreti tramite la vescicola biliare nel tubo
digerente, la cui azione detergente è necessaria all’assorbimento da partedell’intestino dei grassi alimentari;
• costituisce lo scheletro degli ormoni steroidei molecola da dove derivano gli
ormoni chiamati steroidei (ormoni maschili: androgeni; ormoni femminili:estrogeni, progesterone; e ormoni corticoidi: cortisone e cortisolo);
• con l’aiuto dell’irradiazione solare trasforma la vitamina D nella pelle;• partecipa alla struttura delle membrane che circondano le cellule, composte
per circa la metà da sostanze grasse;
• è molto poco solubile;• abbonda nel tessuto nervoso. Inoltre, conferisce rigidità alle membrane cellulari e del mitocondrio e vienetrasportato ai tessuti extraepatici da lipoproteine quali LDL e VLDL.Il 30% del colesterolo si trova in forma libera (gruppo -OH su C3 non esteri-ficato), il 70% esterificato (gruppo -OH legato ad acido grasso).
1.2.3 Proteine
Le proteine rappresentano gli elementi strutturali e funzionali più importantinei sistemi viventi. Sono soggette ad un continuo processo di demolizione esintesi, il turnover proteico, attraverso il quale l’organismo è in grado di rin-novare continuamente le proteine logorate sostituendole con nuovo materialeproteico (globuli rossi, capelli, unghie, muscoli).Il turnover proteico è esteso a tutte le proteine, diminuisce dalla nascita all’età adultae richiede circa il 20% di energia del metabolismo basale. Quantitativamente corri-sponde a 3-4 volte l’introduzione di proteine ed è pari a 3-4 g di proteine/kg/die.Qualsiasi processo vitale dipende da questa classe di molecole. La caratteri-stica strutturale comune a tutte le proteine è di essere dei polimeri lineari di
amminoacidi della serie L uniti tra loro da un legame peptidico. Ciascuna pro-
teina ha però una propria struttura tridimensionale che la rende capace di svol-
28Fondamenti della Scienza dell’Alimentazione Capitolo I"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#29,29,"gere specifiche funzioni biologiche.
Si stima che ne esistano più di 50.000 tipi di proteine umane e che il numerodi proteine distinte all’interno di una cellula vari tra le 3.000 e le 5.000. Nelsolo siero possono essere identificate più di 1.400 proteine.Le proteine svolgono numerose importanti funzioni riassunte nella Tabella 2.
Catalizzatori di reazioni chimiche tutti gli enzimi sono proteine
Trasporto emoglobina, mioglobina, albumina, 
transferrina
Deposito di materiale ferritina
Proteine dei sistemi contrattili actina-miosina, tubulina-dineina
Componenti strutturali collagene, tessuto connettivo, 
citoscheletro, pelle
Protezione immunitaria gli anticorpi sono delle proteine 
altamente specifiche
Funzione ormonale molti ormoni sono di natura proteica
(insulina, glucagone)
Tossine alcuni veleni hanno una struttura proteica.
Controllo e regolazione espressione genica Istoni
Generazione e trasmissione impulso nervoso ad esempio la rodopsina, presente nei 
bastoncelli della retina, è una proteinache è in grado di funzionare come recettore per la luceTabella 2 - Funzioni delle proteine
29Capitolo I Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#3,3,"3Fondamenti della Scienza dell’Alimentazione
Prefazione
Il Consiglio dell’Ordine Nazionale dei Biologi, al momento del suo insedia-
mento, ha istituito dieci commissioni permanenti di studio. Nel corso dei mesi,queste si sono occupate di organizzare corsi di formazione, conferenze e con-vegni. In aggiunta, hanno avviato un’intensa attività editoriale destinata tantoagli addetti ai lavori quanto a un pubblico più generalista. Questo volume è stato elaborato dalla commissione “Nutrizione” dell’ONB,con l’intento di fornire strumenti utili al corretto svolgimento dell’attività pro-fessionale di Biologo Nutrizionista.Il Consiglio dell’Ordine e la commissione si sono posti come obiettivo quellodi contribuire ad accrescere le nozioni scientifiche degli addetti ai lavori, an-dando al di là delle competenze di base.Elaborare un profilo nutrizionale, infatti, necessita obbligatoriamente di unabuona conoscenza della biochimica degli alimenti e del loro impatto con or-gani, tessuti e cellule. Tali competenze, pertanto, sono imprescindibili al finedi migliorare lo stato di salute e il benessere degli individui.Sono molte le malattie che possono essere determinate da una dieta scorrettae il biologo deve, con professionalità, favorire scelte alimentari che possanocontribuire a prevenire importanti patologie.La commissione “Nutrizione”, con questo contributo scientifico, vuole dareun messaggio importante ai colleghi Nutrizionisti affinché esercitino al megliola professione.
Dr. Ermanno Calcatelli
Presidente dell’Ordine Nazionale dei Biologi"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#30,30,"Bibliografia
• Fidanza F., Liguori G., Nutrizione Umana. Idelson Editore, 1988 
• Fidanza F. Ruoli e richieste di energia e nutrienti energetici . Gnocchi 
• Mariani Costantini A., Cannella C., Tomassi G. – Fondamenti di Nutrizione Umana. Il
Pensiero Scientifico Editore, 1999 
• Cozzani I., Dainese E., Biochimica degli alimenti e della nutrizione. Piccin Editore, 2006• Murray M., Pizzorno J., Pizzorno L., Enciclopedia della Nutrizione. Dalla A alla Z tutti i
cibi che guariscono . Tecniche Nuove
• Riccardi, Pacioni, Giacco, Tivellese. Manuale di Nutrizione Applicata , Sorbona, III Edizione
• Marandola P., Marotta F.. Il Manifesto della lunga vita . Sperling e Kupfer 
• Champe et al., Le basi della biochimica , Ed. Zanichelli 
•The role of virgin olive oil components in the modulation of endothelial function . Perona J.
et Coll. J Nutr Biochem. 2006 Jul;17(7):429-45). 
•L’acido oleico riduce anche il rischio di cancro (Molecular mechanisms of the effects of
olive oil and other dietary lipids on cancer. Escrich E, et Coll. Mol Nutr Food Res. 2007Oct;51 (10):1279-92).
•WHO (2003) Diet, Nutrition and the prevention of Chronic Diseases. Report of a Joint
WHO/FAO Expert Consultation, WHO Techical Report Series 916. Geneva: WHO. 
• Disponibile sul sito: http://www.who.int/dietphysicalactivity/publications/trs916/en/• Stabler & Allen. Vitamin B12 deficiency as a worldwide problem . Ann. Rev. Nutr. 24,
2004:299-326.
• Rioux V . and Legrand P. (2007) Saturated fatty acids: simple molecular structures with
complex cellular functions . Current Opinion in Clinical Nutrition and Metabolic Care
10:752-58
Sitografia
http://www.bda-ieo.it/index.aspx
http://www.ministerosalute.ithttp://www.epicentro.iss.it/problemi/vitamine/epid.asphttp://www.iss.it/osnami/http://sinu.it/html/pag/larn_minerali.asphttp://www.efsa.europa.eu/it/scdocs/doc/nda_op_ej822_vit_k2_summary_it.pdfhttp://www.eufic.org/article/it/salute-e-stile-di
30"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#31,31,31Capitolo II Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#32,32,"CAPITOLO II
ACQUA E FIBRA ALIMENTARE
Riassunto
L’acqua è una componente essenziale del corpo umano, circa il 60-70% del
peso corporeo. Svolge innumerevoli funzioni nei processi fisiologici e nellereazioni biochimiche all’interno dell’organismo. Per consentire che tutto ciòpossa correttamente avvenire e quindi conservare uno stato di salute buonobisogna mantenere un adeguato equilibrio nel bilancio idrico dell’organismoche è determinato dal bilanciamento tra entrate ed uscite. Il fabbisogno diacqua cambia per età e sesso ed aumenta in alcune condizioni fisiologichequali gravidanza ed allattamento così come in alcune condizioni patologichequali diarrea, vomito, stati febbrili.La fibra alimentare è ritenuta una componente importante della dieta umanaed esercita effetti di tipo funzionale e metabolico. E’ costituita da parti dellaparete cellulare vegetale che il nostro organismo non è in grado di digerire.La fibra alimentare è una miscela estremamente complessa di polisaccarididiversi che appartiene alla famiglia dei carboidrati, resiste all’idrolisi da partedegli enzimi gastrici e viene fermentata dalla microflora batterica del colon.Numerosi studi osservazionali suggeriscono che un consumo insufficientepossa contribuire a numerosi disturbi cronici come stipsi, diverticolite, emor-roidi, vene varicose, diabete, obesità, malattie cardiovascolari, tumori delcolon-retto e varie altre tipologie di tumore.
32Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#33,33,"2.1 ACQUA
L’organismo umano è formato principalmente di acqua che ne è costituente
essenziale per il mantenimento della vita. Il contenuto di acqua nel corpo umano varia con l’età e il sesso. Neonato: 75 % circa del peso corporeo e si abbassa progressivamente dal 1°al 9° anno di etàUomo: 60-70% del p.c. Donna: 55-65% del p.c. Le differenze tra i sessi sono presenti già a partire dall’adolescenza. Nelladonna, infatti, è presente una maggiore percentuale di tessuto adiposo, tessutopovero in acqua, e ciò comporta una minore quantità di acqua. Con l’invec-chiamento il contenuto di acqua, sia come valore assoluto che come frazionepercentuale, si riduce. L’uomo medio è alto 175 cm e pesa circa 70 Kg. Di questo peso il 16% è co-stituito da proteine, il 13% da lipidi, il 5% da Sali minerali, l’1% da glucidi,le vitamine sono in tracce e circa il 60-70% è costituito da acqua. Quest’ultimaentra nella composizione dei muscoli e degli organi interni per il 75% circa,nel tessuto adiposo per il 10%, nello scheletro per oltre il 30%. E’ localizzataall’interno delle cellule per il 66% circa, nella linfa per il 2% circa, nel plasmaper il 7% circa e come acqua extracellulare ovvero negli spazi tra le celluleper il 25% circa.Una percentuale così alta di acqua nel corpo umano trova giustificazione nellenumerose funzioni che questa svolge nei processi fisiologici e nelle reazionibiochimiche all’interno dell’organismo:• Costituente principale del citoplasma delle cellule • Costituente principale di sangue, linfa, liquido cefalo rachidiano• Solvente di nutrienti, succhi digestivi, gas, elettroliti, colloidi• Veicolo per l’assorbimento dei principi nutritivi • Mezzo in cui avvengono le reazioni metaboliche e digestive• Veicolo per il trasporto di nutrienti, ormoni, elettroliti e secrezioni • Allontana le sostanze di rifiuto • Garantisce la giusta consistenza del contenuto intestinale• Indispensabile nel sistema di regolazione della temperatura corporea e in
quello di disintossicazione 
• Svolge il ruolo di ammortizzazione nelle articolazioni e nei tessuti • Mantiene elastiche mucose e pelle attraverso il giusto grado di idratazione.
33Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#34,34,"Appare ovvio, guardando a tutte le innumerevoli funzioni che l’acqua svolge,
che per conservare uno stato di salute buono bisogna mantenere un adeguatoequilibrio nel bilancio idrico dell’organismo.Il bilancio idrico è dato dall’equilibrio tra entrate e uscite (uomo adulto, atti-
vità fisica moderata, temperatura 18-20°C), così come rappresentato in tabella.
Nel nostro organismo l’equilibrio idrico è mantenuto attraverso due meccanismi:
1) Il meccanismo della sete che regola la quantità di acqua da ingerire. E’ un
meccanismo con un tempo di risposta ritardato e a volte non interviene neitempi giusti per evitare gli effetti negativi dovuti alla perdita di acqua. Inparticolare nell’anziano è un meccanismo che non sempre è funzionante equindi non permette il rimpiazzo dell’acqua persa con conseguente disi-dratazione.
2) Il riassorbimento dell’acqua a livello renale attraverso la regolazione della
quantità di acqua eliminata con le urine.
Già una piccola disidratazione pari all’1% del peso corporeo mette in difficoltàattività e performance fisiche dell’organismo. Con una percentuale di disidra-tazione dal 2% al 10% si assiste a sintomi sempre più importanti, da secchezzadella bocca e sensazione di sete ad alterazione della termoregolazione, a mu-cose secche ed asciutte, mal di testa, crampi muscolari, debolezza, maggioreirritabilità, malessere generale, allucinazioni, vomito, tachicardia fino perditadi conoscenza e pericolo per la stessa vita. Una disidratazione persistente aumenta inoltre il rischio di contrarre tumoridell’apparato urinario e del colon nonché di avere formazione di calcoli re-nali.
2.1.1 LARN e ACQUA
Fabbisogno di acqua per adulti e anziani: circa 1 ml/Kcal/giorno.Fabbisogno di acqua per bambini : circa 1,5 ml/kcal/giorno. La quota di
acqua per calorie è maggiore perché i bambini hanno maggior rischio di disi-dratarsi.Entrate Uscite
Bevande 1,5-2 lt Rene (urine) 0,5-1,5 lt
Alimenti 0,5-1 lt Cute (sudore) 0,1-1 lt
Ossidazioni 0,3- 0,5 lt Vie aeree (respirazione) 0,4 - 0, 6 lt
(acqua metabolica x formazione endogena)
Intestino (feci) 0,05 – 0,2 lt
34Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#35,35,"Per valutare il fabbisogno giornaliero di acqua si può anche applicare la for-
mula:Peso corporeo x 0,03(per es. un uomo di 70 kg necessita di 2,1 l d’acqua al giorno: 70x0,03= 2,1)Durante la gravidanza e l’allattamento il fabbisogno idrico aumenta così comeanche in alcune condizioni patologiche come diarrea, vomito, stati febbrili, ecc.L’acqua metabolica prodotta dalla respirazione cellulare è pari a:
• 0,56 g. per 1 g. di glucidi,• 1,07 g. per 1 g. di lipidi,• 0,39 g. per 1g. di proteine
In pratica, considerando un soggetto adulto che pesa di 70 kg, con un apportocalorico giornaliero di 2400 kcal costituito da: 70g di proteine (12%), 350 g.di carboidrati (58%) e 80 g. di lipidi (30%) si ottiene una produzione di 310ml di acqua endogena. Poiché il nostro metabolismo non produce acqua inquantità sufficiente a coprire il fabbisogno giornaliero occorre introdurla conalimenti e bevande.Negli alimenti l’acqua è presente in quantità diverse:
Data l’importanza dell’acqua nell’alimentazione umana, esperti della nutri-
zione hanno elaborato la piramide dell’idratazione racchiudendo nell’ imma-gine della piramide, ormai nota ai più, le indicazioni per individui adulti, sanie moderatamente attivi circa il consumo di acqua e non solo allo scopo di sol-lecitare l’attenzione dell’opinione pubblica e di tutti coloro che operano perpromuovere salute riducendo al minimo gli effetti negativi di una scorrettaidratazione (Figura 1). 
frutta, ortaggi, verdura e latte oltre l’85%   H2O
carne, pesce, uova, formaggi freschi 50-80%   H2O
pasta e riso cotti 60- 65%  H2O
pane e pizza 20-40%  H2O
biscotti, fette biscottate,  farina e frutta secca meno del 10%  H2O
35Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#36,36,"Alla base della piramide, ovviamente, l’acqua. Almeno 5 bicchieri (da 200 ml
ciascuno) per un totale di circa 1 litro necessario per equilibrare mediamenteil bilancio idrico fisiologico.Al 2° livello: tè, caffe decaffeinato, oro, infusi e tisane, tutti senza zuccheroche possono integrare la restante quota idrica della giornata (0-3 bicchieri)Al 3° livello: latte, spremute di frutta fresca e succhi di frutta al 100%, e cen-trifugati (0-2 bicchieri)Al 4° livello: tutti gli altri tipi di succhi e la birra analcolica (0-2 bicchieri). Al 5° livello: il caffè sotto forma di espresso o americano da assumere di pre-ferenza senza zucchero (0-5 tazzine) Al 6° livello: le bevande idrosaline formulate per la reidratazione da consu-mare prima o dopo intensa attività fisica contenenti zuccheri, elettroliti, aromi(0-500 ml)Al 7° livello e quindi apice della piramide bibite analcoliche, energy-drink,sciroppi e soft drink ad alto contenuto di zuccheri (occasionalmente)La stratificazione nei diversi livelli della piramide serve, così come per la pi-ramide alimentare rispetto ai vari alimenti, a dare indicazioni sulle quantitàconsigliate per i vari tipi di bevande poiché alcune sono reidratanti ma ancheFigura 1: piramide dell’idratazione suggerita per la popolazione italiana (riadatta da Giam-
piero M et al.; ADI Magazine 2011; 2: 105-115)
36Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#37,37,"apportatrici di sostanze che richiedono attenzione nella quantità di consumo.
Ricapitolando, ogni giorno dovremmo reintegrare un paio di litri di liquidi ela precedenza va all’acqua e alle bevande non caloriche e non alcoliche, senzadimenticare che verdure, frutta e minestre contribuiscono, più di altri alimenti,al rifornimento quotidiano di liquidi.L’equilibrio idrico può essere mantenuto bevendo sia acqua del rubinetto cheacque minerali entrambe sicure e controllate tenendo conto che nelle secondesono contenuti sali minerali. Le acque minerali vengono classificate in basealla quantità e qualità di questi minerali quali carbonati, solfuri, cloruri e fosfatidi calcio, sodio, potassio, magnesio, ferro, bario, alluminio, silicio e manga-nese. Dal un punto di vista nutrizionale le acque minerali ricche in sali di calciopossono essere utili nella prevenzione dell’osteoporosi e nelle varie fasi dellavita. 
ACQUE MINERALI. Totale di sali minerali (residuo fisso) nelle acque im-
bottigliate
Durante una moderata attività fisica attraverso la sudorazione, nella maggior
parte delle persone, vengono persi 1-2 litri di liquidi per ora, con perdita anchedi sali minerali soprattutto sodio, potassio e cloro. Nel caso di attività non ago-nistica basterà una dieta equilibrata ricca in acqua, frutta, verdure per reintegrareacqua e sali minerali, mentre in caso di attività agonistica bisognerà ricorrere, aseconda dei casi e della prestazione, ad integratori anche idrosalini.
Bibliografia 
• INRAN. Linee Guida per una Sana Alimentazione Italiana. Revisione 2003 
• Consigli Paolo. L’acqua pura e semplice. Tecniche Nuove• Giampietro M. e al. Piramide dell’idratazione suggerita per la popolazione italiana adulta
sana. ADI Magazine 2011; 2: 105-115Tipologia Residuo fisso
Acque minimamente mineralizzate meno di 50 mg/litro
Acque oligominerali 50-500 mg/litro
Acque minerali propriamente dette (acque medio minerali) 500-1500 mg/litro
Acque fortemente mineralizzate più di 1500 mg/litro
37Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#38,38,"2.2 Fibra alimentare
Il concetto di fibra alimentare è cambiata notevolmente negli ultimi anni conil progredire delle conoscenze scientifiche. E’ ormai riconosciuto che la fibraalimentare comprende una gamma molto ampia di sostanze con un significatofisiologico maggiore di quanto si pensasse. E’ costituita soprattutto da partidella parete cellulare vegetale che il nostro organismo non è in grado di dige-rire. Pur non potendosi considerare un nutriente, la fibra alimentare esercitaeffetti di tipo funzionale e metabolico che la fanno ritenere un’importante com-ponente della dieta umana. Non esiste una definizione generalmente accettatadi fibra alimentare in Europa o nel mondo. Tuttavia, vi è consenso su defini-zioni basate sulle sue caratteristiche fisiologiche anche se con accenti diversida parte dei vari organismi internazionali.L’American Association of Cereal Chemist (AACC 2001) definisce le fibre
alimentari come “parti commestibili di piante o analoghi di carboidrati resi-stenti alla digestione e all’assorbimento, con fermentazione completa o par-ziale nell’intestino crasso. Le fibre alimentari comprendono polisaccaridi,oligosaccaridi, lignina e sostanze vegetali associate. Esse promuovono effettifisiologici benefici tra cui l’effetto lassativo e la regolazione della colestero-lemia e della glicemia”L’Agence Francaise de Securitè Sanitaire des Aliments (AFSSA 2002) stabi-lisce che “ la fibra alimentare e costituita da: • polimeri di carboidrati con grado di polimerizzazione ≥ 3 di origine vegetale
con lignina o altri componenti differenti dai carboidrati quali, ad esempio,polifenoli, cere, saponine, fitati, cutina, fitosteroli 
• polimeri di carboidrati con grado di polimerizzazione ≥ 3, ottenuti con mezzi
fisici, enzimatici o chimici o sintetici
La fibra alimentare non è né digerita né assorbita nell’intestino tenue e presentaalmeno una delle seguenti proprietà:
- Stimola la fermentazione nel colon- Riduce i livelli di colesterolo pre-prandiali- Riduce la glicemia post-prandiale e / o livelli di insulina “
Il Codex Alimentarius Commission (CAC 2006) definisce:
“La fibra alimentare come polimeri di carboidrati con un grado di polimeriz-zazione non inferiore a 3, che non sono né digeriti né assorbiti nell’intestinotenue. Un grado di polimerizzazione non inferiore a 3 esclude mono e disac-caridi. La fibra alimentare è costituita da uno o più delle seguenti componenti:
38Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#39,39,"• polimeri di carboidrati commestibili naturalmente presenti negli alimenti
consumati
• polimeri di carboidrati, che sono stati ottenuti da materie prime alimentari
mediante procedimenti fisici, enzimatici o mezzi chimici
•polimeri di carboidrati sintetici
Essa generalmente ha proprietà quali:
• ridurre il tempo di transito intestinale ed aumentare la massa fecale• essere fermentata dalla microflora del colon• ridurre il colesterolo totale e / o livelli di colesterolo LDL• Ridurre la glicemia post-prandiale e / o i livelli di insulina”
L’Health Council of The Netherland (2006) si esprime con la definizione:
“La fibra alimentare sta ad indicare una serie di sostanze che non sono digerite
o assorbite nell’intestino tenue dell’uomo, e che hanno la struttura chimica deicarboidrati o di composti analoghi dei carboidrati, lignina e sostanze affini “Sebbene il concetto di fibra alimentare sia stato dibattuto per decenni e il di-battito continui ancora, i costituenti ormai considerati parte di essa non sonomolto diversi oggi da quelli discussi vari decenni fa e da tutte le definizioni sipuò evincere che la fibra alimentare è una miscela estremamente complessadi polisaccaridi diversi che appartiene alla famiglia dei carboidrati, resiste al-l’idrolisi da parte degli enzimi gastrici e che viene fermentata dalla microflorabatterica del colon.
La fibra alimentare può essere equiparata alla parete della cellula vegetale e
rappresenta lo scheletro della pianta. 
La costituzione scheletrica è determinata da:Componenti strutturali della parete cellulare, comprendenti Polisaccaridi
strutturali quali la cellulosa, l’emicellulosa, e le pectine. Altri costituenti sono
rappresentati da Lignina, proteine, e materiale inorganico.Componenti non strutturali della parete cellulare, comprendenti Polisac-
caridi di varia origine, quali le mucillagini, le gomme, estratti di alghe, e po-
lisaccaridi modificati.Le fibre alimentari, dal punto di vista della struttura chimica e dell’attività fi-
siologica sono state divise storicamente in idrosolubili ed insolubili anche se
39Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#4,4,4
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#40,40,"questi termini da alcuni anni sono stati definiti fuorvianti dall’Organizzazione
Mondiale della Sanità e dalla Food and Agricultural Organization perché espri-mono una distinzione fisiologica troppo semplicistica.
È vero però che la fibra alimentare ha un’azione diversa a seconda della idro-
solubilità.
Fibre Insolubili: Cellulosa, Emicellulosa, Lignine
Le fibre alimentari insolubili, presenti principalmente nella crusca di cereali,nelle verdure e negli ortaggi, assorbono acqua comportandosi come “agentidi rigonfiamento” e sono utilizzate solo in piccola parte dalla microflora. De-terminano aumento della massa fecale, accelerato transito intestinale, riduzionedel tempo di contatto con la mucosa intestinale di sostanze nocive. Sono quindiparticolarmente indicate nella regolazione delle funzioni intestinali.
Fibre Idrosolubili: Gomme, Mucillagini, Pectine, Galattomannani
Le fibre alimentari solubili, presenti principalmente nei legumi e nella frutta, resi-stono alla digestione nel tratto superiore dell’intestino e vengono “degradate” dallamicroflora al ceco e al colon destro. Determinano rallentamento dello svuotamentogastrico e senso di sazietà, rallentato transito intestinale, aumento dell’eliminazionedegli acidi biliari, riduzione e regolazione dell’assorbimento di zuccheri e grassi.La fermentazione delle fibre solubili porta inoltre alla produzione di acidi grassi acatena corta (“scafs”, short chain fatty acids). Queste fibre sono indicate nell’ali-mentazione di soggetti con disturbi metabolici quali diabete, malattie cardiovasco-lari che traggono vantaggio da un assorbimento di nutrienti lento e/o ridotto e,poiché inducono senso di sazietà, anche nelle diete per la riduzione del peso.
Fanno parte delle fibre solubili i polisaccaridi non cellulosici che si dividono in:1) Olisaccaridi non digeribili: Galattomannani, PHGG, Fruttooligosaccaridi,
Fos, Xilani, Inulina
2) Etero-Omo Polisaccaridi non digeribili: Gomma-Guar, Pectina, Agar-car-
ragenina, Alginati, Psyllium
La maggior parte degli alimenti di origine vegetale contiene sia fibre solubili
che insolubili in proporzioni differenti. Elencati qui di seguito i più importanti componenti della fibra alimentare conuna breve descrizione. 
40Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#41,41,"2.2.1 Fibra insolubile
Cellulosa 
La cellulosa è uno dei più importanti polisaccaridi, costituita esclusivamenteda unità di glucosio, fino a 10.000 unità per molecola unite tra loro da un le-game β(1➜4) glicosidico. La catena polimerica non è ramificata e le catenesono disposte parallelamente le une alle altre e legate tra loro per mezzo di le-gami ad idrogeno molto forti. Si formano così fibrille e catene molto lunghedifficili da dissolvere. Queste fibrille localmente sono molto ordinate e for-mano una struttura cristallina idrofoba. Principale fonte alimentare . La cellulosa è un componente principale della
parete cellulare della maggior parte delle piante ed è quindi presente in frutta,verdura, legumi e cereali. Gran parte della fibra di crusca dei cereali è cellu-losa.Funzione. Trattiene l’acqua. Aumenta la massa fecale. Diminuisce la pressioneintracolicaRiduce il tempo di transito intestinale. Lega i sali minerali. E’ indicata nellastipsi e nella diverticolosi.
Emicellulose
Le emicellulose sono polisaccaridi contenenti zuccheri diversi dal glucosio esono associate con la cellulosa nelle pareti cellulari delle piante. Esse com-prendono molecole sia lineari che ramificate, più piccole della cellulosa, tipi-camente contenenti 50-200 unità di pentosi (xilosio e arabinosio) e unità diesosi (glucosio, galattosio, mannosio, ramnosio, glucuronico e acido galattu-ronico). Il termine emicellulose indica quindi un gruppo eterogeneo di sostanzeche sono presenti nei cibi vegetali in forme solubili in acqua e forme insolu-bili.Principale fonte alimentare . Crusca, cereali, verdura, legumi, frutta, noci.
Funzione. Trattengono l’acqua ed aumentano la massa fecale. Regolarizzano
il transito intestinale. Fanno diminuire la pressione intracolica. Legano i salibiliari. Ne è indicato il consumo nella sindrome dell’intestino irritabile.
Lignina 
La parola lignina proviene dal termine latino lignum, che significa legno e per
questo motivo le piante che contengono una grande quantità di lignina sonodenominate legnose. È composta da una struttura polimerica di unità fenilpro-paniche e materiale non saccaridico. Essa svolge in tutti i vegetali la funzione
41Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#42,42,"di legare e cementare tra loro le fibre per conferire ed esaltare la compattezza
e la resistenza della pianta. Pur non essendo un polisaccaride la lignina è legatachimicamente alle emicellulose nella parete cellulare vegetale e quindi è inti-mamente associata ai polisaccaridi della parete cellulare delle piante. Dopo ipolisaccaridi la lignina è il polimero organico più abbondante nel mondo ve-getale. E’ presente in alimenti con un componente “legnoso” e negli stratiesterni dei cereali.Principale fonte alimentare. Frumento, verdura, frutta (fragole, pere, pesche,
prugne)Funzione. Aumenta la massa fecale. Riduce il tempo di transito intestinale.
Lega i Sali biliari e gli ioni. E’ consigliata nella stipsi.
2.2.2 Fibra solubilePectine
Le pectine sono polisaccaridi solubili in acqua calda per poi trasformarsi ingel durante il raffreddamento. Sono composte principalmente da catene diacido galatturonico intervallate da unità di ramnosio e sono ramificate con ca-tene di pentosi ed esosi. Le pectine sono presenti nelle pareti della cellula enei tessuti intracellulari di frutta e verdura e sono utilizzati come agenti geli-ficanti e addensanti in vari alimenti.Principale fonte alimentare . Frutta, verdura, patate dolci
Funzione. Aumenta il tempo di svuotamento gastrico. Modifica la produzione
di gas. Modifica la produzione di acidi grassi volatili. Riduce l’assorbimentodei nutrienti. Lega i sali minerali e gli ioni. Indicate in diverticolosi, obesità,diabete mellito, dislipidemie, litiasi biliare.
β-glucani
I β-glucani sono polimeri costituiti da molecole di glucosio unite mediante le-gami glicosidici β(1-3) e β(1-4). Sono una componente importante della paretecellulare dei cereali e sono i principali componenti della frazione solubile dellafibra alimentare. Hanno un struttura lineare e sono di piccole dimensioni. Que-ste proprietà influenzano la loro solubilità, permettendo loro di formare solu-zioni viscose. Principale fonte alimentare . 
Avena, orzo ed in piccole quantità nel granoFunzione.Aumentano il tempo di svuotamento gastrico. Incrementano la peristalsi inte-
42Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#43,43,"stinale. Giocano un ruolo nel contenimento del livello di colesterolo e di glu-
cosio ematico.
Gomme e mucillagini
Gli idrocolloidi comprendono una vasta gamma di polisaccaridi viscosi. Essisono derivati   da essudati di piante (gomma arabica e adragante), semi (guar egomme locust) ed estratti di alghe (agar, carragenine e alginati). Le mucillaginisono presenti nelle cellule degli strati esterni di semi ad esempio nella famigliadelle Plantaginaceae tipo la piantagine ispaghula (psyllium). Questi idrocol-loidi sono utilizzati in piccole quantità come gelificanti, addensanti, stabiliz-zanti e emulsionanti in taluni prodotti alimentari. Principale fonte alimentare . 
Avena e legumiFunzione.Formano sostanze viscose e legano ioni ed altre sostanze. Aumentano il tempodi transito intestinale e danno sensazione di sazietà. Riducono l’assorbimentodei nutrienti e del colesterolo. Trovano indicazione nell’obesità, diabete mel-lito, dislipidemie. 
Oligosaccaridi non digeribili .
Gli Oligosaccaridi non digeribili hanno un grado di polimerizzazione che va
da 3 a 10. Possono essere sintetizzati chimicamente o derivare per idrolisi en-zimatica da monosaccaridi, disaccaridi o polisaccaridi. Vengono inclusi nelladefinizione di fibra alimentare perché, come risultato della loro non digeribi-lità, mostrano effetti fisiologici simili a quelli dei polisaccaridi. Essi sono in genere altamente fermentabili ed alcuni hanno proprietà prebio-tiche.I probiotici più noti sono i fruttani che includono i frutto-oligosaccaridi o oli-gofruttosi (FOS) ottenuti dall’idrolisi enzimatica dell’inulina e i loro analoghisintetici sono ottenuti per sintesi enzimatica dal saccarosio.L’inulina è costituita da polimeri del β-D- fruttosio, è solubile in acqua ed è
accumulata nei vacuoli. Ricerche approfondite hanno dimostrato che l’assun-zione di quantità moderate di inulina determina un aumento significativo deibifidobatteri nel tratto intestinale con effetti benefici e ad una riduzione deibatteri indesiderabili. 
Principale fonte alimentare .
Cipolle, cicoria, topinanbur, porri, carciofi, asparagi, segale e frumento. 
43Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#44,44,"Funzione. 
Stimolano selettivamente la crescita e/o l’attività di un limitato numero di bat-teri nel colon; modificano positivamente il rapporto tra microorganismi sim-bionti e patogeni. 
2.3 Ruolo fisiologico della fibra alimentare e benefici per la salute
Numerosi studi osservazionali sulle fibre alimentari ne hanno evidenziato ef-
fetti fisiologici e metabolici importanti per la salute dell’uomo suggerendo cheun consumo insufficiente possa contribuire a numerosi disturbi cronici comestipsi, diverticolite, emorroidi, vene varicose, diabete, obesità, malattie car-diovascolari, tumori del colon-retto e varie altre tipologie di tumore. Tutti que-sti disturbi hanno una eziologia multifattoriale ed è perciò complicato valutarequanto incide il consumo di fibre e se gli effetti benefici sono da attribuire aspecifici componenti della fibra o ad un modello alimentare totale. 
Fermentazione colica
La fibra alimentare rappresenta per la flora batterica intestinale un substratofondamentale per la sua crescita e determina numerosi effetti:• Produzione di acidi grassi a catena corta (SCAFs): acetato, propionato, bu-
tirrato che svolgono diverse funzioni, lassativa, riduzione della flora putre-fattiva e neutralizzazione dei prodotti del metabolismo putrefattivo, aumentodella digestione e della metabolizzazione del lattosio
• Acidificazione del contenuto colico: un pH basso migliora il trofismo delle
cellule del colon
• Effetto prebiotico: ovvero è substrato per la crescita di specie batteriche be-
nefiche
• Produzione di energia, circa 1,6 kcal/g ( 6kJ/g) (LARN da British Nutrition
Foundation 1990)
Inizio moduloMolti componenti della fibra alimentare sono parzialmente o completamentefermentati dalla microflora del colon. La flora batterica intestinale è un com-plesso ecosistema formato da più di 400 specie batteriche con considerevolivariazioni negli individui a seconda di fattori quali l’età e la dieta.Nello stomaco: 1000 batteri/grammoNel tenue: 100 milioni batteri/grammo
44Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#45,45,"Nel colon: 1000 miliardi batteri /grammo.
La maggior parte dei batteri nel colon usano carboidrati come fonte di energia,ma non tutte le specie possono degradare i polisaccaridi ed alcuni batteri uti-lizzano i prodotti di degradazione iniziali di un’altra specie. I batteri del colonattraverso un’ampia gamma di enzimi producono idrogeno, metano, anidridecarbonica, acidi grassi a catena corta (principalmente acetato 60%, propionato25% e butirrato 15%) e lattato.Gli acidi grassi a catena corta (SCAFs) hanno un effetto trofico sulla mucosa
del colon, producono energia a livello del colonocita, hanno effetto selettivosulla flora batterica, hanno effetto preventivo della diarrea, producono ente-roglucagone e agiscono come immunomodulatori assorbendo procarcinogenie promuovendo l’attacco alle cellule maligne.Gli acidi grassi a catena corta prodotti a livello del colon raggiungono il fegatoe vengono trasformati in grassi, corpi chetonici e glucosio (neoglucogenesi)Le fibre alimentari hanno effetto prebiotico ovvero sono in grado di stimolare
in maniera selettiva la crescita di alcune specie batteriche benefiche presenti alivello intestinale (Bacteroides, Bifidobacterium, Lattobacilli). Questa attivitàprebiotica determina importanti effetti sulla fisiologica attività intestinale:- Facilita la digestione e l’assorbimento di vari nutrienti- Produce nutrienti (vitamine del gruppo B) - Aumenta le dimensioni dei villi intestinali e quindi la superficie di assorbi-
mento
- Aumenta il turn-over delle cellule intestinali- Impedisce lo sviluppo di batteri patogeni
Effetti della fibra sul transito intestinale. Le fibre alimentari sono in grado
di accelerare il transito intestinale con diversi meccanismi a seconda della loro
solubilità in acqua. La fibra insolubile assorbe acqua, determina un effetto massa e quindi si haun aumento del peso delle feci ed una distensione delle pareti del colon.La fibra solubile assorbe acqua e come abbiamo visto ha un effetto prebioticoquindi aumenta la massa batterica ed aumenta la massa fecale.STIPSI. La stipsi è una modificazione del funzionamento dell’intestino tale
che l’espulsione delle feci è alterata nel ritmo giornaliero e/o richiede unosforzo eccessivo per essere portata a termine.Le cause possono essere molteplici di tipo motorio o funzionale, endocrino-metaboliche, legate a farmaci o a fattori psicosociali. Esiste inoltre una stipsiidiopatica.
45Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#46,46,"L’alimentazione è il principale determinante il transito intestinale ed in parti-
colare l’assunzione di fibre il cui ammontare dovrebbe essere di circa 32-45g/die per raggiungere una massa fecale “critica” di 160-200 g/die necessariper minimizzare il rischio di costipazione. 
Effetti della fibra sulla diverticolosi . La malattia diverticolare è una condi-
zione clinica complessa.
Diverticolosi, diverticolite e malattia diverticolare sono forme cliniche diversedi una unica iniziale patologia. La diverticolosi del colon è caratterizzata daernie della parete del colon ed è normalmente asintomatica. I diverticoli pos-sono però causare dolore quando si infiammano ad esempio a seguito di azionebatterica portando ad una condizione detta diverticolite. Le cause della malattiadiverticolare sono diverse: predisposizione genetica, fattori ambientali, età (ri-dotta resistenza della parete, segmentazione del colon), ridotto apporto di fibrecon la dieta.Vi è evidenza da studi osservazionali e studi di intervento che l’assunzione difibre alimentari protegga dalla malattia ed allevi la sintomatologia. E’ parti-colarmente indicata la cellulosa presente nella crusca dei cereali. Questi effettiprotettivi comportano un aumento del peso delle feci, la diminuzione deltempo di transito e la diminuzione della pressione intracolica.
Effetti della fibra sulle IBD (inflammatory bowel disease ).Le malattie in-
fiammatorie croniche intestinali quali la colite ulcerosa ed il morbo di Chron
sono patologie croniche ad eziologia multifattoriale con quadri clinici diversiche colpiscono prevalentemente i giovani. Le fibre alimentari potrebbero avereun ruolo nella dieta dei pazienti affetti da IBD in quanto capaci di “migliorare”la flora batterica intestinale. L’aumentata produzione di SCFAs, che hanno unruolo chiave nel mantenimento dell’omeostasi del colon, da parte delle fibrealimentari potrebbe avere un ruolo positivo nella gestione dei pazienti. L’uso di fibre alimentari è controindicato nelle forme acute e nelle forme ste-nosanti e fistolizzanti
Effetti della fibra sulla digestione e l’assorbimento dei carboidrati.
Quando si consumano pasti ricchi in fibre la tolleranza al glucosio migliora ela secrezione insulinica diminuisce sia in soggetti normali che diabetici noninsulino-dipendenti.Meccanismi ipotizzati per gli effetti dell’azione delle fibre sui carboidrati sonodiversi:
46Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#47,47,"- ritardo del tempo di svuotamento gastrico
- formazione di gel con sequestro di glucosio- alterazione del tempo di transito intestinale- isolamento dei carboidrati dagli enzimi digestivi- inibizione della digestione dei carboidrati complessi- produzione di SCFAs che aumentano l’utilizzazione del glucosio- aumento della sensibilità insulinica
Diabete gestazionale. La dieta alimentare è un utile strumento di preven-
zione/controllo nel trattamento del Diabete Gestazionale. Una dieta povera difibre è un fattore di rischio infatti si è visto che le fibre alimentari sono ingrado di ridurre il livello della glicemia post-prandiale nella gravidanza.
Diabete. La prevalenza del Diabete Mellito tipo 2 aumenta in maniera pro-
gressiva, specie nel sesso femminile, fino a 70 anni. Le cause sono molteplici:
disfunzione delle cellule β pancreatiche, ridotta secrezione di insulina, ridottasensibilità insulinica (insulino-resistenza), alterazioni endocrine, alterazionimetaboliche con le ben conosciute complicanze. La pianificazione alimentaree la distribuzione di specifici principi nutrizionali svolge un ruolo fondamen-tale nella terapia del diabete. Diete ricche in fibre (35gr/die) si sono rivelateefficaci nel migliorare il controllo del diabete con riduzione della glicemia adigiuno e dopo il pasto.
Effetti della fibra sul metabolismo lipidico. 
Una dieta ricca di fibre alimentari ha un ruolo importante nel trattamento del-l’iperlipidemia, riducendo il colesterolo totale e la frazione LDL. Per spiegaretale effetto, son state formulate diverse ipotesi: - il legame tra fibre e acidi biliari rende questi ultimi indisponibili a formare
le micelle necessarie per l’assorbimento dei grassi e del colesterolo
- nei soggetti diabetici, migliorando il controllo glico-metabolico che agisce
sul metabolismo lipidico, ne limita la sintesi
- viene modulato il metabolismo dei grassi a livello epaticoI livelli di trigliceridi a digiuno e post-prandiali diminuiscono con il supple-mento di fibre solubili 
Effetti della fibra alimentare nella prevenzione del cancro del colon. L’ef-
fetto della fibra alimentare sul cancro del colon-retto è stata oggetto di po-
lemiche. La carcinogenesi è un processo biologico complesso che può essere
47Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#48,48,"legata a mutazioni genetiche ereditarie, ma è sicuramente influenzata anche
da fattori esterni, tra cui la dieta. La fibra ha effetti che potrebbero contribuiread una riduzione del rischio di malattia:
- maggiore velocità del transito intestinale- diluizione dei carcinogeni e dei promotori della carcinogenesi- maggiore eliminazione - riduzione del loro contatto con la mucosa- produzione di SCFAs con effetto protettivo sulla mucosa- abbassamento del pH che riduce la carcinogenesi- migliore risposta immunitaria (sia aspecifica che specifica)- maggiore produzione di interleuchine ed IgA
L’incidenza del cancro del colon-retto è minore in quei paesi che hanno una
dieta alimentare prevalentemente a base di fibre.
Effetti della fibra alimentare nella prevenzione di altre forma cancerose .
Dati osservazionali sul rapporto tra diete ricche in fibre ed insorgenza di di-
verse forme di cancro non hanno dato risultati consistenti. Anche se molti studicaso-controllo hanno dimostrato una riduzione del rischio di cancro al senotra donne in post-menopausa che consumano diete ricche in fibre, la maggio-ranza degli studi prospettici non ha confermato questa associazione. Esistonoalcune prove, tuttavia, che l’assunzione di cereali integrali è protettivo controil cancro al seno, e che il rischio di cancro allo stomaco è correlato inversa-mente con consumo di grano intero. 
Effetti della fibra sulla prevenzione delle malattie cardiovascolari. 
La dieta ha un ruolo nella prevenzione delle malattie cardiovascolari. Diversimeccanismi sono stati proposti per spiegare i possibili effetti protettivi dellafibra alimentare sul sistema cardiovascolare. Questi includono:- cambiamenti, ovvero riduzione, nell’assorbimento del colesterolo e nel rias-
sorbimento della bile;
- alterazioni nella produzione di lipoproteine nel fegato e cambiamenti nella
clearance delle lipoproteine ematiche;
- controllo della glicemia e sul metabolismo dell’insulina- diminuzione della densità energetica del cibo, controllo della fameTutti questi effetti possono tradursi in minori livelli plasmatici di colesterolototale e LDL e quindi ridurre alcuni dei fattori di rischio dell’aterosclerosi. Unaumento del consumo di fibre del tipo β-glucani, pectine e gomma di guar è
48Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#49,49,"associato a riduzioni significative dei livelli di colesterolo nel sangue in sog-
getti normopeso, sovrappeso od obesi, così come in soggetti iperlipidemici,anche se molti studi di intervento hanno dimostrato che questo tipo di fibreagiscono in tal senso solo in quantità più elevate di quelle di una dieta abituale.I risultati di una meta-analisi su pazienti con livelli di colesterolo elevati hamostrato che un maggior apporto di queste fibre può essere un efficace ed utilecomplemento ad altri cambiamenti dietetici come la riduzione del consumodi grassi. Anche circa il consumo di avena, crusca di avena e psyllium ci sonodati sufficienti per consigliarne il consumo. L’assunzione di cereali integraliè inversamente associato con il rischio di malattia coronarica negli uomini enelle donne, e l’assunzione di frutta e verdura è inversamente associata al ri-schio nelle donne. Vi sono anche prove che l’aumento di assunzione di fibrealimentari, aumentando il consumo di cereali integrali, frutta e verdura, in unadieta a ridotto contenuto di grassi, riduce i livelli di trigliceridi, soprattutto trai soggetti con livelli inizialmente elevati.
Effetti della fibra alimentare sull’obesità .
L’obesità ed il sovrappeso sono un eccessivo deposito di tessuto adiposo nel-
l’organismo come conseguenza dell’eccedenza dell’introito alimentare rispettoalla spesa energetica dell’organismo. Le cause possono essere diverse: - fattori genetici (spesso parenti obesi)- fattori ambientali (abitudini alimentari, lavoro)- fattori comportamentali- fattori ormonali (ipopituitarismo, ipotiroidismo, Morbo di Cushing, ipogo-
nadismo)
Gli alimenti ricchi in fibra hanno una bassa densità energetica ed occupano volume,pertanto si ritiene che potrebbero promuovere sazietà e giocare un ruolo importantenel controllo del bilancio energetico e del peso corporeo. E’ stato suggerito chealimenti con un basso indice glicemico sono più sazianti di alimenti con alto indiceglicemico. Studi di intervento, indicano che lo svuotamento gastrico può essereritardato dal consumo di fibre solubili quali le pectine. Più interessante sembranoessere gli effetti sull’intestino tenue dove, formando gel, questo tipo di fibre ral-lentano l’assorbimento dei carboidrati, li rendono meno accessibili alla digestioneenzimatica e riducono il loro contatto con la mucosa intestinale. Tutto ciò aumentail senso di sazietà. I risultati variano a seconda del tipo di fibra e se aggiunta comeintegratore isolato o se presente in fonti alimentari.
2.4 LARN 2012 e FIBRA ALIMENTARE
49Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#5,5,"Introduzione
Le scoperte degli ultimi decenni hanno messo in luce molti aspetti nuovi ed
interessanti riguardo al rapporto tra l’uomo e il cibo. E’ oramai chiaro che glialimenti non sono solo una fonte di molecole in grado di fornire, una voltametabolizzate, energia o nutrienti utili per la crescita ed il sostentamento delnostro organismo, ma piuttosto contengono molecole in grado d’influenzarel’espressione genica, il funzionamento di enzimi e proteine e, persino, il nostroatteggiamento nei confronti dei cibi stessi. Ciò è possibile grazie a complicatimeccanismi molecolari che permettono di integrare un numero elevatissimodi informazioni provenienti da organi e tessuti differenti, ognuno dei qualipresenta una propria specificità d’azione e funzioni fisiologiche ben definite.Ciò significa che la comprensione dei fenomeni fisiologici legati allanutrizione umana non possa prescindere dalla conoscenza di tali meccanismie del ruolo che i singoli componenti alimentari, nutrienti e non, svolgono nelnostro organismo.Tuttavia anche tale operazione, seppur perpetuata in modo rigoroso, puòrilevarsi del tutto inutile e non adeguata a descrivere le reali esigenzenutrizionali della maggior parte delle persone. L’uomo è infatti un animalemolto complesso, non standardizzabile o riconducibile facilmente ad unsemplice modello matematico. Il fenotipo umano è infatti il risultato dicombinazioni genotipiche uniche molte delle quali, seppur possano convergereverso fenotipi apparentemente simili, presenteranno sempre aspetti peculiaried unici.In ultima istanza, non dobbiamo dimenticare che altri fattori indipendenti qualigli stimoli provenienti dall’ambiente esterno e lo stile di vita possonoinfluenzare e pesantemente sia le nostre esigenze alimentari che il nostrocomportamento alimentare, contribuendo così a complicare, non poco, ilquadro generale.Il manuale di “Fondamenti della Scienza della Nutrizione” che la commissione“NUTRIZIONE” dell’Ordine dei Biologi propone, ha come obbiettivo quellodi affrontare la nutrizione umana da differenti punti di vista. L’obbiettivo èstato quello di generare, per la prima volta, un manuale che possa essereutilizzato come testo di riferimento da tutti coloro i quali intendono affrontarela professione del Biologo Nutrizionista.Il manuale, passo dopo passo, guida il lettore, attraverso un percorso lineareche permette di acquisire, progressivamente, tutti gli elementi utili adinterpretare la maggior parte dei complicati meccanismi che permettono di
5Introduzione Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#50,50,"SDT- Obiettivi Nutrizionali per la Prevenzione
Preferire alimenti naturalmente ricchi in fibre alimentari quali cereali integrali,legumi, frutta e verdura. Negli adulti consumare almeno 25g/die di fibra ali-mentare anche in caso di apporti energetici < 2000Kcal/dieAI- Assunzione adeguataEtà evolutiva (≥ 1 anno) 8,4g/1000 Kcal (2 MJ)
RI- Intervallo di Riferimento per l’Assunzione di Macronutrienti
Adulti 12,6-16,7 g/1000 Kcal (3,4 g/MJ)
Effetti collaterali di dosi eccessive: distensione addominale, coliche addomi-
nali per eccessiva produzione di gas e diarrea. La tolleranza è individuale.
PRINCIPALI ALIMENTI RICCHI IN FIBRA
Legumi: fagioli, fave, ceci, lenticchie, piselli Cereali e derivati : pasta, biscotti, pane e cereali da colazione (soprattutto se
integrali), prodotti da forno, orzo perlatoVerdura e ortaggi : carciofi, cavoli, cicoria, carote, melanzane, barbabietole,
funghi, agretti, finocchiFrutta fresca: pere, mele, fichi, banane, kiwi, lamponi, fichi d’India, ribesFrutta secca in guscio: noci, nocciole, mandorleFrutta essiccata: albicocche secche, fichi secchi, mele essiccate, uva passa,prugne secche, castagne secche
50Fondamenti della Scienza dell’Alimentazione Capitolo II"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#51,51,"Percentuale di fibra per 100g di peso nei principali alimenti
CEREALI %
Crusca di grano 44,0
Farina integrale 9,6
Farina bianca 3,0
Farina di soia 14,3
Riso integrale lessato 5,5
Riso bianco lessato 0,8
Pane integrale 8,5
Pane misto 5,1
Pane bianco 2,7
All Brain (crusca) 26,7
Cornflakes 11,0
Muesli 7,4FRUTTA FRESCA E SECCA %
More 7,3
Uva 6,8
Mirtilli 4,2
Banane 3,4
Pere 3,4
Fragole 2,3
Prugne 2,1
Mele 2,0
Arance 2,0
Mandorle 14,3
Arachidi 8,2
Nocciole 6,2
VERDURE %
Ravanelli 8,3
Spinaci lessati 6,3
Carote lessate 3,0
Carote crude 2,9
Cavoletti di Bruxelles, 
broccoli lessati 2,9
Patate al forno con la buccia 2,0
Cavolfiore, verza lessati 1,8
Lattuga 1,5
Pomodori 1,5LEGUMI %
Piselli congelati lessati 12,0
Fagioli lessati 7,4
Fave lessate 5,1
Lenticchie lessate 3,7
51Capitolo II Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#52,52,"Bibliografia 
• American Association of Cereal Chemists. AACC Dietary Fiber Technical Committee. The
definition of dietary fiber. Cereal Foods World 2001
• Food and Agriculture Organization of the United Nations/World Health Organization.
Carbohydrates in Human Nutrition. Report of a Joint FAO/WHO Expert Consultation,
FAO/WHO, Rome, Italy, 1998
• John F. Howlett et al.The definition of dietary fiber – discussions at the Ninth Vahouny Fiber
Symposium: building scientific agreement - Food Nutr Res. 2010
• Miller Jones J. Dietary fibre intake, disease prevention, and health promotion: An overview
with emphasis on evidence from epidemiology. In: Bioactive Carbohydrates for Food andFeed. JW van der Kamp ed. Academic Publishers, Wageningen, 2004, Netherlands
• World Health Organization. Diet, nutrition and the prevention of chronic diseases. Report
of a Joint WHO/FAO Expert Consultation. WHO Technical Report Series 916, Geneva, 2003
• Watzl B, Girrbach S, Roller M. Inulin, oligofructose and immunomodulation. Br J Nutr.
2005 Apr
• Clayton BD, et al. BNF-TasK Force on Complex Carbohydrates in Foods• Chapman and Hall I ed; 11 New fetter Lane, London 1990. • Bassotti G, Iantorno G, Fiorella S et al. Colonic motility in man: features in normal subjects
and in pz. with chronic idiopathic constipation. Am J Gastroenterol 1999.
• Anderson JW, Chen WL. Plant fiber: carbohydrate and lipid metabolism. Am J Clin
Nutr1979
• Eglash A, Lane CH, Scheider DM. Clinical inquires. What is the most beneficial diet for
Patients with diverticulosis? J Fam Pract. 2006 Sep
• HoweGR, Benitu E, Castelleto R et al. Dietary intake of fiber and decreased risk of cancer
and rectum.Evidence from combined analysis of 13 case-control-studies. J Nat CancerInst.1992
• SINU (Società Italiana di nutrizione Umana). LARN – Livelli di Assunzione di Riferimento
di Nutrienti ed energia per la popolazione italiana. Revisione 2012
52"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#53,53,53Capitolo III Fondamenti della Scienza dell’Alimentazione
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#54,54,"CAPITOLO III
Metabolismo dei Carboidrati
Riassunto
I carboidrati o glucidi sono sostanze chimiche composte da carbonio, idro-
geno e ossigeno. I carboidrati più semplici sono i monosaccaridi mentre i di-saccaridi sono costituiti da 2 monosaccaridi. I polisaccaridi sono costituitida un numero elevato di monosaccaridiL’assunzione complessiva raccomandata di carboidrati si aggira sul 60%della razione alimentare, suddivisa tra zuccheri semplici (circa 15%) e poli-saccaridi (circa 45%).La loro metabolizzazione inizia nel cavo orale dove la ptialina è capace didemolire i legami alfa-1-4 ma non i legami a-1-6. Si formano così le primemolecole di destrine, maltosio e glucosio. Nello stomaco a casa degli acidigastrici che aumentano il pH la digestione viene momentaneamente sospesa.L’idrolisi poi riprende nell’intestino dove il pH è leggermente basico ad operadella alfa-milasi pancreatica. I prodotti finali della digestione dei carboidrati,i monosaccaridi glucosio, fruttosio, mannosi e galattosio, sono assorbiti dallecellule epiteliali intestinali ed entrano nel sangue. Il fattore condizionante ilmetabolismo glucidico nell’organismo è il mantenimento della glicemia entrovalori ben precisi, mediante l’attività antagonista di due ormoni, l’insulinaed il glucagone.La glicolisi, è il processo di ossidazione anaerobico che avviene nel citopla-sma per mezzo del quale le cellule possono ricavare energia dal glucosio senzala presenza di ossigeno. La glicolisi è una sequenza di reazioni che converteil glucosio in acido piruvico (piruvato), con concomitante produzione di ATP .Avviene nel citoplasma delle cellule di tutti i tessuti. E’ il preludio al ciclodell’acido citrico (ciclo di Krebs) ed alla catena di trasporto degli elettroni,con cui viene recuperata la maggior parte dell’energia contenuta nella mole-cola di glucosio. La gluconeogenesi è il processo di sintesi di glucosio a par-tire da precursori non glucidici, che consente il mantenimento dell’omeostasiglicemica, quando le riserve di glicogeno sono esaurite e/o l’apporto glucidicodella dieta è insufficiente. La gluconeogenesi avviene nel citoplasma delle cel-lule epatiche a partire dall’acido piruvico, principalmente in condizioni di di-giuno fra un pasto e l’altro. La glicogenosintesi è la formazione di glicogeno(polimero del glucosio) a partire dal glucosio. Questo processo avviene nel
54Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#55,55,"muscolo e nel fegato dopo un pasto ricco di carboidrati.
La glicogenolisi rappresenta la via di degradazione del glicogeno per ottenereglucosio 6-fosfato: il glicogeno è trasformato in glucosio 1-fosfato dall’enzimafosforilasi e successivamente in glucosio 6-fosfato dall’enzima fosfoglucomu-tasi. La glicogenolisi avviene principalmente nel fegato per mantenere costantii livelli di glucosio ematico.Il Ciclo dei Pentosi o Shunt dell’Esoso Monofosfato è una via alternativa allaglicolisi per la demolizione della molecola del glucosio, avviene nel citopla-sma cellulare e riveste particolare importanza per il fegato, tessuto adiposo,rene, eritrociti dove ha la funzione di produrre NADPH per le biosintesi diacidi grassi, produrre ribosio e pentosi per la sintesi dei nucleotidi, produrreenergia attraverso la formazione di intermedi della via gli colitica.Il ciclo di Krebs, la catena di trasporto degli elettroni e la fosforilazione os-sidativa costituiscono il metabolismo ossidativo terminale, nel quale i prodottidel metabolismo intermedio vengono completamente bruciati a CO
2ed H2O.
In condizioni di aerobiosi, l’acido piruvico prodotto durante la glicolisi entranel mitocondrio per essere completamente ossidato attraverso il ciclo diKrebs. Quando il glucosio viene ossidato completamente a CO
2ed H2O, si ge-
nerano in totale 30 o 32 ATP .
55Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#56,56,"3.1 I Carboidrati o Glucidi
I glucidi, chiamati anche (impropriamente) carboidrati, sono sostanze chimi-
che composte da carbonio, idrogeno e ossigeno e possono essere definiti comederivati aldeidici o chetonici di alcoli polivalenti.I glucidi hanno formula elementare C
n(H2O)n. Presentano dei gruppi -OH,
quindi possono essere considerati alcoli polivalenti, e un gruppo aldeidico (al-dosi) o un gruppo chetonico (chetosi).I carboidrati più semplici sono i monosaccaridi. Ad esempio ribosio, galattosio
e glucosio sono monosaccaridi aldosi; il fruttosio è un monosaccaride chetoso.Dal punto di vista biochimico, il glucosio può essere considerato il capostipitedi tutti i glucidi (Figura 1).
Figura 1: struttura chimica del glucosio e del fruttosio
Più unità di monosaccaridi (da 2 a migliaia) possono legarsi con un legameglicosidico che si stabilisce tra un gruppo -OH di un monosaccaride in posi-zione 1 ed un gruppo -OH di un altro monosaccaride, con perdita di una mo-lecola di H
2O.
I disaccaridi sono costituiti da 2 monosaccaridi. Sono disaccaridi il saccarosio
(glucosio + fruttosio), il lattosio (glucosio + galattosio), il maltosio (glucosio+ glucosio) (Figura 2).
56Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#57,57,"Figura 2: struttura chimica di alcuni disaccaridi
I polisaccaridi sono costituiti da un numero elevato di monosaccaridi. Sono
polisaccaridi:
3) glicogeno: catena ramificata di α-D-glucosio con legami α-1,4- ed α-1,6-
glicosidici (Figura 3)
4) cellulosa : catena lineare di β-D-glucosio con legami β-1,4-glicosidici
5) amilosio: catena lineare di α-D-glucosio con legami α-1,4-glicosidici
6) amilopectina : catena ramificata di α-D-glucosio con legami α-1,4- ed α-
1,6-glicosidici
7) amido: costituito da amilosio ed amilopectina
57Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#58,58,"Figura 3: struttura chimica del glicogeno
3.2 Classificazione
I carboidrati si classificano in:-Monosaccaridi
Sono i glucidi più semplici e contengono da 3 a 9 atomi di carbonio; quellid’importanza biologica comprendono il glucosio, il fruttosio ed il galattosio.Il glucosio è scarsamente presente in natura, a parte piccolissime quantità nellafrutta e nella verdura. Il fruttosio è presente come tale nella frutta e nel miele. 
-DisaccaridiSi possono considerare come l’unione di due molecole di monosaccaridi me-diante legami glicosidici; quelli d’importanza biologica comprendono il sac-carosio, il lattosio e il maltosio.Il saccarosio è composto da glucosio + fruttosio e si trova nella frutta, spe-cialmente nella barbabietola e nella canna, da cui è estratto per produrre lozucchero da tavola.Il lattosio è contenuto nel latte ed è formato da glucosio + galattosio. Il mal-tosio (glucosio + glucosio) deriva dalla fermentazione (o dalla digestione)dell’amido.
-OligosaccaridiIl termine oligosaccaridi è usato generalmente per i composti formati da 3 a10 monosaccaridi. A questo gruppo appartengono il raffinosio, lo stachiosio
58Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#59,59,"ed il verbascosio non digeribili per l’uomo, composti da galattosio, glucosio
e fruttosio e contenuti soprattutto nei legumi. La produzione di gas a seguitodella fermentazione di questi zuccheri nell’intestino crasso spiega il meteo-rismo provocato, soprattutto in alcuni soggetti, dal consumo di leguminose.
-PolisaccaridiIl termine polisaccaridi è usato generalmente per i composti formati da piùdi 10 monosaccaridi.Essi si dividono in:• omopolisaccaridi, costituiti da un solo tipo di monosaccaride (esempio:
glicogeno)
• eteropolisaccaridi costituiti da più di un tipo di monosaccaridi (esempio:
mucopolisaccaridi, presenti nei tessuti connettivi degli animali)
I polisaccaridi più importanti per l’alimentazione umana sono l’amido e il gli-cogeno.L’amido costituisce la riserva energetica del mondo vegetale: le principali sor-
genti sono: i cereali (pane, pasta, riso) e le patate. E’ presente sotto forma digranuli a struttura semicristallina: la cottura dei cibi altera tale struttura (pro-cesso di gelatinizzazione), rendendo l’amido digeribile. Il raffreddamento deicibi, che conduce a parziali fenomeni di ricristallizzazione dell’amido, ne ri-duce parzialmente la digeribilità.Il glicogeno è d’origine animale. Negli alimenti (carne, fegato) il suo contenuto
tuttavia è privo di significato nutrizionale essendo presente in minime quantità(lo stato di anossia che segue la morte dell’animale lo trasforma in acido lat-tico).Gli altri polisaccaridi non-amidacei sono ampiamente diffusi in natura, manon sono rilevanti a scopo nutrizionale, poiché non possono essere digeritidall’uomo per mancanza degli enzimi necessari.
3.3 Funzioni dei glucidi
I glucidi presentano una duplice funzione:
- Plastica , entrano nella costituzione di strutture essenziali per gli organismi
viventi
-Energetica, forniscono all’organismo energia per le prestazioni funzionali 
I glucidi, sebbene nel mondo animale siano meno abbondanti delle proteine,
59Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#6,6,"regolare il metabolismo umano, senza tuttavia mai eccedere con i tecnicismi
scientifici o dilungarsi nella descrizione di particolari non strettamente utilialla formazione del Biologo Nutrizionista. La nutrizione costituisce il punto d’incontro di una moltitudine di disciplinebiomediche ma sempre più sta divenendo un campo di informazioni confusoin cui anche il professionista trova difficoltà ad orientarsi. L’attività delnutrizionista deve essere considerata nell’ottica di conoscenze scientificheaggiornate che spaziano dagli aspetti fisiologici, biochimici, genetici epatologici, al fine di garantire reali effetti benefici per la salute umana e per ilbenessere.Il testo rappresenta anche un mezzo pratico e di facile consultazione perinformazioni basilari rivolto non solo ai Nutrizionisti ma anche a tutti iProfessionisti della Biologia che potranno usufruire di uno strumento diindagine agile e semplice per affrontare in maniera rigorosa gli aspetti dellanutrizione umana.  
6Fondamenti della Scienza dell’Alimentazione Introduzione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#60,60,"hanno un’importanza metabolica fondamentale, perché rappresentano la sor-
gente primaria da cui le cellule ricavano l’energia. Sono quindi il materiale chi-mico indispensabile per lo svolgimento delle diverse forme di lavoro biologico.Nell’uomo, le cellule si alimentano sottraendo glucosio dal sangue, dove èpresente in concentrazione di 70-110 mg/100 ml. Quando il tasso ematico di-minuisce drasticamente (valori inferiori a 40 mg/100 ml), le cellule nervosene soffrono e si ha il coma ipoglicemico .
Quando i glucidi non sono introdotti in misura sufficiente con l’alimentazione,il fegato trasforma gli amminoacidi o il glicerolo (ottenuto dalla degradazionedei grassi), in glucosio (gluconeogenesi). Il fegato è anche dotato di una riservadi glucosio polimerizzato in lunghe catene ramificate, il glicogeno , che è uti-
lizzato attraverso la glicogenolisi per mantenere costante la glicemia. I glucidi hanno anche un ruolo strutturale. L’acido ialuronico, un eteropoli-saccaride, è un costituente essenziale del connettivo, del fluido sinoviale edell’umor vitreo. Le glicoproteine sono una classe di proteine coniugate con-tenenti da 1% ad 80% di sostanze glucidiche, che svolgono funzioni diverse.Ricordiamo inoltre che i glucidi entrano nella struttura di altri composti comenucleosidi, coenzimi, glicolipidi. 
3.4 Fabbisogno giornaliero
Dal momento che l’organismo ha la capacità di sintetizzare i glucidi da altre
sostanze, i carboidrati non possono essere considerati nutrienti propriamenteessenziali; esiste tuttavia la necessità di mantenere il livello di glicemia entroun intervallo di valori adeguato al fabbisogno del sistema nervoso centrale edegli eritrociti (globuli rossi).Acido citrico Frutta Assorbiti come taliL’assunzione complessiva raccoman-data di carboidrati si aggira sul 60% della razione alimentare, suddivisa tra zuc-cheri semplici (circa 15%) e polisaccaridi (circa 45%). Gli alimenti contenenticarboidrati complessi, oltre a fornire energia a più lento rilascio rispetto a quellisemplici, apportano anche altri nutrienti fondamentali all’equilibrio generaledella dieta: questo aspetto è rilevante soprattutto quando è necessario mantenerel’apporto energetico complessivo entro limiti relativamente modesti.
60Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#61,61,"3.5 Digestione dei carboidrati
I più comuni carboidrati della dieta sono l’amido, il saccarosio ed il lattosio.
L’amido, il polisaccaride di riserva delle piante, è formato da due componenti
l’α-amilosio e l’amilopectina . L’amilosio e l’amilopectina sono formati en-
trambi da molecole di glucosio unite fra loro con legami glicosidici α-1,4, ma
nell’amilopectina, ramificata, vi sono anche catene laterali unite alla catenaprincipale mediante legami glicosidici α-1,6. Più della metà dei carboidrati
ingeriti dall’uomo è costituita dall’amido.Nel cavo orale, l’ α-amilasi agisce spezzando i legami α-1,4 tra i residui di
glucosio all’interno della molecola di amido, formando frammenti più sem-plici, le destrine. Le destrine prodotte sono le amilodestrine, le eritrodestrine,Prodotti terminaliGLUCIDI Principali sorgenti alimentaridella digestione
POLISACCARIDI
Cellulosa Gambo o foglie di vegetali Non digeribile
Pectine Frutta Non digeribile
Inulina Carciofi, cipolle, aglio Non digeribile
Amido Tessuti di deposito vegetali 
(patate e altri tuberi, legumi) Glucosio
Destrine - Glucosio
Glicogeno Carne e pesce Glucosio
DISACCARIDI
Saccarosio Zucchero di canna e di bietola Glucosio e Fruttosio
Lattosio Latte e derivati Glucosio e Galattosio
Maltosio Prodotti del malto, biscotti Glucosio
MONOSACCARIDI
Glucosio Frutta, miele, sciroppo Glucosio
Fruttosio Frutta e miele Fruttosio
Galattosio - Galattosio
DERIV ATI DA GLUCIDI
Alcol etilico Bevande fermentate Assorbiti come tali
Acido lattico Latte e derivati Assorbiti come tali
Acido malico Frutta Assorbiti come tali
61Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#62,62,"le acrodestrine e la destrina limite formata da tre residui, legati con legame
glicosidico α-1,4, ed uno legato con legame glicosidico α-1,6.
I prodotti digestivi entrano nello stomaco dove però l’acidità gastrica inibisce
l’azione dell’ α-amilasi. Il contenuto dello stomaco passa quindi nell’intestino
dove il bicarbonato secreto dal pancreas neutralizza l’acidità gastrica, facendoinnalzare il pH ai limiti ottimali per l’azione degli enzimi intestinali e pancreatici.Il pancreas secerne inoltre α -amilasi pancreatica che entra nel lume dell’intestino
tenue e continua il processo digestivo. L’ α-amilasi pancreatica, come l’enzima
salivare, spezza i legami α-1,4 fra i residui di glucosio all’interno della catena.
I prodotti dell’ α-amilasi pancreatica sono il disaccaride maltosio, il trisaccaride
maltotrioso e piccoli oligosaccaridi contenenti legami α-1,4 ed α -1,6.
Gli enzimi prodotti dalle cellule epiteliali intestinali e localizzati sull’orlettoa spazzola continuano il processo digestivo:- Una α-glucosidasi idrolizza residui di glucosio dall’estremità non riducente
degli oligosaccaridi. Questo enzima idrolizza anche i legami α-1,4 del
maltosio, rilasciando due molecole di glucosio.
- Una α-destrinasi idrolizza i legami α-1,6, rilasciando residui di glucosio
dagli oligosaccaridi ramificati. I disaccaridi della dieta sono digeriti daenzimi presenti sull’orletto a spazzola delle cellule epiteliali intestinali.
- La saccarasi converte il saccarosio in glucosio e fruttosio.
- La lattasi converte il lattosio in glucosio e galattosio.
I prodotti finali della digestione dei carboidrati, i monosaccaridi glucosio, frut-
tosio (derivato dall’idrolisi del saccarosio), mannosio (epimero del glucosio) ,
galattosio (derivato dall’idrolisi del lattosio), sono assorbiti dalle cellule epi-
teliali intestinali ed entrano nel sangue. Polisaccaridi indigeribili come la cel-
lulosa (che consiste di unità di glucosio legate da legami glicosidici α-1,4)
fanno parte delle fibre alimentari, che passano attraverso l’intestino alle feci.
AssorbimentoI monosaccaridi (glucosio, fruttosio, mannosio, galattosio) liberatisi a livello
intestinale dopo i processi di digestione ed assorbimento dei carboidrati delladieta, passano dall’enterocita alla vena porta e quindi giungono al fegato.La membrana cellulare epatica è liberamente permeabile al glucosio (la suaconcentrazione negli epatociti è uguale a quella plasmatica) ed il suo trasportonella cellula è indipendente dalla disponibilità di insulina. Entrato nell’epato-cita, il glucosio e gli altri monosaccaridi sono trasformati in glucosio 6-fosfato.L’attività dell’enzima glucochinasi è stimolata dall’insulina favorendo l’uti-
62Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#63,63,"lizzazione di glucosio. Una parte del glucosio attraversa il fegato e passa in
circolo, ma una volta fosforilato a glucosio 6-fosfato non è in grado di attra-versare la membrana plasmatica.
Consumo di glucosio in condizioni basaliIl fattore condizionante il metabolismo glucidico nell’organismo è il mante-
nimento della glicemia entro valori ben precisi, mediante l’attività antagonista
di due ormoni, l’insulina ed il glucagone.
Insulina e glucagone
L’insulina è un ormone proteico prodotto dalle cellule beta delle isole di Lan-gerhans ed è il principale regolatore del metabolismo intermedio agendo comeormone anticatabolico. Quando i livelli di insulina nel sangue sono bassi, mas-sima è la produzione di glucosio e minima la sua utilizzazione; essa, infatti, fun-ziona come ipoglicemizzante, permettendo l’assorbimento cellulare del glucosioematico. Nel fegato l’insulina stimola la glicogenosintesi, inibendo la glicoge-nolisi. Nel muscolo l’insulina favorisce la formazione del glicogeno, la sintesiproteica e l’immagazzinamento degli amminoacidi. Nel tessuto adiposo l’insu-lina ha sia un effetto lipogenico (stimola la formazione dei trigliceridi) sia uneffetto antilipolitico, ovvero inibisce la degradazione dei trigliceridi.La riserva di glicogeno epatico utilizzabile è circa 70-100 g, non sufficientiper mantenere la glicemia più a lungo di 24 ore, perciò è necessario ripristinarequesta riserva con l’assunzione di cibo. Il glicogeno muscolare non è utilizza-bile per regolare la glicemia, ne risulta disponibile per altri tessuti non essendoespresso a livello del tessuto muscolare, come anche nel cervello, l’enzimaglucosio-6-fosfatasi. Tale enzima defosforila il glucosio-6-fosfato riformandoglucosio che può, invece, attraversare la membrana cellulare.Durante il digiuno, l’azione dell’insulina è minima e massima è l’azione di unaltro ormone proteico prodotto dalle cellule alfa delle isole di Langerhans: ilglucagone. Il glucagone ha un effetto iperglicemizzante: stimola la liberazionedi glucosio dai tessuti. Nel tessuto adiposo il glucagone stimola la lipolisi, nelfegato la gluconeogenesi e la glicogenolisi; nei muscoli stimola la degrada-zione delle proteine in amminoacidi.Nell’uomo, a digiuno il tasso ematico del glucosio è 70-110 mg per 100 ml disangue. Il 50% del glucosio ematico è utilizzato dal cervello ed il resto daiglobuli rossi e bianchi e dal muscolo scheletrico. L’origine di tale glucosio èepatica, attraverso la glicogenolisi (75%) e la gluconeogenesi (25%). 
63Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#64,64,"Destino metabolico del glucosio dopo un pasto
Subito dopo un pasto, i livelli di glucosio possono aumentare a 120-130 mg
per 100 ml di sangue e possono raggiungere livelli anche superiori (fino a170). L’equilibrio basale è ristabilito dopo 90-120 minuti nel corso dei qualiil 15-20% del glucosio è utilizzato dai tessuti insulino-dipendenti (soprattuttotessuto adiposo e muscolo scheletrico). Circa il 25% è utilizzato dai tessuti in-sulino-indipendenti (cervello, globuli rossi), mentre il rimanente 55-60% èutilizzato dal fegato (glicogenosintesi, glicolisi, sintesi degli acidi grassi). Nel fegato, una quantità relativamente piccola di glucosio epatico è ossidataa CO
2ed H2O attraverso il ciclo di Krebs, mentre la maggior parte dell’ATP
richiesto dal fegato deriva dall’ossidazione di acidi grassi ed amminoacidi. Inconfronto ad altri tessuti, quali muscolo e cervello, la quantità di glucosio me-tabolizzato nel fegato attraverso la via glicolitica è piccola: l’obiettivo dellaglicolisi epatica è quello di produrre acido piruvico da convertire poi in ace-til-CoA ed infine in acidi grassi (Figura 4).Circa la metà del glucosio metabolizzato nel fegato entra nello shunt deipentosi, che produce NADPH+H
+per la sintesi degli acidi grassi.
Il glucosio può essere utilizzato inoltre nella formazione di acido glucuronico,oltre che per la sintesi di mucopolisaccaridi, glicoproteine e glicolipidi.L’eccesso di glucosio epatico è in gran parte trasformato ed immagazzinatosotto forma di glicogeno attraverso la via della glicogenosintesi, che rappre-senta così la principale utilizzazione epatica del glucosio 6-fosfato.
64Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#65,65,"Figura 4: Utilizzazione e produzione di glucosio 6-fosfato (glucosio 6-P) nel fegato.
La funzione principale del fegato nel metabolismo dei glucidi è legata alla sua
attività glucostatica: è in grado di “tamponare” le variazioni della glicemia aseguito di modificazioni metaboliche e/o variazioni dell’apporto nutrizionale. Il fegato mantiene l’omeostasi glucidica attraverso:
- Immagazzinamento di glucosio in forma di glicogeno.
- Rilascio di glucosio dal glicogeno.- Utilizzazione del glucosio (glicolisi, shunt dell’esosomonofosfato).- Sintesi di glucosio mediante gluconeogenesi.- Conversione di glucidi in acidi grassi.
3.6 GlicolisiLa glicolisi è una sequenza di reazioni che converte il glucosio in acido piru-
vico (piruvato), con concomitante produzione di ATP (Figura 5). La glicolisisi compie nel citoplasma delle cellule di tutti i tessuti. E’ il preludio al ciclodell’acido citrico (ciclo di Krebs) ed alla catena di trasporto degli elettroni,con cui viene recuperata la maggior parte dell’energia contenuta nella mole-cola di glucosio.
65Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#66,66,"3.6.1 Le reazioni della glicolisi
• Il glucosio è convertito a glucosio 6-fosfato in una reazione che utilizza ATP
e produce ADP. Enzimi: esochinasi e, nel fegato, glucochinasi, ambedue
soggetti a meccanismi di regolazione.
• Il glucosio 6-fosfato è isomerizzato a fruttosio 6-fosfato. Enzima:
fosfoglucoisomerasi.
• Il fruttosio 6-fosfato è fosforilato dall’ATP. Si formano fruttosio 1,6-bifosfato
e ADP. Enzima: fosfofruttochinasi .
• Il fruttosio 1,6-bifosfato è scisso a formare i due trioso-fosfati, gliceraldeide
3-fosfato e diidrossiacetone fosfato. Enzima: aldolasi.
• Il diidrossiacetone fosfato è isomerizzato a gliceraldeide 3-fosfato. Enzima:
triosofosfato isomerasi.
Come risultato netto delle reazioni sopra riportate, si formano due moli di gli-
ceraldeide 3-fosfato da una mole di glucosio con consumo di due moli di ATP.• La gliceraldeide 3-fosfato è ossidata dal NAD
+e reagisce con fosfato
inorganico (Pi). Si formano 1,3 bifosfoglicerato (acido 1,3 bifosfoglicerico)
e NADH + H+. Enzima: gliceraldeide 3-fosfato deidrogenasi .
• Il gruppo aldeidico della gliceraldeide 3-fosfato è ossidato ad acido che
forma un’anidride ad alta energia con il fosfato inorganico. L’energia delgruppo anidridico del 1,3-bifosfoglicerato è sfruttata per produrre ATP daADP in una reazione al termine della quale si forma 3-fosfoglicerato.Enzima: fosfoglicerato chinasi .
• Il gruppo fosfato del 3-fosfoglicerato è trasferito al carbonio 2, con
formazione di 2-fosfoglicerato. Enzima: fosfogliceromutasi.
• Al 2-fosfoglicerato viene sottratta una molecola di acqua, formando fosfoenol -
piruvato, che presenta un gruppo fosforico ad alta energia. Enzima: enolasi.
• Nell’ultima reazione glicolitica da fosfoenolpiruvato si forma piruvato, con
contemporanea formazione di ATP da ADP. Enzima: piruvato chinasi .
3.6.2 Gli enzimi di regolazione della glicolisi
Esochinasi
L’esochinasi si trova nella maggior parte degli organi e tessuti ed ha il compitodi trasformare il glucosio in glucosio 6-fosfato da immettere nella via glicolitica.Ha una bassa Km per il glucosio, è inibita dal suo prodotto, il glucosio 6-fosfato:quindi è attiva quando il glucosio 6-fosfato viene rapidamente utilizzato.
66Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#67,67,"Figura 5: reazioni della glicolisi
67Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#68,68,"Glucochinasi
La glucochinasi si trova nel fegato e funziona ad una velocità apprezzabile su-bito dopo un pasto. Ha un’alta K
mper il glucosio, quindi è molto attiva subito
dopo un pasto, quando il livello di glucosio nella vena porta è alto, e relativa-mente non attiva durante le fasi di digiuno quando i livelli di glucosio sonobassi. La glucochinasi non è inibita da glucosio 6-fosfato.
Fosfofruttochinasi
La fosfofruttochinasi funziona a ritmo elevato quando le cellule necessitanodi ATP o, nel caso del fegato, quando il glucosio ematico è elevato. E’ inibitada acido citrico (prodotto nel ciclo di Krebs) ed ATP: quando la cellula pre-senta elevate concentrazioni di ATP, la glicolisi viene inibita.
Piruvato chinasi
La piruvato chinasi è inibita nel fegato durante le fasi di digiuno, quando i li-velli dell’ormone glucagone sono alti. L’inibizione della piruvato chinasi fa-vorisce la gluconeogenesi.
3.6.3 Destini metabolici dell’acido piruvico Conversione in Acetil-CoA
Il principale destino metabolico dell’acido piruvico è la sua completa ossida-zione attraverso il ciclo di Krebs, nella matrice mitocondriale, dove è traspor-tato mediante carriers e trasformato in Acetil-CoA. La reazione è catalizzatadal complesso multienzimatico della piruvato deidrogenasi.
piruvato deidrogenasiPiruvato + CoA + NAD+
Acetil CoA+CO2+NADH+H+
piruvato deidrogenasi
Formazione di acido ossalaceticoL’acido piruvico può essere convertito ad acido ossalacetico dalla piruvato car-
bossilasi, che si trova in tessuti come fegato e cervello, ma non nel muscolo.
Conversione ad alaninaL’acido piruvico può essere transaminato per formare l’amminoacido alanina(vedi metabolismo proteico).
68Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#69,69,"Formazione di acido lattico
Dal piruvato si può formare acido lattico quando la quantità di ossigeno adisposizione è limitata, come durante un’intensa attività muscolare. L’acido lattico si ottiene per riduzione dell’acido piruvico utilizzando NADHprodotto nella glicolisi. La reazione è catalizzata dall’enzima lattico
deidrogenasi (LDH).
lattico deidrogenasiPiruvato + NADH+ H+Lattato + NAD+
La riossidazione del NADH durante la conversione del piruvato a lattatopermette alla glicolisi di continuare a funzionare in condizioni di anaerobiosi.Se il NAD
+non fosse rigenerato, la glicolisi si fermerebbe a gliceraldeide 3-
fosfato, quindi non potrebbe essere prodotto ATP.Soltanto una piccola parte dell’energia del glucosio viene utilizzata nel casodella conversione anaerobia a lattato. Molta più energia può essere estratta incondizioni aerobie per mezzo del ciclo di Krebs e della catena respiratoria chesaranno trattati più avanti. Il vantaggio di questa via alternativa è la rigenerazione di NAD
+che può far
continuare il processo demolitivo del glucosio.Lo svantaggio risiede nel fatto che l’acido lattico è un catabolita tossico per lacellula. Lo smaltimento di questa molecola dalle cellule muscolari avvienemolto lentamente: il suo accumulo provoca affaticamento fisico, e, se la con-centrazione nel sangue supera il valore di 0,5 mg/ml, il processo di contrazionemuscolare si blocca e sopravviene un crampo muscolare.L’acido lattico viene trasportato al di fuori della cellula nel flusso sanguignoed inviato al fegato, dove viene riossidato ad acido piruvico e questo di nuovotrasformato in glucosio mediante la gluconeogenesi. Il glucosio dal fegatopassa nel sangue e da qui ancora nel muscolo, dove può avere inizio unulteriore processo glicolitico.Il processo metabolico seguito dall’acido lattico ha un andamento ciclico eprende il nome di Ciclo di Cori (Figura 6).
69Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#7,7,"CAPITOLO I - I MACRO e MICRONUTRIENTI
1.1 - I Micronutrienti1.1.1 I Sali Minerali1.1.2 VitamineVitamine idrosolubili Vitamine liposolubili 
1.2 I Macronutrienti
1.2.1 CarboidratiClassificazione dei glucidi1.2.2 LipidiClassificazione e funzione dei lipidi1.2.3 ProteineClassificazione e funzione delle proteine Bibliografia
CAPITOLO II - ACQUA E FIBRA ALIMENTARE
2.1 Acqua2.2.1 Larn e acqua2.2 Fibra alimentare2.2.1 Fibra insolubile2.2.2 Fibra solubile2.3 Ruolo fisiologico della fibra alimentare e benefici per la saluteFermentazione colicaPrincipali alimenti ricchi in fibra2.4 LARN 2012 e FIBRA ALIMENTAREBibliografia
CAPITOLO III - METABOLISMO DEI CARBOIDRATI
I Carboidrati o GlucidiClassificazioneFunzioniFabbisognoDigestione dei CarboidratiAssorbimentoConsumo di glucosio in condizioni basaliDestino metabolico del glucosio dopo un pastoGlicolisi
7Indice Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#70,70,"Gli eritrociti, cellule specializzate nel trasporto di ossigeno, non contengono
mitocondri. In tali organelli citoplasmatici avvengono il ciclo di Krebs e lafosforilazione ossidativa, per cui l’unico modo per estrarre energia dal glucosioin queste cellule è la formazione di acido lattico da piruvato. 
Conversione dell’acido piruvico ad etanolo
Nel lievito ed in parecchi microorganismi l’acido piruvico viene trasformatoin etanolo. Il primo passaggio è la decarbossilazione dell’acido piruvico adacetaldeide catalizzata dall’enzima piruvato decarbossilasi , l’acetaldeide è
poi ridotta ad etanolo mediante una reazione di ossidoriduzione catalizzatadall’alcol deidrogenasi:
piruvato decarbossilasiAcido piruvico CO2+ acetaldeide
alcol deidrogenasiAcetaldeide + NADH +H+etanolo + NAD+
La conversione del glucosio ad etanolo è chiamata fermentazione alcolica .
Figura 6: ciclo di Cori
70Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#71,71,"3.6.4 Significato della glicolisi
Funzione plastica
La glicolisi conduce alla formazione di molecole che hanno funzione strutturale.Il diidrossiacetone 3-fosfato, trasformato in glicerolo 3-fosfato, rappresenta ilpunto di partenza della lipogenesi da glucidi. L’acetil CoA avvia la sintesidegli acidi grassi che entrano nella costituzione di fosfolipidi, di glicolipidied esteri del colesterolo.
Funzione preparatoria
L’acetil CoA entra nel metabolismo ossidativo terminale.
Funzione energetica
La glicolisi contribuisce alla formazione di ATP. Per ogni mole di glucosioche prende la via glicolitica, si producono 2 moli di acido piruvico, 2 moli diNADH e 2 moli di ATP 
3.7 GLUCONEOGENESI
La gluconeogenesi è il processo di sintesi di glucosio a partire da precursori
non glucidici, che consente il mantenimento dell’omeostasi glicemica, quandole riserve di glicogeno sono esaurite e/o l’apporto glucidico della dieta è in-sufficiente. La gluconeogenesi avviene nel citoplasma delle cellule epatiche apartire dall’acido piruvico, principalmente in condizioni di digiuno fra un pastoe l’altro (Figura 7).
Reazioni della gluconeogenesi
Il piruvato (derivato dal lattato o da amminoacidi come l’alanina) è convertitoad ossalacetato dall’enzima piruvato carbossilasi, un enzima mitocondriale
che richiede biotina ed ATP.L’ossalacetato non può attraversare la membrana mitocondriale, quindi è con-vertito in:Malato ad opera dell’enzima malico deidrogenasi:
malico deidrogenasiAc. ossalacetico+NADH+ H+
malico deidrogenasiAc. malico + NAD+
71Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#72,72,"2) Aspartato ad opera dell’enzima glutammico ossalacetico transaminasi :
Glutammico-ossalacetico transaminasiAc. ossalacetico + Ac. glutammico 
Glutammico-ossalacetico transaminasiAc. aspartico + Ac.α -chetoglutarico
Malato ed aspartato attraversano la membrana mitocondriale interna e vengono
riconvertiti ad ossalacetato nel citoplasma.
• L’ossalacetato è decarbossilato e fosforilato dall’enzima fosfoenolpiruvato
(PEP) carbossichinasi a formare fosfoenolpiruvato (PEP) e CO2. E’
necessaria energia sotto forma di GTP che viene convertito in GDP e Pi.
• Il fosfoenolpiruvato va incontro alle tappe inverse della glicolisi formando
alla fine, fruttosio 1,6-bifosfato.
• Il fruttosio 1,6-bifosfato è convertito a fruttosio 6-fosfato dall’enzima
fruttosio 1,6-bifosfatasi , che rilascia fosfato inorganico.
• Il fruttosio 6-fosfato è convertito a glucosio 6-fosfato dalla stessa isomerasi
utilizzata nella glicolisi. 
•L a  glucosio 6-fosfatasi , enzima presente solo nel fegato, idrolizza fosfato
inorganico dal glucosio 6-fosfato, rilasciando glucosio libero nel sangue.
72Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#73,73,"La sintesi di glucosio da due moli di acido piruvico richiede energia, fornita
dall’idrolisi di 6 legami altamente energetici: 4 ottenuti dall’ATP e 2 dal GTP.Nello schema di reazioni soprariportato si intende che 2 moli di acido piruvicoportano alla formazione di 1 mole di fruttosio 1,6-bifosfato.I principali precursori della gluconeogenesi sono:• Acido lattico: proviene dagli eritrociti e dal muscolo in esercizio.
• Amminoacidi: provengono dal muscolo per degradazione delle proteine
muscolari.
• Glicerolo: deriva dalla degradazione dei trigliceridi del tessuto adiposo
(Figura 8).
Figura 7: reazioni che caratterizzano la gluconeogenesi epatica
73Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#74,74,"3.7.1 Regolazione della gluconeogenesi
In condizioni di digiuno, l’ormone glucagone aumenta e stimola la gluconeo-
genesi.
Regolazione della piruvato deidrogenasi
Il glucagone stimola il rilascio di acidi grassi dal tessuto adiposo.Gli acidi grassi sono trasferiti al fegato ed ossidati producendo ATP, che pro-voca l’inattivazione dell’enzima piruvato deidrogenasi: il piruvato è così con-vertito ad ossalacetato invece che ad acetil-CoA.Figura 8: substrati utilizzati dal fegato per sintetizzare glucosio attraverso la gluconeogenesi.
74Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#75,75,"Regolazione della piruvato chinasi
Il glucagone provoca la fosforilazione della piruvato chinasi e quindi la suainattivazione: di conseguenza, il fosfoenolpiruvato formato dall’ossalacetatonon è convertito a piruvato, ma prende la via della gluconeogenesi.
Regolazione della fosfofruttochinasi
La fosfofruttochinasi è inattiva poiché la concentrazione del suo inibitore,l’ATP, è elevata: il fruttosio 6-fosfato non è quindi convertito a fruttosio 1,6-bifosfato, bensì isomerizzato a glucosio 6-fosfato.
Regolazione della glucochinasi 
Nelle condizioni che favoriscono la gluconeogenesi, la concentrazione di glu-cosio è bassa: l’enzima è inattivo, dal momento che ha una elevata K
mper il
glucosio. 
3.8 Glicogenosintesi
Il glicogeno, la forma più importante di riserva dei carboidrati, è un polimero
di D-glucosio con legami α-1,4 glicosidici, altamente ramificato attraverso
legami α-1,6 glicosidici, che si formano in media ogni 10 unità di glucosio
(Figura 9).
75Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#76,76,"La glicogenosintesi è la formazione di glicogeno dal glucosio. Questo processo
avviene nel muscolo e nel fegato dopo un pasto ricco di carboidrati.Le reazioni della glicogenosintesi sono le seguenti:
glucochinasiGlucosio + ATP Glucosio 6-fosfato + ADP
fosfoglucomutasiGlucosio 6-fosfato Glucosio 1-fosfato
UDP-glucosio pirofosforilasiGlucosio 1-fosfato +UTP UDP-glucosio + PPi
pirofosfatasiPPi + H2O 2 Pi
• Il glucosio entra nella cellula ed è fosforilato a glucosio 6-fosfato dalla
esochinasi (o glucochinasi nel fegato). 
•L a fosfoglucomutasi converte il glucosio 6-fosfato in glucosio 1-fosfato.
• Il glucosio 1-fosfato reagisce con UTP (uridina trifosfato), formando UDP-
glucosio in una reazione catalizzata dalla UDP-glucosio pirofosforilasi. In
questa reazione viene rilasciato PPi (pirofosfato inorganico) che viene scissoda una pirofosfatasi in 2 molecole di Pi (fosfato inorganico) (Figura 10).Figura 9: struttura ramificata del glicogeno
76Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#77,77,"glicogeno sintasiUDP-glucosio + glicogeno (n residui) 
glicogeno sintasiGlicogeno (n residui+1) + UDP
• I residui di glucosio vengono trasferiti dall’UDP-glucosio al glicogeno
primer dall’enzima glicogeno sintasi (Figura 11). I primers sono molecole
di glicogeno parzialmente degradate nel fegato durante le fasi di digiuno e
nel muscolo durante l’esercizio fisico intenso. Sono costituiti da unaproteina, la glicogenina dotata di attiviità catalitica. 
Tale attività permette alla proteina nativa di catalizzare una reazione ditrasferimento del gruppo glicosidico dell’UDP-glucosio ad un suo residuodi tirosina in posizione 194. Così procede unendo ripetitivamente unità diglucosio mediante legame α-1,4 glicosidico fino ad ottenere una catena con
otto residui glicosidici per poi lasciare spazio alla glicogeno sintasi .Figura 10: sintesi dell’UDP-glucosio
77Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#78,78,"• Infine, l’UDP viene rilasciato e può essere convertito in UTP mediante grazie
all’azione di una nucleotide fosfotransferasi che utilizza una molecola di ATP.
nucleodide difosfochinasiUDP + ATP UTP + ADP
Quando una catena contiene 11 o più residui di glucosio, un tratto di 6-8 residui
viene rimosso dalla catena e viene legato con legame α-1,6 ad un residuo di
glucosio all’interno di una catena con legami α-1,4. Queste ramificazioni sono
formate dall’ enzima ramificante, che rompe un legame α-1,4 e ne forma uno
di tipo α-1,6 (Figura 12).Figura 11: reazione catalizzata dall’enzima glicogeno sintasi
78Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#79,79,"I nuovi punti di ramificazione si formano in seguito al trasporto di almeno 7
unità glucidiche legate da legami α-1,4 da una sequenza di almeno 11 residui,
per formare un legame α-1,6 con un residuo che disti almeno 4 residui di glu-
cosio dalla ramificazione già esistente
3.9 Glicogenolisi
La glicogenolisi rappresenta la via di degradazione del glicogeno per ottenere
glucosio. La glicogenolisi è un processo complesso che prevede il coinvolgi-mento di diversi enzimi. La maggior parte delle molecole di glucosio contenutenel glicogeno viene trasformato in glucosio 1-fosfato grazie all’azione dal-l’enzima glicogeno fosforilasi
glicogeno fosforilasiGlicogeno (n residui) Glicogeno (n-1 residui)
Pi
Glucosio 1-PFigura 12: meccanismo di azione dell’enzima ramificante durante la glicogenosintesi.
79Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#8,8,"Gluconeogenesi
GlicogenosintesiGlicogenolisiCiclo dei PentosiMetabolismo Ossidativo terminaleCiclo di Krebs o dell’Acido CitricoCatena respiratoria e formazione di ATP nella fosforilazione ossidativaCenni di Patologia Clinica Bibliografia
CAPITOLO IV - METABOLISMO DEI GRASSI
LipidiI triacilgliceroliFosfolipidiDigestione ed assorbimento dei lipidiLe lipoproteineRegolazione della biosintesi di lipidiIl catabolismo dei lipidiSintesi e funzione fisiologica dei corpi chetoniciBibliografia
CAPITOLO V - METABOLISMO DELLE PROTEINE
Proteine Assunzione dei protidiDigestione delle proteine - Assorbimento di aminoacidi e peptidiBibliografia
CAPITOLO VI - RIPARTIZIONE DEI MACRONUTRIENTI 
Il concetto di dieta equilibrataIl concetto di dietaCaratteristiche di una dieta varia ed equilibrataDieta e attività fisicaPrincipi generali per impostare un profilo nutrizionale ripartizione dei macro-nutrienti Esempio di schema dieteticoBibliografia
8Fondamenti della Scienza dell’Alimentazione Indice"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#80,80,"L’enzima glicogeno fosforilasi rimuove i residui di glucosio, uno alla volta,
dal glicogeno. Questo enzima utilizza Pi per rompere i legami α-1,4,
producendo glucosio 1-fosfato (Figura 13).
La fosforilasi può agire solo fino a 4 unità di glucosio da un punto di ramifi-
cazione• Le 4 unità che rimangono sulla ramificazione sono rimosse dall’ enzima
deramificante , che ha sia un’attività transferasica che α-1,6 glicosidasica.
• Tre dei 4 residui che rimangono sul punto di ramificazione sono rimossi
come trisaccaride ed attaccati all’estremità di un’altra catena: l’enzima è unatransferasi, che rompe un legame α-1,4 e forma un nuovo legame α-1,4.
• Un’unità di glucosio rimane legata nel punto di ramificazione con legame
α-1,6. Questo singolo residuo di glucosio viene idrolizzato dalla α-1,6
glicosidasi , che forma glucosio libero (Figura 14).Figura 13: meccanismo d’azione dell’enzima glicogeno fosforilasi
80Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#81,81,"Le molecole di glucosio 1-fosfato vengono successivamente trasformate in
glucosio 6-fosfato dall’enzima fosfoglucomutasi. La glicogenolisi avviene
principalmente nel fegato per mantenere costanti i livelli di glucosio ematico.Infatti nel fegato è presente l’enzima glucosio 6-fosfatasi che trasforma il glu-
cosio 6-fosfato in glucosio. Il glucosio dagli epatociti va nel sangue.
glucosio 6-fosfatasiGlucosio 6-fosfato Glucosio
H2OP i
L’enzima glucosio 6-fosfatasi è presente nel fegato, ma non nel muscolo, per-
tanto il glicogeno muscolare non può fungere da riserva di glucosio ematico.Nel muscolo il glicogeno è degradato per produrre energia durante la contra-zione muscolare.Anche durante il digiuno prolungato non vengono mai esaurite del tutto le riservedi glicogeno, e la piccola quota rimanente è in grado di funzionare da “primer” perla sintesi di nuovo glicogeno, quando siano nuovamente disponibili carboidrati eso-geni. Nel caso si abbia la completa deplezione del glicogeno, una piccola proteinaglicosilata, la glicogenina , funge da primer per innescare la sintesi del glicogeno.
Figura 14: meccanismo d’azione dell’enzima deramificante
81Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#82,82,"3.9.1 Regolazione delle riserve di glicogeno
Degradazione del glicogeno
• Gli ormoni glucagone e adrenalina attivano l’enzima adenilato ciclasi della
membrana cellulare, che converte l’ATP in cAMP.
• Il cAMP attiva una proteina chinasi (proteina chinasi A).
• La proteina chinasi A fosforila la glicogeno sintasi ,causandone
l’inattivazione ed impedendo la sintesi del glicogeno.
• La stessa proteina chinasi A fosforila la fosforilasi chinasi , attivandola;
questo enzima a sua volta fosforila la fosforilasi b, che si converte nella sua
forma attiva o fosforilasi a aumentando la degradazione del glicogeno.
Sintesi del glicogenoL’ormone insulina, la cui concentrazione è elevata dopo un pasto, stimola lasintesi di glicogeno sia nel fegato che nel muscolo.In stato di alimentazione, il livello di glucagone è basso ed il meccanismocAMP (AMP ciclico) dipendente non viene attivato.• Il cAMP è convertito ad AMP da una fosfodiesterasi .
• Appena il cAMP diminuisce, viene inattivata la proteina chinasi.
• Ne consegue la defosforilazione della fosforilasi chinasi e della fosforilasi
a, che diventano inattive.
• L’insulina attiva le fosfatasi che defosforilano questi enzimi.
• La fosfatasi defosforila anche la glicogeno sintasi e l’enzima diventa attivo.
Il processo attivato dal cAMP è un meccanismo “a cascata” in cui il segnaleormonale originario è amplificato più volte.Una molecola di ormone, attraverso l’attivazione dell’enzima adenilato ciclasi,produce molte molecole di cAMP, che attivano l’enzima proteina chinasi.Una molecola attiva di proteina chinasi fosforila molte molecole di fosforilasichinasi, che convertono la fosforilasi b in fosforilasi a.Una molecola di fosforilasi a produce molte molecole di glucosio 1-fosfatodal glicogeno.Il risultato netto è che una molecola di ormone può generare decine di migliaiadi molecole di glucosio 1-fosfato.Nel fegato, il glucagone (durante il digiuno) e l’adrenalina (durante l’eserciziofisico) stimolano la degradazione del glicogeno. Il glucosio libero che vieneprodotto è utilizzato per mantenere i livelli di glucosio ematico.Nel muscolo, l’adrenalina stimola la lisi del glicogeno a glucosio 1-fosfato,poi convertito a glucosio 6-fosfato, che entra nella glicolisi e genera ATP per
82Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#83,83,"la contrazione muscolare. Il muscolo è privo dell’enzima glucosio 6-fosfatasi,
quindi non produce glucosio libero per contribuire al mantenimento della gli-cemia.Il muscolo non degrada glicogeno in risposta al glucagone.
3.10 Ciclo del Pentosio Fosfato
Accanto alla glicolisi sono state descritte altre vie di demolizione del glucosio.
La più importante è il ciclo dei pentosi o shunt dell’esoso monofosfato : avviene
nel citoplasma cellulare e riveste particolare importanza per il fegato, tessutoadiposo, rene, eritrociti.E’ una via multifunzionale e si divide in:- Parte ossidativa ed irreversibile- Parte non-ossidativa e reversibile
Parte ossidativa ed irreversibile del ciclo
Da glucosio 6-fosfato si formano NADPH e ribulosio 5-fosfato (Figura 15).
Figura 15: parte ossidativa del ciclo del pentosio fosfato
83Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#84,84,"• Il glucosio 6-fosfato è convertito a 6-fosfogluconolattone e il NADP+è
ridotto a NADPH + H+. Enzima: glucosio 6-fosfato deidrogenasi .
• Il 6-fosfogluconolattone è idrolizzato a 6-fosfogluconato. Enzima:
gluconolattonasi .
• Il 6-fosfogluconato è decarbossilato ossidativamente. Si libera CO2e si
forma un secondo NADPH + H+dal NADP+; gli altri atomi di carbonio
restano come ribulosio 5-fosfato. Enzima: 6-fosfogluconato deidrogenasi .
NADPH viene utilizzato come donatore di idrogeno ed elettroni nelle biosin-
tesi di acidi grassi e del colesterolo.
Il ribulosio 5-fosfato fornisce il ribosio 5-fosfato per la sintesi dei nucleotidi
necessari per la formazione di RNA e DNA.Nelle reazioni ossidative, il glucosio 6-fosfato è decarbossilato ossidativa-mente, viene rilasciata CO
2, si generano NADPH e ribulosio 5-fosfato.
Parte non ossidativa e reversibileDa ribulosio 5-fosfato si formano altri zuccheri a 5 atomi di carbonio che pos-sono essere convertiti in intermedi della via glicolitica.Nelle reazioni non ossidative il ribulosio 5-fosfato, prodotto nelle reazioni os-sidative, è convertito nel suo isomero ribosio 5-fosfato, che può essere usato
per la sintesi dei nucleotidi. Il ribulosio 5-fosfato può essere convertito anchenel suo epimero xilulosio 5-fosfato .
Il ribosio 5-fosfato e lo xilulosio 5-fosfato possono andare incontro ad una seriedi reazioni catalizzate dagli enzimi transchetolasi e transaldolasi, che trasferi-
scono i carboni da un composto all’altro. Alla fine si formano due intermedidella glicolisi: il fruttosio 6-fosfato e la gliceraldeide 3-fosfato (Figura 16).
84Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#85,85,"Il ribulosio 5-fosfato può essere isomerizzato a ribosio 5-fosfato. Enzima:
fosforiboisomerasi.
• Il ribulosio 5-fosfato può essere epimerizzato a xilulosio 5-fosfato. Enzima:
ribulosio fosfato epimerasi .
• Un’unità a due atomi di carbonio può essere trasferita dallo xilulosio 5-fosfato
al ribosio 5-fosfato per formare sedoeptulosio 7-fosfato. La gliceraldeide 3-fosfato si forma dai restanti atomi di carbonio dello xilulosio 5-fosfato. Enzima:
transchetolasi ; richiede tiaminapirofosfato come coenzima.
• Un’unità a tre atomi di carbonio può essere trasferita dal sedoeptulosio 7-
fosfato alla gliceraldeide 3-fosfato, formando fruttosio 6-fosfato. I quattrorestanti atomi di carbonio del sedoeptulosio 7-fosfato formano eritrosio 4-fosfato. Enzima: transaldolasi.
• Un’unità a due atomi di carbonio può essere trasferita dallo xilulosio 5-
fosfato all’eritrosio 4-fosfato a formare un’altra molecola di fruttosio6-fosfato. Gliceraldeide 3-fosfato si forma dai restanti atomi di carbonioFigura 16: reazioni non ossidative del ciclo dei PPP
85Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#86,86,"dello xilulosio 5-fosfato. Enzima: transchetolasi.
Significato del ciclo dei pentosi
Dal ciclo dei pentosi si ha:
✓Formazione di NADPH per le biosintesi di acidi grassi 
✓Biosintesi di pentosi e produzione di nucleotidi 
✓Ossidazione terminale con produzione di energia attraverso la formazionedi intermedi della via glicolitica 
3.11 Metabolismo Ossidativo Terminale
3.11.1 Ciclo di Krebs o dell’Acido CitricoIn condizioni di aerobiosi, l’acido piruvico prodotto durante la glicolisi entra
nel mitocondrio per essere completamente ossidato attraverso il ciclo di Krebs.Una volta entrato nel mitocondrio, l’acido piruvico subisce una decarbossila-zione ossidativa ad opera del complesso multienzimatico della piruvato dei-
drogenasi per formare Acetil CoA.
Tale complesso multienzimatico è costituito da 3 enzimi ognuno dei quali èaffiancato da un coenzima:
Tale complesso catalizza la reazione:                                                    
Piruvato deidrogenasiPiruvato + CoA + NAD+
Piruvato deidrogenasiAcetil CoA + CO2+ NADH + H+
Tale reazione (irreversibile) avviene nella matrice mitocondriale e rappresenta
il punto di unione fra la glicolisi ed il ciclo di Krebs.Il complesso multienzimatico ha la seguente regolazione:
Inibizione da prodotto Acetil CoA ed NADH
Regolazione a feedback GTP (inattivatore), AMP (attivatore)
Regolazione per modificazione covalente Fosforilazione da parte di ATPEnzima Coenzima
Piruvato deidrogenasi TPP (tiamina pirofosfato)
Diidrolipoil transacetilasi Lipoamide
Diidrolipoil deidrogenasi F AD
86Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#87,87,"Il ciclo di Krebs, la catena di trasporto degli elettroni e la fosforilazione ossi-
dativa costituiscono il metabolismo ossidativo terminale, nel quale i prodottidel metabolismo intermedio vengono completamente bruciati a CO
2ed H2O.
La glicolisi, la β-ossidazione, la degradazione di numerosi amminoacidi,
hanno come prodotto finale l’acetil CoA: questa molecola è essenziale perl’inizio del ciclo di Krebs, reagisce con l’acido ossalacetico ed entra nel ciclo.Alla fine del ciclo di reazioni, l’acido ossalacetico è rigenerato e può riprenderela sequenza di reazioni con un’altra molecola di acetil CoA.Durante il ciclo, l’acetil CoA è ossidato ad anidride carbonica, e contempora-neamente sono prodotti NADH + H
+e FADH2.
Reazioni del ciclo di KrebsIl ciclo di Krebs consiste in 8 reazioni sequenziali, catalizzare da altrettantienzimi o complessi multienzimatici (Figura 17)• Acetil CoA si condensa con ossalacetato e si forma citrato. Enzima: citrato
sintasi (1).
• Il citrato è isomerizzato a isocitrato tramite un riarrangiamento della
molecola. Enzima: isocitrato isomerasi o aconitasi (2).
• La prima decarbossilazione ossidativa avviene quando l’isocitrato è ossidato
a α-chetoglutarato. Si produce una molecola di CO
2, NAD+è convertito in
NADH + H+. Enzima: isocitrato deidrogenasi (3). L’H+prodotto è utilizzato
nella stessa reazione per la decarbossilazione dell’intermedio ossalsuccinato.La stechiometria globale di questa reazione non vede quindi la produzionedi ioni H
+.
•L ’α-chetoglutarato è convertito a succinil CoA nella seconda
decarbossilazione ossidativa. Si produce una molecola di CO2, NAD+è
convertito in NADH + H+. Enzima: α-chetoglutarato deidrogenasi (4).
• Il legame tioestere altamente energetico del succinilCoA è scisso e rilascia
l’energia necessaria per la sintesi di GTP da GDP e fosfato inorganico (Pi);si forma succinato. Enzima: succinil CoA sintetasi (5).
• Il succinato è ossidato ed il FAD diventa FADH
2. Si forma fumarato.
Enzima: succinato deidrogenasi (6).
• L’aggiunta di una molecola di H2O scinde il doppio legame del fumarato e
si forma malato. Enzima: fumarasi (7).
• Il malato è ossidato con trasformazione del NAD+in NADH + H+. Si
rigenera l’ossalacetato e così si completa il ciclo. Enzima: malato
deidrogenasi (8).
87Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#88,88,"Regolazione del ciclo di Krebs
Il ciclo è regolato dalle necessità energetiche della cellula, cioè dalla concen-trazione di ATP.Quando la cellula richiede energia, vengono accelerate le reazioni della catenadi trasporto degli elettroni. NADH viene rapidamente ossidato ed aumenta lavelocità del ciclo di Krebs.Quando la concentrazione di ATP è elevata, diminuisce la velocità della catenadi trasporto degli elettroni, aumenta la concentrazione di NADH e viene inibitoil ciclo di Krebs.NADH + H
+ed FADH2entrano nella catena di trasporto degli elettroni loca-
lizzata nella membrana interna del mitocondrio.Figura 17: ciclo di Krebs
88Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#89,89,"La reazione globale per il ciclo di Krebs è:
AcetilCoA+3 NAD++F AD+GDP+Pi+2H2O 
2CO2+CoA+3NADH+2H++F ADH2+GTP
Come tutti i fenomeni ossidativi anche il ciclo di Krebs libera una certa quan-
tità di energia recuperata sotto forma di ATP: si ha la formazione diretta di
ATP(GTP) solo nella conversione di succinil CoA ad acido succinico. Il restodell’ATP si forma tramite la fosforilazione ossidativa con formazione di 2,5di ATP (o 1,5 per il F AD), per ogni mole di NAD+ (o F AD) ridotto. In totale si formano per ogni ciclo 9 moli di ATP tramite la fosforilazione os-sidativa ed 1 direttamente dal ciclo. Per ogni mole di acetil CoA degradata aCO2 ed H2O si producono quindi 10 moli di ATP .
Funzione biosintetica del ciclo di Krebs
- Alcuni metaboliti del ciclo di Krebs possono dare origine ad amminoacidi:
a) l’acido α-chetoglutarico dà origine all’acido glutammico per transamina-
zione e alla glutammina
b)il succinil CoA dà origine alla metionina, lisina, treonina e leucinac) l’acido ossalacetico dà origine all’acido aspartico per transaminazione e
all’asparagina
- Quando l’acido citrico (che si ottiene dalla condensazione di acido
ossalacetico ed acetil CoA) è in eccesso (per esempio dopo un pasto moltoricco di carboidrati), fuoriesce dai mitocondri e nel citosol produce acetilCoA, dal quale poi inizia la sintesi di acidi grassi.
- Gli intermedi del ciclo di Krebs devono essere sostituiti se sottratti per le
biosintesi. Se, per esempio, l’acido ossalacetico è convertito in unamminoacido per la sintesi proteica, allora nuovo acido ossalacetico siformerà da acido piruvico. La reazione, catalizzata dalla piruvico
carbossilasi, è la seguente:
Piruvato carbossilasiAc. piruvico + CO2+ATP 
Piruvato carbossilasiAc. ossalacetico + ADP + Pi
89Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#9,9,"CAPITOLO VII – V ALUTAZIONE DELLO STATO NUTRIZIONALE 
La valutazione dello stato nutrizionaleComposizione corporeaIndicatori antropometrici dello stato nutrizionale Plicometria Bioimpedenziometria Bibliografia
CAPITOLO VIII – FABBISOGNO ENERGETICO
Metabolismo basale (M.B.) CalorimetriaCalorimetria diretta Calorimetria indirettaTermogenesi indotta dalla dieta (TID) Costo energetico attività fisica (LAF) Bibliografia
CAPITOLO IX - STRUMENTI DI INDAGINE ALIMENTARE
Strumenti di indagine alimentareDiario di registrazione degli alimenti Il ricordo delle 24 oreIl questionario di frequenza degli alimentiStrumenti brevi per valutare la dietaStoria dieteticaElaborazione dei datiBibliografia
CAPITOLO X - L.A.R.N. E LINEE GUIDA 
Adeguatezza nutrizionale della dietaI livelli di assunzione di riferimento di nutrienti e energia per la popolazioneitalianaCome si usano i LARNL’evoluzione delle linee guida per una sana alimentazioneAttualità e modernità delle linee guida per una sana alimentazione: dalle ca-renze nutrizionali alla alimentazione come prevenzione.Perché le revisioni periodiche delle Linee Guida?Le Linee Guida nei moderni strumenti di comunicazioneConclusioniBibliografia
9Indice Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#90,90,"3.11.2 Catena respiratoria e formazione di ATP nella fosforilazione ossi-
dativa
NADH+ H+e FADH2formati nella glicolisi, nell’ossidazione degli acidi grassi
e nel ciclo di Krebs, sono utilizzati per produrre ATP.
Gli elettroni sono trasferiti da NADH+H+e FADH2all’ossigeno molecolare
attraverso un sistema di trasporto di elettroni, la catena respiratoria, stretta-
mente associata alla fosforilazione ossidativa, che è il principale processo diformazione di ATP.La catena di trasporto degli elettroni è localizzata nella membrana internadei mitocondri ( Figura 18).
Catena di trasporto degli elettroni.L’ossigeno molecolare è trasportato alle cellule dall’emoglobina attraverso icapillari sanguigni.La catena respiratoria è composta da quattro complessi enzimatici:
- NADH-Q reduttasi
- F ADH
2reduttasi
- Citocromo c reduttasi- Citocromo c ossidasi
Ognuno dei complessi sfrutta l’energia derivante dal trasporto degli elettroni
per pompare protoni nello spazio intermembrana (Figura 19).Figura 18: struttura dei un mitocondrio
90Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#91,91,"La teoria chemiosmotica spiega la fosforilazione ossidativa mediante un mo-
vimento di protoni.
I principi di questa teoria sono:- La membrana mitocondriale interna è impermeabile agli ioni , in particolare
agli ioni H
+, che si accumulano all’esterno della membrana, causando una
differenza di potenziale elettrochimico attraverso la membrana stessa
- La differenza di potenziale attiva l’enzima di membrana ATP sintasi- I protoni possono rientrare nella matrice solo attraverso il complesso
dell’ATP sintasi, dove viene generato ATP
Durante il trasporto degli elettroni attraverso la catena respiratoria una partedell’energia viene dispersa sotto forma di calore.
Trasporto di elettroni da NADH a O
2
• Gli elettroni del NADH vengono trasferiti al flavin mononucleotide (FMN)
presente nel complesso della NADH-Q reduttasi (Complesso I).
• FMN trasferisce i suoi elettroni al coenzima Q, tramite una serie di proteine
contenenti ferro-zolfo.
L’energia prodotta da questo movimento di elettroni è utilizzata per pomparequattro protoni nello spazio intermembrana attraverso il Complesso I; con-temporaneamente si genera un potenziale elettrochimico.
✓Gli elettroni sono trasferiti dal coenzima Q ai citocromi b e c1facenti parte
del complesso citocromo c reduttasi (Complesso III).Figura 19: catena di trasporto degli elettroni mitocondriale
91Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#92,92,"✓Il citocromo c1cede gli elettroni al citocromo c.
L’energia prodotta nel trasporto degli elettroni dal coenzima Q al citocromo
c è utilizzata per pompare altri quattro protoni nello spazio intermembrana;contemporaneamente si genera un potenziale elettrochimico.
✓Il citocromo c trasferisce gli elettroni al complesso citocromo c ossidasi(Complesso IV) costituito dai citocromi a e a
3ed altri due protoni vengono
pompati nello spazio intermembrana.Il citocromo a
3cede gli elettroni all’ossigeno molecolare che viene ridotto
ad H2O.
L’energia prodotta dal trasferimento degli elettroni dal citocromo c all’ossigenomolecolare è utilizzata per pompare protoni nello spazio intermembrana; con-temporaneamente si genera un potenziale elettrochimico. L’ossidazione di unamole di NADH porta alla formazione di 2,5 moli di ATP.
Trasferimento degli elettroni da FADH
2
La rimozione degli elettroni da FADH2avviene in due tappe:
✓FADH2trasferisce i suoi elettroni ad un centro ferro-zolfo (Complesso II),
che a sua volta li cede al coenzima Q.
✓Gli elettroni sono poi trasferiti al complesso citocromo c reduttasi, citocromoc ossidasi e all’ossigeno molecolare come per NADH.
✓Dal momento che gli elettroni provenienti dal FADH2passano direttamente
al coenzima Q (e non al complesso NADH-Q reduttasi), si producono solo1,5 moli ATP quando FADH2 si ossida.
Agenti disaccoppiantiLo stretto accoppiamento che esiste fra il trasporto degli elettroni e la fosfori-lazione ossidativa nei mitocondri può essere rotto dal 2,4-dinitrofenolo e daalcuni altri composti aromatici acidi che trasportano protoni attraverso la mem-brana mitocondriale interna. In presenza di questi agenti disaccoppianti , il tra-
sporto degli elettroni d NADH e FADH
2all’ossigeno molecolare procede
normalmente, ma non si forma ATP ad opera dell’ATPasi mitocondriale, poi-ché la forza motrice protonica attraverso la membrana mitocondriale internaviene dissipata. Il disaccoppiamento della fosforilazione ossidativa può esserebiologicamente importante: ha la funzione di produrre calore per mantenerecostante la temperatura del corpo in animali in ibernazione ed in alcuni animaliappena nati incluso l’uomo. Il tessuto adiposo bruno, che è molto ricco di mi-tocondri, è specializzato in questo processo di termogenesi e la proteina di-saccoppiante si chiama termogenina.
Agenti disaccoppianti sono: anestetici, antibiotici, coloranti, tossine batteriche,
92Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#93,93,"ormoni come la tiroxina.
Energia generata per ossidazione del glucosio in CO2ed H2O
Quando il glucosio viene ossidato completamente a CO2ed H2O, si generano
in totale 30 o 32 ATP (Figura 20).
• Due moli nette di ATP si formano dalla conversione di una mole di glucosio
a due moli di piruvato.
• Le due moli di piruvato entrano nel mitocondrio e sono convertite in due moli
di acetil CoA, grazie all’azione dell’enzima piruvato deidrogenasi, producendodue moli di NADH, che danno 5 ATP per fosforilazione ossidativa.
• Le due moli di acetil CoA sono ossidate nel ciclo di Krebs, generando un
totale di 20 moli di ATP.
• Altro ATP (3 o 5 molecole) viene prodotto dalla riossidazione del NADH+H
+
generato nel citoplasma durante la glicolisi.
• NADH+H+non può attraversare la membrana interna del mitocondrio,
quindi gli elettroni sono trasferiti alla catena respiratoria mitocondrialeattraverso due sistemi navetta (shuttle).
Figura 20: ATP generato attraverso la completa ossidazione del glucosio
93Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#94,94,"3.12 Cenni di Patologia Clinica 
Carenza di Lattasi Intestinale
La lattasi è generalmente presente nei neonati e nei bambini, che sono quindi ingrado di scindere il lattosio presente nel latte e di assorbire, a livello intestinale,galattosio e glucosio. Con il progredire dello sviluppo, l’espressione e l’attivitàdella lattasi inizia a diminuire nella maggior parte delle persone intorno ai 2 annidi vita (non vi sono invece differenze significative di incidenza fra i due sessi)con una riduzione progressiva geneticamente programmata. I sintomi di intol-leranza al lattosio raramente si sviluppano prima dei 6 anni. Generalmente sonomantenuti a livelli efficaci di lattasi soltanto nelle popolazioni caucasiche, a con-dizione che si continui a inserire nella propria alimentazione latte o in generalealimenti che contengano lattosio. Il lattosio non digerito è ossidato dalla florabatterica intestinale producendo meteorismo addominale e diarrea.
Galattosemia
La presenza di elevate concentrazioni di galattosio nel sangue può essere dovutaad una deficienza dell’enzima galattosio 1-fosfato uridil-trasferasi (enzima delmetabolismo del galattosio), che impedisce la conversione del galattosio in glu-cosio; galattosio e galattosio 1-fosfato si accumulano nei tessuti. L’eccesso digalattosio è ridotto a galattitolo, che può provocare cataratta; il galattosio 1-fo-sfato interferisce con il metabolismo del glucosio causando gravi danni ai variorgani e tessuti. Una forma più lieve di galattosemia è dovuta alla carenza del-l’enzima galattochinasi (enzima del metabolismo del galattosio).
Carenza di piruvato chinasi
La carenza dell’enzima piruvato chinasi causa una diminuzione della produ-zione di ATP durante la glicolisi. I globuli rossi, che utilizzano come fonteenergetica la glicolisi, non hanno più a disposizione ATP per la pompa delsodio, perciò le membrane si lisano facilmente causando anemia emolitica.
Intolleranza al fruttosio
L’intolleranza al fruttosio si verifica in seguito a carenza dell’enzima fruttosio1-fosfato aldolasi (enzima del metabolismo del fruttosio). Il fruttosio 1-fosfatosi accumula e non si forma più glucosio, causando una severa ipoglicemia.Quando è carente l’enzima fruttochinasi (enzima del metabolismo del frutto-sio), il fruttosio non può essere metabolizzato velocemente, quindi aumenta alivello ematico ed è riscontrabile nelle urine.
94Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#95,95,"Carenza di glucosio 6-fosfato deidrogenasi
L’enzima glucosio 6-fosfato deidrogenasi catalizza la trasformazione del glu-cosio 6-fosfato in 6-fosfogluconolattone con concomitante produzione diNADPH. La carenza di questo enzima comporta un’insufficiente produzionedi NADPH, molecola importante per il mantenimento allo stato ridotto delglutatione. L’incapacità della cellula a riconvertire il glutatione ossidato inglutatione ridotto, comporta un danno ossidativo con lisi dei globuli rossi (cel-lule molto sensibili al danno ossidativo, perché non possono sintetizzare nuovienzimi al posto di quelli danneggiati, in quanto sono privi di nucleo) ed anemiaemolitica.
Malattie del metabolismo del glicogeno (glicogenosi)
Si tratta di malattie dismetaboliche in cui si ha un accumulo di glicogeno nel fe-gato o nel muscolo. Le carenze enzimatiche causa dell’accumulo sono soprattuttoa carico della degradazione del glicogeno e della sua conversione in glucosio.
Malattia di McArdle
Un difetto del metabolismo del glicogeno confinato al muscolo si realizzanella malattia di McArdle. L’enzima glicogeno fosforilasi è assente ed il pa-ziente non è in grado di mobilizzare il glicogeno a scopo energetico, quindilimitata è la capacità di svolgere esercizi fisici a causa di dolorosi crampi mu-scolari.
Malattia di Von Gierke
Questa malattia è caratterizzata da una deficienza genetica dell’enzima glu-cosio 6-fosfatasi. Il fegato non è in grado di convertire il glucosio 6-fosfato inglucosio per rilasciarlo nel sangue. Nel fegato aumenta la concentrazione diglucosio 6-fosfato, la glicogeno fosforilasi è inibita ed è attivata la glicogenosintasi; di conseguenza si ha accumulo di glicogeno nel fegato ed epatomegaliamassiva.L’assenza di glucosio 6-fosfatasi determina ipoglicemia, in quanto non si puòformare glucosio da glucosio 6-fosfato. La malattia può essere curata con spe-cifici medicinali che inibiscono l’ingresso di glucosio negli epatociti, anchese nella maggioranza dei casi è necessario un trapianto di fegato.
Malattia di Cori 
La malattia di Cori è caratterizzata da una deficienza dell’enzima deramifi-cante α-1,6 glicosidasi. Come risultato, il muscolo ed il fegato accumulano
95Capitolo III Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#96,96,"glicogeno con ramificazioni esterne molto corte ed il glicogeno non può essere
completamente degradato. Questi pazienti tendono ad essere ipoglicemici. Lamalattia di Cori è trattata mediante un controllo della dieta, aumentando lafrequenza dei pasti e riducendone la quantità; l’intento è quello di diminuireil deposito di glicogeno.Sono conosciute anche altre malattie genetiche che riguardano il metabolismodel glicogeno (malattia di Andersen, malattia di Pompe, malattia di Hers), masono molto rare.
Diabete Mellito           
Il diabete mellito rappresenta un gruppo di disordini metabolici caratterizzatida un’iperglicemia cronica. E’ una patologia molto frequente che colpisce circa30 milioni di persone nel mondo. Il diabete mellito è una malattia irreversibilee sebbene i pazienti abbiano un normale stile di vita, a lungo termine si pos-sono verificare complicanze come malattie vascolari, retinopatie, nefropatie.Esistono due tipi di diabete:1. diabete di tipo 1 (10% dei pazienti diabetici)2. diabete di tipo 2 (90% dei pazienti diabetici)Il diabete di tipo 1 colpisce soprattutto i giovani adolescenti ed è dovuto alladistruzione autoimmune delle cellule beta delle isole di Langerhans. La causascatenante le reazioni autoimmunitarie è ancora sconosciuta, ma potrebbe es-sere un’infezione virale.Il diabete di tipo 1 sembra essere ereditario anche se i geni responsabili nonsono ancora stati completamente scoperti.I pazienti affetti da diabete di tipo 1 non sono in grado di produrre insulina equindi la devono introdurre dall’esterno.Il diabete di tipo 2 è molto comune e colpisce normalmente gli adulti; la ma-lattia può essere presente in forma subclinica per molti anni prima della dia-gnosi e l’incidenza aumenta notevolmente con l’età ed il grado di obesità.La maggioranza dei pazienti presenta una ridotta secrezione di insulina a causadi un danno alla funzionalità delle cellule beta, oppure una resistenza all’insulinastessa. Questa forma di diabete potrebbe avere una forte componente ereditaria,anche se ancora non sono stati identificati i geni responsabili della malattia.La carenza di insulina determina notevoli variazioni metaboliche; in primoluogo l’organismo non è in grado di utilizzare completamente i carboidrati in-trodotti con la dieta, quindi produce glucosio ematico sfruttando le riserve diglicogeno; i tessuti periferici, come il muscolo, assorbono una quantità minoredi glucosio. Per risparmiare glucosio, l’organismo utilizza i trigliceridi come
96Fondamenti della Scienza dell’Alimentazione Capitolo III"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#97,97,"fonte energetica, con conseguente accumulo dei corpi chetonici: si instaura
uno stato di acidosi metabolica associata a vomito e diarrea. Il fiato di questipazienti presenta il tipico odore di acetone. L’eccesso dei corpi chetonici èescreto con le urine.
Ipoglicemie
Si parla di ipoglicemia quando in condizioni di digiuno, il livello del glucosioematico si abbassa sotto i 40-50 mg/dl.
Ipoglicemie esogene
La più comune ipoglicemia esogena è legata alla somministrazione di dosi ecces-sive di insulina o di farmaci orali ipoglicemizzanti nei soggetti affetti da diabete.Può verificarsi ipoglicemia dopo digiuno prolungato, soprattutto in seguito adun eccessivo esercizio fisico. Anche un’elevata ingestione di alcolici può pro-vocare ipoglicemia, perché aumentano nel fegato i livelli di NADH, che ini-biscono la gluconeogenesi.
Ipoglicemie endogene
L’ipoglicemia endogena può derivare da un elevato assorbimento cellulare diglucosio, da alterazioni delle vie metaboliche della glicogenolisi e gluconeo-genesi, o da un’eccessiva secrezione di insulina (tumori benigni o malignidelle cellule beta delle isole di Langerhans chiamati insulinomi). Il tessutonervoso è il più vulnerabile all’ipoglicemia, poiché tale tessuto necessaria-mente utilizza glucosio ematico, non essendo in grado di sintetizzare glucosioo di immagazzinarlo in modo significativo.
Bibliografia
• D. V oet, J.G. V oet, C.W. Pratt. Fondamenti di Biochimica. Edizioni Zanichelli. 3 Ed. 1200
pp. 2013
• E. Marinello , R. Pagani. Elementi di Biochimica Medica. Edizioni ETS. 468 pp. 2009
• G. Zubay, W.W. Parson, D.E. Vance. Principles of Biochemistry. Edizioni McGraw-Hill
Education, 992 pp. 1995
• P. Kumar, M. Clarks. Clinical Medicine, Edizioni Elsevier Saunders. 8 Ed. 1304 pp. 2012• W.D. McArdle, F.I. Katch, V .L. Katch. Sports and Exercise Nutrition. Edizioni Lippincott
Raven. 4 ed. 681 pp. 2012
97Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#98,98,"CAPITOLO IV
I LIPIDI ED IL METABOLISMO LIPIDICO
Riassunto
I lipidi sono composti molto importanti per l’uomo e comprendono differenti
classi di molecole, diverse tra loro per struttura chimica, abbondanza,distribuzione e funzione. Tra i lipidi più abbondanti ricordiamo i fosfolipidi,costituenti essenziali delle membrane biologiche ed i triglicilgliceroli, cherappresentano, senza dubbio, la principale riserva energetica dell’uomo. Altriancora, seppur meno abbondanti, svolgono una funzione ormonale, agisconoda agenti emulsionanti, da messaggeri o regolatori della fluidità dellemembrane cellulari. La maggior parte dei lipidi vengono assorbiti con glialimenti, veicolati nell’organismo tramite le lipoproteine ed accumulati negliadipociti. Tuttavia, in condizioni di surplus calorico, essi possono esseregenerati anche per sintesi endogena, partendo per esempio dai carboidrati ineccesso. In caso di necessità il nostro organismo è in grado di mobilizzare ilipidi dal tessuto adiposo e distribuirli alle cellule, le quali, metabolizzandoli,possono ricavare da essi una notevole quantità di energia. Sintesi edegradazione dei lipidi sono processi strettamente regolati dall’azione diormoni quali insulina, glucagone e adrenalina. 
98Fondamenti della Scienza dell’Alimentazione Capitolo IV"
data_test\rootfolder\varie\Alimentazione\Fond_Scienza_Aliment.pdf#99,99,"4.1 I lipidi 
I lipidi sono generalmente molecole organiche fortemente idrofobiche e quindiinsolubili in solventi acquosi. La classe dei lipidi comprende molecolestrutturalmente molto diverse tra loro quali i triacilgliceroli, le cere, gli steroli,i fosfolipidi e i glicolipidi. Nel nostro organismo i lipidi adempiono a differentifunzioni: rappresentano la principale riserva energetica dell’uomo, agisconoda isolanti termici, forniscono protezione meccanica, sono costituentiessenziali delle membrane cellulari, agiscono da molecole segnale, sonoprecursori di numerosi ormoni, e ottimi combustibili per la produzione dienergia.
4.2 Gli acidi grassi
Il carattere idrofobico dei lipidi è legato alla presenza, nella loro struttura,degli acidi grassi. Gli acidi grassi sono molecole sostanzialmente apolari,costituite da catene idrocarburiche di varia lunghezza e differente grado diinsaturazione. La loro formula generica è riportata nella Figura 1:
CH
3-(CH2)n-CH2-COO-
Figura 1: formula di struttura di un acido grasso
La maggior parte degli acidi grassi presenti in natura contiene un numero paridi atomi di carbonio, compreso tra 16 e 22-24, ed un numero di doppi legamivariabile generalmente tra zero e quattro. Gli acidi grassi che non contengonodoppi legami vengono definiti saturi, quelli con un doppio legame,monoinsaturi e quelli con un numero maggiore di doppi legami, vengonodefiniti polinsaturi (PolyUnsaturated Fatty Acids, PUFA). Uno degli acidigrassi più diffuso negli alimenti è l’acido oleico, un acido grasso monoinsaturocostituito da 18 atomi di carbonio. Il doppio legame presente negli acidi grassiinsaturi può assumere configurazione “cis” o “trans”, a seconda che i dueatomi di idrogeno che si legano ai due atomi di carbonio, giacciano o menosullo stesso piano (vedi Figura 2). In natura la maggior parte degli acidi grassiinsaturi presentano doppi legami nella configurazione “cis” mentre quelli conconfigurazione “trans” sono più rari. Per esempio la carne bovina ed ovina, iformaggi ed il latte non contengono più del 2-8% di acidi grassi nellaconfigurazione “trans”.
99Capitolo IV Fondamenti della Scienza dell’Alimentazione"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#0,0,Diagrammi a Blocchi
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#1,1,"Cos’è un diagramma a blocchi?Il diagramma a blocchi (diagramma di flusso o flow chart) è uno schema a blocchi utilizzato per rappresentare gli algoritmi.
Si tratta di una rappresentazione grafica che utilizza delle forme geometriche per descrivere gli algoritmi."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#10,10,"Cos’è una variabile?Le variabili sono aree di memoria RAM dove vengono memorizzati i dati e che possono essere cambiati durante l’esecuzione di un’applicazione.
Le costanti invece contengono un valore non modificabile.
Per entrambe è opportuno dare dei nomi sensati, non troppo lunghi e non separati da spazi."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#11,11,"Esercizi struttura sequenziale (1)Eseguire il prodotto tra due numeri;
Calcolare l'ipotenusa date le misure dei cateti di un triangolo rettangolo
Date 2 variabili, scambiarne il contenuto;
Calcolare il numero minimo di banconote per un importo in euro, tenendo conto dei diversi tagli da 500, 200, 100, 50, 20, 10, 5 euro.

"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#12,12,Esercizi struttura condizionale (1)
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#13,13,Esercizi struttura iterativa (1)
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#14,14,"Esercizi vettori (1)Caricamento di 10 numeri in un vettore;
Somma degli elementi di un vettore;
Ricerca di un valore all’interno di un vettore."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#2,2,"Cos’è un algoritmo? A cosa serve?Per algoritmo si intende una successione di passi (o istruzioni) che definiscono le operazioni da eseguire sui dati per ottenere i risultati.
Esempi di algoritmi ne troviamo tantissimi, anche nella vita di tutti i giorni. Tipicamente è necessario un algoritmo a fronte di un problema, come ad esempio: andare a scuola; per risolvere questo problema dobbiamo seguire una sequenza ordinata e finita di passi (algoritmo), come ad esempio:
Svegliarsi  Fare colazione  Vestirsi  Uscire di casa  Prendere l’autobus  Entrare in classe
Quindi, l’insieme dei passi che consentono di risolvere un problema prende nome di algoritmo."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#3,3,"Come si descrive un algoritmo?Ci sono tanti modi per rappresentare un algoritmo, un metodo molto utilizzato è quello basato sui diagrammi a blocchi, conosciuti anche con il nome di flow chart (letteralmente diagrammi di flusso).
Sono dunque utilizzati dei blocchi, cioè delle forme geometriche e ciascuna di essa ha un significato ben preciso."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#4,4,"Quanti e quali blocchi abbiamo in un diagramma?I blocchi convenzionalmente utilizzati in un flow chart sono:
Ellisse
Parallelogramma
Rettangolo
Rombo"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#5,5,"EllisseL’ellisse è utilizzata semplicemente solo per indicare l’inizio e la fine di un diagramma a blocchi.
Quindi ciascun diagramma inizierà con il blocco inizio e terminerà, dopo aver risolto il compito assegnato, con il blocco fine."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#6,6,"ParallelogrammaIl parallelogramma è utilizzato per prendere dei dati in INPUT o per visualizzare dei dati in OUTPUT. 
Nel caso in cui deve prendere dei dati in input è consigliabile inserire una I in alto a sinistra, seguita dai due punti. Similmente per l’output, che si è soliti indicare con una O in alto a sinistra, sempre seguita dai due punti (ma va bene una qualunque altra convenzione)."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#7,7,"RettangoloIl rettangolo è utilizzato per eseguire dei calcoli, ovvero per elaborare dei dati. 
Ad esempio: per calcolare la somma tra due numeri, l’area di un rettangolo, la media fra tre numeri, …"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#8,8,"RomboIl rombo è utilizzato per le istruzioni condizionali, ovvero per porre una domanda. All’interno dunque viene fatto un test, per cui si valuta una condizione che può essere o vera o falsa, quindi si sceglie tra due strade diverse. 
Un esempio di semplice test potrebbe essere quello di vedere se un numero è positivo o negativo."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#9,9,RomboIl rombo viene spesso utilizzato anche per i cicli while e do-while.
data_test\rootfolder\varie\HTML&CSS.pptx#0,0,HTML e CSS
data_test\rootfolder\varie\HTML&CSS.pptx#1,1,"Tag base dell’HTML: <p>, <div> e <span><p>, <div> e <span> sono tre diversi tipi di contenitori (di testo o altro), e si comportano in modo diverso:
<p> è un elemento di blocco e lascia spazio prima e dopo la propria chiusura;
<div> è un elemento di blocco, non lascia spazio prima e dopo la propria chiusura, ma va a capo;
<span> è un elemento inline e quindi non va a capo."
data_test\rootfolder\varie\HTML&CSS.pptx#2,2,"Tag base dell’HTML: <ul>, <ol> e <li><ul> e <ol> sono tag che descrivono l’inizio di una lista, in particolare:
<ul> per le liste non ordinate;
<ol> per le liste ordinate.
<li> serve a descrivere l’inizio di un elemento della lista.
Esempio di utilizzo:
"
data_test\rootfolder\varie\HTML&CSS.pptx#3,3,"Tag base dell’HTML: <table>, <tr>, <th> e <td><table> descrive l’inizio di una tabella, e contiene al suo interno i tag <tr>, che descrivono l’inizio di una riga; i tag <tr> a loro volta possono contenere due tag:
<th> per descrivere una cella di «testata»;
<td> per descrivere una generica cella di contenuto."
data_test\rootfolder\varie\HTML&CSS.pptx#4,4,"Tag base dell’HTML: <img><img> serve per inserire un’immagine all’interno della pagina, l’attributo «src» dei questo tag serve a specificare quale immagine caricare."
data_test\rootfolder\varie\HTML&CSS.pptx#5,5,"Tag base dell’HTML: <form>Un form (modulo) è una sezione di documento HTML che contiene elementi di controllo che l’utente può utilizzare per inserire dati o in generale per interagire. I dati inseriti possono essere poi inoltrati al server dove un agente può processarli. Gli elementi di controllo sono caratterizzati da un valore iniziale e da un valore corrente. Gli elementi di controllo possono essere: 
Bottoni di azione
Checkbox (caselle di spunta)
Radio Button (bottoni mutuamente esclusivi)
Liste di selezione (lista di opzioni)
Caselle di inserimento di testo"
data_test\rootfolder\varie\HTML&CSS.pptx#6,6,Esercizi
data_test\rootfolder\varie\homework\id-homework-1.pptx#0,0,Ingegneria dei dati 2022/2023Homework 1Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-1.pptx#1,1,"Homework 1Leggere l'articolo (divulgativo) di Andrew Ng ""Data-centric AI"" (https://spectrum.ieee.org/andrew-ng-data-centric-ai)
In una relazione di circa 300 parole: 1) descrivi quella consideri la tesi più importante dell'autore e 2) esprimi la tua posizione rispetto ad essa. 

Termini di consegna: inviare la relazione entro le ore 12:00 del14 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-2.pptx#0,0,Ingegneria dei dati 2022/2023Homework 2(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-2.pptx#1,1,"Homework 2A partire dal codice github dell'ing. Tommaso Teofili (https://github.com/tteofili/lucenex):
scrivere un programma Java che indicizza i file .txt contenuti in una directory del proprio laptop. In particolare, si devono considerare due campi (e quindi creare due indici): il nome del file, il contenuto del file. Per ciascun campo utilizzare un analyzer appropriato
scrivere un programma Java che legge una query da console, interroga l'indice e stampa il risultato. Usare una semplice sintassi per la query (ad esempio, una query inizia con la parola chiave nome o contentuto seguita da una sequenza di termini (eventualmente racchiusi tra virgolette per esprimere una phrase query)
testare il sistema con una decina di query diverse

Scrivere una relazione che, oltre a riportare l'url del proprio progetto su Github (o analogo) descriva:
gli analyzer che si è scelto di utilizzare (motivando le scelte)
il numero di file indicizzati e i tempi di indicizzazione
le query usate per testare il sistema"
data_test\rootfolder\varie\homework\id-homework-2.pptx#2,2,"Homework 2
Termini di consegna: inviare la relazione entro le ore 21:00 del 22 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-3.pptx#0,0,Ingegneria dei datiHomework 3(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-3.pptx#1,1,"Homework 3Implementare l'algoritmo ""MergeList"" per la soluzione al problema ""Joinable Table Search""
Utilizzare la libreria Apache Lucene
Testare la correttezza dell'algoritmo su un piccolo insieme di tabelle, appositamente costruito
Testare l'efficacia e l'efficienza dell'algoritmo sulle tabelle contenute nel dataset ""tables"" del progetto Mentor: https://gitlab.com/Rm3UofA/Mentor/Datasets"
data_test\rootfolder\varie\homework\id-homework-3.pptx#2,2,"Homework 3Ogni team deve preparare 
una presentazione di 5' per illustrare le caratteristiche del dataset 
una presentazione di 10' minuti per illustrare la valutazione sperimentale della propria implementazione dell'algoritmo ""MergeList""
Termini di consegna: entro le ore 19:00 del 2 novembre 2022 ogni membro del team deve inviare le due presentazioni al docente compilando il seguente modulo (compilare il modulo due volte, una per ciascuna presentazione):
             https://forms.office.com/r/PYP0ncXYqc 

Quattro team (scelti dal docente) presenteranno il proprio lavoro nella lezione del 3 novembre 2022


"
data_test\rootfolder\varie\homework\id-homework-3.pptx#3,3,"Presentazione Caratteristiche del DatasetDurata 5'
Deve riportare statistiche sul dataset ""tables"" che possano essere utili all'analisi del problema, all'implementazione dell'algoritmo di soluzione e alla sua valutazione. 
Ad esempio:
Numero di tabelle
Numero medio di righe
Numero medio di colonne
Numero medio di valori nulli per tabella
Distribuzione numero di righe (quante tabelle hanno 1, 2, 3, 4, etc. righe)
Distribuzione numero di colonne (quante tabelle hanno 1, 2, 3, 4, etc. colonne)
Distribuzione valori distinti (quante colonne hanno 1, 2, 3, 4, etc valori distinti)
Altro a vostra scelta
Presentare le statiche in maniera opportuna, anche attraverso l'uso di rappresentazioni grafiche
"
data_test\rootfolder\varie\homework\id-homework-3.pptx#4,4,"Presentazione Valutazione SperimentaleDurata 10'
Deve includere
Descrizione ad alto livello dell'implementazione (classi e metodi principali)
Principali problemi riscontrati nell'implementazione
Valutazione sperimentale:
Con una descrizione chiara e precisa di obiettivi e metriche di ciascun esperimento"
data_test\rootfolder\varie\homework\id-homework-4.pptx#0,0,Ingegneria dei datiHomework 4(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-4.pptx#1,1,"Homework 4 - Esercizio 1Scegliere una tipologia di prodotti su amazon.it (ad esempio fotocamere, oppure prodotti senza glutine)
Scegliere un pagina con un prodotto della tipologia scelta
Individuare nella pagina almeno 5 caratteristiche del prodotto
Scrivere un'espressione XPath per estrarre il nome, il prezzo e il valore di ciascuna delle caratteristiche individuate al punto precedente
Verificare che le espressioni XPath funzionino correttamente su almeno altre 10 pagine di prodotti della stessa categoria
Se una regola XPath non funziona, correggerla affinchè funzioni correttamente su tutte e 10 le pagine

"
data_test\rootfolder\varie\homework\id-homework-4.pptx#2,2,"Homework 4 - Esercizio 2Scegliere un tipo di entità di interesse (ad esempio, giocatori di basketball, aziende, università, etc.)
Cercare 5 sorgenti Web che pubblicano pagine di dettaglio di istanze dell'entità scelta (ad esempio siti web che pubblicano pagine di giocatori di basketball)
Su ogni sorgente scegliere 5 pagine di dettaglio
Scrivere espressioni XPath per estrarre I valori di (almeno) 5 attributi rilevanti su tutte le pagine scelte
"
data_test\rootfolder\varie\homework\id-homework-4.pptx#3,3,"Termini di consegnaOgni studente deve preparare individualmente una relazione in cui descrive l'attività svolta per portare a termine l'homework
Termini di consegna: entro le ore 19:00 del 19 novembre 2022 inviare la relazione al docente compilando il seguente modulo:
             https://forms.office.com/r/PYP0ncXYqc 


"
data_test\rootfolder\varie\homework\id-homework-5.pptx#0,0,Ingegneria dei datiHomework 5(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-5.pptx#1,1,"Homework 5Obiettivo: creare un dataset strutturato con dati estratti da sorgenti Web
Ci interessano dati su una tipologia di entità: aziende
Per semplicità, ci concentriamo su sorgenti in lingua inglese
Scrivere un programma di estrazione dati per almeno 1000 istanze da almeno 4 sorgenti web"
data_test\rootfolder\varie\homework\id-homework-5.pptx#2,2,"TecnologieE' possibile usare una delle seguenti tecnologie (ma è possibile usarne altre)

In Python: 
https://scrapy.org/ 
https://www.crummy.com/software/BeautifulSoup/
In Java: 
https://www.selenium.dev/ 
https://jsoup.org/ 

"
data_test\rootfolder\varie\homework\id-homework-5.pptx#3,3,"Termini di consegnaOgni team deve preparare una presentazione così strutturata
1 minuto per illustrare come è stata scelta la tecnologia per implementare il sistema di estrazione
2 minuti per illustrare l'architettura del sistema di estrazione dati realizzato
3 minuti per illustrare le prestazioni del sistema di estrazione
4 minuti per illustrare le caratteristiche delle sorgenti e le caratteristiche del dataset ottenuto
Termini di consegna: 
entro le ore 19:00 del 9 dicembre 2022 inviare la presentazione al docente compilando il seguente modulo: https://forms.office.com/r/PYP0ncXYqc 
Il 13 dicembre, ogni team dovrà consegnare il dataset con i dati estratti al docente (in un file compresso). Ogni team può liberamente scegliere in che modo strutturare il dataset
Quattro team (scelti dal docente) presenteranno il proprio lavoro nelle lezioni del 13 e del 15 dicembre 2022
"
data_test\rootfolder\varie\homework\id-homework-6.pptx#0,0,Ingegneria dei datiHomework 6(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-6.pptx#1,1,"Homework 6Leggere uno tra questi due articoli: 
Y. Suhara et at ""Annotating Columns with Pre-trained Language Models"" (https://arxiv.org/pdf/2104.01785.pdf) 
K. Koutras et at ""Valentine: Evaluating Matching Techniques for Dataset Discovery""(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458921) 
In una relazione di circa 900 parole, descrivere: 1) descrivere  il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 
Leggere l'articolo (scientifico):
P. Konda et al. ""Magellan: Toward Building Entity Matching Management Systems"" (http://www.vldb.org/pvldb/vol9/p1197-pkonda.pdf)
In una relazione di circa 900 parole, descrivere: 1) il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 

Termini di consegna: inviare le due relazioni entro le ore 18:00 del 5 gennaio 2023 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-7.pptx#0,0,Ingegneria dei datiHomework 7(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-7.pptx#1,1,"Homework 7L'obiettivo dell'homework è quello di valutare il sistema CERTA per la generazione di spiegazioni di diversi sistemi di Record Linkage basati su tecniche di deep learning

Seguire le istruzioni riportate a questo indirizzo:
	 https://gist.github.com/tteofili/eaaeaaa8af2d22005fe199f1dc8874ad 

Termini di consegna: entro le ore 18.00 del 21 gennaio 2023 caricare il file cvv nel seguente modulo:
	https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#0,0,Ingegneria dei datiHomework 8(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#1,1,"Homework 8L'obiettivo dell'homework è quello di integrare le sorgenti dati collezionate da tutti i team nell'homework 5 e di arricchirle con le tecniche sviluppate nell'homework 3 
Analizzare le sorgenti dati e individuare le principali eterogeneità
Definire uno schema mediato opportuno ed allineare gli schemi delle sorgenti allo schema mediato. È possibile usare:
Una soluzione custom (anche manuale)
FlexMatcher https://flexmatcher.readthedocs.io/en/latest/ 
Coma https://sourceforge.net/projects/coma-ce/  
Uno dei tool del progetto Valentine https://github.com/delftdata/valentine
Calcolare il Record linkage. E' possibile usare:
Una soluzione custom
Python Record Linkage Toolkit https://recordlinkage.readthedocs.io/en/latest/ 
Magellan https://github.com/anhaidgroup/deepmatcher
DeepMatcher (soluzione neural network) https://github.com/anhaidgroup/deepmatcher 
Ditto (soluzione neural network) https://github.com/megagonlabs/ditto 
EMT (soluzione neural network molto simile a Ditto) https://github.com/brunnurs/entity-matching-transformer 
Un sistema non supervisionato  https://github.com/uestc-db/Unsupervised-Entity-Resolution oppure https://github.com/chu-data-lab/zeroer
Arricchire i dati integrati usando le tecniche (e il dataset di tabelle) sviluppate nell'homework 3
"
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#2,2,"Termini di consegnaPreparare un documento scritto di 4 pagine e una presentazione di 15' che descrivano:
Le caratteristiche salienti delle sorgenti
I benefici potenziali di integrare i loro dati
Lo schema mediato
Le soluzioni che avete scelto per integrare i dati
Le prestazioni (in termini id precision, recall, F-measure, tempi di calcolo, sforzo umano)
I dati tabulari che avete trovato per arricchire le informazioni integrate dalle sorgenti
Il documento e la presentazione vanno consegnati caricandoli attraverso il modulo all'indirizzo:
	https://forms.office.com/r/PYP0ncXYqc
"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#0,0,"Caratteristiche del dataset tables - Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#1,1,Formato del dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#10,10,Distribuzione numero di colonne
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#11,11,Distribuzione numero di valori distinti per colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#12,12,Distribuzione percentuale di valori distinti per colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#2,2,Formato del dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#3,3,"Formato delle celle
	- Celle vuote e «None»
	- Classificazione tipi di cella"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#4,4,"Formato delle celle
	- Frequenza di termini all’interno del dataset"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#5,5,"Formato delle celle
	- Frequenza di termini all’interno del dataset"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#6,6,"Formato delle righe
	- Righe con celle vuote e con celle «None»"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#7,7,"Formato delle colonne
	- Colonne con celle vuote e con celle «None»
	- Classificazione tipi di colonna"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#8,8,Distribuzione numero di righe
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#9,9,"Fun Fact
	- Tabelle con 100 righe: 5 076"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#0,0,"Ingegneria Dei Dati:Valutazione Sperimentale Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638dedo99/Homework3 (github.com)Link Repository Progetto:"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#1,1,"Organizzazione del progetto: packageIndex
indicizzazione di tutto il file in inputModel
modello utilizzato per estrarre i dati dal datasetQuery
esecuzione delle query ed estrazione dei documenti ritenuti compatibili"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#10,10,"Valutazione sperimentale del progetto (2)Tempo necessario per l’indicizzazione dell’intero file JSON contenente 550.271 tabelle (14,2 Gb): 297.882 s (c.a. 5 minuti)

Query d’esempio [«singlular», «plural», «fmou», «dual»], tempo di esecuzione:
Con SimpleTextCodec: 18 minuti
Senza SimpleTextCodec: 6 secondi"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#11,11,"Valutazione sperimentale del progetto (3)Per testare l’efficacia e l’efficienza del sistema sono state effettuate tre tipologie di test:

Test al variare di k

Test al variare della lunghezza della query

Precision, Recall, F1 e Accuracy su dataset di test"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#12,12,Test al variare di k
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#13,13,Test al variare della lunghezza della query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#14,14,"Dataset di testÈ stato costruito un dataset per testare l’efficacia del sistema, con le seguenti caratteristiche:

30 tabelle

Ogni tabella riporta informazioni su film, libri, autori, attori, …"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#15,15,Dataset di test
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#16,16,Dataset di test: distribuzione righe
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#17,17,Dataset di test: distribuzione colonne
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#18,18,Dataset di test: distribuzione valori distinti
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#19,19,"QuerySono state costruite 23 query di test, ottenute calcolando lo score Jaccard fra tutte le possibili coppie di colonne all’interno del dataset. Ogni query di test contiene:

Colonna di valori che rappresenta la query

Top 3 colonne con score Jaccard più alto"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#2,2,Le classiIndexCellModelCoordinatesQueryJSONObjectJSONIndexerQueryManager
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#20,20,Query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#21,21,"Precision, Recall, F1 e Accuracy"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#22,22,"QuerySolo per una query il sistema non restituisce alcun risultato corretto:
[«USA», «USA», «USA», «USA», «USA», «USA», «USA»]

Le altre query su cui il sistema fatica a restituire il risultato corretto sono molto simili:
[«USA», «Italia», «Italia», «Francia», «Inghilterra», …]"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#3,3,"Classe JSONIndexer (1)La classe JSONIndexer è composta da due metodi:


readJsonStream(InputStream in, Codec codec): lettura dell’input dal file JSON


indexJSONStream(JsonReader reader, Codec codec): estrazioni degli oggetti JSON (tabelle) dal reader, parsing in un oggetto Java e successiva indicizzazione. I documenti inseriti nell’indice corrispondono ciascuno ad una colonna di una tabella.


Uso della libreria Gson per convertire rappresentazioni JSON in oggetti Java e viceversa."
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#4,4,"Classe JSONIndexer (2)Definizione di un Tokenizer CustomCreazione dei documentiAnalyzer analyzer = CustomAnalyzer.builder()        .withTokenizer(PatternTokenizerFactory.NAME, ""pattern"", ""~"", ""group"", ""-1"")        .build();for(Cell c : obj.getCells())    if (!c.getHeader()) {        if(colonnaXvalori.containsKey(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString())) {            String value = colonnaXvalori.get(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString());            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), value + ""~"" + c.getCleanedText());        } else            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), c.getCleanedText());    }"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#5,5,"Classi JsonObject, Cell e CoordinatesLe classi JsonObject, Cell e Coordinates sono stati realizzate per rendere agevole la trasformazione da un oggetto Json ad un oggetto Java.

Le seguenti classi sono dotate di variabili di istanza, relative alle sole informazioni necessarie rispetto al completo contenuto dell’oggetto Json, e i corrispondenti metodi setter e getter.public class JSONObject {
 String id;
 Cell[] cells;
}public class Cell {
 Boolean isHeader;
 String cleanedText;
 Coordinates Coordinates;
}public class Coordinates {
 Double row;
 Double column;
}"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#6,6,"Classe QueryManager
mergeList(int n, String[] queryString) restituisce le prime n colonne tra tutte le tabelle che hanno corrispondenze con il maggior numero di termini nella query

executeQuery(String field, String[] queryString) genera una mappa (idTabella_idcolonna -> numero corrispondenze) scansionando tutti gli elementi presenti nella query

sortMapByValues(Map<String, Integer> columnsXcount) effettua l’ordinamento della mappa sull’intero contenuto nel campo valore

runQuery(IndexSearcher searcher, Query query,  Map<String, Integer> columnsXcount) restituisce per ciascun elemento della query una mappa con le colonne delle tabelle in cui è presente

"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#7,7,"Problemi riscontratiIndividuare la corretta rappresentazione dei documenti nell’indice

Individuare un modo corretto di tokenizzare i documenti (nello specifico il campo ‘value’)

Tempi di indicizzazione"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#8,8,"ObiettiviImplementare nel modo più efficiente l’indicizzazione di una grande quantità di dati

Restituire, a seguito di una query, le tabelle con la relativa colonna in cui sono state incontrate delle corrispondenze senza includere nel conteggio eventuali ripetizioni dello stesso termine nella colonna 

Restituire in ordine decrescente i risultati sulla base del numero di corrispondenze ottenute"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#9,9,"Valutazione sperimentale del progetto (1)Tutti i risultati sono stati ottenuti utilizzando un calcolatore con le seguenti specifiche:

Processore Intel core i7 di 8° gen

RAM 8Gb

SSD 512Gb"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#0,0,"Web Scraping:Scraping business informationDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
13 Dicembre 2022Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselGitHub: Web Scraping- Homework5"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#1,1,"Purpose del progettoIntroduzioneAutomatizzazione della ricerca ed estrazione di informazioni relative ad aziende


Utilità

Creazione di un dataset relativo ad aziende per diversi task:
Addestramento modello AI
Analytics

Data IntegrationScopo"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#10,10,Sorgente: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#11,11,Sorgente: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#12,12,"Efficacia X-Paths: Data ConsistencyAnalisi pattern

Address, Business code, Business name (E-business), Date, ecc…

Analisi frequenza valori celle 
Legal form, Status, ecc…



Analisi frequenza token 
Business name, ecc…Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#13,13,"Efficacia X-Paths: Analisi PatternTable: GOV.UK

Field: Address

Example values: '38SpringfieldRoad Gillingham Kent England ME71YJ’



    
Regex: 
	([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|
	(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|
	([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\s?[0-9][A-Za-z]{2})
UK Postal codeLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#14,14,"Efficacia X-Paths: Analisi PatternIndirizzi non conformi

Austrasse429490 Vaduz Liechtenstein

Pasiadou5KatoLakatamia 2332Nicosia Nicosia Cyprus

LaChausseeStreet PortLouis MauritiusLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#15,15,"Efficacia X-Paths: Frequenza ValoriTable: E-Business

Field: Legal form

Example values:
Private limited company, Public limited company, Non-profit association, ecc…


    
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#16,16,Efficacia X-Paths: Frequenza ValoriLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#17,17,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Example values: P & A PROPERTY (WESTON) LIMITED, P A JONES LIMITED, P A H 		       CARPENTRY & JOINERY LTD  

	
    
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#18,18,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Most frequent tokens:
Limited, LTD,LTD., Services, …


    
Analisi

1466 su 1469 hanno nel loro nome 
      i 10 token più frequenti
1 ) LIMITED -> 728
2 ) LTD -> 533
3 ) SERVICES -> 94
4 ) ELECTRICAL -> 38
5 ) CONSTRUCTION -> 37
6 ) BUSINESS -> 36
7 ) CORP. -> 35
8 ) PROPERTIES -> 34
9 ) HOMES -> 27
10 ) LTD. -> 26
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#19,19,"Test sistema: WorkflowIl sistema è stato testato nel seguente modo:
Campionamento casuale del dataset estratto:
Companiesmarketcap  30 URL
Infoclipper  50 URL
GovUK  29 URL
Ebusiness  30 URL
Estrazione manuale dei dati contenuti nel campione selezionato
Confronto dati estratti dal sistema e dati ottenuti manualmente
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#2,2,"Ricerca sitiFiltraggio sitiSchema datiParsing dati &
Data ConsistencyAcquisizione datiAnalisi datiRoad mapIntroduzione"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#20,20,"Test sistema: companiesmarketcap.comLilla SystemErrori dovuti esclusivamente alla variabilità giornaliera dei campi
"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#21,21,Test sistema: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#22,22,Test sistema: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#23,23,"Test sistema: info-clipper.comLilla SystemPostalcode
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {187’, 00187’} 
State
Nel nostro sistema nel campo state inseriamo anche la sigla dello stato, nei test l’utente non inserisce nel campo State la sigla  {'California(CA)', 'California'} "
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#24,24,Test sistema: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#25,25,"Test sistema: gov.ukLilla SystemCompany ID
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {'6174105', '06174105’} 
Company Status
Gli errori sono dovuti al cambiamento di status dell’azienda  {'Active', 'Dissolved'}
Dissolution Date
L’azienda nel frattempo è stata dissolta  {'nan', 14 February 2023 '} 
"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#26,26,"Efficienza temporale: Estrazione datiTempo complessivo

Tempo di request 

Tempo di estrazione del dato (navigazione del dom via X-Path)
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#27,27,Efficienza temporale: RequestLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#28,28,"Efficienza temporale: Estrazione datiLilla System//div[@class = ""company-code""]//*[@id=""cmkt""]/div[3]/div[1]/div[2]/div[3]/div[1]/a/text()"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#29,29,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#3,3,"
Beautiful soup

Request

LXML & Etree
Web ScrapingPandas & numpy                    	
Matplotlib

Geopandas
Data ProfilingTecnologieLilla SystemPython"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#30,30,"Dataset: companiesmarketcap.com   Analisi campi

Name: Nome dell’azienda
Company Code: Codice identificativo delle società quotate in borsa (WMT, AMZN, UPS, KR, …)
Marketcap: Somma del valore totale delle azioni in circolo
Share Price: Costo singola azione
Earnings: Profitto annuo
Revenue: Ricavi annui
Shares: Numero totale di azioni in circolo
Employees: Numero totale di dipendenti


  Numeriche generali

Totale istanze: 1400
Totale colonne: 10


Celle totali: 14000
Valori nulli: 21Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#31,31,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#32,32,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#33,33,Dataset: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#34,34,"Dataset: e-BusinessAnalisi campi

Name: Nome dell’azienda
Company code: Codice identificativo dell’azienda
Legal Form: Forma giuridica dell’azienda
Status: Status dell’azienda (Deleted, Entered into the register, ecc…)
Registration Date: Data di inserimento dell’azienda nel registro
Capital: Capitale dell’azienda
Address: Indirizzo sede dell’azienda
Deletion Time: Data di eliminazione dell’azienda dal registro

  Numeriche generali

Totale istanze: 1469
Totale colonne: 10



Celle totali: 14690
Valori nulli: 2120 Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#35,35,Dataset: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#36,36,Dataset: e-BusinessESTONIALilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#37,37,"Dataset: info-clipper.comAnalisi campi

Name: Nome dell’azienda
Trade Name: Nome commerciale dell’azienda
Address: Indirizzo sede dell’azienda
City: Città 
Postalcode: Codice postale nei formati UK, USA, Italia, Estonia
State: Stato Americano di residenza o Nazione di residenza
Country: Nazione di residenza
Location type: Tipo di sede (es. Headquarter, Secondary Office, ecc…)



  Numeriche generali

Totale istanze: 1504
Totale colonne: 10



Celle totali: 15040
Valori nulli: 1289Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#38,38,"Dataset: info-clipper.com


Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#39,39,"Dataset: info-clipper.com


STATI UNITILilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#4,4,"Lilla
SystemGeneral web pageRequest: get informationResponse: list of linksRequest: get all linksResponse:  informationCreate datasetSpecific web pageDatasetData Parsing and
Data ConsistencyArchitetturaLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#40,40,"Dataset: info-clipper.com


ESTONIALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#41,41,"Dataset: info-clipper.com


ITALIALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#42,42,"Dataset: info-clipper.com


INGHILTERRALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#43,43,"Analisi campi

Name: Nome dell’azienda
Company ID: Codice identificativo dell’azienda
Company Status: Status dell’azienda (Active, Dissolved, Registered, Liquidated)
Company Type: Tipo dell’azienda (Overseas Entity, Private Limited Company, ecc…)
Registration Date: Data di registrazione di aziende estere
Incorporation Date: Data di inserimento delle aziende inglesi nel registro
Dissolution Date: Data di dissoluzione dell’azienda
Office Address: Indirizzo dell’azienda


Dataset: gov.uk  Numeriche generali

Totale istanze: 1331
Totale colonne: 10



Celle totali: 13310
Valori nulli: 2555Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#44,44,Dataset: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#45,45,Dataset: gov.ukREGNO UNITOLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#46,46,Dataset: gov.ukINGHILTERRALilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#47,47,"Member: Pietro Baroni
Matricola: 536373
Task: Algoritmi
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Task: Analytics
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693 
Task: AlgoritmiLinkedin: Matteo WisselTeamLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#48,48,"GRAZIE PER L’ATTENZIONERoma, 13  Dicembre 2022GitHub: Web Scraping- Homework5"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#5,5,Sorgente: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#6,6,Sorgente: ariregister.rik.ee (e-Business)Lilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#7,7,Sorgente: ariregister.rik.ee (e-Business)Lilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#8,8,Sorgente: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#9,9,Sorgente: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#0,0,"Data integration:Arlecchino systemDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
22 Febbraio 2023Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselArlecchino System
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#1,1,"Purpose del progettoIntroduzioneUse Case

Integrazione di dataset aziendaliScopo

Implementazione di un sistema di Data IntegrationDataset

Dataset_Corso_Ingegneria_dei_Dati_2022/23
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#10,10,"ParsingArlecchino SystemParsing nomi colonne
Trasformazione in lower case  
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)  Parsing valori celle 

Parsing di stringhe: 
Trasformazione in lower case
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)
Esempio: Amazon -> amazon
  
Parsing di valori monetari:
Normalizzazione valori 
Inserimento unità di misura
Esempio: $102 million -> doll_ 0.102 b 

Parsing valori percentuali
Parsing valori rank
Parsing valori date
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#11,11,Schema matching: Formulazione problemaArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#12,12,"Schema Matching: Matching Module (SMM)Arlecchino SystemPre-processing module

Input: colonne e samples di valori 
Output: un dizionario parziale di sinonimi
Utilità: 1. riduzione del search space del JaccardModule
    2. inferisce informazioni al JaccardModule  
JaccardModule

Input: dizionario sinonimi_preprocessing
Output: dizionario sinonimi_finale
Utilità: trova le reali correlazioni semantiche tra le colonneUser"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#13,13,"SMM: MotivazioniArlecchino SystemAnalisi senza pre-processingAnalisi con pre-processingSample data: 1000 per colonna
Colonne totali: 18
Numero medio di sinonimi reali: 1.6 

Stima confronti totali: ≈ 153
Numero medio confronti per colonna: ≈ 18
Numero medio di confronti inutili: ≈ 17
Esempio 
cluster cbinsightsSample data: 1000 per colonna

Colonne totali: 18

Numero medio di sinonimi reali: 1.6

Stima confronti totali: 14
Numero medio confronti per colonna:  2.5
Numero medio di confronti inutili: 0.84

Fattore di riduzione: ≈ 12"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#14,14,"Pre-processing: Name SimilarityArlecchino SystemName similarity di colonne

Input: (column_names, dizionario_sinonimi_pregressi)
Output: un dizionario parziale di sinonimi
Utilità: individua i sinonimi schema-wise 
	(dettati da similarità di nome)Logica:	
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#15,15,"Pre-processing: Data CorrelationArlecchino System

Data similarity di colonne [1]

Input: (sample_dati_colonne)
Output: un dizionario sinonimi4cluster
Utilità: individua i sinonimi data-wise
	(dettati da similarità di dati) [1] Schema Matching using Machine LearningTanvi Sahay, Ankita Mehta, Shruti Jadon"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#16,16,"SMM: Features EngineeringArlecchino SystemFeatures selezionate
Min_val
Max_val
Avg
Variance
Standard_Dev
Is_incremental
Is_year Type_of_string (1 perc_, 2 rank_, 3 link, 4-5 monetari, 6 resto)
AVG_monetary_value
AVG_len_of_field
VAR_len_of_field
SDEV_len_of_field
Ratio_white_space
Ratio_numeric_values
Is_country (1 se country, 0 altrimenti)
Is_sector (1 se sector, 0 altrimenti)1. Type_of_data (0 string, 1 integer, 2 date)for Integerfor stringsfor date"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#17,17,"Pre-processing: Analisi OutputArlecchino SystemDizionario sinonimi_preprocessing (largo)

Unione dei dizionari di sinonimi prodotti dai due step di pre-processing
Scopo: limitare eventuali errori (high recall)
Esempio (companiesmarketcap):
Token: market_cap

True_sinonimi
	market_cap->{marketcap, market_capitalization, pricecap, …}
sinonimi4NameCorr
	market_cap->{marketcap, market_capitalization,…}

sinonimi4Clusters
	market_cap->{marketcap, pricecap, …}

sinonimi_preprocessing
	market_cap->{marketcap, market_capitalization, pricecap, …}
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#18,18,"SMM: JaccardModuleArlecchino SystemJaccardModule

Input: sinonimi_preprocessing

Logica: per ogni colonna c presente nel dizionario dei sinonimi_preprocessing, il sistema genera un file .csv contenente tutte le colonne giudicate sinonimi"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#19,19,"SMM: OutputArlecchino SystemDizionario sinonimi finali

Risultato finale del Matching module
Per ogni colonna dello schema mediato è definita  una lista di  possibili sinonimi (colonne semanticamente simili)

L’utente seleziona i match opportuni eliminando eventuali errori del sistema

Al netto della validazione dell’utente, il sistema aggiorna il dizionario dei sinonimi pregressi


User"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#2,2,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#20,20,Schema MediatoArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#21,21,"Record LinkageArlecchino SystemInput: schema mediato (184.587 record)

Output: dataset finale

Scopo: Trovare nella tabella in input i record relativi alla stessa entità ed unirli in un unico record

 Record Linkage
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#22,22,"Record Linkage: BlockingArlecchino SystemNumero di confronti iniziali: 34.072.360.569 Numero di confronti post-blocking: 2.177.713Tempi: 76 min 36 secBlocking step1. overlap di una parola nel nome delle aziende

2. overlap di una parola nel paese delle aziende (se presente)

3. Indice di Levenshtein < 0.7 tra i nomi
 delle aziende

"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#23,23,"Record Linkage: Training SetArlecchino SystemTotale record: 1300

Divisi in training set, test set e validation set (ratio 3:1:1)

Label Match: 695

Label No-Match: 605

Training set"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#24,24,"Record Linkage: Model TrainingArlecchino SystemIperparametri:
Epoche = 10
Dimensione batch = 16 
Statistiche:
Tempo impiegato: 10 min 29 secModello utilizzato: Matching Model di Deep MatcherModel Training"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#25,25,"Record Linkage: PredictionArlecchino SystemStatistiche:
Predizioni effettuate: 2.177.713
Predizioni Match: 1.480.727
Tempo impiegato: 14 ore e 45 minuti
Utilizzo del modello addestrato per eseguire le predizioni sulle coppie non bloccatePrediction"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#26,26,Record Linkage: JoinArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#27,27,Schema IntegratoArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#28,28,"ArricchimentoColonna usate come input:
Nome dell’azienda
CEO dell’aziendaTabelle con più occorrenze in output:
List of S&P 500 companies
List of largest companies by revenue
List of largest European manufacturing companies by revenue
List of multinationals with research and development centres in Israel
List of largest Nordic companies
Automotive industryPMF system(HW3)Top table ids Dataset utenteinput (Schema mediato, 
[name, ceo] )Indice HW3Arlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#29,29,Schema ArricchitoArlecchino System142 celle riempite
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#3,3,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#30,30,"Testing SMM: MetricheArlecchino SystemLogica

 Confronto tra i sinonimi computati per una colonna dello schema mediato S e i sinonimi veri S’

Metriche

Numero di confronti inutili effettuato per sorgente

Similarità tra sinonimi computati:
Precision
Recall
F1"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#31,31,Testing: Pre-Processing per clustering (Conf.)Arlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#32,32,Testing: performance SMM clusterArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#33,33,"Testing: Pre-Processing per clusteringArlecchino SystemRisultati
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#34,34,"Testing: JaccardModule for cluster Arlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0.5 "
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#35,35,Testing: Pre-processing for schema mediatoArlecchino SystemRisultati
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#36,36,Testing: performance SMM schema finaleArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#37,37,"Testing: Schema MediatoArlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0..5Pre-processingJaccardModule"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#38,38,Testing: Record LinkageArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#39,39,MiglioramentiArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#4,4,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#40,40,"Member: Pietro Baroni
Matricola: 536373
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693Linkedin: Matteo WisselTeamArlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#41,41,"GRAZIE PER L’ATTENZIONERoma, 22 Febbraio 2023GitHub: Arlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#5,5,"Analisi dei sorgentiDati finanziari
Dati giuridici
Dati geografici
Dati di personale
Etichette tipologie datiSorgenti	"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#6,6,"Struttura dello schema mediato Schema mediatoVisione unificata delle informazioni


Schema mediato
Benefici"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#7,7,Arlecchino SystemArlecchino System…
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#8,8,"TecnologieArlecchino SystemSchema Matching

Preprocessing Module - custom
JaccardModule - customRecord Linkage

Magellan (py_entitymatching)
DeepMatcherData Enrichment

 Sistema HW3"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#9,9,ArchitetturaArlecchino SystemParsing&CleaningSchema MatchingRecord Linkage
