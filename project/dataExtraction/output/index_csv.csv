path,page,text
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#0,0,Calcolatori  Elettronici T  Complementi ed Esercizi  di Reti Logiche  
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#1,1,Stefano Mattoccia  Ricevimento : su appuntamento via email    Telefono  : 051 2093860  Email   : stefano.mattoccia@unibo.it  Web   : www.vision.deis.unibo.it/smatt 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#10,10,"OE=0 0 1 U=? Quale valore logico assume U ? 
Che cosa è necessario garantire nella rete seguente ?  Quando il segnale U assume un valore logico significativo ? 1 U=? OE1 OE2 I1 I2 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#11,11,"Esercizio 1  Registro a 1 bit con uscita tri-state Utilizzando latch SR progettare una rete che, quando WE=1,memorizza sulluscita OUT il segnale di ingresso IN. Lultimo valore trasferito in uscita deve essere mantenuto per tutto il tempo in cui il segnale WE=0. La rete deve essere inoltre dotata di un segnale OE che, se a livello logico 0, pone il segnale di OUT nello stato di alta impedenza. WE IN OUT OE ? WE IN OE OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#12,12,"S Q Q* R WE IN OE OUT Soluzione 
La rete tratteggiata (8X) è un latch CD dotato di uscita tri-state ed esiste in forma integrata (‘373). Q 
NOTA - Perché le due reti seguenti NON sono equivalenti ? a b c b a c "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#13,13,"RSA notevoli: Flip-Flop D FFD D CK Q Q* D CK Q Q* FFD: RSA che assume il valore logico presente sull’ingresso D durante i fronti di salita (positive edge triggered) dell’ingresso CK 
Il FFD è tipicamente utilizzato come cella elementare di memoria  nelle reti sequenziali sincrone. In tal caso, il segnale CK, è un segnale di tipo periodico (clock). CK D Q "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#14,14,"FFD D CK Q Q* D CK Q Q* A_SET* A_RES* 
A_RES* A_SET* 
CK D Q* Q I FFD sono dotati di due ulteriori ingressi “asincroni” che consentono di settare (A_SET) o resettare (A_RES) Q indipendentemente da CK e D. A_SET* 
A_RES* Tipica realizzazione di  un FFD della famiglia  TTL (‘374) mediante 3  latch SR.  Q=0 se A_RES=1 Q=1 se A_SET=1  A_SET e A_RES sono  prioritari rispetto  a CK e D NOTA: i segnali asincroni di set e reset denominati nella slide (rispettivamente) A_SET e A_RES  sono spesso denominati (rispettivamente) PR e CL oppure S e R. Inoltre, se non indicati nello  schema logico si suppone che tali comandi siano non asseriti (A_SET=0 e A_RES=0). "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#15,15,"Vincoli di corretto impiego per i FFD   Tempi di Setup (τSU), Hold (τH) e Risposta (τR) FFD D CK Q Q* D CK Q Q* CK D Q τH τSU τR Il corretto funzionamento è garantito solo se τSU≥ τSUmin e τH ≥ τHmin. In caso contrario, metastabilità.   Cosa implicano i parametri τSUmin e τRmin indicati nei datasheet ? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#16,16,"Il FFD come elemento fondamentale delle RSS 
D CK Q Se all’ingresso CK viene inviato un segnale periodico (clock):   il FFD ritarda (D = Delay) il segnale di uscita Q, rispetto al  segnale di ingresso D, di un tempo pari al periodo di clock T  Qn+1 = Dn FFD D CK Q Q* D CK Q Q* 
T T T T "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#17,17,"Vincoli di campionamento e metastabilità Il mancato rispetto dei vincoli sul campionamento dei segnali porta  a metastabilità.  CK D Q τSU τH ???????????? 
0 1 metastabile 
stabile stabile ? ? 1? 0? τ = ??? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#18,18,"Sincronizzazione di segnali (non sincroni) FFD D CK Q I metastabile FFD D CK Q Stabile (?) I_sync I_M Normalmente i segnali provenienti dall’esterno (ma non solo) non sono sincroni con il clock della RSS. Questo è un problema molto comune.   Come gestire potenziali situazioni di metastabilità che potrebbero  compromettere il corretto funzionamento della RSS?  
CK •  La soluzione mostrata garantisce che l’uscita I_sync assume il valore   di I nel momento in cui tale segnale è stato campionato?   •  Sono sufficienti due livelli di FF?  •  Quali sono gli effetti collaterali di questa soluzione? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#19,19,Reti Sequenziali Sincrone (RSS) ? k (k) FFD k k FFD sull’anello di retroazione  Tutti con lo stesso clock di periodo T S S* S S* CK S U S* It t+T t+2·T t-T Nel caso specifico: Moore o Mealy ? Lo stato cambia anche se non cambia l’ingresso ? L’uscita cambia anche se non cambia l’ingresso ? CK 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#2,2,"Introduzione Reti Logiche: sintesi mediante approccio “formale” 
Calcolatori Elettronici: sintesi mediante approccio “diretto” Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL 
Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#20,20,"Alcune considerazioni sulle RSS •  Lo stato della rete cambia solo in corrispondenza dei fronti di   salita del clock che si susseguono con periodo T  •  La rete risponde ogni T ⇒ se si desidera massimizzare la velocità   di risposta della rete è necessario adottare il modello di Mealy   •  La rete è svincolata dai ritardi della rete G! Quindi, nessun   problema di corse critiche (purché T > τSUmin + τRmin !)  •  All’interno di uno stesso progetto sono tipicamente presenti più    RSS e non necessariamente per tutte le RSS il clock è lo stesso   e/o coincide con il clock del processore  •  Le RSS sono (più) facili da progettare delle RSA "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#21,21,"Clock gating e glitch sul clock Nelle reti sincrone è necessario evitare variazioni spurie (glitch) del segnale di clock che possono provocare commutazioni indesiderate dei FFD.   Ad esempio, per via dei reciproci ritardi tra i t segnali D[t-1..0] e/o le alee introdotte dalla rete combinatoria di decodifica, a causa del “clock gating“, può verificarsi quanto segue FFD D CK Q Q* D CK Q Q* CK P CK_G 
CK_G Glitch sul clock → commutazione spuria del FFD ! NO !! Rete di  Decodifica D[t-1..0] P t "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#22,22,"Il clock gating, oltre a generare potenziali glitch introduce  “clock-skew”. Ad esempio, consideriamo le due RSS seguenti Clock gating e clock-skew 
CK CK_G τAND FFD D CK Q Q* I1 CK B B* CK_G 1 FFD D CK Q Q* I2 CK A A* τAND 
τAND I clock delle due reti sono sfasati di un tempo pari al ritardo introdotto dall’AND. Tale fenomeno (“clock-skew”) è potenzialmente dannoso. Perchè ? 
Il “clock-skew” non è causato solo dal clock gating ma anche (ad esempio) da percorsi elettrici di lunghezza diversa. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#23,23,"Esercizio 2  Progettare un registro a 8 bit con uscita tri-state utilizzando FFD positive edge triggered.  La rete, ad ogni fronte di salita del clock, memorizza il byte IN[7..0] in ingresso se WE=1 mentre mantiene il valore precedentemente memorizzato in caso contrario (WE=0). L’uscita OUT[7..0] della rete deve essere posta nello stato di alta impedenza quando il segnale OE=0. Inoltre, la rete deve essere dotata di un ingresso asincrono di RESET (A_RESET) che, se 1, pone al livello logico 0 l’uscita OUT[7..0] indipendentemente dal valore dei segnali WE, IN e CK. Quali condizioni devono essere soddisfatte perché sia garantito il corretto funzionamento della rete ? ? WE A_RESET IN[7..0] CK OUT[7..0] OE WE IN[7..0] OE OUT[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#24,24,"WE OE FFD D Q Q* R IN OUT 0 1 Q A_RESET Soluzione Caso singolo bit 
NOTA  - Per garantire il corretto funzionamento della rete è   necessario rispettare tempi di setup e hold  - Il FFD esiste (8X) in forma integrata (74XX374) ed è dotato   di comando di OE CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#25,25,"NOTA  - La soluzione seguente NON è corretta in quanto:       a) variazioni spurie (glitch), dovute a instabilità del        segnale WE, possono causare commutazioni indesiderate         del flip-flop       b) il gate ritarda il segnale di clock del FFD e potrebbe        causare potenziali sfasamenti (“clock-skew”) tra i clock        dei vari componenti della rete sincrona complessiva WE OE FFD D Q Q* R IN OUT Q A_RESET CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#26,26,"FFD D Q Q* R IN7 WE OE OUT7 0 1 
FFD D Q Q* R IN1 OUT1 0 1 
FFD D Q Q* R IN0 OUT0 0 1 Q7 
Q1 Q0 A_RESET Estensione a 8 bit CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#27,27,"Estensione a 8 bit (meglio) 
WE OE FFD D Q Q* R IN[7..0] OUT[7..0] 0 1 Q[7..0] A_RESET CK 8 8 8 8 8 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#28,28,"Esercizio 3  Progettare una rete che periodicamente dopo tre periodi di clock setta al livello logico 1 la propria uscita per un periodo clock. 
A_RESET CK OUT 
CK OUT (0) (1) (2) (0) (1) (2) (3) (3) ? OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#29,29,"COUNTER X4 Una possibile soluzione si basa sullutilizzo di un contatore modulo 4.  Soluzione 3.1  
CK u1 u0 OUT A_RESET Progettare un contatore modulo 4…. A_RES Perchè ? u1 u0 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#3,3,"Modello della Macchina a Stati Finiti (FSM) - Mealy F G k n I? r U S S* U=F(S,I) S*=G(S,I) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#30,30,FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#31,31,"Contatore modulo 4 con comando di ENABLE (EN) 
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 EN 0 1 EN "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#32,32,"0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 UP/DOWN (U/D*)  
FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 U/D* "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#33,33,Contatore modulo 4 con LOAD (L) FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 1 0 L 1 0 L i0 i1 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#34,34,"Esercizi E3-1) Progettare un contatore modulo 4 dotato dei segnali       U/D*, EN e L nei seguenti 2 casi:   a) segnale L prioritario rispetto a EN    b) segnale EN prioritario rispetto a L       In entrambi i casi si supponga che U/D* sia il     segnale meno prioritario tra i tre.  E3-2) Progettare un contatore modulo 8  E3-3) Progettare un contatore modulo 5 utilizzando un       contatore modulo 8 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#35,35,Osservando le forme donda mostrate sotto si può ottenere una soluzione alternativa alla precedente (3.1) Soluzione 3.2  CK u1 u0 OUT (0) (1) (2) (0) (1) (2) (3) (3) 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#36,36,FFD D Q Q* R* CK A_RESET* FFD D Q Q* R* OUT NOTA - Questa soluzione non può essere ottenuta con il metodo   della sintesi formale studiato a Reti Logiche 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#37,37,"ττττNOTA - Non è il caso della rete della pagina precedente, ma la   presenza di alee può creare problemi alle reti che seguono   se queste utilizzano come ingresso di clock un segnale che    presenta oscillazioni spurie (glitches).    Si consideri ad esempio il caso seguente: 
FFD D Q Q* c b a 1 1 IN OUT S u u S τττ
Alea statica: provoca un campionamento indesiderato del FFD "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#38,38,NOTA -  Le alee possono essere eliminate introducendo ulteriori   gates (vedi reti logiche)   -  In alcuni casi le alee possono essere filtrate dagli   stessi gates (ad esempio nel caso di ‘lentezza’ dei   dispositivi rispetto ai tempi del glitch); questa   possibilità deve essere verificata attentamente   analizzando i datasheets dei componenti utilizzati a b c a b c Un impulso troppo breve potrebbe essere filtrato dallAND 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#39,39,"Soluzione canonica ottenuta mediante sintesi formale. Soluzione 3.3  
A,0 B,0 C,0 D,1 Grafo degli stati  
Tabella di flusso  sn sn+1 sn,u u A B 0 B C 0 C D 0 D A 1 Tabella delle  transizioni  y1n y0n u 0 0 0  1 0 0 1 1  0 0 1 0 1  1 0 1 1 0  0 1 y1n+1 y0n+1 Sintesi minima (mappe di Karnaugh,…) u = y1n·y0n y0n+1 = y0n* y1n+1 = y1n XOR y0n "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#4,4,"F G k n I? r U S S* U=F(S) S*=G(S,I) Modello della Macchina a Stati Finiti (FSM) - Moore "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#40,40,"FFD D Q Q* FFD D Q Q* XOR y0 y1 R* R* CK u NOTA  - Se si desidera aggiungere un segnale di ENABLE alla rete   precedente mediante il metodo della sintesi formale ?   - E necessario ripetere tutti i passi precedenti (grafo,   diagramma stati, …) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#41,41,Esercizio 4  Progettare un registro a scorrimento (shift-register) a 3 bit. ? IN A_RESET CK OUT1 OUT2 OUT0 IN A_RESET O1 O2 O0 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#42,42,"CK IN A_RESET OUT1 Soluzione 
OUT2 OUT0 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#43,43,"FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* IN OUT2 OUT1 OUT0 
CK Esercizi E4-1) Progettare uno shift-register dotato di comandi         di enable EN e LOAD (parallelo e prioritario         rispetto allenable).  E4-2) Utilizzando due shift-register a 4 bit e un        contatore modulo 8: progettare un convertitore         serie parallelo a 8 bit dotato di un segnale (ACK)    che comunica lavventura ricezione degli 8 bit.  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#44,44,Esercizio 5  Progettare una rete sincrona dotata di un ingresso  IN e di un’uscita OUT. L’uscita OUT deve asserirsi esattamente per un periodo di clock se viene rilevata una transizione da 0 a 1 del segnale di ingresso (monoimpulsore). Si noti che il segnale di ingresso potrebbe anche essere non sincrono (purché rispetti tempi di setup  e hold) ? IN CK OUT CK IN OUT IN OUT 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#45,45,"FFD D Q Q* FFD D Q Q* IN OUT CK Soluzione 
CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#46,46,"FFD D Q Q* IN OUT CK Perchè questa soluzione è sbagliata (1) ? 
CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#47,47,"Perchè questa soluzione è sbagliata (2) ? 
FFD D Q Q* IN OUT CK CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#48,48,"Perchè questa soluzione è sbagliata (3) ? 
FFD D Q Q* IN OUT CK CK IN OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#49,49,"Esercizio 6  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati sull’ingresso IN[7..0] mentre il segnale EN era a livello logico 1 sono stati FFh (primo carattere della sequenza), 27h e 30h. Nel caso sia rilevata la sequenza FF-27-30, nel periodo di clock successivo a quello dell’ultimo carattere ricevuto (30h), deve essere asserita l’uscita OUT e rimanere tale fino a che non viene asserito il segnale (asincrono) di reset A_RESET. In seguito ad un reset deve riprendere immediatamente il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere. ? EN A_RESET IN[7..0] CK OUT EN A_RESET IN[7..0] OUT "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#5,5,"Reti Sequenziali Asincrone (RSA) ? k τk Retroazione diretta (τ: ritardo intrinseco della RC G) S U S* IS S* S S* 
t t+τ(1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#50,50,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#51,51,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK DEC_30 DEC_27 DEC_FF OE* OE* 0 0 Soluzione 6.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#52,52,"Soluzione 6.2 
CK A_RESET* LOAD ENABLE 0 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Una soluzione alternativa utilizzando un contatore dotato di  comando di LOAD 
Cè un problema… "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#53,53,"CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  .. nella soluzione della pagina precedente cosa accade se i  caratteri ricevuti (con EN=1) sono FF-FF-27-30 ? 
DEC_FF "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#54,54,"Esercizi E5-1) Riprogettare la rete dellesercizio 6 in modo che     OUT assuma il valore logico 1 in seguito alla     ricezione anche non consecutiva (con EN=1) dei     caratteri FFh, 27h e 30h.          Ad esempio, OUT=1 se i caratteri ricevuti (mentre     EN=1) sono stati: FF-7A-80-9F-27-B2-30-…  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#55,55,"Esercizio 7  Modificare lesercizio precedente in modo che, in seguito al rilevamento della sequenza, luscita OUT assuma il valore logico 1 per un solo periodo di clock. Appena ricevuta una sequenza completa il controllo dei caratteri in ingresso deve riprendere immediatamente. ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#56,56,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h 
OUT (1) (2) (3) Soluzione 7.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#57,57,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* A_RESET* 
A_RESET* CK CK 
CK "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#58,58,"Soluzione 7.2 
CK A_RESET LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30* + OUT ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Rispetto allesercizio 6.2 è sufficiente modificare il comando di LOAD facendo in modo che LOAD=1 quando OUT=1 ?  
EN·DEC_FF 
Cosa accade se (con EN=1) la sequenza è 45-FF-27-30-FF-27-30-… ? "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#59,59,"Esercizi E6-1) Riprogettare la rete dellesercizio 6 in modo che    OUT=1 in seguito alla ricezione anche non consecutiva    (con EN=1) dei caratteri FFh, 27h e 30h.         Ad esempio, OUT=1 se i caratteri ricevuti mentre EN=1    sono stati: FF-7A-80-9F-27-B2-30-…   E6-2) Cosa accade alle soluzioni 6.1 e 6.2 se (mentre EN=1)       la sequenza è: 45-FF-27-30-FF-27-30-… ?  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#6,6,"•  Le reti asincrone rispondono molto rapidamente (appena possibile)   alle variazioni degli ingressi •  Non è necessario un segnale di sincronismo (clock) •  Ridotta dissipazione di potenza Aspetti positivi delle RSA (vs RSS) Aspetti negativi delle RSA (vs RSS) •  Vincoli per il corretto impiego   - l’ingresso può variare solo quando la rete ha raggiunto     una condizione di stabilità   - i segnali di ingresso possono variare uno alla volta •  Esposte a potenziali malfunzionamenti (corse critiche)  •  Difficili da progettare In pratica, sono utilizzate per realizzare latch e flip-flop.  A noi interessano (maggiormente) le reti sincrone (RSS) ! "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#60,60,"Esercizio 8  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati in ingresso IN[7..0] mentre il segnale EN=1 sono stati FFh (primo carattere della sequenza), 27h  e 30h. Nel caso sia rilevata tale sequenza, due periodi di clock successivi a quello dell’ultimo carattere della sequenza ricevuto deve essere asserita l’uscita OUT e rimanere tale fino a che il segnale di reset (asincrono) A_RESET non assume il valore logico 1. In seguito ad un reset (asincrono) la rete deve riprendere immediatamente  il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere.  ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#61,61,"CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 18h 16h 80h 
OUT (1) (2) (3) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#62,62,"374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 
EN 
FFD D Q Q* 1 0 OUT R* R* R* A_RESET* 
A_RESET* A_RESET* 
Il segnale EN condiziona lultimo carattere della sequenza CK CK 
CK FFD D Q Q* R* A_RESET* CK Soluzione 8.1 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#63,63,CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = (ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*)·OUT_1*  ENABLE = (ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30)·OUT_1*  DEC_FF Soluzione 8.2 FFD D Q Q* R* A_RESET* CK OUT_1 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#64,64,"Esercizio 9  Progettare una rete dotata di tre ingressi E, A/I*, A_RES e unuscita OUT. Il segnale di ingresso A/I* influisce sulla rete solo se contemporaneamente E=1. Luscita della rete deve andare al livello logico 1 per un periodo di clock se viene rilevato per cinque volte, anche non consecutive, il valore 1 del segnale A/I* in presenza del segnale E=1. Ogni volta che il segnale A/I* assume il valore 0 (con E=1) deve essere ridotto di uno il numero di eventi rilevati fino a quel momento. Successivamente a un reset (segnale asincrono) o nel caso nessun evento sia stato ancora rilevato (o che il numero di incrementi sia stato compensato da un numero equivalente di decrementi la rete deve rimanere nello stato 000 anche se A/I*=0 ed E=1. Dopo avere rilevato cinque eventi la rete deve riprendere l’analisi degli ingressi. ? E A/I* A_RESET CLOCK OUT OUT E A/I* A_RES "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#65,65,"COUNTER X 8 EN U/D# LOAD I2 I1 I0 O2 O1 O0 E A/I* OUT OUT CLOCK 0 0 A/I* 
O2 O1 O0 A/I* RESET A_RESET Soluzione 9.1 E L’OR blocca il conteggio (EN=0), anche con E=1, se il contatore si trova nello stato 000 e il comando DOWN è asserito (A/I*=0). Perché ? 
O1 è strettamente necessario ?  (No, perché ?) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#66,66,"A,0 B,0 C,0 D,0 E,0 F,1 E A/I* 0 – 1 0 0 – 0 – 0 – 0 – 1 1 1 1 1 1 1 1 1 1 1 1 0 – 1 0 1 0 1 0 1 0 1 0 Soluzione mediante sintesi formale: grafo -> tabella di  flusso -> tabella delle transizioni,... NON SI USA !!!! Soluzione 9.2 "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#67,67,Esercizio 10  Utilizzando un microprocessore dotato di un bus indirizzi a 16 bit e di un bus dati a 8 bit: mappare nello parte bassa dello spazio di indirizzamento 12k di RAM e nella parte alta 16k di EPROM. 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#68,68,"Soluzione RAM (12K) 
EPROM (16K) 0000h  2FFFh 
C000h FFFFh A15..A12 A11..A8 A7..A4 A3..A0 0000 0000 0000 0000 (0000h)  
1111 1111 1111 1111 (FFFFh) 0010 1111 1111 1111  (2FFFh) 
1100 0000 0000 0000 (C000h) RAM_1 (8k) RAM_2 (2k) RAM_3 (2k) 
EPROM (16k) 0001 1111 1111 1111 (1FFFh)  0010 0000 0000 0000  (2000h) 0010 0111 1111 1111  (27FFh) 0010 1000 0000 0000  (2800h) CS_RAM_1=A15*·A13* CS_RAM_2=A15*·A13· A11* CS_RAM_3=A15*·A13· A11 CS_EPROM=A15 Segnali di decodifica: "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#69,69,"- Il segnale CS_EPROM si attiva per ogni indirizzo maggiore   o uguale di 8000h (seconda metà dello spazio di   indirizzamento) 0000h  
C000h FFFFh 8000h Indirizzi di memoria con A15=1 CS_EPROM=A15 NOTA  - La codifica semplificata implica lattivazione dei   segnali di selezioni anche per indirizzi diversi da   quelli in cui sono realmente presenti i dispositivi    di memoria.  
EPROM (16K) EPROM (16K) "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#7,7,"RSA notevoli: Latch SR SR S R Q Q* S R Q Q* S R 0 0 0 1 1 0 1 1 Q Q* Q Q* 0 1 1 0 
Q = S’ ↑ (q ↑ R’) S’ R’ Q Q*  Q = R ↓ (S ↓ q) S R Q Q*  
I comandi di set e reset devono avere una durata minima (vedi datasheet) per consentire il raggiungimento della condizione di stabilità "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#70,70,"- Il segnale CS_RAM_1 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=0:  0000h  
FFFFh 8000h CS_RAM_1=A15*·A13* RAM_1 (8k) A15..A12  A11..A8    A7..A4   A3....A0 0000  0000  0000  0000 (0000h)  0001  1111  1111  1111 (1FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0100  0000  0000  0000 (4000h)  0101  1111  1111  1111 (5FFFh)  Quindi, CS_RAM_1=1 per entrambi i  seguenti intervalli di memoria: 1FFFh  4000h RAM_1 (8k) 5FFFh "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#71,71,"- Il segnale CS_RAM_2 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=0 :  0000h  
FFFFh 8000h CS_RAM_2=A15*·A13·A11* A15..A12  A11..A8    A7..A4   A3....A0 0010  0000  0000  0000 (2000h)  0010  0111  1111  1111 (27FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  0000  0000  0000 (3000h)  0011  0111  1111  1111 (37FFh)  Quindi, CS_RAM_2=1 per i seguenti quattro intervalli di memoria: 2000h  4000h 6000h A15..A12  A11..A8    A7..A4   A3....A0 0110  0000  0000  0000 (6000h)  0110  0111  1111  1111 (67FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  0000  0000  0000 (7000h)  0111  0111  1111  1111 (77FFh)  RAM_2 (2k) RAM_2 (2k) 3000h  RAM_2 (2k) RAM_2 (2k) 7000h "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#72,72,"- Il segnale CS_RAM_3 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=1 :  0000h  
FFFFh CS_RAM_3=A15*·A13·A11 A15..A12  A11..A8    A7..A4   A3....A0 0010  1000  0000  0000 (2800h)  0010  1111  1111  1111 (2FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  1000  0000  0000 (3800h)  0011  1111  1111  1111 (3FFFh)  Quindi, CS_RAM_3=1 per i seguenti quattro intervalli di memoria: 2800h  6800h A15..A12  A11..A8    A7..A4   A3....A0 0110  1000  0000  0000 (6800h)  0110  1111  1111  1111 (6FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  1000  0000  0000 (7800h)  0111  1111  1111  1111 (7FFFh)  RAM_3 (2k) RAM_3 (2k) 3800h  RAM_3 (2k) RAM_3 (2k) 7800h "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#73,73,"0000h  
FFFFh 2800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 2000h  3800h  RAM_2 (2k) RAM_3 (2k) 3000h  4000h  6800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 6000h  7800h  RAM_2 (2k) RAM_3 (2k) 7000h  EPROM (16K) EPROM (16K) 8000h  C000h Effetto di replica nella mappatura in memoria dovuto alla  decodifica semplificata. Nella figura seguente sono indicati  solo gli indirizzi iniziali. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#74,74,"Esercizio 11  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:  - mappare nello parte bassa dello spazio di indirizzamento    32k di RAM e nella parte alta 32k di EPROM   Nel sistema sono presenti anche due dispositivi di I/O denominati D1 (dotato di due registri interni) e D2 (dotato di quattro registri interni):  - mappare in memoria anche i due dispositivi di I/O D1 e    D2 agli indirizzi 2000h e 1000h  Osservando che esiste una sovrapposizione tra gli indirizzi di una memoria e dei due dispositivi di IO, si scrivano i CS, in forma semplificata, di tutti i dispositivi presenti nel sistema riducendo al minimo gli indirizzi “sottratti” dai dispositivi di IO alla memoria. "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#75,75,"Soluzione  RAM: 1 chip da 32KB RAM  (00000h->07FFFh) CS_RAM = BA19*·CS_D1*·CS_D2*   EPROM: 1 chip da 32KB EPROM (F8000h – FFFFFh) CS_EPROM = BA19   D1: Mappato in memoria allindirizzo 02000h, occupa 2 locazioni (A0)     nello spazio di indirizzamento. CS_D1 = BA19*·BA14*·BA13·BA12*·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·          BA5*·BA4*·BA3*·BA2*·BA1*   D2: Mappato in memoria allindirizzo 01000h, occupa 4 locazioni (A1A0) nello spazio di indirizzamento.  CS_D2 = BA19*·BA14*·BA13*·BA12·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·       BA5*·BA4*·BA3*·BA2*  "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#76,76,"Esercizio 12  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:    - mappare 32k di RAM nella parte bassa dello spazio di    indirizzamento, 32k di RAM a partire dallindirizzo     1C000h e 64k EPROM nella parte alta dello spazio di    indirizzamento "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#77,77,"RAM_1 (32k) RAM_2 (32k) 
EPROM (64k) 00000h 10000h 20000h 30000h 
F0000h 1C000h    0001 1100 0000 0000 0000  23FFFh    0010 0011 1111 1111 1111     
FFFFFh Soluzione 00000h    0000 0000 0000 0000 0000  07FFFh    0000 0111 1111 1111 1111     
F0000h    1111 0000 0000 0000 0000  FFFFFh    1011 1111 1111 1111 1111     CS_RAM_1=A19*·A17*·A16* CS_RAM_2=A19*·(A17 + A16) CS_EPROM=A19 CS_RAM_2=A19*·CS_RAM_1* oppure "
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#8,8,RSA notevoli: Latch CD CD C D Q Q* C D Q Q* C D 0 0 0 1 1 0 1 1 Q Q* Q Q* Q Q* 0 1 1 0 SR S R Q Q* C D Q Q* C D Q τSU τH τSU ≥ τSUmin τH≥ τHmin Vincoli: Tempo di risposta: τR > τH Latch CD: il problema/vantaggio delle “uscite trasparenti” 
data_test\rootfolder\università\CalcolatoriElettronici\00_Complementi_Esercizi_Reti_Logiche.pdf#9,9,"Driver 3-state 
OE I U OE=0 I U OE=1 I U I OE U Quale è il valore della tensione  ? OE I 1 0 1 1 0 0 0 1 U 0 1 Z Z ? "
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#0,0,"01 IntroduzioneCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#1,1,"DocentiStefanoMattocciaRicevimento:pressostudio,vicinoaula5.7,suappuntamentoconcordatoviaemailEmail:stefano.mattoccia@unibo.itHomepage:http://vision.disi.unibo.it/~smattMatteoPoggi(tutor,AA2020/21)Ricevimento:pressoLaboratoriodiComputerVision,suappuntamentoconcordatoviaemailEmail:m.poggi@unibo.itHomepage:https://mattpoggi.github.io/"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#10,10,"Struttura di una prova d’esame 
Esercizio 1: progetto di un sistema a microprocessore.Per superare l’esame, è necessario proporre una soluzione ragionevole. L’esercizio 1 determina il superamento/non superamentodella prova.Esercizi 2 e 3: domande di teoria che richiedono qualcheragionamento. Volutamente non è fornita la soluzione."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#11,11,"Elaborazione delle informazioni
InputOutputUnessereviventeelaboracontinuamentedelleinformazionieforniscedellerisposteoagisceinundeterminatomodoinbasealleinformazioniiningresso.
Unsistemadiqualsiasinaturaperl’elaborazionedelleinformazioniisolatodall’esternoservirebbeabenpoco(meglio,nulla).Inputeoutputdebbonoesserecodificatiinmodoappropriato
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#12,12,"Elaborazione delle informazioniOvviamente,inquestocorso,siamointeressatiasistemidinaturaelettronicaperelaborareleinformazioni.Inparticolare,perleragionievidenziateaRetiLogicheT,siamointeressatiasistemidigitali->RetiLogiche
InputOutput
RL01101101011101"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#13,13,Elaborazione delle informazioniUnprimoproblema:leretilogicheelaboranoinformazioniditipodigitaleMoltiinputeoutputdiparticolareinteressenonsonodinaturadigitalemaanalogica(quellapreferitadagliesseriumani)•Prossimitàaunsemaforoounostacolo•Monitor•Movimentodelmouse•Voce/Audio•Pressionetasti•Touchscreen•etc
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#14,14,"InputOutput
RLA/D
D/A
Pertanto,è(spesso)necessarioconvertiresegnalidinaturaanalogicainsegnalidigitalieviceversaElaborazione delle informazioni
‘01001101’ ‘110111’ Inunsistemadielaborazione,iningressoeinuscitatroviamosolosegnalidigitali(binari)"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#15,15,Elaborazione delle informazioniAltroproblema:laretelogicacheelaboraleinformazionièspessomoltoefficienti/veloce/etcmaallostessotempopocoflessibileperquantoriguardaillinguaggioutilizzabileperfornireleinformazioni(digitali)ininputeinterpretareleinformazioni(digitali)elaborateinoutput.Sesidesiderainteragireconunsistemadielaborazionedigitaleenecessarioadeguarsiallinguaggiochelaretelogicautilizza.Questolinguaggioècodificatodall’evoluzionetemporaledialcunisegnali(ilminimoindispensabile)emessioricevibilidallaretelogica.L’evoluzionetemporalediquestisegnalisidefinisceciclodibus(buscycle).
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#16,16,"RLElaborazione delle informazioni
ttttttttQuindi,l’unicomodoperinteragireconunsistemadigitaleperl’elaborazionedelleinformazioniconsistenell’adottarequestaconvenzione(ie,iciclidibus,descrittiindettagliosuidatasheetcheilproduttoredelsistemarendesempredisponibili).
ciclo di busciclo di bus"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#17,17,"Quale rete logica utilizzare?Sonodisponibilidiversearchitetturedielaborazione(i,e,retilogiche).Qualescegliere?Dipendedalcontestoapplicativoedalleprestazioni,consumi,ingombri,peso,etc:-sistemageneralpurpose-sistemaembedded-sistemapervideogiochi-etcUnatipologiadiarchitettura,basatasulmodellodiVonNeumann,èmoltopiùflessibiledellealtreepuòessereutilizzata,anchesenonsempreconrisultatiottimali,inognicontesto.Questomodelloèl’oggettodiquestocorsoeutilizzacomeelementodibaseunaCPU(microprocessore)."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#18,18,"Esempi di architetture di elaborazione
19
•CPU(CentralProcessingUnit)•CPUMulticore•CPUEmbedded•SOC(SystemonaChip)•GPU(GraphicProcessingUnit)•FPGA(FieldProgrammableGateArray)•Sistemiibridi(e.g.FPGA+CPU)•..."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#19,19,■Architetturadeltuttogeneralecheportaarealizzazionipocodipendentidalfunzionamentodesiderato■Ilfunzionamentodesideratoèespressointerminidi✸sequenzadiistruzioni(programma)✸memorizzatesuunsupportodimemoria■Percambiarefunzionamentoèsufficientecambiareilprogramma:questodifattomodificalaretelogicadicontrolloperogniistruzioneeseguita■L’architetturaèadattaatrattareproblemimoltopiùcomplessidiquellivistinelcorsodiretilogichemaconefficienza(tipicamente)inferiore■L'importanzaeladiffusionedeicalcolatoridipendefortementedallaflessibilitàdiquestomodelloIl modello di riferimento: Von Neumann
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#2,2,"Obiettivi del corsoApprendere,•i principi di funzionamento•le architetture•la progettazione hardware e softwaredei sistemi per l’elaborazione delle informazioni basati microprocessore(o CPU –Central Processing Unit)
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#20,20,"Rete combinatoriaUscite OjIngressi Xi  Variabilidi statoYk(n+1)Variabili di statoYk(n)Rete Sequenziale(Sincrona)RegistriSistema di elaborazione: rete sequenzialeIl sistema di elaborazione può essere schematizzato in modoastratto come una Rete Sequenziale (Sincrona), RSS"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#21,21,"Come cambiareil funzionamento della RL?
RegistriUscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RetecombinatoriaSegnali dicontrolloProgramma(software)RispettoaRetiLogiche,lanovitàèilsoftware(programma)checonsentedivariareilfunzionamentodellareteinbasealleesigenzedesiderate(ie,ilcodicescrittodalprogrammatore)."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#22,22,"In realtà le cose sono più complesse
Uscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RCSegnali dicontrolloProgramma(software)Unità dicontrollo(RSS)Istruzioni (dalla memoria)
LunitàdicontrollononsologovernalaretecombinatoriamaanchetuttelealtreretilogichepresentinelsistemaEsempio:abilitagliingressieleuscitequandonecessario,etcRegistri
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#23,23,"•Ilprogrammarisiedeinmemoriaedècostituitodaistruzionicodificateinformabinaria(linguaggiomacchina)•Inmemoriarisiedonoancheglioperandidelleistruzioni,cioèidatielaboratiedaelaborare(formabinaria)•LeistruzionivengonoeseguiteinsequenzadallaCPU•LaCPUèunamacchinasequenzialesincrona(conunclock)Modello di esecuzione del programma
Uscite
istruzioniIngressiCPUIstr. #1Istr. #2. . .Istr. #NCk"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#24,24,"Alivellodimassimaastrazione,ilfunzionamentodell’interosistemapuòesseredescrittomedianteduesolistati:–StatoincuilaCPUleggeinmemorialaprossimaistruzionedaeseguire(INSTRUCTIONFETCHoIF)–StatoincuilaCPUeseguelistruzionelettainIF(EXECUTEoEX)ISTRUCTIONFETCH(IF)EXECUTE(EX)
CPUIstr. #1Istr. #2. . .Istr. #N"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#25,25,"RL CPU e istruzioni•Leretilogichevistearetilogicheelaboravanoeproducevanosegnalibinari•SelaCPUèunaRL,comesonocodificateleistruzioni?•Ovviamenteinbinario...•Esempioistruzione#1->00010100000101111101010000010011istruzione#2->10110101100100011001010000011001......istruzione#N->01010110100101010101010110011110•OgniistruzioneindicaallaCPUqualeoperazionedevesvolgere/eseguire•Nonsembraessereunmodomoltocomodo(pergliesseriumani)"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#26,26,"Esempi di istruzioni•QualiistruzionipossonoessereeseguitedaunaCPU?•Somme•Moltiplicazioni•Divisioni•Confronto•Letturedallamemoriaodaaltridispositivi*•Scrittureinmemoriaoversoaltridispositivi*•...EsistonosostanzialmenteduetipologiediCPU:•RISC(ReducedInstructionSetComputer)Pocheesempliciistruzioni,retilogichesempliciemoltoveloci(frequenzadiclockelevata).eg,ARM•CISC(ComplexInstructionSetComputer)Molteistruzioni,alcunemoltocomplesse,retilogichecomplicate.eg,InteleAMD"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#27,27,"RISC vs CISC•TipicamenteaunasolaistruzioneCISCcorrispondonopiùistruzioniRISC•Tuttavia,ognisingolaistruzioneRISCèeseguitaspessopiùrapidamentediunaistruzioneCISC•Spesso,ilcodiceRISC,anchesepiùdenso,èpiùveloce•LeRLRISCsonotipicamentepiùsemplicidiquelleCISC•Seleretisonopiùsemplicilospazio(silicio)puòessereutilizzatoperaltrefinalità(registri,cache,etc)•IprocessoriRISCsonomoltodiffusi(smartphone,tablete)•AncheiprocessoriCISCsonomoltodiffusi(PC)perviadelsoftwareesistente*•LeCPUCISCmodernesonoinrealtàinternamentedeiRISC"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#28,28,"•IndipendentementedaltipodiCPU,leistruzioniinformabinarianonsonofacilmenteinterpretabilieperquestononutilizzateinquestaformaquandosiscriveilcodice•Illinguaggiochesiutilizzaèl’assembler:ADDR1,R2,R3;poneinR1lasommatraregistriR2eR3Questaistruzionepotrebbeesserecodificatacon:00010100000101111101010000010011Iltraduttoreassembler->codicemacchinainbinarioèunaLookUpTable(LUT),ovverounatabellaL’assemblersembraessereunpassoavantinotevolema...Perchénonavetemaiutilizzatoillinguaggioassemblernonostantescrivetecodicedalprimoanno?Istruzioni in forma più comprensibile"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#29,29,"Compilatore e istruzioni binarie•Ilmotivoècheavetescrittocodiceadaltolivello(C)eutilizzatouncompilatore(e.g.,GCC)•Ilcompilatore,converteilcodicescrittoinlinguaggioadaltolivelloinistruzionimacchinabinarie#include<stdio.h>intmain(intargc,char**argv){inta=5;intb=6;intc;c=a+b;printf(“Lasommatra%de%dè%d\n”,a,b,c);}GCC0001010000010111110101000001001110110101100100011001010000011001. . .01010110100101010101010110011110"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#3,3,Orario lezioniOrario ufficiale:https://corsi.unibo.it/laurea/IngegneriaInformatica/orario-lezioni?anno=2&curricula=Lunedì inizio ore 9.00-11onlineGiovedì inizio ore 14.00-17.00Aula 6.1
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#30,30,"Come si accede alla memoria (e non solo)?•SappiamocheilcodicenelmodellodiVonNeumannrisiedeinmemoria•Comesilegge(escrivedallamemoria)?•Comesileggonoescrivonoidati?
CPU
?•L’unico modo è attraverso dei segnali predefiniti (con un ben definito andamento temporale, ciclo di bus)  "
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#31,31,"IndirizziBA[K..0]DatiBD[R..0] READControlloWRITEREADYINT
CPU
K+1R+1
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#32,32,"Come avviene la comunicazione?CPU
K+1MemoriaPeriferica#i
R+1•Tutto viaggia sui bus di sistema•Tutto è regolato da cicli di bus"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#33,33,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#34,34,CKADDRESSMEMRDMEMWRDATADATA_OUTReady?Esempio di ciclo di scrittura
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#35,35,"Range di indirizzi•Sesonodisponibili32bit(BA[31..0])èpossibileavereaccessoa2^32elementi(memorie,periferiche)•32segnalidiindirizzo,4GB•Aogniindirizzoèassociatoundispositivo(memorie,periferiche)•E’necessariodecodificarel’indirizzoemessodallaCPUperdeterminareconqualedispositivolaCPUintendecomunicare•Quantibytepossonoesseretrasferitiduranteunciclodibus?Dipendedall’ampiezzadelbusdati"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#36,36,"Relazione tra hardware e software•ConsideriamounaistruzioneperleggeredallamemoriaunbyteaundeterminatoindirizzoxxxLBdestinazione,indirizzo;letturadiunbytePerprimacosaèeseguitoilfetchdell’istruzioneall’indirizzoxxx.come?Conunciclodibus,naturalmenteComefacciamoaconoscerel’indirizzoxxx?LaCPUhaaccessoalprogramcounterPCUnavoltalettaedecodificata,l’istruzioneèeseguita.Durantel’esecuzioneèeseguitounciclodibusdiletturaDuranteilciclodibusèemessol’indirizzo"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#4,4,"Materiale didatticoDisponibile in formato PDF sul sito del corso:http://vision.disi.unibo.it/~smatt/Site/Courses.htmlNel sito sono presenti anche numerose prove d’esameI lucidi non sono un libro, seguire con attenzione le lezioni è fondamentale per superare rapidamente e con buoni risultati l’esame..."
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#5,5,"Materiale didattico per approfondimentiSeguendo il corso con attenzione e utilizzando i lucidiforniti NON è necessario utilizzare altro materialeper la preparazione dell’esame.Tuttavia, per chi desiderasse approfondire:–Hennessy & Patterson, ""Computer architecture: a quantitative  approach, Morgan Kaufmann, Anche in versione italiana. La seconda edizione (inglese, a dx) descrive approfonditamente il processore DLX-G. Bucci, Architettura e organizzazione dei calcolatori elettronici. Fondamenti, McGraw-Hill-J. Yiu, The definitive guide to the ARM Cortex M0, Newnes-Patterson &  Waterman, RISC-V, Strawberry Canyon
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#6,6,RequisitiPer superare in modo proficuo il corso di Calcolatori Elettronici T è fondamentale avere compreso bene:1) Fondamenti di Informatica T2) Reti Logiche TPer Reti Logiche T è cruciale la progettazione diretta.Si sconsiglia vivamente di seguire questo corso senza avere solide basi in 1) e soprattutto di Reti Logiche T
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#7,7,"Avvisi e altre comunicazioni Eventuali comunicazione di carattere generale sarannoinserite nella pagina web del corso, nella sezione “Avvisi” di Calcolatori Elettronici T o chat Teams
"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#8,8,"Modalità di svolgimento dell’esame •L’esame consiste in una prova SCRITTA di 2.5 ore•Nessuna prova orale• Non è possibile portare libri, appunti, computer, telefoni, smartphone, tablet, smartwatch, etc• E’ indispensabile (pena l’esclusione dall’esame) presentarsi con documento di identitàe badge•Esami gravemente insufficienti saranno verbalizzati"
data_test\rootfolder\università\CalcolatoriElettronici\01_Introduzione.pdf#9,9,"Prossimi appelli d’esame 
•La date degli esami sono consultabili su Almaesami•L’iscrizioneagli appelli via Almaesamiè obbligatoria e si chiude (circa) una settimana prima• Non è ammessa alcuna deroghe all’iscrizione•Sono previsti 6 appelli all’anno: -3 Dicembre/Febbraio -2 Giugno/Luglio -1 SettembreNessun appello straordinarioSe possibile (aule, etc) il primo appello subito dopo il termine delle lezioni"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#0,0,"02 Mappinge decodificaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#1,1,"Spazio di indirizzamento•Una CPU emette un certo numero di indirizzi e altri segnalisui bus di sistema per comunicare con altri moduli  •Il numero di diversi indirizzi emessi dalla CPU costituiscelo spazio di indirizzamento•Una CPU che emette un indirizzo a 20 bit ha uno spazio diindirizzamento di 1 MB (2^20)•Una CPU che emette un indirizzo a 32 bit ha uno spazio diindirizzamento di 4 GB (2^32)•Le prime CPU avevano spazi di indirizzamento molto ridottodi alcuni KB (e.g., 64 KB o meno)•Oggi è consuetudine avere almeno 32 bit di indirizzo"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#10,10,"11Memorie RAM (SRAM)
•Memorie volatili, leggibili e scrivibili•Capacità a multipli di 4:8K, 32K, 128K, 512K, etc•DRAM: 1 transistore per  bit, maggiore capacità, più lenteAiCE*OE*I/OiTceTaccToe(Out)ReadCycleAiCE*WE*I/OiTawTwp(In)TdsWriteCycleNCA16A14A12A7A6A5A4A3A2A1A0I/O0I/O1I/O2GNDVCCA15NCWE*A13A8A9A11OE*A10CE*I/O7I/O6I/O5I/O4I/O31234567891011121314151632313029282726252423222120191817128K ´8RAM"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#11,11,"12
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#12,12,"13
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#13,13,"14
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#14,14,"15
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#15,15,"16
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#16,16,17Integrati Notevoli: 2441A11A21A31A42A12A22A32A41Y11Y21Y31Y42Y12Y22Y32Y4EN1*EN2*74XX244ENx*xAixYiDriver 3-state ad 8-bit(strutturato in 2 gruppi di 4 bit) 
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#17,17,"18
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#18,18,"19
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#19,19,"20
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#2,2,"Un indirizzo per distribuire merci
WR(consegna)RD(preleva)
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#20,20,21EN*BiDIRAiA1A2A3A4A5A6A7A8B1B2B3B4B5B6B7B8EN*DIR74XX245IntegratiNotevoli: 245Driver bidirezionale (transceiver) ad 8-bit.
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#21,21,"22
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#22,22,"23
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#23,23,"24
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#24,24,"25Integrati Notevoli: 373D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7COE*74XX373
CDiQiOE*OiZCQiDCDiOE*OiLatch CD 
Latch a 8-bit con uscite 3-state"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#25,25,"26Integrati Notevoli: 374D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7CKOE*74XX374
CKDiQiOE*OiZQiDCKDiOE*OiFlip-Flop D
Registro edge-triggeredcon uscite 3-state"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#26,26,
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#27,27,"28
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#28,28,"29
"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#29,29,"30Registro Edge-Triggered con WE*WE*D0OE*O0Flip-Flop DMUX10CKDQ0O1Flip-Flop DDQ1MUX10ON-1Flip-Flop DDQNMUX10D1
DN-1D[0..N-1]WE*OE*O[0..N-1]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#3,3,"CPU
Decoder(RC)I livelloCS_ACS_BCS_CCS_DCS_ECS_FCS_GCS_HABCD
EFGHUn indirizzo per distribuire dati (CPU)
Il decoder di II livello è all’interno di ciascundispositivo (memoria, etc) 
BA[K-1..0]BD[R-1..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#30,30,"Register File (1 read-port, 1 write-port)DEC01M-1EN*m  Read_AddressDEC01M-1EN*m  Write_AddressRD*WR*N  Write_DataRead_DataN CKD[0..N-1]WE*OE*O[0..N-1]R0D[0..N-1]WE*OE*O[0..N-1]R1
D[0..N-1]WE*OE*O[0..N-1]RM-1N.B. :M=2m"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#31,31,Mappingdi dispositivi da 8 bit in sistemicon bus dati da 8 bit•Consideriamodispositiviconportadatia8bit•Imponiamo(temporaneamente)lulteriorecondizionecheilparallelismodelbusdatisiaa8bit•Inquesteipotesilassegnamentoaundispositivodiunafinestradiindirizziinunospaziodiindirizzamentoavverràingeneralenelrispettodelledueseguentiulterioricondizionirestrittive:–ladimensionedellafinestradiindirizziassociataaundispositivoèunapotenzadidue–lafinestraècompostadaindirizzicontigui
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#32,32,"33Dimensione della finestra occupata da un dispositivo -esempi•Undispositivoaccessibileattraversoilbusoccupaingeneralen=2^Kposizioninellospaziodiindirizzamento•nrappresentailnumerodioggettia8bitindirizzabiliallinternodeldispositivo(es.numerodicelledimemorianelleRAMedEPROM)•K(numerodibitdiindirizzointernialdispositivo)èfortementevariabilealvariaredeldispositivo:–Ingeneraleneidispositividiinput/output(i.e.,leinterfacce)Kèpiccolo(e.g.,2)–ingeneraleneidispositividimemoriaKègrande(e.g.,perunaRAMda128KBsihaK=17)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#33,33,"Caratteristiche ai morsetti di un dispositivo indirizzabile su una finestra di n = 2^K byteQualunquedispositivoda8bitconall’internon=2^kelementiindirizzabiliseparatamentehaalsuointernoundecoder(IIlivello)diKvariabiliconingressodienablecheselezionaisingolioggettiindirizzabili–Read(RD),dettoancheOutputEnable(OE)èilcomandodilettura.QuandoRDeCSsonoattivi,ildispositivoesponeilsuBD[7..0]ilcontenutodellacellaindirizzata–Write(WR),èilcomandodiscrittura.QuandoCSasseritosulfrontedidiscesediWRècampionatoildaatopresentesuBD[7..0]DISPCSA[K-1..0].RDWRD[R..0]?KBA[K-1..0]CS_DISP8BD[7..0]RDWR"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#34,34,"350K32K8K8K8K8KSpazio di memoria8KDispositivo di memoria fisico che realizza una zona della memoria logica00001FFF0121314Ind. delBloccoIndirizzo interno al blocco
CS = A14 AND A13*(Dispositivo da 8K di memoria)Esempio con 15 bit di indirizzo del sistema 
In questo caso "
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#35,35,"Mapping allineato di dispositivi da 8 bit in sistemi con bus dati da 8 bitSiconsideriundispositivoDdin=2^Kbyteindirizzabili•SidicecheDèmappatoallindirizzoAsegliindirizzideibytediDsonocompresitraAeA+(n-1),cioèseAèlindirizzopiùbassotratuttigliindirizziassociatiaD•SidicecheDèallineatoseAèunmultiplodin(numerodibytesinternialdispositivo),cioèse:(indirizzopiùbassodiD)MODn=0(condizionediallineamento)•SeDèallineatoalloraikbitmenosignificatividiAsonougualiazeroEsempi:•Undispositivodaduebyteèallineatoseèmappatoaunindirizzopari•Unadispositivoda8byteèallineatoseèmappatoaunindirizzoilcuivalorecodificatoinbinarioterminacon3zeri•Undispositivoda16byteèallineatoseilsuoindirizzoinizialeincodiceesadecimalehalaciframenosignificativaugualeazero•Undispositivoda64KBèallineatoseilsuoindirizzoincodiceesadecimalehalequattrocifremenosignificativeugualiazero"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#36,36,"Come individuare univocamente una finestra allineata di 2^K byte in uno spazio di indirizzamento•Supponiamo di mappare un dispositivo D di 2^k bytes(k=4) a un indirizzo A allineato di uno spazio di indirizzamento di 1 MB (bus di indirizzi di 20 bit): •Allora possiamo porre A = α ## (0)k(ex F8570) ove αè una configurazione binaria di 20 -K bit e gli indirizzi associati a D saranno compresi traAmin= A = α ## (0)k e Amax= Amin+ 2k -1 = α## (1)k    (Amin= F8570–Amax=  F857F)•Dunque, possiamo indicare lindirizzo  Aidelli-esimo byte di D come linsieme di due campi concatenati: Ai = α ## i(Ai = F8573)αindividua tra le 2^(20-K) finestre allineate di 2^K byte presenti nello spazio di indirizzamento, quella su cui è mappato (a = F857)iindividua loffset nel chip del byte indirizzato (i = 3)(NB ## è l’operatore simbolico concatenazione)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#37,37,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 1IndirizzamentodiunbytediunaRAMallindirizzo40010Hinunospaziodiindirizzamentodi1MBnellipotesididisporrediunchipda128KBmappatoallindirizzo40000H:Lindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi128KBincuièmappatalaRAM,ilsecondoidentificaloffsetall’internodellaRAM
A0A19A17A16Identificatore dellafinestra di 128Kin cui si trova la RAMOffset del byte indirizzato allinterno del dispositivo di 128KB 0      1       00  0000  0000  0001  0000iα"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#38,38,"Campi in cui si suddivide lindirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 2Indirizzamentodiunbyteall’indirizzo1026HinundispositivodiI/Odi16bytemappatoall’indirizzo1020Hdiunospaziodiindirizzamentodi64KBLindirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi16Bincuièmappatoildispositivo,ilsecondoidentificaloffsetneldispositivo
A0A15A4A3Identificatore dellafinestra di 16Bin cui si trova DOffset del byte indirizzato allinterno del dispositivo Ddi 16 Bindirizzato 0 0 0 1       0 0 0 0         0 0 1 00       1        1        0iα"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#39,39,"Decodifica degli indirizzi in caso di mappingallineato•Consideriamounospaziodiindirizzamentodi1MBincuisiamappatoundispositivodi2^Kbyte•PerindividuareunacelladiindirizzoAi=α##ipossiamodecodificaretuttii20bitchecompongonoAi•Questadecodificaèeffettuataricorrendoallastrutturadeidecoderadalbero,conalberodiduelivelli:–IlIlivelloèusatoperdecodificareα(cheidentificalaposizioneincuiilchipèmappato);perdecodificareαdobbiamodecodificare20-Kvariabili–ilIIlivellovieneutilizzatoperdecodificarei(cheidentificailbyteallinternodelchip,serveundecoderdikvariabili)•IldecoderdiIIlivellositrovaallinternodelchipmentreladecodificadiαèacaricodelprogettistadelsistemachepuòutilizzareundecoderdi20-kvariabiliconcuisidecodificaα•Ladecodificaècompletasesiutilizzanotuttii20-Kbitperdecodificareα,semplificatasesiutilizzasolounsottoinsieme(minimo)dei20-Kbit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#4,4,"Condizione di visibilità di un dispositivo da parte del software•Condizionenecessariaaffinchéundispositivofisico(memoria,interfaccia,oaltraentità)siaaccessibilealsoftwareè:–ildispositivodeveesseremappatoinunospaziodiindirizzamento•Mappareinunospaziodiindirizzamentosignifica:–associarealdispositivounafinestradiindirizzidiquellospaziodiindirizzamento•Siaccedeaidispositivimappatiinunospaziodiindirizzamentoconciclidibus"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#40,40,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèdifattoattivato(mappato)induedifferentizonedellamemorialogica00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13*Segliindirizziusatidaunprogrammasonoquellichevannoda16Ka24K(overoda4000Ha5FFFH)equellida24Ka32K(da6000Ha7FFF)nonsonousatialloraèpossibileladecodificaincompletaoparzialeinquantolazona24K-32Knonvienemaiindirizzata.EspressioneCSpiùsemplice
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#41,41,0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèattivato(mappato)induedifferentizonedellamemorialogicanonconsecutive00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13Decodifica parziale 2/2
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#42,42,EsercizioSiconsideriunsistemaconbusindirizzia16bitebusdatia8bit.Scrivereleespressionididecodificacompletaesemplificata(quelladausareall’esame)neiseguenticasi:1)Dispositivodimemoriada16KBmappatoa8000h2)Dispositivodimemoriada8KBmappatoa0000h3)EntrambiidispositiviprecedentiSec’èunsolodispositivo(casi1e2)ilCSèmoltoparticolare….
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#43,43,44
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#44,44,"Mapping, read, write e set/reset di un FFD
•Il FFD èun elementaredispositivodi memoria•Con unaCPU, come possiamo:•scriverenelFFD•leggerenelFFD •settareo resettarein modoasincronoilFFD FFDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]?
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassi"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#45,45,"NellepagineseguentiassumiamocheicomandidelFFDsianomappatineiseguentiindirizzi:CS_READ_FFD ->  80003hCS_WRITE_FFD ->  80002hCS_A_RES_FFD ->  80001hCS_A_SET_FFD ->  80000hAssumiamoinoltrediutilizzareilsegnaleBD0delbusdatiperleggereescrivereilsingolobitdidato.Ovviamentesarebbepossibileutilizzarealtriindirizzinonappartenentiallememorieeanchealtrisegnalidelbusdati(anchediversiperlettureescritture).Seiltestodell’esamenonspecificaqualiindirizziusarelasceltaèlasciataallostudente.Spesso,lasceltadegliindirizzisemplifica/complicaisegnalididecodifica."
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#46,46,CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#47,47,"CKADDRESS
DATADATA_OUTReady?Esempio di ciclo di scrittura
MEMRDMEMWR"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#48,48,"FFDDQA_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD0BD0MEMWR*CS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_FFD = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_FFD = BA19·BA18*·BA1·BA0*       (ist. scrittura)CS_A_RES_FFD = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_FFD = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).01"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#49,49,"FFD(x8)D[7..0]Q[7..0]A_RESA_SETCS_A_RES_FFD
CS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD[7..0]BD[7..0]MEMWR*Estensione a 8 bit
01
StessiCSdellapaginaprecedente,cambiasoloilnumerodibitdidatotrasferiti.8888"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#5,5,"Esempio: una CPU con K=3 bit di indirizzo
CPU3•Lospaziodiindirizzamentosarebbedisolo8elementi•Supponiamodiavereduedispositividimemoria,da4byte:AeB76543210111110101100011010001000Decoder(RC)I livelloCS_ACS_BBA[2..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#50,50,"Mapping, read, write e set/reset di un latch
•Anche il latch CD è un elementare dispositivo di memoria•Con una CPU, come possiamo:•scriverenel latch•leggerenel latch •settare o resettare in modo asincrono il latch CDDQA_RESA_SET
CPUMEMRDMEMWRBD[7..0]BA[19..0]
Consideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassiC?"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#51,51,"CDA_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD0BD0CS_WRITE_LATCHCS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_LATCH = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_LATCH = BA19·BA18*·BA1·BA0*·MEMWR(ist. scrittura)CS_A_RES_LATCH = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_LATCH = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).CDQMappiamo i quattro comandi del latch agli stessi indirizzi usati per il FFD."
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#52,52,"Estensione a 8 bit
Stessi CS della pagina precedente, cambia solo il numero di bit di dato trasferiti.CD(x8)A_RESA_SETCS_A_RES_LATCH
CS_A_SET_LATCHCS_READ_LATCHBD[7..0]CS_WRITE_LATCHCBD[7..0]888D[7..0]Q[7..0]"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#53,53,"Incrementare il parallelismo dei dati
•Abbiamoconsideratofinoaorasistemiconunparallelismo(busdati)a8bit•Ognitrasferimentorichiedeunciclodibus•Nelementi(byte)->Nciclidibus•Sappiamochelememorie(enonsolo)sonolente(vsCPU)
1"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#54,54,"i)
ii)
iii)
111"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#55,55,"•Possiamo fare meglio?•Si, aumentando il parallelismo dei dati•Riducendo la dimensione di ciascuna memoria•Trasferendo più dati nello stesso ciclo di bus 
¼¼¼¼i)i)i)i)IS"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#56,56,"•CosaNON fare?•Trasferireglielementisequenzialmentein memoriepiùpiccole•Elementicontiguivannosumemoriediverse 
¼¼¼¼NOilparallelismodi ciascunamemoriaèsempre8 bit!
i)ii)iii)iv)i)ii)iii)iv)"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#57,57,"Memoria con processori a parallelismo > 8Il caso dei 16 bitIndirizzo fisicomemorie = Indirizzo logico/ 2Sul piedino  A0della memoria -> BA1busA1della memoria ->BA2 bus……………………………..
MemorialogicaMemoriafisicaBUS ALTOBUS BASSO876543210876543210abcdefghi
acegibdfhlWord(3) -> Byteh(1) e Byteb(2) -> 2 lettureLogicoFisicoFisicoLe memorie  fisiche vanno sempre in coppiaPer ogni bancoci deve essere un ByteEnableBE0 per banco 7-0 e BE1 per banco 15-8078bit 15Indirizzo interno ai chip
Memorie sempre in coppia Ad esempio 2 x8K = 16 K (Lettura bytes 3 e 4 che però stanno a indirizzi fisici interni delle memorie differenti)(d ,e)(d )(e )"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#58,58,"Memorie con bus a 16 bitBE1      BE01           1       Word1           0       Byte alto (ind. dispari)0           1       Byte basso (ind. pari)0           0       Non possibile  Lo scambio byte alto esterno, byte basso del registro  e viceversa avviene allinternodel microprocessore
BA0del processorenon viene generato (di fatto seleziona il banco -al suo posto BE0 e BE1)BA1del processore connesso ai piedini A0delle memorieBA2del processore connesso ai piedini A1delle memorie etc. etc.7      015     8Memorie fisicheMicroprocessoreRiMUX"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#59,59,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  740000h5FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19*BA18BA17*BE1CSEPROM0= BA19*BA18BA17* BE0Individua la zona di memoria da realizzareLe memorie vanno sempre in coppia (16 bit)La decodifica si fa come se si avesse una memoria a 8 bit. Si usano dispositivi di taglia metà selezionati con BE0 e BE1Memoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#6,6,"•Comefacciamoadattivareunadelleduememorieinbaseall’indirizzoBA[2..0]emessodallaCPU?•Ovvero,comeèfattalaretedidecodifica(Ilivello)chegeneraiduesegnaliCS_AeCS_B?•CS_A=BA2CS_B=BA2*•Questisegnalisarannoinviatiaallememorie(decodificadiIlivello)•Poi,saràindividuatol’elementoall’internodellememoriaselezionata(decodificadiIIlivello)76543210111110101100011010001000BA2=1BA2=0II livello"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#60,60,"MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh
00000h64K64K070bit  780000h9FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*
CSEPROM1= BA19BA18*BA17*BE1CSEPROM0= BA19BA18*BA17*BE0Individua la zona di memoria da realizzareMemoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#61,61,"BUS BASSO4000540004400034000240001400005FFFF5FFFE5FFFD5FFFC5FFFBMemoria Logica
128K0   Eprom Pin0    Bus Pin77EPROM0BE0 -64KFFFFFFFEFFFDFFFC0003000200010000BUS ALTO07EPROM1BE1 -64KFFFFFFFEFFFDFFFC0003000200010000Eprom PinBus Pin       15              8Indirizzi interni della EPROMIndirizzi interni della EPROM
Indirizzi della memoria logicaMemoria con processori a parallelismo > 8Il caso dei 16 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#62,62,"Memoria con processori a parallelismo 32 bitMemorialogicaMemoriafisica
BUS 3BE3876543210abcdefghi
aeibfl07815cgdh162324bit 3187654210BUS 2BE2BUS 1BE1BUS 0BE0Indirizzo fisico = Indirizzo logico/4"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#63,63,"64Bus enable con parallelismo 32 bitBE3      BE2     BE1     BE01            1            1           1       Word 32 bit0            0            1           1       Half word bassa 1            1            0           0      Half word alta  0            0            0           1       Byte 0-7  N.B. BA0 e BA1  del processorenon vengono generati (di fatto selezionano uno  dei banchi -al loro posto BE0, BE1, BE2, BE3)BA2del processore connesso ai piedini A0delle memorieBA3del processore connesso ai piedini A1delle memorie etc. etc.etc.0            0            1           0       Byte 15-8  Lo scambio fra i bytes (half word) dei banchi di memoria e i byte (half word)  dei registri  e viceversa avviene allinternodel microprocessore"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#64,64,"65Memoria logicaMemoria fisica
BUS 32MB2MB2MBFFFFFFFFh
00000000h512K243140000000h401FFFFFh00000h7FFFFhIndirizzi interni alle EPROM
4 Memorie x 512K= 2MBEPROM3BE3*
CSEPROM3= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE3CSEPROM2 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE2CSEPROM1 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE1CSEPROM0= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE0Individua la zona di  memoria da realizzare512K1623EPROM2BE2*512K815EPROM1BE1*512K07EPROM0BE0*BUS 2BUS 1BUS0Selezionail BUS
CS espressi in forma veraMemoria allineata11 bitdi indirizzosono fissiMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#65,65,"Memoria logicaMemoria fisicaBUS 3  -D24-312MB2MB2MBFFFFFFFFh
00000000h512K40000000h401FFFFFh00000h7FFFFhEPROM3DLX512K512KEPROM2EPROM100000h7FFFFh00000h7FFFFh512KEPROM000000h7FFFFhBUS 2  -D23-16BUS1  -D15-8BUS 0  -D7-0BE0BE1BE2BE3
Emessi dal processoreal posto di BA1e BA0Memorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#66,66,"Memoria logica(come vista dal programmatore)512K
40000000h401FFFFFh
00000h7FFFFhEPROM3Memoria fisica(come realizzatafisicamente)
dh00001h2MB
512K00000h7FFFFhEPROM2
cg00001h512K00000h7FFFFhEPROM1
bf00001h512K00000h7FFFFhEPROM0
ae00001habcde40000001h40000002h40000003h40000004hIndirizzi fisicidei singolidispositivi
------x
I dati di indirizzi logiciconsecutivisi trovano su dispositivi diversiLa cella x di indirizzo logico abcdefghsi troverà allindirizzo fisicoabcdefgh/4 del dispositivo EPROMi ove iè il resto della divisioneabcdefghMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#67,67,"Esempio:sivuolerealizzarenelDLX(bus32bit)unamemoriaRAMda256Kpostaallindirizzo84000000(allineata).Campodiindirizzamento84000000-8403FFFF.Dispositivi:8RAMda32K(leRAMda64KstaticheNONesistono!!!!)Difattoquindivisonoduebanchida128Kluno:ilprimorealizzalamemoriada84000000a8401FFFFelaltroda84020000a8403FFFF.Ichipdimemoriada32Kutilizzanoallorointerno(fisicamente)comeindirizzidiselezionedellecelleipinA14-A0chesonoperòcollegatirispettivamenteagliindirizziemessidalDLXBA16-BA2(ricordiamoinfatticheBA1eBA0delDLXNONsonoemessiealloropostovengonoemessiBE3,BE2,BE1eBE0).SinotiilruolodellindirizzoDLXBA17chedivideiduebanchiPrimobanco(decodificanonsemplificata)CSRAM00=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE0CSRAM01=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE1CSRAM02=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE2CSRAM03=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE3Secondobanco(decodificanonsemplificata)CSRAM10=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE0CSRAM11=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE1CSRAM12=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE2CSRAM13=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE3Ovviamentenelcasodidecodificasemplificata(memorialogicaincompletamenterealizzatafisicamente)lefunzionididecodificavengonoridottedicomplessità.OvequestiduebanchifosserogliunicidarealizzareiCSdipenderebberosolodaBA17edaBEiMemorie con parallelismo 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#7,7,"Come è fatto un generico dispositivo?•Unqualsiasidispositivo(memoria,periferica,etc),comunicaconlaCPUmedianteunainterfacciastandardasxDISPCSA[K-1..0].RDWRD[R-1..0]?KBA[K-1..0]CS_DISPRBD[R-1..0]RDWRCPU•Lacomunicazioneconl’esternoavvienesecondomodalitàchesonospecifichedeldispositivoequindinonstandard•BA[K-1..0]utilizzati(internamente)perdecodificadiIIlivello"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#8,8,"9Memorie EPROM•Memorie non volatili a sola lettura•Capacità a multipli di 2:32K, 64K, 128K, 256K, etcVPPA16A15A12A7A6A5A4A3A2A1A0D0D1D2GNDVCCPGM*NCA14A13A8A9A11OE*A10CE*D7D6D5D4D3EPROM1234567891011121314151632313029282726252423222120191817128K ´8AiCE*OE*DiTceTaccToeCE*OE*DiCella M/bit i"
data_test\rootfolder\università\CalcolatoriElettronici\02_Mapping_e_decodifica.pdf#9,9,CQiDCella di indirizzo jA0  A1    An-1WR RDD0   DiDN-1La cella di una RAMDECODERIIj2n´N
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#0,0,"03 Linguaggio macchinaCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#1,1,"Instruction Set Architecture•L’insieme delle istruzioni e dei registri di una CPU costituiscono l’InstructionSet Architecture(ISA)•Mediante l’ISA è possibile accedere alle risorseinterne (e.g., registri) ed esterne (e.g., memoria)•Tipicamente le istruzioni in linguaggio macchina sono generate da un compilatore•Più raramente, come in questo corso, scritte daiprogrammatori•Purtroppo, (quasi) ogni CPU possiede un proprio ISA •A proposito di ISA, esistono due linee di pensiero:•RISC: insieme ridotto di istruzioni semplici -> moltiregistri interni (DLX, ARM, RISC-V, etc)•CISC: insieme ampio di istruzioni complesse -> pochiregistri (Intel X86)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#10,10,Consentediesprimereefficacementeconfigurazionibinarie:•Traslazionelogicaasinistradinbit:<<n(inserendo“0”adestra)•Traslazionelogicaadestradinbit:>>n(inserendo“0”asinistra)•Concatenazionediduecampi:##•Ripetizionenvoltedix:(x)n•Ennesimobitdiunaconf.binariax:xn(ilpediceselezionaunbit)•Selezionediuncampoinunastringadibitx:xn..m(unrangeinpediceselezionailcampo)•Datalaconfigurazionebinariadi8bitC=011011002:–C<<2:101100002–C3..0##1111:1100|11112–(C3..0)2:110011002–(C6)4##C>>4:1111|000001102Notazioneper la costruzionedi configurazionibinarie
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#11,11,"•Trasferimentodiundato:←Ilnumerodibittrasferitièdatodalladimensionedelcampodestinazione;lalunghezzadelcampovaspecificatasecondolanotazioneseguentetuttelevoltechenonèaltrimentievidente•Trasferimentodiundatodinbit:←nQuestanotazionesiusapertrasferireuncampodinbit,tuttelevoltecheilnumerodibitdatrasferirenonèevidentesenzalarelativaindicazioneesplicita•Contenutodicelledimemoriaadiacentiapartiredall’indirizzox:M[x]Esempio:R1←32M[x]indicailtrasferimentodallamemoriaversoilregistroR1dei4byte:M[x],M[x+1],M[x+2],M[x+3]Altranotazione"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#12,12,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
IlsegnalediRESETèasserito,all’avvio,daunareteesterna.AncheisegnalidiREADY,INTsonogeneratidaretiesternemautilizzatiduranteilnormalefunzionamento.Segnali del processore DLX30
32"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#13,13,"•Unicospaziodiindirizzamentodi4G•32registrida32bitGP(R0,…,R31,conR0=0)•Istruzionidilunghezzacostante,32bitallineate•Campidelleistruzionididimensioni/posizionifisse•3formatidiistruzione:I,R,J•Noncisonoistruzionipergestirelostack•Peristruzionicheprevedonounindirizzodiritorno(JAL/JALR),essoèsalvatoinR31•NonesisteunregistrodiFLAGsettatodalleistruzioniALU.Lecondizionisonosettateesplicitamenteneiregistri(istruzioniSET)•E’presenteun’unicamodalitàdiindirizzamentoinmemoria(indiretto,medianteregistro+offset)•Leoperazioniaritmetico/logichesonoeseguitesolotraregistri(nontraregistriememoria)•Esistonoalcuneistruzioni(MOVS2IeMOVI2S)perspostaredatitraregistriGPeregistrispecialieviceversaCaratteristiche dell’ISA DLX (integer)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#14,14,"Registri del DLX (integer)R0=0R1R2R3R28R29R30R3132PCIARMARMDR32Registri GP*accessibilidirettamentedal codiceRegistri nonaccessibilidirettamentedal codice*
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#15,15,DLX (integer): tipi di datoNelDLX(integer)sonodisponibilitretipididato:BYTE(8bit)HALF-WORD(16bit)WORD(32bit)•Idatididimensioneinferiorea32bit(quindia8o16bit)lettidallamemoriadebbonoessereestesia32bitduranteilcaricamentoneiregistri(semprea32bit)•Questaoperazionepuòessereeseguitamantenendoomenoilsegnodeldatolettodallamemoria07015031
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#16,16,"Estensione del segnoInmolticasiènecessarioèestenderelarappresentazionediundatocodificatoconnbit,inundatoconunarappresentazioneambit(conm>n).Peresempio,volendotrasferireunbyte(n=8)dallamemoriainunregistroa32bit(m=32)ènecessarioconoscerelamodalitàconlaqualeèrappresentatoildatoletto.Esempio:10110101(n=8)Assumendoildatosenzasegno(unsigned),l‘estensionea32bitavvieneaggiungeno24zeri:00000000000000000000000010110101oppure(0)24##10110101Assumendoildatoconsegno(signed),l’estesioneavvienereplicando24volteilbitdisegno11111111111111111111111110110101oppure(1)24##10110101"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#17,17,"Il set di istruzioni (integer) del DLX•Le principali istruzioni aritmetiche e logiche•Istruzioni logiche anche con op. immediato: AND, ANDI, OR, ORI, XOR, XORI•Istruzioni aritmetiche: ADD, ADDI, SUB, SUBI•Istruzioni di shift(a destra anche aritmetico): SLL1, SRL, SRA2•Istruzioni di SET CONDITION: Sx, con x= {EQ, NE, LT, GT, LE, GE} •Le principali istruzioni di trasferimento dati•Loadbyte signede unsigned(LB, LBU), loadhalfwordsignede unsigned(LH, LHU), loadword (LW)•Storebyte, storehalfword, storeword: SB, SH, SW•Copia un dato da un registro GP a un registro speciale e viceversa MOVS2Ie MOVI2S•Le principali istruzioni di trasferimento del controllo•Istruzioni di salto condizionato (PC+4 relative): BNEZ, BEQZ•Istruzioni di salto incondizionato J: assoluto (con reg.) e PC-relative•Istruzioni di chiamata a procedura Jumpand Link (JAL). L’indirizzo di ritorno viene automaticamente salvato in R31. JAL con registro e immediato  (PC-relative)•Istruzione di ritorno dalla procedura di servizio delle interruzioni: RFE1)Shiftlogicoasinistraeshiftaritmeticoasinistracoincidono(entrano0neibitmenosignificativi).PerquestaragioneNONesisteSLA.Fareattenzioneconshiftasinistra,nonpreservailsegnoepuògenerareoverflow2)Trascinandoadestradiunaposizioneunregistroeinserendoasinistrasempreilbitdelsegnosimantieneilsegnodeldatomentrelosidividesuccessivamenteper2"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#18,18,"Elencoistruzionidel DLX (integer)Data TransferLWRa,Imm16bit(Rb)LB Ra,Imm16bit(Rb)LBU Ra,Imm16bit(Rb)LH  Ra,Imm16bit(Rb)LHURa,Imm16bit(Rb)SW  Ra,Imm16bit(Rb)SH  Ra,Imm16bit(Rb)SB  Ra,Imm16bit(Rb)MOVS2IRa,Rs*MOVI2SRs*,RaSpecial registerRs* (IAR)Aritmetiche/logicheADD Ra,Rb,RcADDIRa,Rb,Imm16bitADDURa,Rb,RcADDUI Ra,Rb,Imm16bitSUB Ra,Rb,RcSUBIRa,Rb,Imm16bitSUBURa,Rb,RcSUBUIRa,Rb,Imm16bitSLL Ra,Rb,RcSLLI Ra,Rb,Imm16bitSRL Ra,Rb,RcSRLI Ra,Rb,Imm16bitSRA Ra,Rb,RcSRAI Ra,Rb,Imm16bitOR Ra,Rb,RcORIRa,Rb,Imm16bitXORRa,Rb,RcXORIRa,Rb,Imm16bitANDRa,Rb,RcANDIRa,Rb,Imm16bitLHI Ra,Imm16bitControlloSxRa,Rb,RcSxIRa,Rb,Imm16bitBEQZRa,Imm16bitBNEZ Ra,Imm16bitJImm26bitJRRaJALImm26bitJALRRaxpuò essere: LT,GT,LE,GE,EQ,NE
Ra{R0+,R1,..,R30,R31}Rb{R0,R1,..,R30,R31}Rc{R0,R1,..,R30,R31}+RanonpuòessereR0comeregistrodestinazionediistruzioniload,MOV2SI,aritmetico/logiche,LHIeSET∈∈∈
Per le istruzioni aritmetiche: l’immediato a 16 bit è esteso senza segno se di tipo U (unsigned) altrimenti con segno.  Per istruzioni logiche, sempre estensione senza segno.  "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#19,19,"DLX: formato delle istruzioni
•Istruzionidiload,store,branch,JeJALconregistro,serconditionSxIeALUconoperandoimmediato.L’immediatoèa16bit•NelleoperazioniloadeALURS2/RdèRd.NellestoreRS2/RdèRS2.InentrambiicasiRS1perindirizzosorgente(loadostore)oregistrosorgente(operazioniALUconconoperandoimmediato)IOpCodeRS2/RdRS1Immediato di 16 bit
JOpCodeImmediato/offset di 26 bit (PC relative)•Salti incondizionato con e senza ritorno (Je JAL) con immediatoROpCodeRS2RS1RdOpCodeext. (11 bit)•IstruzioniALUdeltipoRd¬Rs1opRs2oppuresetconditionSxtraregistri6 bit5 bit5 bit5 bit11 bit031•In alcuneistruzionidi tipoI (LOAD e ALU), RS2 rappresentailregistrodestinazioneRd•Alcuneistruzioni(e.g., J e JAL con registro) potrebberoesserecodificatecon piùdi un formatotraquellidisponibili"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#2,2,"Requisitidi un linguaggiomacchina/ISAOltreallapossibilitàdipoterrisolvereunqualsiasiproblema*,unrequisitofondamentalediunlinguaggiomacchina/ISAèquellodiminimizzareiltempodiesecuzionedelcodice*•SeCPImedioèilnumeromediodiclockperl’esecuzionediunaistruzione,l’obiettivoèquellodiminimizzareCPUTime=Nistruzioni*CPImedio*TCK•Lostessoproblema,puòesserequindirisoltoconCPUTimediversiinbasea:•Nistruzioni(RISC,richiedonoingenerepiùistruzioni)•CPImedio(RISC,tipicamenteistruzionipiùveloci)•TCK(Retilogichesemplicipotenzialmentepiùveloci)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#20,20,"Modalitàdi accessoallamemoria•OgniISAdisponediistruzioniperaccedereallamemoriainletturaescrittura•Normalmenteèpossibilestabilireladimensionedeldatochepuòesseretrasferito(BYTE,HALF-WORD,WORD,etc)•Idueprincipalimetodidiaccessoallamemoria(indirizzamento)sono:–Diretto(indirizzocablatonell’istruzione)–Indiretto(indirizzomodificabilearun-time)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#21,21,"Indirizzamentodiretto•Conquestamodalitàl’istruzionecontienealsuointernounvalore(cablato)chespecifical’indirizzodiaccessoallamemoriaLBR7,0800h-“LeggiunBYTE(8bit)all’indirizzo0800hememorizzalanelregistroR7”A0870800Ipotetica codifica dell’istruzione con 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#22,22,"Indirizzamentoindiretto•Conquestamodalitàl’indirizzodiaccessoallamemoriaèottenutosommandounvalorecostantepresentenell’istruzioneconilcontenutodiunregistro•Indirizzo=costante+registro•Ilregistroècablatonell’istruzionemailsuocontenutopuòcambiareatempodiesecuzioneLBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hememorizzalanelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#23,23,"Indirizzamentodirettovsindiretto1/2•Ladifferenzatraleduemodalitàdiindirizzamentoènotevole•Perrenderveneconto,poteteconsiderareuncasopiuttostocomune:“sommareglielementidiunarrayAdi8elementimemorizzatoapartiredall’indirizzo0800h”
00800h10801h20802h30803h40804h50805h60806h70807h
A[0]"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#24,24,"Indirizzamentodirettovsindiretto2/2Diretto(non usato):XOR  R8,R8,R8; R8=0LBU R7,0800hADD R8,R8,R7 ; R8=R8+R7LBU R7,0801hADD R8,R8,R7 ; R8=R8+R7LBU R7,0802hADD R8,R8,R7 ; R8=R8+R7LBU R7,0803hADD R8,R8,R7 ; R8=R8+R7LBU R7,0804hADD R8,R8,R7 ; R8=R8+R7LBU R7,0805hADD R8,R8,R7 ; R8=R8+R7LBU R7,0806hADD R8,R8,R7 ; R8=R8+R7LBU R7,0807hADD R8,R8,R7 ; R8=R8+R7Indiretto:XOR  R8,R8,R8; R8=0ADDI R9,R8,8; R9=8LOOP: SUBI R9,R9,1; R9=R9-1LBU R7,0800h(R9); legge BYTE ; a 0800+R9ADD R8,R8,R7; R8=R8+R7BNEZ R9,LOOP; se R9!=0; salta a LOOP•Il registro R9 è utilizzato in ogniiterazione per cambiare l’indirizzobase (0800h)•Pensate se l’array fosse di 1000000elementi..."
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#25,25,"DLX: modalitàdi accessoallamemoria•IlDLXprevedeun’unicamodalitàdiindirizzamento:indiretto•L’indirizzo(a32bit)èsempreottenutosommandounregistroa32bitconunvaloreimmediatoa16bitestesoa32bitconsegno.•Esempio:LWR7,Imm16_bit(R8)•CaricainR7,lawordall’indirizzo(a32bit)ottenutosommandoR8ilvaloredell’immediatoestesoa32bitconsegno:R7ç32M[R8+Imm16_bit[15]16##Imm16_bit[15..0]]•Nell’eserciziodellepagineprecedentiabbiamosottointeso,persemplicità,chel’indirizzofossea16bit.Inrealtà,nelDLXl’indirizzoèsemprea32bit(lospaziodiindirizzamentoè4G)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#26,26,"Come sonomemorizzatiidatiin memoriain un sistemacon parallelismo> 8? •Consideriamounsistemaconbusdatia16bit•Comepossiamomemorizzareilvalorea16bit0468hapartiredall’indirizzo(chesupponiamoa20bit)00010h?•Esistonodueconvenzioni:04680468046800010h00011h00010h00011h880000Fh00012h0000Fh00012h16HL
Little Endian(e.g., Intel)Big Endian(e.g., Motorola)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#27,27,"Istruzioni Aritmetico Logiche (ALU)•Istruzioni a 3 operandi:–2 operandi “sorgente”–1 operando “destinazione”. •“destinazione”: sempre un registro (a 32 bit)•“sorgente”: registro, registro •“sorgente”: operando immediato(16 bit)Esempi: ADD R1,R2,R3; R1 çR2 + R3 formato RADDIR1,R2,3; R1 çR2 + 3 formato I; il valore (3) dell’immediato a 16 bit ; è esteso a 32 bit "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#28,28,"Istruzioni di Set ConditionQuesteistruzioniconfrontanoidueoperandisorgenteemettonoa“1”oppurea“0”l’operandodestinazioneinfunzionedelrisultatodelconfronto•“SET EQUAL” (SEQ, =) : settase uguale•“SET NOT EQUAL” (SNE, !=): settase diverso•“SET LESSER THAN” (SLT, <) : settase <•. . . Gli operandi possono anche essere unsigned:•“SET LESSER THAN UNSIGNED” (SLTU, <)Esempi SLT R1,R2,R3; R1 ç1 se R2<R3 altrimenti R1 ç0; formato RSLTIR1,R2,3; R1 ç1 se R2<3 altrimenti R1 ç0; formato I"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#29,29,"Istruzioni per il trasferimento dati •Sonoistruzionicheaccedonoallamemoria(loadestore):LB,LBU,SB,LH,LHU,SH,LW,SW•L’indirizzodell’operandoinmemoriaèlasommadelcontenutodiunregistroa32bitconun“offset”di16bit(Imm16bit)estesoconsegnoa32bit•L’istruzioneècodificatasecondoilformatoIEsempi:LWR1,40(R3);R1←32M[40+R3]LBR1,40(R3);R1←32(M[40+R3]7)24##M[40+R3]LBUR1,40(R3);R1←32(0)24##M[40+R3]"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#3,3,"Istruzionie risorseinterne a unaCPULeistruzionieseguibilidaunaCPU,codificateinbinario,sonoingeneremoltopiùsemplicidelleistruzionicheutilizzateneilinguaggiadaltolivello.Tipicheoperazionisono:-somme,sottrazioni,divisioni,moltiplicazioni,etc-lettureescrittureinmemoriaeperiferiche-confrontotraoperandi(“A>B?”)-salticondizionati(“saltase”)eincondizionati(“salta”)-...E’possibile,medianteleistruzioni,accederearisorseinternedellaCPUcomeregistriarchitetturalietalvoltaaregistridistato(e.g.,AeramaggiorediB?)LerisorsechesonoaccessibilialleistruzioniinlinguaggiomacchinasonodefinitedaiprogettistidallaCPUTuttavia,nontuttiiregistriinternisonoaccessibilialprogrammatore(senzachequestorappresentiunproblema)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#30,30,"Istruzioni per il trasferimento del controllo:salti incondizionati (con e senza ritorno)•“JUMP”: salto incondizionato•“JUMP AND LINK: salto incondizionato con ritornoEsempiJoffset; PC = PC + 4 + (offset[25])6## offset, tipo JJR R3; PC = R3, tipo RJAL offset; R31 = PC+4; PC = PC + 4 + (offset[25])6## offset, tipo JJALR R5; R31 = PC + 4, PC = R5JR R31; PC = R31; istruzione per tornare da una procedura "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#31,31,"BCONDRd,Imm16E’ possiibleverificare solo due condizioni (COND):•BEQZ“BEQUAL ZERO”: salta se registro è 0•BNEQZ“BRANCH NOT EQUAL ZERO”: salta se registro è ≠ 0EsempiBEQZR4,Imm16; se R4==0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4BNEZR4,Imm16; se R4!=0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4Conunaistruzioneditiposetseguitadaun’istruzionedibranchsirealizzalafunzionedicompareandbranch(confrontoesaltocondizionatodalrisultatodelconfronto)senzabisognodiflagdedicatiIstruzioni per il trasferimento del controllo: salti condizionati (Branch)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#32,32,"Come generare valori a 32 bitNelDLXèpresenteunaistruzione,LHI(“LoadHighImmediate”)checonsentedicrearerapidamentevaloria32bit(NONèunaistruzionediaccessoallamemoria!).LHI Rd,Imm16; Rd= Imm16 ## 0000h  InserisceinRdilvaloredell’immediatonei16bitpiùsignificativie0neirimanentibitTipicamente,LHIèutilizzatapergenerareindirizzia32bitpartendodaimmediatia16bit.QualipotrebberoesseredellealternativeallaLHI?Esempio LHI R1,8420; R1 = 8420 ## 0000h = 84200000h"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#33,33,"Esempio di codice assemblerDLX 1QualevaloreassumonoiregistriR3edR4alterminedell’esecuzionedelcodiceseguente?LHIR1,0xE000ADDUIR2,R0,0x0081SB0x0000(R1),R2LBUR3,0x0000(R1)LBR4,0x0000(R1)R3=?,R4=?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#34,34,"EsercizioScrivereilcodiceDLXchesommaduewordmemorizzateapartiredallametàdellospaziodiindirizzamento(80000000h).LHIR4,8000h;R4=8000##0000hLWR5,0(R4);R5<-M[R4+0]LWR6,4(R4);R6<-M[R4+4]ADDR7,R5,R6;R7=R5+R6"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#35,35,"EsercizioProgettareunsistemabasatosulprocessoreDLXcon512MBdiEPROMnellapartebassadellospaziodiindirizzamento,1GBdiRAMapartiredall’indirizzo0x40000000e512MBdiRAMnellapartefinaledellospaziodiindirizzamento.Nelsistema,medianteopportuneistruzionisoftware,ènecessariopoter:-impostareallivellologico0o1unsegnaledenominatoSTARTUP,mappatoa0xC0000000einizialmentealvalore1-invertirelostatodiunLED,inizialmentespentoemappatoall’indirizzo0x90000000,prevedendoanchelapossibilitàdipoterneleggerelostato(ie,determinareseilLEDèaccesoospento)EPROM512 MBRAM 1 GBRAM512 MB
0xC00000000x90000000
0x1FFFFFFF
0x40000000
0x7FFFFFFFSTARTUPLED
0xE0000000"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#36,36,"Struttura di una soluzioneRispostaaeventualidomandespecificheindicateneltestoIndicazionedeidispositiviedellememorieutilizzaticonrelativiindirizzidimappingreali(inizioefineinesadecimale)Scritturadeichip-selectdiciascundispositivocondecodificasemplificataProgettodieventualiretilogichenecessarieperrisolvereilproblema
ScritturadelcodiceinassemblerDLX,necessarioarisolvereilproblemaIndicazionedicomesonoconnessituttiidispostivi(inclusetuttelememorie)presentinellasouzioneaibusdisistemadelDLXCognomeNomeMatricolaDataTipoesame(CalcolatoriToLA)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#37,37,Soluzione -chip selectCS_EPROM_512_3=CS_EPROM_512_2=CS_EPROM_512_1=CS_EPROM_512_0=CS_RAM_1_GB_L_3=CS_RAM_1_GB_L_2=CS_RAM_1_GB_L_1=CS_RAM_1_GB_L_0=CS_RAM_1_GB_H_3=CS_RAM_1_GB_H_2=CS_RAM_1_GB_H_1=CS_RAM_1_GB_H_0=CS_READ_LED=(0x90000000)CS_SWITCH_LED=(0x90000004)CS_READ_STARTUP=(0xC0000000)CS_WRITE_STARTUP=(0xC0000004)CS_RAM_512_3=CS_RAM_512_2=CS_RAM_512_1=CS_RAM_512_0=
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#38,38,Soluzione –rete segnale STARTUPAll’avviodelsistemaSTARTUP=1
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#39,39,Soluzione –rete segnale LEDAll’avviodelsistemaLED=0
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#4,4,"Registridi unaCPU•OgniCPUpossiedeuncertonumerodiregistriaccessibilialprogrammatore•Ilnumeroeladimensionedeiregistridipendonodall’ISA(equestohaimpattosullaretelogicarisultante)•Ovviamente,averemoltiregistrigeneralpurpose(GP)èvantaggioso(menoaccessiallalentamemoria)•Avereistruzionichepossonousaretutti,oquasi,iregistriGPsenzavincolièvantaggioso•LostessoISApuòessererealizzatoconretilogichecompletamentedifferenti(e.g.,InteleAMD)•Questeretihannoingenereprestazionidiverse(diversoCPUTimesebbeneabbianostessoNistruzioni)•NonsarebbestatomeglioavereunsoloISA?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#40,40,"Soluzione –connessione memorie
_3_2_1_0BA[  ..  ]MEMWRMEMRDCS_CS_CS_CS_
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[  ..  ]RD WR CSRD WR CSRD WR CSRD WR CS"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#41,41,"Soluzione –codice assemblerDLX 1/2 LetturasegnaleSTARTUP
ImpostazionesegnaleSTARTUPalvalorelogico0"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#42,42,"Soluzione –codice assemblerDLX 2/2 LetturasegnaleLED
InversionevaloredelsegnaleLED"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#43,43,"Simulatore DLXNell’ambitodialcunetestidilaureaèstatosviluppatounsimulatorediistruzioniDLXperscopididatticidisponibileaquestoindirizzo:http://dlx-simulator.disi.unibo.it/dlxAncorainfasedisperimentazionemapotrebbeessereunavalidaalternativaalsoftwareindicatonellepagineseguenti.Perchifosseinteressato,sebbenesiaancorainformamoltopreliminare,èpossibilesimulareancheistruzioniRISC-VSonograditesegnalazionidibachiesuggerimentipermigliorareisimulatoriinprossimetesiTesidilaureasvolteinquestocontesto:FedericoPomponii,“SviluppodiunsimulatoreDLXperscopididattici”,AA2019/20FabrizioMaccagnani,“ProgettodiunsimulatorediDLXperscopididattici”,AA2018/19AlessandroFoglia,“ProgettodiunsimulatorediRISC-Vperscopididattici”,AA2018/19"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#44,44,"AlcunenotesulsimulatoreDLXattuale-Negliimmediatinecessarioilprefisso0X(eg,0x8000)-Nellestoreladestinazioneasinistra(eg,SW0x800(R0),R18)-Altro?Esempio:sommaelementidiunarrayinit:XORR8,R8,R8;R8=0ADDIR9,R8,0x0008;R9=8LOOP:SUBIR9,R9,0x0001;R9=R9-1LBUR7,0x0800(R9);leggeunBYTEa00000800+R9ADDUR8,R8,R7;R8=R8+R7BNEZR9,LOOP;seR9!=0saltaaLOOP
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#45,45,
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#46,46,"Esempio di codice assemblerDLX 2E’correttoilcodiceseguente?LHIR1,0x0000ADDIR2,R0,0x0081SH0x7FF1(R1),R2LHUR3,0x7FF1(R1)LHR4,0x7FF1(R1)"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#47,47,"Esempio di codice assemblerDLX 3ScrivereilcodiceassemblerDLXperinserireinmemoria,apartiredall’indirizzoE0000800hl’arraydiwordindicatoinfigura.
01234567
0xE00008000xE00008040xE00008080xE000080C0xE00008100xE00008140xE00008180xE000081C0xE0000820
32"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#48,48,"ADDR2,R0,R0;R2usatocomeindicedelcicloLHIR3,0xE000;R3=E0000000Loop:SWR2,0800(R3);scriveindiceinmemoriaADDIR2,R2,1;incrementaindicedelciclodi1ADDIR3,R3,4;incrementaindiceoffestdi4SNEIR4,R2,8;confrontaindiceR2con8BNEZR4,Loop;saltaseR4nonèzeroi)QualevaloreènecessariosostituireaLoopinBNEZ?i)Sipuòfaremeglio(ie,usaremenoistruzioni)?"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#49,49,"76543210
0x000008000x000008040x000008080x0000080C0x000008100x000008140x000008180x0000081C0x00000820
32Esempio di codice assemblerDLX 4Scrivereilcodiceassemblerperilcalcolodellasommadeiprimi8elementidiunvettorediWORDmemorizzatoapartiredall’indirizzo00000800h.Ilrisultatodell’elaborazionedeveesserememorizzatoall’indirizzoE0000200h.Σ
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#5,5,"IA: Intel X86 (CISC)
IA: ARM (RISC)
ATMEL (RISC 8 bit)ArduinoUnoDesktopSmartphonee Tablet"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#50,50,"ADDR1,R0,R0;azzeraR1,accumulatoreADDIR2,R0,20h;R2=3210Loop:SUBIR2,R2,4h;R2=R2-410LWR3,0800(R2);leggewordinmemoriaADDR1,R1,R3;aggiornaaccumulatoreR1BNEZR2,Loop;saltaseR2nonèzeroLHIR7,0xE000;R7=E0000000SWR1,0200h(R7);memorizzaaccumulatoreinE0000200h"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#51,51,Esercizio
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#6,6,"RISC-V (1/2)•IlprogettoRISC-Vmiraproprioaquesto:creareunISAunicoeopensource•Ovviamentel’obiettivononèquellodiuniformareleretilogichecheimplementanol’ISA•L’ISAbasedelprogettoRISC-VèmoltosimileaquelladelDLXchestudieremoeprogetteremoinquestocorso•Esistonospecificheperestenderel’ISAbasealfinedicontemplareparticolarifunzionalità(floating-point,SingleInstructionMutipleData(SIMD),32/64/128bit,etc)
https://riscv.org/
RISC-V: The Free and Open RISC Instruction Set Architecture"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#7,7,"RISC-V (2/2)
https://www.slideshare.net/KrsteAsanovic/riscv-20160507patterson
"
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#8,8,"Codificabinariadelleistruzioni•LeistruzioniperessereeseguitedallaretelogicaCPUdebbonoesserecodificateinbinariosecondounformatonotoedocumentatodalproduttore(datasheet)•Lacodificabinariadeveconteneretutteleinformazioninecessarieall’UnitàdiControlloperpotereseguirel’istruzione•EsistonoCPUconcodificadelleistruzionialunghezza:-costante(e.g.,32bitcasoRISCDLXemoltialtri)-variabiledaistruzioneaistruzione(IntelX86)Esempio:LBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hetrasferiscinelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit. I bit non utilizzati per codificare R3, R7e 0800rappresentano il codice operativo (op code) "
data_test\rootfolder\università\CalcolatoriElettronici\03_Linguaggio_macchina.pdf#9,9,"Linguaggioassembler•Lacodificadelleistruzioniinlinguaggiomacchinaèpocointuitivapergliesseriumani•Nellinguaggio*assemblersicodificanoleinformazioniinunmodo(unpo’)piùintuitivoMacchina->Assembler014FA27Dh->ADDR1,R2,R3;R1=R2+R3Escludendolacaratteristicaappenaevidenziata,unaltrosignificativovantaggioèquellodipoterdefiniredellelabelutili(spesso)neisaltiLOOP:SUBR1,R1,R3......BNEZ(R1),LOOP;saltaaLOOPseR1!=0"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#0,0,"04 InterruzioniCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#1,1,"•Inunsistemaamicroprocessoreèdifondamentaleimportanzapotergestireeventichesiverificanoall’esterno(manonsolo)dellaCPU•Peresempio,determinareseèstatopremutountastosullatastiera,seilmouseèstatospostato,etc•Unastrategia,pocoefficiente,perraggiungerequestoscopoconsistenelcontrollareperiodicamentesetalieventisisonoverificati(polling)•Questopuòesserefattointerrogandodicontinuolaperifericachesidesideragestire•Ovviamente,conquestastrategia,laCPUspendemolticiclimacchinaperlaverifica(oleverifiche)•Unastrategiamoltopiùefficiente,basatasuunastrategia“push”,consistenell’usodiinterruptGestioneeventicon unaCPU: polling"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#10,10,"Interruzionimultiple e priorità
•Inunsistemanelqualeèpresentepiùdiunasorgentediinterruzioneèfondamentalepoterassociareunlivellodiprioritàaciascunainterruzione•Sarebbeauspicabilepoterinterromperel’interrupthandlerinesecuzionesegiungeunarichiestadiinterruzionepiùprioritaria(annidamento)•Esempio:
PROBLEMA_SISTEMA_FRENIPROBLEMA_SISTEMA_AUDIOINT?
"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#11,11,"•AssumeremocheilDLXsiasensibileallivellodelsegnalediinterruptINTenonalsuofronte•L’indirizzodiritorno(PC+4)èsalvatoinIAR•Inseguitoall’arrivodiuninterrupt,l’istruzioneincorsoècompletataedèeseguitoilcodiceall’indirizzo00000000h•Ilritornodall’interrupthandler(PCçIAR)avvienemediantel’istruzioneRFE(ReturnFromException)•Ingenere,manonnelDLXbase,gliinterruptpossonoessereabilitatiodisabilitatimedianteistruzioni•Nell’ISADLX,ègestitounsoloindirizzodiritorno.Pertanto,ilDLXdisabilitaleinterruzionimentreeseguel’handlereleriabilitaautomaticamenteritornandodall’handler(RFE).Incasocontrario,nelDLX,servirebbeunostacksoftwareInterrupt nelDLX"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#12,12,"•Conannidamento(nesting)delleinterruzionisiintendelapossibilitàdipoteravviareuninterrupthandlerdurantel’esecuzionediunaltrohandler•QuestacaratteristicaèstandardnellamaggiorpartedelleCPUincommerciomanonèprevistadalDLXbase•Perpoterannidaregliinterruptsarebbenecessariounostacksoftware(utilizzandol’istruzioneMOVS2I)eaverelapossibilitàdiri-abilitaregliinterruptnell’handlermedianteopportuneistruzioni(ENI)nonprevistadall’ISAbase•Incasomultiplesorgentidiinterruzione,nasceilproblemadicomeassociareunascaladiprioritàalleinterruzioni•Atalfineesistonovariepolitiche:prioritàfissa,variabile,etc.Ovviamentelaprioritàècrucialenonsoloquandoèpossibileannidaregliinterrupt"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#13,13,"•Lerichiestediinterruptpossonoverificarsiinqualsiasimomento•E’perònecessariomantenerelaconsistenzadeidatiinmodocheilcodiceinesecuzionenonsiamodificatodall’arrivoomenodiinterruptediconseguenzadall’esecuzioneomenodegliinterrupthandler•Perquestaragioneènecessariofareinmodochel’interrupthandler(i.e.,ildriverdeldispositivo)noninterferiscaconilcodicedelprogramma(main)inesecuzione•Comefare?Salvandoeripristinandoiregistrimodificatidall’interrupthandlerall’internodellostessocodice(handler)•Nellapaginaseguenteèmostratol’effettodiunpessimointerrupthandlerchenonpreservairegistriInterrupt handler e consistenzadeidati"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#14,14,"1
+
2
=
33
a)b)c)
d)e)
1+2=33??Chi ha scrittoildriver/handler del nuovodispositivo, avràsalvatoe ripristinatolo statodeiregistri?Temodi no…"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#15,15,"Nelcasodiunasingolasorgentediinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;codicedirispostaallarichiesta;diinterruzione;istruzionidiripristinodeiregistri;modificatiinprecedenzaXXXXXXXXhRFE;ritornodall’interrupt(PCçIAR)Interrupt handlercon singolainterruzione"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#16,16,"Nelcasodimultiplesorgentidiinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;Identificazionedell’interruptpiù;prioritariotraquelliasseriti;ripristinaregistriesaltaalcodice;dell’interruptpiùprioritario;salvaregistrimodificatiinseguito;codicehandler_1XXXXXXXXh;ripristinaregistrieritorno(RFE);salvaregistrimodificatiinseguito;codicehandler_2YYYYYYYYh;ripristinaregistrieritorno(RFE)Interrupt handlercon multiple interruzione
RFERFEPreambolo"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#17,17,"•Conlastrategiamostratanellapaginaprecedenteèilsoftware,interrogandoognisingolaperiferica,adoverdeterminarequalèl’interruptpiùprioritario•Atalfinesaràanchenecessariaunaopportunainfrastrutturahardware(itri-stateserviranno?)•Tuttavia,èpossibilevelocizzareesemplificareleretilogichedisupportoaquestocompitomediantel’utilizzodiundispositivoadhoc(PIC)•IlPICsioccupadigestiremultiplesorgentidiinterruzioneediforniredirettamenteallaCPU(surichiesta)qualèilcodice/indirizzodell’interruptpiùprioritariotraquelliasseritiinquelmomento•Tipicamente,inunPICèpossibiledisabilitarelesingolesorgentidiinterruzioneestabilireillivellodiprioritàdiciascunainaccordoavariepolitiche(prioritàfissa,variabile,etc)Programmable Interrupt Controller (PIC)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#18,18,PICCSA[K-1..0]RDWRD[7..0]KBA[?..?]CS_PIC8BD[7..0]RDWRINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTINTINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0•LastrutturadiunipoteticoPICpotrebbeesserequellamostratainseguito•LevariesorgentidiinterruzioneINT[7..0]sonoinviatealPICchesioccupadiinviarelarichiestasull’unicopinINTdelDLX•Piùavantineprogetteremounomoltosempliceconfunzionalitàdibase(abilita/disabilitaINT_i)
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#19,19,"INTPICCSA[K-1..0]RDWRD[7..0]INT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTCPU•IlPICinviailsegnalediINTefornisceallaCPU,surichiesta,ilcodicedell’interruptconprioritàpiùelevatatraquelliasseritiinquelmomento•PerchénelPICèpresenteancheilsegnaleWR?Perché dei timer?Come può essere realizzato un timer?
Cosa comunicano alla CPU le reti?"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#2,2,"main(){bool tasto_premuto=false;while(1){if (tasto_premuto==true)gestisci_evento();. . .}}void gestisci_evento(){. . .return;}Premuto?Premuto?Premuto?Premuto?
LaCPUspendemoltotemponelcontrollare(polling)sel’eventosièverificato.Questastrategiarallental’esecuzionedelmainPocoefficiente…."
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#20,20,"(i)(ii)INT
ΔxΔyΔwheelpressed_Lpressed_R•Inrealtàleinformazionisonoconvogliatesuuncanaleseriale(USB,PS/2)perridurreilnumerodiconnessioni/fili•Tuttavia,possiamopensareperlenostrefinalitàchel’interfacciamouse/CPUespongaisegnalidiunaportadiI/Ostandard(CS,RD,WR,D[7..0],indirizzi)
Inrealtàgliinterruptsonoemessiperiodicamente(e.g.,100Hz)esolosenecessario(uneventonelmouse)
"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#21,21,
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#22,22,"•InunaCPU(manonnelDLX)puòesserepresenteunulterioresegnale(ininput)denominatoNMI(NotMaskableInterrupt)•Atalesegnalesonocollegateunnumerolimitatodisorgentidiinterruzioniparticolarmentecritiche•Peresempio,l’outputdiunaretecherilevaesegnalaunaimminenteperditadialimentazioneelettrica•UnarichiestadiinterruptinviatasulpinNMInonpuòessereignorata(eventualiistruzionichedisabilitanogliinterruptnonagisconoperquestosegnale)einterrompel’esecuzionedialtrihandler•L’handlerassociatoalpinNMIèaprioritàmassimaedeveessereseguitonelminortempopossibileInterrupt non mascherabili(segnaleNMI)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#23,23,"•IlsegnaleNMIvausatoconcautelaesolopersegnalazionicriticheallaCPU•NelcasodelDLXutilizzeremosoloINT•Sefossedisponibile,perlagestionedelsegnaleNMIsarebbenecessarioinserireleistruzioninellaprimapartedel“preambolo”all’indirizzo00000000h,primadigestiregliinterruptchesonoinviatiattraversoINT"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#24,24,"ProgettareunsistemabasatosulprocessoreDLX,conun1GBdiEPROMaindirizzibassie512MBdiRAMaindirizzialti.Intalesistema,utilizzandounpulsante,deveesserepossibileaccendere/spegnereunledmedianteinterrupt.All’avvioilleddeveessereacceso.Sifaccial’ipotesicheR29eR30possanoessereusatisenzalanecessitàdiessereripristinati.Esercizio"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#25,25,"Alcune considerazioni sul reset asincrono
FFDDQQ*A_SETA_RESRESETClockRESET_SYNCTuttavia,presentadeiproblemi:•E’semprenecessariounsegnalediclock•QuandoRESETvaa1,RESET_SYNCsiasserisce(ie,diventaattivo)alprimofrontediclockL’applicazionediunsegnaleasincronodireset,puòportareaproblemidimetastabilitànelmomentoincuitalesegnalevienepostoalvalore0(ie,quandosiescedalreset,assumendochetalesegnalesiaattivoalto).Leproblematichesonoanalogheaquelleevidenziateduranteilcampionamentodiunsegnalechenonrispettaitempidisetupehold.Unapossibilesoluzioneèlaseguente:"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#26,26,"FFDDQQ*A_SETA_RES0ClockRESET_SYNCRESETUnasoluzionecheeliminaidueproblemiprecedenti,echegarantisceun’uscitasincronadalreset,èlaseguente:
ClockRESETRESET_SYNCAttivazionenonsincronadelresetUscitasincronadalreset"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#3,3,"•UninterruptèuneventocheinterrompelaCPUduranteilregolareflussodiesecuzionedelcodice•L’interruptsegnalachesièverificatouneventochemeritaimmediata*attenzionedapartedellaCPU•SelaCPUèabilitata*ariceveretalesegnalazione,esegueautomaticamenteunaporzionedicodicedenominatainterrupthandleralfinedigestirel’evento•Glieventipossonoessererelativiafattoriesterni(e.g.,premutountasto)ointerni(e.g.,èstataeseguitaunadivisioneperzero,overflow,etc)•Quandodipendonodafattoriinternisiparladieccezioni(exceptions)•Inoltre,èpossibileinvocarel’handlermedianteopportuneistruzioni(e.g.,perinvocaresystemcall)Gestioneeventicon CPU: interrupt"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#4,4,"READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET
READYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR
Inogniprocessore,èpresentealmenounsegnaledenominatoINTpergestireleinterruzioni.Inmolticasi,manonnelDLX,èpresenteancheunulterioresegnaledenominatoNMIpergestireinterruzionichenonpossonoessereignorate.Gestione interruzioni nel DLX30
32NMI(NA nelDLX)NMI"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#5,5,"•Nelcasodiinterruptgeneratodall’esternolasituazioneèquesta:
•Lapressionedeltastoinnesca*l’esecuzionedelcodicedell’interrupthandler(2)(1)(2); Interrupt hander. . . . . . . . . .. . . . .RFEINT
LaCPUnormalmentesvolgeoperazioniutiliedèavvisatasoloquandosiverifical’evento(inquestocaso,lapressionedeltasto)"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#6,6,"•Nelcasodiinterruptgeneratodall’esternolasituazione,dalpuntodivistasoftware,èquesta:main(){Istruzione1;Istruzione2;Istruzione3;Istruzione4;Istruzione5;Istruzione6;Istruzione7;Istruzione8;}
(i); Interrupt handler ADD R1,R0,R0. . . . . . . . . .RFE(ii)(iii)•L’interruptpuòverificarsiinqualsiasimomento(i.e.,durantel’esecuzionediqualsiasiistruzione)enonèsincronizzatoconilclock•Assumeremosempreche,l’esecuzionedell’istruzionedurantelaqualesiverifical’interruptsiasempreportataatermineprimadieseguirel’handler
L’is tr uzio n e4èportataatermineprimadieseguirel’interrupthandler"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#7,7,"•EsistonoCPUsensibiliallivellodelsegnalediinterrupt,altrealfrontedisalitaealtreaentrambelecose•NelcasodelDLXassumeremochelaCPUsiasensibileallivellodelsegnale(1sel’interruptèattivoe0incasocontrario)•Nelcasodeidispositivichegeneranointerrupt,assumeremocheessorimangaa1fintantochélacausachelohageneratononsiastatagestitadallaCPU•Pertanto,seunaperifericahauninterruptalivelloasserito,rimanetalefintantochél’interruptnonègestitodallaCPU(nonnecessariamentesubito*)•Inalcunicasi,nell’handlerpuòesserenecessarioeseguiredelleoperazionisoftwareperpoterportareallivellologico0ilsegnalediinterruptprovenientedall’esternodopoavergestitol’eventoSegnaledi interrupt: fronteo livello"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#8,8,"FFDDQ1A_RESINT_FRONTEINT_LIVELLOCS_RESET_INT
•Comefareseildispositivochegeneral’interruptassumechelaCPUsiasensibileaifrontimentrelaCPUèsensibilesoloallivellodelsegnale?•E’necessarioeseguireunatrasformazionedafrontealivellodelsegnaleINT_FRONTE•Inuncasocomequesto,illivellologicodelsegnaleINT_LIVELLOdeveessereportatoazerodaunopportunocomandosoftware(CPU)cheasserisceilsegnaleCS_RESET_INTTrasformazioneda frontea livello"
data_test\rootfolder\università\CalcolatoriElettronici\04_Interruzioni.pdf#9,9,"•C’èperòunproblema:escludendoNMI(discussodopo)ilDLXhaunsolosegnalediinterruptdenominatoINT.Comefacciamoagestire,cometipicamenteaccade,multiplesorgentidiinterrupt?•Siconvogliano(e.g.,medianteunORoaltrefunzioniinbaseallespecificheesigenze)tuttigliinterruptversol’unicosegnaleINTpresentenelDLX•Rimaneunaltroproblema:comedeterminarequale/qualiinterruptsonoasseritiinundeterminatoistante?•Atalpropositoè(tipicamente)necessariopoterdeterminarelostatodellerichiestediinterruptmedianteopportuneistruzionisoftware•Vedremocheesistonoanchedellereti,denominatePIC,chepossonoagevolarequestocompitoallaCPUGestionedi interruzionimultiple"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#0,0,"05 Periferiche di I/O con handshakeCalcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#1,1,"Porte di Input/Output (I/O)•InprecedenzaabbiamovistocomeprogettaredellesempliciperiferichediI/O,perscambiaredatitraCPUemondoesternomedianteunbuffer•Tuttavia,nonvieranessunagaranziasulcorrettoesitodeitrasferimenti•Infatti,cosaaccadese,mentrelaCPUscrivenellaportainoutput,undispositivoesternoleggedallamedesimaporta?Inoltre,cosaaccadeselaCPUleggeundatocheinrealtànonèmaistatoscrittodaundispositivoesterno?Comepuòsaperlo?Perquesto,itrasferimentisonointrinsecamenteespostiaerrori•Inpiù,lagestionedeltrasferimentieratotalmenteacaricodellaCPU(chepotrebbefarealtro)•LeportediI/Ononeranoingradodigenerareinterruptcontutteleproblematichechenederivano"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#10,10,"WROBFINT_OACKHandshake (OUTPUT): formed’onda
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUTOUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#11,11,"Unesempiodiunitàesternainoutputpotrebbeessererappresentatadaunastampantecheimprimesullacartaunacarattereallavolta.LaCPU,fornisce*idatiallastampanteattraversolaperifericadioutputquandoilsegnaleINT_Oèasserito(questoimplicacheOBFsia0)LastampanteleggeildatosoloquandoilsegnaleOBFèasserito(i.e.,quandolaportainoutputcomunicaallastampantecheunnuovodatoèstatoscrittodallaCPUnelbufferedèquindidisponibile)
OUTPUTINT_OACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK
Lastampantedevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#12,12,"ProgettareunaretelogicabasatasuFFDingradodigestirelecomunicazioniconduedispositiviesterni–unoininputmappatoaCS+0eunoinoutputmappatoaCS+1–utilizzandoilprotocollodihandshakeEsercizio
ParallelI/OBD[7..0]RDINT_ICSA0WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFA_RESETRDINT_ICSBA2WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFRESET
BD[7..0]"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#13,13,"ProgettodellinterfacciaL’interfacciaparallelaèdotatadidueporte,ciascunaingradoditraferiredatia8bit:•PortainINPUTmappataall’indirizzoCS+0•PortainOUTPUTmappataall’indirizzoCS+1Alfinedirisolvereilproblema,risultautilepensarelaportadiI/Ocomecompostadadueporteindipendenti:unaportaininputeunaportainoutputInoltre,nellasoluzionesidesideraevitareclockgatingIlpuntodipartenzasonoleformed’ondadelprotocollodihandhsake,mostratenellepagineprecedenti"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#14,14,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#15,15,"STBIBFINT_IRDHandshake (INPUT)
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUT01230INPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#16,16,"STBIBFINT_IRDU0U1U2U300 0 010 0 011 0 011 1 011 1 101 1 100 1 100 0 100 0 010 0 011 0 011 1 011 1 1Handshake (INPUT): soluzionesenzaclock gating
013715141280137151otrasferimento2otrasferimento3otrasferimentoOsservando le forme donda, è possibile individuare unasoluzione senza clock gating
Due trasferimenti, un ciclo completo "
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#17,17,"IlsegnaleDEC(x)identificalaconfigurazionebinariaU3U2U1U0equivalenteaxinbase10.Pertanto,isegnaliIBFeINT_Irisultano:IBF=(DEC(1)+DEC(3)+DEC(7))+(DEC(14)+DEC(12)+DEC(8))INT_I=DEC(3)+DEC(12)Oppure,IBF=U0XORU3INT_I=U1XORU2CSèilchip-selectdellaperifericaininputFFDDQ0A_RESQ0*RESETSTBU0FFDDQ1A_RESQ1*RESETSTB*U1
FFDDQ3A_RESQ3*RESETRD*U3Q3*Q310CS·A0*FFDDQ2A_RESQ2*RESETRDU2Q2*Q210CS·A0*"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#18,18,"373D[7..0]Q[7..0]OECCS·RD·A0*D_IN[7..0]BD[7..0]STBHandshake (INPUT): buffer di ingressocon 373 Ipotizzando di mappare la porta in INPUTall’indirizzoCS + 0e di voler utilizzare dei latch 373 come buffer.
Ovviamentesarebbepossibileunasoluzionedeltuttoequivalentecon374comemostratonellapaginasuccessiva"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#19,19,374D[7..0]Q[7..0]OECS·RD·A0*D_IN[7..0]BD[7..0]STB*Handshake (INPUT): buffer di ingressocon 374 IpotizzandodimapparelaportainINPUTall’indirizzoCS+0edivolerutilizzaredeiFFD374comebuffer
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#2,2,"FFD(x8)D[7..0]Q[7..0]CS·RDDI[7..0]BD[7..0]WRITE*Unasempliceperifericaperleggeredatidall’esterno,senzautilizzareinterrupt,èlaseguente:CPU
EsternoTuttavia,conquestasoluzione,sorgonodeglievidentiproblemi:•ComepuòsaperelaCPUcheèdisponibileunnuovodatoscrittodall’esternonellaporta?•Comesipuòsaperedall’esternochelaCPUhalettoildatoscrittoinprecedenzanellaporta?
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#20,20,Esercizio: progettodellaportain outputProgettarelaperifericapergestireitrasferimentiinOutputmediantehandshakeapartiredalleformedondamostratenelleslidesuccessive.OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#21,21,"WROBFINT_OACKHandshake (OUTPUT)
NOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUT01230OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#22,22,"Registridi statoe programmazioneSarebbeutileaggiungereallaperifericachegestisceinputeoutputconprotocollodihandshakeiseguentiregistri:•Registrodistato(letturasegnalidistatopergestioneapolling)indirizzoA1A0=10•Registrodiprogrammazione(enable/disablesingolainterfaccia,etc)indirizzoA1A0=11Ovviamente,serveunulteriorebit(A1)perindirizzaregliulterioridueregistriEsercizioComesipotrebbemodificareilprogettodellaportadiI/Oconhandshakeperaggiungerequestenuovefunzionalità?"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#23,23,"ProgettareunsistemabasatosulmicroprocessoreDLX,con1GBdiEPROMagliindirizzibassie2GBdiRAMagliindirizzialti.Nelsistemaèpresenteunaportaininput,giàprogettataedenominataINPUT_PORT,eunpulsantedenominatoP.Ilbyte(unsigned)lettodaINPUT_PORTdeveesserememorizzatoall’indirizzoFFFF0020hmentreilregistroR20deveessereincrementatodiuno,viasoftware,aognipressionediPeinizializzatoa0all’avviodelsistema.Inoltre,siassumache:1)IlpulsantePabbiaprioritàmaggiorediINPUT_PORT2)IlpulsantePnonpossaesserepremutoprimachesiaterminatalagestionediPdapartedell’interrupthandler.Atalfinesegnalare,conunLED,quandoilpulsantenondeveesserepremuto3)IregistridaR25aR30possonoessereutilizzatisenzalanecessitàdiessereripristinati4)IlregistroR20siamodificabilesolodall’handlerchegestisceilpulsanteEsercizio"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#3,3,"Unesempiocheevidenziaquestiproblemiriguardaloscambiodibeni/datitraunproduttoreeunconsumatore
Seilproduttoreproduceuncaffècheèprelevatoprimadell’arrivodiunaltrotuttopotrebbeapparentementefunzionarecorrettamente(setupehold?)Tuttavia,comepuòsapereilproduttorecheilcaffèèstatoprelevato?Comepuòsapereilconsumatorecheèdisponibileunnuovocaffèpreparatodalproduttore?Perquesteragioni,sorgonoaltriproblemi...PC
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#4,4,"Unprimoproblemasiverificaseilconsumatoresmettediprelevarecaffèperchénonèpronto(e.g.,ilconsumatoreèaltelefono).Comepuòsaperloilproduttore?
PC
bla,bla,bla"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#5,5,"Ilproblemadualesiverificaseilproduttoresmettediprepararecaffèperchéimpegnatoafarealtro(e.g.,parlarealtelefono).Comepuòsaperloilconsumatore?
bla,bla,bla
•IdueproblemievidenziatipossonoessererisoltiinmodomoltosemplicericorrendoaqualcheformadisincronizzazionetraledueentitàPeC•Perquestoscopol’handshakeèunapprocciosemplice,efficienteeampiamenteutilizzatoPC
"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#6,6,"Segnali del protocollo handshake: INPUT
1.SeIBF=0,quandopossibile*UEpuòscrivereildatonelbufferdingressodellaporta2.UE,portandoSTBa1,scriveildatonellaportachecontemporaneamenteasserisceIBF(InputBufferFull)3.QuandoUEportaSTBazero(scritturaterminata),linterfacciaattivaINT_I(InterruptRequest)4.Quandopossibile*,laCPUandràaleggereildatoscrittonellaportadaUE.Altermine,IBFandràazero(mentreINT_Ivaa0,dall’iniziodellalettura)INPUTUnitàEsterna(UE)InputRDINT_IBD[7..0]D_IN[7..0]STBIBFCSRDINTRBD[7..0]CSD[7..0]STBIBF"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#7,7,"STBIBFINT_IRDHandshake (INPUT): formed’ondaINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]
NOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTCSRDINTRBD[7..0]CSD[7..0]IBFSTB"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#8,8,"Unesempiodiunitàesternaininputpotrebbeessererappresentatadaunsensore(e.g.,ditemperatura)IlsensoreinviaidatiallaCPUattraversolaperifericadiinputquandounanuovamisuraèdisponibileeIBF=0.Alterminediogniscritturanellaportadapartedelsensoreditemperatura,ilsegnaleINT_IsiasserisceINPUTINT_ISTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB
Ilsensoredevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake"
data_test\rootfolder\università\CalcolatoriElettronici\05_Handshake.pdf#9,9,"Segnali del protocollo handshake: OUTPUTOUTPUTUnità Esterna(UE)Output1.IlsegnaleINT_OasseritocomunicaallaCPUchelaportapuòaccettareunnuovodato2.InrispostoallarichiestadiinterruptlaCPUscrive,quandopossibile*,ildatosulbufferdellaporta1.LinterfacciasegnalaaUEcheèdisponibileunnuovodatoattivandoOBF(OutputBufferFull)2.Quandopossibile*,UEleggeildatoscrittodallaCPUasserendoACK(acknowledge)WRINT_OBD[7..0]D_OUT[7..0]ACKOBFCSWRINTRBD[7..0]CSD[7..0]ACKOBF"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#0,0,"06 ProgrammableInterrupt Controller (PIC)Calcolatori Elettronici TIngegneria Informatica
Stefano Mattoccia"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#1,1,"•Abbiamogiàvistocheèpossibile,opzionalmente,utilizzareundispositivoad-hocperlagestionedimultiplesorgentiinterruzionidenominatoPIC•IlPICvelocizzaefacilitalafasedianalisiegestionedegliinterrupt•TipicamenteunPICconsentedi:•Abilitaredisabilitaresingoleinterruzioni•Fornireinformazionisulleinterruzioniasserite•Gestirelaprioritàdelleinterruzioni•Perleragionievidenziate,unPICèprogrammabilemediantel’utilizzodiopportuniregistriinterni•Sebbenesiasemprepossibileunagestioneinteramentesoftwaredelleinterruzioni,l’utilizzodiunPICpuòessereunavalidaalternativa•Perquesteragioni,progettiamounPICmoltosempliceGestionedelleinterruzionicon PIC"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#10,10,"EN_INT_0INT_0Diconseguenza,inogniistante,gliinterruptabilitatirisultanodalleuscitediquestarete:EN_INT_1INT_1EN_INT_2INT_2EN_INT_3INT_3RAW_ENABLED_INT_0RAW_ENABLED_INT_1RAW_ENABLED_INT_2RAW_ENABLED_INT_3Si ricorda che, come mostrato nello schema ai morsetti del PIC, risulta:INT_0= INT_OUT_PORT_0INT_1= INT_OUT_PORT_1INT_2= INT_IN_PORT_0INT_3= INT_IN_PORT_1Al pin di interrupt del DLX è pertanto inviato il segnale:INT_DLX= RAW_ENABLED_INT_0+RAW_ENABLED_INT_1+RAW_ENABLED_INT_2+RAW_ENABLED_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#11,11,"Perevitareproblemidimetastabiitàèpossibilecampionarelostatodegliinterrupt,primadiprocedereallalorolettura,peresempioconquattroFFDchecampionanogliinterruptsulfrontedisalitadiMEMRD.RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_0SYNC_ENABLED_INT_0RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_1SYNC_ENABLED_INT_1RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_2SYNC_ENABLED_INT_2RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_3SYNC_ENABLED_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#12,12,"Alfinedileggerelostatodegliinterruptasseriti,traquellichesonostatiabilitati,siutilizzanodeibuffertri-statepilotatidalsegnaleCS_PIC_READ_INTscomesegue:CS_PIC_READ_INTsSYNC_ENABLED_INT_0CS_PIC_READ_INTsSYNC_ENABLED_INT_1CS_PIC_READ_INTsSYNC_ENABLED_INT_2CS_PIC_READ_INTsSYNC_ENABLED_INT_3CS_PIC_READ_INTs‘0000’ENABLED_INT[0]ENABLED_INT[1]ENABLED_INT[2]ENABLED_INT[3]ENABLED_INT[7..4]IsegnaliENABLED_INT[7..0]sonoconnessialbusdatiBD[7..0]44"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#13,13,"Lareteseguente,consentedileggereaCS_PIC_READ_CODEilcodicea16bit(perragionimostratedopo)dell’interruptpiùprioritario(BD[15..0])
CS_PIC_READ_CODESYNC_ENABLED_INT_0·SYNC_ENABLED_INT_1*· SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3* CS_PIC_READ_CODESYNC_ENABLED_INT_1·SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_2·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_3CS_PIC_READ_CODE‘00000000’
CS_PIC_READ_CODE‘0000’INT_CODE[7..0]INT_CODE[8]INT_CODE[9]INT_CODE[10]INT_CODE[11]INT_CODE[15..12]NOTA: come richiesto dal testo del problema, si assegna il seguente ordine crescente di priorità:0) INT_0 (Minima) 1) INT_12) INT_23) INT_3 (Massima)4488"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#14,14,"Icodicidipriorità,a16bitpervelocizzarel’handler,associatiallequattrointerruzionielettiall’indirizzoCS_PIC_READ_CODE,risultano:0800hseèasseritoSYNC_ENABLED_INT_3(massimapriorità)0400hseèasseritoSYNC_ENABLED_INT_2enonSYNC_ENABLED_INT_30200h se è asseritoSYNC_ENABLED_INT_1e non SYNC_ENABLED_INT_2oSYNC_ENABLED_INT_30100h se è asserito SYNC_ENABLED_INT_0e nessun altro segnaleIl codice per abilitare le interruzioni dalle 4 porte risulta:LHI R25,8000h; R25 = 80000000hADDI R26,R0,000Fh; R26 = 0 + 0000000FSBR26,(R25)04h; scrive il byte 0Fh contenuto in R26; all’indirizzo CS_PIC_SET_INTs(80000004h)Il codice per leggere quali sono le interruzioni asserite:LHI R25,8000h; R25 = 80000000hLBUR26,(R25)08h; legge in R26 gli interrupt asseriti, tra quelli; abilitati, all’indirizzo CS_PIC_READ_INTs; (80000008h)"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#15,15,"Il codice dell’interrupt handlerè il seguente:00000000: LHI R25,8000h; prepara indirizzo 80000000h00000004: LHU R26,(R25)0Ch; lettura del codice di priorità a 16 bit; all’indirizzo CS_PIC_READ_CODE00000008: LHIR27,FFFF; prepara in R27 l’indirizzo per : operazioni comuni successive al salto 0000000C: JRR26; salta all’indirizzo presente in R26; checorrisponde al codice di interrupt ; più prioritario letto mediante LHU00000100: LBU R28,(R27)10h; legge in memoria un byte a FFFF0010h00000104: SB R28,(R25)2h; scrive quanto letto in OUTPUT_PORT_000000108: RFE; (80000002h) e ritorna dall’interrupt00000200: LBU R28,(R27)20h; legge in memoria un byte a FFFF0020h00000204: SB R28,(R25)3h; scrive quanto letto in OUTPUT_PORT_100000208: RFE; (80000003h) e ritorna dall’interrupt00000400: LBU R28,(R25)0; legge da INPUT_PORT_0(80000000h)00000404: SB R28,(R27)40h; scrive byte in memoria a FFFF0040h  00000408: RFE; ritorna dall’interrupt00000800: LBU R28,(R25)1; legge da INPUT_PORT_1(80000001h)00000804: SB R28,(R27)80h; scrive byte in memoria a FFFF0080h  00000808: RFE; ritorna dall’interrupt"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#16,16,"RAM_3RAM_2RAM_1RAM_0BA[28..2]Interfacciamento RAMMEMWRMEMRDCS_RAM_0CS_RAM_1CS_RAM_2CS_RAM_3
BD[7..0]BD[15..8]BD[23..16]BD[31..24]
A[26..0]RD WR CSRD WR CSRD WR CSRD WR CS"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#17,17,"Interfacciamento EPROM
BD[7..0]BD[15..8]BD[23..16]BD[31..24]EPROM_3EPROM_2EPROM_1EPROM_0BA[29..2]MEMRDCS_EPROM_0CS_EPROM_1CS_EPROM_2CS_EPROM_3
A[27..0]RD  CSRD  CSRD  CSRD  CS"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#2,2,"InunsistemabasatosulDLX,con1GBdiEPROMmappatanegliindirizzibassie512MBdiRAMmappatanegliindirizzialti,sonopresentiegiàprogettate2portea8bitinINPUT(IN_1eIN_0)e2portea8bitinOUTPUT(OUT_1eOUT_0)basatesulprotocollodihandshake.ProgettareunsemplicePICalfinediassegnareleseguentiprioritàstaticheallequattrointerruzioni:IN_1(massimapriorità),IN_0,OUT_1eOUT_0(minimapriorità).IlPICdovràinoltreconsentiredi:a)disabilitare/abilitareselettivamente,medianteparoledicontrollo,ciascunainterruzionegeneratadalle4perifericheb)fornireleinterruzioniasserite(traquelleabilitate)c)fornireuncodicecheindicaqualèl’interruzionepiùprioritaria(traquelleabilitate)inundeterminatoistanteUtilizzandolaretelogicaprogettatagestirelequattrointerruzioniinmodochedurantel’esecuzionedell’interrupthandlersiaeseguito,nelmodopiùrapidopossibile,soloiltrasferimentoattivopiùprioritarioinquelmomento.Eventualialtrerichiesteditrasferimentoattivesarannogestitedurantesuccessiveesecuzionidell’interrupthandler.IdatilettidalleporteinINPUTdovrannoesserescrittiaFFFF0080(IN_1)eFFFF0040(IN_0)mentreidatidascriverenelleporteinOUTPUTdovrannoesserelettidaFFFF0020(OUT_1)eFFFF0010(OUT_0).All’avviodelsistemailPICdovràautomaticamentedisabilitaretuttelerichiestediinterruzioneprovenientidallequattroporte.-ScrivereilcodicecheabilitatutteleinterruzioninelPICeilcodicecheconsentedileggerelostatodegliinterrupt-Scrivereilcodiceottimizzatodell’interrupthandler(iregistridaR25aR29possonoessereutilizzatisenzalanecessitàdidoverliripristinare).Progettodi un semplicePIC"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#3,3,"PICProgrammableInterruptControllerA_RESETINT_0 (-)INT_1INT_2INT_3 (+)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_INTs_CODED[3..0]INT_TO_DLXENABLED_INT[7..0]INT_CODE[15..0]4816BD[7..0]BD[15..0]BD[3..0]INT(to DLX)CS_PIC_SET_INTs
CS_PIC_READ_INTsCS_PIC_READ_CODEINT_OUT_PORT_0INT_OUT_PORT_1INT_IN_PORT_0INT_IN_PORT_1RESETIlPIC(ProgrammableInterruptController),ingradodigestire4interruzioni,puòessereschematizzatonelmodoseguente:
RDWRMEMRDMEMWR"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#4,4,"NelPIC,lamassimaprioritàèassegnataaINT_3,quellaminimaaINT_0.Leprioritàsonostatiche,comeprevistodaltesto.IsegnalidiingressodelPICINT_3,INT_2,INT_1eINT_0sonoconnessiai4interruptdelleperifericheinmododasoddisfareivincolisullaprioritàprevistidaltestodelproblema.ScrivendoaCS_PIC_SET_INTs,idatipresentisuipinD[3..0]consentonodiabilitare/disabilitareisingoliinterrupt.Gliinterruptasseritidalleperiferiche,traquelliabilitati,possonoessereletti,aCS_PIC_READ_INTs,attraversoisegnaliENABLED_INT[7..0].Essendoprevistisolo4interrupt,4degli8bitsonocablatia0(i4bitpiùsignificativi).Ilcodicechecorrispondeall’interruptpiùprioritario,traquelliabilitati,potràessereletto,aCS_PIC_READ_CODE,attraversoisegnaliINT_CODE[15..0].Diquestiultimi16segnali,12sarannosemprecablatia0perragionichiariteinseguito."
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#5,5,"Dispositivi e segnali presenti nel sistemaMemorie:RAM_512_MBmappata da E0000000h:FFFFFFFFh, 4 banchi da 128 MBEPROM_1_GB mappata da 00000000h:3FFFFFFFh, 4 banchi da 256 MBPorte di input, output e altri chip-selecte/o segnali:CS_INPUT_PORT_0mappato a 80000000hCS_INPUT_PORT_1mappato a 80000001hCS_OUTPUT_PORT_0mappato a 80000002hCS_OUTPUT_PORT_1mappato a 80000003hCS_PIC_SET_INTsmappato a 80000004hCS_PIC_READ_INTsmappato a 80000008hCS_PIC_READ_CODEmappato a 8000000Ch"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#6,6,"Segnali di decodifica di memorie, periferiche e segnali:CS_RAM_0 = BA31·BA30·BE0CS_RAM_1= BA31·BA30·BE1CS_RAM_2= BA31·BA30·BE2CS_RAM_3= BA31·BA30·BE3CS_INPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE0·IBF_0mappato a 80000000hCS_INPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE1·IBF_1mappato a 80000001h CS_OUTPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE2·OBF_0*mappato a 80000002h CS_OUTPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE3·OBF_1*mappato a80000003hCS_PIC_SET_INTs= BA31·BA30*·BA3*·BA2mappato a 80000004hCS_PIC_READ_INTs= BA31·BA30*·BA3·BA2*·MEMRDmappato a 80000008hCS_PIC_READ_CODE= BA31·BA30*·BA3·BA2·MEMRDmappato a 8000000ChCS_EPROM_0 = BA31*·BE0 CS_EPROM_1= BA31*·BE1CS_EPROM_2 = BA31*·BE2CS_EPROM_3 = BA31*·BE3"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#7,7,"INPUTPORT_0D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_0MEMRDUNITA’ESTERNA#0INT_IN_PORT_0BD[7..0]IBF_0Nelsistemasonopresentidueporteininput,collegateaibusdatiBD[7..0](INPUT_PORT_0)eBD[15..8](INPUT_PORT_1)
INPUTPORT_1D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_1MEMRDUNITA’ESTERNA#1INT_IN_PORT_1BD[15..8]IBF_1STB_1STB_0A_RESETRESET
A_RESETRESET"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#8,8,"OUTPUTPORT_0D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFA_RESETCS_OUTPUT_PORT_0MEMWRRESETUNITA’ESTERNA#2INT_OUT_PORT_0     BD[23..16]NelsistemasonopresentianchedueporteinoutputcollegateaibusdatiBD[23..16](OUTPUT_PORT_0)eBD[31..24](OUTPUT_PORT_1)
OUTPUTPORT_1D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFCS_OUTPUT_PORT_1MEMWRUNITA’ESTERNA#3INT_OUT_PORT_1     BD[31..24]ACK_1OBF_1ACK_0OBF_0
A_RESETRESET"
data_test\rootfolder\università\CalcolatoriElettronici\06_PIC.pdf#9,9,"RESETFFDDQA_RES10MEMWR*D0EN_INT_0AlfinediabilitareedisabilitareselettivamentegliinterruptsipossonoutilizzarequattroFFD.IquattrobitD[3..0]sonoconnessiaisegnaliBD[3..0]delbusdatieutilizzatipercondizionareognisingolainterruzionemedianteisegnaliEN_INT_0,EN_INT_1,EN_INT_2eEN_INT_3generatidalleretiseguenti:CS_PIC_SET_INTsEN_INT_0RESETFFDDQA_RES10MEMWR*D1EN_INT_1CS_PIC_SET_INTsEN_INT_1RESETFFDDQA_RES10MEMWR*D2EN_INT_2CS_PIC_SET_INTsEN_INT_2RESETFFDDQA_RES10MEMWR*D3EN_INT_3CS_PIC_SET_INTsEN_INT_3"
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#0,0,"DLX: implementazione sequenziale  Calcolatori Elettronici T Ingegneria Informatica 
"
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#1,1,"Datapath e Unità di Controllo  • La struttura di una CPU, come tutte le reti logiche sincrone che  elaborano dati, può essere strutturata in due blocchi: Unità di Controllo e Datapath  • La CPU, per funzionare, ha bisogno della memoria esterna su cui risiedono il programma e i dati 
reset interrupt ready 
CPU istruzioni Dati (in)  indirizzi 
Dati (out) U.d.C. Data Path clock memoria Rete logica CPU "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#10,10,"Estrazione “automatica” dei registri durante la fase di decode di una istruzione (qualsiasi)  I Codice  operativo  RS2/Rd RS1 Operando immediato di 16 bit J Codice  operativo  Offset di 26 bit (PC relative) R Codice  operativo  RS2 RS1 Rd Estensione al Cod. op (11 bit) 0 31 < A B 
Questi 5 + 5 bit  sono utilizzati per estrarre, preventivamente e ancora prima di conoscere che tipo  di istruzione che è stata letta dalla memoria, dal Register File due registri in A e B. Nel caso di  istruzione J non ci sono registri coinvolti e quindi saranno estratti bit corrispondenti all’offset. Nel  caso di istruzione I, in B potrebbe finire il valore del registro destinazione (e.g. in una LD o  operazione ALU (tipo I)). Infine: i 5 + 5 bit rappresentano gli indici (o presunti tali) ma non il valore dei due registri che è  contenuto nel Register File. "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#11,11,"Gli stati della fase di fetch  • In questa fase si deve verificare se è presente un interrupt (evento esterno asincrono che la CPU deve “servire” con apposito software); • se l’interrupt è presente e può essere servito (IEN = true) si esegue implicitamente l’istruzione di chiamata a procedura all’indirizzo 0, e si salva l’indirizzo di ritorno nell’apposito registro IAR; • se l’interrupt non è presente o le interruzioni non sono abilitate, si va a leggere in memoria la prossima istruzione da eseguire (il cui indirizzo è in PC) MAR ← PC Dall’ultimo stato  dell’istruzione precedente  IAR:  Interrupt  Address  Register  IAR ← PC PC ← 0 IEN ← 0 IEN:  Interrupt  Enable  Flag  (int and IEN) = 1 (int and IEN) = 0 IR ← M(MAR) Alla fase di decodifica Ready = 1 Ready = 0 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#12,12,Si modifica il  DATAPATH in  maniera da poter  indirizzare  la memoria dal PC.  Meno stati ma maggiore complessità  Data transfer ALU Set Jump Branch Ready ? INSTRUCTION FETCH INSTRUCTION  DECODE* Tutte le istruzioni impiegano un clock in meno per essere eseguite !  Ma potenzialmente aggiore lentezza  -> minore freq. clock Il diagramma  degli  stati del  controller  PC <- PC +4  A <- RS1 B <- RS2  IR <- M [PC] 
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#13,13,"Ready ? IR <- M [PC] 
 MAR <- A + (IR15)16 ## IR15..0 LOAD MDR <- M[MAR]  LB Ready ? C <- (MDR7)24 ## MDR7..0 RD <- C   PC <- PC +4  A <- RS1  B <- RS2  Controllo per  l’istruzione LB  (LOAD BYTE) ALU ALU Parte comune 
RS2 è da intendersi come registro di destinazione (A) = (RS1) Estensione segno "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#14,14,"Estensione del segno   (IR15)16 ## IR15..0 0    15      31 IR 
31 30…………17  16 BUS S1 o S0 Da UdC 
15-0 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#15,15,"MDR <- M[MAR]
MDR <- B.C <- MDRRD <- C M[MAR] <-MDRINIT STORE 
LB LBU LH LHU LW Controllo per  le istruzioni di  DATA  TRANSFER  LB  LBU LH LHU LW STORE  Byte -> SB Half Word –> SH Word -> SW  C <-(MDR7)24 ## MDR7..0C <- (0)24 ## MDR7..0C <- (MDR15)16 ## MDR15..0 C <-(0)16 ## MDR15..0MAR <- A + (IR15)16 ## IR15..0 LOAD 
Mancano nell’esempio  SH e SB (sempre unsigned)  che corrispondono a attivazione degli specifici WE delle memorie e “traslatori” dei bytes del registro MDR.  Come si realizzerebbero ?  NB: in lettura la parte meno  significativa del dato viene letta  sempre allineata al registro MDR per permettere il filling SW Il contenuto di A come unsigned Ready ? 
Ready ? "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#16,16,"17  17  Trasferimenti BYTE, HW  •  I trasferimenti di bytes sono SEMPRE considerati allineati •  I trasferimenti di HW debbono avvenire a indirizzi multipli di 2 •  I trasferimenti di Word debbono sempre avvenire a indirizzi multipli di 4 •  In caso di disallineamento: fault •  Nel caso di store di dati di dimensione inferiore alla word NON si ha estensione del segno •  La lettura/scrittura di bytes e HW (a causa del reciproco disallineamento fra i registri e la memoria) implica che fra i registri e la memoria siano interposti dei mux/demux (realizzati con tristate) Registro MDR 
Memoria Come sono attivati i WE delle memorie ? Progettare la rete  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#17,17,"Trasferimenti BYTE, HW  MDR 
Memoria 31 0 Mux Demux I MUX 23-16 e 31-24 hanno come ingresso anche il bit 7 del byte 7-0 della memoria (LB) e il bit 15 del byte 15-8 della memoria (LH)  Ad esempio in una LB il MUX 7-0 si collega direttamente alla memoria mentre i MUX 15-8, 23-16 e 31-24 si collegano al bit 7 del MUX 7-0 proveniente dalla memoria.  In una SH a indirizzo multiplo di 2 e non di 4  il DEMUX 7-0  dal MDR si collega alla memoria 23-16 e il DEMUX 15-8 alla memoria 31-24. Gli altri due bytes della memoria rimangono invariati Mux Demux “0” Bit più signif. byte precedenti Solo in lettura Trasferimento  “unsigned” 24 23 16 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#18,18,"C <- A + TempC <- A xor TempC <- A - Temp C <- A and TempC <- A or TempINIT RD <- CRegistro (formato R) Immediato (formato I) 
ADD AND SUB XOR OR   Temp <- BTemp <- (IR15)16 ## IR15..0Esempi di istruzioni  ALU  Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP  Lo stesso schema si può usare per gli shift etc.  Il contenuto dei registri come signed se op aritmetica "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#19,19," RD <- C A = Temp
C <- 1SEQ SLT SGE SNE SGT SLE YES NO  Il risultato del test è un input per il controller ! Registro (formato R) Immediato (formato I) Controllo per  le istruzioni  di SET  (confronto) ex. SLT R1,R2,R3  
INIT Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP   Temp<- BTemp <- (IR15)16 ## IR15..0 A < Temp A >= Temp A <= Temp A > Temp A! = TempC <- 0I micropassi sono eseguiti  in ALU ma il risultato  NON è memorizzato in un registro: i flag sono utilizzati dalla ALU per impostare (almeno) il bit 0 del registro C  Il contenuto dei registri come signed "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#2,2,"•  Datapath: contiene tutte le unità di elaborazione ed  i registri necessari per l’esecuzione delle istruzioni  della CPU. Ogni istruzione appartenente all’ISA è  eseguita mediante una successione di operazioni  elementari, dette micro-operazioni •  Micro-operazione: operazione eseguita all’interno  del DATAPATH in un ciclo di clock ( e s e m p i :  trasferimento di un dato da un registro ad un altro  registro, elaborazione ALU) •  Unità di Controllo: è una RSS che in ogni ciclo di  clock invia un ben preciso insieme di segnali di  controllo al DATAPATH al fine di specificare  l’esecuzione di una determinata micro-operazione  Datapath e Unità di Controllo  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#20,20,"INIT  C <- PCJALR JAL JMP JR JALR 
JALR JR JAL 
JMP JAL JALR  JAL Controllo per  le istruzioni  di JUMP  (IR15)16 ## IR15..0  C <- PC
PC <-  PC + (IR25)6 ## IR25..0 PC <- A R31 <- CPer il salvataggio in R31 
Istruzione  formato I  Istruzione  formato J  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#21,21,"INIT A = 0 BRANCH 
YES YES NO NO BEQZ BNEZ Controllo per  le istruzioni  di BRANCH  A! = 0 PC <-  PC + (IR15)16 ## IR15..0 Ex. BNEQZ R5, 100 Il controllo se 0 (o !=0) è fatto sull’intero registro A (a 32 bit) e non solo sul bit meno significativo "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#22,22,"Numero di clock necessari per eseguire le istruzioni  Istruzione Cicli Wait Totale Load 6 2 8 Store 5 2 7 ALU 5 1 6 Set 6 1 7 Jump 3 1 4 Jump and link 5 1 6 Branch (taken) 4 1 5 Branch (not taken) 3 1 4 CPICPIN numero totale di istruzioni iin=i = 1 ∑(*)Esempio su DLX  LOAD: 21%, STORE: 12%, ALU: 37%, SET: 6%, JUMP: 2% BRANCH (taken): 12%, BRANCH (not-taken): 11%    CPI = 6.3 "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#23,23,"Controllo cablato (“hardwired”) Segnali di  controllo 
INSTRUCTION REGISTER (IR) 40 Opcode +  OpCode Extension   6 Datapath Stato presente Rete combinatoria che  genera uscite e stato futuro Int e ready 2 6+11 3 Stato futuro 228 righe Rs1, Rs2, Rd - Indici di Rs1, Rs2 e Rd provengono da IR - IR25..0 sono portati ai bus S1 ed S2 del data path attraverso due buffer tristate IR25..0 U.d.C. 
32 bit dalla  memoria - U.d.C. genera anche i segnali di comando per la memoria (MEMRD e  MEMWR) Flag "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#24,24,"I passi dell’esecuzione delle istruzioni  Nel DLX l’esecuzione di tutte le istruzioni può essere scomposta in 5 passi, ciascuno eseguito in uno o più cicli di clock.   Tali passi sono detti:  1) FETCH:   l’istruzione viene prelevata dalla memoria e posta in IR.  2) DECODE: l’istruzione in IR viene decodificata e vengono prelevati gli   operandi sorgente dal Register File.   3) EXECUTE: elaborazione aritmetica o logica mediante la ALU.   4) MEMORY: accesso alla memoria e, nel caso di BRANCH aggiornamento   del PC (“branch completion”).   5) WRITE-BACK:   scrittura sul Register File. "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#25,25,"Le micro-operazioni eseguite  in ciascun passo  1) FETCH MAR   ß PC ;   ß  M[MAR]; 2) DECODE A  ß RS1, B  ß RS2,  PC  ß PC+4 IR   "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#26,26,"Le micro-operazioni eseguite  in ciascun passo  MEMORIA: MDR   ß   B;        ALU:   BRANCH: 3) EXECUTE MAR      A + (IR15)16 ## IR15..0 ; ß C  <- A op B (oppure A op (IR15)16 ## IR15..0) ; Temp       PC + (IR15)16 ## IR15..0) ; (utilizza ALU, S1, S2, dest: qui non si sa       ancora se si deve saltare) ß (utilizzano ALU, S1, S2, dest)  C <-  sign( A op B (oppure A op (IR15)16 ## IR15..0));  se SCn (NB: serve nelle Store  ove RD=RS2 operazione non significativa nelle LOAD)  J e JAL  Temp       PC + (IR25)6 ## IR25..0) ;  ß JR e JALR Temp       A;  ß "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#27,27,"Le micro-operazioni eseguite  in ciascun passo  4) MEMORY MDR   ß M[MAR];  (LOAD) ß  MDR;    (STORE)  BRANCH: M[MAR]  If (Cond)      PC       Temp; ß Memoria: 
[A] è il registro che condiziona il salto (Cond) ; JAL e JALR: C       PC; ß "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#28,28,"5) WRITE-BACK RD  ß C ; C ß MDR; (se è una LOAD – due micropassi)) Le micro-operazioni eseguite  in ciascun passo  
PC       Temp; ß  istruzioni J, JR, JAL, JALR  istruzioni diverse da J, JR, JAL, JALR RD  ß C ; "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#3,3,"Register file C A B Struttura del DLX (esecuzione sequenziale)  
TEMP IAR PC S1 S2 dest alu 
CPU Memoria dati in scrittura dati/istruzioni in lettura Indirizzi Instruction register C O N T R O L U N I T 
fetch MDR MAR execute Parallelismo dell’architettura: 32 bit (bus, alu e registri hanno parallelismo 32) I segnali di controllo non sono riportati !  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#4,4,"I registri del DLX (tutti a 32 bit)  • Register f i l e: 32 General Purpose Registers R 0 … . R 3 1  con  R0=0 • IAR: Interrupt Address Register –  D e p o s i t o  dell’indirizzo di ritorno in caso di interruzione • PC: Program Counter • MAR: Memory Address Register –  C o n t i e n e  l’indirizzo  del dato da scrivere o leggere in memoria • IR: Instruction Register –  C o n t i e n e  l’istruzione  attualmente in esecuzione • TEMP: Temporary Register –  R e g i s t r o  d i  d e p o s i t o  temporaneo di risultati  • MDR: Memory Data Register –  R e g i s t r o  d i  t r a n s i t o  temporaneo dei dati da e per la memoria • A e B: Registri di uscita dal Register File A parte il Register File questi registri NON sono accessibili  al programmatore. In alcuni casi istruzioni speciali per  accedere ad alcuni (e.g., IAR) "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#5,5,"Funzioni della ALU       Dest (uscite) – 4 bit di comando  S1 + S2 S1 – S2 S1 and S2 S1 or S2 S1 exor S2 Shift S1 a sinistra di S2 posizioni Shift S1 a destra di S2 posizioni Shfit S1 aritmetico a destra di S2 posizioni S1 S2 0 1   Flag di uscita  Zero Segno negativo Carry 
• La ALU è una rete PURAMENTE combinatoria • Non esiste nel DLX un registro di flag "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#6,6,"Trasferimento dati sul datapath • I bus S1 ed S2 sono multiplexati (tri-state) con parallelismo 32 bit. • I registri campionano sul fronte positivo del clock, hanno due porte di uscita O1 e O2 per i due bus (o i registri A e B) e dispongono di tre ingressi di controllo:  – un ingresso di Write Enable (WE*)  ed  uno di Output Enable per ogni porta di uscita, una per ogni bus S1 e S2 (OE1* e OE2*). • Al fine di valutare la massima frequenza a cui è possibile far funzionare il datapath è importante conoscere le seguenti temporizzazioni: – TC (max) : ritardo max tra il fronte positivo del clock e l’istante in cui i  segnali di controllo generati dall’unità di controllo sono validi; – TOE (max): ritardo max tra l’arrivo del segnale OE e l’istante in cui i dati del registro sono disponibili sul bus; – TALU (max): ritardo massimo introdotto dalla ALU; – TSU (min)  : tempo di set-up minimo dei registri (requisito minimo per il corretto campionamento da parte dei registri).  • La massima frequenza di funzionamento del data path si calcola come segue:      fCK(max) = 1/TCK TCK  > TC (max) + TOE (max) + TALU (max) + TSU (min) "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#7,7,"Esempio : esecuzione della microistruzione  Rin ← Rout  S2 
alu WE*  OE1* OE2* WE* OE1* OE2* S1 Rout Rin dest clock O2 O1 O2 O1 I I i1 i2 u = i2 WERin* OE2Rout* I segnali in blu (segnali di controllo) provengono dall’Unità di Controllo 
I segnali di controllo in grassetto sono attivi nel ciclo di clock in cui il micro-step Rin ← Rout viene eseguito  (e.g. TEMP) (e.g. MAR) Clock sempre collegato:  write enable !  "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#8,8,"Il progetto dell’Unità di Controllo  • Una volta definito il Set di Istruzioni e progettato il DATAPATH, il passo successivo del progetto di una CPU è il progetto dell’Unità di Controllo  (CONTROLLER). • Il CONTROLLER è una RSS: il suo funzionamento può essere specificato tramite un diagramma degli stati.  •  Il CONTROLLER (come tutte le RSS) permane in un determinato stato per un ciclo di clock e transita (può transitare) da uno stato all’altro in corrispondenza degli istanti di sincronismo (fronti del clock).  •  Ad ogni stato corrisponde quindi un ciclo di clock.  Le micro-operazioni che devono essere eseguite in quel ciclo di clock sono specificate (in linguaggio RTL) nel diagramma degli stati che descrive il funzionamento del CONTROLLER all’interno degli stati. •  A partire dalla descrizione RTL si sintetizzano poi i segnali di controllo che  devono essere inviati al DATAPATH per eseguire le operazioni elementari  associate ad ogni stato.   "
data_test\rootfolder\università\CalcolatoriElettronici\07_DLX_sequenziale.pdf#9,9,"Il diagramma  degli  stati del  controller  Data transfer ALU Set Jump Branch Ready ?  IR <- M [MAR] INSTRUCTION  FETCH INSTRUCTION  DECODE* MAR <- PC  
 PC<- PC+4 A <- RS1 B <- RS2 Oltre a decodificare l’istruzione si prelevano  gli operandi sorgente dal RF (anche se non utilizzati !) e si incrementa il PC.  Qui non si sa ancora quale sia l’istruzione ma il trasferimento ai registri è fatto  comunque !! N.B. I primi tre stadi sono comuni a tutte  le istruzioni  "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#0,0,"ISA DLX: implementazione pipelinedCalcolatori Elettronici TIngegneria Informatica
"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#1,1,"Principio del PipeliningIl pipeliningè oggi la principale tecnica di base impiegata per rendere veloceuna CPU . Lidea alla base del pipeliningè generale, e trova applicazione in molteplici settori dellindustria (linee di produzione, oleodotti …)Un sistema, S, deve eseguire Nvolte unattività A: A1 , A2 , A3…ANSR1 , R2 , R3…RNLatency: tempo che intercorre fra linizio ed il completamentodellattività A(TA).Throughput: frequenza con cui vengono  completate le attività."
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#10,10,"Requisiti per l’implementazione in pipeline•Ogni stadio deve essere attivo in ogni ciclo di clock. •Enecessario incrementare il PC in IF (invece che in ID).•Enecessario introdurre un ADDER (PC <--PC+4 –PC <-PC+1) nello stadio IF.•Sono necessari due MDR (che chiameremo LMDR e SMDR) per gestire il caso di una LOAD seguita immediatamente da una STORE (WB-MEM sovrapposti –sovrapposizione di due dati in attesa di essere scritti, uno in memoria e l’altro nel RF). •In ogni ciclo di clock devono poter essere eseguiti 2 accessi alla memoria (IF, MEM): InstructionMemory (IM) e Data Memory (DM) ->  Architettura ‘Harvard’•Il clock della CPU è determinato dallo stadio più lento: IM, DM devono essere delle memorie cache(on-chip) •I Pipeline Registerstrasportano sia dati sia informazioni di controllo (l’unità di controllo è ‘distribuita’  fra gli stadi della pipeline)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#11,11,"GerarchiadellamemoriaL0 (registri CPU)L1L2L3Memoria (DDR)
DiscoCosto/ByteTempo di accessoH
LL
HCPU "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#12,12,"13MemoriecacheCPUCacheMemoria (DDR)Una(opiùlivelli)memoriavelocemadiridottedimensioni,iecache,ingradodisfruttareilprincipiodilocalitàfannoapparirela(lenta)memoriaDDRmoltopiùveloce"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#13,13,"14
Area di silicio occupata da cache L1,L2,L3 in un Intel Core i5Fonte: https://thecodeartist.blogspot.com/2011/12/why-readmostly-does-not-work-as-it.html"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#14,14,"IFIDEXMEMWBDatapath in Pipeline del DLX
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBEstensionedel segnoNumero reg. dest.nel caso di LOADe ALU instr.JL (il PC in   R31)JLRPer il calcolo del nuovo PC nei salti
Per le operazioni con immediatiRDDRS1RS2
Numero del registro di destinazioneDatiPCIn realtà è un contatore programmabile  visto che i due bit meno significativi sono a 0se saltoContiene anche i circuiti di swapPer SCn(anche <0 e >0)[agisce sulluscita]
=0?per BranchDurante JMP e BRANCH taken in IF/ID entra PC… Pazienza, sarà eliminata l’istruzione mediante NOP"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#15,15,"Stadiodi Fetch con contatore1/2
Counter 30 bitENU[29..0]ClockSTALL*LDJUMPPC[31..2]I[29..0]JUMP_ADDRESS[31..2]
Sempre con riferimento allo stesso schema del DLX. Il segnale JUMPcodifica se il DLX deve saltare alla destinazione specificata daJUMP_ADDRESS[31.2]. Entrambi i segnali sono inviati dallo stadio MEM.Il segnale STALL, è generato dalla Unità di Controllo quando lostadio di IF deve essere bloccato. PC (to memory)ConriferimentoalprimoschemadelDLXpipelinedstudiatoduranteilcorso(maconsiderazionianaloghesiapplicanoallealtreversionidelDLX),lareteseguenteconsentedisostituireloschemabasatosuregistroemultiplexerconuncontatorea30bit(iduebitmenosignificatividell’indirizzosonosuperfluiperchéilDLXesegueilfetchsempreaindirizziallineati).PC +1 (to IF/ID)Come?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#16,16,"REGISTER30 bitStadio di Fetch con contatore 2/2Un’osservazione: come possiamo generare PC + 1 per lo stadio IF/ID(quando viene eseguito il fetch a PC è necessario fare entrare nellapipeline (stadio IF/ID) PC +1 ?
CKD[29..0]OUT[29..0]+1PC +1 (to IF/ID)
PC  (to memory)Stato presenteStato futuro
PC[31..2]"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#17,17,"Sezione IDIRRFSERDDRS1RS2IF/IDID/EX
IR25-21IR20-16
Numero registro destinaz.(dallo stadio WB) Dati (dallo stadio WB)(31-16) Immed./Branch(31-26)  JumpIR15IR25LBSWIR31-26 (Codop)IR15-0    (Offset/Immediato/Branch/Load -Reg. dest.)IR25-16   (J; JL))
PC31-0    (JAL)PCAB26 (J e JL)
61632323232
32Info che viaggiacon listruzioneIR10-00 (ExtCO)DEC
Estensione segno"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#18,18,"Datapath in Pipeline del DLX ADD4MUX
DMALUMUXMUXIMRFSEPCDEC
MUXIF/IDID/EXEX/MEMMEM/WBIR1ABIR2PC2CONDX
X: ALUOUPUT/DMAR/BTASMDRYLMDR
Y: ALUOUPUT1IFIDEX MEMWBPC1PC3PC4IndirizzoDatiIR3IR4n.  registro di destinazionePer SCn(anche <0 e >0)[agisce sulluscita]
=0?=0?per BranchJLJLR(il PC in R31)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#19,19,"Esecuzione in pipeline di istruzione ALU
X : ALUOUTPUT(in EX/MEM),  Y : ALUOUTPUT1NB in questa come nelle altre istruzioni RD (RS2) è trasferita fino allo stadio WBIFIDEXMEMY <-X (parcheggioin attesa di WB)WBRD <-YIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;X <-A op BoppureX <-A op (IR215)16##IR215..0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]N.B. al passare degli stadi IRperde i bit che non servono più in tutte le istruzioni. Da uno stadio al successivo vengono mantenuti i bit che servono qualunque sia listruzione"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#2,2,"Motore: 2000 ccTipo:BenzinaColore:Rosso
"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#20,20,Esecuzione in pipeline di istruzione MEMIFIDEXMEMLMDR <-M[MAR]  (LOAD)oppureM[MAR] <-SMDR  (STORE)WBRD <-LMDR   (LOAD)  [ext. Segno]IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;MAR <-A op (IR215)16##IR215..0SMDR <-B[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2[IR4  <.-IR3]
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#21,21,"Esecuzione in pipeline di istruzione BRANCH 
X : BTA (BRANCH TARGET ADDRESS)IFIDEXMEMif (Cond) PC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-PC2 op (IR15)16##IR15..0Cond <-A op 0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3Il test avviene sul valore del registro"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#22,22,"Esecuzione in pipeline di unistruzione JRIDMEMWBIFIDEXMEMPC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-A [PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]
Come sarebbe la sequenza degli stati per una J ?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#23,23,"Esecuzione in pipeline di istruzione JL  o JLRIDIFIDEXMEMPC <-X ; PC4<-PC3WBR31 <-PC4IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;PC3 <-PC2X <-A (Se JLR)     X <-PC2 + (IR25)6##IR25..0(Se JL)
NB: La scrittura in R31 NON può essere anticipata perché potrebbe sovrapporsi ad altra scrittura di registro Decod. in tutti gli stadi[IR4 <-IR3][IR3  <.-IR2]
Evidenziati perché in questo caso utilizzati"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#24,24,"25Qual sarebbe la sequenza nel caso di SCN  (ex SLT R1,R2,R3) ?IDIFIDEXMEMWBIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;???"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#25,25,"Alee nelle Pipeline•AleeStrutturali-Unarisorsaècondivisafraduestadidellapipeline:leistruzionichesitrovanocorrentementeintalistadinonpossonoessereeseguitesimultaneamente.•AleediDato–Sonodovuteadipendenzefraleistruzioni.Adesempiounaistruzionecheleggeunregistroscrittodaunistruzioneprecedente(RAW).•AleediControllo–Leistruzionicheseguonounbranchdipendonodalrisultatodelbranch(taken/nottaken).SiverificaunasituazionediAlea(Hazard)quandoinundeterminatociclodiclockunistruzionepresenteinunostadiodellapipelinenonpuòessereeseguitainquelclock.
Listruzionechenonpuòessereeseguitavienebloccata(stallodellapipeline),insiemeatuttequellechelaseguono,mentreleistruzionichelaprecedonoavanzanonormalmente(cosìdarimuoverelacausadellalea)."
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#26,26,"Clk 6Clk 7Clk 8Alee e Stalli
IDIFIDEXMEMWBIi-3Ii-2Ii-1IiIDEXMEMIDEXIDIFIFIFIFIi+1Clk 1Clk 2Clk 3Clk 4Clk 5WBClk 9Clk 10Clk 11Clk 12WBWBT5=  8 * CLK = (5 + 3) * CLKT5= 5 * (1 + 3/5 ) * CLKCPI  idealeStalli per istruzioneTN= N *  1  * CLKTN= N *  (1 + S) * CLKCPI  effettivoSSSSSIFSMEMWBStallo: blocco del clock dello stadio e di tutti quelli precedentie propagazione progressiva agli stadi successiviEffetto–adesempio-diunaaleadidato:selistruzioneIinecessitadiundatoprodottodallaistruzioneIi-1deveaspettarefinoalWBdellaIi-1"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#27,27,"IFIDEXMEMWBStalli nel salto (1/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoal campionamento della  verifica della condizione di salto sono inserite 3 NOP al posto dei codici operativi provenienti dalla memoria"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#28,28,"IFIDEXMEMWBStalli nel salto (2/3)
ADD4MUX
DATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOPNOP forzate per salto
Al primo fronte positivo del clock successivoalla verifica della condizione di salto sono inserite 2 NOP al posto dei codici operativi provenienti dalla memoriaNB In questo caso la condizione di salto e il nuovo PC sono presentatial MUX nello stesso periodo di produzione  della condizione"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#29,29,"IFIDEXMEMWBStalli nel salto (3/3)ADD4
DATAMEMALUMUXMUX=0?INSTRMEMRFSEDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2
DatiPCse salto
=0?NOPNOP per salto
Al primo fronte positivo del clock successivoalla produzione della verifica della condizione di salto e inserita una NOP al posto del codice operativo proveniente dalla stadio IF/IDNB In questo caso la condizione di salto e il nuovo PC agisconosul MUX nello stesso periodo di produzione  della condizione
PCMUX"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#3,3,"Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
Motore: 2000 ccTipo:BenzinaColore:Rosso
t"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#30,30,"ForwardingADD  R3, R1, R4Clk 6Clk 7Clk 8MEMWBIFIDEXMEMWBIDEXMEMIDEXIDIFIFIFIFClk 1Clk 2Clk 3Clk 4Clk 5WBEXMEMIDEXClk 9MEMWBWBIDIDIDIl forwardingconsente di eliminare quasi tutte le alee di tipo RAW dellapipeline del DLX senza stallarela pipeline. (NB: nel DLX si alteranoi registri  soloin WB)SUB  R7, R3, R5 aleaOR  R1, R3, R5 aleaLW  R6, 100 (R3) aleaAND R9, R5, R3  no aleaAnche qui il dato non è ancora in RF per essere estratto in ID !"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#31,31,"Implementazione del ForwardingFU
EX/MEMMUXMEM/WBALUMUXID/EXMUXMUXRS1/RS2CODOPRD2/CodOpRD1 (registro di destinazione/CodOpConfronto fraRS1, RS2 e RD1, RD2 e i cod. Op.RFMUX
Spesso realizzato allinterno del RFOppure SPLIT-CYCLE(v. dopo)scrittura prima di lettura
Permette di anticipareil registro su ID/EXControllo MUX: codice operativo IF/ID e confronto RD con RS1 e RS2 IF/IDFU –> Forwarding Unit"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#32,32,"33Split-cycleT
In questo semiperiodo si scriveil registroIn questo semiperiodo si leggeil registro"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#33,33,"34Alea di dato dovuta alle istruzioni di LOAD
N.B.ildatorichiestodallaADDèpresentesoloallafinediMEM.Laleanonpuòessereeliminataconilforwarding(amenodinonaprireunaulteriorediingressoaimuxdellaALUdallamemoria–ritardi!)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7LW    R1,32(R6)MEMWBIFIDEXMEMIFIDEXIFIDIFIDEX
LW     R1,32(R6)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7IFIDEXMEMWBIFIDSEXMEMIFSIDEXSIFIDEnecessario stallare lapipelineDi fatto non viene generato il clock. Il blocco di un  clock si propaga lungo  la pipeline uno stadio alla volta. Dalla fine di questo stadio in poi normale forwarding"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#34,34,"Delayed loadIn diverse CPU RISC lalea associata alla LOAD non è gestita in HW stallando la pipeline ma è gestita via SW dal compilatore (delayed load): Istruzione LOADdelay slotIstruzione SuccessivaIl compilatore cercadi riempire il delay-slotcon unistruzione utile(caso peggiore: NOP).LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#35,35,"36Alee di Controllo
BEQZ R4, 200PCBEQZ R4, 200PC+4SUB  R7, R3, R5PC+8OR   R1, R3, R5PC+12LW   R6, 100 (R8)PC+4+200AND R9, R5, R3(BTA)Next InstructionAddressR4 = 0 :    Branch Target Address(taken)R4 ¹0 :   PC+4(not taken)Clk 6Clk 7Clk 8IFIDEXMEMWBIDIDClk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFWBIDIDIDIFEXWBIDMEMFetch connuovo PCNuovo valore PC calcolato (Aluout)SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Nuovo valore in PC (un clock dopo)  
IDIFEXWBIDMEM"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#36,36,"ADD4
IMRFSEPCDECInstruction FetchInstruction DecodeExecuteMemoryWriteBack
IF/IDID/EXALUMUXEX/MEMMUXMUXDatapath in Pipeline del DLX  (caso 1/3) -(Branch o JMP)BEQZ R4, 200
MUXDMMEM/WBNel momento in cui il nuovo PC agisce sulla IM treistruzioni hanno eseguito i primi trestadi (fino a EXincluso)=0?=0?"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#37,37,"Gestione delle Alee di ControlloBEQZ R4,200Clk 6Clk 7Clk 8IFIDEXMEMWBClk 1Clk 2Clk 3Clk 4Clk 5SSIFSFetch at new PC•Always Stall (blocco di tre clock che si propaga)
Hyp.:  Freq.Branch = 25 %CPI = (1 + S) = ( 1 + 3 * 0.25) = 1.75•Predict Not TakenIFIDEXMEMWBIDIDIDBEQZ R4, 200SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Clk 6Clk 7Clk 8Clk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFIFWBEXWBIDIDIDMEMBranch CompletionFlush:diventanoNOPNOP           NOP           NOP           IF–maquilistruzioneprecedentenonancoradecodificataSIFIFIDSSituazione realeIF ripetuto PC <-PC -4Qui il nuovo valoreè campionato dal PC
Nessun danno: nessuna istruzione ha effettuato WB !"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#38,38,"Delayed branchSimilmentealcasodellaLOAD,indiverseCPUditipoRISClaleaassociataalleistruzionidiBRANCHègestitaviaSWdalcompilatore(delayedbranch):Istruzione BRANCHdelay slotIstruzione SuccessivaIl compilatore cercadi riempire i delay-slotcon istruzioni utili(caso peggiore: NOP).delay slotdelay slot"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#39,39,"Delayed branch/jumpAdd  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21Sne   R1, R8, R9; condizione di branchBr     R1, +100Sne   R1, R8, R9; condizione di branchBr     R1, +100Add  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21CompilatoOriginale
Eseguite inentrambi i casiOvviamente in questo gruppo  non debbono esserci salti !!!!Al posto di una o più istruzioni posposteil compilatore mette delle NOP in caso non riesca a trovarne di adatte"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#4,4,"•Latenza: 5 fasi(clock)•Throughput: a regime, dopo5 fasi(clock), un’automobileper fase(clock)"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#40,40,Gestione delle Alee di Controllo con BTBDynamic Prediction: Branch Target Buffer -> nessuno stallo (quasi)T/NTTAGSPredicted PCPC=HIT:  Fetch a PC  predettoMISS: Fetch a  PC + 4Predizione Corretta :    0 stalli Predizione Errata :       da 1 a 3 stalli  (fetch corretto in  ID o EX   v. precedentemente)N.B.  Qui il branch è individuato durante il periodo del clock IF che carica IR1 in IF/ID
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#41,41,"Buffer di predizione: caso più semplice un bit che  indica cosa è successo l'ultima volta.
In presenza di preponderanza di un caso quando si verifica il caso opposto si hannodueerrorisuccessivi.Loop1Loop2Quando esce da loop2 sbaglia (predetto takenma in realtà untaken) ma sbagli ancora quando predice untakenrientrando nuovamente in loop2 a causa di  loop1 "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#42,42,"Normalmente duebits.TAKENTAKEN
UNTAKENUNTAKENTAKENUNTAKENTAKENUNTAKENTAKENTAKEN
UNTAKENUNTAKEN"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#43,43,"Esempio, molto frequente, di loop annidato:for (i=0; i<5000; i++)for (j=0; j<1000; j++}{x[i,j] = i*j + i + j;...... }"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#5,5,"Principio del Pipelining1) Sistema Sequenziale A2A3tANA1TALatency(tempo di esecuzione di una istruzione)= TAThroughput=1TA2) Sistema in Pipeline
SAP1P2P3P4tS1S2S3S4Si: pipeline stage"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#6,6,"Principio del PipeliningP1TPP2P1A2P2P3P1A3tA1
SS1S2S3S4P4P3P2P1A4P4P3P4P2P3P4AnLatency(2)= 4 *TP = TAThroughput(2)@1TP4TA==4 * Throughput(1)TP : pipeline cycle "
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#7,7,"Pipeliningin una CPU (DLX)Attività:    A1 , A2 , A3…ANIstruzioni:    I1 , I2 , I3…INIEXIDtMEMWBIF
CPI=1 (idealmente !)IF/IDID/EXEX/MEMMEM/WBCPU (datapath)IFIDEXMEMWBPipeline CycleClock CycleRitardo dello stadio piùlentoRegistri(Pipeline)Registers)ReticombinatorieN.B. architettura TOTALMENTEdiversa !!!!!"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#8,8,"Pipeline del DLXInstr iInstr i+1Instr i+2Instr i+3Instr i+4IFIDEXMEMWB
Tclk=  Td  +  TP+  TsuClock CycleCPI (ideale)  = 1
Overhead introdotto dai Pipeline Registers:Ritardo registroa monteSet-up registro a valleRitardo stadio combinatorio più lentoIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBt"
data_test\rootfolder\università\CalcolatoriElettronici\08_DLX_pipelined.pdf#9,9,DDRCTp
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#0,0,"Machine Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning: Introduzione
1"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#1,1,"Sommario
Informazioni sul corso  
Programma, testi consigliati, precondizioni  
Software tools  
Cos'è il deep learning  
Representation learning  
Autoencoders  
Factors of variation  
Approcci di IA ed evoluzione delle architetture  
Curse dimensionality  
Local constancy & smoothness regularization  
Libreria D2L"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#10,10,"Google Colaboratory (o Colab)  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#11,11,"Google Colaboratory (o Colab)  
GPUs includes Tesla 
 P100
  (used in Colab), Tesla 
 V100
  (equipped in 
Amazon EC2 P3 instance), and Tesla 
 T4
 (equipped in Amazon EC2 
G4 instance). 
 TPUs
  are tensor processing units developed by Google 
to accelerate operations on a Tensor
 ﬂ
ow Graph. Each TPU packs up 
to 180 tera
 ﬂ
ops of 
 ﬂ
oating-point performance and 64 GB of high-
bandwidth memory onto a single board.
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#12,12,"Cos'è il Deep Learning
Il 
machine learning
  riguarda tecnologie capaci di acquisire conoscenza 
relativamente all'ambiente di interesse allo scopo di risolvere problemi in 
modo automatizzato, cioè senza l'intervento dell'utente.  
Per problemi complessi occorre rappresentare la conoscenza come 
concetti su vari livelli di astrazione, creando dipendenze tra gli stessi, in 
modo simile a come avviene nella mente umana.  
Da queste strutture deriva il termine 
 deep learning
 . 
Storicamente i computer sono stati impiegati per rappresentare conoscenza 
formale (es. regole per giocare a scacchi) su cui implementare meccanismi 
di 
reasoning
  (es. regole logiche) mentre è stato più dif
 ﬁ
cile rappresentare la 
conoscenza informale.  
Esempio: Cyc inference engine e ""Fred shaving in the morning""
13"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#13,13,"Representation learning (1)
Successivamente sono state introdotte tecniche di machine learning per 
acquisire la conoscenza (
 know-how
 ) estraendo 
 patterns
  dai dati in modo 
automatico, es. logistic regression e naive Bayes.  
Le prestazioni di tali approcci dipendono dalla scelta con cui i dati sono 
rappresentati. È importanti scegliere le informazioni più rilevanti (
 features
 ) 
per il task che si intende risolvere (approccio 
 hand-designed
 ). 
LXI + XCIX = ?  
Per alcuni task de
 ﬁ
nire una rappresentazione dei task è arduo.  
Es. identi
 ﬁ
care un auto potrebbe ridursi al task di riconoscere le ruote; 
come puoi farlo a partire da una rappresentazione a pixel?  
A differenza del hand-designed, il 
 representation learning
  introduce un 
sotto-task nel processo di ML che mira a riconoscere le feature più rilevanti 
in modo automatico. 
14"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#14,14,"Representation learning (2)
Identi
 ﬁ
care le features in modo automatico garantisce vantaggi:  
L'approccio hand-designed è lungo e richiede risorse  
Si può facilmente adattare l'addestramento a nuovi tasks
15"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#15,15,"Autoencoders
Gli 
autoencoders
  sono composti da un 
 encoder
  e un 
 decoder
 . Il primo 
converte l'input in una rappresentazione compatta, cioè con 
dimensionalità ridotta,, il decoder mira a ricostruire l'input originale da tale 
rappresentazione.  
L'addestramento degli autoencoders crea uno 
 spazio 
 che mira a 
rappresentare solo le features salienti necessarie per identi
 ﬁ
care una certa 
istanza, tralasciando informazioni non utili.  
Nel corso vedremo diversi tipi di autoencoders. Le 
 Generative Adversarial 
Network (GAN)
  impiegano tali tecnologie.
16"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#16,16,"Factors of variation
Le features identi
 ﬁ
cate con un approccio hand-designed, oppure 
riconosciute in modo automatico durante il learning, devono saper 
distinguere i 
 fattori di variazione
 . 
Sono spesso considerati degli elementi astratti (non misurabili) che 
in
ﬂ
uenzano il modo in cui le istanze vengono viste dagli approcci di ML. 
Se identi
 ﬁ
cati ci permettono di capire meglio la grande variabilità di 
istanze in certi domini.  
Ad esempio, età, sesso, un certo accento possono in
 ﬂ
uenzare le parole 
pronunciate da una certa persona in un task di speech-recognition. 
Osservando un automobile, la posizione, il colore, l'angolo di incidenza 
dei raggi solari sono altri tipici fattori per l'analisi di una immagine.  
Se riusciamo a riconoscerli e ignorarli durante il processamento saremmo 
in grado di sempli
 ﬁ
care molti task di ML.
17"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#17,17,"Esercizio
Prova a identi
 ﬁ
care un ulteriore task adatto ad un approccio di ML, ed 
elenca qualche fattore di variazione. 
18"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#18,18,"Deep Learning
Il Deep learning segue un approccio di 
 representation learning
 , dove certe 
rappresentazioni sono espresse mediante altre più semplici, es., l'immagine 
di un uomo viene composta da angoli e contorni, che a sua volta sono 
rappresentati con piccoli segmenti.  
Un esempio di una architettura Deep, il 
 multilayer perception:
19
Immagine tratta da Zeiler and Fergus (2014)."
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#19,19,"Schema sempli
 ﬁ
cato approcci di IA
I box scuri includono fasi esplicite di apprendimento.
20
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#2,2,"Il corso
L'obiettivo del 
 corso di Deep Learning (DL)
  di 6 CFU è fornire competenze 
avanzate e speci
 ﬁ
che nell'ambito delle architetture di reti neurali Deep.  
Il corso è strutturato in una parte teorica e 
 metodologica
  sui concetti 
fondamentali, e da una 
 attività di programmazione 
 in cui tali concetti sono 
applicati nella risoluzione di problemi mediante recenti framework di 
sviluppo (Keras & PyTorch).  
Al termine del corso lo studente sarà in grado di:  
addestrare e ottimizzare in maniera adeguata reti neurali Deep;  
saper distinguere tra diverse soluzioni, e saper selezionare e 
personalizzare le architetture di reti più ef
 ﬁ
caci da utilizzare in ambiti 
applicativi reali, supervised, unsupervised o seguendo un approccio 
basato su un apprendimento per rinforzo.  
Il corso prevede lo svolgimento di progetti.
3"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#20,20,"Evoluzione delle architetture
Ogni 2,4 anni il numero di neuroni nascosti è all'incirca raddoppiato.
21
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#21,21,"I.A. & Big Data: il contesto attuale
2222
 
  Large amount of 
Human -generated content
Posizione GPS, “mi piace”, precedenti 
acquisiti, immagini sui social.
Infrastructures
Cloud computing, GPU -enabled 
infrastructure
EU GDPR 
personal information as 
economic assetAI-enabled frameworks
Recommender systems, Speech and Text 
processing, Video and Image analysis
Oligopoly on data
Poche imprese possiedono 
grandi quantità di dati sull’utente.
AI-based interpretation of content
by natural language processing, personality 
traits, object recognition, etc.AI & Big Data
La distribuzione traintelligenza artificiale , e-commerce e abitudini di consumo -12 aprile 2018 Fabio Gasparetti"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#22,22,"Curse of dimensionality
Nei corsi di I.A. e M.L. sono stati descritti numerosi algoritmi che si 
adattano facilmente i vari task. Ma solo pochi riescono ad affrontare 
problemi centrali come riconoscere il parlato od oggetti arbitrari.  
Tali task causano il cosiddetto 
 curse of dimensionality
 : il numero di 
potenziali con
 ﬁ
gurazioni di variabili di ingresso cresce in modo 
esponenziali col numero di variabili considerate.  
Ne segue: istanze di training << # potenziali con
 ﬁ
gurazioni 
23
Incrementando il numero di dimensioni (da 1d a 3d) il 
numero di regioni di interesse (box colorati) incrementa, 
e abbiamo necessità di un numero elevato di istanze per 
caratterizzarne ognuna."
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#23,23,"Local constancy & Smoothness regularization
Imponiamo che la distribuzione di probabilità a priori, che in
 ﬂ
uenza i 
parametri ma anche la funzione che stiamo cercando di stimare, sia 
smoothness prior
  o 
local constancy prior
 . 
Sotto questa assunzione, se l'output di una funzione è OK per una certa 
istanza 
 x
, allora l'output è buono anche per istanze vicine ad 
 x
: 
Esempio
 : algoritmo di 
 k
-nearest neighbors.  
Per dimensionalità elevate, una funzione smooth potrebbe cambiare (in 
modo smooth) in modo diverso a seconda della dimensione. Occorrono 
molte istanze di training per caratterizzarle.  
Il deep learning introduce dipendenze tra le regioni di interesse (cioè nelle 
distribuzioni dei dati) per ridurre il numero di istanze necessarie. 
24
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#24,24,"La libreria D2L
Durante il corso faremo uso di una libreria Python di supporto chiamata 
D2L.ai  
La libreria d2l mette a disposizione alcune funzionalità per rendere il 
codice più interpretabile e compatto.  
Vediamone alcuni esempi di impiego:  
01-d2l_3.2.ipynb  
02-d2l_regressione_3.3.ipynb
25"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#3,3,"Il programma
4
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#4,4,"Testi consigliati e altri riferimenti
• I. Goodfellow, Y. Bengio, and A. Courville, ""Deep Learning"", MIT Press, 
2016.  
• A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola, ""Dive into Deep Learning"", 
2020 (free online).  
• A. Geron, “Hands-on Machine Learning with Scikit-Learn, Keras, and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems”, 
O'Reilly Media, Inc, USA, 2019.  
• M. Nielsen, ""Neural Networks and Deep Learning"", 2019 (free online).  
Altri riferimenti a codice, tutorial, e altre fonti saranno dati durante il corso.
5"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#5,5,"Precondizioni
Le seguenti lezioni del corso di Machine Learning sono requisiti per il 
corso di DL:  
Introduzione alla Regressione  
La Valutazione nella Regressione  
Over
 ﬁ
tting, Cross Validation  
Introduzione alle Reti Neurali Arti
 ﬁ
ciali (es. algoritmo di 
backpropagation)  
Sebbene alcuni dei concetti saranno ripresi per introdurre i formalismi 
necessari al resto del corso.
6"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#6,6,"Software Tools
Docker  
https://www.docker.com/community-edition#/download  
Jupyter Notebook Scienti
 ﬁ
c Python Stack + Tensor
 ﬂ
ow + Tensorboard  
https://github.com/lspvic/jupyter_tensorboard  
docker pull lspvic/tensorboard-noteboo
 k
docker run -it --rm -p 8888:8888 lspvic/tensorboard-noteboo
 k
Docker Engine Utility for NVIDIA GPUs  
https://github.com/NVIDIA/nvidia-docker   
Anaconda + Tensor
 ﬂ
ow 
https://docs.anaconda.com/anaconda/user-guide/tasks/tensor
 ﬂ
ow/ 
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#7,7,"Jupiter
https://jupyter.readthedocs.io/en/latest/  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#8,8,"Google Colaboratory (o Colab)  
Servizio di calcolo online basato su Nvidia Tesla T4 GPUs  
12 GB of RAM  
ﬁ
no a 12 ore di seguito  
Supporto multi-ambiente: TensorFlow, Keras, PyTorch, e OpenCV.  
Molti dataset disponibili nell'ambiente  
https://www.tensor
 ﬂ
ow.org/datasets/catalog/overview   
Interfaccia Jupyter ben nota.  
Default: Runtime Python 3 e nessun acceleratore hardware.  
Menu Runtime -> Change runtime type  
Possibilità di trasferire l’esecuzione in locale (per elaborazioni molto 
lunghe)  
https://research.google.com/colaboratory/local-runtimes.html  
"
data_test\rootfolder\università\DeepLearning\01-Introduzione-sbloccato.pdf#9,9,"Google Colaboratory (o Colab)  
Acceleratore: GPU
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Multilayer Perceptrons, One-hot encoding e Softmax
1"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#1,1,"Sommario
Monotonicità  
MLP e Hidden layers  
Non linearità  
Funzioni di attivazione  
Datasets  
MLP e Tensor
 ﬂ
ow 
Da regressione lineare a classi
 ﬁ
cazione  
Funziona softmax  
One-hot encoding e misure di distanza"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#10,10,"Alcuni toy datasets 
Elenchiamo alcuni dataset che vengono spesso impiegati negli approcci di 
ML e DL:  
MNIST  
notMNIST  
fashion-MNIST  
Dataset più complessi saranno introdotti più avanti. 
11"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#11,11,"Dataset MNIST
Composto da cifre numeriche, usato per addestrare sistemi OCR.  
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others.""  
Contiene 60K immagini di addestramento e 10K di training.  
1998: un linear classi
 ﬁ
er ha ottenuto 7.6% di errore rate.  
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%.  
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono 
centrate in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare 
una cifra.  
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#12,12,"Dataset MNIST: train.csv e test.csv
Il 
ﬁ
le train.csv contiene una matrice con 785 colonne. La prima colonna è il 
label
 della cifra (es. 3) e le restanti colonne sono la rappresentazione 
sequenziale dell’immagine:  
Il 
ﬁ
le test.csv ha la stessa rappresentazione senza la prima colonna.  
Esempio di immagini:
13
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#13,13,"Dataset MNIST - svantaggi
Troppo semplice: algoritmi classici di ML raggiungono i 97% di precisione, 
architetture DL il 99.7%  
Si rischia di ideare nuove architetture adatte solo per questo dataset e 
dif
ﬁ
cilmente adattabili in altri contesti.  
Molto diverso dai task studiati attualmente nell’ambito del DL.
14"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#14,14,"Dataset notMNIST
Simile a MNIST: contiene 10 labels (lettere da A a J), ma ogni lettera nel 
dataset ha un font molto diverso dalle altre, es.:  
http://yaroslavvb.blogspot.
 ﬁ
/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione  
notMNIST_small.tar.gz -> test 
15
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#15,15,"Dataset fashion-MNIST
Fornito da Zalando: 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc).  
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST:  
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
16
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#16,16,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes.  
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su WordNet. In 
media 1K immagini per concetto.  
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi.  
Open Image
 : 9 milioni di URLs di immagini annotate con bounding boxes e 
migliaia di classi.  
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 questions 
per immagini con 10 ground truth answers per question.  
The Street View House Numbers
 : 600K immagini di numeri civici.  
Risultati sperimentali ottenuti per varie architetture  
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
17"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#17,17,"MLP e Tensor
 ﬂ
ow
Proviamo a costruire una MLP con Tensor
 ﬂ
ow (Keras).  
Coalb 04-mlp_5.2.1.ipynb
18"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#18,18,"Da regressione lineare a classi
 ﬁ
cazione
Nei problemi di regressione rispondiamo a domande del tipo ""
 Quale 
quantità o valore?
 "". Ma molti problemi mirano a trovare una classe di 
appartenenza,  
es. è una email di spam? è più probabile che un utente si iscriva ad un 
abbonamento oppure no?  
Ci può interessare la classe più verosimile (
 hard assignements
 ), oppure la 
distribuzione di probabilità sulle classi possibili (
 soft assignements
 ), o siamo 
in presenza di più classi di appartenenza (
 multi-label classi
 ﬁ
cation
 ). 
In caso di più valori in output (es. un layer di output con più nodi), ogni 
valore può essere interpretato come 
 il grado di appartenenza dell'istanza in 
ingresso ad una certa classe
 . La loss misura il discostamento tra classe attesa 
e valori prodotti dal modello. 
19"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#19,19,"Classi
 ﬁ
cazione binaria
Si ha interesse ad associare una istanza in input ad un valore in y
 ∈
{0,1} 
Se usiamo un modello di regressione, estraiamo dall'istanza x features 
numeriche e le combinano linearmente. Il risultato dipende dalle somme 
dei valori di input e dei parametri del modello.  
Al risultato del modello applichiamo la funzione 
 logistic
 , che restituisce un 
valore in [0,1]. La funzione è facilmente differenziabile.  
Interpretiamo tale valore come la probabilità di appartenenza ad una delle 
due classi.  
Si ottiene una 
 logistic regression
 . 
Vogliamo generallizzare la logistic regression al caso K classi, con K>2
20!""=	argmax!*(!|-)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#2,2,"Motivazioni
Tale dispensa richiama in modo sommario molti concetti trattati nel corso di 
ML con particolare attenzione ai concetti che interessano maggiormente lo 
sviluppo di architetture DL (architetture MLP).  
Si rimanda al materiale del corso di ML per i dettagli
3"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#20,20,"Esempio  
Supponiamo di avere 3 classi e l’output della combinazione lineare sia:  
Sebbene la classe più probabile sia associata all’indice 1, i valori non sono 
direttamente interpretabili come distribuzioni di probabilità, infatti:  
I valori non sono in in [0,1]  
La somma non è pari 1
21y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#21,21,"La funzione Softmax
La funzione 
 softmax
  prende in input un vettore in 
 ℝ
T
 e dà in output un 
vettore 
 ℝ
T  
nell'intervallo (0,1] la cui somma è pari a 1. È de
 ﬁ
nita: 
L'output può essere interpretato come distribuzione di probabilità su K 
classi, a differenza di altri modelli (es. classi
 ﬁ
catore SVM).
22S(yi)=eyi
eyj
jK
∑"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#22,22,"Layer softmax nelle reti neurali
La funzione softmax è tipicamente applicata all’output di un layer fully-
connected, creando un nuovo layer chiamato 
 softmax
 . 
Il seguente esempio rappresenta un singolo layer, con funzione di attivazione 
softmax su T classi.  
Nota
 : la funzione softmax introduce non linearità.
23
y s(y)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#23,23,"Softmax in Keras
In Keras è semplice implementare il modello precedente con il parametro 
activation
  di layer Dense:  
24
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#24,24,"One-hot encoding
Nel ML le rappresentazioni dell’input e output sono sottoinsiemi dei 
domini 
 ℕ
 e 
ℝ
. Tali insieme introducono implicitamente ordinamenti.  
Es. se abbiamo 3 categorie (es. rosso=1, bianco=2 e nero=3) e gli 
assegniamo 3 numeri, introduciamo una relazione di ordinamento che 
non esiste nei dati.  
Durante l’addestramento tali relazioni possono essere considerate 
potenziali features, e di conseguenza apprese dall'algoritmo  
Es. Le due istanze Rosso-Nero possono considerarsi più distanti rispetto 
a Rosso-Bianco  
La rappresentazione 
 one-hot
  caratterizza ogni istanza con una 
con
ﬁ
gurazione univoca, costituita da una sequenza binaria di zero, tranne 
un solo elemento pari a 1.
25"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#25,25,"One-hot encoding in Python
Colab 05_onehot.ipynb
26"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#26,26,"Loss e one-hot encoding
Se la 
 softmax
  genera una distribuzione di probabilità su K possibili, la 
codi
ﬁ
ca one-hot genera una distribuzione che ""concentra"" tutta la densità di 
probabilità sulle classi corrette, es.:  
[0, …, 0, 1, 0 …, 0].  
Per addestrare il modello occorre de
 ﬁ
nire una misura di loss che tenga conto 
della distanza tra le due distribuzioni.
27"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#27,27,"Misura di Distanza: cross entropy
Per confrontare due generici vettori 
 p
 e 
q
 che rappresentano distribuzioni di 
probabilità si impiega la misura 
 cross entropy
 : 
Dove 
 x
 si estende su tutte i valori potenziali della variabile causale su cui 
sono de
 ﬁ
nite le probabilità, cioè le classi in output.  
Attenzione: la funzione H non è simmetrica:  
Se uno dei parametri (
 p
 o 
q
) è codi
 ﬁ
cato one-hot, in che posizione conviene 
averlo?
28H(p,q)≠H(q,p)H(p,q)=−p
x∑ (x)⋅log	q(x)"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#28,28,"Misura di Distanza: cross entropy
Nella fase di addestramento un parametro della cross entropy è l’output 
della funzione softmax s(y), mentre il secondo è la codi
 ﬁ
ca one-hot che 
indica una o più classi di appartenenza.  
Supponiamo di usare la codi
 ﬁ
ca one-hot per il calcolo dei logaritmi:  
Anche il layer softmax può generare valori 0, ma è un problema raro e 
facilmente risolvibile (es. aggiungendo un 
 ε
).
29D(s(y),ˆy)=−s(y1)⋅log	1.0+s(y2)⋅log	0+s(y3)⋅log	0 ( ) ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#29,29,"Multinomial logistic classi
 ﬁ
cation
30x=2.0
0.7
1.5
...
8.0⎡
⎣⎢
⎢
⎢
⎢
⎢
⎢⎤
⎦⎥
⎥
⎥
⎥
⎥
⎥S(y)=0.659
0.242
0.099⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥y=2.0
1.0
0.1⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥ˆy=1.0
0.0
0.0⎡
⎣⎢
⎢
⎢⎤
⎦⎥
⎥
⎥D(ˆy,S(y))Input
Linear model Softmax Onehot rep.
Cross entropy distanceLabels"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#3,3,"Monotonicità
Le architetture lineare impongono l'assunzione di 
 monotonicità
 : 
l'incremento di una feature generare un incremento/decremento nel valore 
in output del modello, a seconda del valore dei pesi (o parametri).  
Per certi task è verosimile, sebbene non sempre vero, ad esempio:  
Task: ""
 un individuo sarà regolare con le rate del mutuo?
 "". Se il salario 
passa da 0K a 50K la probabilità che ripaghi il mutuo sarà molto diversa; 
mentre se il salario passa da 1M a 1,05M la probabilità non cambierà 
molto.  
Task: ""
 predire se un individuo è malato in base alla temperatura
 "".  
T << 37 o T >> 37 indica una possibile patologia.  
Come pensi si può risolvere il problema impiegando un algoritmo di 
regressione lineare?
4"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#30,30,"Esercizio
Supponiamo di avere 3 istanze di addestramento che consistono in varie 
features (es. sex, age, etc) e vogliamo predire se un elettore voterà 
democratico o repubblicano con una rete neurale.  
Avendo due reti che producono in output i seguenti valori:  
Calcola l’errore impiegando: (1) cross entropy, (2) mean squared error, (3) 
accuratezza (binaria).
31
#1
#2"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#31,31,"Confronto tra misure di loss
Cross entropy  
#1: -(ln(0.4) + ln(0.4) + ln(0.1)) / 3 = 1.38  
#2: -(ln(0.7) + ln(0.7) + ln(0.3)) / 3 = 0.64 (smaller)  
Mean squared error  
#1: [(0.3 - 0)^2 + (0.3 - 0)^2 + (0.4 - 1)^2 + …] / 3  
(0.54 + 0.54 + 1.34) / 3 = 0.81  
#2: (0.14 + 0.14 + 0.74) / 3 = 0.34 (smaller)  
Accuratezza (binaria)  
Entrambi: classi
 ﬁ
cation error 1/3 = 0.33, accuracy 2/3 = 0.67  
Nota
 : le implementazione delle misure discusse sono in 
 sklearn.metrics  
32"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#32,32,"Confronto tra misure di loss
Cross entropy  
#1: 1.38  
#2: 0.64 (migliore)  
Mean squared error  
#1: 0.81  
#2: 0.34 (migliore)  
Accuratezza (binaria)  
Entrambi: 0.67  
Rispetto alla cross entropy, MSE da molta importanza agli output sbagliati, 
ma allo stesso tempo, se la rete si avvicina ai risultati corretti, i gradienti 
diventano assai bassi, rallentando notevolmente la convergenza.
33
#1
#2"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#4,4,"Monotonicità
Per un task ""
 l'immagine contiene un cane
 ?"", come possiamo creare una 
relazione tra un certo pixel è una classe in output?  
L'assunzione di linearità ci impone un vincolo tra:  
luminosità del pixel <-> classe di appartenenza;  
ignorando però il contesto (altri pixel) e la complesse relazioni tra essi che 
portano a rappresentare visivamente un oggetto.  
Invece di de
 ﬁ
nire una rappresentazione adeguata, impieghiamo reti neurali 
multistrato
 , dove gli 
 hidden layer
  si occupano di riconoscere una 
rappresentazione adeguata dei dati in input, che viene impiegata da un 
predittore lineare per generare l'output. 
5"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#5,5,"Hidden layers e MLP
L'approccio più semplice per aggiungere strati nascosti è 
 impilarli
  (stack) uno 
dopo l'altro, ottenendo L layers.  
Interpretiamo gli L layer, tranne l'ultimo, come l'insieme di nodi impiegati 
per la rappresentazione, e l'ultimo come predittore lineare.  
Otteniamo una architettura 
 Multilayer perceptron (MLP)
  fully connected.
6
"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#6,6,"Da lineare a non lineare
Indichiamo con 
  un 
minibatch
  (una sottoinsieme del dataset di 
training) di 
 n
 istanze dove ogni istanza ha 
 d
 features.  
Per un hidden layer con 
 h
 unità, indichiamo con 
  il relativo 
output. Avendo layer fully connected, abbiamo come parametri:  
i pesi 
   e i  bias 
  . 
Il layer di output avrà parametri:   
    e    
L'output è ricavato nel seguente modo:  
 
 
Secondo te, combinando più funzioni af
 ﬁ
ni, siamo riusciti a introdurre non 
linearità nel modello?
X
∈
ℝ
n
×
d
H
∈
ℝ
n
×
h
W
(
1
)
∈
ℝ
d
×
h
b
(
1
)
∈
ℝ
1
×
h
W
(
2
)
∈
ℝ
h
×
q
b
(
2
)
∈
ℝ
1
×
q
H
=
X
W
(
1
)
+
b
(
1
)
O
=
H
W
(
2
)
+
b
(
2
)
7"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#7,7,"Da lineare a non lineare
Combinando le equazioni viste in precedenza otteniamo un modello 
equivalente ad un singolo layer:  
 
La non linearità viene espressa mediante funzioni di attivazione 
  non 
lineari (es. ReLU) impiegate all'interno delle unità nascoste, a valle della 
trasformazione af
 ﬁ
ne. 
Facendo 
 stacking
  di più hidden layer con funzioni non lineari, es:  
 
 
si ottengono architetture 
 deep
 , che approssimano funzioni più complesse.
O
=
(
X
W
(
1
)
+
b
(
1
)
)
W
(
2
)
+
b
(
2
)
=
X
W
(
1
)
W
(
2
)
+
b
(
1
)
W
(
2
)
+
b
(
2
)
=
X
W
+
b
σ
H
(
1
)
=
σ
1
(
X
W
(
1
)
+
b
(
1
)
)
H
(
2
)
=
σ
2
(
H
(
1
)
W
(
2
)
+
b
(
2
)
)
8"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#8,8,"Universal approximators
Ci si può chiedere quanta capacità rappresentativa (i.e. quanto è 
 potente
 ) è 
espressa da una rete neurale.  
Alcuni risultati suggeriscono che 
 per
ﬁ
no con un solo hidden layer
  è possibile 
approssimare qualsiasi funzione con un numero adeguato di unità.  
Una rete neurale deep può essere pensata come un programma in C,  
cioè puoi risolvere qualsiasi problema software, ma i programmi possono 
raggiungere complessità molto elevate.  
Vedremo architetture di reti deep possono risolvere gli stessi task in modo 
molto più ef
 ﬁ
ciente. 
9"
data_test\rootfolder\università\DeepLearning\02-MLP_onehot_softmax-sbloccato.pdf#9,9,"Funzioni di attivazione
Ne esistono molte, ad esempio:  
Funzione Sigmoide  
Tangente iperbolica (tanh)  
Relu 
Leaky Relu  
Swish  
Relu parametrizzato  
ELU 
Softplus e Softsign  
Selu 
Gelu  
Durante il corso discuteremo pro e contro delle principali.  
Colab 03-funzioni_di_attivazione_5.1.2
10"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Kayers e moduli in Keras
1"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#1,1,"Sommario
Moduli e Keras  
Sequential  
Moduli custom  
Gestione dei parametri: lettura, condivisione, inizializzazione  
Inizializzazione lazy  
Layer custom  
I/O 
GPU e Keras"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#10,10,"Gestione dei parametri: accesso
Il loop di addestramento mira a trovare i parametri che minimizzano la funzione di 
loss. Le architetture più classiche hanno implementazioni che si occupano 
interamente della gestione dei parametri. In altri casi è necessario accedervi 
durante l'esecuzione (es. debugging, riuso dei parametri in parti diverse del 
modello).  
Vediamo come accedere ai parametri. Costruiamo un semplice modello:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
I layer nel modello sono memorizzati mediante liste. I parametri sono facilmente 
accedibili:  
net.layers[
 2
].weights       # secondo layer: 4 pesi e 1 bias  
[<tf.Variable 
 'dense_1/kernel:0'
  shape=(
 4
, 
1
) dtype=float32, numpy=  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32)>,  
 <tf.Variable 
 'dense_1/bias:0'
  shape=(
 1
,) dtype=float32, numpy=array([
 0.
], dtype=float32)>]  
11"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#11,11,"Gestione dei parametri: lettura
In Keras i parametri sono salvati in particolari classi. Per ottenere il valore 
bisogna convertire le classi in tensori, ad esempio, per ottenere il bias dal 
secondo layer della rete:  
type
(net.layers[
 2
].weights[
 1
]), tf.convert_to_tensor(net.layers[
 2
].weights[
 1
]) 
(tensorflow.python.ops.resource_variable_ops.ResourceVariable,  
 <tf.Tensor: shape=(
 1
,), dtype=float32, numpy=array([
 0.
], dtype=float32)>)  
Mentre per ottenere tutti i parametri:  
net.get_weights()  
[array([[-
 0.20149094
 ,  
0.69364685
 , -
0.12403131
 ,  
0.81778544
 ], 
        [ 
 0.3347332
  ,  
0.43645364
 ,  
0.18376476
 , -
0.5020199
  ], 
        [-
 0.7681664
  , -
0.14477473
 , -
0.6313741
  ,  
0.8246415
  ], 
        [-
 0.8074637
  , -
0.20050609
 ,  
0.4308104
  ,  
0.69257575
 ]], 
       dtype=float32),  
 array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32),  
 array([[-
 0.6941955
  ], 
        [-
 0.9906301
  ], 
        [-
 0.13128954
 ], 
        [ 
 0.22367525
 ]], dtype=float32),  
 array([
 0.
], dtype=float32)]  
12"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#12,12,"Condivisione dei parametri
In alcune architetture è conveniente condividere i parametri in layer distinti, 
in modo che la modi
 ﬁ
ca dei parametri di un layer si ri
 ﬂ
etta sull'altro.  
shared = tf.keras.layers.Dense(
 4
, activation=tf.nn.relu)  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    shared,  
    shared,  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
In questo caso, i gradienti del secondo e terzo layer sono sommati.
13"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#13,13,"Inizializzazione dei parametri
All'interno del modulo Python 
 keras.initializers
  sono contenute le 
implementazioni di vari tipi di inizializzazione dei parametri. Tali approcci 
dipendono solitamente dall'input e dell'output e i valori dei bias sono 
impostati a zero.  
Per default, l'inizializziazione dei parametri è basata su una distribuzione 
uniforme (
 glorot initializer
 ) nell'intervallo [-k,k], dove k = sqrt(6/(
 ﬁ
n_in + 
fan_out)).  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(
 4
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 1
), 
]) 
X = tf.random.uniform((
 2
, 
4
)) 
net(X).shape  
Vedi: 
 https://keras.io/api/layers/initializers/  
14"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#14,14,"Inizializzazione dei parametri
Nell'esempio si impiega una inizializzazione basata su una distribuzione 
gaussiana con deviazione standard 0.01.  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.random_normal_initializer(mean=
 0
, stddev=
 0.01
), 
        bias_initializer=tf.zeros_initializer()),  
    tf.keras.layers.Dense(
 1
)]) 
net(X) 
net.weights[
 0
], net.weights[
 1
] 
(<tf.Variable 
 'dense_2/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
 array([[-
 0.00021173
 ,  
0.00316905
 , -
0.00598176
 ,  
0.00144992
 ], 
        [-
 0.00882782
 ,  
0.01484077
 , -
0.00652608
 , -
0.00581241
 ], 
        [ 
 0.00398763
 , -
0.01069997
 , -
0.01145216
 , -
0.00430671
 ], 
        [ 
 0.00342147
 , -
0.01215916
 ,  
0.01345742
 ,  
0.01632656
 ]], 
       dtype=float32)>,  
 <tf.Variable 
 'dense_2/bias:0'
  shape=(
 4
,) dtype=float32, numpy=array([
 0.
, 
0.
, 
0.
, 
0.
], dtype=float32)>)  
Invece per una inizializzazione con valori costanti:  
    tf.keras.layers.Dense(  
        
 4
, activation=tf.nn.relu,  
        kernel_initializer=tf.keras.initializers.Constant(
 1
), 
        bias_initializer=tf.zeros_initializer()),  
Nota
 : è possibile impiegare inizializzazioni distinte per ogni layer.
15"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#15,15,"Inizializzazione dei parametri - custom
Per una inizializzazione custom dei parametri bisogna creare una classe a 
partire dalla classe Initializer, e de
 ﬁ
nire la funzione __call__() che restituisce 
il tensore in base alle dimensioni passate come parametro, es:  
class 
MyInit
(tf.keras.initializers.Initializer):  
    
 def 
__call__
 (
self
, shape, dtype=
 None
): 
        data=tf.random.uniform(shape, -
 10
, 
10
, dtype=dtype)  
        factor=(tf.abs(data) >= 
 5
) 
        factor=tf.cast(factor, tf.float32)  
        
 return
 data * factor  
net = tf.keras.models.Sequential([  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(  
        
 4
, 
        activation=tf.nn.relu,  
        kernel_initializer=MyInit()),  
    tf.keras.layers.Dense(
 1
), 
]) 
net(X) 
print
(net.layers[
 1
].weights[
 0
]) 
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[-
 0.
       , -
 6.526873
  ,  
8.615063
  ,  
5.7617836
 ], 
       [ 
 0.
       ,  
 0.
       ,  
 6.0559807
 , -
0.
       ],  
       [-
 6.7486644
 ,  
8.665197
  ,  
0.
       , -
 7.035637
  ], 
       [-
 0.
       , -
 0.
       , -
 7.608464
  ,  
0.
       ]], dtype=float32)>  
16"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#16,16,"Inizializzazione dei parametri - custom (2)
In alternativa si possono impostare i parametri direttamente:  
net.layers[
 1
].weights[
 0
][:].assign(net.layers[
 1
].weights[
 0
] + 
1
) 
net.layers[
 1
].weights[
 0
][
0
, 
0
].assign(
 42
) 
net.layers[
 1
].weights[
 0
] # stampa  
<tf.Variable 
 'dense_8/kernel:0'
  shape=(
 4
, 
4
) dtype=float32, numpy=  
array([[
 42.
       , -
 5.526873
  ,  
9.615063
  ,  
6.7617836
 ], 
       [ 
 1.
       ,  
 1.
       ,  
 7.0559807
 ,  
1.
       ],  
       [-
 5.7486644
 ,  
9.665197
  ,  
1.
       , -
 6.035637
  ], 
       [ 
 1.
       ,  
 1.
       , -
 6.608464
  ,  
1.
       ]], dtype=float32)>  
Nell'esempio aggiorno i pesi del primo layer (+1) e imposto uno speci
 ﬁ
co 
peso al valore 42.
17"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#17,17,"Inizializzazione lazy
Nel codice visto, il risultato di alcune istruzioni dipende da iperparametri 
quali la dimensione dei layer (es. inizializzazione dei parametri, inserire un 
layer senza indicarne il numero di nodi), sebbene tali iperparametri non 
sono esplicitamente indicati.  
Con la inizializzazione differita (o lazy) è possibile de
 ﬁ
nire una architettura 
in modo più possibile parametrico, in modo da speci
 ﬁ
care solo gli 
iperparametri essenziali e derivare gli altri in modo automatico.  
In questo esempio manca la dimensione del layer di input, perciò Keras non 
può de
 ﬁ
nire completamente gli iperparametri:  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
[net.layers[i].get_weights() 
 for
 i 
in 
range
(
len
(net.layers))]  
[[], []]  
...
18"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#18,18,"Inizializzazione lazy (2)
Se proviamo a de
 ﬁ
nire le dimensioni di un certo input, Keras può 
completare l'inizializzazione, ad esempio:  
X = tf.random.uniform((
 2
, 
20
)) 
net(X) 
[w.shape 
 for
 w 
in
 net.get_weights()]  
[(
20
, 
256
), (
256
,), (
256
, 
10
), (
10
,)]
19"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#19,19,"Layer custom
Possiamo de
 ﬁ
nire layer anche senza parametri da sottoporre ad 
addestramento. Nell'esempio implementiamo una sorta di normalizzazione 
sottraendo la media dai valori in input. Tale operazioni vanno inserite nella 
funzione call().  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
class 
CenteredLayer
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
call
(
self
, inputs):  
        
 return
 inputs - tf.reduce_mean(inputs)  
layer = CenteredLayer()  
layer(tf.constant([
 1.0
, 
2
, 
3
, 
4
, 
5
])) 
<tf.Tensor: shape=(
 5
,), dtype=float32, numpy=array([-
 2.
, -
1.
,  
0.
,  
1.
,  
2.
], dtype=float32)>  
Impieghiamo il layer custom nel nostro modello, e veri
 ﬁ
chiamo che con dait 
random otteniamo un valore medio in output quasi 0:  
net = tf.keras.Sequential([tf.keras.layers.Dense(
 128
), CenteredLayer()])  
Y = net(tf.random.uniform((
 4
, 
8
))) 
tf.reduce_mean(Y)  
<tf.Tensor: shape=(), dtype=float32, numpy=
 9.313226e-10
 >
20"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#2,2,"Deep networks e moduli
Abbiamo visto come una MLP sia composta da uno o più layer, ognuno 
composto da uno o più nodi che costituiscono l'unità elementare di 
elaborazione.  
Alcuni risultati ci suggeriscono che questo sia un modello suf
 ﬁ
cientemente 
generale per simulare un dominio molto vasto funzioni. Ma risultati 
sperimentali hanno dimostrato che modelli intermedi, più grandi del singolo 
neurone, ma più piccoli dell'intero modello computazionale siano più adatti 
per costruire architetture deep.  
Esempio
 : l'architettura 
 ResNet-152
  (Residual NN) sviluppata nell'ambito 
della computer vision è una delle prime architetture con 100ia di layers. 
La rete è costituita da schemi di nodi e connessioni (
 moduli
 ) che si 
ripetono. Particolari tecniche (
 skip connections
 ) sono impiegate per 
risolvere il vanishing problem.  
Un modulo può essere un layer, più layers, o l'intero modello; e generalizza 
un elemento computazionale che può essere ripetuto, o riutilizzato in diverse 
architetture.
3"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#20,20,"Layer custom con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
21"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#21,21,"Layer con parametri
Nell'esempio ricreiamo un layer fully connected con una classe custom. 
Nella funzione 
 __init__
 () creiamo i parametri che non dipendono dalla 
dimensione dell'input, mentre in 
 build
 () de
ﬁ
niamo quelli che dipendono, 
con eventuale inizializzazione. La funzione 
 build
 () viene invocata 
automaticamente prima di call().  
La funzione 
 add_weight
 () automatizza la creazione dei parametri da 
sottoporre ad addestramento.  
class 
MyDense
(tf.keras.Model):  
    
 def 
__init__
 (
self
, units):  
        
 super
().
__init__
 () 
        # il secondo parametro indica la dimensione dell'input  
        
 self
.units = units  
    # il secondo parametro indica la dimensione dell'input  
    
 def 
build
(
self
, X_shape):  
        
 self
.weight = 
 self
.add_weight(name=
 'weight'
 , 
            shape=[X_shape[-
 1
], 
self
.units],  
            initializer=tf.random_normal_initializer())  
        
 self
.bias = 
 self
.add_weight(  
            name=
 'bias'
, shape=[
 self
.units],  
            initializer=tf.zeros_initializer())  
    
 def 
call
(
self
, X): 
        linear = tf.matmul(X, 
 self
.weight) + 
 self
.bias 
        
 return
 tf.nn.relu(linear)  
# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models
22"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#22,22,"I/O su 
 ﬁ
le - tensori
Gli addestramenti di reti deep possono essere molto lunghe. È necessario 
salvare i risultati parziale e 
 ﬁ
nali su 
 ﬁ
le in modo da poterli recuperare 
facilmente.  
Ad esempio, per salvare e recuperare i tensori:  
import 
numpy 
as 
np 
import 
tensorflow  
as 
tf 
# salvataggio  
x = tf.range(
 4
) 
np.save(
 'x-file.npy'
 , x) 
# recupero  
x2 = np.load(
 'x-file.npy'
 , allow_pickle=
 True
) 
# salvataggio di più sensori  
y = tf.zeros(
 4
) 
np.save(
 'xy-files.npy'
 , [x, y])  
x2, y2 = np.load(
 'xy-files.npy'
 , allow_pickle=
 True
) 
# o salvare dizionari stringa-tensore  
mydict = {
 'x'
: x, 
'y'
: y} 
np.save(
 'mydict.npy'
 , mydict)  
mydict2 = np.load(
 'mydict.npy'
 , allow_pickle=
 True
) 
23"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#23,23,"I/O su 
 ﬁ
le - modelli
Per i modelli, occorre distinguere architettura e parametri. Per la prima, ci si 
basa sul codice che si usa per crearla, perciò senza salvataggio su 
 ﬁ
le. 
Mentre per i parametri si sfruttano le funzionalità di Keras.  
Ad esempio, de
 ﬁ
niamo una architettura, salviamo i parametri e ricostruiamo 
la rete con il recupero dei parametri:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
 def 
call
(
self
, inputs):  
        x = 
 self
.flatten(inputs)  
        x = 
 self
.hidden(x)  
        
 return 
self
.out(x) 
net = MLP()  
X = tf.random.uniform((
 2
, 
20
)) 
Y = net(X)  
net.save_weights(
 'mlp.params'
 ) 
...  
clone = MLP()  
clone.load_weights(
 'mlp.params'
 )
24"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#24,24,"GPU e Keras
Per default i tensori sono creati in memoria e le computazioni sono sulla 
CPU. Ma possiamo comunque controllare l'elaborazione:  
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
cpu
():   
    
 return
 tf.device(
 '/CPU:0'
 ) 
def 
gpu
(i=
0
):   
    
 return
 tf.device(
 f'/GPU:
{
i
}
'
) 
cpu(), gpu(), gpu(
 1
) 
(<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa2b271c0
 >, 
 <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa257a100
 >, 
 [<tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ad00
 >, 
  <tensorflow.python.eager.context._EagerDeviceContext at 
 0x7fafa253ab40
 >]) 
def 
num_gpus
 ():   
    
 return 
len
(tf.config.experimental.list_physical_devices(
 'GPU'
)) 
def 
try_gpu
(i=
0
):   
    
# restituisce gpu(i) se esiste, altrimenti cpu()  
    
 if
 num_gpus() >= i + 
 1
: 
        
 return
 gpu(i) 
    
 return
 cpu() 
def 
try_all_gpus
 ():   
    # 
Numero di GPU disponibili, o CPU se le GPU non ci sono  
    
 return
 [gpu(i) 
 for
 i 
in 
range
(num_gpus())]  
try_gpu(), try_gpu(
 10
), try_all_gpus()
25"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#25,25,"GPU e Keras (2)
# su quale device è allocato il tensore  
# Nota: è fondamentale avere tutti i parametri di una operazione sullo stesso device  
x = tf.constant([
 1
, 
2
, 
3
]) 
x.device  
'/job:localhost/replica:0/task:0/device:GPU:0'  
# alloca un tensore su una GPU  
with
 try_gpu():  
    X = tf.ones((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
1.
]], dtype=float32)>  
# alloca un tensore sulla seconda GPU  
with
 try_gpu(
 1
): 
    Y = tf.random.uniform((
 2
, 
3
)) 
<tf.Tensor: shape=(
 2
, 
3
), dtype=float32, numpy=  
array([[
 0.44844735
 , 
0.7493162
  , 
0.5692874
  ], 
       [
 0.10097635
 , 
0.81023645
 , 
0.5274769
  ]], dtype=float32)>  
# per calcolare X + Y, dobbiamo averli sullo stesso device  
# spostiamo X sulla stessa GPU di Y  
with
 try_gpu(
 1
): 
    Z = X  
print
(X) 
print
(Z) 
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
tf.Tensor(  
[[
1. 
1. 
1.
] 
 [
1. 
1. 
1.
]], shape=(
 2
, 
3
), dtype=float32)  
# ora possiamo calcolarlo  
Y + Z
26"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#26,26,"GPU e Keras (3)
È possibile indicare a Keras di impiegare le GPU disponibili per 
l'elaborazione di un certo modello:  
strategy = tf.distribute.MirroredStrategy()  
with
 strategy.scope():  
    net = tf.keras.models.Sequential([  
        tf.keras.layers.Dense(
 1
)]) 
INFO:tensorflow:Using MirroredStrategy 
 with
 devices (
 '/job:localhost/replica:0/task:0/device:GPU:0'
 , 
'/
job:localhost/replica:0/task:0/device:GPU:1'
 ) 
net(X) 
<tf.Tensor: shape=(
 2
, 
1
), dtype=float32, numpy=  
array([[-
 1.1522729
 ], 
       [-
 1.1522729
 ]], dtype=float32)>  
# vediamo la conferma cheanche i parametri sono memorizzati nello stesso device  
net.layers[
 0
].weights[
 0
].device, net.layers[
 0
].weights[
 1
].device  
(
'/job:localhost/replica:0/task:0/device:GPU:0'
 , 
 
'/job:localhost/replica:0/task:0/device:GPU:0')
27"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#3,3,"Moduli in Keras
Un modulo è rappresentato da una classe Python che implementa la forward 
propagation, memorizza i parametri, e fornisca la backpropagation. 
Quest'ultimo aspetto può essere delegato alla tecnica autodiff, senza perciò 
de
ﬁ
nire manualmente i singoli gradienti.  
Ad esempio il seguente codice genera due layer: il primo con 256 nodi 
 fully 
connected
  (o 
denso
 ) ed uno di output con 10 nodi.  
import 
tensorflow  
as 
tf 
net = tf.keras.models.Sequential([  
    tf.keras.layers.Dense(
 256
, activation=tf.nn.relu),  
    tf.keras.layers.Dense(
 10
), 
]) 
X = tf.random.uniform((
 2
, 
20
)) 
net(X).shape  
Il modello è costruito istanziando la classe 
 Sequential
  e passandogli i singoli 
layer come parametri. Sia 
 Sequential
  che 
 Dense
  sono istanze di 
 keras.Model
 .  
4"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#4,4,"Sequential in Keras
Sequential crea una lista ordinata di layer.  
La procedura di forward propagation è de
 ﬁ
nita implicitamente: l'output di 
un layer corrisponde all'input del secondo.  
Nell'esempio si invoca net(X), che corrisponde alla funzione net.call(X), per 
ottenere l'output dal modello appena creato.
5"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#5,5,"Moduli custom
Per creare nuovi moduli occorre tener presente come vengono impiegati 
durante l'esecuzione:  
1.
I dati di input vengono mandati in input alla forward propagation  
2.
La funzione di propagazione restituisce i valori in output  
3.
Si calcolano i gradienti dell'output rispetto agli input per mezzo del 
metodo di backpropagation. Uno step solitamente gestito in automatico  
4.
Memorizzare i parametri ottenuti necessari per la successiva forward 
propagation
6"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#6,6,"Moduli custom
Ad esempio, la rete precedente (un layer da 256 nodi seguito da un layer di 
10 nodi) si codi
 ﬁ
ca nel seguente modo:  
class 
MLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 # Sempre necessario richiamare il costruttore della superclass  
        
 super
().
__init__
 () 
        
 self
.hidden = tf.keras.layers.Dense(units=
 256
, activation=tf.nn.relu)  
        
 self
.out = tf.keras.layers.Dense(units=
 10
) 
    
# forward propagation  
    
 def 
call
(
self
, X): 
        
 return 
self
.out(
self
.hidden((X)))  
de
ﬁ
nendo il costruttore e la funzione che si occupa della forward 
propagation.  
Il metodo call permette di creare layer che richiedono particolari 
elaborazioni (es. controllare il 
 ﬂ
usso di esecuzione durante la forward 
propagation) che non corrispondono a quelle prede
 ﬁ
nite in Keras.
7"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#7,7,"Moduli custom - esempio
Durante l'elaborazione possiamo aver bisogno di accedere a costanti, cioè valori 
che non sono associati a parametri da stimare durante l'apprendimento, perciò 
non soggetti a back propagation.  
Nell'esempio, istanziamo i parametri in modo casuale, e rimarranno costanti 
durante il training. Restituiamo la somma dei valori in output.  
L'esempio è di scarsa utilità ma dimostra le potenzialità dei moduli custom.  
class 
FixedHiddenMLP
 (tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.flatten = tf.keras.layers.Flatten()  
       
self
.rand_weight = tf.constant(tf.random.uniform((
 20
, 
20
))) 
        
 self
.dense = tf.keras.layers.Dense(
 20
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        X = 
 self
.flatten(inputs)  
        
 # Usiamo i parametri costanti per generare l'output  
        X = tf.nn.relu(tf.matmul(X, 
 self
.rand_weight) + 
 1
)        
        X = 
 self
.dense(X)  
        
 # Control flow: simil l1 regularization  
        
 while
 tf.reduce_sum(tf.math.abs(X)) > 
 1
: 
            X /= 
 2 
        
 # reduce_sum() calcola la somma dei valori per una certa dimensione del tensore  
        
 # senza secondo parametro la somma è operata su tutte le dimensioni del tensore  
        
 return
 tf.reduce_sum(X)  
net = FixedHiddenMLP()  
net(X) 
<tf.Tensor: shape=(), dtype=float32, numpy=
 0.88945085
 >
8"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#8,8,"Moduli custom - esempio
Nell'esempio de
 ﬁ
nisco un altro modello (NestMLP) e successivamente un 
nuovo modello che include il primo come layer:  
class 
NestMLP
(tf.keras.Model):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
        
 self
.net = tf.keras.Sequential()  
        
 self
.net.add(tf.keras.layers.Dense(
 64
, activation=tf.nn.relu))  
        
 self
.net.add(tf.keras.layers.Dense(
 32
, activation=tf.nn.relu))  
        
 self
.dense = tf.keras.layers.Dense(
 16
, activation=tf.nn.relu)  
    
 def 
call
(
self
, inputs):  
        
 return 
self
.dense(
self
.net(inputs))  
chimera = tf.keras.Sequential()  
chimera.add(NestMLP())  
chimera.add(tf.keras.layers.Dense(
 20
)) 
chimera.add(FixedHiddenMLP())  
chimera(X)
9"
data_test\rootfolder\università\DeepLearning\03-Layers_moduli_keras-sbloccato.pdf#9,9,"Esercizio
Implementare un modulo che prende l'output di due moduli (es. 
 net1
 e 
net2
) e restituisce un output concatenato durante la forward propagation.
10"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN) - parte 1
1"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#1,1,"Sommario
Introduzione  
Architettura Visual cortex  
MLP fully connected e limiti  
Invarianza (spaziale) e principio di località  
Convolutional layer e canali"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#10,10,"MLP - fully connected
Le reti MLP sono comunque ef
 ﬁ
caci in molti contesti, ad esempio:  
In presenza di dati in formato 
 tebellare
 , dove non assumiamo a priori 
una struttura che mette in correlazione le features per ogni istanza, 
sebbene possano esserci potenziali correlazioni e dipendenze.  
Dati da cui si possono estrarre un numero di features non elevatissimo 
(<<1000), che perciò necessitano di un numero di parametri da stimare 
limitato.
11"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#11,11,"Invarianza (spaziale) #1
12
Nella identi
 ﬁ
cazione delle targhe, per addestrare una MLP dobbiamo 
costruire un training set con molte istanze, in modo da :  
avere lo stesso oggetto che compare in varie posizioni, angolazioni e 
dimensioni.  
oggetto visualizzato parzialmente (es. sul bordo).  
casi di overlap tra oggetti etc."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#12,12,"Invarianza (spaziale) #2
Nel task ""Where's Waldo?"" non siamo interessati alla posizione, ma solo 
alla presenza o meno di una certa istanza.  
Il modello dovrebbe tentare di analizzare piccole zone dell'immagine e 
confrontarle con il pattern ""Waldo"".
13
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#13,13,"Proprietà locali
14Per riconoscere certe caratteristiche speci ﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata . Non c'è bisogno di considerare l'intera immagine iniziale.  
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  "
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#14,14,"MLP: Proprietà desiderate
15
Nei primi layer la rete dovrebbe comportarsi in modo simile 
indipendentemente dalla posizione di una certa regione di interesse 
(
translation invariance
  o 
translation equivariance
 ). 
Nei primi layer l'analisi deve essere limitata a piccole regioni 
dell'immagine in input, e non sull'intera immagine (
 principio di località
 ).  
Nei successivi layer, tali analisi considerano regioni più vaste, combinando 
l'output delle analisi precedenti, 
 ﬁ
no ad arrivare all'intera immagine."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#15,15,"Esempio MLP e immagini
16
Supponiamo di avere una MLP con uno strato nascosto 
 H
. L'input 
 X
 è 2d, ed è 
rappresentato da un tensore, anch'esso 2d. Supponiamo per ora che 
 H
 abbia la 
stessa struttura di 
 X
. 
Indichiamo con [
 X
]
i,j
 e [
H
]
i,j
 il pixel nella posizione <i,j> e il corrispettivo nodo nel 
layer nascosto.  
Indichiamo con 
 W
 e 
U
 pesi e bias della rete. Poiché ogni nodo di 
 H
 riceve input 
da tutti i pixel in input, usiamo matrici-tensori di ordine 4.  
Dove [
 V
]
i,j,a,b
 := [
H
]
i,j,i+a,j+b 
 , 
perciò introduciamo un semplice cambio notazione. 
Gli indici 
 a
 e 
b
 sono offset rispetto a <i,j> e scorrono l'intera immagine in input, 
perciò possono assumere valori negativi.  
Numero di parametri: per immagini 1000x1000 abbiamo 10
12
 parametri, infatti 
ogni nodo in 
 H
 deve essere connesso con tutti i nodi del layer precedente.
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#16,16,"Invarianza spaziale nella pratica
17
Tale proprietà impone che, se abbiamo uno 
 shift
 nell'input 
 X
, anche la 
rappresentazione 
 H
 deve subire lo stesso 
 shift
, in modo da mantenere lo 
stesso output. Ma questo è possibile solo se 
 U 
e 
V
 non dipendono da 
 <i,j>
, 
cioè [
 V
]
i,j,a,b
 := [
V
]
a,b  
e 
U
 è una costante.  
Rappresenta l'operatore di 
 convoluzione
 . Il pixel <i+a,j+b>, vicino alla 
location <i,j>, è pesato con il coef
 ﬁ
ciente [
 V
]
a,b
 per ottenere l'output [
 H
]
i,j
. 
[
V
]
a,b  
richiede meno coef
 ﬁ
cienti poiché è indipendente dalla location. I 
parametri passano da 10
12
 a 4·10
6
, con 
 a
 e 
b
 in (-1000,1000).
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#17,17,"Principio di località nella pratica
18
Limitiamo l'analisi per determinare [
 H
]
i,j
 a una zona 
 Δ
×
Δ
, con 
Δ
<<1000 
(es. 
Δ
=10), perciò evitando di considerare l'intera immagine:  
I parametri si riducono ulteriormente da 4·10
6
 a 4·
Δ
2
, sebbene il layer 
nascosto mantenga la dimensione iniziale, e perciò la quantità di 
informazione originale.  
La regione 
 Δ
×
Δ
 che genera le attivazioni nel successivo strato è chiamata 
Local receptive 
 ﬁ
eld (LRF)
 .
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#18,18,"CNN - Convolutional layer e LRF
19
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input:  
immagine 25x25 pixe l
in bianco e neroOutput dopo il primo  
layer convolutivo .local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato  
da una certa posizione del 
LRF  che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#19,19,"Convolutional neural networks
20
Il layer 
 H
 che abbiamo introdotto prende il nome di 
 convolutional layer,
  e 
le rete basate su tale layer 
 Convolutional neural networks
  (CNNs).  
V
 è comunemente chiamato 
 convolution kernel
  o 
ﬁ
ltro
. 
Per rappresentare features più complesse e ad alto livello, si impiegano più 
layer convolutivi alternati a non linearità."
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#2,2,"Introduzione
Alcune so
 ﬁ
sticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come:  
•
Riconoscere un giocattolo in una immagine  
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speci
 ﬁ
che.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture.  
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identi
 ﬁ
carlo.  
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
3"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#20,20,"Channels (canali)
21
Le immagini a colori hanno 3 canali RGB, perciò, ai due assi principali che 
identi
 ﬁ
cano le relazioni spaziali, ne aggiungiamo un terzo ottenendo 
tensori 3d [
 X
]
i,j,k
 con 
 ﬁ
ltri del tipo [
 V
]
a,b,c
 . 
Muovendoci in profondità, possiamo creare una terza dimensione per ogni 
strato hidden. In pratica si ha uno 
 stack
  di griglie, chiamato 
 feature maps
 , 
dove ogni griglia è creata con un 
 ﬁ
ltro distinto. Il numero di griglie 
corrisponde ai canali per quello strato.  
Generalizzando, supponendo di avere più canali in input (
 c
) e più canali 
nell'hidden layer (
 d
), si ha:  
Il successivo layer userà i 
 d
 canali dell'hidden layer che diverranno i 
 c 
canali di input.
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#21,21,"Esercizio
22
Impiega il dataset di cifre MNIST e crea una rete convolutiva per la 
classi
 ﬁ
cazione.  
Colab 
 07-lenet.ipynb 
"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#3,3,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive 
 ﬁ
eld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale.  
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
con
ﬁ
gurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"".  
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi.  
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
4"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#4,4,"L'architettura della Visual cortex
5
Secondo te è una MLP?Ad ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#5,5,"L'architettura della Visual cortex
6
È simile a una MLP ,  
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione  
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#6,6,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
7"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#7,7,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
8"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#8,8,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel  
•
Creiamo un primo layer di appena 1000 nodi, che perciò 
 ﬁ
ltra 
notevolmente le informazioni passata ai successivi layer.  
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare.  
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo 
task
, es. riconoscere linee orizzontali.  
•
I neuroni specializzati sono attivati se il pattern da identi
 ﬁ
care è 
localizzato in una certa zona.  
•
Ma vorremmo poter identi
 ﬁ
care lo stesso pattern indipendentemente da 
dove compare.
9"
data_test\rootfolder\università\DeepLearning\04-CNN parte 1-sbloccato.pdf#9,9,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?  
3. Le reti 
 MLP 
non riescono a codi
 ﬁ
care esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identi
 ﬁ
cano 
features analizzando piccole aree dell'immagine.  
•
I neuroni ""ad alto livello"" combinano tali features per identi
 ﬁ
care features 
spazialmente più estese.
10"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
2a parte
1"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#1,1,"Sommario
Convolutional Neural network  
•
Convolutional layer  
•
Local receptive 
 ﬁ
eld 
•
Stride e Padding  
•
Filters e Feature Maps  
•
Pooling Layer  
Architettura LeNet-5"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#10,10,"CNN - Stride
11•La distanza s tra due LRF  adiacenti è chiamata stride . 
•Finora abbiamo visto stride di 1 pixel, ma la LRF  può scorrere di più pixel . 
•Le CNN spesso impiegano kernels di dimensione 1,3,5 o 7. Questo rende più facile mantenere 
la dimensionalità con padding (vedi di seguito) che consistono nello stesso numero di righe in 
cima e in fondo, e colonne a sinistra e a destra dell'immagine. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3  
Stride = 2"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#11,11,"CNN: Padding
12•Supponendo stride > 1 , può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF ) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input.  
•Il padding  aggiunge dimensioni  ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding ). Si hanno i seguenti vantaggi :
•Permettere alla LRF  di scorrere per intero l'immagine in input senza ignorarne delle parti .
•Un LRF potrebbe ""imparare"" a riconosce una certa feature  quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo , senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#12,12,"CNN: Riduzione dimensionalità e Stride
13Output layer precedente•La presenza di stride > 1  altera gli indici iniziali e ﬁnali che identi ﬁcato il LRF associato ad 
un certo nodo.  
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista .
•Stride > 1 riducono la dimensione  del layer convoluzionale a scapito della precisione .
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3  
Stride = 2"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#13,13,"CNN: Filters
14Filters•Supponiamo di poter rappresentare gra ﬁcamente i pesi associati a un certo nodo , usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters  o convolution kernels  
(o kernels )
•Ad esempio, una LRF  77 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#14,14,"Esempi di 
 ﬁ
ltri e attivazioni (1)
15Esempio di input  
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo .
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#15,15,"Esempi di 
 ﬁ
ltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#16,16,"CNN: Feature Maps
17Filters•Le LRF  scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione . Tale approccio prende il nome di shared weights . 
•L'insieme delle attivazioni ottenute (output) con lo stesso ﬁltro viene chiamato feature map 
poiché rappresenta le features apprese nella dimensione spaziale. Esse possono essere 
visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map  dove le zone dell'input simili a una 
linea verticale  sono più evidenziate  (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate . Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#17,17,"CNN: Stacking feature maps
In 
ogni layer
  possiamo avere 
 più 
ﬁ
ltri con le medesime dimensioni
 . Ogni 
ﬁ
ltro produrrà una diversa feature map. Ogni layer sarà così costituito da 
una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i 
 ﬁ
ltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di:  
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP.  
•
Durante la backpropagation, adattare ogni 
 ﬁ
ltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso 
 ﬁ
ltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
18"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#18,18,"Canali multipli in input
Abbiamo già visto l'operatore di convoluzione in presenza di più canali.  
Se in ingresso abbiamo più canali, es. RGB, 
 c
i
 > 1, allora il 
 ﬁ
ltro 
rappresentato dal tensore 
 k
h
 × 
k
w
 dovrà essere ripetuto per ogni canale. Se 
concateniamo i tensori abbiamo un tensore 
 c
i 
× k
h
 × 
k
w
. 
Il risultato sarà un tensore 2d poiché il risultato delle singole convoluzioni 
sarà sommato nella dimensione dei canali.  
Ad esempio, considerando 2 canali in input:
19
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#19,19,"Canali multipli in output
Nelle CNN tradizionalmente il numero di canali aumentano con il numero 
di layer processati, generalmente riducendo allo stesso tempo la risoluzione 
spaziale degli input.  
Idealmente ogni canale rappresenterà un different set di features, ma in 
realtà le features possono essere 
 sparse
  su più canali.  
Per avere un output multicanale, creiamo più tensori 
 c
i 
× k
h
 × 
k
w 
, ognuno 
per singolo canale in output. Se li concateniamo otteniamo un kernel  
c
o 
× c
i 
× k
h
 × 
k
w
 .
20"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#2,2,"CNN - Struttura gerarchica
3Input layer:  
È un layer costituito da unità  
a cui viene associato il valore  
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerData una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota : Nelle tradizionali MLP , input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori , ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN  tale ridimensionamento è controproducente  poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell' input layer  le features  
corrispondono ai singoli pixel"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#20,20,"CNN: Feature Maps e Canali
21...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB, cioè 3 
canali.Possiamo de ﬁnire un certo numero di 
ﬁltri (es. 12) per riconoscere diverse 
caratteristiche salienti dell'immagine 
iniziale. I ﬁltri analizzano 
contemporaneamente 3 canali RGB, 
perciò i ﬁltri saranno de ﬁniti con 
matrici a 3 dimensioni. Un ﬁltro 
applicato all'immagine in input 
produce un singolo convolutional layer.I successivi layer convoluzionali 
analizzato le attivazioni di più ﬁltri 
contemporaneamente. I ﬁltri di questo 
layer riconosceranno caratteristiche 
più astratte.depth = 3 depth = 12 depth = 7"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#21,21,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori:  
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
2201234567891011121300 12345678910111213
senza padding ('VALID' ) con padding ('SAME' )ignorati
stride=5padding P=+3"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#22,22,"Stride, padding e Keras
Le dimensioni del kernel e i restanti iperparametri sono de
 ﬁ
niti via 
costruttore del modello Conv2D:  
# numero di kernels pari a 1  
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=
 3
, padding=
 'same'
, strides=
 2
) 
conv2d = tf.keras.layers.Conv2D(
 1
, kernel_size=(
 3
,
5
), padding=
 'valid'
, strides=(
 3
, 
4
)) "
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#23,23,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di 
 ﬁ
ltri per layer (o 
 depth
 ) 
Dimensione del LRF  
Stride e padding  
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una con
 ﬁ
gurazione 
verosimilmente già ottimizzata.
24"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#24,24,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con 
ﬁ
ltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200  
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile.  
•
Con 
ﬂ
oat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
25"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#25,25,"Pooling layer
Ripetendo i layer convolutivi, ad ogni layer il 
 receptive 
 ﬁ
eld
 sarà 
 sensibile  
ad una parte sempre maggiore in riferimento all'immagine iniziale. Perciò 
gli ultimi nodi della rete saranno attivati in base all'intera informazione 
presente nell'immagine iniziale.  
Spesso l'informazione spaziale esatta delle features riconosciute non è 
importante, soprattutto se ci interessa l'invarianza ad eventuali translazione 
dell'input.  
I pooling layer sono utili per:  
mitigare la sensitività
  dei layer convolutivi rispetto alle posizioni delle 
features  
ridurre la dimensionalità dell'input da elaborare
 .
26"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#26,26,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti:  
•
Meno complessità computazione  
•
Meno risorse di memoria  
•
Meno parametri (e ridurre l'over
 ﬁ
tting come effetto collaterale)  
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF.  
•
Occorre de
 ﬁ
nire dimensione, stride e padding  
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
27"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#27,27,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁ
eld (
pooling size
 ), il 
pooling stride
 , e tipo di aggregazione.  
•
Spesso pooling size e stride corrispondono.  
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identi
 ﬁ
cata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche.  
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta.  
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel 
ﬁ
eld considerato.  
•
average pooling:
  considero il valor medio nel 
 ﬁ
eld.
28"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#28,28,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max.  
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
29
A causa del padding VALID  
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  fpo è il pooling size , spo il pooling stride ,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#29,29,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri.  
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente:  
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#3,3,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la 
 ﬁ
nestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della 
 ﬁ
nestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#30,30,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classi
 ﬁ
cazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden:  
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID  
•Numero ﬁltri (o depth) = 96  
•L’output per ogni ﬁltro avrà dimensione di lato 
(227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 
=290.400 nodi.  
•L'attivazione di un nodo si ricava considerando 
11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri.  
•Per la proprietà degli shared weights, nella CNN il 
numero di parametri sarà 11x11x3x96 + 96 = 
34.944.  × ×
×
×
feature mapscomputazione"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#31,31,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST.  
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identi
 ﬁ
cate dalle CNN 
per fare classi
 ﬁ
cazione per mezzo della MLP.  
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni."
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#32,32,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/  "
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#33,33,"Architettura LeNet-5
convolutional layer#1 conv. laye r
feature maps:  
28x28, depth 6#3 conv. layer  
feature maps:  
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling laye r
feature maps:  
14x14, depth 6#4 pooling laye r
feature maps:  
5x5, depth 16
conv. layer#6 fully connected layer  
nodi 84#5 conv. layer  
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer  
nodi 10
La con ﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding."
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#34,34,"LeNet-5: esempio di 
 ﬁ
ltri
Nel caso del dataset MNIST di caratteri numerici (immagini 28x28), 
otteniamo 
 ﬁ
ltri di questo tipo:  
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#4,4,"CNN - LRF
5Output layer precedente•In un certo layer convoluzionale , un nodo con indice (i, j) prende in input  gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF  va dalla riga  i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e fw corrispondono all'altezza e larghezza del LRF . 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni .forward propagation
Esempio con LRF 3x3  
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding  
(discusso più avanti)
•Notazioni: rispetto alle slide precedenti 2Δ=fh=fw"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#5,5,"Cross-correlazione
Supponendo 
 K
 il kernel e 
 X
 l'input 2d, possiamo de
 ﬁ
nire la funzione 
 corr2d
 () che 
restituisce un output di dimensioni pari all'input, meno la dimensione del kernel 
 + 
1
: 
import 
tensorflow  
as 
tf 
from 
d2l 
import
 tensorflow 
 as
 d2l 
def 
corr2d
(X, K):  
    h, w = K.shape  
    Y = tf.Variable(tf.zeros((X.shape[
 0
] - h + 
 1
, X.shape[
 1
] - w + 
 1
))) 
    
 for
 i 
in 
range
(Y.shape[
 0
]): 
        
 for
 j 
in 
range
(Y.shape[
 1
]):         
            # estraggo la parte di X che mi interessa  
            # calcolo una moltiplicazione element-wise tra le matrici  
            # ricavo infine la somma  
            Y[i, j].assign(tf.reduce_sum(  
                X[i: i + h, j: j + w] * K))  
    
 return
 Y 
X = tf.constant([[
 0.0
, 
1.0
, 
2.0
], [
3.0
, 
4.0
, 
5.0
], [
6.0
, 
7.0
, 
8.0
]]) 
K = tf.constant([[
 0.0
, 
1.0
], [
2.0
, 
3.0
]]) 
corr2d(X, K)  
<tf.Variable 
 'Variable:0'
  shape=(
 2
, 
2
) dtype=float32, numpy=  
array([[
 19.
, 
25.
], 
       [
 37.
, 
43.
]], dtype=float32)>  
Nota
 : l'operatore di 
 convoluzione
  è simile all'operatore 
 cross-correlazione
 , ma nel 
primo il kernel è ""
 capovolto"" 
 durante il calcolo. Nelle CNN si impiega usualmente 
la cross-correlazione. Non c'è differenza poiché i pesi ricavati durante 
l'addestramento sono i medesimi, ma con ordine invertito. Spesso nei testi e nel 
codice i due termini assumono lo stesso signi
 ﬁ
cato.
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#6,6,"Esempio di modello Conv2D
class 
Conv2D
(tf.keras.layers.Layer):  
    
 def 
__init__
 (
self
): 
        
 super
().
__init__
 () 
    
 def 
build
(
self
, kernel_size):  
        initializer = tf.random_normal_initializer()  
        
 self
.weight = 
 self
.add_weight(name=
 'w'
, shape=kernel_size,  
                                      initializer=initializer)  
        
 self
.bias = 
 self
.add_weight(name=
 'b'
, shape=(
 1
, ), 
                                    initializer=initializer)  
    
 def 
call
(
self
, inputs):  
        
 return
 corr2d(inputs, 
 self
.weight) + 
 self
.bias"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#7,7,"Esempio: riconoscimento bordi
Supponiamo che vogliamo riconoscere il bordoe in una immagine 
monitorando il cambio del valore dei pixel.  
Costruiamo una immagine 6x8 nel seguente modo:  
X = tf.Variable(tf.ones((
 6
, 
8
))) 
X[:, 
2
:
6
].assign(tf.zeros(X[:, 
 2
:
6
].shape))  
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
8
) dtype=float32, numpy=  
array([[
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
], 
       [
 1.
, 
1.
, 
0.
, 
0.
, 
0.
, 
0.
, 
1.
, 
1.
]], dtype=float32)>  
Costruiamo un kernel 1x2  
K = tf.constant([[
 1.0
, -
1.0
]]) 
Con la crosscorrelazione, l'output è 0 quando due elementi adiacenti 
dell'input sono uguali, altrimenti un valore diverso da 0.  
Nota
 : la crosscorrelazione corrisponde ad una approssimazione 
discreta della derivata del primo ordine.
"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#8,8,"Esempio: riconoscimento bordi
Si nota il risultato +1 nei bordi da bianco a nero, -1 da nero a bianco:  
Y = corr2d(X, K)  
Y 
<tf.Variable 
 'Variable:0'
  shape=(
 6
, 
7
) dtype=float32, numpy=  
array([[ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
], 
       [ 
 0.
,  
1.
,  
0.
,  
0.
,  
0.
, -
1.
,  
0.
]], dtype=float32)>  
Trasponendo l'immagine, il kernel non individua più i bordi:  
corr2d(tf.transpose(X), K)  
<tf.Variable 
 'Variable:0'
  shape=(
 8
, 
5
) dtype=float32, numpy=  
array([[
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
], 
       [
 0.
, 
0.
, 
0.
, 
0.
, 
0.
]], dtype=float32)>"
data_test\rootfolder\università\DeepLearning\05-CNN parte 2-sbloccato.pdf#9,9,"Kernel: training
Al principio non abbiamo kernel precostituiti, dobbiamo ottenerli 
durante l'addestramento, soprattutto se abbiamo molti layer convolutivi 
in cascata. Il procedimento è simile al caso MLP, es:  
# Un layer convolutivo, 2d con 1 canale in output, un kernel 1x2  
# Per semplicità ignoriamo i bias ora  
conv2d = tf.keras.layers.Conv2D(
 1
, (
1
, 
2
), use_bias=
 False
) 
# L'input è nella forma (batch_size, height, width, channel),  
# dove batch size e canali sono entrambi 1  
X = tf.reshape(X, (
 1
, 
6
, 
8
, 
1
)) 
Y = tf.reshape(Y, (
 1
, 
6
, 
7
, 
1
)) 
lr = 
3e-2  
# Learning rate  
Y_hat = conv2d(X)  
for
 i 
in 
range
(
10
): 
    
 with
 tf.GradientTape(watch_accessed_variables=
 False
) 
as
 g: 
        
 # indichiamo noi le variabili su cui operare il gradiente  
        g.watch(conv2d.weights[
 0
]) 
        Y_hat = conv2d(X)  
        l = (
 abs
(Y_hat - Y)) ** 
 2 
        
 # aggiornamento kernel  
        update = tf.multiply(lr, g.gradient(l, conv2d.weights[
 0
])) 
        weights = conv2d.get_weights()  
        weights[
 0
] = conv2d.weights[
 0
] - update  
        conv2d.set_weights(weights)  
        
 if
 (i + 
1
) % 
2
 == 
0
: 
            
 print
(
f'epoch 
 {
i + 
1
}
, loss 
{
tf.reduce_sum(l)
 :
.3f
}
'
) 
epoch 
2
, loss 
17.533 
epoch 
4
, loss 
3.607 
epoch 
6
, loss 
0.878 
epoch 
8
, loss 
0.259 
epoch 
10
, loss 
0.089 
# monitoriamo i tensori ottenuti  
tf.reshape(conv2d.get_weights()[
 0
], (
1
, 
2
))"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
3a parte
1"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#1,1,"Sommario
Calcolo del numero dei parametri  
LeNet-5 e calcolo dei parametri  
Architettura AlexNet  
1x1 convolution"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#10,10,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
11"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#11,11,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 .
12"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#12,12,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
13"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#13,13,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
14"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#14,14,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.
15"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#15,15,"CNN - Esercizio
Se le tue GPU non hanno memoria suf
 ﬁ
ciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?  
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers.  
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.  
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni  
ﬂ
oat a 16
  bit invece che 32.  
5.
Distribuire la computazione
  su più elaboratori.
16"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#16,16,"Architettura CNN più recenti
Ne sono state proposte molte. Anche se sviluppate in un particolare task di 
computer vision, esse sono state impiegate in modo pro
 ﬁ
cuo in altri domini, es. 
tracking, segmentation, object detection, style transformation.  
La challenge ImageNet (dal 2010) è favorito lo sviluppo di molte architetture.  
Le CNN sono relativamente semplici, ma creare una architettura ef
 ﬁ
ciente 
richiede intuizione, una base algebrica, e molti tentativi.  
Speso nuove architetture sfruttano elementi di architetture precedenti."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#17,17,"Architettura CNN più recenti #1
Sebbene LeNet sia ef
 ﬁ
ciente per il problema OCR, non si adatta facilmente a 
dataset più grandi ed eterogenei. Effettivamente dal 1995 (LeNet) al 2012 (AlexNet) 
sono state proposte tecniche ML alternative (es. kernels, ensemble, structured 
estimation) ef
 ﬁ
cienti in molti tasks.  
Perché abbiamo atteso così a lungo per avere una rete più versatile e capace di 
competere con le altre architetture ML?  
Nel anni '90 una scheda GPU come la NVIDIA GeForce 256 era capace di 480 
MFLOP, senza la disponibilità di framework software per sempli
 ﬁ
care la 
programmazione. Oggi la NVIDIA Ampere A100 raggiunge i 300 TFLOPS . Un 
dataset di cifre a bassa risoluzione (28x28) era considerato molto arduo da trattare.  
In pratica, era molto complesso testare architetture GPU-based anche su 
dataset semplici.  
I 
dati disponibili
  adatti all'addestramento sono aumentati sensibilmente, e questo 
ha garantito la sperimentazione di un numero maggiore di architetture.  
ImageNet è stato costruito mediante Google Image e per mezzo di Amazon 
Mechanical Turk per la classi
 ﬁ
cazione manuale."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#18,18,"LeNet vs AlexNet
AlexNet ha 8 layers: 5 convolutivi, 2 FC nascosti, 1 FC output.  
Usa la ReLU invece delle sigmoid o tanh.
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#19,19,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%) sviluppata da Alex Krizhevsky e 
Ilya Sutskever.  
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.  
E' molto simile a 
 LeNet-5
  ma con più profondità.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer.  
Impiega ReLI, SGD e 
momentum.  
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 NVIDIA 
GTX 580s con 3Gb)."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#2,2,"Calcolo del numero di parametri di una rete neurale
Il calcolo del numero di parametri è
  fondamentale per 
comprendere la complessità 
 della rete e apportare miglioramenti 
all'architettura (es. introducendo pooling layer per ridurre i 
parametri).  
Il calcolo dipende dal tipo di layer che stiamo considerando e dai 
valori ricevuti dal layer precedente.  
Consideriamo il calcolo del numero di parametri per le seguenti 
con
ﬁ
gurazioni:  
Un 
Convolutional layer 
 seguito da un 
 FC layer
   (
CONV
 FC
) 
Un
 Input layer 
 seguito da un 
 Convolutional layer
  (
I
FC
) 
Un 
FC layer 
 seguito da un 
 FC layer 
 (
FC
 FC
)
→
→
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#20,20,"Architettura AlexNet (2)
Le immagini di ImageNet sono 8x più grandi rispetto a MNIST.  
I LRF del primo strato sono 11x11, 5x5 nel secondo e 3x3 nel terzo.  
Dopo il primo, il secondo e 5o strato convolutivo, c'è un 
 max-pooling layers
  con 
ﬁ
nestra 3x3 e uno stride pari a 2.  
AlexNet ha 10 volte i canali di LeNet.  
La rete FC multi-layer ha 1Gb di parametri. La doppia pipeline di elaborazione 
permetteva di suddividere l'occupazione.  
Il numero elevato di parametri rende AlexNet poco ef
 ﬁ
ciente rispetto ad 
architetture più recenti.  
La ReLU rende la computazione dei gradienti più rapida. Inoltre se 
l'inizializzazione dei parametri porta a valori di attivazione vicini ad 1 o 0 
(estremi dell'intervallo) la derivata è vicina allo 0, e questo rallenta 
l'aggiornamento dei pesi. Il gradiente della ReLU è sempre 1 per valori positivi.  "
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#21,21,"Architettura AlexNet (3)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signi
 ﬁ
cativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
Il dropout nei layer FC prende il posto del weight decay della LeNet. Questo 
garantisce una sorta di regolarizzazione dei parametri  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#22,22,"Esempio: Filtri di AlexNet
Esempi di 
 ﬁ
ltri dei primi layer di Alex Net dopo l'addestramento:
"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#23,23,"AlexNet e Keras
08-AlexNet.ipynb"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#24,24,"La 
1
1 convolution
  è un 
 ﬁ
ltro di dimensione 
 1
1
C
 e (ovviamente) si 
applica a input con profondità 
 C
. 
•
Può essere vista come una 
 rete neurale con un layer,
  che prende in input 
un vettore di 
 C
 elementi.  
•
Per 
C
 pari a 
 1 
non viene impiegato  
•
Un 
ﬁ
ltro 1
 1
1 corrisponde ad una moltiplicazione per uno scalare, operazione 
inutile in una rete neurale.  
A cosa può servire?
×
 ×
×
×
×
CNN: 1
 1 convolution
×
output layer precedente :
supponi una profondità C > 1feature map  
avrà la stessa 
dimensione dell'input 
ma profondità pari a 1
dimensione LRF : 
11C××"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#25,25,"CNN: 1x1 convolution (2)
Effettua un 
 feature pooling
  cioè combina linearmente più features legate tra 
loro da un certa legame spaziale (es. i 3 valori dei canali RGB di un pixel).  
•
Utile quando si hanno feature maps con grande profondità e si vuole ridurre 
il numero di paremetri nei layer successivi.  
•
Mentre il 
 pooling
  tradizionale aggrega più feature vicine all'interno della 
stessa feature map.  
Se in input abbiamo una feature maps con profondità 
 C
, ogni mappa 
rappresenterà l'importanza di una diversa feature in una certa posizione. La  
1
1 convolution
  raccoglie le informazioni di 
 C
 features diverse valutate nella 
stessa posizione per determinare un singolo output.
×
1x1 conv
La profondità è passata da 32 a 1.  
Impiegano n ﬁltri 1x1 conv, 
otteniamo una profondità n della 
feature maps in output."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#26,26,"CNN: 1x1 convolution (3)
Oltre a ridurre il numero di parametri nei layer successivi in presenza di 
feature maps con grande profondità, la 
 1
1 convolution
  viene usata 
anche per creare nuove 
 proiezioni  
lineari
  a partire dalle feature map 
correnti.  
•
Le proiezioni creazioni 
 nuove features
  determinate dalla combinazioni 
di più feature maps nei layer precedenti. 
×
+verso i layer successivi..."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#3,3,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  nel layer convoluzionale, che 
produrranno i valori delle attivazioni nelle feature maps.  
•
Il layer di input non ha pesi associati.  
Se indichiamo con:  
•
#
W
c
 e #
B
c 
il numero di pesi e bias del layer convoluzionale  
•
f
 la dimensione del LRF  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
C
 profondità delle istanze in input (es. 3 per immagine a colori RGB)  
allora si ha:  
#
W
c
 = f
2 
 C 
 N
c 
    e    #
 B
c
 = N
 c 
Lo stesso risultato si ottiene per con
 ﬁ
gurazioni 
 CONV
 CONV
 , considerando come 
profondità 
 C
 la profondità delle feature maps nel layer precedente.  
Si nota come il numero di parametri è indipendente dalla dimensione X,Y dell'input.
×
×
→
Calcolo del numero dei parametri: 
 I
FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#4,4,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso alle 
feature maps prodotte dal convolutional layer precedente.  
Se indichiamo con:  
•
#
W
cf
 e #
B
cf  
il numero di pesi e bias del layer FC  
•
O
 dimensione delle feature maps nel convolutional layer, supponendo larghezza e 
altezza coincidenti.  
•
N
c
 numero dei 
 ﬁ
ltri nel convolutional layer  
•
F
 numero dei nodi nel layer FC  
allora si ha:  
#
W
cf
 = O
2 
 N
c 
 F 
   e   
 #B
cf
 = F  
Spesso si opera una ""
 linearizzazione
 "" dell'output del convolutional layer. Se 
abbiamo 
 N
c 
ﬁ
ltri e una dimensione delle feature maps pari a OxO, introduciamo 
una rappresentazione 1-dimensionale con un vettore di 
 O
2
• N
 c
 elementi, passato in 
input al layer fully-connected.
×
×
Calcolo del numero dei parametri: 
 CONV
 FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#5,5,"I 
parametri
  consistono nell’insieme dei 
 pesi e bias
  del layer FC connesso al FC 
precedente.  
Se indichiamo con:  
•
#
W
ff
 e #
B
ff 
 il numero pesi e bias del layer FC  
•
F
 il numero di nodi nel layer FC  
•
F
-1
 il numero di nodi nel layer FC precedente  
allora si ha:  
#W
 ff
 = F
 -1 
 F
    e   
 #B
ff
 = F
 ×
Calcolo del numero dei parametri: 
 FC
 FC
→"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#6,6,"LeNet-5: numero di parametri
Indichiamo con 
 f
, 
s
 e 
p
 rispettivamente la dimensione del 
 ﬁ
ltro, stride e 
pooling (dove 0 corrisponde al pooling VALID).
Non è un vero layer ,
ma una linearizzazione dei 
dati: rendiamo ﬂat la 
rappresentazion e
5x5x16 -> 40028x28x6  
feature maps di 6 ﬁltri 
di dimensione 28x28 l'uno
14x14x6  
un pooling layer con f e s pari 
a 2 dimezza le dimensioni ,
ma mantiene uguale la dept h
della feature maps."
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#7,7,"LeNet-5: numero di parametri (2)
Dopo la convoluzione 
abbiamo 6 ﬁltri 28x28. Dopo il pooling abbiamo  
6 ﬁltri 14x14
Invece di avere 240000 
parametri ne abbiamo 
151600 (vedi commento 
dopo).Stesso procedimento di S2 
ma ora abbiamo 16 ﬁltriPooling
Poolingncl-1 è la profondità  
del  layer precedente. 
supponiamo input depth = 1  
cioè scala di grigiil pooling layer non  
altera la profondità
ognuno dei 28x28 in output 
ha 5x5x6 connessioni col 
layer precedente, cioè 
l’immagine in input.Connections =  
28x28 x 5x5x1x6 = 117600
Connections =  
10x10x5x5x6x10 = 150000"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#8,8,"LeNet-5: peculiarità
Nel #3 hidden layer, con lo scopo di ridurre potenziali simmetrie e il numero di 
connessioni, gli autori hanno deciso che
  solo 10 delle 16 features maps sono connesse 
con le 6 features maps del layer precedente
 .  
La tecnica 
 dropout
  introdotta solo successivamente ha automatizzato questo step, 
perciò non si riscontra in architetture più recenti.
Schema di interconnessione tra feature maps impiegato.
Connections =  
10x10x5x5x6x10 = 150000"
data_test\rootfolder\università\DeepLearning\06-CNN parte 3-sbloccato.pdf#9,9,"LeNet-5: numero di parametri (3)
Rendiamo “ ﬂat” l’output 
precedente.  Abbiamo 400 
(5x5x16) nodi dal layer S4. 
Il primo strato fully 
connected layer ha 120 nodi. 
Ogni nodo del layer è 
connesso con i 400 nodi 
dello strato precedente.Fully connected layer con 
84 neuroni.softmax"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
4a parte - Architetture
1"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#1,1,"Sommario
Architetture avanzate CNN  
VGG  
NiN 
GoogleNet"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#10,10,"Poiché le risorse di calcolo necessarie alla VGG sono molto 
maggiori di AlexNet, costruiamo una rete con un numero minore di 
canali, suf
 ﬁ
cienti per il dataset Fashion-MNIST.  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
with
 d2l.try_gpu():  
    model = VGG(arch=((
 1
, 
16
), (
1
, 
32
), (
2
, 
64
), (
2
, 
128
), (
2
, 
128
)), lr=
0.01
) 
    trainer.fit(model, data)  
C'è una similarità tra val_loss e train_loss, con un discostamento 
minimale che può rappresentare un piccolo over
 ﬁ
tting.
Training VGG Network e Keras
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#11,11,"L'upsampling di Fashion-MNIST di un fattore 8 (da 28x28 a 
224x224) è molto inef
 ﬁ
ciente. Prova a modi
 ﬁ
care l'architettura per 
trattare immagini 28x28.
VGG - Esercizio"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#12,12,"Rispetto a LeNet, AlexNet e VGG intervengono principalmente 
creando strutture (conv_layer + pooling) più ""profonde"" e più 
""ampie"".  
Ma i layer FC 
 ﬁ
nali richiedono ancora molti parametri.  
Una semplice VGG-11 richiede matrici 25088x4096, con una 
occupazione di 400Mb di RAM (FP32). Non adatti a sistemi 
embedded e mobile.  
L'architettura Network in network (NiN) blocks consiste in un 1x1 
conv layer che aggiunge non-linearità tra le attivazioni dei canali, e 
un 
global average pooling
  nell'ultimo layer.
Network in Network (NiN)"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#13,13,"Rimpiazza i layer FC di una rete CNN tradizionale con un pooling.  
Prende in input un tensore 3d (height,width,channels) e ricava 
l'avg rispetto al dimensione channels.  
L'idea è generare una feature map per ogni categoria di interesse nel 
task nei layer 
 ﬂ
attening, inviando l'output direttamente alla softmax.  
Introduce una sorta di codi
 ﬁ
ca più diretta tra feature maps e 
categorie di interesse. Le feature maps possono essere interpretate 
come 
 mappe di con
 ﬁ
denze con le categorie
 . 
Non ci sono i parametri tradizionali, e si evitano fenomeni di 
over
ﬁ
tting.  
È più robusto a traslazioni spaziali poiché l'operazione considera 
tutte le informazioni spaziali disponibili.
Global average pooling
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#14,14,"Ricordiamo che l'input e output dei conv layers sono tensori 4d: 
istanze, channel, height e width.  
L'input e output di un layer FC sono tensori 2d (istanze, features).  
L'idea è applicare un FC layer a ogni posizione di pixel (per ogni 
height e width). La rete risultante 1x1 conv può essere interpretata 
come un layer FC indipendente per ogni pixel.  
Il blocco NiN è costituito da un conv layer seguito da convoluzioni 
1x1. 
In questo modo non c'è necessità di una grossa rete FC al termine 
dell'architettura.
Blocchi NiN"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#15,15,"La rete NiN usa le stesse dimensioni dei 
 ﬁ
ltri di AlexNet: 11x11, 5x5 
e 3x3; e le stesse dimensioni dei canali di output.  
Le conv net sono seguite da pooling layer 3x3 con stride 2.  
NiN non include FC layer. Il numero dei canali di output dei blocchi 
NiN corrispondono al numero di classi del task, seguite da un 
global average pooling
 , ottenendo un vettore di logits.  
L'architettura riduce il numero di parametri a scapito del tempo di 
training, più lungo.
Architettura NiN"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#16,16,"Architettura NiN
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#17,17,"NiN in codice Keras:  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
def 
nin_block
 (out_channels, kernel_size, strides, padding):  
    
 return
 tf.keras.models.Sequential([  
    tf.keras.layers.Conv2D(out_channels, kernel_size, strides=strides,  
                           padding=padding),  
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
), 
    tf.keras.layers.Conv2D(out_channels, 
 1
), 
    tf.keras.layers.Activation(
 'relu'
)])
Blocco NiN in Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#18,18,"class 
NiN
(d2l.Classifier):  
    
 def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            nin_block(
 96
, kernel_size=
 11
, strides=
 4
, padding=
 'valid'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 256
, kernel_size=
 5
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            nin_block(
 384
, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
), 
            tf.keras.layers.Dropout(
 0.5
), 
            nin_block(num_classes, kernel_size=
 3
, strides=
 1
, padding=
 'same'
), 
            tf.keras.layers.GlobalAvgPool2D(),  
            tf.keras.layers.Flatten()])  
model = NiN()  
X = tf.random.normal((
 1
, 
224
, 
224
, 
1
)) 
for
 layer 
 in
 model.net.layers:  
    X = layer(X)  
    
print
(layer.
__class__
 .
__name__
 ,
'output shape:
 \t
'
, X.shape)  
Sequential output shape:     (
 1
, 
54
, 
54
, 
96
) 
MaxPooling2D output shape:   (
 1
, 
26
, 
26
, 
96
) 
Sequential output shape:     (
 1
, 
26
, 
26
, 
256
) 
MaxPooling2D output shape:   (
 1
, 
12
, 
12
, 
256
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
384
) 
MaxPooling2D output shape:   (
 1
, 
5
, 
5
, 
384
) 
Dropout output shape:        (
 1
, 
5
, 
5
, 
384
) 
Sequential output shape:     (
 1
, 
5
, 
5
, 
10
) 
GlobalAveragePooling2D output shape:         (
 1
, 
10
) 
Flatten output shape:        (
 1
, 
10
)
Architettura NiN in Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#19,19,"model = NiN(lr=
 0.05
) 
trainer = d2l.Trainer(max_epochs=
 10
, num_gpus=
 1
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 224
, 
224
)) 
model.apply_init([
 next
(
iter
(data.get_dataloader(
 True
)))[
0
]], d2l.init_cnn)  
trainer.fit(model, data)  
Training NiN in Keras
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#2,2,"Networks Using Blocks (VGG)
Sebbene 
 AlexNet
  abbia permesso di ottenere buone performance in 
diversi task, non fornisce dei 
 template
  per la realizzazione di nuove 
architetture.  
Il Visual Geometry Group Oxford University ha de
 ﬁ
nito 
l'architettura VGG che consiste in strutture ripetute de
 ﬁ
nite per 
mezzo di istruzioni di loop e subroutines.  
Il 
blocco
  fondamentale della CNN è una sequenza di (i) 
convolutional layer con padding (ii) nonlinearità come la ReLU, (iii) 
pooling layer per ridurre la risoluzione.  
Il problema di questo approccio è che la risoluzione spaziale si 
riduce abbastanza rapidamente. Introduce il limite rigido di 
 log
2
d 
layer convolutivi prima che tutte le dimensioni (
 d
) si esauriscano.  
Per esempio per 
 ImageNet
  non si possono avere più di 8 layer."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#20,20,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁ
ltri negli strati iniziali.  
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#21,21,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identi
 ﬁ
cate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei 
 ﬁ
ltri
. Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo.  
•
Si impiegano 
 ﬁ
ltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function.  
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 ."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#22,22,"CNN: Inception module (GoogleNet)
GoogleNet ha vinto la challenge ImageNet 2015 con una struttura 
che combina le caratteristiche di NiN, blocchi ripetuti, e un mix di 
kernel convolutivi.  
Crea una distinzione tra:  
stem
 (data ingest), primi 2-3 conv layers per estrarre feature a 
basso livello  
body
  (data processing), serie di blocchi convolutivi  
head
  (prediction), per problemi di classi
 ﬁ
cation, segmentation, 
detection, o tracking.  
L'idea è combinare l'output di più conv layer con diverse 
dimensioni in un unico output "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#23,23,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempli
 ﬁ
care i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali.  
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5.  
•
Sperimentalmente si nota come gli inception module sono più 
ef
ﬁ
cienti se usati negli layer più a valle.
Inception module
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#24,24,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri.  
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#25,25,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classi
 ﬁ
cazione 
 per mezzo di una softmax.  
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer.  
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati.  
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più ef
 ﬁ
ciente il training e migliorare l’accuracy.
auxiliary classi ﬁerauxiliary classi ﬁer"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#26,26,"GoogLeNet: esempio di 
 ﬁ
ltri
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#27,27,"Inception e Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
Inception
 (tf.keras.Model):  
    
# `c1`--`c4` sono il numero di canali in output per ogni ramo  
    
 def 
__init__
 (
self
, c1, c2, c3, c4):  
        
 super
().
__init__
 () 
        
 self
.b1_1 = tf.keras.layers.Conv2D(c1, 
 1
, activation=
 'relu'
) 
        
 self
.b2_1 = tf.keras.layers.Conv2D(c2[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b2_2 = tf.keras.layers.Conv2D(c2[
 1
], 
3
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b3_1 = tf.keras.layers.Conv2D(c3[
 0
], 
1
, activation=
 'relu'
) 
        
 self
.b3_2 = tf.keras.layers.Conv2D(c3[
 1
], 
5
, padding=
 'same'
, 
                                           activation=
 'relu'
) 
        
 self
.b4_1 = tf.keras.layers.MaxPool2D(
 3
, 
1
, padding=
 'same'
) 
        
 self
.b4_2 = tf.keras.layers.Conv2D(c4, 
 1
, activation=
 'relu'
) 
    
 def 
call
(
self
, x): 
        b1 = 
 self
.b1_1(x)  
        b2 = 
 self
.b2_2(
self
.b2_1(x))  
        b3 = 
 self
.b3_2(
self
.b3_1(x))  
        b4 = 
 self
.b4_2(
self
.b4_1(x))  
        
 return
 tf.keras.layers.Concatenate()([b1, b2, b3, b4])"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#28,28,"GoogleNet e Keras
Uno stack di 9 blocchi 
 inception, 
 organizzati in 3 gruppi 
intramezzati da max-pooling per ridurre le dimensioni, e un global 
average pooling per generare l'ultimo output prima del FC layer.
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#29,29,"GoogleNet e Keras
class 
GoogleNet
 (d2l.Classifier):  
    
 def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, 
7
, strides=
 2
, padding=
 'same'
, 
                                   activation=
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b2
(
self
): 
    
 return
 tf.keras.Sequential([  
        tf.keras.layers.Conv2D(
 64
, 
1
, activation=
 'relu'
), 
        tf.keras.layers.Conv2D(
 192
, 
3
, padding=
 'same'
, activation=
 'relu'
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b3
(
self
): 
    
 return
 tf.keras.models.Sequential([  
        Inception(
 64
, (
96
, 
128
), (
16
, 
32
), 
32
), 
        Inception(
 128
, (
128
, 
192
), (
32
, 
96
), 
64
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#3,3,"VGG Blocks
L'idea è di impiegare convoluzioni multiple e distinte tra periodici 
downsampling (eg. max-pooling) sotto forma di unico blocco 
funzionale.  
L'ipotesi che 
 diverse dimensioni di convoluzioni (deep e wide) 
possono meglio rappresentare le features signi
 ﬁ
cative
 .  
Per esempio 3x3 convolutions interessa gli stessi pixel della 5x5 
convolutions. Ma l'ultima usa un numero di parametri (
 25•c
2
) come 
tre 3x3 convolutions (
 3•9•c
2
), cioè uno 
 stacking
  di convoluzioni 
3x3. Dimostrano che tali con
 ﬁ
gurazioni (deep & narrow) ottengono 
prestazioni migliori.  
La dimensione della rete con stacking 3x3 può oltrepassare i 100 
layers, un approccio molto comune nelle moderne architetture."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#30,30,"GoogleNet e Keras
@d2l
.add_to_class(GoogleNet)  
def 
b4
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 192
, (
96
, 
208
), (
16
, 
48
), 
64
), 
        Inception(
 160
, (
112
, 
224
), (
24
, 
64
), 
64
), 
        Inception(
 128
, (
128
, 
256
), (
24
, 
64
), 
64
), 
        Inception(
 112
, (
144
, 
288
), (
32
, 
64
), 
64
), 
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, padding=
 'same'
)]) 
@d2l
.add_to_class(GoogleNet)  
def 
b5
(
self
): 
    
 return
 tf.keras.Sequential([  
        Inception(
 256
, (
160
, 
320
), (
32
, 
128
), 
128
), 
        Inception(
 384
, (
192
, 
384
), (
48
, 
128
), 
128
), 
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Flatten()])  
@d2l
.add_to_class(GoogleNet)  
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
    
super
(GoogleNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.Sequential([  
        
 self
.b1(), 
self
.b2(), 
self
.b3(), 
self
.b4(), 
self
.b5(), 
        tf.keras.layers.Dense(num_classes)])  "
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#31,31,"GoogleNet e Keras
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
model = GoogleNet().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
192
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
480
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
832
) 
Sequential output shape:     (
 1
, 
1024
) 
Dense output shape:  (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = GoogleNet(lr=
 0.01
) 
    trainer.fit(model, data)  
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#32,32,"GoogleNet - vantaggi
GoogleNet richiede meno potenza di calcolo rispetto alle 
architetture precedenti mantenendo una precisione più elevata.  
L'approccio è basato sulla approssimazione dell'architettura senza 
andare a scapito delle prestazioni.  
Introduce un 
 design by block
 , con iperparametri più ""ad alto livello""."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#33,33,"Architetture AlexNet, VGG, NiN, GoogleNet
Esercizio
 : valuta la differenza di prestazioni e i tempi di 
addestramento su medesimi dataset (FashionMNIST) o subset di 
dataset più complessi (ImageNet)."
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#34,34,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza.  
35
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#35,35,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Scarica alcune immagini di animali, ad esempio usando la funzion 
matplotlib.image.mpimg.imread(). Ridimensionali e fai crop 299x299 pixel, 
con 3 canali RGB.  
•
Scarica i modelli pre-addestrati di Inception v3  
•
https://github.com/tensor
 ﬂ
ow/models/tree/master/research/slim  
•
Crea il modello Inception v3 usando la funzione inception_v3() con 
is_training=False, num_classes=1001 nel seguente modo:  
from 
 tensor
 ﬂ
ow.contrib.slim.nets 
 import 
 inceptio
 n
import 
 tensor
 ﬂ
ow.contrib.slim 
 as 
sli
m
X 
= 
tf
.
placeholder
 (
tf
.
ﬂ
oat32
 , 
shape
 =[
None
 , 
299
, 
299
, 
3
]
)
with 
slim
.
arg_scope
 (
inception
 .
inception_v3_arg_scope
 ())
:
logits
 , 
end_points 
 = 
inception
 .
inception_v3
 (
X
, 
num_classes
 =
1001
 , 
is_training
 =
False
 )
predictions 
 = 
end_points
 [
""Predictions""
 ]
saver 
 = 
tf
.
train
.
Saver
 (
)
•
...
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#36,36,"Esercizio su Inception v3 e classi
 ﬁ
cazione di immagini
... Problema di classi
 ﬁ
cazione di immagini usando Inception v3  
•
Crea una sessione e usa Saver per recuperare il modello pre-addestrato.  
•
Lancia il modello per addestrare le immagini che hai scaricato visualizzando 
le top-5 predictions e la relativa probabilità.  
•
I nomi delle categorie le trovi qui: 
 https://github.com/ageron/handson-ml/
blob/master/datasets/inception/imagenet_class_names.txt  
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#4,4,"VGG Blocks in Keras
Un funzione che prende come parametri il numero di layer 
convolutivi e il numero di channel di output  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2l
def 
vgg_block
 (num_convs, num_channels):  
    blk = tf.keras.models.Sequential()  
    
 for
 _ 
in 
range
(num_convs):  
        blk.add(  
            tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                   padding=
 'same'
, activation=
 'relu'
)) 
    blk.add(tf.keras.layers.MaxPool2D(pool_size=
 2
, strides=
 2
)) 
    
 return
 blk"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#5,5,"L'architettura VGG e AlexNet a confronto, con i blocchi funzionali 
che si ripetono:
VGG Network e AlexNet
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#6,6,"L'aspetto distintivo sono i layer convolutivi,raggruppati in 
trasformazioni non lineari che medesima dimensione per gruppo.  
Si impiegano 
 ﬁ
ltri 
3x3
 con zero padding in modo da scorrere 
l'intera l'immagine.  
Successivamente c'è lo step di riduzione della risoluzione (2x2 
pooling)  
Al termine ci sono layer FC  
Nota: 100M di parametri nei FC in confronto dei 40M degli strati 
convolutivi
VGG Network"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#7,7,"VGG Network - Dettaglio parametri
"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#8,8,"La prima parte della rete VGG è una successione di blocchi VGG.  
La conv_arch consiste in una lista di tuple (una per blocco), ognuna 
che contiene 2 valori: il numero di conv layers e il numero di 
canali.  
class 
VGG
(d2l.Classifier):  
    
 def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential()  
        
 for
 (num_convs, num_channels) 
 in
 arch: 
            
 self
.net.add(vgg_block(num_convs, num_channels))  
        
 self
.net.add(  
            tf.keras.models.Sequential([  
            tf.keras.layers.Flatten(),  
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(
 4096
, activation=
 'relu'
), 
            tf.keras.layers.Dropout(
 0.5
), 
            tf.keras.layers.Dense(num_classes)]))  
VGG Network e Keras"
data_test\rootfolder\università\DeepLearning\07-CNN parte 4-sbloccato.pdf#9,9,"La VGG originale chiamata 
 VGG-11
  ha 5 blocchi: i primi 2 con un 
conv layer ognuno, e gli 3 con 2 conv layer ognuno. Il 1o blocco ha 
64 canali, e i successivi raddoppiato i canali, 
 ﬁ
no a 512.  
VGG(arch=((
 1
, 
64
), (
1
, 
128
), (
2
, 
256
), (
2
, 
512
), (
2
, 
512
))).layer_summary(  
    (
1
, 
224
, 
224
, 
1
)) 
Sequential output shape:     (
 1
, 
112
, 
112
, 
64
) 
Sequential output shape:     (
 1
, 
56
, 
56
, 
128
) 
Sequential output shape:     (
 1
, 
28
, 
28
, 
256
) 
Sequential output shape:     (
 1
, 
14
, 
14
, 
512
) 
Sequential output shape:     (
 1
, 
7
, 
7
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
La dimensione 
 ﬁ
nale dopo la sequenza dei blocchi è 7x7, seguita 
dal 
ﬂ
attening e il successivo processamento FC.
VGG Network e Keras"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Convolutional Neural Networks (CNN)  
5a parte - Batch Normalization e ResNet
1"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#1,1,"Sommario
Internal covariate shift  
Batch normalization  
Architettura Residual Network (ResNet)"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#10,10,"Batch Normalization layer
Poiché la BN dipende dalla dimensione del mini batch, e perciò dai dati di 
training, non possiamo ignorarla quando de
 ﬁ
niamo la nostra architettura.  
Per reti FC si può applicare la BN tra la trasformazione lineare e il calcolo 
della funzione di attivazione.  
Per conv layers l'approccio è simile, ma consideriamo la BN per ogni 
singolo canale, valutandola sui i dati sparsi spazialmente. Perciò ogni canale 
avrà una stima diversa di media e deviazione standard.  
Questo è in linea col principio di 
 invarianza spaziale
 , cioè nel calcolo 
possiamo ignorare l'informazione relativa alla posizione.
11"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#11,11,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci:
12"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#12,12,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).
13"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#13,13,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 .
14"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#14,14,"Batch Normalization - Altri vantaggi
Si dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, 
garantisce ulteriori bene
 ﬁ
ci: 
•
Permette di impiegare
  funzioni di attivazione che saturano
  per input molto 
grandi o piccoli (es. logistic e tanh).  
•
Riduce la dipendenza 
 sugli effetti di una certa 
 scelta dei parametri iniziali
 . 
•
Richiamo: Introduce una certa 
 regolarizzazione 
 dei parametri, sebbene non 
sostituisce le tecniche più ef
 ﬁ
caci (es. dropout)  
•
Richiamo: Permette l'uso di 
 learning rate più elevati
 , riducendo i tempi di 
apprendimento.  
•
Es. Per un tipico task di image classi
 ﬁ
cation, si ottengono incrementi x14.
15"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#15,15,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?
16"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#16,16,"Batch Normalization
Perché non ci limitiamo a normalizzare i dati in input ad ogni layer  
e lasciare alla rete determinare i parametri W per l'ottimalità input-output?  
Se impieghiamo funzioni di attivazioni logistiche, 
 forziamo al rete a 
lavorare in regime di quasi-linearità
 , riducendo la capacità di costruire 
relazioni input-output non lineari.
17"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#17,17,"Batch Normalization e LeNet - Keras
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
class 
BNLeNet
(d2l.Classifier):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 () 
        
 self
.save_hyperparameters()  
        
 self
.net = tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(filters=
 6
, kernel_size=
 5
, 
                                   input_shape=(
 28
, 
28
, 
1
)), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Conv2D(filters=
 16
, kernel_size=
 5
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.AvgPool2D(pool_size=
 2
, strides=
 2
), 
            tf.keras.layers.Flatten(), tf.keras.layers.Dense(
 120
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(
 84
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'sigmoid'
 ), 
            tf.keras.layers.Dense(num_classes)])  
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
) 
with
 d2l.try_gpu():  
    model = BNLeNet(lr=
 0.5
) 
    trainer.fit(model, data)
18
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#18,18,"Architettura Residual Network - Motivazioni
In generale, architetture di reti complesse (es. più profonde) possono stimare 
una classe più ampia di funzioni. Ma se aggiungiamo layer, nessuno ci 
garantisce che l'apprendimento ci permette di trovarle, anzi in taluni casi 
possiamo allontanarci dall'ottimo.  
Inoltre reti profonde potrebbero soffrire del vanishing gradient problem.  
Ma se aggiungiamo layer che mirano a stimare una funzione identità, i.e., 
f(x)=x, sicuramente manteniamo la stessa ef
 ﬁ
cacia della rete iniziale.  
L'ipotesi è che, i layer che aggiungiamo alla rete dovrebbero avere più 
probabilità nel rappresentare funzioni identità per garantire prestazioni ottimali."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#19,19,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers.  
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice e veloce propagare segnali 
 su varie parti 
della rete.  
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#2,2,"Motivazioni
L'addestramento delle architetture Deep mostra alcune problematiche 
aggiuntive oltre quelle già discusse per le MLP. Una signi
 ﬁ
cativa è il tempo 
necessario per addestrarle.  
Spesso si operano 
 standardizzazioni
  nei valori delle features in ingresso con 
forme di pre-processamento, es:  
imporre µ=0 (zero mean) o la unit-variance (cioè dividere per la stddev)  
zero mean
  sul valore delle features, considerando la singola istanza; spesso 
utile per dati con informazioni spaziali.  
Ci garantisce che durante l'addestramento i valori dei parametri rimangano in 
intervalli ottimali, sia considerando i layer per l'intera profondità della rete, sia 
tra i nodi di un singolo layer, sia tra i valori di ogni parametro per la durata 
dell'addestramento."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#20,20,"ResNet: Residual learning e residual block
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning o mapping
 . 
Dal punto di vista operativo, è suf
 ﬁ
ciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#21,21,"Architettura ResNet
L'architettura ResNet impiega conv layer 3x3 (simili a VGG).  
Ogni blocco ResNet ha due 3x3 conv layer seguite dalla batch normalization e 
attivazione ReLU. Prima dell'ultima ReLU sommiamo l'input dalla skip 
connection.  
La 1x1 conv layer è necessaria per adattare i canali dell'input con quelli 
ottenuti a valle del blocco.
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#22,22,"Blocco ResNet e Keras
class 
Residual
 (tf.keras.Model):  
    
def 
__init__
 (
self
, num_channels, use_1x1conv=
 False
, strides=
 1
): 
        
 super
().
__init__
 () 
        
 self
.conv1 = tf.keras.layers.Conv2D(num_channels, padding=
 'same'
, 
                                            kernel_size=
 3
, strides=strides)  
        
 self
.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 3
, 
                                            padding=
 'same'
) 
        
 self
.conv3 = 
 None 
# dipende se vogliamo usare o meno il 1x1 conv layer  
        
 if
 use_1x1conv:  
            
 self
.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=
 1
, 
                                                strides=strides)  
        
 self
.bn1 = tf.keras.layers.BatchNormalization()  
        
 self
.bn2 = tf.keras.layers.BatchNormalization()  
    
def 
call
(
self
, X): 
        Y = tf.keras.activations.relu(
 self
.bn1(
self
.conv1(X)))  
        Y = 
 self
.bn2(
self
.conv2(Y))  
        
 if 
self
.conv3 
is 
not 
None
: 
            X = 
 self
.conv3(X)  
        Y += X  
        
 return
 tf.keras.activations.relu(Y)  
blk = Residual(
 3
) 
X = tf.random.normal((
 4
, 
6
, 
6
, 
3
)) 
Y = blk(X)  
Y.shape 
TensorShape([
 4
, 
6
, 
6
, 
3
]) "
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#23,23,"Architettura ResNet-18
I primi layer di ResNet sono simili a GoogleNet, ma in ResNet si usa la Batch 
normalization.  
Seguono vari moduli ripetuti ResNet. La ResNet-18 include 18 layer totali, ma 
si hanno modelli addestrati con molti più layer, es. ResNet-152.
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#24,24,"Architettura ResNet e Keras
class 
ResNet
(d2l.Classifier):  
    
def 
b1
(
self
): 
        
 return
 tf.keras.models.Sequential([  
            tf.keras.layers.Conv2D(
 64
, kernel_size=
 7
, strides=
 2
, 
                                   padding=
 'same'
), 
            tf.keras.layers.BatchNormalization(),  
            tf.keras.layers.Activation(
 'relu'
), 
            tf.keras.layers.MaxPool2D(pool_size=
 3
, strides=
 2
, 
                                      padding=
 'same'
)]) 
@d2l
.add_to_class(ResNet)  
def 
block
(
self
, num_residuals, num_channels, first_block=
 False
): 
    blk = tf.keras.models.Sequential()  
    
for
 i 
in 
range
(num_residuals):  
        
 if
 i == 
0 
and 
not
 first_block:  
            blk.add(Residual(num_channels, use_1x1conv=
 True
, strides=
 2
)) 
        
 else
: 
            blk.add(Residual(num_channels))  
    
return
 blk 
@d2l
.add_to_class(ResNet)  
def 
__init__
 (
self
, arch, lr=
 0.1
, num_classes=
 10
): 
    
super
(ResNet, 
 self
).
__init__
 () 
    
self
.save_hyperparameters()  
    
self
.net = tf.keras.models.Sequential(
 self
.b1()) 
    
for
 i, b 
in 
enumerate
 (arch): 
        
 self
.net.add(
 self
.block(*b, first_block=(i==
 0
))) 
    
self
.net.add(tf.keras.models.Sequential([  
        tf.keras.layers.GlobalAvgPool2D(),  
        tf.keras.layers.Dense(units=num_classes)]))  "
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#25,25,"Architettura ResNet e Keras
class 
ResNet18
 (ResNet):  
    
def 
__init__
 (
self
, lr=
0.1
, num_classes=
 10
): 
        
 super
().
__init__
 (((
2
, 
64
), (
2
, 
128
), (
2
, 
256
), (
2
, 
512
)), 
                       lr, num_classes)  
ResNet18().layer_summary((
 1
, 
96
, 
96
, 
1
)) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
24
, 
24
, 
64
) 
Sequential output shape:     (
 1
, 
12
, 
12
, 
128
) 
Sequential output shape:     (
 1
, 
6
, 
6
, 
256
) 
Sequential output shape:     (
 1
, 
3
, 
3
, 
512
) 
Sequential output shape:     (
 1
, 
10
) 
trainer = d2l.Trainer(max_epochs=
 10
) 
data = d2l.FashionMNIST(batch_size=
 128
, resize=(
 96
, 
96
)) 
with
 d2l.try_gpu():  
    model = ResNet18(lr=
 0.01
) 
    trainer.fit(model, data)  
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#26,26,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?
27"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#27,27,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.
28"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#28,28,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.
29"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#29,29,"CNN - Esercizio
Quali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda 
GoogleLeNet e ResNet?  
•
AlexNet
  è più profonda e ampia rispetto a LeNet-5, e crea stack di 
convolutional layer uno sull'altro, invece di alternarli con pooling layer.  
•
GoogleNet
  impiega inception modules, che permettono di avere reti ancora 
più profonde ma con meno parametri rispetto alle precedenti.  
•
ResNet
  introduce le skip connections, che permettono un numero di layer 
oltre i 100. Anche la relativa semplicità la contraddistingue. 
30"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#3,3,"Motivazioni
Inoltre un layer che produce valori di attivazione molto elevati rispetto agli altri 
(es. x100) richiede aggiustamenti (es. modi
 ﬁ
cando il learning rate in modo 
adattivo per produrre variazioni più ef
 ﬁ
caci durante il training).  
In
ﬁ
ne, per affrontare l'over
 ﬁ
tting è spesso utile introdurre 
 regolarizzazioni
  sul 
valore dei parametri (es. aggiungendo del rumore)."
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#30,30,"Esercizio su CNN e MNIST
Prova costruire una tua architettura CNN (cioè con uno o più convolution 
layers, pooling layers, etc) per raggiungere la migliore accuratezza per i 
dataset MNIST.  
•
MNIST dataset: 
 http://yann.lecun.com/exdb/mnist/   
•
MNIST e Tensor
 ﬂ
ow: 
https://www.tensor
 ﬂ
ow.org/quantum/tutorials/mnist  
"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#4,4,"Internal covariate shift
Con 
Internal covariate shift
  si indica la circostanza in cui 
 la distribuzione 
dei valori di attivazione nella rete cambia a causa della variazione dei 
parametri durante il training
 .  
•
Fenomeno fondamentale nelle architetture deep (con molti layers).  
•
E' chiaro che i parametri in
 ﬂ
uenzano le attivazioni, ma 
 la distribuzione 
dei valori 
 non dovrebbe alterarsi a causa dei parametri.  
•
Il vanishing/exploding gradient ricade in questa circostanza.  
•
ReLU, e le sue varianti, riducono il fenomeno ma non lo escludono.  
L'obiettivo è ridurre il 
 covariance shift
  all'interno della reti.
5"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#5,5,"Batch Normalization
La 
batch normalization
  (
BN
) è una tecnica per affrontare tale problema. 
Prima della funzione di attivazione di ogni layer:  
•
Normalizza gli input
 , centrandoli in 0 e dividendoli per la deviazione 
standard 
 σ
. 
•
Introduce 
 2 parametri
 , uno per determinare la 
 scalatura
  e uno per lo 
 shift
. 
Tali parametri saranno soggetti ad addestramento.  
Dopo la normalizzazione 
 la rete apprende il valore medio e la scala più 
giusta degli input per ogni layer
 . 
•
La normalizzazione è frequente nei dati in ingresso degli approcci basati su 
ML. La tecnica proposta estende tale tecnica ad ogni layer della rete.  
Per normalizzare bisogna prima conoscere valor medio e varianza dei dati. 
Si stimano entrambi 
 impiegando 
 mini-batch,  
cioè un piccolo sottoinsieme 
del training set. Da questo il termine 
 batch normalization
 .
6"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#6,6,"Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
7
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#7,7,"Batch Normalization - Considerazioni
La tecnica BN può essere impiegata sui singoli layer, soprattutto sugli 
hidden, oppure all'intera rete.  
La stima di media e deviazione standard sono ricavate sul mini batch 
corrente.  
Possiamo interpretare i parametri 
 scale
  e 
offset
  stimati durante 
l'apprendimento come un mezzo per ""recuperare"" i gradi di libertà persi a 
causa della normalizzazione e limitarsi a considerare mini-batch invece 
dell'intero dataset.  
Con mini-batch di dimensione adeguata (un iperparametro da de
 ﬁ
nire) si 
raggiungono buoni incrementi di prestazioni e una 
 stabilità
  nell'andamento. 
Ma richiede un tuning che dipende dai dati impiegati.  
La tecnica non permette al valore dei parametri di divergere. Inoltre permette 
di incrementare il 
 learning rate
 . 
8"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#8,8,"Batch Normalization - Considerazioni (2)
Può sembrare illogico introdurre approssimazioni nei valori di media e 
deviazione standard, ma nella pratica rappresentano una sorta di rumore 
introdotto arti
 ﬁ
cialmente che garantisce tempi più rapidi e minor effetto 
over
ﬁ
tting.  
Valori spesso ottimali della dimensione del mini batch sono 50-100 istanze, 
che garantiscono la giusta 
 quantità di rumore
  introdotto durante 
l'apprendimento.
9"
data_test\rootfolder\università\DeepLearning\08-CNN parte 5-sbloccato.pdf#9,9,"Batch Normalization - Considerazioni (3)
In casi particolari 
 γ
 e 
β
 possono assumere valori tali da ""invertire"" il processo 
di normalizzazione degli input del processo di 
 batch normalization
 , se 
questo garantisce l'ottimalità durante il training.  
La BN può essere vista come una 
 trasformazione lineare
 , perciò facilmente 
differenziabile
  durante il calcolo dei gradienti.  
La normalizzazione basata su mini-batch è essenziale per garantire 
l'ef
ﬁ
cienza di tale tecnica, ma è inutile nel test e in produzione.  
In 
produzione
  vogliamo una rete che renda l'output dipendente 
unicamente e deterministicamente dall'input
 , perciò non in
 ﬂ
uenzata 
dallo speci
 ﬁ
co mini-batch.  
Per tale motivo la normalizzazione sarà calcolata sull'intera popolazione 
 {x} 
con valori di media e varianza costanti durante l'elaborazione:
10
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep
1"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#1,1,"Sommario
Motivazioni dell'apprendimento speci
 ﬁ
co per reti Deep  
Vanishing/Exploding gradients  
La funzione di attivazione softmax  
Inizializzazione dei parametri  
Funzione di attivazione ReLU e variazioni  
Batch normalization  
Gradient clipping  
Reusing Pretrained layers - Transfer learning  
Unsupervised Pretraining  
Pretraining su Auxiliary tasks"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#10,10,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
11"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#11,11,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
12"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#12,12,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
13"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#13,13,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
14"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#14,14,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
15"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#15,15,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
16"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#16,16,"Inizializzazione di Xavier e He  
Schema di dimostrazione
Impiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché 
porre un vincolo sulla varianza?  
Consideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore 
X
 di 
n
 elementi, con una matrice di pesi 
 W 
si ha:  
                             
Vale anche:  
                      
Supponendo 
 X
 e 
y
 indipendenti, vale la seguente uguaglianza:  
             
Avendo media pari a 0, si riduce a:   
Supponendo 
 w
i
 e 
x
i  
indipendenti, e ogni 
 w
i
 (e 
x
i
) generato con stessa distribuzione, si ha:  
  
Se imponiamo che le due varianza 
  e 
  siano identiche, allora otteniamo:  
y
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
σ
2
(
y
)
=
σ
2
(
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
+
b
)
σ
2
(
w
i
x
i
)
=
μ
(
x
i
)
2
σ
2
(
w
i
)
+
μ
(
w
i
)
2
σ
2
(
x
i
)
+
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
w
i
x
i
)
=
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
=
n
⋅
σ
2
(
w
i
)
σ
2
(
x
i
)
σ
2
(
y
)
σ
2
(
x
i
)
σ
2
(
w
i
)
=
1
n
17"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#17,17,"Altre inizializzazioni
Ricerche più recenti adattano la suddetta inizializzazione considerando 
diversi scenari di funzione attivazione
 , dove si distinguono per ogni layer il 
numero di connessioni in input (
 n
inputs
) e in output (
 n
outputs
 ). 
Riferimenti:  
•
He et al. 
 Delving Deep into Recti
 ﬁ
ers: Surpassing Human-Level Performance on ImageNet Classi
 ﬁ
cation
  2015
18
Hu initialization →"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#18,18,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?
19"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#19,19,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.
20"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo visto architetture di Reti neurali (
 NN
) con più strati (
 layer
 ), ognuno 
composto da molti nodi completamente connessi con i layer precedenti e 
successivi (
 fully connected
 ). 
L'addestramento (training) di tali architetture mostra le seguenti 
problematiche:  
•
Vanishing gradients
  o 
Exploding gradients
 : che rendono la ricerca dei 
parametri molto dif
 ﬁ
cile 
•
Lentezza
 : la stima di molti parametri richiede molto tempo  
•
Over
 ﬁ
tting
: la presenza di molti parametri aumenta la possibilità di 
over
ﬁ
tting (cioè mancanza di generalizzazione).  
Per tale motivo introduciamo
  tecniche di addestramento speci
 ﬁ
che
 per 
affrontarle, che permettono di de
 ﬁ
nire architetture NN più complesse e 
deep
 .
3"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#20,20,"Inizializzazione dei pesi
Perché non usiamo la 
 zero initialization
  (valori iniziali tutti uguali a 0)?  
1.
Valori dei pesi prossimi allo 0 favoriscono i vanishing gradients 
problem
 . 
•
Allo stesso modo, valori troppo grandi ""saturano"" la logistic function, 
generando gradienti vicini allo 0.  
2.
Per 
valori prossimi allo 0 la logistic function si comporta in modo 
lineare
 .  
•
Tale comportamento ci preclude l'addestramento di funzioni complesse e non 
lineari, anche in presenza di più layer.
21"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#21,21,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?
22"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#22,22,"Inizializzazione dei pesi
Perché non scegliere un singolo valore random diverso da 0 per tutti i 
pesi?  
1.
Avere 
 una rete inizializzata con gli stessi valori implica avere stessi 
gradienti e stessi aggiornamenti per ogni nodo di un layer
 .  
•
Uno degli obiettivi della inizializzazione dei parametri è 
 rompere eventuali 
simmetrie
  nel comportamento della rete.  
•
La simmetria 
 non permette di specializzare diversi neuroni su diversi scopi
 .  
•
Un layer con tutti nodi con lo stesso peso è equivalente ad un layer con un 
singolo nodo.  
•
La 
backpropagation  
non è in grado di risolvere in modo adeguato questo tipo 
di simmetrie
 .
23"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#23,23,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?
24"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#24,24,"Inizializzazione dei pesi
Possiamo inizializzare il valore dei bias a 0?  
•
È possibile inizializzare i 
 bias
 a 0, oppure seguire il procedimento di 
inizializzazione usato per i pesi 
 w
.
25"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#25,25,"Inizializzazione dei pesi e softmax
La 
softmax
  è spesso usata nella classi
 ﬁ
cazione multi label.  
Tende a dare 
 molta più probabilità
  alle classi associate ai nodi che hanno in 
output 
 attivazione superiori agli altri,
  soprattutto se l'intervallo dei valori 
delle attivazioni è esteso.  
Si cerca di ridurre questo intervallo (ad esempio con vincoli sulla varianza) 
per alleviare questo comportamento ""
 opinionated
 "", soprattutto nelle prime 
fasi di training.  
•
L'inizializzazione dei pesi è fondamentale.  
•
Si garantisce una esplorazione più ampia dello spazio di ricerca.
26
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#26,26,"Nonsaturing activation functions
La 
logistic function
  è molto popolare, ed è in parte ispirata al 
comportamento di un neurone 
 ﬁ
sico.  
Ma nelle architetture 
 deep
  è più conosciuta la:  
Recti
 ﬁ
ed Linear Function  
ReLU :  
f(x)=max(0,x)  
Fino a pochi anni fa la più popolare nelle architetture deep.
27
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#27,27,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:
28"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#28,28,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
 .
29"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#29,29,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 .
30"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#3,3,"Vanishing/Exploding gradients
L'
algoritmo di backpropagation
  usato per addestrare una NN segue questi passi:  
•
Per ogni coppia input-output si valuta l'errore tra output ottenuto dalla NN e 
output atteso mediante la 
 loss function 
 (o 
cost function
 ). 
•
Si calcola il 
 gradiente
 , cioè l'insieme delle derivate parziali dell'errore rispetto 
ai parametri (pesi), mediante la 
 chain rule
 . 
•
In base a tali valori si aggiornano i pesi in modo da ridurre l'errore, ad esempio 
mediante il 
 gradient descent.  
Impiegando i gradienti per addestrare la rete può capitare di ottenere valori 
molto piccoli (
 vanishing gradients
 ), soprattutto per i layer vicini all'input.  
•
Il gradiente nei primi strati si ottiene come 
 prodotto
  dei gradienti degli strati più 
lontani.  
•
Questo implica che nei primi layer i pesi non vengono pressoché alterati 
durante il training 
 e dif
ﬁ
cilmente si converge ad una soluzione
 .
4"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#30,30,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.
31"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#31,31,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 :
32"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#32,32,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
33"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#33,33,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
34"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#34,34,"ReLU activation function
I principali 
 vantaggi
  della ReLU sono:  
•
Garantisce la 
 non linearità
  anche per valori prossimi allo 0.  
•
Non satura per valori positivi elevati
 . I gradienti sono sempre signi
 ﬁ
cativi. 
Rispetto alla logistic (o tanh) 
 riduce il vanishing problem
 . 
•
Riduce la complessità computazione
  non essendoci la componente 
esponenziale da differenziare.  
Ma ha dei 
 svantaggi
 : 
•
Sperimentalmente 
 è più prona all'over
 ﬁ
tting
, perciò si usa insieme a tecniche 
per ridurre questo problema (es. dropout).  
•
Se durante l'apprendimento l'input 
 x
 combinato coi pesi 
 w
 genera un valore 
negativo, e l'output è pari a 
 0
. Può capitare che 
 i neuroni smettano di generare 
valori diversi da 0
  (
dying ReLUs
 ). 
•
L'intervallo dell'output è 
 [
0,
∞
]
35"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#35,35,"Leaky ReLU
Per risolvere il problema
  dying ReLUs
  si introduce la 
 Leaky ReLU 
 o 
LReLU:  
                               
dove 
 α
 è un 
 iperparametro
  (es. 
0.01
) che garantisce un valore diverso da 
 0 
per 
x < 0
 . 
f
(
x
)
=
m
a
x
(
α
⋅
x
,
x
)
36
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#36,36,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU):  
α
 viene impostato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
37"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#37,37,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU):     
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 La media degli output di un layer 
è più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  
Non ha singolarità nello 0
 , cioè ha sempre derivate <> 0.  
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di 
convergenza più veloce.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
38"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#38,38,"Altre ReLU
Parametric ReLU (PReLU)
 :  
•
α
 diviene un parametro che viene stimato durante il training
 . 
•
Rispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  
Randomized Leaky (RReLU)
 : 
•
α
 viene alterato in modo casuale durante il training,  
e tenuto 
 ﬁ
sso durante il test.  
•
Può ridurre fenomeni di over
 ﬁ
tting.  
Exponential Linear Unit (ELU)
 :     
•
Ha un gradiente <> 0 per x < 0
  (contro il dying ReLU)
 .
 Producendo valori <0, la media 
degli output di un layer è più vicina allo 0 rispetto a quella della ReLU, e si riduce il 
vanishing problem.  
•
Non ha singolarità nello 0
 , cioè è sempre derivabile.  
•
Sebbene richieda più tempo per il calcolo del gradiente, compensa con un 
 tasso di 
convergenza più veloce 
 della ReLU.
E
L
U
α
(
z
)
=
{
α
(
e
x
−
1
)
,
x
<
0
x
,
x
≥
0
39
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#39,39,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?
40"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#4,4,"Vanishing/Exploding gradients
In modo simile i 
 gradienti possono aumentare 
 e in alcuni layer il valore può 
eccedere gli intervalli rappresentabili nei framework di NN (
 exploding 
gradients
 ). 
•
Fenomeno che capita spesso nelle 
 Recurrent NN
  che studieremo più avanti  
Più in generale, 
 strati diversi della rete possono aggiornarsi con 
""velocità"" 
 (cioè valori di gradienti)
  molto diverse
 . 
Tali problemi sono ancora più evidenti 
 con funzioni di attivazione con 
valore medio <> 0
 , e 
inizializzazione dei pesi casuale 
 con distribuzione 
gaussiana
 . 
•
Ad esempio, nel caso della 
 logistic 
 (o
 sigmoid
 )
 function
 , per valori in input 
grandi in modulo, la funzioni 
 satura a 0 o 1
 , con 
 derivate
  tendenti allo 
 0
. 
Si ha perciò 
 vanishing gradients
 . 
5"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#40,40,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
41"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#41,41,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
42"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#42,42,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
43"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#43,43,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
44"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#44,44,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
45"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#45,45,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
46"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#46,46,"Funzioni di Attivazione
In quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, 
logistic, softmax?  
1.
La 
ELU
 è una buona scelta iniziale.  
2.
Per reti veloci, meglio una 
 leaky ReLU
 , o varianti.  
3.
La semplicità della 
 ReLU
  motiva la sua diffusione, sebbene 
 ELU
 e 
leaky  
ReLU
  si comportino generalmente meglio.  
4.
La possibilità della 
 ReLU
  di produrre esattamente 0 torna utile in certi task.  
5.
La tangente iperbolica 
 tanh
 è usata nell'output layer per produrre valori tra 
-1
 e 
1
, ma non viene più usata negli hidden layers.  
6.
La 
logistic
  è usata nell'output layer per stimare probabilità (es. 
classi
 ﬁ
cazione binaria), ma è raramente usata per gli hidden layers.  
7.
La 
softmax
  è adatta per ottenere distribuzioni di probabilità su classi 
mutuamente esclusive.
47"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#47,47,"Gradient clipping
Una tecnica molto facile per ridurre il fenomeno del 
 exploding gradients
  è 
introdurre 
 una soglia per limitare il valore dei gradienti
  durante il 
backpropagation, chiamata 
 gradient clipping
 . 
Chiaramente ponendo valori soglia rischiamo di ridurre l'informazione che 
tali parametri possono propagare.  
La rivedremo tra poco ma nel dominio della regolarizzazione dei parametri 
W
.
48"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#48,48,"Reusing pretrained layers
Addestrare un rete deep complessa 
 richiede molte risorse
 , a volte 
impossibili da avere, ad eccezione di pochi laboratori al mondo.  
Il 
transfer learning
  è l'approccio che ha l'obiettivo di
  ri-utilizzare parametri 
ottenuti da architetture già addestrate 
 su obiettivi simili.  
Ha il duplice vantaggio di ridurre:  
•
il 
tempo di addestramento,  
•
la 
dimensione del training set
  relativo all'obiettivo di interesse.  
Ad esempio, una rete è addestrata a riconoscere animali, piante, automobili, 
etc., mentre siamo interessati a distinguere il modello di certe auto.  
•
Conviene riutilizzare i parametri che permettono di rappresentare speci
 ﬁ
che 
features della classe auto (es. forme di fanali e paraurti) e sfruttarli per 
adattare la rete alle nuove classi.
49"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#49,49,"Esempio di complessità della architettura GPT-3
Generative Pre-trained Transformer 3
  (
GPT-3
 ) è un architettura deep creata 
da 
OpenAI
  per ottenere modelli (transformer) di linguaggio naturale.  
Apparsa nel 2020 come evoluzione delle versioni v2 e v1, è popolare 
per la capacità di redigere testo (es. news) simili a quelle scritte da 
persone umane. E' suf
 ﬁ
ciente dare poche parole per farla partire.  
Contiene 175 miliardi di parametri.  
Addestrata su quasi 500 miliardi di parole estratte da varie fonti 
(CommonCrawl, WebText2, Books, Wikipedia)  
Con una GPU cloud Tesla V100 richiederebbe $4.6M e 355 anni per 
l'addestramento.  
Esempi di applicazione: 
 https://beta.openai.com/examples/  
50"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#5,5,"Logistic (sigmoid) function
6
Saturazione  
(risposta max)  
gradiente basso
Saturazione  
(risposta max )
gradiente basso Quasi-lineare 
derivata costante 
cioè indipendente dagli input
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#50,50,"Reusing pretrained layers
Nelle architetture deep i 
 layer rappresentano features 
 rilevanti per la 
classi
 ﬁ
cazione 
 con diversi livelli di 
 astrazione
 . Ad esempio nel task della 
classi
 ﬁ
cazione delle immagini:  
•
I 
primi layer
  (vicini all'input) si specializzano su  
features di base
 , come 
line, angoli, variazioni cromatiche  
•
I 
layer più vicini all'output
  legano le feature precedenti per rappresentare 
oggetti complessi e relative 
 caratteristiche salienti
  (es. il muso e le orecchie 
di un animale).  
Il transfer learning 
 mira a riutilizzare i parametri (e il tipo di feature) più 
importanti.  
•
I pesi che si riusano si possono 
 congelare, 
 e focalizzare l'addestramento 
solo sui nuovi parametri che dipendono dal nuovo task.  
•
Si sempli
 ﬁ
ca l'addestramento poiché alcuni parametri non si alterano. 
51"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#51,51,"Transfer learning - procedimento
Gli output layers della rete iniziale spesso si scartano perché tipicamente 
non riadattabili al nuovo task, cioè non rappresentano le feature signi
 ﬁ
cative 
per il nuovo task e ai nuovi output di interesse.  
Il 
procedimento
  generale del 
 transfer learning
  è il seguente:  
1.
Si tenta di 
 riutilizzare tutti i parametri della vecchia rete
  e si valutano le 
performance.  
2.
Si 
""scongelano"" gli ultimi 1 o 2 layer
  e si permette il loro addestramento, 
valutando miglioramenti.  
3.
In caso il training set sia limitato, 
 si scartano gli ultimi layer,
  e si 
congelano i restanti. Si valutano le performance.  
4.
Se si hanno suf
 ﬁ
cienti dati, i
  layer scartati si rimpiazzano con nuovi 
layer
 , eventualmente aumentano la profondità della rete rispetto a quella 
di partenza.
52"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#52,52,"Reusing pretrained layers
Nota: 
 Il transfer learning è adatto quando le istanze in input hanno feature a basso livello  
(es. numero di pixel di una immagine) simili a quelle delle istanze in input alla nuova rete.
53
Parametri da addestrare,  
parzialmente riutilizzati
Parametri ﬁssi ottenuti  
dalla rete già addestrata.
Rete già addestrata  
per un certo task.Rete da addestrare  
per un task simile.CongelatiNon congelati
}}"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#53,53,"Transfer learning
Dove posso trovare parametri già addestrati?
54"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#54,54,"Transfer learning
Dove posso trovare parametri già addestrati?  
Sui repository dei framework di DL, o su blog specializzati, si trovano 
elenchi aggiornati di modelli per diversi task, es:  
•
https://github.com/tensor
 ﬂ
ow/models  
•
https://pytorch.org/docs/stable/torchvision/models.html   
I modelli fanno riferimento ad architetture DL conosciute in letteratura  
•
Es. AlexNet, VGG, ResNet, SqueezeNet, DenseNet, Inception v3, GoogLeNet, 
Shuf
ﬂ
eNet v2, MobileNet v2, ResNeXt, Wide ResNet, MNASNet
55"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#55,55,"Unsupervised Pretraining
Può capitare di lavorare su un task dove abbiamo 
 un training set di istanze 
labelled
  ridotto
 , e non esistono modelli pre-addestrati da impiegare.  
Nel 
unsupervised pretraining
  la rete viene addestrata 
 uno strato alla volta
 , 
partendo da quello più vicino agli input.  
•
Ogni layer è addestrato impiegando l'output del layer precedente, quindi in 
modo 
 unsupervised
 . 
•
Tutti i layer sono congelati, tranne quello sotto addestramento.  
•
Quando tutti i layer sono stati addestrati, la rete può essere addestrata con 
un approccio 
 ﬁ
ne-tuned 
 supervised
 .  
•
Tipicamente (1) si aggiunge un ultimo layer, (2) si congelano i pesi dei 
layer precedenti, e (3) si considera il training set disponibile.
56"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#56,56,"Unsupervised Pretraining
La fase di unsupervised permette di creare 
 una approssimazione dei 
parametri (o inizializzazione) 
 utile per la fase di addestramento reale.  
Ipotesi sostengono che tale fase individua il sottoinsieme di 
 minimi
  più 
probabili nello spazio di ricerca.  
È un approccio piuttosto lungo da completare, ma è stato impiegato di 
frequente 
 ﬁ
no alla comparsa delle prime tecniche che hanno affrontato il 
vanishing gradients
  problem. 
57"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#57,57,"Unsupervised Pretraining - considerazioni
Ricordiamoci che in una architettura deep è facile ricavare valori di errore 
sugli strati 
 ﬁ
nali, vicini all'output atteso. Ma a causa del vanishing problem, 
 i 
primi strati potrebbero non avere suf
 ﬁ
ciente informazione per il relativo 
addestramento
 . 
L'approccio iterativo del 
 unsupervised pretraining  
addestra 
 uno strato alla 
volta
 , mantenendo costanti gli altri parametri, perciò senza la possibilità che 
possano in
 ﬂ
uenzare il training in modo sub-ottimale.  
•
L'addestramento è suddiviso in più fasi, e in ogni fase abbiamo pochi 
parametri da determinare.  
•
L'
output atteso 
 di un layer sotto addestramento 
 corrisponde all'output dello 
strato precedente
  (approccio unsupervised)  
•
In ogni fase si tenta di identi
 ﬁ
care 
 minimi locali 
 utili per la fase 
 ﬁ
nale.  
Con 
pretraining
  si indica in generale 
 il procedimento di addestrare modelli 
sempli
 ﬁ
cati su dati sempli
 ﬁ
cati 
prima di arrivare al modello 
 ﬁ
nale su dati 
complessi.
58"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#58,58,"Unsupervised Pretraining
59
Layer addestratoLayer addestratoLayer addestratoRete addestrata"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#59,59,"Pretraining su auxiliary task
Un modo alternativo per addestrare una rete con scarsi dati di training e 
trovare un 
 auxiliary task
 , cioè un task simile che condivide un insieme di 
feature detectors
  salienti con il task di nostro interesse.  
Ipotesi
 : se riusciamo ad addestrare la rete sul task alternativo, potremmo 
riutilizzare i primi layer dato che si sono specializzati sulle features di 
comune interesse.  
Esempio: 
 face detection  
Tipicamente ci sono
  poche istanze 
 per ogni viso da riconoscere.  
Possiamo andare su Google e collezionare facilmente molti visi di 
celebrity. La rete imparerà a riconoscere le 
 feature salienti
  che potranno 
essere impiegate sul nostro training set.  
Un approccio alternativo è ""corrompere"" un sottoinsieme di istanze 
disponibili di una certa classe per associarle ad una classe negativa.
60"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#6,6,"Vanishing/Exploding gradients
Una possibilità sarebbe 
 comprimere
  i valori delle attivazioni in un intervallo 
ristretto, ma intorno allo 0 la logistic mostra comportamenti prettamente 
lineari, che non permettono di rappresentare funzioni complesse.
7"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#7,7,"Vanishing/Exploding gradients
8
"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#8,8,"Vanishing/Exploding gradients problem:  
Cosa succede durante l'addestramento?
Comportamenti tipici in presenza di vanishing gradients problem sono:  
•
Le performance migliorano 
 troppo lentamente
 , o 
non migliorano  
•
Prematura convergenza
  (ma non a valori ottimi)  
•
Analizzando i parametri appresi si notano 
 variazioni più signi
 ﬁ
cative negli 
ultimi strati
 , vicini all'output, 
 rispetto ai primi strati
 .
9"
data_test\rootfolder\università\DeepLearning\09-Training Deep 1-sbloccato.pdf#9,9,"Inizializzazione di Xavier e He 
L'obiettivo è garantire la propagazione delle attivazioni (forward) e dei 
gradienti (backward) in modo corretto, cioè senza 
 exploding
  e 
vanishing
 . 
Xavier e He
  propongono di mantenere uguali:  
•
i valori della varianza degli output di ogni layer con la varianza degli input 
del layer successivo
  (forward propagation).  
•
le varianze dei gradienti ottenuti prima e dopo un certo layer
  (backward 
propagation)  
Tali condizioni possono essere veri
 ﬁ
cate solo se ogni layer ha lo 
 stesso 
numero di connessioni in entrata e in uscita
 .  
Introducendo una approssimazione de
 ﬁ
niamo la 
 Xavier initialization
  così:
10I pesi della rete sono inizializzati per ogni layer in modo casuale  
con distribuzione gaussiana  con media 0  e varianza pari a n-1, 
dove n il numero di nodi del layer precedente."
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 2: Optimizers, learning rates adattivi
1"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#1,1,"Sommario
Faster Optimizer  
Momentum optimization  
Nesterov Accelerated Gradient  
AdaGrad Algorithm  
RMSProp algorithm  
Adam Optimization  
Learning rate schedule   
Adaptive learning rate algorithms"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#10,10,"Richiami: Gradient descent
•
Alterazioni troppo piccole allungano i tempi di esplorazioni.  
•
Alterazioni troppo grandi (es. learning rate elevati) generare comportamenti 
che possono allontanarci dall'ottimo.
11
Ricerca lenta Ricerca imprecisa"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#11,11,"Gradient descent vs Stochastic vs Minibatch
•
Gradient descent
 : iteriamo sull'intero training set, cioè su tutte le istanze, 
prima di aggiornare i pesi.  
•
Sebbene la stima dell'errore sia molto precisa, per training set grandi 
dobbiamo attendere molto prima di aggiornare i parametri. Gli output 
sono ricavati con i parametri ricavati nel ciclo precedente, senza poterli 
aggiornare durante l'epoca.  
•
Stochastic Gradient descent (SGD)
 : ad ogni istanza estratta dal training set 
(in modo random) aggiorniamo i parametri.  
•
La stima dei gradienti è approssimata su una singola istanza, perciò poco 
precisa. Ma aggiorniamo i parametri istantaneamente. Convergenza più 
rapida, ma meno probabilità di raggiungere l'ottimo.  
•
Minibatch SGD
 : dopo un minibatch di istanze aggiorniamo i pesi.  
•
Si suppone che il minibatch stimi meglio le variazioni dei parametri 
simulando la stima sull'training set. In altre parole, riduce la varianza sui 
valori stimati. Combina i vantaggi di entrambi.
12"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#12,12,"Richiami: (Mini)Batch Normalization
Consiste in un 
 algoritmo
  applicato ad ogni singola istanza in input 
 x
i
, 
considerando un mini-batch 
 B
 di 
m
 istanze con 
 media  
 e 
varianza   
I parametri da apprendere durante il training sono 
 γ
 (
scale
 ) e 
β
 (
offset
 ). 
ε
 è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10
-3
)
μ
B
 σ
2
B
13
da Ioffe e Szegedy ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"" 2015Trasformazione lineare"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#13,13,"Gradient vs Stochastic Gradient descent
In condizioni ideali (es. convex function) un gradient descent tradizionale è 
l'approccio ottimale per raggiungere il minimo in poche iterazioni.  
L'approccio stocastico introduce rumore che può rallentare il 
raggiungimento del minimo (es. a dx dopo 50 iterazioni non si hanno ancora 
valori ottimali, a sx dopo 20 iterazioni possiamo fermarci).  
Ma generalmente nel DL non abbiamo 
 convex functions
 .
14
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#14,14,"Gradient descent e learning rate
•
Per rendere la ricerca 
 più ef
 ﬁ
ciente 
 potremmo pensare di 
 variare il learning 
rate 
  durante l'esplorazione:  
•
Aumentandolo ulteriormente al principio
 , per rendere la ricerca più rapida,  
e riducendolo alla 
 ﬁ
ne
, soprattutto nel caso del SGD e minibatch SGD, per 
ridurre gli effetti che il rumore possa avere sulla ricerca dell'ottimo.  
•
Nell'esempio, aumentiamo la velocità durante la discesa della curva, e la 
riduciamo quando la curva riduce la pendenza.
η
15
Costo
Θ"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#15,15,"Momentum optimization
La 
momentum optimization 
 introduce il concetto di 
 accelerazione
  e 
velocità  
durante l'esplorazione.  
Introduco il 
 vettore momentum  
m
, usato per aggiornare i pesi 
 . Il suo compito è 
interpretare il gradiente 
  come una 
 accelerazione,
  che altera la 
 velocità 
corrente
  rappresentata da 
 . 
 
 
 è chiamato 
 parametro momentum
 , o semplicemente 
 momentum
 , e ha lo scopo 
di evitare che la velocità cresca eccessivamente.  
•
=0 resistenza massima (corrisponde al gradient descent), 
 =1 nessuna resistenza.  
Si veri
 ﬁ
ca facilmente che, se il il valore del gradiente rimane costante, la variazione 
massima dei pesi è 
 . 
•
Per 
 =0.9 e 
 =1
, si ottiene 10 volte il valore del gradiente.
Θ
η
∇
Θ
J
(
Θ
)
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
m
β
β
 β
η
1
1
−
β
β
 η
16"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#16,16,"Momentum optimization (2)
Analogia con una biglia su una super
 ﬁ
cie. La direzione non corrisponde più 
a quella determinata dal gradiente calcolato attualmente, ma in base alle 
media pesata di tutti i gradienti precedenti.  
L'approccio rientra nella classi dei 
 accelerated gradient methods
 . 
Ha molteplici 
 vantaggi
 : 
•
Rende più stabile la ricerca quando qualche gradiente risulta scarsamente 
accurato (es. scelta sbagliata della istanza/minibatch), mediando su una serie 
di valori.  
•
Si 
accelera l'esplorazione
  quando stiamo esplorando spazi dei parametri 
ampi, e dove le super
 ﬁ
ci de
 ﬁ
nite dalla funzione di costo variano lentamente.  
•
L'accelerazione permette più facilmente di 
 evitare (o uscire) minimi locali 
rispetto al gradient descent tradizionale
 . 
Il momentum 
  è un 
 iperparametro da stimare
  caso per caso, ma valori 
intorno allo 
 0.9
 sono molto comuni.
β
17"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#17,17,"Momentum optimization
18apprendimento lento
apprendimento veloce
Discesa del gradiente  
con Momentum optimizationDiscesa del gradiente  
tradizionale"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#18,18,"Momentum optimization: esempio
10-momentum.ipynb
19"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#19,19,"Nesterov Accelerated Gradient
Il 
Nesterov Accelerated Gradient
  (
NAG
 ) è una variazione del momentum 
optimization dove il 
 gradiente
  viene valutato non nella posizione corrente 
ma nella direzione del momentum  
 : 
 
 
In genere il vettore momentum indica la direzione verso l'ottimo, perciò 
sembra più logico misurare il gradiente verso quella direzione.  
Queste piccole variazioni si sommano e il NAG si dimostra essere 
 più 
rapido rispetto al momentum optimization
 .
Θ
+
β
⋅
m
m
←
β
⋅
m
+
η
∇
Θ
J
(
Θ
+
β
⋅
m
)
Θ
←
Θ
−
m
20"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#2,2,"Gli optimizer
Un 
optimizer
  è un algoritmo usato per alterare i parametri della rete, ed 
eventualmente alcuni iperparametri quali il learning rate, in modo da 
minimizzare la misura di loss.  
Per tale motivo la funzione di loss è anche chiamata 
 objective function
 . 
Nelle architetture deep si impiegano spesso 
 optimizer
  alternativi alla discesa 
del gradiente.  
Concettualmente, l'apprendimento delle architetture DL è ricavare un 
modello adatto al task in base ai dati disponibili, mentre l'optimizer si 
focalizza sulla objective function.  
L'ottimizzazione si focalizza sulla loss è sui dati disponibili, perciò ul 
training error
 . 
Altrettanto fondamentale nel DL è minimizzare l'
 over
ﬁ
tting
, cioè 
massimizzare le capacità di 
 generalizzazione
 . Per questo durante 
l'ottimizzazione dobbiamo includere ulteriori analisi. 
3"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#20,20,"Nesterov Accelerated Gradient
Nello scenario classico di una discesa verso l'ottimo il NAG 
 riduce eventuali 
oscillazioni 
 causate dall'accelerazione puntuale del momentum 
optimization.
21
βm"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#21,21,"AdaGrad Algorithm: Motivazioni
In presenza di 
 dati sparsi
 , i parametri 
  associati alle
  features poco 
frequenti riceveranno update signi
 ﬁ
cativi molto raramente
 .  
•
Se decrementiamo il learning rate durante l'esplorazione, nel caso tali 
features non compaiono al principio del training, 
 è probabile che i relativi 
pesi non verranno aggiornati adeguatamente prima di raggiungere la 
condizione di ottimo.  
Facciamo l'ipotesi  
che il 
 learning rate  
 è legato 
 al numero di volte  
s(i,t)
 che 
abbiamo 
 ""notato"" una certa features 
 i
 durante il training 
 ﬁ
no al tempo 
 t
. 
•
Features frequenti vedranno il learning rate associato ai relativi parametri 
diminuire più velocemente:  
 
Ma se contiamo solo le occorrenze 
 non teniamo in considerazione il valore 
del gradiente
 , a volte molto grande, a volte irrilevante.
Θ
η
η
=
η
0
s
(
i
,
t
)
+
ϵ
22"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#22,22,"AdaGrad Algorithm
Il 
AdaGrad algorithm
  rende il 
 learning rate adattivo
 , dove 
 ogni parametro 
ha un proprio rate
 . 
Per tale motivo si considera un 
 vettore  
s
 che 
 memorizza gli update per ogni 
parametro
  calcolato nel seguente modo:  
 
 
si assume 
 s
0
 = 0. 
La prima espressione accumula nel vettore 
 s
 i quadrati dei gradienti rispetto 
ai parametri  
ﬁ
no all'istante attuale.  
•
Se 
la funzione di costo è ripida
  rispetto ad una direzione 
 i
, la sequenza dei 
gradienti assumeranno un valore elevato
  in modulo, e la componente  
aumenterà ad ogni iterazione.
s
←
s
+
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
Θ
s
i
23...cont"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#23,23,"AdaGrad Algorithm (
 cont.
 )
La seconda è simile alla discesa del gradiente, ma 
 il vettore dei gradienti è 
scalato del fattore  
 , dove 
  è il solito parametro di smoothing per 
evitare divisioni per 0.  
•
Le coordinate che mostreranno spesso gradienti elevati saranno 
maggiormente 
 ridimensionate
 , al contrario, gradienti signi
 ﬁ
cativi sporadici 
o in valore ridotto corrisponderanno a learning rate più importanti.  
I principali vantaggi di 
 AdaGrad
  sono i seguenti:  
•
Adatto a training data sparsi e addestramenti molto lunghi.  
•
Il
 tuning del learning rate super
 ﬂ
uo
. Si imposta a un valore comune,  
es. 
=0.01, evitandolo di considerare come iperparametro da ottimizzare.  
•
La 
complessità computazione è paragonabile alla discesa del gradiente 
tradizionale.
s
+
ϵ
 ϵ
η
24"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#24,24,"AdaGrad Algorithm
25
parametro soggetto a gradienti 
elevati e legati a features frequenti
parametro soggetto a gradienti  
ridotti e legati a features sparse"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#25,25,"RMSProp algorithm
AdaGrad può rallentare la discesa del gradiente interrompendo 
anticipatamente il training.  
L'
algoritmo RMSProp
  è una variazione di AdaGrad dove 
 il vettore 
accumulatore 
 s
 considera maggiormente gli ultimi gradienti calcolati
 .  
•
Si introduce un 
 fattore di decay  
. 
 
 
•
Sebbene 
  sia un iperparametro, valori intorno allo 0.9 mostrano un buon 
comportamento.  
RMSProp
  si dimostra
  spesso migliore di AdaGrad
  e di altre ottimizzazioni 
(es. Momentum optimization e NAG).
β
s
←
β
s
+
(
1
−
β
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
⊘
 s
+
ϵ
β
26"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#26,26,"Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
β
1
27Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#27,27,"Adam Optimization
Riguardo il 
 tuning
  dell'Adam Optimization:  
•
Valori tipici per 
  e 
 sono 0.9 e 0.999, rispettivamente.  
•
Come per gli altri 
 algoritmi di adaptive learning rate
 , il valore iniziale di  
può essere impostato ad un valore tipico di 0.001 senza ulteriore tuning.
β
1
β
2
η
28"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#28,28,"Tecniche di ottimizzazione e complessità
Gli approcci 
 ﬁ
nora trattati si basano su 
 derivate parziali del primo ordine  
(Jacobians). Il numero di output per ogni dimensione in input è 
 n
,
 con 
 n 
numero di parametri.  
Esistono molti approcci del 
 secondo ordine (
 Hessians), ma richiedono 
 n
2 
Hessians per output.  
•
Recenti architetture Deep contengono oltre 10
8
 parametri.  
•
Limiti sulla memoria di calcolo non permettono di usare tali approcci.
29"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#29,29,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?
30"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#3,3,"Gli optimizer (2)
Nel DL le funzioni di 
 loss
 sono complesse e non hanno una 
 soluzione 
analitica
 , cioè non possono essere formalizzati in modo da poter ricavare la 
soluzione ottima con le risorse (tempo e hardware) disponibili in una serie di 
step. Per questo si impiegano 
 soluzioni numeriche
  che seguono un 
procedimento di trail & error su un insieme di soluzioni candidate.  
Es.
 i coef
 ﬁ
cienti di una regressione lineare possono essere ricavati 
analiticamente via algebra lineare (es. 
 matrix factorization
 ), oppure 
numericamente (es. 
 gradient descent
 ) quando i dati non sono 
interamente memorizzabili.
4"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#30,30,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepasserà il momentum. 
31"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#31,31,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.
32"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#32,32,"Momentum
Cosa succede se usiamo il momentum optimizer con iperparametro 
quasi 1 (es. 0.99999)?  
1.
La ricerca sarà molto veloce verso l'ottimo, ma a causa del 
momentum, la ricerca oltrepassera il momentum.  
2.
Rallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.  
3.
Potrà oscillare molte volte prima di arrivare al minimo.
33"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#33,33,"Keras e optimizer
Si può de
 ﬁ
nire facilmente via compile()  
from
 tensorflow 
 import
 keras
from
 tensorflow.keras 
 import
 layers
model = keras.Sequential()
model.add(layers.Dense(
 64
, kernel_initializer=
 'uniform'
 , input_shape=(
 10
,)))
model.add(layers.Activation(
 'softmax'
 ))
opt = keras.optimizers.Adam(learning_rate=
 0.01
)
model.
compile
(loss=
'categorical_crossentropy'
 , optimizer=opt
 )
# oppur
e
model.compile(loss='categorical_crossentropy', 
 optimizer='adam'
 )
Oppure all'interno del training loop:  
optimizer = tf.keras.optimizers.Adam()
# Iterate over the batches of a dataset.
for
 x, y 
in
 dataset:
   
with
 tf.GradientTape() 
 as
 tape:
        
 # Forward pass.
        logits = model(x)
        
 # Loss value for this batch.
        loss_value = loss_fn(y, logits)
    
# Get gradients of loss wrt the weights.
    gradients = tape.gradient(loss_value, model.trainable_weights)
    
# Update the weights of the model.
    
optimizer.apply_gradients
 (
zip
(gradients, model.trainable_weights))
34
Optimizer disponibili:  
•
SGD,  
•
RMSprop,  
•
Adam,  
•
Adadelta,  
•
Adagrad,  
•
Adamax,  
•
Nadam,  
•
Ftrl"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#34,34,"Richiami: Learning rate
Impostare un 
 learning rate troppo alto
  può far 
 divergere
  l'apprendimento 
dall'ottimo.  
Valori 
 troppo bassi 
 provocano 
 tempi di addestramento lunghi
 .  
Valori 
 elevati
  rendono il processo più rapido avvicinandosi all'ottimo ma 
senza convergere realmente
 .  
•
Tecniche quali
  AdaGrad, RMSProp
  e 
Adam
  affrontano questo problema ma 
richiedono comunque tempo, perciò 
 risorse di calcolo
 . 
Avviando il training più volte 
 su un training set ridotto e con diversi learning 
rate ci permette di 
 stimare
  quello più adatto.
35
EpocheLoss"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#35,35,"Richiami: Learning rate
36
Minimo cost function
learning rate elevato
learning rate basso
learning rate ideale"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#36,36,"Learning rate schedule
Le strategie di 
 learning schedules
  mirano ad 
 adattare il valore del learning rate  
durane il training.  
I più popolari algoritmi di 
 adaptive learning rate
  sono:  
•
Predetermined piecewise constant learning rate
 : 
•
Ogni 
 n
 epoche decrementa il rate di un valore predeterminato.  
•
Performance scheduling
 : 
•
Misura le perfomance (es. validation error) ogni 
 n
 steps e riduce il rate di un 
fattore prede
 ﬁ
nito quando le performance non migliorano.  
•
Exponential scheduling
 : 
•
Il rate si riduce di 
  dopo 
 r
 steps:  
•
Power scheduling
 : 
•
Simile al precedente ma il rate decresce più lentamente: 
1
10
η
(
t
)
=
η
0
⋅
10
−
t
r
η
(
t
)
=
η
0
(
1
+
t
r
)
−
c
37"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#37,37,"Learning rate schedule: considerazioni
Nel dominio dello 
 speech recognition
  e impiegando il Momentum 
optimization, il 
 performance scheduling
  e 
exponential scheduling  
dimostrano 
 migliori performance
 . 
•
L'
exponential scheduling 
 è da preferire perché 
 più facile nel tuning
 . 
Se si impiegano i seguenti optimizer 
 AdaGrad, RMSProp
  e 
Adam 
 non è 
necessario implementare il learning rate schedule.
38"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#38,38,"Keras e learning rate
Nell'esempio si de
 ﬁ
nisce un learning rate adattivo basato su exponential 
decay:  
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=
 1e-2
,
    decay_steps=
 10000
,
    decay_rate=
 0.9
)
optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)
39"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#4,4,"Local vs Global minimum
Un approccio numerico tradizionale che porta lo stato vicino ad un minimo 
locale restituirà una soluzione sub-ottima. Introducendo un certo grado di 
rumore abbiamo possibilità di continuare la ricerca altrove  
Nel 
minibatch stoachastic gradient descent
 , si introducono variazioni 
dovute ai gradienti calcolati sui minibatch e non sull'intero batch. 
5
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#5,5,"Saddle points
I punti di sella generano vanishing gradients, e creano problemi se non 
siamo in minimi locali o globali.  
Nell'esempio 
 f(x)=x
3
6
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#6,6,"Saddle points (2)
Nell'esempio sotto abbiamo 
 f(x,y)=x
2
-y
2 
con punto di sella in (0,0), massimo 
per y e minimo per x. Se assumiamo l'input di f un vettore k-dimensionale e 
l'output scalare, abbiamo  
Derivate parziali  
La 
matrice di Hessian
  (H) consiste nelle derivate parziali del secondo 
ordine. Essa rappresenta proprietà geometriche della super
 ﬁ
cie, 
soprattutto quando i gradienti sono pari a 0.
7
∇f(x)=[∂f(x)
∂x1,∂f(x)
∂x2,⋯,∂f(x)
∂xk]
Hf=∂2f
∂x1∂x1∂2f
∂x1∂x2⋯∂2f
∂x1∂xk
∂2f
∂x2∂x1∂2f
∂2x2⋯∂2f
∂x2∂xk
⋯
∂2f
∂x1∂xk∂2f
∂x2∂xk⋯∂2f
∂2xk"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#7,7,"Punti critici
In particolare gli autovalori e il determinante di H ci danno indicazioni sui punti 
critici e sulla funzione di costo.  
Una 
 convex function
  (cioè con un unico minimo) ha sempre autovalori non negativi.  
Ma il calcolo di H è oneroso di risorse (spazio e calcolo). Inoltre i task su cui si 
applicano architetture di DL non sono tipicamente associati a convex functions.
8
"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#8,8,"Formalismo
Nei lucidi seguenti useremo il formalismo:  
•
:   i pesi attuali 
 w
 e 
b
 della RN (in passato 
 W
) 
•
 :  
funzione di costo
  (in passato 
 E 
o 
f
) 
•
 : 
gradiente
  della funzione di costo  
•
:   
 learning rate 
 o step size (in passato 
 ) 
•
, 
:  
moltiplicazione
  e 
divisione element-wise
 , 
   cioè posizione 
  posizione  
Θ
J
(
Θ
)
∇
Θ
J
(
Θ
)
η
 α
⊗
⊘
×
9"
data_test\rootfolder\università\DeepLearning\10-Training Deep 2-sbloccato.pdf#9,9,"Richiami: Gradient descent
Il processo di ottimizzazione 
 Gradient descent
  opera una 
 sequenza di step 
regolari
  per ogni punto verso la direzione di massima discesa che 
corrisponde a quella determinata dall'opposto del suo gradiente in quel 
punto.  
 
In questo modo si ha che:  
•
L'
aggiornamento dipende solo dal gradiente calcolato localmente
 , e non 
da quelli precedenti.  
•
Se il 
 gradiente locale è piccolo
 , l'aggiornamento sarà 
 poco signi
 ﬁ
cativo
 .
Θ
←
Θ
−
η
∇
Θ
J
(
Θ
)
10"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
L'addestramento delle reti neurali Deep  
Parte 3: Over
 ﬁ
tting 
1"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#1,1,"Sommario
Affrontare l'Over
 ﬁ
tting 
Richiami  
Early stopping  
1 e 
 2 regularization  
Dropout  
Max-Norm regularization  
Data Augumentation  
Esercizi
ℓ
 ℓ"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#10,10,"Early stopping - ipotesi
Alcuni studi mostrano che le reti DL hanno la capacità di fare 
 ﬁ
tting di label 
arbitrarie, per
 ﬁ
no generate casualmente, ma solo dopo un numero elevato 
di iterazioni. In presenza di label ben de
 ﬁ
nite nel training set, la rete tende a 
rappresentarle per prime, e poi interpolare i dati associati a label ""rumore"".  
Ci garantisce la capacità di generalizzazione: è suf
 ﬁ
ciente riuscire ad 
addestrare il modello sui dati con label ben de
 ﬁ
nite, ed evitare di 
continuare su dati mal addestrati.
11"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#11,11,"Early stopping
Invece di introdurre vincoli sui parametri (l1 e l2 regularization), il vincolo 
può essere sul numero di epoche del training.   
Nella tecnica di regolarizzazione 
 early stopping
  interrompiamo il training 
quando le prestazioni della rete non migliorano, ad esempio:  
•
Alla 
ﬁ
ne di ogni epoca possiamo valutare le prestazioni sul 
 validation set
 .  
•
Teniamo traccia dell'ultima volta in cui il modello ha migliorato le 
prestazioni.  
•
Se dopo un certo numero di epoche non ci sono stati miglioramenti 
signi
ﬁ
cativi (> 
 ε
), spesso chiamata 
 patience criteria
 , interrompiamo e 
scegliamo lo snapshot del modello che in passato si è dimostrato migliore.  
Il vantaggio è aumentare il potere di generalizzazione evitando di 
considerare label noisy. Inoltre riduce il tempo di training.  
È spesso utile combinarlo ad altre tecniche di regolarizzazione.
12"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#12,12,"1
 e 
 2
 regularization
 ℓ
ℓ
1
 e 
 2 
regularization
  introducono limiti sul valore dei parametri e possono 
prevenire l'over
 ﬁ
tting.  
•
Corrispondono rispettivamente alle tecniche di 
 Lasso
  e 
Ridge 
 nella 
regressione e 
 1
 e 
 2
-penalty nella classi
 ﬁ
cazione.  
•
In pratica, oltre alla corrispondenza tra output attesi e output prodotti dalla 
rete, aggiungiamo un ulteriore vincolo da soddisfare durante il training.  
Modelli complessi tendono a rappresentare anche 
 ﬂ
uttuazioni causate dal 
rumore.  
Le due regolarizzazioni spingono i parametri del modello ad assumere valori 
vicini allo 0 e, come effetto collaterale, a ridurre gli effetti dei layer nascosti 
della rete, perciò rendendo il modello meno complesso.
ℓ
ℓ
ℓ
ℓ
13"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#13,13,"1
 regularization
ℓ
Nella 
 1
  si 
aggiunge la magnitudo sui pesi 
 (valore assoluto) come 
coef
ﬁ
ciente di penalità
  (o 
termine di regolarizzazione
 ) alla funzione di loss.  
1
 riduce signi
 ﬁ
cativamente il valore dei pesi associati alle feature meno 
importanti, operando una sorta di 
 feature selection
 , che
  riduce complessità 
e signi
 ﬁ
catività di alcune feature
 .  
Alfa è l'iperparametro 
 regularization rate
 . Valori 
 troppo elevati 
 comportano 
modelli semplici e potenziali 
 under
 ﬁ
tting, valori molto bassi 
 annullano la 
regolarizzazione.
ℓ
ℓ
14
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#14,14,"2
 regularization
ℓ
Nella 
 2
  si 
aggiunge la magnitudo al quadrato sui pesi 
 (o norma Ecluidea)  
come coef
 ﬁ
ciente di penalità.
ℓ
15
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#15,15,"Dropout - motivazioni
Abbiamo visto come modelli semplici possono garantire la generalizzazione. 
Possiamo intervenire (1) riducendo il numero delle dimensioni, o (2) 
riducendone l'importanza 
 (
2
 regularization), oppure (3) imponendo che la 
funzione stimata sia 
 smooth
  cioè poco sensibile a piccoli cambiamenti 
dell'input.  
Alcune teorie mettono in correlazione la smoothness con la capacità di 
essere resilienti alle perturbazioni nell'input. In base ad esse è stata proposta 
la tecnica di 
 iniettare
  rumore durante la forward propagation negli strati 
intermedi. L'obiettivo è minimizzare la situazione in cui un layer si 
specializza solo su un sottoinsieme di pattern di attivazione del layer 
precedente (
 co-adaptation
 ). 
Nella pratica, si disabilitano una frazione di nodi del layer precedente così 
da contribuire con un valore pari a 0 nell'input del layer attuale
ℓ
16"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#16,16,"Dropout (1)
Nel 
dropout
  si assegna ad ogni nodo una probabilità 
 p
 di essere disattivato 
(ignorato) in un certo step durante la fase di forward e backward propagation, 
ad eccezione dell'output layer.  
•
p
 è un iperparametro chiamato 
 dropout rate
  (es. p=0.5).  
•
Ogni attivazione di un layer intermedia è sostituita con:  
•
Nel caso fosse 0 i gradienti svaniscono durante il backpropagation.  
Dopo la fase di training (es. in produzione) tutti i nodi saranno attivati.  
Ad ogni step abbiamo una diversa con
 ﬁ
gurazione di rete. 
 Con N nodi 
possiamo avere 2
N
 con
ﬁ
gurazioni diverse, tutte addestrate per lo stesso scopo.
17
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#17,17,"Dropout (2)
Una impresa funziona meglio senza un dipendente?  
•
Sì, se i lavoratori sanno adattarsi, cioè: ognuno si occupa di più cose, 
maggiore cooperazione, e non contare solo sui vicini.  
Garantisce reti più 
 robuste 
 e con capacità di 
 generalizzazione
 . 
Si ottiene un incremento delle prestazioni del 
 1-2% 
 per
ﬁ
no nelle architetture 
più ottimizzate.
18"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#18,18,"Dropout - esempio
19
senza Dropout con Dropout"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#19,19,"Dropout: altre considerazioni
Una 
 rete complessa
  con molti parametri facilmente incorpora 
dipendenze che rappresentano feature dei dati di ingresso di scarso 
interesse (
 over
ﬁ
tting
).  
•
Se ad ogni step proponiamo dati a diverse con
 ﬁ
gurazioni di layer è 
meno probabile che un certo peso si focalizzi su una feature poco 
signi
ﬁ
cativa.  
La tecnica dropout 
 raddoppia circa il numero di iterazioni per 
raggiungere la convergenza
 , ma il 
 tempo di addestramento per una 
epoca è più breve 
 dato che ho meno nodi funzionanti.  
Per avere aggiornamenti più lenti si può considerare un singolo mini-
batch per ogni con
 ﬁ
gurazione considerata.
20"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#2,2,"Richiami: Over
 ﬁ
tting
Le reti deep contengono molti parametri che mirano a modellare un insieme 
vasto di funzioni, anche complesse.  
L'obiettivo dell'
 addestramento
  è ottenere una rete che mostra 
 buone 
prestazioni sia sul training set, sia in produzione 
 (cioè su dati mai visti).  
•
In queste condizioni si ha 
 generalizzazione
 . 
Il 
test set  
permette di 
 valutare l'over
 ﬁ
tting
 del modello 
 ﬁ
nale testandolo su 
dati mai visti in precedenza durante il training, ma con distribuzione di 
probabilità simile.  
•
Se un modello 
 ﬁ
tta
 i dati di training e di test contemporaneamente, si ha 
minimo over
 ﬁ
tting.  
Il 
validation set
  è usato più raramente per 
 valutare la combinazione migliore 
degli iperparametri
  durante lo sviluppo della rete. Non è impiegato durante il 
training né Nonostante ciò, le sue caratteristiche possono essere parzialmente 
rappresentate all'interno della rete, 
 rendendo la valutazione meno oggettiva
 .
3"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#20,20,"Dropout e analogia col boosting
Supponiamo di avere un problema di 
 classi
 ﬁ
cazione
 . Il 
dropout  
interpreta la rete come un insieme (molto grande) di classi
 ﬁ
catori 
“
weak
 ”.  
•
Durante l’addestramento 
 disattivo una parte della rete per 
sfruttare solo un sotto-modello alla volta
 . 
•
L'
accuratezza dei singoli sotto-modelli è minore di quella che 
potrei ottenere addestrando l'intera rete 
 su tutto il training set.  
•
Ma alla 
 ﬁ
ne considero la 
 rete nella sua interezza
 , cioè con tutti i 
sotto-modelli attivati, 
 ottenendo un aumento delle prestazioni
 . 
•
Nel 
boosting si suppongono modelli indipendenti
  mentre nel 
dropout c’è inevitabilmente dipendenza
  dovuta alla condivisione 
dei parametri tra sotto-modelli.
21"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#21,21,"Dropout nella pratica
Dal punto di vista operativo, con 
 p=0.5,
  durante il test ogni nodo di 
un qualsiasi hidden layer riceve il doppio degli input rispetto alla 
fase di training.  
•
Dopo il training è importante moltiplicare il valore degli input per  
1-p
 o avremmo dei segnali di ingresso con magnitudine troppo 
elevata. In alternativa, si può scalare l'output di ogni neurone.  
Durante lo sviluppo della rete, se notiamo che il modello mostra 
over
ﬁ
tting possiamo introdurre il dropout, ovvero incrementare 
 p
. 
Se mostra unde
 ﬁ
tting lo decrementiamo.  
Dropconnect
  è una variazione del dropout, dove sono gli archi ad 
essere disattivati.
22"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#22,22,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#23,23,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#24,24,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe. "
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#25,25,"Dropout
In una rete multi-layer, consideriamo il dropout su ogni layer?  
Negli 
 hidden layers
 , per creare diverse con
 ﬁ
gurazioni di rete da 
addestrare singolarmente.  
Non lo consideriamo nel 
 output layer 
 essendo quello che genera 
il feedback necessario per addestrare la con
 ﬁ
gurazione corrente.  
Es. nel caso della classi
 ﬁ
cazione, se omettiamo un nodo nel 
layer di output, non otteniamo il comportamento della rete 
per quella classe.  
Lo possiamo usare nel 
 input layer 
 perché permette di addestrare 
il modello ignorando alcune feature in ingresso che possono 
in
ﬂ
uenzare negativamente l'addestramento (es. p=0.8)  
E simile ad una feature selection."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#26,26,"Dropout
10-dropout
  (python)
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#27,27,"Max-Norm regularization
La 
Max-norm regularization
  introduce il 
 vincolo sul modulo dei 
pesi
 con un iperparametro 
 r
: 
 ,            dove
  indica la 
 2
-norm  
Ad ogni training step normalizziamo i pesi:  
 
Riducendo 
 r
, oltre a regolarizzare i pesi, si affronta anche il 
vanishing/exploding problem.  
w
2
≤
r
 ⋅
2
ℓ
w
←
w
r
w
2"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#28,28,"Data Augumentation
La 
data augumentation
  genera nuove istanze da dare in input
 , 
aumentando la dimensione del training set.  
Nel caso delle immagini (
 image augumentation
 ), si automatizza 
il processo con tecniche tradizionali quali:  
•
Ruotare, spostare, ridimensionare, aggiungere un rumore, copie 
speculari, variazioni di luce e contrasto, etc.  
•
Es. fare crop dell'immagine in modo che il soggetto compaia in 
diverse posizioni, modi
 ﬁ
care l'intensità dei colori per ridurre la 
relativa sensitività del modello.  
Lo scopo e (1) rendere la rete meno dipendente da queste 
variazioni e (2) incrementare il set di training nel caso ci fossero 
un numero insuf
 ﬁ
ciente di istanze."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#29,29,"Data Augumentation in Keras
11-data_augmentation.ipynb
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#3,3,"Richiami: Over
 ﬁ
tting
Per ridurre l'over
 ﬁ
tting si può intervenire:  
•
Cambiando la struttura della rete
  (es. riducendo il numero di nodi/pesi/
layer).  
•
Alterando i valori del parametri
  durante l'addestramento.
4"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#30,30,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Con 
modello sparso
  indichiamo una versione ""sempli
 ﬁ
cata"" di 
modello tipicamente più complesso, utile per elaboratori con 
meno risorse computazionali.  
Ad esempio: mini computers e smartphones."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#31,31,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#32,32,"Sparse Model
Elenca 2 modi per creare modelli sparsi  
Una volta addestrato il modello si possono azzerare i parametri 
vicini allo 0  
La 
 1
 regularization incrementa il numero di parametri vicino 
allo 0 che possono essere azzerati  
Il 
FTRLOptimizer
  è una altro algoritmo adatto per questo scopo.
ℓ"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#33,33,"Tool: Gradient Descent Visualization
θ1
θ2loss"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#34,34,"Richiami 
 
 
 
 
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
 s
+
ϵ
35Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵ
 s←s+∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘ s+ϵAdaGradAdam"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#35,35,"Qualche indicazione pratica
Per problemi di classi
 ﬁ
cazione, inizia da una con
 ﬁ
gurazione di default,  
come la seguente:  
Oppure cerca modelli pre-addestrati per compiti uguali o simili.  
Modi
 ﬁ
ca la con
 ﬁ
gurazione intervenendo:  
•
Se 
converge troppo lentamente incrementa il learning rate  
•
Se converge ma 
 con performance non adeguate
 , prova un 
 learning schedule
 , es. 
exponential decay.  
•
Se 
il training set è troppo piccolo, fai data augumentation
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#36,36,"Kaggle: piattaforma per competizioni ML-based
Ogni competizione consiste in un dataset di training e uno di test.  
Il partecipante suddivide il training set in due, una parte per la 
validazione, oppure opera una cross-fold validation.  
Il test set completo rimane privato 
 ﬁ
no alla 
 ﬁ
ne della competizione.
37
https://www.kaggle.com/c/digit-recognizer/data"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#37,37,"Over
 ﬁ
tting: un caso reale
Il ranking 
 ﬁ
nale viene calcolato sul 
 test set
 .
38
Differenza rispetto al training (e validation) set pubblico
Scendendo si hanno di solito valori negativi: approcci che 
si comportano molto bene nel training ma non nel test set."
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#38,38,"La regola del 30
La 
regola del 30  
è un semplice procedimento empirico adatto per 
classi bilanciate
  (cioè con lo stesso numero di istanze per ogni label).  
Fornisce una idea 
 se un incremento di prestazioni è signi
 ﬁ
cativo o 
meno
  (es. dovuto solo al caso).  
Se dopo aver aggiornato il classi
 ﬁ
catore ottengo un incremento 
(o decremento) di accuratezza che riguarda almeno 30 istanze, 
allora il miglioramento (peggioramento) è signi
 ﬁ
cativo.  
39"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#39,39,"La regola del 30
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima 
percentuale per dire che l’incremento di accuratezza è signi
 ﬁ
cativo? 
40"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#4,4,"Richiami: Over
 ﬁ
tting
5Training/Validation
 Produzione/
Test
label:A
label:J
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#40,40,"La regola del 30: soluzione
Se il set di validazione ha 
 N
 istanze, qual è la differenza minima percentuale per 
dire che l’incremento di accuratezza è signi
 ﬁ
cativo?  
L’incremento percentuale si calcola:  
Esempio:  
Se N = 1000 -> 3%  
Se N = 3000 -> 1%  
Se N = 30.000 -> 0.1%  
Seguendo la regola, è meglio usare un validation set ampio, così anche 
incrementi (es. 0.1%) possono essere tenuti in considerazione.  
Indicazioni più accurate sono ottenute con 
 test di signi
 ﬁ
catività
 .
41(N+30)−N
N⋅100"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#41,41,"Esercizio su Deep NN
Costruisci una rete Deep, con 5 layer hidden da 100 nodi l'uno, 
inizializzazione Xavier e He, e funzione di attivazione ELU  
Usa la Adam optimization con early stopping.  
Impiega il dataset di cifre MNIST, ma solo da 0 a 4. Usa come output 
un layer softmax da 5 neuroni.  
Ricordati di salvare periodicamente i checkpoints, e il modello 
 ﬁ
nale.  
Fai tuning sugli iperparametri usando la cross-validation, e vedi se 
puoi incrementare la precisione.  
Prova ad aggiungere la Batch normalization e confronta le curve di 
learning. Converge prima? Produce un modello migliore?  
Secondo te c'è over
 ﬁ
tting sul training set? Prova ad aggiungere il 
dropout ad ogni layer e valuta miglioramenti.
42"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#42,42,"Esercizio sul Transfer Learning
Crea una nuova Deep NN e riusa i parametri degli hidden layer della 
rete precedente. Congelali e rimpiazza il layer softmax con uno 
nuovo.  
Addestra la rete sulle cifre 5-9, usando solo 100 immagini per cifra, e 
vedi quanto impiega. Nonostante le poche immagini riesci ad avere 
una buona precisione?  
Prova a fare caching dei layer congelati, e addestra di nuovo il 
modello. Quanto è veloce ora?  
Prova di nuovo usando solo 4 hidden layer. La precisione aumenta?  
Ora scongela i primi 2 layer e continua il training. Ottieni maggiori 
performance?
43"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#43,43,"Esercizio sul Pretraining su auxiliary task
Costruiamo una Deep NN che confronta due cifre MNIST per veri
 ﬁ
care se sono le 
stesse. Dopodiché impieghiamo gli stessi layer 
 ﬁ
nali della rete per addestrare un 
classi
 ﬁ
catore MNIST su pochissimi dati di training.  
Inizia da 2 Deep NN (A e B), simili a quanto costruito nel esercizio su Deep NN. 
Aggiungi un singolo layer di output che connette l'output di ambedue le reti. Usa la 
funzione concat() di Tensor
 ﬂ
ow con axis=1. Usa quanto ottieni come input al nuovo 
output layer. L'output layer contiene un singolo nodo e usa la logistic come funzione 
di attivazione.  
Suddividi MNIST in 2 sets: primo split da 55,000 immagini, secondo split da 5,000. 
Crea una funzione che genera un batch dove ogni istanza è una coppia di immagini 
prese dallo split #1. Metà devono appartenere alla classe ""stessa classe"" (label 0), 
l'altra metà ""classi diverse"" (label 1).  
Addestra la rete sul training set. Per ogni coppia manda in input in simultanea 
l'immagina da A e l'immagine da B.  
Ora crea una nuova rete riutilizzando e congelando i pesi degli hidden layers di A e 
aggiungendo una softmax layer di 10 nodi. Addestra la rete sullo split #2 e vedi se 
ottieni prestazioni elevate avendo solo 500 immagini per classe.
44"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#5,5,"Affrontare l'Over
 ﬁ
tting
Valori dei pesi limitati in modulo signi
 ﬁ
cano spesso modelli meno complessi, e meno 
in
ﬂ
uenzati da 
 ﬂ
uttuazioni statistiche dei dati in input.  
•
Valori elevati nei pesi implicano attivazioni molto diverse per leggere variazioni in input.  
Tranne nei casi di training set molto grandi, si impiegano sempre 
 tecniche di 
regolarizzazione
 , tra le quali:  
•
Early stopping
 : 
•
terminare l'addestramento quando le performance degradano  
•
 1
 e 
 2
 regularization (o weight regularization)
 :  
•
penalizzare il modello in base alla magnitudo dei pesi  
•
Dropout
 : 
•
per ogni layer ignorare alcuni input durante l'addestramento  
•
Max-Norm regularization (o weight constraint)
 :  
•
introdurre un range di ammissibilità per il valore dei pesi  
•
Data Augumentation (non regolarizza i pesi, ma aumenta la dimensione del training set)
 : 
•
modi
 ﬁ
care il training set, es. aggiungendo del rumore
ℓ
ℓ
6"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#6,6,"Richiami: Over
 ﬁ
tting
7
Complessità del modello"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#7,7,"Richiami: bias e varianza 
High Validation error
High Test errorSi
SiNo
No
Done! •Bigger mode l
•Train longer  
•New model architecture 
•More data  
•Regularization  
•New model architecture Bias 
(unde ﬁt)
Varianc e
(over ﬁt)
"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#8,8,"Over
 ﬁ
tting e regolarizzazione
Il procedimento di training 
 ﬁ
nora seguito è:  
•
addestrare
  il modello su un training set, e valutare l'
 errore di 
generalizzazione
  su holdout data (test set).  
La differenza di performance tra i due set si chiama 
 generalization gap
 . Se 
la differenza è elevata si ha 
 over
ﬁ
tting
 sul training data.  
Nello scenario del DL, prendendo l'esempio del task della classi
 ﬁ
cazione, 
si hanno tipicamente modelli complessi a suf
 ﬁ
cienza per 
 ﬁ
ttare
 ogni istanza 
di training, anche per training set molto grandi. Farebbe pensare che per 
ridurre il generalization error siamo costretti a introdurre regolarizzazioni 
(es. riducendo la complessità, vincoli sul valore dei parametri).  
In realtà si nota come nel DL si raggiungano spesso 0 training error, perciò 
l'unico aspetto da ottimizzare è il generalization error. Inoltre, contrario alla 
logica, l'errore si può ridurre anche rendendo l'architettura più complessa 
(es. più layer e nodi). I progettisti hanno più possibilità di affrontare 
l'over
 ﬁ
tting rispetto alle architetture NN tradizionali.
9"
data_test\rootfolder\università\DeepLearning\11-Training Deep 3-sbloccato.pdf#9,9,"Ispirazione ai modelli non parametrici
Gli approcci parametrici possono essere de
 ﬁ
niti in vari modi, es. sono 
basati su modelli statistici che rappresentano i parametri con distribuzioni 
standard. Nei modelli nonparametrici la variabilità dei parametri è più 
ampia e ci sono meno vincoli da rispettare (es. su media, varianza).  
Spesso i modelli nonparametrici confrontano le istanze e si basano 
sull'ipotesi che istanze simili in input producono output simili (es. k-NN).  
Un altro modo per caratterizzare i modelli nonparametrici è sulla 
complessità che tende a crescere al crescere del numero di dati disponibili 
di training.  
Le reti NN sono spesso viste come modelli non parametrici
 . Si hanno un 
numero molto abbondate di parametri che tendono a interpolare i training 
data.
10"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #1
1"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#1,1,"Sommario
Nodi e layers ricorrenti  
•
Calcolo degli output  
Predizione  
Architetture RNN  
•
Sequence-to-sequence  
•
Sequence-to-vector  
•
Vector-to-sequence  
•
Encoder-decoder  
Memory cells  
•
LSTM  
•
GRU"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#10,10,"Architetture RNN (1) 
Ci sono vari tipi di architetture RNN, che dipendono dal task che si vuole 
affrontare.  
La rete 
 sequence-to-sequence
  è utile per task di 
 predizione
 .  
•
Supponiamo di avere la quotazione di chiusura di un titolo in borsa, misurata 
negli ultimi N giorni. La rete deve produrre in output le stesse quotazioni 
traslate di un giorno nel futuro.  
La rete 
 sequence-to-vector
  è simile alla precedente ma 
 scarta tutti i valori in 
output tranne l'ultimo
 . 
•
Se in input abbiamo una sequenza di 
 id
 di parole, l'ultimo output può 
corrispondere al 
 sentiment
  (es. -1 [hate], +1 [love).
11
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#11,11,"Architetture RNN (2) 
La rete 
 vector-to-sequence
  prende in input ripetutamente lo stesso vettore per 
una successione di steps e produce una sequenza in output.  
•
Se il vettore in input corrisponde ad una immagine, possiamo addestrare la 
rete per produrre una descrizione testuale associata (sequenza di parole).
12
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#12,12,"Architetture RNN (3) 
In
ﬁ
ne si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
vector-to-sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio.  
•
Una rete 
 sequence-to-sequence
  non è adatta poiché l'intera frase. Le ultime 
parole dell'input potrebbero in
 ﬂ
uenza l'inizio dell'output, mentre la rete 
traduce ogni parola via via che l'input è reso disponibile. Inoltre le lunghezze 
dell'input e output potrebbero non corrispondere.
13
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#13,13,"RNN: Addestramento 
L'addestramento di una RNN richiede l'
 unrolling through time
  e l'uso della 
tecnica 
 backpropagation through time
  (
BPTT
 ). 
•
La prima passata corrisponde alla 
 forward
  pass tradizionale (frecce 
tratteggiate).  
•
L'output è valutato con una 
 funzione di costo  
 . Per talune 
architetture la funzione può ignorare alcuni output.  
•
Il gradiente della funzione di costo è propagato 
 backward
  (frecce continue) e 
i parametri aggiornati di conseguenza.
C
(
Y
(
0
)
,
Y
(
1
)
,
⋯
,
Y
(
T
)
)
14
In questo esempio la funzione  
è valutata con gli ultimi 3 
output, e perciò i gradienti non 
transitano per Y (0) e Y (1).
Da notare che i medesimi 
parametri W,b sono impiegati 
ad ogni step. La 
backpropagation considera 
tutti gli steps per fare 
l'aggiornamento."
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#14,14,"Time series: Predizione (forecasting)
Analizziamo le seguenti 
 time series
 :  
•
numero orario di utenti attivi su un sito web,  
•
temperatura giornaliera in un certo luogo  
•
situazione 
 ﬁ
nanziare di una società misurata trimestralmente con metriche 
multiple (es. reddito, debito, etc).  
Le prime due sono 
 univariate  
time series
  perché valutiamo temporalmente 
una singola metrica, l'ultima è una 
 multivariate  
time series
 . 
La predizione di un valore in un tempo futuro è chiamato 
 forecasting
 . 
Con 
imputation
  si intende stimare un valore mancante all'interno della time 
series.  
Le RNN si usano spesso per fare 
 forecasting
  e 
imputation
 .
15"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#15,15,"RNN e Keras (1)
Generiamo 
 time series
  in modo random:  
def 
generate_time_series
 (
batch_size
 , 
n_steps
)
:
    
# valori random in [0,1); il parametro di rand è lo shape
    freq1, freq2, offsets1, offsets2 = np.random.rand(
 4
, batch_size, 
 1
)
    
# n_steps valori nell'intervallo 0, 1 equamente spaziati
    time = np.linspace(
 0
, 
1
, n_steps)
    series = 
 0.5
 * np.sin((time - offsets1) * (freq1 * 
 10
 + 
10
))  
#   wave 1
    series += 
 0.2
 * np.sin((time - offsets2) * (freq2 * 
 20
 + 
20
)) 
# + wave 2
    series += 
 0.1
 * (np.random.rand(batch_size, n_steps) - 
 0.5
)   
# + noise
    
return
 series[..., np.newaxis].astype(np.float32)
Dove 
batch_size
  sono il numero di 
 time series
  da generare con lunghezza 
n_steps
 . Le serie sono 
 univariate
 . La funzione restituisce un array NumPy di 
dimensioni [
 batch_size
 , 
n_steps
 , 1].  
Ogni serie è generata come somma di due funzioni 
 seno
 di ampiezza 
 ﬁ
ssa ma 
frequenza e fase random, e con aggiunta di rumore.  
16"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#16,16,"RNN e Keras (2)
Creiamo training set, validation set e test set:  
n_steps = 
 50
series = generate_time_series(
 10000
, n_steps + 
 1
)
X_train, y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-1
]
X_valid, y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-1
]
X_test, y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-1
]
X_train
  contiene 7000 time series di lunghezza 50 steps, e ha dimensioni 
[7000,50,1]  
X_valid
  contiene 2000 time series  
X_test
  contiene 1000 time series  
Poiché vogliamo un 
 forecast
  di un singolo valore per time series, il vettore 
colonna target ha dimensioni [7000,1]  
17"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#17,17,"RNN e Keras (3)
Per valutare il modello introduciamo degli approcci 
 baseline
 , con cui 
confrontarci.  
Un semplice modello stima il valore futuro facendolo coincidere con l'ultimo 
valore nella time series (
 naive forecoasting
 ). 
>>> y_pred = X_valid[:, 
 -1
]
>>> np.mean(keras.losses.mean_squared_error(y_valid, y_pred))
0.020211367
•
Sebbene banale, ottiene buone prestazioni: 
 Mean squared error (MSE) di 0.02  
Un altro approccio è impiegare una rete 
 fully connected
 . Ad esempio con un 
singolo layer, perciò si riduce ad una combinazione lineare dei valori della 
time series in ingresso.  
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 50
, 
1
]),
    keras.layers.Dense(
 1
)
]
)
•
Con la con
 ﬁ
gurazione: MSE loss, Adam optimizer, 20 epoche di training; si 
ottiene un MSE di 0.004.
18"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#18,18,"RNN e Keras (4)
Implementiamo una semplice RNN, con un layer con un singolo nodo con la 
funzione Keras 
 SimpleRNN
 .  
model = keras.models.Sequential(
 [
  keras.layers.SimpleRNN(1, input_shape=[None, 1]
 )
]
)
Come dimensione dell'input impostiamo 
 None
  poiché una RNN elabora 
 time 
series
  di qualsiasi lunghezza e non occorre speci
 ﬁ
carla anticipatamente.  
Di default la 
 SimpleRNN
  usa la attivazione 
 tangente iperbolica
 .  
Il primo output viene elaborato con 
 h
(init)
=0
 e 
x
(0)
 pari al valore in input al 
primo step. Il nodo calcola la somma pesata dei 2 contributi e valuta la 
tangente iperbolica al risultato, ottenendo il primo valore in output 
 y
0
. Nella 
SimpleRNN
  tale valore corrisponde al valore per lo stato 
 h
(0)
.  
Al successivo step, lo stesso nodo prende in input il successivo input 
 x
(0) 
e lo 
stato 
 h
(0)
 e ripete l'elaborazione.  
L'unico valore in output corrisponde 
 y
49
. Se si vogliono ottenere tutti i valori in 
output impostare 
 return_sequences=True
 .
19"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#19,19,"RNN e Keras (5)
Una volta compilato e sottoposto a 
 ﬁ
t (con
 ﬁ
gurazione: 20 epoche, Adam op.), 
tale modello raggiunge un MSE di 0.014, perciò al di sotto del modello 
lineare.  
•
Il modello lineare ha un totale di 51 parametri, cioè un parametro per ogni 
input e il bias. Nella SimpleRNN abbiamo un singolo parametro per input, 
uno per l'hidden state e per il bias, cioè 3 parametri in totale.  
•
Un SimpleRNN è una rete troppo semplice per avere questo task.
20"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#2,2,"Motivazioni
Abbiamo assunto input per i nostri modelli di tipo vettoriale, dove ogni 
elemento 
 x
j
 corrisponde ad un attributo (o feature). Perciò possiamo 
raggruppare facilmente i dati in formato tabellari 
 istanze 
 x
 attributi
 . 
Successivamente abbiamo considerato immagini, dove per ogni coordinata 
abbiamo il valore del pixel. In questo scenario abbiamo introdotto le CNN, 
capaci di implementare logiche gerarchiche e gestire proprietà di 
invarianza.  
Come possiamo trattare input sotto forma di sequenze, come time series 
prediction, video analysis, etc?  
Oppure affrontare task che producono in output sequenze come l'
 image 
captioning, speech synthesis, 
 e
 music generation.
3"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#20,20,"Trend e stagionalità (seasonality)
Ci sono molti altri modelli per il forecast di time series, come il 
 weighted 
moving average
  e l'
autoregressive integrated moving average 
 (
ARIMA
 ). 
Alcune modelli richiedono di 
 rimuovere preliminarmente trend e stagionalità 
nei dati, ad esempio:  
•
Se i visitatori di un sito web crescono stabilmente 10% al mese, occorre 
rimuovere questa variazione dai dati in input. Una volta ottenuta la 
predizione si può reintegrare al valore 
 ﬁ
nale.  
•
Per predire la vendita di creme solari, occorre preliminarmente rimuovere la 
stagionalità annuale associata ai mesi estivi. Per esempio, rimuovendo al 
valore attuale il valore nell'anno precedente (
 differencing
 ). Si può reintegrare 
al valore 
 ﬁ
nale ottenuto.  
Le RNN non richiedono generalmente questi preprocessamenti, anche se 
possono aumentare le prestazioni, poiché la rete non è costretta ad 
apprenderli.
21"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#21,21,"Deep RNN: considerazioni
Una DeepRNN raggiunge un MSE di 0.003.  
Una architettura più adatta avrebbe un ultimo layer con un singolo valore in 
output per time step. Ma in questo caso avremmo un 
 hidden state  
rappresentato con un solo valore, che non avrebbe molta utilità. Una 
DeepRNN sfrutta tutti gli hidden states dei layer precedente per ""trasportare"" 
l'informazione necessaria per produrre l'ultimo output, e il contributo 
dell'hidden dell'ultimo layer risulta assai limitato.  
Possiamo sostituire il layer in output con un layer fully connected (o Dense). 
L'accuratezza non è alterata, il tempo di addestramento si riduce leggermente 
e possiamo scegliere qualsiasi funzione di attivazione.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 1
)
])
22"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#22,22,"Predizione di più dati
Possiamo tentare di stimare più valori temporalmente futuri, impi  
Elenchiamo alcuni approcci:  
•
Usare l'output come input nello step successivo ottenendo un valore alla 
volta  
•
Simile al precedente ma in output prediciamo contemporaneamente più 
valori ma considerando una unica loss (
 sequence-to-vector
 ) 
•
Simile al precedente ma con una loss per ogni valore predetto (
 sequence-to-
sequence
 )
23"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#23,23,"Predizione di più dati - uno dato alla volta
Possiamo tentare di stimare più valori temporalmente futuri.  
Una possibilità è impiegare il modello attuale, ottenere l'output e 
concatenarlo al predente input, ottenendo un secondo input e così via.  
•
Ad esempio, per predire 10 dati:  
series = generate_time_series(
 1
, n_steps + 
 10
)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for
 step_ahead 
 in 
range
(
10
):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=
 1
)
Y_pred = X[:, n_steps:]
Otteniamo un MSE=0.029. L'approccio 
 naive
  ottiene 0.223, ma il modello 
lineare 0.0188, ed è più accurato e veloce da addestrare.  
La Deep RNN rimane valida se limitiamo il numero di valori da predire.
24"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#24,24,"Predizione di più dati - sequence-to-vector
Una seconda opzione è addestrare la RNN per predire 10 valori 
contemporaneamente.  
•
Usiamo la 
 sequence-to-vector
 , ma con 10 valori in output invece di 1.  
Intanto cambiamo i valori target:  
series = generate_time_series(
 10000
, n_steps + 
 10
)
X_train, Y_train = series[:
 7000
, :n_steps], series[:
 7000
, 
-10
:, 
0
]
X_valid, Y_valid = series[
 7000
:
9000
, :n_steps], series[
 7000
:
9000
, 
-10
:, 
0
]
X_test, Y_test = series[
 9000
:, :n_steps], series[
 9000
:, 
-10
:, 
0
]
L'output layer consisterà di 10 nodi:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
),
    keras.layers.Dense(
 10
)
]
)
E si potranno predire 10 valori in modo simile:  
Y_pred = model.predict(X_new)
Ora l'MSE è di 0.008, migliore del modello lineare.
25"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#25,25,"Predizione di più dati - sequence-to-sequence
Un ulteriore modello da impiegare è il 
 sequence-to-sequence
 , dove le 10 
predizioni sono comunque ottenute sequenzialmente step-by-step.  
•
Il vantaggio è avere una 
 loss
 ad ogni step, perciò più gradienti che saranno 
usati per aggiornare il modello, non solo seguendo un approccio 
 through-time,  
ma direttamente dagli output generati, come avviene nelle reti non ricorrenti.  
Al primo step il modello produrrà in output la predizione per gli step da 1 a 10, 
allo step successivo le predizioni da 2 a 11, e così via. Il target avrà la stessa 
lunghezza dell'input.  
•
Sebbene in output otteniamo una parte dei valori usati in input, l'input 
corrente consiste sempre in valori apparsi nel passato. Sarebbe scorretto 
impiegare valori del dataset che temporalmente sono da considerarsi futuri.  
Creiamo le sequenze target di 10 elementi:  
Y = np.empty((
 10000
, n_steps, 
 10
)) 
# each target is a sequence of 10D vectors
for
 step_ahead 
 in 
range
(
1
, 
10
 + 
1
):
    Y[:, :, step_ahead - 
 1
] = series[:, step_ahead:step_ahead + n_steps, 
 0
]
Y_train = Y[:
 7000
]
Y_valid = Y[
 7000
:
9000
]
Y_test = Y[
 9000
:]
26"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#26,26,"Predizione di più dati - sequence-to-sequence
Per avere un modello 
 sequence-to-sequence
  impostiamo 
return_sequences=True
  per ogni layer, compreso l'ultimo. Ad ogni step 
valutiamo l'output del layer FC.  
•
Keras fornisce il 
 TimeDistributed
  layer, adatto ad essere valutato ad ogni step. 
I valori in input vengono automaticamente ridimensionati cosicché ogni step 
è trattato come una istanza separata  
•
[
batch size, time steps, input dim.
 ] 
 [
batch size × time steps, input dim.
 ] 
•
Nell'esempio abbiamo 20 nodi nel layer 
 SimpleRNN
 . L'output sarà una 
sequenza e non un singolo vettore. Il layer Dense viene applicato in modo 
indipendente ad ogni step.  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
→
27"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#27,27,"Predizione di più dati - sequence-to-sequence
L'output nell'ultimo step è impiegato per la predizione e valutazione.  
Sebbene usiamo la MSE su tutti gli output, per la valutazione ci limitiamo a 
usare una metrica 
 custom
  che elabora l'MSE sull'ultimo step.  
def 
last_time_step_mse
 (
Y_true
, 
Y_pred
):
    
return
 keras.metrics.mean_squared_error(Y_true[:, 
 -1
], Y_pred[:, 
 -1
])
optimizer = keras.optimizers.Adam(lr=
 0.01
)
model.
compile
(loss=
""mse""
, optimizer=optimizer, metrics=[last_time_step_mse])
Si ottiene MSE di 0.006, 25% meglio del modello precedente.  
È possibile combinare i due approcci: predire 10 valori, concatenarli ai dati in 
input e predire i successivi 10, ottenendo sequenze di lunghezza arbitraria.  
Nota: Il 
 Montecarlo Dropout
  (
MC Dropout
 ) è spesso inclusa in ogni cella per 
omettere in modo random parte degli input e degli hidden state.  
28"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#28,28,"Predizione di più dati: limiti (1)
Per addestrare una RNN su sequenze molto lunghe occorre creare 
 reti molto 
deep
 , coi noti problemi di 
 instabilità dei gradienti
  (es. tempo di 
apprendimento troppo lungo, o instabile).  
Inoltre la rete fa più fatica a ricordare le informazioni iniziali della sequenza.  
Alcune tecniche viste possono essere nuovamente applicate (es. dropout, 
optimizers più adatti alla architettura deep).  
Le 
ReLU  
non sono adatte
  per le 
 RNN
 . 
•
Supponiamo che la discesa del gradiente aggiorni i parametri in modo da 
incrementare leggermente l'output. Siccome ad ogni step sono usati gli stessi 
parametri, anche l'output al successivo step può essere leggermente 
incrementato, e così via, 
 ﬁ
no a valori troppo elevati o instabili. 
 Una funzione 
che non satura non può prevenire questo
 .  
•
Anche i gradienti possono assumere valori troppo elevati, perciò sono utili 
tecniche quali il 
 Gradient clipping.
29"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#29,29,"Predizione di più dati: limiti (2)
La 
Batch normalization
  non mostra sperimentalmente la stessa ef
 ﬁ
cacia 
rispetto alle reti deep tradizionali e non ottiene bene
 ﬁ
ci. 
•
Teoricamente un layer BN può essere aggiunto ad ogni memory cell, e 
interverrà dopo ogni step, sia sugli input correnti sia sull'hidden state (dello 
step precedente).  
•
Ma il layer BN sarà usato ad ogni step, con gli stessi parametri, senza 
considerare la scala di valori e l'offset degli input e dell'hidden state attuali.  
Nota: un tecnica simile ma più adatta è la 
 Layer normalization
 , ma invece di 
normalizzare rispetto al batch, normalizza rispetto alla dimensione delle 
features.
30"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#3,3,"Introduzione
Una 
 time series
  consiste in una serie di misurazioni indicizzate con un 
ordine temporale.  
•
Es. ultima quotazione giornaliera di un titolo 
 ﬁ
nanziario, situazione oraria del 
meteo, traiettoria di una automobile  
Le 
Recurrent Neural Networks
  (
RNN
 ) sono architetture di reti neurali 
adatte ad analizzare time series e stimare misure mancanti o future.  
Rispetto alle 
 CNN
  possono elaborare dati in ingresso con lunghezza 
arbitraria non pre
 ﬁ
ssata, più adatte in certi contesti.  
•
Es. analisi di una frase per fare una traduzione automatica o speech-to-text  
Ciononostante non sono le uniche architetture per 
 time series
 . 
•
Reti
 fully-connected 
 sono sempre adatte per sequenze di lunghezza 
limitata, mentre sequenze molto lunghe possono essere elaborate da 
ﬁ
ltri convoluzionali.
4"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#30,30,"RNN più recenti
Le celle introdotte 
 ﬁ
nora soffrono del problema del 
 vanishing
  (e exploding) 
gradient. Il gradient clipping o altre tecniche, sebbene risolvano il problema, 
non permettono alle RNN di analizzare sequenze lunghe.  
Per tale motivo sono state introdotte le 
 memory cells
 , cioè unità di 
elaborazione che mantengono lo stato memorizzato e lo propagano alle celle 
successive evitando che ""svanisca"" a causa dei gradienti troppo bassi.  
Le 
Long Short-Term Memory (LSTM)
  sono le prime memory cell introdotte in 
letteratura, le 
 Gated Recurrent Unit (GRU)
  ne sono una versione sempli
 ﬁ
cata. 
Nelle 
 Bidirectional Recurrent Neural Networks
  si sfruttano le informazioni 
raccolte negli step precedenti e successivi per determinare l'output nello step 
corrente.
31"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#31,31,"Celle LSTM - motivazioni
Le 
LSTM
  sono memory cells introdotte per dotare la cella di memoria 
 a lungo 
termine 
 utile per riconoscere pattern di segnale più estesi.  
Oltre alla rappresentazione 
 long-term
 , determinata dai pesi che sono appresi 
durante il training, le celle hanno una memoria
  short-term
  capace di 
rappresentare le attivazioni ef
 ﬁ
mere. Tale memoria viene condivisa da una 
cella alla successiva.  
All'interno delle memory cells, oltre allo stato, esistono una serie di 
 gate 
controllers
  che determinano quali input in
 ﬂ
uenzano lo stato, se lo stato deve 
essere azzerato (o dimenticato) e come lo stato in
 ﬂ
uenza l'output della cella.  
•
Perciò nella LSTM esistono meccanismi dedicati sia per aggiornare lo stato, 
sia per azzerarlo.  
I gate sono governati da parametri che sono stimati durante l'apprendimento.
32"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#32,32,"Celle LSTM e Keras
Keras ne sempli
 ﬁ
ca l'uso con la funzione 
 LSTM
 : 
model = keras.models.Sequential([
    keras.layers.LSTM(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.LSTM(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
O impiegando la cella general purpose 
 RNN
  che può assumere come 
argomento 
 LSTMCell
 , utile per creare celle 
 custom
 , con lo svantaggio di 
perdere parte delle ottimizzazioni GPU:  
model = keras.models.Sequential([
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
,
                     input_shape=[
 None
, 
1
]),
    keras.layers.RNN(keras.layers.LSTMCell(
 20
), return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
]
)
Successivamente vedremo una implementazione con le funzionalità
  d2l
.
33"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#33,33,"Celle LSTM: Architettura (1)
L'architettura di una cella 
 LSTM
  è la seguente:  
Esistono 4 gates (
 FC
) i cui input sono: l'
 hidden state
  dello step precedente 
 h
(t-1) 
e l'input corrente 
 x
(t)
.  
I gate sono: 
 forget gate
 , 
input gate
 , 
output gate
 , e 
input node
 . I relativi output, 
f(t)
, 
i(t)
, 
o(t)
 e 
g(t)
; sono determinati da una rete fully connected (FC). Hanno 
tutti funzione di attivazione 
 logistic
 , tranne l'
 input node
  che impiega la 
 tanh
.
34
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#34,34,"Celle LSTM: Architettura (2)
Possiamo interpretare i gate nel seguente modo:  
•
L'
input gate
  determina quanto dell'input corrente deve essere aggiunto ad 
 c
(t) 
che assume il ruolo di stato corrente.  
•
Il 
forget gate 
 in
ﬂ
uenza quanto tenere e quanto dimenticare dello stato interno 
precedente 
 c
(t-1)
.  
•
L'
output gate
  quanto la cella corrente in
 ﬂ
uenzerà l'output 
 y
(t)
. 
•
L'
input node
  rappresenta la computazione di una cella ricorrente tradizionale.
35
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#35,35,"Celle LSTM: Architettura (3)
Per esempio, se il 
 forget gate
  fosse sempre 1 e l'
 input gate
  fosse 0, lo stato 
 c
(t-1) 
rimarrebbe imperturbato negli step futuri. Nella realtà, i gate saranno addestrati 
in modo da perturbare lo stato in funzione degli input analizzati dalla cella.  
•
Questa tecnica basata su gate affronta il 
 vanishing gradient problem  
garantendo che gli stati possano propagarsi temporalmente per molti step.  
L'
input node
  produce 
 g
(t)
 e si comporta come una cella ""base"", ma nella LSTM 
una parte rilevante del output del cella base è memorizzato nello stato interno 
c(t)
, e il resto scartato. La suddivisione tra output e stato è più netta. 
36
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#36,36,"Celle LSTM: Architettura (4)
L'output della cella 
 h(t), 
 corrispondente al valore y di una cella tradizionale, è 
generato prendendo il valore 
 tanh
 dello stato interno corrente 
 c(t)
 e calcolando 
una moltiplicazione element-wise con il valore ottenuto dall'
 output gate
 . 
•
Se l'
output gate
  è 1 lo stato interno in
 ﬂ
uenzerà i layer successivi (in una 
architettura multilayer) nello step corrente. Se è 0 lo stato non li in
 ﬂ
uenzerà.  
•
È sempre possibile che lo stato interno si propaghi per molti step, e che non 
in
ﬂ
uenzi l'output a causa dell'
 output gate 
 che lo inibisce, 
 ﬁ
no ad un certo 
step in cui il gate potrà invertire il valore. Per tale motivo 
 h(t)
 è visto come 
stato 
 short-term,
  mentre 
 c(t) 
long-term
 .
37
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#37,37,"Celle LSTM: Architettura (5)
In sintesi, la 
 LSTM
  è in grado di riconoscere sequenze lunghe, per mezzo dell'
 input 
gate
, memorizzarlo in uno stato long-term, e preservarlo 
 ﬁ
nché è giudicato 
importante, per mezzo del
  forget gate
 , e ripescarlo quando necessario.  
•
Per tale motivo le LSTM hanno ottenuto buoni risultati nell'analisi di pattern, anche molto estesi, in 
time series, testi, audio, etc.  
In termini analitici, per una singola istanza in input si ha:  
•
dove 
 W
xi
, 
W
xf
, 
W
xo
,
W
xg
 sono le matrici dei pesi dei 4 layer per le connessioni con 
l'input vector 
 x
(t)
. 
•
W
hi
, 
W
hf
, 
W
ho
,
W
hg
 sono le matrici dei pesi dei 4 layer per le connessioni con lo stato 
short-term precedente 
 h
(t-1)
. 
•
b
i
, 
b
f
, 
b
o
,
b
g
 sono i bias, inizializzati a 1 invece di 0 per evitare di ""dimenticare"" tutto 
all'inizio del training.
38
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#38,38,"Celle LSTM, Keras e d2l
11-memory_cells.ipynb
39"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#39,39,"Celle LSTM: Peephole connections
In una cella LSTM tradizionale i gate controllers analizzano 
 x
(t)
 e 
h
(t-1)
. Può 
essere utile dargli la possibilità di usare le informazioni nello stato long-term.  
Le 
peephole connections
  aggiungono il precedente stato long-term 
 c
(t-1) 
all'input dei controllers del 
 forget
  e 
input
  gate. Lo stato long-term corrente 
 c
(t)
 è 
aggiunto all'input controller dell'output gate.  
Non sempre ci sono miglioramenti,  
perciò si può tentare di usarli e valutare.  
In Keras non c'è supporto uf
 ﬁ
ciale alla cella con 
 peephole connections
 , ma si 
può creare un layer RNN generico e passargli 
 PeepholeLSTMCell
  al suo 
costruttore.
40
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#4,4,"Alcuni task con dati temporali
Speech recognition  
Music generation  
Sentiment classi
 ﬁ
cation  
DNA sequence analysis  
Machine translation  
(Video) Activity recognition
“It was a bright cold day in 
April, and the clocks were 
striking thirteen
“I loved this so much. I crap out 
on books about 40 pages in about 
90% of the time.”
Ø  
o few inputs
ACAAGATGCCATTGTCCCCCGGCCTCCTGCTGC ACAAGATG CCATTGTCCCCCGGCCTCCT GCTGC
“Ho corso per arrivare in orario.” “I ran to get on time.”
Alzarsi -> In piedi -> Camminare"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#40,40,"Celle GRU - motivazioni
Dopo le LSTM sono state studiate altre architetture che potessero mantenere i 
vantaggi ma con meno risorse di calcolo necessarie.  
Le celle 
 Gated Recurrent Unit (GRU)
 , con un numero minore di gate, sono 
state proposte per tale scopo, 
41"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#41,41,"Celle GRU
Le celle 
 Gated Recurrent Unit
  (
GRU
 ) sono una versione sempli
 ﬁ
cata, e con 
meno parametri, delle LSTM. In molti task mostrano prestazioni simili con 
tempi di addestramento ridotti.  
Le sempli
 ﬁ
cazioni sono le seguenti:  
•
Entrambi i vettori di stato sono fusi in un singolo vettore 
 h
(t)
. 
•
Un singolo 
 update gate  
z
(t)
 rappresenta una fusione del 
 forget
  e 
input gate
 . 
La funzione 
 keras.layers.GRU
  è impiegata in modo simile a SimpleRNN e 
LSTM.
42
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#42,42,"Celle GRU (2)
Intuitivamente il 
 reset gate
  r(t)
 controlla quanto dello stato precedente 
vogliamo mantenere nelle successive elaborazioni.  
L'
update gate  
z(t)
 controlla quanto il nuovo stato sia copia dello stato 
precedente.  
Entrambi i gate sono implementati con una FC e funzione di attivazione 
sigmoid
 , perciò con output in (0,1).
43
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#43,43,"Celle GRU (3)
Il 
hidden state candidato h(t) 
 (candidato poiché dobbiamo ancora sommare la 
componente del 
 update gate
 ) sarà generato combinando insieme 
 x(t)
 e 
l'output del reset gate 
 r(t)
, e impiegando una funzione di attivazione 
 tanh
. 
Quando il  
reset gate  
ha output pari a 1, otteniamo una RNN tradizionale. Se il 
gate
 genera 0, l'hidden state candidato coincide con l'output della FC con 
 x(t) 
come input. Perciò l'hidden state sarà resettato. 
44
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#44,44,"Celle GRU (4)
Il 
hidden state h(t)  
dipende dal 
 update gate
 , che determina quanto il nuovo 
stato corrisponde al vecchio oppure al nuovo stato candidato.  
Quando l'
 update gate
  è 1, manteniamo lo stato così com'è, e l'informazione 
x(t) non sarà considerata per alterarlo. Perciò ignoriamo lo step corrente nella 
catena di correlazioni che stiamo rappresentando con lo stato. Se l'output del 
gate è 0, lo stato corrisponde al candidato che abbiamo appena creato.
45
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#5,5,"Nodi Ricorrenti
Finora abbiamo considerato reti neurali 
 feedforward
 , dove le attivazioni si 
propagano
  dall'input all'output layer.   
Le 
RNN
  sono simili alle reti feedforward, ma hanno connessioni anche 
 verso i 
layer precedenti
 , creando una specie di ciclo.  
La più semplice 
 RNN
  consiste in un 
 nodo ricorrente 
 (o
 recurrent neuron
 ) 
che 
riceve l'input 
 x
, produce in output 
 y,
 e lo stesso output viene 
 riproposto
  in input.  
•
Ad ogni 
 iterazione  
t
, (o 
step
, o 
frame
 ), il nodo ricorrente riceve l'input 
 x
(t)
 e 
l'output precedente 
 y
(t-1)
. Il valore 
 y
(t)
 alla prima iterazione si considera pari a 0.  
La RNN si può rappresentare esplicitando l'asse temporale (
 unrolling the 
network through time
 ).
6
"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#6,6,"Nodi Ricorrenti e Layers
Se 
x
(t) 
e 
y
(t-1)
 sono vettori, i parametri che de
 ﬁ
niscono il comportamento di un 
nodo ricorrente consistono in due vettori di pesi: 
 w
x
 e 
w
y
.  
L'
output  
di un singolo nodo
  si ricava nel modo usuale:  
 
Un
 layer di nodi ricorrenti 
 comprende più nodi, ed i parametri saranno 
perciò rappresentati da due matrici 
  e 
 .
y
(
t
)
=
σ
(
w
T
x
x
(
t
)
+
w
T
y
y
(
t
−
1
)
+
b
)
W
x
W
y
layer di nodi ricorrenti"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#7,7,"Nodi ricorrenti: calcolo degli output
Nel caso più generale di
  un layer di nodi ricorrenti 
 con un input costituito da 
vettori
 , cioè istanze rappresentate con più features:  
  dove:  
•
  è una matrice 
 m
n
nodi
, che contiene gli output del layer di 
 n
nodi
 nodi 
ricorrenti, per ognuna delle 
 m
 istanze all'interno del mini-batch,  
•
  è una matrice 
 m
n
inputs
, dove 
 n
inputs
 sono il numero di features in input,  
•
  è la matrice 
 n
inputs
 n
nodi
 dei pesi delle connessioni per le istanze in input,  
•
  è la matrice 
 n
nodi
n
nodi
 dei pesi delle connessioni per i valori in output 
ottenuti nello step precedente.  
•
Si può dire che una RNN è una feedforward NN dove i parametri di ogni 
layer sono condivisi (cioè sono gli stessi) per tutti i time steps.
Y
(
t
)
=
σ
(
x
(
t
)
W
x
+
y
(
t
−
1
)
W
y
+
b
)
y
(
t
)
×
x
(
t
)
×
W
x
×
W
y
×
8"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#8,8,"Nodi ricorrenti: forma compatta
Le matrici dei pesi 
  e 
   sono spesso 
 concatenate
  verticalmente in una 
singola matrice (
 n
inputs
+n
nodi
)
n
nodi 
La notazione 
  rappresenta la concatenazione delle matrici 
  
In questo modo si ottiene la seguente 
 forma compatta
 : 
   con    
È chiaro che 
  è funzione di 
  e 
 , quest'ultimo è funzione di 
  e 
, che è funzione di 
  e 
 , e così via.  
Di conseguenza  
dipende da tutti i valori in input 
 ﬁ
no a 
t=0
. 
Si può dire che il nodo contiene memoria di tutti gli input precedenti. In realtà 
i pattern che può riconoscere non sono lunghi tipicamente più di 10 steps.
W
x
W
y
×
[
X
(
t
)
Y
(
t
−
1
)
]
X
(
t
)
 e 
Y
(
t
−
1
)
σ
(
[
X
(
t
)
Y
(
t
−
1
)
]
W
+
b
)
 W
=
[
W
x
W
y
]
Y
(
t
)
 X
(
t
)
Y
(
t
−
1
)
 X
(
t
−
1
)
Y
(
t
−
2
)
 X
(
t
−
2
)
Y
(
t
−
3
)
Y
(
t
)
9"
data_test\rootfolder\università\DeepLearning\12-RNN 1-sbloccato.pdf#9,9,"Memory Cells
Una rete neurale in grado di tenere traccia degli stati in cui si è trovata nelle 
passate iterazioni si chiama 
 memory cell
  (o 
cell
). 
•
Un singolo
  recurrent node,
  o un layer di tali nodi, è una 
 cella
 elementare, in 
grado di riconoscere piccoli patterns, tipicamente non più lunghi di 10 steps.  
Indichiamo 
 stato
  di una cella all'istante 
 t
 con la notazione 
 , dove 
 h
 sta per 
hidden
 . Lo stato dipende dall'input corrente e dallo stato precedente:  
 
•
Anche l'
 output  
 dipende dalle stesse quantità.  
Nelle celle elementari 
 output
  e 
stato  
coincidono
 , ma nelle celle più 
complesse non sempre accade, come nel seguente esempio:
h
(
t
)
h
(
t
)
=
f
(
h
(
t
−
1
)
,
x
(
t
)
)
y
(
t
)
10
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recurrent Neural Networks (RNN) - parte #2
1"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#1,1,"Sommario
1d convolution per sequenze  
WaveNet  
Deep RNN  
Bidirectional RNN  
Encoder-decoder e Keras  
Esercizi"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#10,10,"Bidirectional RNN - motivazioni
Finora abbiamo visto scenari di predizione dove un valore in output dipende 
dai valori precedenti (es. predizione di una parola data una frase iniziale).  
In altri task è utile considerare il contesto di un valore in entrambe le 
direzioni, es. Part-of-speech tagging.  
•
Ad esempio, nel seguente task tentiamo di predire il token mancante dal 
testo dato come input:
11
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#11,11,"Bidirectional RNN
Nelle Bidirectional RNN abbiamo 2 layer unidirezionali con direzioni opposte, 
che operano sul medesimo input. Nel primo layer, il primo input è 
 x
1
 e l'ultimo 
x
T
, nel secondo il primo input è 
 x
T
 e l'ultimo 
 x
1
. 
L'output è generato concatenando l'output dei 2 layers.  
•
Nel caso multilayer, l'output diverrà l'input dei successivi 2 layers 
bidirezionali, e così via 
 ﬁ
no al layer di output.  
In Keras sono implementate con il parametro 
 bidirectional=
 True
.
12
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#12,12,"Architettura Encoder-decoder - Keras
14-encoder_decoder_interfaces.ipynb
13
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#13,13,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?
14"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#14,14,"RNN - Applicazioni
Puoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  
E di una sequence-to-vector, o di una vector-to-sequence?  
Sequence-to-sequence: previsioni meteo, machine translation (con Encoder-
decoder), video captioning, speech to text, music generation, identi
 ﬁ
care 
accordi nella musica.  
Sequence-to-vector: classi
 ﬁ
care brani musicali in base al genere, analizzare il 
sentimento di una recensione di un libro, predire quale parola sta pensando un 
paziente afasico in base ai segnali di impianti cerebrali, stimare la probabilità 
di vedere un certo 
 ﬁ
lm in base ai 
 ﬁ
lm visti in passato.  
Vector-to-sequence: image captioning, creare una playlist di musica in base agli 
embedding dell'artista corrente, generare una melodia in base a dei parametri, 
identi
 ﬁ
care pedoni in una foto.
15"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#15,15,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?
16"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#16,16,"RNN - Dimensioni
Quante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni 
dimensione? E riguardo gli output?  
Un layer RNN deve avere input 3 dimensionali: la prima dimensione è la 
dimensione del batch (cioè il numero di time series), la seconda rappresenta il 
dimensione temporale, e la terza indica il numero di features per step.  
L'output sarà ancora 3 dimensionale, con le stesse 2 dimensioni dell'input, ma 
con l'ultima dimensione uguale al numero di nodi. 
17"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#17,17,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?
18"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#18,18,"RNN - Parametro return_sequence
Se vuoi costruire una sequence-to-sequence RNN, quali layer devono avere 
return_sequence=True? E per quanto riguarda la sequence-to-vector?  
Per una sequence-to-sequence, il parametro è True per tutti i layer.  
Per una sequence-to-vector, il parametro è True per tutti gli RNN layers eccetto 
l'ultimo layer, impostato a False.
19"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#19,19,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?
20"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#2,2,"1d convolution per le sequenze
Sebbene popolari, 
 LSTM
  e 
GRU
  non sono adatte a sequenze che contengono 
pattern signi
 ﬁ
cativi che si estendo per molti steps (es. 100). Una alternativa è 
ridurre
  la lunghezza delle sequenze in input.  
Impieghiamo le 
 1d convolution
  sulle sequenze in input considerando come 
profondità la dimensione temporale piuttosto che spaziale. Fissiamo segmenti 
di dimensioni prede
 ﬁ
nita sulle sequenze in input per creare tali sequenze che 
corrispondono alle dimensioni del kernel.  
Estendiamo l'approccio considerando più 
 ﬁ
ltri 1d convolution.  Ogni 
 ﬁ
ltro 
riconoscerà determinati pattern.  
•
Ad esempio, con 10 kernels, l'output complessivo del layer consisterà in 10 
sequenze 1-dimensionali, tutte della stessa lunghezza, o una singola 
sequenza 10-dimensionale.  
Possiamo avere reti che alternano layer 1d convolution e layer ricorrenti, ed 
eventualmente layer di pooling. In questo modo le celle analizzeranno dati 
temporali più 
 compatti
 . Oppure possiamo avere reti costituite interamente da 
moduli convolutivi (es. WaveNet).
3"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#20,20,"RNN - Forecasting
Supponi di avere una time series univariate con campionamento giornaliero e 
vuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?  
L'architettura più semplice è una sequence-to-vector, cioè uno stack di RNN 
layers (tutti con return_sequences=True eccetto il primo), con 7 nodi nel layer 
di output. Si addestra il modello con 
 ﬁ
nestre random dalle time series (es. 
sequence di 30 giorni consecutivi e un vettore contenente i valori dei successivi 
7 giorni come target).  
In alternativa si imposta return_sequences=True per tutti i layer creando una 
sequence-to-sequence. Per l'addestramento si usano random windows con la 
stessa lunghezza del target. 
21"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#21,21,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?
22"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#22,22,"RNN - Training
Quali sono le maggiori dif
 ﬁ
coltà nel training di una RNN e come puoi 
affrontarle?  
Le due maggiori problematiche sono l'instabilità dei gradienti e la short-term 
memory limitata. I problemi peggiorano in presenza di sequenze molto lunghe.  
Per affrontarli si usano learning rate più bassi, funzioni di attivazioni che 
saturano ed eventualmente gradient clipping, layer normalization o dropout ad 
ogni step. Per la short-term memory, si impiegano celle LSTM o GRU.
23"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#23,23,"RNN - LSTM
Rappresenta l'architettura LSTM gra
 ﬁ
camente.
24"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#24,24,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?
25"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#25,25,"RNN - 1d conv
Perché vorresti impiegare una 1d conv all'interno di una RNN?  
Una RNN opera sequenzialmente: per calcolare l'output al tempo t, deve prima 
calcolare gli output degli step precedenti. Questo rende impossibile 
parallelizzare l'elaborazione.  
La 1d conv non mantiene uno stato tra elaborazioni successive perciò e 
facilmente parallelizzabile. Non essendo ricorrente, è meno affetta da gradienti 
instabili.  
Più 1d conv possono processare l'input riducendo la risoluzione temporale 
(downsampling) permettendo di analizzare time series molto lunghe.  
Infatti la WaveNet analizza time series impiegando solo 1d conv.
26"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#26,26,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video? 
27"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#27,27,"RNN - Scenario
Quale architettura NN impiegheresti per classi
 ﬁ
care video?  
Prendiamo un frame per secondo e lo diamo in input a una rete 
convoluzionale. L'output della CNN è passato in input a una sequence-to-
vector RNN, il cui output è passato a una layer softmax, ottenendo una 
distribuzione di probabilità sulle classi.  
La funzione di costo può essere una cross entropy.  
Per usare l'audio si possono impiegare layer 1d conv, per ridurre la risoluzione 
da migliaia di audio frames per secondo a 1 solo per secondo, così da 
sincronizzarsi rispetto ai frame, e concatenare l'output con l'input alla 
sequence-to-vector.
28"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#28,28,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow.
29
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#29,29,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset 
disponibile dentro Tensor
 ﬂ
ow. 
DOWNLOAD_ROOT = 
 ""http://download.tensorflow.org/data/""
FILENAME = 
 ""quickdraw_tutorial_dataset_v1.tar.gz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/quickdraw""
 ,
                                extract=
 True
)
quickdraw_dir = Path(filepath).parent
train_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""training.tfrecord-*""
 )])
eval_files = 
 sorted
([str(path) 
 for
 path 
in
 quickdraw_dir.glob(
 ""eval.tfrecord-*""
 )])
with 
open
(quickdraw_dir / 
 ""eval.tfrecord.classes""
 ) 
as
 test_classes_file:
    test_classes = test_classes_file.readlines()
    
with 
open
(quickdraw_dir / 
 ""training.tfrecord.classes""
 ) 
as
 train_classes_file:
    train_classes = train_classes_file.readlines()
assert
 train_classes == test_classes
class_names = [name.strip().lower() 
 for
 name 
in
 train_classes]
sorted
(class_names)
30"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#3,3,"1d convolution per le sequenze: esempio
Il modello include una 
 1d conv 
 che opera una sorta di 
 downsampling
  delle 
sequenze in input di un fattore 2 impiegano uno stride 2. Il kernel è più grande 
dello stride perciò tutta l'informazione verrà considerata.  
Riducendo la lunghezza in input sarà più facile per la GRU riconoscere pattern 
più lunghi.  
model = keras.models.Sequential([
    keras.layers.Conv1D(filters=
 20
, kernel_size=
 4
, strides=
 2
, 
padding=
 ""valid""
,
                        input_shape=[
 None
, 
1
]),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.GRU(
 20
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 10
))
])
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, 
metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train[:, 
 3
::
2
], epochs=
 20
,
                    validation_data=(X_valid, Y_valid[:, 
 3
::
2
]))
•
Nota: Avendo kernel di dimensione 4, è opportuno ignorare i primi 3 step nei valori target, e 
fare dowsampling dei target di un fattore 2.
4"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#30,30,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
def 
parse
(
data_batch
 ):
    feature_descriptions = {
        
 ""ink""
: tf.io.VarLenFeature(dtype=tf.float32),
        
 ""shape""
: tf.io.FixedLenFeature([
 2
], dtype=tf.int64),
        
 ""class_index""
 : tf.io.FixedLenFeature([
 1
], dtype=tf.int64)
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[
 ""ink""
])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), 
 -1
, 
3
])
    lengths = examples[
 ""shape""
][:, 
0
]
    labels = examples[
 ""class_index""
 ][:, 
0
]
    
return
 sketches, lengths, label
 s
def 
quickdraw_dataset
 (
filepaths
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                      
 n_parse_threads
 =
5
, 
n_read_threads
 =
5
, 
cache
=
False
)
:
    dataset = tf.data.TFRecordDataset(filepaths
 ,
                                      num_parallel_reads=n_read_threads
 )
    
if
 cache
:
        dataset = dataset.cache(
 )
    
if
 shuffle_buffer_size
 :
        dataset = dataset.shuffle(shuffle_buffer_size
 )
    dataset = dataset.batch(batch_size
 )
    dataset = dataset.
 map
(parse, num_parallel_calls=n_parse_threads
 )
    
return
 dataset.prefetch(
 1
)
31"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#31,31,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro Tensor
 ﬂ
ow. 
train_set = quickdraw_dataset(train_files, shuffle_buffer_size=
 10000
)
valid_set = quickdraw_dataset(eval_files[:
 5
]
)
test_set = quickdraw_dataset(eval_files[
 5
:]
)
def 
draw_sketch
 (
sketch
, 
label
=
None
)
:
    origin = np.array([[
 0
., 
0
., 
0
.]]
)
    sketch = np.r_[origin, sketch
 ]
    stroke_end_indices = np.argwhere(sketch[:, 
 -1
]==
1
.)[:, 
0
]
    coordinates = np.cumsum(sketch[:, :
 2
], axis=
 0
)
    strokes = np.split(coordinates, stroke_end_indices + 
 1
)
    title = class_names[label.numpy()] 
 if
 label 
is 
not 
None 
else 
""Try to guess""
    plt.title(title
 )
    plt.plot(coordinates[:, 
 0
], -coordinates[:, 
 1
], 
""y:""
)
    
for
 stroke 
 in
 strokes
 :
        plt.plot(stroke[:, 
 0
], -stroke[:, 
 1
], 
"".-""
)
    plt.axis(
 ""off""
)
def 
draw_sketches
 (
sketches
 , 
lengths
, 
labels
)
:
    n_sketches = 
 len
(sketches
 )
    n_cols = 
 4
    n_rows = (n_sketches - 
 1
) // n_cols + 
 1
    plt.figure(figsize=(n_cols * 
 3
, n_rows * 
 3.5
)
)
    
for
 index, sketch, length, label 
 in 
zip
(
range
(n_sketches), sketches, lengths, labels)
 :
        plt.subplot(n_rows, n_cols, index + 
 1
)
        draw_sketch(sketch[:length], label
 )
    plt.show()
32"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#32,32,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
for
 sketches, lengths, labels 
 in
 train_set.take(
 1
)
:
    draw_sketches(sketches, lengths, labels
 )
lengths = np.concatenate([lengths 
 for
 _, lengths, _ 
 in 
train_set.take(
 1000
)]
)
plt.hist(lengths, bins=
 150
, density=
 True
)
plt.axis([
 0
, 
200
, 
0
, 
0.03
]
)
plt.xlabel(
 ""length""
 )
plt.ylabel(
 ""density""
 )
plt.show(
 )
def 
crop_long_sketches
 (
dataset
, 
max_length
 =
100
)
:
    
return
 dataset.
 map
(
lambda
 inks, lengths, labels: 
(inks[:, :max_length], labels)
 )
cropped_train_set = crop_long_sketches(train_set
 )
cropped_valid_set = crop_long_sketches(valid_set
 )
cropped_test_set = crop_long_sketches(test_set
 )
33"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#33,33,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
model = keras.models.Sequential(
 [
    keras.layers.Conv1D(
 32
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 64
, kernel_size=
 5
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.Conv1D(
 128
, kernel_size=
 3
, strides=
 2
, activation=
 ""relu""
)
,
    keras.layers.BatchNormalization()
 ,
    keras.layers.LSTM(
 128
, return_sequences=
 True
)
,
    keras.layers.LSTM(
 128
)
,
    keras.layers.Dense(
 len
(class_names), activation=
 ""softmax""
 )
]
)
optimizer = keras.optimizers.SGD(lr=
 1e-2
, clipnorm=
 1
.
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 ,
              optimizer=optimizer
 ,
              metrics=[
 ""accuracy""
 , 
""sparse_top_k_categorical_accuracy""
 ]
)
history = model.fit(cropped_train_set, epochs=
 2
,
                    validation_data=cropped_valid_set
 )
y_test = np.concatenate([labels 
 for
 _, _, labels 
 in
 test_set]
 )
y_probas = model.predict(test_set)
34"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#34,34,"RNN - Sketch dataset
Addestra un modello per la classi
 ﬁ
cazione per il Sketch-RNN dataset disponibile dentro 
Tensor
 ﬂ
ow. 
np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas)
 )
n_new = 
 10
Y_probas = model.predict(sketches
 )
top_k = tf.nn.top_k(Y_probas, k=
 5
)
for
 index 
in 
range
(n_new)
:
    plt.figure(figsize=(
 3
, 
3.5
)
)
    draw_sketch(sketches[index]
 )
    plt.show(
 )
    
print
(
""Top-5 predictions:""
 .
format
(index + 
 1
)
)
    
for
 k 
in 
range
(
5
)
:
        class_name = class_names[top_k.indices[index, k]
 ]
        proba = 
 100
 * top_k.values[index, k
 ]
        
 print
(
""  {}. {} {:.3f}%""
 .
format
(k + 
1
, class_name, proba)
 )
    
print
(
""Answer: {}""
 .
format
(class_names[labels[index].numpy()])
 )
model.save(
 ""my_sketchrnn""
 )
35"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#35,35,"RNN - Generazione di musica
Scarica il dataset Bach chorales e scompattalo. Consiste in 382 corali composti 
da Johann Sebastian Bach. Ogni corale è lungo da 100 a 640 time steps, e ogni 
step contiene 4 interi, dove ogni interno corrisponde alla nota su un piano. Lo 0 
indica che che non si suona alcuna nota.  
Addestra un modello ricorrente o convoluzionale, o entrambi, che può predire 
il successivo step (4 note), data una sequenza del corale. Usa quello modello 
per generare musica in stile Bach, ad esempio dando in input l'inizio di un 
corale e ottenendo la predizione che userai come successivo input.  
In
ﬁ
ne dai un'occhiata al Google Coconet model.  
36"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#36,36,"RNN - Generazione di musica
DOWNLOAD_ROOT = 
 ""https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/""
FILENAME = 
 ""jsb_chorales.tgz""
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=
 ""datasets/jsb_chorales""
 ,
                                extract=
 True
)
jsb_chorales_dir = Path(filepath).parent
train_files = 
 sorted
(jsb_chorales_dir.glob(
 ""train/chorale_*.csv""
 ))
valid_files = 
 sorted
(jsb_chorales_dir.glob(
 ""valid/chorale_*.csv""
 ))
test_files = 
 sorted
(jsb_chorales_dir.glob(
 ""test/chorale_*.csv""
 ))
import
 pandas 
 as
 pd
def 
load_chorales
 (
filepaths
 ):
    
return
 [pd.read_csv(filepath).values.tolist() 
 for
 filepath 
 in
 filepaths]
train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)
train_chorales[
 0
]
notes = set()
for
 chorales 
 in
 (train_chorales, valid_chorales, test_chorales):
    
for
 chorale 
 in
 chorales:
        
 for
 chord 
in
 chorale:
            notes |= set(chord)
n_notes = 
 len
(notes)
min_note = 
 min
(notes - {
 0
})
max_note = 
 max
(notes)
37"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#37,37,"RNN - Generazione di musica
assert
 min_note == 
 36
assert
 max_note == 
 81
from
 IPython.display 
 import
 Audio
def 
notes_to_frequencies
 (
notes
):
    
# Frequency doubles when you go up one octave; there are 12 semi-tones
    
# per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    
return 
2
 ** ((np.array(notes) - 
 69
) / 
12
) * 
440
def 
frequencies_to_samples
 (
frequencies
 , 
tempo
, 
sample_rate
 ):
    note_duration = 
 60
 / tempo 
 # the tempo is measured in beats per minutes
    
# To reduce click sound at every beat, we round the frequencies to try to
    
# get the samples close to zero at the end of each note.
    frequencies = np.
 round
(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(
 0
, note_duration, n_samples)
    sine_waves = np.sin(
 2
 * np.pi * frequencies.reshape(
 -1
, 
1
) * time)
    
# Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 
 9
.).reshape(
 -1
, 
1
)
    
return
 sine_waves.reshape(
 -1
)
def 
chords_to_samples
 (
chords
, 
tempo
, 
sample_rate
 ):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[
 -1
:]] 
# make last note a bit longer
    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)
                     
 for
 melody 
 in
 freqs.T], axis=
 0
)
    n_fade_out_samples = sample_rate * 
 60
 // tempo 
 # fade out last note
    fade_out = np.linspace(
 1
., 
0
., n_fade_out_samples)**
 2
    merged[-n_fade_out_samples:] *= fade_out
    
return
 merged
38"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#38,38,"RNN - Generazione di musica
def 
play_chords
 (
chords
, 
tempo
=
160
, 
amplitude
 =
0.1
, 
sample_rate
 =
44100
, 
filepath
 =
None
):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    
if
 filepath:
        
 from
 scipy.io 
 import
 wavfile
        samples = (
 2
**
15
 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        
 return
 display(Audio(filepath))
    
else
:
        
 return
 display(Audio(samples, rate=sample_rate))
for
 index 
in 
range
(
3
):
    play_chords(train_chorales[index])
def 
create_target
 (
batch
):
    X = batch[:, :
 -1
]
    Y = batch[:, 
 1
:] 
# predict next note in each arpegio, at each step
    
return
 X, Y
def 
preprocess
 (
window
):
    window = tf.where(window == 
 0
, window, window - min_note + 
 1
) 
# shift values
    
return
 tf.reshape(window, [
 -1
]) 
# convert to arpegio
def 
bach_dataset
 (
chorales
 , 
batch_size
 =
32
, 
shuffle_buffer_size
 =
None
,
                 
 window_size
 =
32
, 
window_shift
 =
16
, 
cache
=
True
):
    
def 
batch_window
 (
window
):
        
 return
 window.batch(window_size + 
 1
)
    
def 
to_windows
 (
chorale
):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 
 1
, window_shift, drop_remainder=
 True
)
        
 return
 dataset.flat_map(batch_window)
    chorales = tf.ragged.constant(chorales, ragged_rank=
 1
)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).
 map
(preprocess)
    
if
 cache:
        dataset = dataset.cache()
    
if
 shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.
 map
(create_target)
    
return
 dataset.prefetch(
 1
)
39"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#39,39,"RNN - Generazione di musica
train_set = bach_dataset(train_chorales, shuffle_buffer_size=
 1000
)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)
n_embedding_dims = 
 5
model = keras.models.Sequential([
    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,
                           input_shape=[
 None
]),
    keras.layers.Conv1D(
 32
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 48
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 2
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 64
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 4
),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(
 96
, kernel_size=
 2
, padding=
 ""causal""
 , activation=
 ""relu""
, dilation_rate=
 8
),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(
 256
, return_sequences=
 True
),
    keras.layers.Dense(n_notes, activation=
 ""softmax""
 )
])
model.summary()
optimizer = keras.optimizers.Nadam(lr=
 1e-3
)
model.
compile
(loss=
""sparse_categorical_crossentropy""
 , optimizer=optimizer,
              metrics=[
 ""accuracy""
 ])
model.fit(train_set, epochs=
 20
, validation_data=valid_set)
model.save(
 ""my_bach_model.h5""
 )
model.evaluate(test_set)
40"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#4,4,"Architettura WaveNet
Le rete convolutiva 
 WaveNet
  impiega più layer 1d conv, dove ad ogni layer si 
raddoppia la lunghezza della LRF, chiamato anche 
 dilatation rate.
  In questo 
modo ogni layer raddoppia i dati analizzati rispetto al layer precedente.  
•
I primi layer riconoscono pattern 
 short-term
 , gli ultimi i pattern estesi.  
•
Per dilatation >1, i layer ignoreranno alcuni campioni all'interno del LRF che 
però saranno considerati nei layer precedenti.  
Il training è più rapido rispetto alle RNN non essendoci collegamenti ricorrenti.  
L'output può essere accodato all'input successivo per fare predizione (es. 
generazione voce umana).
5
stack of conv layers"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#40,40,"RNN - Generazione di musica
def 
generate_chorale
 (
model
, 
seed_chords
 , 
length
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note = model.predict_classes(arpegio)[:
 1
, 
-1
:]
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
seed_chords = test_chorales[
 2
][:
8
]
play_chords(seed_chords, amplitude=
 0.2
)
new_chorale = generate_chorale(model, seed_chords, 
 56
)
play_chords(new_chorale)
def 
generate_chorale_v2
 (
model
, 
seed_chords
 , 
length
, 
temperature
 =
1
):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [
 1
, 
-1
])
    
for
 chord 
in 
range
(length):
        
 for
 note 
in 
range
(
4
):
            next_note_probas = model.predict(arpegio)[
 0
, 
-1
:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=
 1
)
            arpegio = tf.concat([arpegio, next_note], axis=
 1
)
    arpegio = tf.where(arpegio == 
 0
, arpegio, arpegio + min_note - 
 1
)
    
return
 tf.reshape(arpegio, shape=[
 -1
, 
4
])
41"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#41,41,"RNN - Generazione di musica
new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 0.8
)
play_chords(new_chorale_v2_cold, filepath=
 ""bach_cold.wav""
 )
new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.0
)
play_chords(new_chorale_v2_medium, filepath=
 ""bach_medium.wav""
 )
new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 
 56
, temperature=
 1.5
)
play_chords(new_chorale_v2_hot, filepath=
 ""bach_hot.wav""
 )
play_chords(test_chorales[
 2
][:
64
], filepath=
 ""bach_test_4.wav""
 )
42"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#5,5,"6
1
2
3
4
https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio
Nella 
 WaveNet
  l'output layer ha la 
stessa dimensionalità temporale 
dell'input.  
Il singolo valore in output è prodotto 
da una 
 softmax
 , perciò con 
distribuzione sulle categorie 
disponibili.  
Le 
dilated convolution
  sono simili ai 
layer convolutivi con pooling e 
stride, ma in questo caso l'output ha 
la stessa dimensione dell'input.  
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#6,6,"WaveNet: esempio
Impostando il 
 padding  
causal
  si garantisce che l'input non conterrà dati oltre a 
quello attuale.  
Il parametro 
 dilatation_rate
  de
ﬁ
nisce l'architettura WaveNet.  
L'ultimo layer è convolutivo con 10 
 ﬁ
ltri di dimensione 1 senza funzione di 
attivazione. Ogni conv layer produce una sequenza della stessa lunghezza 
dell'input, cosicché possiamo usare i target senza ridimensionarli.  
Nell'esempio manca il layer softmax impiegato nell'esempio precedente.  
model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[
 None
, 
1
]))
for
 rate 
in
 (
1
, 
2
, 
4
, 
8
) * 
2
:
    model.add(keras.layers.Conv1D(filters=
 20
, kernel_size=
 2
, padding=
 ""causal""
 ,
                                  activation=
 ""relu""
, dilation_rate=rate))
model.add(keras.layers.Conv1D(filters=
 10
, kernel_size=
 1
))
model.
compile
(loss=
""mse""
, optimizer=
 ""adam""
, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=
 20
,
                    validation_data=(X_valid, Y_valid))
7"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#7,7,"Deep RNN
Finora abbiamo visto RNN con un singolo hidden layer ricorrente, uno strato 
di input e uno di output. Le memory cell permettono di creare correlazioni 
che in
 ﬂ
uenza step anche distanti tra loro (direzione temporale).  
Nelle Deep RNN si vogliono identi
 ﬁ
care correlazioni anche tra input e output 
nello stesso step (direzione input-output). Per questo si considerano più layer 
stacked 
 sequence-to-sequence.  
•
Il primo layer produce una sequenza in output di lunghezza T, che sarà 
l'input del successivo layer.  
•
Ogni cella perciò dipenderà dai valori  
del layer negli step precedente, e dai  
valori generati dai layer precedenti nello  
stesso step.  
Architetture comuni di RNN hanno  
lunghezza (
 numero di step
 ) nel range  
64-2056 e profondità in 1-8.
8
"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#8,8,"Deep RNN - Keras (1)
12-deep_rnn.ipynb
9"
data_test\rootfolder\università\DeepLearning\13-RNN 2-sbloccato.pdf#9,9,"Deep RNN - Keras (2)
In alternativa alla classe GRU possiamo operare uno stacking impiegando 
Sequential:  
model = keras.models.Sequential([
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
, input_shape=[
 None
, 
1
]),
    keras.layers.SimpleRNN(
 20
, return_sequences=
 True
),
    keras.layers.SimpleRNN(
 1
)
])”
Nota
 : ricordati di impostare return_sequences=
 True
 per ogni layer (tranne 
l'ultimo se ci interessa in output solo l'ultimo valore), altrimenti l'output del 
layer sarà 2D (solo l'ultimo valore) e si crea un mismatch con l'input atteso in 
3D dal successivo layer.
10"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Attention mechanisms e Transformers
1"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#1,1,"Sommario
Beam search  
Attention mechanism  
Multi-head attention  
Self-attention  
Transformers  
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#10,10,"Beam search (2)
La complessità è pari a 
 O
(
k·
|
Y
|·
T'
)
, dove 
 T'
 è il numero massimo di token 
della sequenza in output, e 
 Y
 è il vocabolario.  
Al contrario dell'approccio greedy, la beam search permette di scegliere alcuni 
token meno probabili, sebbene la frase nel suo complesso generi accuracy 
migliori.  
Una ricerca esaustiva di tutte le possibili combinazioni richiederebbe 
complessità 
 O
(|
Y
|
T'
).
11"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#11,11,"Attention cues
Il meccanismo si ispira a studi di neuroscienze cognitive, dove si tenta di dare 
attenzione solo ad una parte degli stimoli generati dal sistema di visione.  
•
le 
nonvolitional cues
  (
keys
) sono legate alla visibilità dell'oggetto 
nell'ambiente (es. tazza di caffè rossa su un tavolino grigio),  
•
le 
volitional cue
  (o 
query
 ) dipendono dal task che stiamo seguendo (es. 
leggere un libro su un tavolo).  
Se abbiamo dei 
 sensory inputs
  da analizzare, la 
 query
  interagisce con le 
 keys 
per selezionare gli input più corretti.  
L'
attention pooling
  aggrega gli input per generare l'output.
12
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#12,12,"Attention pooling e Keras
Ci sono vari modi di implementare l'attention pooling. Qui diamo un esempio 
basato sul modello di regressione Nadaraya-Watson kernel.  
Generiamo un dataset arti
 ﬁ
ciale con questo modello:  
con epsilon generato con distribuzione normale media 0 e varianza 0.5, e 50 
istanze di training e test.  
class 
NonlinearData
 (
d2l
.
DataModule
 ):
    
def 
__init__
 (
self
, 
n
, 
batch_size
 ):
        
 self
.save_hyperparameters()
        f = 
 lambda
 x: 
2
 * tf.sin(x) + x**
 0.8
        
 self
.x_train = tf.sort(tf.random.uniform((n,
 1
)) * 
5
, 
0
)
        
 self
.y_train = f(
 self
.x_train) + tf.random.normal((n,
 1
))
        
 self
.x_val = tf.
 range
(
0
, 
5
, 
5.0
/n)
        
 self
.y_val = f(
 self
.x_val)
    
def 
get_dataloader
 (
self
, 
train
):
        arrays = (
 self
.x_train, 
 self
.y_train) 
 if
 train 
else
 (
self
.x_val, 
 self
.y_val)
        
 return 
self
.get_tensorloader(arrays, train)
n = 
50
data = NonlinearData(n, batch_size=
 10
)
13
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#13,13,"Attention pooling e Keras (2)
Gra
ﬁ
chiamo gli esempi di training (cerchi), il ground truth senza rumore 
(curva blu) la funzione generata per la prediction (tratteggiata rossa).  
Proviamo con l'estimator più facile: 
 average pooling
  sui dati di input:  
y_hat = tf.repeat(tf.reduce_mean(data.y_train), n)
plot_kernel_reg(y_hat)
def 
plot_kernel_reg
 (
y_hat
):
    d2l.plot(data.x_val, [data.y_val, y_hat.numpy()], 
 'x'
, 
'y'
, legend=[
 'Truth'
, 
'Pred'
],
             xlim=[
 0
, 
5
], ylim=[
 -1
, 
5
])
    d2l.plt.plot(data.x_train, data.y_train, 
 'o'
, alpha=
 0.5
);
14"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#14,14,"Attention pooling e Keras (3)
Nel seguente nonparametric attention pooling chiamato 
 Nadaraya-Watson 
kernel regression 
 pesiamo gli output in base alla posizione degli input.  
dove K è il kernel. Generalizzandolo (non serve ora studiare i dettagli del 
regressore) possiamo de
 ﬁ
nire un qualsiasi 
 attention pooling
  nel seguente 
modo:  
dove 
 x
 è la 
 query
 , e (
x
i
,y
i
) e la coppia 
 chiave-valore
 . Perciò ogni valore 
 y
i
 è 
pesato e si può pensare come una distribuzione di probabilità sull'insieme 
chiavi-valore.  
15
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#15,15,"Attention pooling e Keras (4)
Gra
ﬁ
cando l'output del nuovo modello otteniamo:  
def 
diff
(
queries
, 
keys
):
    
return
 tf.reshape(queries, (
 -1
, 
1
)) - tf.reshape(keys, (
 1
, 
-1
))
def 
attention_pool
 (
query_key_diffs
 , 
values
):
    attention_weights = tf.nn.softmax(- query_key_diffs**
 2
/
2
, axis=
1
)
    
return
 tf.matmul(attention_weights, values), attention_weights
y_hat, attention_weights = attention_pool(
    diff(data.x_val, data.x_train), data.y_train)
plot_kernel_reg(y_hat)
16
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#16,16,"Attention pooling e Keras (5)
Analizzando i pesi generati dell'attention pooling, con le 
 query
  come 
validation inputs
  e 
keys
 come 
 training inputs
 , notiamo come all'avvicinarsi dei 
valori tra 
 query
  e 
chiave
 , i pesi sono più signi
 ﬁ
cativi:  
d2l.show_heatmaps([[attention_weights]],
                  xlabel=
 'Sorted training inputs'
 ,
                  ylabel=
 'Sorted validation inputs'
 )
17
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#17,17,"Attention Scoring functions
L'output dell'
 attention mechanism
  possiamo valutarlo con una 
 softmax
  e 
interpretarlo come distribuzione di probabilità sui valori che sono in paio con 
le chiavi.  
18
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#18,18,"Multi-head attention
L'attention mechanism potrebbe richiedere di analizzare dipendenze su vari 
intervalli (short e long-range) all'interno delle sequenze. Invece di un singolo 
pooling, possiamo generare 
 h
 proiezioni lineari indipendenti. Gli 
 h
 output 
sono concatenati e passati ad una combinazione lineare 
 ﬁ
nale per produrre 
l'output. Ognuna delle 
 h 
attention pooling
  è chiamato 
 head
 .
19
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#19,19,"Self-attention e positional encoding
Supponiamo che in input all'attention mechanism diamo una sequenza di 
tokens. I tokens rappresentano perciò sia le query, le chiavi e i valori. Ogni 
query è relativa e tutte le coppie chiave-valore e genera un output. Per tale 
motivo si parla di 
 self-attention
 . 
Si può dimostrare facilmente che le CNN e i self-attention possono essere 
implementati con computazioni parallele, sebbene sequenze molto lunghe 
penalizzano molto i self-attention.  
Possiamo aggiungere informazioni aggiuntive, come quelle associate alla 
posizione, alla rappresentazione in input del self-attention, poiché durante i 
calcoli queste informazioni vengono ignorate, a differenza delle RNN.
20"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#2,2,"Introduzione
In una architettura 
 encoder-decoder,
  durante la traduzione di un testo notiamo 
come alcune parole generate dal decoder dipendano da poche parole in input 
al encoder. Se le frasi sono molte lunghe, una RNN fa fatica a identi
 ﬁ
care tali 
dipendenze.  
Gli 
attention mechanism 
 introdotti nel 2014 da Bahdanau et al.
(1)
 risolvono in 
parte le limitazioni della memoria delle RNN, arrivando a processare frasi di 
30 parole circa.  
Gli attention mechanism sono alla base dell'architettura 
 Transformers
 , che è 
lo stato dell'arte nel campo dell'NLP in molti task, es. machine language 
translation, conversational chatbots, e per migliorare le performance dei 
search engines.  
L'obiettivo degli 
 attention mechanism 
 è assegnare un livello di importanza alle 
features e sfruttarlo per agevolare il raggiungimento di un certo task. 
3 (1) https://arxiv.org/abs/1409.0473"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#20,20,"Attention mechanism e Encoder-decoder (1)
Nell'architettura 
 encoder-decoder con 
 attention mechanism
 , oltre all'ultimo 
hidden state propagato dal encoder al decoder (non visibile nel disegno), 
inviamo al decoder tutti i valori generati in output dal encoder
 . 
•
Ad ogni step, il 
 decoder
  calcola una combinazione lineare dei valori ottenuti 
in output dal encoder così da determinare su quale parola porre l'attenzione 
al successivo step.  
•
Il peso 
  è riferito al 
 i
-esimo output, allo step 
 t
-esimo...
 α
(
t
,
i
)
21
Nell'esempio, se  è 
maggiore di  e , 
allora il decoder 
assegnerà maggiore 
attenzione al termine 
""milk"" nello step corrente .
La restante elaborazione 
coincide l'architettura 
originale.α(3,2)
α(3,0)α(3,1)Questa con ﬁgurazione 
speci ﬁca di attention 
mechanism è anche 
chiamata:  
Bahdanau attention .  
 
Dato che concatena gli 
output del encoder con gli 
hidden state, si chiama 
anche: concatenative 
attention , o additive 
attention ."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#21,21,"Attention mechanism e Encoder-decoder (2)
I valori 
  sono generati da una rete neurale chiamata 
 alignment model  
(o 
attention layer)
  addestrata con il resto del encoder-decoder.  
•
Consiste in una 
 time-distributed Dense layer
  con un singolo nodo, che 
riceve tutti gli output dal encoder, concatenati con l'hidden state del decoder 
estratti dallo step precedente.  
•
Il layer produce una serie di valori e
 (3,0)
, e
(3,1)
, etc; che indicano 
 quanto ogni 
output è allineato con l'hidden state precedente
 . La 
softmax
  normalizza tali 
valori.
α
(
t
,
i
)
22
 rappresenta l'hidden 
state del decoder .
La rete densa richiede il 
calcolo di n2 parametri, 
supponendo n la 
lunghezza delle frasi in 
input e output. Ma se non 
abbiamo frasi lunghissime 
la complessità è ancora 
praticabile. h(2)"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#22,22,"Image captioning
In questo task occorre generare un testo signi
 ﬁ
cativo in linguaggio naturale 
che descrive una immagine. In altre parole dobbiamo dotare l'algoritmo di 
capacità di ""
 comprensione""
 . 
Usiamo un 
 encoder-decoder
 , dove il 
 decoder
  sfrutta l'
 attention mechanism
 . 
L'
encoder
  è una CNN, e le features sono estratte dal layer convolutivo. 
L'
attention mechanism
  avrà perciò informazione posizionale codi
 ﬁ
cata 
nell'input. Il 
 decoder
  usa lo stato precedente, il token generato in precedenza 
e un context vector per generare il nuovo token.
23 ...
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#23,23,"Image caption e Visual Attention
Il 
context vector
  è generato dall'
 attention mechanism 
 a partire dalle features 
della CNN nell'encoder. Esso rappresenta i pesi per ogni location spaziale 
dell'output dell'encoder (
 visual attention
 ).  
Ad ogni step il decoder usa l'attention model per identi
 ﬁ
care le giusta 
porzione dell'immagine da analizzare per poi per generare la frase.
24
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#24,24,"Explainability
Nel ML con 
 explainability
  si intende la capacità del modello di descrivere il 
suo comportamento in termini comprensibili all'uomo.  
•
Interpretability
  è un concetto simile, ma legato alle relazioni causa-effetto 
del modello, e perciò sulla capacità di stimare un certo output in base a una 
certa con
 ﬁ
gurazione di input. Si può avere interpretability senza 
explainability.  
Utile quando si vuole comprendere un certo output, eventualmente errato.  
•
Es. l'output ""un lupo che si muove sulla neve"" prodotto quando c'è un cane 
come input può dipendere dal fatto che il modello si focalizza sulla presenza 
della neve per classi
 ﬁ
care l'animale.  
I 
modelli DL 
 sono molto complessi e spesso 
 dif
ﬁ
cilmente esplorabili
 . 
Un tentativo è creare modelli interpretabili (es. alberi di decisione) a partire 
dagli output di un modello non interpretabile
(3)
, e usarli per costruire le 
motivazioni di un certo output.
25 (3) https://arxiv.org/abs/1602.04938"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#25,25,"Architettura Transformer - motivazioni
Computazionalmente, i modelli di attention e le 
CNN sono più veloci rispetto all RNN. I Transformer 
sono unicamente basati su tali modelli.  
In ""Attention is all you need""
(4)
, un team di Google 
propose l'architettura 
 Transformer
 , dove il task della 
traduzione dei testi si affronta senza RNN, ma 
principalmente con 
 layer embedding
 , 
dense layers
  e 
di 
normalization
 .  
Inizialmente proposti nel task 
 seq2seq
  sul testo, 
sono stati poi usati in svariati altri domini, es. 
visione, speech, reinforcement learning.  
L'encoder
  mappa le sequenze in input in una 
rappresentazione continua latente che incapsula 
tutte le informazioni rilevanti della sequenza.  
I multi-head attention creano associazioni tra una 
parola e le altre con un sistema di pesi.
26
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#26,26,"Architettura Transformer - (1)
Ad alto livello possiamo notare uno stack di layer 
multipli che si ripetono (
 N
 volte). Ognuno di questi 
macro-layer ha sotto layer.  
Nell'encoder si ha un 
 multi-head self-attention
  e un 
positionwise feed-forward network
 .  
Nell'
 encoder self-attention
 , queries, keys a values 
sono ottenuti dall'output del layer precedente. In 
modo simile alla ResNet, abbiamo connessioni 
residue.  
Lo stack del decoder oltre layer simili all'encoder 
abbiamo un ulteriore layer 
 encoder-decoder 
attention
  nel mezzo, che prende in input l'output 
del layer precedente nel decoder, e keys e values 
ottenuti dall'encoder. 
27
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#27,27,"Architettura Transformer - (2)
Nel decoder self-attention, queries, keys e values 
sono ottenuti dal layer precedente.  
Ogni posizione nel decoder interessa tutte le 
posizioni viste 
 ﬁ
no alla posizione corrente. Infatti 
nel training i dati sono noti, ma in produzione 
possiamo generare token che dipendono solo dai 
token già generati.  
La 
positionwise feed-forward network
  è composta 
da 2 layer FC e prende in input (batch size, number 
of time steps/sequence length in tokens, number of 
hidden units/feature dimension) e produce in output 
(batch size, number of time steps, ffn_num_outputs).  
I transfomer mantengono la proprietà 
 auto-
regressive
 , cioè l'output dipende linearmente dai 
valori prodotti in precedenza e da un termine 
stocastico.
28
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#28,28,"Architettura Transformer e NLP: dettagli (1)
29 (4) https://arxiv.org/abs/1706.03762
L'input si pre-processa come prima, ottenendo 
una
 rappresentazione in uno spazio a 512 
dimensioni
  (cioè uno shape [batch size, max 
input sentence length, 512]) mediante 
 word 
embeddings
 . 
L'output del decoder ha sempre forma di 
distribuzione di probabilità ([batch size, max 
output sentence length, vocabulary length])  
Il 
decoder
  prende in input la frase target 
traslata di 1 posizione.  
Ad ognuno dei 
 N
 livelli, l'output del 
 encoder  
è inviato in input al 
 encoder-decoder attention  
nel corrispondete livello del 
 decoder
 .EncoderDecoder"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#29,29,"Architettura Transformer e NLP: dettagli (2)
In produzione ancora una volta l'output del decoder (una nuova parola) verrà 
accodata all'input del decoder allo step successivo.
30 (4) https://arxiv.org/abs/1706.03762
Sia encoder sia decoder, oltre agli layer 
embedding, hanno 
 5
N skip connections
 , 
ognuna seguita da una layer di 
normalizzazione
 . 
Le 
positionwise feed-forward
  network sono 
reti MLP
  tradizionali con 2 Dense layer 
ciascuna, il primo layer con attivazione 
ReLU, il secondo senza attivazione. Il 
 layer 
di output
  è una layer denso con softmax.  
Tutti i layer sono 
 time-distributed
 , cosicché 
ogni parola è trattata indipendentemente 
dalle altre.
×
EncoderDecoder"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#3,3,"Introduzione
Nell'esempio sono evidenziate features ricavate dall'
 attention mechanism 
 che 
mettono in correlazione features anche molto distanti tra loro.
4
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#30,30,"Architettura Transformer e NLP: dettagli (3)
Ma se la generazione delle parole è indipendente una dall'altra, e non 
abbiamo RNN, come può funzionare?
31 (4) https://arxiv.org/abs/1706.03762
Il modulo 
 multi-head attention
  codi
 ﬁ
ca ogni 
relazione di una parola con tutte le altre nella 
stessa frase, in modo da evidenziale le 
relazioni più importanti (
 self-attention
 ). 
•
Es. In “They welcomed the Queen of the 
United Kingdom”, il termine queen sarà più 
legato cone 
 united
  e 
kingdom
  rispetto a 
 they 
e 
welcomed
 . 
Il modulo 
 masked multi-head attention
  si 
comporta in modo simile, ma si limita a 
considerare la parola precedente.  
Il 
multi-head attention
  del decoder analizza le 
parole nella frase in input e si focalizza sui 
termini più importanti per la traduzione (es. 
""Queen"")."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#31,31,"Architettura Transformer e NLP: dettagli (5)
Ma se la generazione delle parole è indipendente una dall'altra, come può 
funzionare?
32 (4) https://arxiv.org/abs/1706.03762
I 
positional embeddings
 , che sono dati in 
input al 
 encoder
  e 
decoder
  insieme agli 
embedding tradizionali, 
 rappresentano la 
posizione di un termine rispetto agli altri in 
una certa frase
 .  
Sono aggiunti ai 
 word embedding
  poiché il 
multi-head attention laye
 r ignora posizione 
e ordine delle parole nella frase, come pure 
gli altri layer  essendo tutti 
 layer time-
distributed
 . 
 "
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#32,32,"Keras: Transformer
In Keras una versione di Attention basata su 
 scaled dot-product
  è 
implementata in keras.layers.Attention.  
encoder_outputs = Z
Z = decoder_in
for
 N 
in 
range
(
6
):
    Z = keras.layers.Attention(use_scale=
 True
, causal=
 True
)([Z, Z])
    Z = keras.layers.Attention(use_scale=
 True
)([Z, encoder_outputs])
outputs = keras.layers.TimeDistributed(
    keras.layers.Dense(vocab_size, activation=
 ""softmax""
 ))(Z)
33 ..."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#33,33,"Demo Transformers e NLP
https://transformer.huggingface.co/  
34 ..."
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#4,4,"Richiamo: Architetture encoder-decoder
Si può combinare una rete 
 sequence-to-vector
  (
encoder
 ) con una 
 vector-to-
sequence
  (
decoder
 ) ottenendo una rete 
 encoder-decoder
 . 
•
Un 
encoder
  può rappresentare una frase in un linguaggio in un singolo 
vettore che viene impiegato poi dal 
 decoder
  per generare la frase in diverso 
linguaggio. 
5
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#5,5,"Encoder/Decoder in Keras (1)
L'interfaccia 
 encoder
  può prendere in input una sequenza di lunghezza 
variabile X.  
class 
Encoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
call
(
self
, 
X
, *
args
):
        
 raise
 NotImplementedErro
 r
Il 
decoder
  prende l'output dei decoder per tramutarlo nello stato.  
class 
Decoder
(
tf
.
keras
.
layers
.
Layer
):
   
def 
__init__
 (
self
):
        super().
 __init__
 ()
    
# Later there can be additional arguments (e.g., length excluding padding)
    
def 
init_state
 (
self
, 
enc_outputs
 , *
args
):
        
 raise
 NotImplementedError
    
def 
call
(
self
, 
X
, 
state
):
        
 raise
 NotImplementedError
6"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#6,6,"Encoder/Decoder in Keras (2)
L'architettura completa:  
class 
EncoderDecoder
 (
d2l
.
Classifier
 ):
   
def 
__init__
 (
self
, 
encoder
, 
decoder
):
        super().
 __init__
 ()
        
 self
.encoder = encoder
        
 self
.decoder = decoder
    
def 
call
(
self
, 
enc_X
, 
dec_X
, *
args
):
        enc_outputs = 
 self
.encoder(enc_X, *args, training=
 True
)
        dec_state = 
 self
.decoder.init_state(enc_outputs, *args
 )
        
 # Return decoder output only
        
 return 
self
.decoder(dec_X, dec_state, training=
 True
)[
0
]
7"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#7,7,"Esempio: Machine Translation (1)
In questo caso input e output sono sequenze di lunghezza variabile. La 
sequenza in input è tradotta in una rappresentazione nascosta/latente 
 ﬁ
xed-
shape.  
La sequenza in output è generata 
 token-by-token
 : data l'attuale sequenza in 
input, e i token precedenti generati in output. Durante l'addestramento il 
token da generare sarà estratto dai dati ground-truth. L'
 hidden state 
dell'
encoder
  viene dato in input ad ogni step di decoding. L'output generato 
sarà il nuovo input del decoder nello step successivo.  
Nota: se ignoriamo 
 l'encoder
 , il 
decoder
  corrisponde ad un 
 language model
 . 
Nell'esempio abbiamo frasi tokenizzate, dove <eos> corrisponde a end-of-
sequence. Ad ogni istanze iniziale, si impiega un tag <bos> per indicare 
l'inizio della sequenza
8
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#8,8,"Esempio: Machine Translation (2)
L'encoder
  può essere implementato con una RNN (es. GRU) uni o bi-
direzionale.  
L'output layer del 
 decoder
  sarà una FC che genera la distribuzione di 
probabilità sui token in output.  
La 
loss
 sarà una basata sulla 
 cross-entropy
 . 
Usualmente si usano sequenze di padding per frasi di lunghezza variabile, in 
input e output. Tali padding non intervengono nel calcolo della loss.
9
"
data_test\rootfolder\università\DeepLearning\14-Attention e Autoencoders 1-sbloccato.pdf#9,9,"Beam search (1)
Nell'architettura precedente il token generato è quello con più alta 
probabilità, 
 ﬁ
no a quando non è generato il token <eos>. Seguiamo una 
strategia 
 greedy
 , 
basata sui passati token generati e la variabile di contesto 
 c
, 
che rappresenta la frase in input:  
Nella 
 beam search
  scegliamo i 
 k
 token candidati più probabili. 
Successivamente teniamo in considerazioni i 
 k
 token per la generazione del 
nuovo token, e così via.
10
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Autoencoders
1"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#1,1,"Sommario
Language models: recenti sviluppi  
Autoencoders  
Stacked Autoencoders  
Fashion MNIST dataset  
Visualizzazione con t-SNE  
Unsupervised training con Stacked autoencoders  
Convolutional Autoencoders  
Recurrent Autoencoders  
Denoising Autoencoders  
Sparse Autoencoders  
Variational Autoencoders  
Semantic interpolation"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#10,10,"Rappresentazioni latenti
Latent representation learning
  (LRL), o 
 Latent variable modeling 
 (LVM), è una 
tecnica di apprendimento automatico che tenta di inferire le variabili latenti 
da misurazioni empiriche da variabili osservabili. Tali variabili latenti non 
possono essere misurate direttamente e quindi devono essere dedotte.  
Una o più variabili latenti costituiscono congiuntamente uno 
 spazio latente
  o 
una
 rappresentazione latente
 . Questa rappresentazione è solitamente una 
forma 
 compatta
  dello spazio impiegato per rappresentare le misurazioni 
empiriche, cioè consiste in un numero di variabili latenti inferiore alla 
dimensionalità delle misurazioni.
11 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#11,11,"Autoencoders
Gli 
autoencoders
  apprendono 
 rappresentazioni latenti
  dei dati senza 
l'impiego di approcci supervisionati.  
Inoltre possono essere impiegati per il 
 unsupervised pretraining
 , e per 
generare casualmente nuovi dati 
 che risultano simili a dati già visti in 
precedenza (es. visi di persone), sebbene non sempre realistici.  
•
Con le più recenti 
 Generative adversarial networks
  (
GANs
 ), che spesso 
includono anche moduli di autoencoders, suddividono il processo in 2 parti: 
generazione e discrimazione. In questi casi il realismo è maggiore.  
•
https://thispersondoesnotexist.com/  
https://thisrentaldoesnotexist.com/  
https://github.com/jantic/DeOldify    
Inoltre le GAN possono incrementare la risoluzione delle immagini, 
aggiungere colore alle immagini b/w, photo editing come rimpiazzare oggetti, 
convertire un disegno in una foto realistica, predire il successo frame in un 
video, creare/incrementare dataset per l'addestramento, etc.
12 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#12,12,"Rappresentazione dei dati ef
 ﬁ
ciente
Un 
autoencoder
  può avere una architettura piuttosto comune, es. MLP, dove 
input e output hanno hanno medesima dimensione.  
•
Nel seguente esempio l'
 hidden layer
  consiste in 2 soli nodi, mentre l'
 output 
e
 l'input layer 
 di 3 nodi. Lo scopo del 
 decoder
  (
output layer
 ) è ricostruire 
l'input a partire dalla rappresentazione creata dall'
 encoder
 .  
•
Se la rappresentazione dell'encoder ha meno dimensioni rispetto all'input, 
l'
autoencoder
  si chiama 
 undercomplete
 . 
•
La
 loss di ricostruzione
  valuta la differenza dell'output generato rispetto 
all'input.
13 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#13,13,"Autoencoders
Se l'
autoencoder 
 usa 
attivazioni lineari
  e la 
 MSE
 come funzione di costo, 
allora otteniamo un modello simile alla 
 Principal Component Analysis 
 (
PCA
). 
Nel seguente esempio proiettiamo istanze da un dataset 3d in 2d.  
from
 tensorflow 
 import
 keras
encoder = keras.models.Sequential([keras.layers.Dense(
 2
, input_shape=[
 3
])])
decoder = keras.models.Sequential([keras.layers.Dense(
 3
, input_shape=[
 2
])])
autoencoder = keras.models.Sequential([encoder, decoder])
autoencoder.
 compile
(loss=
""mse""
, optimizer=keras.optimizers.SGD(lr=
 0.1
))
Possiamo addestrarlo e impiegarlo per ottenere le rappresentazioni latenti:  
history = autoencoder.fit(X_train, X_train, epochs=
 20
)
codings = encoder.predict(X_train)
14 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#14,14,"Stacked Autoencoders
Gli 
stacked autoencoders
  (o 
deep autoencoders
 ) sono autoencoders 
organizzati su più layer, spesso in modo speculare.  
•
Non è mai consigliato creare autoencoders troppo complessi per non 
penalizzare il grado di generalizzazione su istanze in input non presenti nel 
dataset di training, su cui il modello non è capace di determinare attivazioni 
signi
ﬁ
cative.  
Nel caso 
 MNIST
  possiamo creare una architettura con 784 inputs, 100 nodi 
nel primo hidden layer, 30 nodi in quello centrale, un altro da 100 e l'output 
layer.
15 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#15,15,"Scaled Exponential Linear Units
La funzione di attivazione 
 Scaled Exponential Linear Units
  (
SELU
 ) 
è simile alla 
ELU ed è de
 ﬁ
nita nel seguente modo:  
 
 
La SELU non si annulla per valore < 0, a differenza della ReLU.  
Si può ipotizzare che la SELU implementi un ulteriore tipo di normalizzazione 
""interna"" che supporti l'invarianza tra media e varianza tra i layer, oltre alle 
due normalizzazioni già note:  
•
Input normalization (
 es. quando scaliamo i dati in ingresso)  
•
Batch normalization
f
(
x
)
=
λ
x
,
if 
x
>
0
f
(
x
)
=
λ
α
(
e
x
−
1
)
 altrimenti
16
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#16,16,"Keras: Stacked Autoencoders
L'implementazione è simile a una MLP. Nell'esempio usiamo una funzione di 
attivazione SELU, e invece delle MSE impieghiamo la 
 binary cross-entropy
  loss  
per accelerare la convergenza.  
stacked_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
),
])
stacked_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])
stacked_ae.
 compile
(loss=
""binary_crossentropy""
 ,
                   optimizer=keras.optimizers.SGD(lr=
 1.5
))
history = stacked_ae.fit(X_train, X_train, epochs=
 10
,
                         validation_data=[X_valid, X_valid])
17 (13) https://arxiv.org/pdf/1706.02515.pdf"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#17,17,"`
Per comprendere se l'output è corretto è utile visualizzarlo. Nel caso del 
dataset Fashion MNIST si ha:  
def 
plot_image
 (
image
):
    plt.imshow(image, cmap=
 ""binary""
 )
    plt.axis(
 ""off""
)
def 
show_reconstructions
 (
model
, 
n_images
 =
5
):
    reconstructions = model.predict(X_valid[:n_images])
    fig = plt.figure(figsize=(n_images * 
 1.5
, 
3
))
    
for
 image_index 
 in 
range
(n_images):
        plt.subplot(
 2
, n_images, 
 1
 + image_index)
        plot_image(X_valid[image_index])
        plt.subplot(
 2
, n_images, 
 1
 + n_images + image_index)
        plot_image(reconstructions[image_index])
show_reconstructions(stacked_ae)
18 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#18,18,"t-Distributed Stochastic Neighbourh 
t-Distributed Stochastic Neighbourh Embedding (t-SNE)
  è un algoritmo non 
supervisionato usato per la visualizzazione dei dati.  
Basato su una tecnica di riduzione della dimensionalità non lineare che punta 
a raggruppare punti simili tra loro in spazi con poche dimensioni preservando 
la struttura dei dati originali.  
Sfrutta la distribuzione t-Student per il calcolo della similarità tra 2 punti nello 
spazio ridotto e sulla Kullback–Leibler divergence.  
È poco affetto dagli outliers.
19 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#19,19,"Visualizzare un dataset con Autoencoders
Sebbene esistano tecniche avanzate di riduzione della dimensionalità e la 
visualizzazione dei dati, gli 
 autoencoders
  sono capaci di ridurre notevolmente 
le dimensioni di un dataset con molti istanze e molte features. Perciò 
possiamo sfruttarlo per generare input verso approcci più tradizionali, anche 
di visualizzazione.  
Sfruttiamo 
 t-distributed stochastic neighbor embedding
  (
t
-
SNE
) implementato 
in Scikit-Learn per la visualizzazione 2d.  
from
 sklearn.manifold 
 import
 TSNE
X_valid_compressed = stacked_encoder.predict(X_valid)
tsne = TSNE()
X_valid_2D = tsne.fit_transform(X_valid_compressed)
plt.scatter(X_valid_2D[:, 
 0
], X_valid_2D[:, 
 1
], c=y_valid, s=
 10
, cmap=
""tab10""
)
20 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#2,2,"Language Models: recenti sviluppi (1)
ELMo
(6)
 Embeddings from Language Models: rappresentazioni contestuali 
ottenute da un approccio 
 Deep bidirectional language model (biLM) 
addestrato su larghi dataset testuali. Gli stati generati dalla rete sono associati 
ai testi in modo da creare rappresentazioni latenti.   
ULMFiT
(7)
 Universal Language Model Fine-tuning: basato su 
 self-supervised 
learning
  con una architettura 
 LSTM
  a 3 layer dove sono richiesti meno dati (es. 
100 istanze) per l'addestramento sfruttando il transfer learning. State-of-the-art 
per la classi
 ﬁ
cazione NLP.
3(6) https://arxiv.org/abs/1802.05365  
(7) https://arxiv.org/abs/1801.06146  
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#20,20,"Fashion MNIST: Autoencoders e t-SNE
Fashion MNIST sottoposto a 
 autoencoders
  e 
t-SNE
 :
21 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#21,21,"Unsupervised training con Stacked autoencoders
Seguendo la 
 ﬁ
loso
ﬁ
a del 
 transfer learning
 , possiamo addestrare un 
autoencoder
  su un grande dataset di dati 
 unlabeled
 , e 
riutilizzare i parametri 
ottenuti nei primi layer 
 con un dataset più limitato di dati 
 labeled
  nel task 
principale di interesse.  
•
Dati 
 unlabeled
  si trovano facilmente sul web, es. immagini, testi, mentre i 
dati labeled sono molto preziosi poiché richiedono molte ore-uomo per 
creare valori target.
22 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#22,22,"Autoencoders: Tying weights (1)
Per 
autoencoders
  simmetrici è possibile creare 
 vincoli
  tra i valori dei parametri 
nei layer speculari (
 tying weights
 ) in modo da dimezzare i parametri da 
stimare durante l'apprendimento.  
In Keras costruiamo un Dense layer per impiegare i pesi di un layer 
precedente; attenzione: occorre trasporli prima di impiegarli nella decodi
 ﬁ
ca. 
class 
DenseTranspose
 (
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
dense
, 
activation
 =
None
, **
kwargs
):
        
 self
.dense = dense
        
 self
.activation = keras.activations.get(activation)
        super().
 __init__
 (**kwargs
 )
    
def 
build
(
self
, 
batch_input_shape
 ):
        
 self
.biases = 
 self
.add_weight(name=
 ""bias""
, initializer=
 ""zeros""
,
                                      shape=[
 self
.dense.input_shape[
 -1
]])
        super().build(batch_input_shape
 )
    
def 
call
(
self
, 
inputs
):
        z = tf.matmul(inputs, 
 self
.dense.weights[
 0
], 
transpose_b
 =
True
)
        
 return 
self
.activation(z + 
 self
.biases)
23 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#23,23,"Autoencoders: Tying weights (2)
La costruzione della rete impiega i nuovi layer per legarli con i precedenti:  
dense_1 = keras.layers.Dense(
 100
, activation=
 ""selu""
)
dense_2 = keras.layers.Dense(
 30
, activation=
 ""selu""
)
tied_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    dense_1,
    dense_2
])
tied_decoder = keras.models.Sequential([
    DenseTranspose(dense_2, activation=
 ""selu""
),
    DenseTranspose(dense_1, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])
24 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#24,24,"Greedy layerwise training
Invece di addestrare tutti i layer contemporaneamente possiamo farlo uno step 
alla volta, aggiungendo un layer dopo aver addestrato il precedente (
 greedy 
layerwise training
 ). 
Dopo il primo step codi
 ﬁ
co tutto il dataset per mezzo del primo autoencoder 
(
phase 1
 ). Uso il nuovo dataset per addestrare un secondo autoencoder (
 phase 
2
). In
ﬁ
ne metto tutti i layer insieme (
 phase 3
 ) 
•
Tale tecnica è attualmente poco popolare a causa di tecniche più recenti.
25 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#25,25,"Convolutional Autoencoders
Le architetture di 
 autoencoders
  viste non sono adatte per le immagini, cioè 
input con grandi dimensionalità.  
Le 
convolutional autoencoders
  impieghiamo dei 
 layer convoluzionali 
 per 
ridurre la dimensionalità
  incrementando la profondità del modello durante la 
codi
ﬁ
ca. 
Il 
decoder
  deve fare l'inverso: ridurre la profondità ed aumentare la risoluzione 
(
upsampling
 ). Si impiegano 
 transpose convolutional layers
  che operano in 
modo inverso alle convolution layer tradizionali.  
Ecco un esempio per Fashion MNIST:  
conv_encoder = keras.models.Sequential([
    keras.layers.Reshape([
 28
, 
28
, 
1
], input_shape=[
 28
, 
28
]),
    keras.layers.Conv2D(
 16
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 32
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
),
    keras.layers.Conv2D(
 64
, kernel_size=
 3
, padding=
 ""same""
, activation=
 ""selu""
),
    keras.layers.MaxPool2D(pool_size=
 2
)
]
)
...
26 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#26,26,"Convolutional Autoencoders
conv_decoder = keras.models.Sequential([
    keras.layers.Conv2DTranspose(
 32
, kernel_size=
 3
, strides=
 2
, padding=
 ""valid""
,
                                 activation=
 ""selu""
,
                                 input_shape=[
 3
, 
3
, 
64
]),
    keras.layers.Conv2DTranspose(
 16
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""selu""
),
    keras.layers.Conv2DTranspose(
 1
, kernel_size=
 3
, strides=
 2
, padding=
 ""same""
,
                                 activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])
27 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#27,27,"Recurrent Autoencoders
Per dati 
 time series
  abbiamo visto come le RNN sono una valida alternativa alle 
FC. 
I 
recurrent autoencoder 
 hanno un 
 encoder
  tipicamente 
 sequence-to-vector 
 che 
""comprime"" l'input in una rappresentazione vettoriale, mentre il decoder è 
vector-to-sequence
 . 
Il seguente 
 autoencoder
  processa sequenze di qualsiasi lunghezza, con 28 
dimensioni considerate per singolo step. L'input possono essere immagini 
Fashion MNIST che saranno processate una riga di pixel alla volta.  
•
Il
 RepeatVector layer 
 del decoder garantisce che l'input vector al decoder sarà 
inviato per intero ad ogni step.  
recurrent_encoder = keras.models.Sequential([
    keras.layers.LSTM(
 100
, return_sequences=
 True
, input_shape=[
 None
, 
28
]),
    keras.layers.LSTM(
 30
)
])
recurrent_decoder = keras.models.Sequential([
    keras.layers.RepeatVector(
 28
, input_shape=[
 30
]),
    keras.layers.LSTM(
 100
, return_sequences=
 True
),
    keras.layers.TimeDistributed(keras.layers.Dense(
 28
, activation=
 ""sigmoid""
 ))
])
recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])
28 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#28,28,"Denoising Autoencoders (1)
Nelle 
 denoising autoencoders
(14)
 in input abbiamo immagini a cui 
aggiungiamo del rumore, e in output ci sono le versioni originali: stiamo 
addestrando la rete a 
 rimuovere il rumore
 .  
•
Il rumore può essere gaussiano, oppure con un random switch-off degli input 
(es. tramite tecniche simili al Dropout).
29 (14) https://jmlr.csail.mit.edu/papers/v11/vincent10a
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#29,29,"Denoising Autoencoders (2)
Codi
ﬁ
ca e output con Fashion MNIST  
dropout_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    
keras.layers.Dropout(
 0.5
),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activ
                       “    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 30
, activation=
 ""selu""
)
])
dropout_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 30
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])
30 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#3,3,"Self-supervised learning
Con 
self-supervised learning  
si intende l'addestramento di una modello in assenza di 
un dataset suf
 ﬁ
cientemente grande in termini di valori target riguardo il task di 
interesse principale.  
In tali casi si sfruttano le stessi istanze presentate in input per creare dei nuovi target 
secondari, distinti da quello iniziale, ma comunque af
 ﬁ
ni. In tal modo la rete può 
identi
 ﬁ
care alcune features salienti impiegabili nel task principale (
 knowledge transfer 
process
 ).  
•
Esempi di task secondari sono
 : identi
 ﬁ
care relazioni sostantivo-verbo o frase-
aggettivo (dominio NLP); due immagini, una ruotata, ed aspettarsi l'angolo di 
rotazione in output alla rete (dominio immagini).  
Sebbene i dataset secondari siano più facili da costruire, non sono suf
 ﬁ
cienti per 
risolvere il problema principale. ma riducono il tempo totale necessario per la fase di 
training del task principale. Una ulteriore fase di addestramento su un dataset ridotto 
(es. quello disponibile inizialmente) rendono la rete ef
 ﬁ
cace anche sul task di interesse 
primario.  
È fondamentale scegliere un task secondario che, durante l'addestramento, generi un 
sottoinsieme di features utili anche per il task principale.  
Attenzione: è un approccio distinto dal 
 unsupervised pretraining
 .
4"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#30,30,"Sparse Autoencoders (1)
Negli 
 sparse autoencoders 
 introduciamo un termine nella funzione di costo che 
favorisce un numero limitato di nodi ""attivi"" nel layer di coding
 , cioè quello che 
è associato allo spazio che stiamo costruendo.  
•
In altre parole, forziamo la rete a rappresentare ogni input con poche attivazioni, 
e perciò 
 ogni nodo attivo rappresenterà un numero limitato di feature molto 
signi
ﬁ
cative
 . 
Con la funzione di attivazione 
 sigmoid
 , che pone una sorta di vincolo sulle 
codi
ﬁ
che in [0,1], e con la 
 ℓ
1
 regularization
  al layer di coding, otteniamo il 
seguente codice Keras:  
sparse_l1_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ),
    
keras.layers.ActivityRegularization(l1=
 1e-3
)
  # vedi lucido seguente
])
sparse_l1_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])
31 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#31,31,"Sparse Autoencoders (2)
Il layer 
 ActivityRegularization
  restituisce gli stessi input, ma ha l'effetto 
collaterale di aggiungere una
  training loss che coincide con la somma dei valori 
assoluti dei suoi input
 . In questo modo forziamo la rete, sia a produrre 
codi
ﬁ
che vicine allo 0
 , sia a ricostruire l'output corretto; perciò avremo 
codi
ﬁ
che con pochi valori, ma molto signi
 ﬁ
cativi, diversi da 0.  
Un modo alternativo è 
 misurare una sorta di ""sparsity"" calcolata durante 
l'apprendimento
  e, se si discosta da un valore target, 
 penalizziamo la rete
 . La 
ricaviamo con l'
 attivazione media
  per ogni nodo nel coding layer nell'intero 
training batch, che avrà una dimensione suf
 ﬁ
ciente per stimare correttamente 
tali valori.  
Successivamente introduciamo la 
 sparsity loss
  che penalizza i nodi troppo 
attivi, o i nodi non suf
 ﬁ
cientemente attivi.  
•
Es. Se l'average per un nodo è 0.3, e la target sparsity è 0.1, penalizziamo in 
modo da ridurre l'attivazione aggiungendo ad esempio l'
 errore quadratico  
(0.3-0.1)2  alla funzione di cost.  
•
Una alternativa migliore è usare 
 Kullback–Leibler (KL)
 , che deriva dei gradienti 
più signi
 ﬁ
cativi interpretando le 2 attivazioni come distribuzioni di probabilità.
32 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#32,32,"Sparsity loss
Sparsity loss
  ricavata con diverse metriche:
33 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#33,33,"Keras: Sparse Autoencoders
Sparse autoencoders con la KL-divergence:  
K = keras.backend
kl_divergence = keras.losses.kullback_leibler_divergence
class 
KLDivergenceRegularizer
 (
keras
.
regularizers
 .
Regularizer
 ):
    
def 
__init__
 (
self
, 
weight
, 
target
=
0.1
):
        
 self
.weight = weight
        
 self
.target = target
    
def 
__call__
 (
self
, 
inputs
):
        mean_activities = K.mean(inputs, axis=
 0
)
        
 return 
self
.weight * (
            kl_divergence(
 self
.target, mean_activities) +
            kl_divergence(
 1
. - 
self
.target, 
 1
. - mean_activities))
        
..
.
kld_reg = KLDivergenceRegularizer(weight=
 0.05
, target=
 0.1
)
sparse_kl_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[
 28
, 
28
]),
    keras.layers.Dense(
 100
, activation=
 ""selu""
),
    keras.layers.Dense(
 300
, activation=
 ""sigmoid""
 ,”
                       activity_regularizer=kld_reg)
])
sparse_kl_decoder = keras.models.Sequential([
    keras.layers.Dense(
 100
, activation=
 ""selu""
, input_shape=[
 300
]),
    keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 ),
    keras.layers.Reshape([
 28
, 
28
])
])
sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])
34 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#34,34,"Sparse Autoencoders e attivazioni
Dopo la fase di training su Fashion MNIST notiamo come circa il 70% delle 
attivazioni è prossima a 0, e che gran parte dei neuroni (90%) ha attivazione 
media tra 0.1 e 0.2.
35 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#35,35,"Variational Autoencoders (1)
I 
variational autoencoders 
 sono molto diffusi. Sono distinti dai precedenti 
poiché sono in parte 
 probabilistici
 , cioè una parte dell'output è generato in 
modo random, e 
 generativi
 , cioè possono generare nuove istanze che 
sembrano campionate dal training set. 
36 (15) https://arxiv.org/abs/1312.6114
Hanno una architettura simile agli altri 
autoencoders, ma all'interno 
l'encoder produce un vettore 
 codi
ﬁ
ca 
media  
 e un vettore 
 deviazione 
standard  
.  
L'
effettiva codi
 ﬁ
ca
 della istanza in 
input sarà generata per mezzo di una 
distribuzione gaussiana con tali 
parametri.  
Durante il training la loss tende a 
raggruppare le codi
 ﬁ
che in modo da 
generare una ""nuvola gaussiana"" di 
punti.
μ
σ"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#36,36,"Variational Autoencoders (2)
La 
funzione di costo
  consiste in due loss: la 
 reconstruction loss 
 che impone 
che l'output sia fedele all'input, e una 
 latent loss 
 che spinge ad avere 
codi
ﬁ
che come se fossero campionate da una distribuzione gaussiana, de
 ﬁ
nita 
per mezzo della KL-divergence.  
37 (15) https://arxiv.org/abs/1312.6114
La forma analitica contiene dettagli 
per limitare l'informazione trasmessa 
al coding layer, ma sempli
 ﬁ
cando si 
ottiene la seguente 
 latent loss
 : 
K 
è la dimensione delle codi
 ﬁ
che e 
 i 
indica l'i-esima componente della 
codi
ﬁ
ca.  
•
Impiegando la log(
 ) invece di 
  si 
ottiene 
 più stabilità
 .
σ
 σ
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#37,37,"Keras: Variational Autoencoders (1)
In Keras creiamo un 
 Sampling
  layer che campiona una istanza dalla distribuzione 
gaussiana  
class 
Sampling
 (
keras
.
layers
.
Layer
):
    
def 
call
(
self
, 
inputs
):
        mean, log_var = inputs
        
 return
 K.random_normal(tf.shape(log_var)) * K.exp(log_var / 
 2
) + mean
Non avendo un modello strettamente sequenziale usiamo le 
 Functional API
  di Keras, 
adatte per architetture particolari, ad esempio con topologie non lineari, pesi condivisi 
tra layer, o input e output multipli.  
Nel codice del 
 encoder
  con Functional API notiamo la rappresentazione esplicita dei 
dati ricavati dalla rete (es. 
 z, codings_mean, codings_log_var
  etc):  
codings_size = 1
 0
inputs = keras.layers.Input(shape=[
 28
, 
28
])
z = keras.layers.Flatten()(inputs)
z = keras.layers.Dense(
 150
, activation=
 ""selu""
)(z)
z = keras.layers.Dense(
 100
, activation=
 ""selu""
)(z)
codings_mean = keras.layers.Dense(codings_size)(z)  
 # 
μ
codings_log_var = keras.layers.Dense(codings_size)(z)  
 # 
γ
codings = Sampling()([codings_mean, codings_log_var])
variational_encoder = keras.Model(
    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])
38 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#38,38,"Keras: Variational Autoencoders (2)
Creiamo il 
 decoder
 , in questo caso potevamo usare anche l'approccio Keras 
Sequential.  
decoder_inputs = keras.layers.Input(shape=[codings_size])
x = keras.layers.Dense(
 100
, activation=
 ""selu""
)(decoder_inputs)
x = keras.layers.Dense(
 150
, activation=
 ""selu""
)(x)
x = keras.layers.Dense(
 28
 * 
28
, activation=
 ""sigmoid""
 )(x)
outputs = keras.layers.Reshape([
 28
, 
28
])(x)
variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])
Creiamo il modello e de
 ﬁ
niamo la 
 latent_loss
  e 
reconstruction_loss
 , e 
addestriamo con 
 RMSprop
  optimizer, adatto in questa con
 ﬁ
gurazione:  
_, _, codings = variational_encoder(inputs)
reconstructions = variational_decoder(codings)
variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])
latent_loss = 
 -0.5
 * K.
sum
(
    
1
 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),
    axis=
 -1
)
variational_ae.add_loss(K.mean(latent_loss) / 
 784
.)
variational_ae.
 compile
(loss=
""binary_crossentropy""
 , optimizer=
 ""rmsprop""
 )
history = variational_ae.fit(X_train, X_train, epochs=
 50
, batch_size=
 128
,
                             validation_data=[X_valid, X_valid])
39 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#39,39,"Generare immagini stile Fashion MNIST
Generiamo nuove istanze campionando in modo causale dalla distribuzione 
gaussiana:  
codings = tf.random.normal(shape=[
 12
, codings_size])
images = variational_decoder(codings).numpy(
 )
Le istanze in output, un po' fuzzy, sono abbastanza verosimili:
40 ...
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#4,4,"Self-supervised learning - esempio
Nel dominio delle immagini possiamo considerare come task secondari quelli 
il cui obiettivo è ricostruire una immagine manipolata, es. distorta, ruotata.  
Nel task 
 patches
 , estraiamo più segmenti dall'immagine e cerchiamo di 
determinare la relazione tra essi (es. posizione relativa tra 2 segmenti).  
•
Es
. prendiamo una patch 
 X
 a caso dall'immagine, ed otteniamo le 8 patches 
che la circondano 
 Y
i
. Usiamo coppie di patches (
 X,Y
i
) come input per 
determinare la posizione della patch 
 Y
i
. Oppure diamo in input tutte le 9 
patches in ordine random e chiediamo alla rete di ""risolvere il puzzle"".
5
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#40,40,"Variational Autoencoders e semantic interpolation
Invece di interpolare due immagini nel ""dominio dei pixel"", possiamo 
interpolare nel dominio latente 
 costruito dall'
 autoencoder
 . 
•
Deriviamo la rappresentazione dal coding layer di due immagini in input, 
interpoliamole e decodi
 ﬁ
chiamole.  
codings_grid = tf.reshape(codings, [
 1
, 
3
, 
4
, codings_size])
larger_grid = tf.image.resize(codings_grid, size=[
 5
, 
7
])
interpolated_codings = tf.reshape(larger_grid, [
 -1
, codings_size])
images = variational_decoder(interpolated_codings).numpy()
41 ...
Le immagini nel box sono 
quelle originali, quelle 
senza sono l'interpolazione 
di quelle adiacenti."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#5,5,"Language Models: recenti sviluppi (2)
GPT
(8)
 sfrutta il 
 unsupervised pretraining
  con una  architettura 
 Transform
  con 
stack di 12 moduli, addestrata su un dataset esteso con tecniche 
 self-
supervised
 .  
•
Necessita di un 
 ﬁ
ne-tuned training per impiegarla su task speci
 ﬁ
ci (es. 
classi
 ﬁ
cazione, misura di similarità, question answering).  
•
GPT-2
(9)
 è una versione estesa con 1.5 miliardi di parametri, con modelli 
disponibili online.  
•
GPT-3
  è estesa a 175 miliardi di parametri. Le APIs sono disponibili ma 
l'accesso è previa veri
 ﬁ
ca.
6(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#6,6,"Language Models: recenti sviluppi (3)
GPT-2 output
7(8) https://bit.ly/38FfBQ7  
(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2
"
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#7,7,"Language Models: recenti sviluppi (4)
BERT
(10)
 Bidirectional Encoder Representations from Transformers: sviluppata 
da Google, simile alla GPT, impiega 
 self-supervised pretraining
  con approccio 
bidirezionale. È stata pre-addestrata su due task:  
•
Ogni parola in una frase ha il 15% di probabilità di essere 
 mascherata
 . Il 
compito della rete è di indovinarla.  
•
Date due frasi, predire se sono consecutive.  
Altri approcci recenti usano CNN con 
 masked 2d-conv
  per il task di 
trasformazione sequence-to-sequence
(11)
, o RNN dove ogni nodo risulta 
indipendente dall'altro, garantendo apprendimenti su sequenze molto più 
lunghe
(12)
.
8(10) https://arxiv.org/abs/1810.04805  
(11) https://arxiv.org/abs/1808.03867(12) https://arxiv.org/abs/1803.04831  "
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#8,8,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14
9 ..."
data_test\rootfolder\università\DeepLearning\15-Attention e Autoencoders 2-sbloccato.pdf#9,9,"Rappresentazione dei dati ef
 ﬁ
ciente
Riusciresti a memorizzare queste due sequenze?  
•
40, 27, 25, 36, 81, 57, 10, 73, 19, 68  
•
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14  
Se riconosci il pattern ""tutti i numeri pari dal 50 al 14"" ti sarà più facile 
ricordare la seconda.
10 ..."
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Generative Adversarial Networks
1"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#1,1,"Sommario
Apprendimento discriminativo e generativo  
Generatie adversarial networks (GANs)  
Deep Convolutional Generative Adversarial Networks"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#10,10,"GAN e Keras: Generatore e Discriminatore
   
for
 epoch 
in 
range
(num_epochs):
        timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
)  
# loss_D, loss_G, num_examples
        
 for
 (X,) 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(
                mean=
 0
, stddev=
 1
, shape=(batch_size, latent_dim))
            metric.add(update_D(X, Z, net_D, net_G, loss, optimizer_D),
                       update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
        
 # Visualizzazione dei dati generati
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, shape=(
 100
, latent_dim))
        fake_X = net_G(Z)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].scatter(data[:, 
 0
], data[:, 
 1
])
        animator.axes[
 1
].scatter(fake_X[:, 
 0
], fake_X[:, 
 1
])
        animator.axes[
 1
].legend([
 ""real""
, 
""generated""
 ])
        
 # Visualizzazione delle loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch + 
 1
, (loss_D, loss_G))
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec'
 )
11"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#11,11,"GAN e Keras: Generatore e Discriminatore
Speci
 ﬁ
chiamo gli iperparametri per fare 
 ﬁ
tting di una distribuzione gaussiana:  
lr_D, lr_G, latent_dim, num_epochs = 
 0.05
, 
0.005
, 
2
, 
20
train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G,
      latent_dim, data[:
 100
].numpy())
> 
loss_D 
0.693
, loss_G 
 0.693
, 
333.2
 examples/sec
12
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#12,12," Deep Convolutional Generative Adversarial 
Nelle GAN abbiamo visto come i campioni generati provengano perloppiù da 
distribuzioni uniformi o normali, che sono poi trasformati in istanze che 
corrispondono alle distribuzioni di un certo dataset di dati reali.  
Per generare campioni più complessi (es. immagini fotorealistiche) sono 
necessarie architetture più complesse come le 
 Deep Convolutional GANs 
(DCGAN)
 . 
13"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#13,13,"DCGAN - Keras (1)
Il dataset è la collezione di Pokemon sprites, ottenuto da pokemondb.  
import
 tensorflow 
 as
 tf
!
pip install d2l==
 1.0.0
a1.post0
from
 d2l 
import
 tensorflow 
 as
 d2
l
d2l.DATA_HUB[
 'pokemon'
 ] = (d2l.DATA_URL + 
 'pokemon.zip'
 ,
                           
 'c065c0e2593b8b161a2d7873e42418bf6a21106c'
 )
data_dir = d2l.download_extract(
 'pokemon'
 )
batch_size = 
 256
pokemon = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir, batch_size=batch_size, image_size=(
 64
, 
64
)
)
Ridimensiono ogni immagini in 64x64. I valori sono in [0,1], mentre il generatore usa la 
 tanh
 e 
genera campioni con pixel in [-1,1]. Normalizziamo i dati con media e deviazione standard pari 
a 0.5.  
def 
transform_func
 (
X
):
    X = X / 
 255
.
    X = (X - 
 0.5
) / (
0.5
)
    
return
 X
data_iter = pokemon.
 map
(
lambda
 x, y: (transform_func(x), y),
                        num_parallel_calls=tf.data.experimental.AUTOTUNE)
data_iter = data_iter.cache().shuffle(buffer_size=
 1000
).prefetch(
    buffer_size=tf.data.experimental.AUTOTUNE)
14"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#14,14,"DCGAN - Keras (2)
d2l.set_figsize(figsize=(
 4
, 
4
))
for
 X, y 
in
 data_iter.take(
 1
):
    imgs = X[:
 20
, :, :, :] / 
 2
 + 
0.5
    d2l.show_images(imgs, num_rows=
 4
, num_cols=
 5
)
Il generatore deve mappare una 
 noise variabile  
 e un vettore di dimensione 
 d
 ad una  
immagine 64x64.  
Usiamo la 
 Conv2DTranspose
  per incrementare  
la risoluzione in input, seguita da una 
 batch normalization  
e attivazione ReLU.  
class 
G_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
strides
=
2
, 
padding
=
""same""
,
                 **
 kwargs
):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d_trans = tf.keras.layers.Conv2DTranspose(
            out_channels, kernel_size, strides, padding, use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.ReLU()
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d_trans(X)))
z
∈
ℝ
d
15
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#15,15,"DCGAN - Keras (3)
Di default abbiamo
  kernel 4x4, stride 2x2 e same padding.  
Con un input 16x16, il generatore raddoppia larghezza e altezza dell'input.  
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))  
# creiamo un dato sintetico
g_blk = G_block(
 20
)
g_blk(x).shape
> TensorShape([2, 32, 32, 20]
 )
Se usiamo un kernel 4x4, stride 1x1 e zero padding, con un input 1x1, l'output avrà 
larghezza e altezza incrementati di 3.  
x = tf.zeros((2, 1, 1, 3)
 )
# padding=""valid"" corresponds to no padding
g_blk = G_block(
 20
, strides=
 1
, padding=
 ""valid""
)
g_blk(x).shape
> TensorShape([2, 4, 4, 20])
16
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#16,16,"DCGAN - Keras (4)
Il 
generatore
  consiste in 4 blocchi base che incrementano ampiezza e altezza 
da 1 a 32. Inizialmente mappa le variabili latenti in 64x8 canali, e poi 
dimezza i canali ogni volta. In
 ﬁ
ne, un
  transposed convolution layer 
 genera 
l'output raddoppiando la dimensione a 64x64 e riducendo i canali a 3 per 
rispettare l'output desiderato. La funzione di attivazione 
 tanh
 è usata per 
generare output in (-1,1).  
n_G = 
64
net_G = tf.keras.Sequential([
    
# Output: (4, 4, 64 * 8)
    G_block(out_channels=n_G*
 8
, strides=
 1
, padding=
 ""valid""
),
    G_block(out_channels=n_G*
 4
), 
# Output: (8, 8, 64 * 4)
    G_block(out_channels=n_G*
 2
), 
# Output: (16, 16, 64 * 2)
    G_block(out_channels=n_G), 
 # Output: (32, 32, 64)
    
# Output: (64, 64, 3)
    tf.keras.layers.Conv2DTranspose(
        
 3
, kernel_size=
 4
, strides=
 2
, padding=
 ""same""
, use_bias=
 False
,
        activation=
 ""tanh""
)
])
17"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#17,17,"Richiami: Leaky ReLU
La leaky ReLU è  utile per affrontare il dying ReLU.  
alphas = [
 0
, 
.2
, 
.4
, 
.6
, 
.8
, 
1
]
x = tf.
range
(
-2
, 
1
, 
0.1
)
Y = [tf.keras.layers.LeakyReLU(alpha)(x).numpy() 
 for
 alpha 
in
 alphas]
d2l.plot(x.numpy(), Y, 
 'x'
, 
'y'
, alphas)
18
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#18,18,"DCGAN - Keras (5)
Il blocco base del discriminatore è un convolution layer seguito da 
 batch 
normalization
  (tranne per l'input layer) e leaky ReLU activation. Gli 
iperparametri sono simili a quelli impiegati al blocco generatore.  
class 
D_block
(
tf
.
keras
.
layers
.
Layer
):
    
def 
__init__
 (
self
, 
out_channels
 , 
kernel_size
 =
4
, 
                 
 strides
=
2
, 
padding
=
""same""
, 
alpha=
0.2
, **kwargs):
        super().
 __init__
 (**kwargs)
        
 self
.conv2d = tf.keras.layers.Conv2D(out_channels, kernel_size,
                                             strides, padding,  
                                      use_bias=
 False
)
        
 self
.batch_norm = tf.keras.layers.BatchNormalization()
        
 self
.activation = tf.keras.layers.LeakyReLU(alpha)
    
def 
call
(
self
, 
X
):
        
 return 
self
.activation(
 self
.batch_norm(
 self
.conv2d(X))
 )
x = tf.zeros((
 2
, 
16
, 
16
, 
3
))
d_blk = D_block(
 20
)
d_blk(x).shape
> TensorShape([2, 8, 8, 20])
19"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#19,19,"DCGAN - Keras (6)
Per un input shape 16x16 e un kernel 4x4 e stride 2 e same padding:  
n_D = 
64
net_D = tf.keras.Sequential([
    D_block(n_D), 
 # Output: (32, 32, 64)
    D_block(out_channels=n_D*
 2
), 
# Output: (16, 16, 64 * 2)
    D_block(out_channels=n_D*
 4
), 
# Output: (8, 8, 64 * 4)
    D_block(out_channels=n_D*
 8
), 
# Outupt: (4, 4, 64 * 64)
    
# Output: (1, 1, 1)
    tf.keras.layers.Conv2D(
 1
, kernel_size=
 4
, use_bias=
 False
)
]
)
x = tf.zeros((
 1
, 
64
, 
64
, 
3
))
net_D(x).shape
> TensorShape([1, 1, 1, 1]) # Predizione: Singolo valore
20
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#2,2,"Apprendimento discriminativo e generativo
Finora abbiamo trattato il 
 discriminative learning
 , cioè un apprendimento 
capace di distinguere le differenti istanze, cioè le relative caratteristiche, e 
classi
 ﬁ
carle, o fare predizione. In molti task arriviamo a livelli di accuratezza 
comparabili a quelli umani.  
Ci sono altri casi in cui vogliamo analizzare grossi dataset senza labels per 
creare un modello che ne descrive le caratteristiche. Con tale modello 
possiamo creare esempi di dato 
 sintetici
  che assomigliano a quelli reali. Tale 
approccio si chiama 
 generative learning
 . 
•
Es. le reti ricorrenti sono un esempio di un modello discriminativo che può 
essere impiegato anche per generare nuove istanze.
3"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#20,20,"Richiami: Adam Optimization
Adam (Adaptive Moment Estimation)  
è una combinazione di Momentum 
optimization e RMSProp
 . 
 
 
 
 
 
dove 
 T
 indica l'iterazione corrente  
Rispetto al Momentum, nella prima espressione si introduce il decay dei gradienti 
con  
La 3
a
 e 4
a
 espressione sono utili per incrementare il valore di 
 m
 ed 
s
 all'inizio del 
training, essendo i valori iniziali pari a 0.
m
←
β
1
m
+
(
1
−
β
1
)
∇
Θ
J
(
Θ
)
s
←
β
2
s
+
(
1
−
β
2
)
∇
Θ
J
(
Θ
)
⊗
∇
Θ
J
(
Θ
)
m
←
m
1
−
β
T
1
s
←
s
1
−
β
T
2
Θ
←
Θ
−
η
⋅
m
⊘
s
+
ϵ
β
1
21Momentum :  
 
RMSProp :  
 
 
 
 
 
RMSProp : m←β⋅m+η∇ΘJ(Θ)
s←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)
Θ←Θ−η∇ΘJ(Θ)⊘s+ϵ"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#21,21,"DCGAN - Keras (7)
Rispetto alle GAN usiamo lo stesso 
 learning rate
  per il generatore e 
discriminatore essendo architetture simili. Portiamo 
  in Adam da 0.9 (spesso 
usato come default) a 0.5.  
Decrementiamo lo 
 smooth
  del momentum, la weighted moving average 
esponenziale dei passati gradienti, per tenere traccia più puntuale delle 
variazioni rapide dei gradienti a causa dell'instabilità creata dal discriminatore-
generatore.  
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr
, 
latent_dim
 ,
          
 device
=d2l.try_gpu()):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_hp = {
 ""lr""
: lr, 
""beta_1""
 : 
0.5
, 
""beta_2""
 : 
0.999
}
    optimizer_D = tf.keras.optimizers.Adam(**optimizer_hp)
    optimizer_G = tf.keras.optimizers.Adam(**optimizer_hp)
β
1
22"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#22,22,"DCGAN - Keras (8)
    animator = d2l.Animator(xlabel=
 'epoch'
, ylabel=
 'loss'
,
                          xlim=[
 1
, num_epochs], nrows=
 2
, figsize=(
 5
, 
5
),
                          legend=[
 'discriminator'
 , 
'generator'
 ]
)
    animator.fig.subplots_adjust(hspace=
 0.3
)
    
for
 epoch 
in 
range
(
1
, num_epochs + 
 1
):
 
       timer = d2l.Timer()
        metric = d2l.Accumulator(
 3
) 
# loss_D, loss_G, num_examples
        
 for
 X, _ 
in
 data_iter:
            batch_size = X.shape[
 0
]
            Z = tf.random.normal(mean=
 0
, stddev=
 1
,
                                 shape=(batch_size, 
 1
, 
1
, latent_dim))
            metric.add(d2l.update_D(X, Z, net_D, net_G, loss,  
                                                           optimizer_D),
                       d2l.update_G(Z, net_D, net_G, loss, optimizer_G),
                       batch_size)
23"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#23,23,"DCGAN - Keras (9)
        
 # Visualizziamo i dati generti
        Z = tf.random.normal(mean=
 0
, stddev=
 1
, 
                                        shape=(
 21
, 
1
, 
1
, latent_dim))
        
 # Normalizziamo i dati generati in (0,1)
        fake_x = net_G(Z) / 
 2
 + 
0.5
        imgs = tf.concat([tf.concat([fake_x[i*
 7
+j] 
for
 j 
in 
range
(
7
)],
                                    axis=
 1
)
                          
 for
 i 
in 
range
(
len
(fake_x) // 
 7
)], axis=
 0
)
        animator.axes[
 1
].cla()
        animator.axes[
 1
].imshow(imgs)
        
 # Visualizziamo le loss
        loss_D, loss_G = metric[
 0
] / metric[
 2
], metric[
 1
] / metric[
 2
]
        animator.add(epoch, (loss_D, loss_G)
 )
    
print
(
f
'loss_D 
 {loss_D
:.3f
}
, loss_G 
 {loss_G
:.3f
}
, '
          
 f
'
{metric[
 2
] / timer.stop()
 :.1f
}
 examples/sec on  
                                      
 {
str
(device._device_name)}
 '
)
24"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#24,24,"DCGAN - Keras (10)
latent_dim, lr, num_epochs = 
 100
, 
0.0005
, 
40
train(net_D, net_G, data_iter, num_epochs, lr, latent_dim)
> loss_D 0.217, loss_G 3.687, 2310.5 examples/sec on /GPU:
 0
25
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#3,3,"Generative adversarial networks
Nel 2014 sono state introdotte le 
 Generative adversarial networks (GAN)
 , un 
modello che sfrutta un approccio 
 discriminativo
  per generare modelli 
generativi:  
•
L'idea è che un modello generativo è buono se non riusciamo a distinguere i 
dati generati da quelli reali.  
Dal punto di vista statistico corrisponde ad un 
 2-sample test
 : misurare se due 
sequenze di istanze 
 X
= {
x
1
, ..., 
x
n
} e 
X'
= {
x'
1
, ..., 
x'
n
} sono ottenute dalla stessa 
distribuzione.  
Nelle GAN tale test è usato dal modello generativo per adattarsi a creare 
istanze sempre più simili ai casi reali.  
•
In pratica, cerchiamo di ""bidonare"" il classi
 ﬁ
catore reale/fake. 
4"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#4,4,"Generative adversarial networks (GANs)
L'architettura include un 
 generative network
 , nel nostro caso una deep 
network, che ha lo scopo di generare istanze simili a quelle reali (es. segnale 
di voce umana, immagini di visi). Il 
 discriminative network
  cerca di 
distinguere dati reali da quelli generate (o fake).  
Il 
discriminator
  è implementato come un classi
 ﬁ
catore binario che produce 
uno scalare per ogni input 
 x 
(es. una FC con 1 layer e funzione di attivazione 
sigmoid
  per convertire lo scalare in probabilità). Assumiamo che la label 
corrispondente sia 1 per una istanza da dati reali, 0 per una fake creata dal 
generatore.  
Il generatore mira a generare una immagine più  
vicina possibile alle immagini reali, e per ottenere  
dal discriminatore il relativo output corrispondente  
a ""il dato e' real"".
5
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#5,5,"Generative adversarial networks (GANs)
Il 
discriminatore
  mira a distinguere immagini generate da immagini reali minimizzando 
la 
cross-entropy loss:  
 
dove 
 D
(x) = 1/(1 + 
 e
-o
) è la probabilità ottenuta con la 
 sigmoid
  a partire dallo scalare 
 o.  
Collezionando in modo casuale 
  (es. con distribuzione normale), dove 
  riveste il 
compito di 
 variabile latente,
  il compito del 
 generatore
  è di bidonare il discriminatore per 
classi
 ﬁ
care 
 x'=G(z)
  come ""dato reale"", cioè vogliano D(G(z)) ≈ 1.  
In altre parole, dato un discriminatore D, aggiorniamo i parametri del generatore per 
massimizzare la 
 cross-entropy loss 
 quando y=0, cioè 
 dato fake
 : 
 
Se il generatore si comporta in modo ottimale, D(x') è circa 1, cosicché la loss è vicina 
allo 0, e perciò i gradienti sono assai ridotti per generare progressi per il discriminatore. 
Minimizzeremo perciò la seguente loss:  
 
che è il feed x'=G(z) nel discriminatore dando il label 1.  
min
 D
{
−
y
 log 
D
(
x
)
−
(
1
−
y
)
 log
(
1
−
D
(
x
)
)
}
z
∈
ℝ
D
z
max
 G
{
−
(
1
−
y
)
 log 
(
1
−
D
(
G
(
z
)
)
)
}
=
max
 G
{
−
 log 
(
1
−
D
(
G
(
z
)
)
)
}
min
 G
{
−
y
 log 
(
D
(
G
(
z
)
)
)
}
=
min
 G
{
−
 log 
(
D
(
G
(
z
)
)
)
}
6"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#6,6,"GAN e Keras (1)
Generiamo dati con un modello gaussiano:  
X = tf.random.normal((1000, 2), 0.0, 1
 )
A = tf.constant([[1, 2], [-0.1, 0.5]]
 )
b = tf.constant([1, 2], tf.float32
 )
data = tf.matmul(X, A) + 
 b
Otteniamo una gaussiana traslata in modo arbitrario con media 
 b
 e covarianza 
A
T
A
. 
d2l.set_figsize(
 )
d2l.plt.scatter(data[:100, 0].numpy(), data[:100, 1].numpy())
 ;
print(f'The covariance matrix is\n{tf.matmul(A, A, transpose_a=True)}'
 )
> The covariance matrix i
 s
> [[1.01 1.95
 ]
> [1.95 4.25]
 ]
batch_size = 
 8
data_iter = d2l.load_array((data,), batch_size)
7
"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#7,7,"GAN e Keras: Generatore e Discriminatore
Il generatore è un semplice layer lineare.  
net_G = tf.keras.layers.Dense(2
 )
Per il discriminatore usiamo una MLP a 3 layer:  
net_D = tf.keras.models.Sequential(
 [
    tf.keras.layers.Dense(5, activation=""tanh"", input_shape=(2,))
 ,
    tf.keras.layers.Dense(3, activation=""tanh"")
 ,
    tf.keras.layers.Dense(1
 )
]
)
De
ﬁ
niamo una funzione per aggiornare il 
 discriminatore
 : 
def 
update_D
 (
X
, 
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_D
 ):
    batch_size = X.shape[
 0
]
    ones = tf.ones((batch_size,)) 
 # Labels corrispondenti ai dati reali
    zeros = tf.zeros((batch_size,)) 
 # Labels corrispondenti ai dati fake
    
# Ignoriamo i gradienti per `net_G` all'interno di GradientTape
    fake_X = net_G(Z)
    
with
 tf.GradientTape() 
 as
 tape:
        real_Y = net_D(X)
        fake_Y = net_D(fake_X)
        loss_D = (loss(ones, tf.squeeze(real_Y)) + loss(
            zeros, tf.squeeze(fake_Y))) * batch_size / 
 2
    grads_D = tape.gradient(loss_D, net_D.trainable_variables)
    optimizer_D.apply_gradients(
 zip
(grads_D, net_D.trainable_variables))
    
return
 loss_D
8"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#8,8,"GAN e Keras: Generatore e Discriminatore
Il generatore sarà aggiornato in modo simile. Riutilizziamo la cross-entropy 
loss ma cambiamo la label dei dati fake da 0 a 1  
def 
update_G
 (
Z
, 
net_D
, 
net_G
, 
loss
, 
optimizer_G
 ):
    batch_size = Z.shape[
 0
]
    ones = tf.ones((batch_size,))
    
with
 tf.GradientTape() 
 as
 tape:
        fake_X = net_G(Z)
 
       fake_Y = net_D(fake_X)
       loss_G = loss(ones, tf.squeeze(fake_Y)) * batch_size
    grads_G = tape.gradient(loss_G, net_G.trainable_variables)
    optimizer_G.apply_gradients(
 zip
(grads_G, net_G.trainable_variables))
    
return
 loss_G
Sia il discriminatore sia il generatore operano una
  logistic regression binaria 
con cross-entropy loss. Usiamo 
 Adam
  per rendere smooth il processo di 
training. Ad ogni iterazione, prima aggiorniamo il discriminatore e poi il 
generatore. 
9"
data_test\rootfolder\università\DeepLearning\16-GAN-sbloccato.pdf#9,9,"GAN e Keras: Generatore e Discriminatore
def 
train
(
net_D
, 
net_G
, 
data_iter
 , 
num_epochs
 , 
lr_D
, 
lr_G
, 
latent_dim
 , 
data
):
    loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=
 True
, reduction=tf.keras.losses.Reduction.SUM)
    
for
 w 
in
 net_D.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    
for
 w 
in
 net_G.trainable_variables:
        w.assign(tf.random.normal(mean=
 0
, stddev=
 0.02
, shape=w.shape))
    optimizer_D = tf.keras.optimizers.Adam(learning_rate=lr_D)
    optimizer_G = tf.keras.optimizers.Adam(learning_rate=lr_G)
    animator = d2l.Animator(
        xlabel=
 ""epoch""
, ylabel=
 ""loss""
, xlim=[
 1
, num_epochs], nrows=
 2
,
        figsize=(
 5
, 
5
), legend=[
 ""discriminator""
 , 
""generator""
 ])
    animator.fig.subplots_adjust(hspace=
 0.3
)
   ...
10"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Recommender Systems
1"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#1,1,"Sommario
MovieLens dataset  
AutoRec  
Implicit feedback (richiami)ù  
Neural Collaborative Filtering (NCF)  
Caser e Sequence-aware Recsys  
Factorization Machines e Deep FM"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#10,10,"Neural Collaborative Filtering for Personalized Ranking
L'output del penultimo layer di entrambe le reti è concatenato è dato in input 
al NeuMF layer:
11
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#11,11,"Sequence-aware recommender systems
Spesso gli utenti operano una sequenza di azioni nei servizi online il cui 
ordine temporale può essere signi
 ﬁ
cativo nel processo di raccomandazione.  
Il modello 
 Caser 
 (Convolutional sequence embedding recommendation 
model) sfrutta le CNN, in particolare 
 horizontal
  e 
vertical
  convolutional 
networks, per identi
 ﬁ
care rispettivamente pattern sequenziali 
 union-level
  e 
point-level
  di tipo short-term.  
I pattern 
 point-level
  identi
 ﬁ
cano l'in
 ﬂ
uenza di un item all'interno di una 
sequenza verso un certo item target. L'union-level analizza l'in
 ﬂ
uenza di varie 
azioni fatte sul valore target (es. l'acquisto di latte e burro può implicare 
l'acquisto di farina).  
I bisogni di lungo termine sono rappresentati nei layer FC 
 ﬁ
nali.
12"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#12,12,"Sequence-aware recommender systems
Supponiamo che ogni utente u sia associato ad una sequenza di items 
. Se prendiamo i passati 
 L
 items, possiamo costruire una 
matrice che rappresenta le interazioni passati con tali items rispetto al time 
step 
t
. 
Dove 
  rappresenta sempre lo spazio di embedding e 
 q
i
 indica la 
 i
-
ma riga. 
  è usata per ottenere i bisogni transienti dell'utente 
 u
 per 
il time step 
 t
, ed è l'input per i successivi convolutional layers:  
•
L'horizontal layer ha 
 d 
ﬁ
ltri orizzontali 
 . 
•
Il vertical layer ha d' 
 ﬁ
ltri verticali  
Dopo una serie di operatori convoluzionali e di pooling otteniamo gli output 
 e 
 :
S
u
=
(
S
u
1
,
⋯
,
S
u
|
S
u
|
)
Q
∈
ℝ
n
×
k
E
(
u
,
t
)
∈
ℝ
L
×
k
F
j
∈
ℝ
h
×
k
,
i
≤
j
≤
d
,
h
=
{
1,
⋯
,
L
}
G
j
∈
ℝ
L
×
1
,
i
≤
j
≤
d
′ 
o
∈
ℝ
d
o
′ 
∈
ℝ
d
′ 
13
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#13,13,"Sequence-aware recommender systems
Gli output sono concatenati e dati in input ad una MLP per ricavarne 
rappresentazioni ad alto livello:  
L'output 
  indica i bisogni a breve termine dell'utente.  
I bisogni a lungo termine dell'utente sono ricavati:  
dove 
  è una ulteriore embedding matrix, e  
  è la 
 user 
embedding matrix
  per i bisogni a lungo termine. 
  e 
  sono la 
u
-ma riga e 
 i
-ma riga rispettivamente di 
 P
 e 
V
.
z
∈
ℝ
k
V
∈
ℝ
n
×
2
k
P
∈
ℝ
m
×
k
p
u
∈
ℝ
k
v
i
∈
ℝ
2
k
14
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#14,14,"Sequence-aware recommender systems
L'architettura generale di Caser è così rappresentata:
15
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#15,15,"Addestramento e architetture sequenziali
In modo simile all'addestramento RNN, in presenza di dati con timestamp che 
rappresentano azioni tra utenti e items (es. l'utente ha lasciato un rating su un 
ﬁ
lm), possiamo costruire un dataset di addestramento creando sequenze di 
dimensione prede
 ﬁ
nita, ad esempio:
16
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#16,16,"Factorization Machines
Le FM sono algoritmi supervisionati che possono essere impiegati in contesti 
di classi
 ﬁ
cazione, regressione e ranking. Si ispirano a modelli di regressione 
lineare, modelli di MF e Support vector machines con kernel polinomiali.  
Mostrano vantaggi in caso di dataset sparsi riducendo notevolmente il tempo 
di addestramento. Inoltre individuano più facilmente correlazioni signi
 ﬁ
cative 
tra i dati.  
Se indichiamo con 
  il vettore delle feature per una certa istanza, e con 
y la label numerica associata (es. 4.5 oppure click/no-click), formalizziamo il 
modello in questo modo:  
dove 
  è il bias globale, 
  sono i pesi per la i-ma variabile, 
 sono i feature embeddings, e 
 v
i
 è la i-ma riga di 
 V
, <v
 i
,v
j
> è il 
prodotto vettoriale tra i 2 vettori è modella l'interazione tra la 
 i
-ma e 
 j
-ma 
feature.
x
∈
ℝ
d
w
0
∈
ℝ
 w
∈
ℝ
d
V
∈
ℝ
d
×
k
17
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#17,17,"Factorization Machines
Nell'espressione precedente si può notare una prima componente che 
rappresenta il modello di regressione lineare, mentre il secondo estende un 
modello di MF:  
Se la feature 
 i
 rappresenta un item, e la feature 
 j
 un utente, il terzo termine è il 
prodotto scalare tra i due embedding, uno dell'utente ed uno dell'item. 
18
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#18,18,"Deep Factorization Machines
In alcuni scenari l'approccio lineare delle FM non è suf
 ﬁ
ciente per 
rappresentare correlazioni e patterns complessi. Ma è possibile integrare 
approcci ""deep"" nel FM per rappresentare interazioni tra features nei dati.  
Nel 
DeepFM
  la componente FM e deep sono combinate in modo 
 parallelo
 . La 
FM è simile all'architettura originale. La deep è implementata con una MLP. 
L'input/embeddings delle 2 componenti è il medesimo, l'output è 
 sommato  
per creare la predizione 
 ﬁ
nale.  
La DeepFM si ispira allearchitetture RecSys chiamate 
 wide & deep
 . In tali 
architetture la predizione combina due pipeline:  
•
la 
memorizzazione
  mira a rappresentare co-occorrenze frequenti tra items o 
features nei dati storici. Si implementa con un modello lineare (es. logistic 
regression)  
•
la 
generalizzazione
  punta a implementare la ""transitività"" delle correlazioni, 
cioè esplorare combinazioni signi
 ﬁ
cative tra features che non sono state mai 
incontrate nel passato. La pipeline è generalmente basata su una MLP.
19"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#19,19,"Deep Factorization Machines
Supponiamo che l'output della FM sia 
 . Indichiamo con 
  il vettore 
delle feature latenti del campo 
 i
-mo.  
L'input della componente deep è la concatenazione degli embeddings di tutti 
i campi associati alle 
 f
 feature categoriche date in input:  
La rete neurale è cosi de
 ﬁ
nita: 
L'output 
  è combinato con il precedente per generare l'output 
 ﬁ
nale:  
 
̂
y
(
F
M
)
e
i
∈
ℝ
k
̂
y
(
D
N
N
)
̂
y
=
σ
(
h
a
t
y
(
D
N
N
)
+
̂
y
(
D
N
N
)
)
20
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#2,2,"Motivazioni
I 
sistemi di raccomandazione
  sono strumenti chiave in molti scenari: e-
commerce, siti per la fruizione di musica e video (es. Spotify, Net
 ﬂ
ix), app 
stores, pubblicità, etc.  
•
Alcune conferenze internazionali speci
 ﬁ
che nel settore (es. RecSys) 
attraggono i maggiori players che fanno a gara per aggiudicarsi i migliori 
ricercatori.  
Supponiamo nel resto dei lucidi che alcuni argomenti sia già noti dai 
precedenti corsi:  
•
Collaborative 
 ﬁ
ltering  
•
Explicit e Implicit feedback  
•
Recommendation tasks (es. rating vs top-n vs sequence aware 
recommendation
3"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#20,20,"Deep Factorization Machines
L'architettura DeepFM è la seguente:
21
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#3,3,"MovieLens dataset
Il dataset più popolare nel mondo accademico 
 RecSys
 . Ne esistono diverse 
versioni in base alla quantità di dati contenuti.  
•
In 
MovieLens 100K
  sono contenuti 100.000 ratings espressi in una scala da 1 
a 5, da 943 utenti su 1682 
 ﬁ
lm. Ogni utente ha espresso rating su almeno 20 
ﬁ
lm. Il formato del dataset è 
 csv
. 
•
http://
 ﬁ
les.grouplens.org/datasets/movielens/ml-100k.zip  
Tecniche quali 
 Matrix Factorization
  sono state in in grado di individuare 
patterns chiave per ottenere migliori risultati rispetto ad approcci più 
tradizionali. Ma si limitano a catturare patterns e correlazioni di tipo lineare. 
4"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#4,4,"MovieLens dataset
MovieLens
  100K
  vs 
1M
5
"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#5,5,"AutoRec
In 
AutoRec
  si impiega un paradigma di Collaborative Filtering basato su 
autoencoders. Invece di rappresentare la matrice user-ratings in un spazio 
latente, o di impiegare le stesse istanze di input anche per l'output come nel 
caso degli autoencoders visti in precedenza, si segue un approccio alternativo:  
•
in 
input
  si hanno un le interazioni utente-item osservate  
•
in 
output
  ci si aspetta l'intera matrice delle interazioni utente-item  
Esistono architetture AutoRec 
 user-based 
 e 
item-based
 . Qui vedremo le 
seconde ma è facile immaginare le prime per analogia.
6"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#6,6,"(Item-based) AutoRec
Indichiamo con 
  la i-ma colonna della matrice dei ratings. I valori di rating 
sconosciuti saranno 0.  
La rete AutoRec la possiamo de
 ﬁ
nire formalmente:  
 
dove f e g sono funzioni di attivazione, W e V matrici di pesi, 
  e 
b
 sono 
biases, 
  la ricostruzione della i-ma colonna.  
La funzione da ottimizzare è la seguente:  
 
dove il primo modulo considera solo i 
 ratings
  noti.
R
*
i
h
(
R
*
i
)
=
f
(
W
⋅
g
(
V
⋅
R
*
i
+
μ
)
+
b
)
μ
h
(
R
*
i
)
argmin
W
,
V
,
μ
,
b
M
∑
i
=
1
|
|
R
*
i
−
h
(
R
*
i
)
|
|
2
+
λ
(
|
|
W
|
|
2
F
+
|
|
V
|
|
2
F
)
)
7"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#7,7,"Richiami: Implicit Feedback
I 
rating espliciti
  (es. valutazioni da 1 a 5) sono generalmente scarsi nei servizi 
di raccomandazione. Inoltre valori mancanti di rating possono essere 
erroneamente interpretati, es.: forme di feedback negativi invece di rating che 
devono essere ancora speci
 ﬁ
cati. 
Si tendono a sfruttare altre fonti che possono essere interpretate come forme di 
implicit feedback
 . 
•
Es. clicks, acquisti, visite, wish lists.
8"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#8,8,"Neural Collaborative Filtering for Personalized Ranking
Il 
Neural Collaborative Filtering (NCF)  
framework con implicit feedback 
sfrutta la capacità di 
 non-linearità 
 delle reti neurali.  
È composto da 2 reti, una basata su Generalized Matrix Factorization, l'altra 
consiste in una MLP.  
L'output delle 2 reti è concatenato per generale la predizione 
 ﬁ
nale. Se in 
AutoRec puntavamo a predire i rating, NCF produce una lista di 
raccomandazioni con score associato ad ogni item della lista.
9"
data_test\rootfolder\università\DeepLearning\17-RecSys-sbloccato.pdf#9,9,"Neural Collaborative Filtering for Personalized Ranking
La 
GMF
  è un approccio di MF implementato con reti neurali. L'input è il 
prodotto element-wise (Hadamard product) tra le rappresentazioni latenti degli 
utenti e degli item:  
Dove 
 p
u
 e 
q
i
 sono rispettivamente la u-ma riga di 
 P
 e q-ma riga di 
 Q
, dove 
 e 
 . L'output è la previsione di score dell'utente 
 u
 per 
l'item 
 i
. 
La 
MLP
 prende in input le rappresentazioni degli utenti e item, ignorando lo 
spazio latente della GMF. Lo scopo è individuare correlazioni aggiuntive con 
operazioni non lineari.
P
∈
ℝ
m
×
k
Q
∈
ℝ
n
×
k
10
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#0,0,"Deep Learning  
Università Roma Tre  
Dipartimento di Ingegneria  
Anno Accademico 2022 - 2023  
Deep Learning e Natural Language Processing
1"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#1,1,"Sommario
DL e NLP: motivazioni  
word2vec  
skip-gram  
CBOW  
GloVe  
fastText  
BERT"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#10,10,"word2vec: skip-gram (training)
Ci poniamo l'obiettivo di massimizzare la probabilità, cioè minimizzare la 
funzione:  
Se impieghiamo lo SGD, usiamo sequenze brevi per stimare il gradiente 
stocastico e aggiornare il modello. La stima è basta sul gradiente del logaritmo 
della probabilità condizionata data una coppia 
 w
o
 e 
w
c
. 
Una volta terminato l'apprendimento, i vettori 
 v
i
 sono tipicamente impiegati 
come 
 embedding
  associati ad un termine.
11
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#11,11,"word2vec: Continuous Bag of Words (CBOW)
Simile allo skip-gram ma assume che le parole contestuali generico la parola 
centrale.  
Essendoci più parole contestuali, i vettori sono mediati. La probabilità 
condizionata di generare un termine 
  dati i termini contestuali 
  è 
la seguente:  
Se consideriamo una sequenza di lunghezza T abbiamo:
w
c
 w
o
1
,
⋯
,
w
o
2
m
12
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#12,12,"word2vec: recap
Diagramma riassuntivo dei 2 modelli:
13
CBOW model Skip-gram model
t-word embedding t-word embeddingmatrix  
Vxdmatrix
dxV"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#13,13,"Word Embedding with Global Vectors (GloVe)
Le co-occorrenze tra termini rappresentano informazioni importanti per 
costruire gli embeddings. Indichiamo con 
 q
ij
 la probabilità condizionata 
 P(w
 j
|
w
i
)
 nel modello 
 skip-gram
 : 
La parola 
 w
i
 può presentarsi molte volte in un corpus. Tutte le parole 
contestuali che co-occorrono con 
 w
i
 creano un multiset, dove 
 x
ij
 indica il 
numero di volte che la parola 
 w
j 
co-occorre con 
 w
i
. La loss function è:  
Indichiamo con 
 x
i
 il numero di parole contestuali dove compare wi come 
parola centrale, e avendo 
 p
ij
=x
ij
/x
i
, otteniamo:
14
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#14,14,"Word Embedding with Global Vectors (GloVe)
La sommatoria interna è la cross-entropy tra la probabilità condizionata 
 q
ij 
relativa alla predizione generata dal modello, e 
 p
ij
 ottenuta analizzando le 
statistica dell'intero corpus.  
Per ridurre la complessità computazionale (soprattutto per generare 
 q
ij
) e per 
mitigare gli effetti generate dai termini che compaiono di rado nel corpus ma 
che possono assumere importanza elevata dalla cross entropy, il modello 
GloVe introduce alcune varianti.  
La nuova 
 loss function
  è la seguente:  
dove si introducono ad ogni parola sono associati 2 bias, 
 b
i
 per le parole 
centrali e 
 c
i
 per le parole impiegate nel contesto; il primo e ultimo termine nel 
termine a quadrato sono il termine di loss, e 
 h(x
ij
)
 genera un peso associato al 
termine di loss.
15
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#15,15,"fastText model
Ci sono relazioni morfologiche comuni tra molti vocaboli, es., tra 
 help
 e 
helps, 
helped, helping
 ; tra 
dog
 e 
dogs
 e tra 
 cat
 e 
cats
; tra 
boy
 e 
boyfriend
  e tra 
 girl
 e 
girlfriend
 . Modelli come skip-gram ignorano queste relazioni, poiché ognuno 
di questi termini è rappresentato da un vettore distinto.  
Il modello 
 fastText
  usa 
subword embeddings
 , dove ogni 
 subword
  è un 
 n-gram 
di caratteri. Ad ogni subword è associato un vettore.  
•
Per esempio, la parola ""where"" genera le subwords “<wh”, “whe”, “her”, 
“ere”, “re>” impiegando una 
 ﬁ
nestra di lunghezza 3.  
La rappresentazione di un termine 
 v
w
 sarà la somma delle sue subwords 
 z
g
: 
Il resto del modello è basato su skip-gram.
16
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#16,16,"Modelli context-indipendent e context-sensitive
Nei modelli precedenti, data una parola, il vettore generato non dipende dal 
contesto attuale (approccio 
 context-independent
 ). Termini polisemici o 
relazioni semantiche del linguaggio naturale saranno perciò ignorate.  
Modelli come 
 ELMo
  combinano le rappresentazioni intermedie ottenute da 
LSTM bidirezionali per ottenere una rappresentazione che dipende dalla 
sequenza in input (approccio 
 context-sensitive
 ).  
•
La rappresentazione così ottenuta è solitamente combinata con quella 
ottenuta in modo context-independent (es. tramite GloVe) nei task successivi. 
Il modello impiegato da ELMo deve essere speci
 ﬁ
co per il task che si andrà 
ad affrontare, e perciò rimarrà costante.  
Per evitare di avere diversi modelli per ogni task, GPT pre-addestra un 
language model che sarà usato per rappresentare sequenze testuali. I 
parametri saranno poi 
 ﬁ
ne-tuned
  in base all'ouput del task successivo. GPT è 
basato su Transformers. Il contesto analizzato da GPT sarà limitato alla parte 
antecedente al termine attuale, perciò non si analizza il contesto a destra del 
termine. 
17"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#17,17,"Bidirectional Encoder Representations from Transformers (BERT)
BERT combina i due approcci appena descritti, rappresentando l'intero 
contesto mediante un approccio bidirezionale.  
È basato su Transformer encoders pre-addestrati. Un output layer speci
 ﬁ
co per 
il task da affrontare sarà di volta in volta addestrato da zero. 
18
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#18,18,"Bidirectional Encoder Representations from Transformers (BERT)
L'input di BERT può essere una singolo testo o coppie di testi.  
Oltre agli 
 positional
  embedding, si impiegano anche 
 segment
  e 
token  
embeddings. Infatti, a differenza delle RNN, i Transformer richiedono tecniche 
speci
 ﬁ
che per rappresentare internamente l'ordine relativo in cui i termini 
compaiono tra loro. Tali embedding sono ricavati durante la fase di training.
19
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#19,19,"Bidirectional Encoder Representations from Transformers (BERT)
Come pretraining (auxiliary) task si impiega il 
 Masked Language modeling
 . 
Dato un corpus testuale, il 15% dei tokens saranno selezionati in modo 
random per il task di predizione. Al loro posto sarà presente un tag <mask>, 
es: 
•
“this movie is great” becomes “this movie is <mask>”  
Un ulteriore auxiliary task speci
 ﬁ
co nello scenario in cui si hanno 2 testi in 
input è il 
 Next sentence prediction
 . Dal corpus si estraggono coppie di frasi 
consecutive, e altrettante coppie di frasi che non sono consecutive. Il task è di 
classi
 ﬁ
cazione binaria.
20"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#2,2,"DL e NLP 
Durante l'apprendimento di tecniche ML abbiamo spesso bisogno di grosse 
moli di dati 
 labelled
  per implementare approcci supervisionati.  
Alcune architetture DL hanno la capacità di riconoscere pattern e 
caratteristiche anche complesse in tali dati, ma dataset adeguati per 
l'addestramento non sono disponibili.  
Per tale motivo sono stati proposti vari approcci come il 
 self-supervised 
learning
 , per analizzare dati un modo non supervisionato (
 auxiliary task, es. 
predire una parte mancante del testo) e costruire rappresentazioni utili per 
supportare l'apprendimento (tipicamente supervisionato) in task più speci
 ﬁ
ci.  
Avendo un dataset di testo, l'input può essere costruito impiegando singole 
parole o n-grams formati da lettere, utili per catturare informazioni 
morfologiche delle parole. L'output è tipicamente una rappresentazione 
vettoriale associata ad ogni parola (
 embedding
 ), indipendente dal contesto in 
cui sarà presente in seguito.
3"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#20,20,"Bidirectional Encoder Representations from Transformers (BERT)
BERT raggiunge prestazioni elevate su numero categorie di tasks, es.:  
•
single text classi
 ﬁ
cation 
 (e.g., sentiment analysis),  
•
text pair classi
 ﬁ
cation
  (e.g., date due domande di Quora determinare se sono 
simili o no),  
•
question answering
 ,  
•
text tagging
  (e.g., named entity recognition)
21"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#3,3,"Esempio di auxiliary task
4
inputsliding-window
output (training set)
  "
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#4,4,"Esempio di embeddings
Embeddings relativi a termini che identi
 ﬁ
cano 115 nazioni estratti da un 
corpus testuale, rappresentati su un piano 2d.
5   
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#5,5,"Esempio di operazioni su embeddings
Essendo vettori, possiamo fare operazioni sugli embeddings, es:  
•
vector(“paris”)−vector(“france”)+vector(""germany"")  
Impiegando il modello di embeddings 
 GloVe
  addestrato sul testa estatto da 
Wikipedia otteniamo:  
•
berlin: 0.8015347  
•
paris: 0.7623165     
•
munich: 0.7013252     
•
leipzig: 0.6616945    
•
germany: 0.6540700 
6   "
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#6,6,"DL e NLP 
Le rappresentazioni pretrained ottenute con approcci non supervisionati sono 
successivamente impiegate su architetture di DL in base al task da risolvere.
7
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#7,7,"word2vec
Il modello impiega 2 reti: 
 skip-gram
  e 
continuos bag of words
  (CBOW).  
Il training è basato sulla stima delle probabilità condizionate di predire una 
certa parola in base a termini che occorrono nel suo intorno. Si segue sempre 
un approccio non supervisionato.
8"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#8,8,"word2vec: skip-gram
Assume che un termine può generare il testo circostante in una sequenza.  
Supponiamo di considerare la sequenza 
 “the”, “man”, “loves”, “his”, “son”
 ; e 
considerare il termine 
 loves
  con parola centrale, e una 
 ﬁ
nestra di 2 termini 
intorno al termine centrale.  
Il modello skip-gram valuta la seguente probabilità condizionata:  
Se assumiamo che i termini siano generati in modo indipendente tra loro, 
possiamo riscriverla:
9
"
data_test\rootfolder\università\DeepLearning\18-NLP-sbloccato.pdf#9,9,"word2vec: skip-gram
Ogni parola con indice 
 i
 ha associati 2 vettori d-dimensionali, 
  e 
. Il primo impiegato quando la parola è usata centralmente, l'altro 
quando la parola appare nel contesto.  
La probabilità di generare un certo termine contestuale con indice 
 o
 dato il 
termine centrale con indice 
 c
 è de
 ﬁ
nita mediante una operazione softmax nel 
seguente modo:  
Data una sequenza di testo lunga 
 T
, dove 
  indica la parola posizionata allo 
step 
t
, e assumendo che le parole contestuali siano generate in modo 
indipendente tra loro, per una 
 ﬁ
nestra di lunghezza 
 m
, la probabilità di 
generare tutti i termini contestuali è de
 ﬁ
nita nel seguente modo:
v
i
∈
ℝ
d
u
i
∈
ℝ
d
w
(
t
)
10
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#0,0,!1Introduzione
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#1,1,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!2
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#10,10,"Misura delle grandezze fisicheEsempio: per misura della larghezza L di una lavagna occorre confrontare la larghezza della lavagna con uno standard di misura delle lunghezze: 
!11L{}=LL⎡⎣⎤⎦Risultato del confrontoGrandezza fisica da misurareLunghezza standard• Se [L]=metro            → {L} = 3,5    [L]=m   →   L = 3,5 m • Se [L]=centimetro    → {L} = 350     [L]=cm   →   L = 350 cm • Se [L]=piede             → {L} = 11,5    [L]=ft     →   L = 11,5 ft • Se [L]=pollice           → {L} = 138    [L]=in     →  L = 138 in La grandezza è sempre la stessa, ma cambiano sia la parte numerica che quella relativa allo standard di misura utilizzato"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#11,11,"Misura delle grandezze fisicheLa misura è identificata da due elementi: • La parte numerica (numero)  {L} • Lo standard usato (l’unità di misura) [L] 
!12L={L}[L]Devono essere specificati entrambi!!!"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#12,12,"Dimensioni delle grandezze fisicheGrandezze principali (che useremo nel corso) • Lunghezza L, Tempo T, Massa M, Intensità di corrente I
!13e ( alcune) grandezze derivate: • Superficie S=[L2], V olume V=[L3] • Frequenza F=[1/T]=[T-1]  • Velocità V=[L/T]=[LT-1], accelerazione A=[L/T2]=[LT-2] • Tensione elettrica V=[ML2I-1T-3]• Grandezza generica  [X]=[MαLβTγI𝛿] 𝛼,𝛽,𝛾,𝛿 sono dette dimensioni della grandezza fisica"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#13,13,"Dimensioni nelle formuleOgni formula ﬁsica è una relazione tra grandezze ﬁsiche → sono due relazioni, una sui numeri e una sulle unità di misura
!14"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#14,14,"Unità di misura (standard di misura)Gli standard devono soddisfare i criteri: • Essere stabili nel tempo • Essere precisi • Essere “facilmente” riproducibili in ogni parte del mondo (universo)
!15Dal 20 maggio 2019 si utilizzano nuove definizioni"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#15,15,"Unità di tempo: il secondoScelta di un fenomeno periodico:  •Giorno solare medio. Diviso in  - 24 ore, 60 minuti primi, 60 minuti secondo - 1 giorno = 86400 secondi  (minuti secondi) • 1967: un secondo corrisponde a 9.192.631.770 oscillazioni dell’isotopo di Cesio 133 tra lo stato fondamentale e il suo primo stato eccitato (invariato al 20/5/2019)!16
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#16,16,"Unità di lunghezza: il metroProdotto della rivoluzione francese (1795)•Deﬁnizione originale– 1 metro = 1/10 000 000 della distanza tra polo nord ed equatore •Deﬁnizione successiva (1889): distanza tra due tacche di una sbarra di platino-iridio (campione di Sèvres)•1983: Lo standard di tempo è ben deﬁnito; la velocità della luce è una costante universale:– 1 metro = distanza percorsa dalla luce in 1/299 792 458 secondi(invariato al 20/5/2019)!17
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#17,17,"Unità di corrente: l’ampereFino al 20/5/2019 L’intensità di corrente che, se mantenuta in due conduttori lineari paralleli di lunghezza infinita e sezione trascurabile, posti a un metro di distanza l’uno dall’altro nel vuoto, produce tra questi una forza pari a 2×10-7 newton per ogni metro di lunghezza. Oggi:  L’ampere sarà definito dal valore numerico della carica elementare fissato a 1,602176634×10-19 coulomb e sarà realizzato attraverso speciali circuiti che contano gli elettroni.!18
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#18,18,"Unità di massa: il kilogrammoProdotto della rivoluzione francese (1795) Intenzione: 1 kg = massa di 1 dm3 di acqua a 4 gradi centigradi Fino al 20/5/2019 Definizione: 1kg =  massa di un cilindro campione di platino iridio di 39 mm di altezza e 39 mm di diametro!19
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#19,19,"Unità di massa: il kilogrammoOggi:  Sarà ridefinito in termini della costante di Planck, sarà realizzato attraverso una speciale bilancia elettromagnetica (detta bilancia di Kibble) e non sarà più necessario riferirsi al campione di Sèvres. il chilogrammo diventa la massa controbilanciata da un certa quantità di corrente, dove entra in gioco la costante di Planck.
!20
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#2,2,"Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali
!3Fino al XVII secolo la Fisica era considerata come filosofia della natura (spinta più da considerazioni filosofiche)Il senso moderno del termine è stato introdotto da Galileo Galilei, partendo dalla definizione di Metodo Scientifico"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#20,20,"Sistema Metrico DecimaleUn insieme di unità di misura costituisce un sistema: Sistema MKS: metro, kilogrammo, secondo (rinominato in SI nel 1970: Sistema Internazionale) Sistema cgs: centimetro, grammo, secondo Sistema metrico decimale: i multipli ed i sottomultipli sono potenze di 10: Multipli prefisso  sottomultipli prefisso 10 deca (da)  10-1 deci   (d) 102 etto (h)  10-2 centi  (c) 103 kilo  (k)                 10-3 milli  (m) 106 mega (M)  10-6 micro  (µ) 109 giga (G)  10-9 nano (n) Esempi: 1 mm, 2 µm, 5 ns, 20 km, 4 hg!21"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#21,21,"Esempio
!22Una macchina percorre una curva semicircolare di raggio R=50 m con una velocità di v = 20 m/s. Calcolare l’accelerazione della macchina.
Risultato: l’accelerazione vale: Analisi dimensionale: [a]=[LT-2]Suggerimento: l’accelerazione (a) si misura in m/s2. La formula da usare è una delle seguenti:"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#22,22,"Esercizio
!23Determinare quanti secondi ci sono in un anno solare;Quanto pesa un metro cubo di acqua?Enrico Fermi amava dire che faceva lezioni che duravano tipicamente un microsecolo. A quanti minuti corrisponde un microsecolo?365.25×24×60×60=31,556,7361dm3→1kg1m3=1000dm3→1000kg100×365.25×24×60=52,594,560 minuti in un secoloUn microsecolo corrisponde a 52.59456 minuti "
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#23,23,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.ithttps://www.unibo.it/sitoweb/lorenzo.rinaldi/
!24"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#3,3,"Il Metodo Scientifico-SperimentaleAlla base del metodo Scientifico c’è l’Esperimento: i processi della Natura sono schematizzati in Modelli da verificare sperimentalmente
!4
...tra le sicure maniere di conseguire la verità è l’anteporre l’esperienza a qualsivoglia discorso, non sendo possibile che una sensata esperienza sia contraria al vero... "
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#4,4,"Il Metodo Scientifico-SperimentaleNessun modello teorico risulta essere valido universalmente Le teorie risultano essere valide entro ben determinati limiti esempio:  •piccole distanze: serve la “teoria dei quanti” •elevate velocità: serve la “teoria della relatività” 
!5"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#5,5,"Il Metodo Scientifico-SperimentaleLe teorie fisiche sono validate tramite osservazioni sperimentali Gli esperimenti devono essere realizzati per determinare con precisione (MISURARE) in maniera RIPRODUCIBILE le grandezze fisiche.
!6Le grandezze Fisiche sono quantità che servono per descrivere i fenomeni naturali in maniera oggettiva (esempio: tempo, spazio, massa,…) 
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#6,6,"Grandezze Fisiche
!7Grandezza fisica: proprietà o caratteristica di un oggetto o di un fenomeno che può essere quantificata (→ misurata)
Esempi: 
lunghezze, durate, velocità, forza, temperatura, pressioneodori, intelligenza, bello, brutto…
Controesempi: 
"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#7,7,"Grandezze principali e derivate Lunghezza e V olume • Il volume V di un cubo di lato L: V=L3
!8
L In un viaggio di T=1 h, ho percorso L=100 km spostandomi ad una velocità v=100 km/h • 3 grandezze: durata, distanza, velocità •1 relazione tra le grandezze v=L/Tlunghezza e tempo sono grandezze principali V olume e velocità sono grandezze derivate"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#8,8,"Grandezze principali e derivate
!9In Fisica ci sono 7 grandezze principali, tutte le altre sono derivabili da esselunghezza tempo massa temperatura intensità di corrente elettrica intensità luminosa quantità di sostanzaMECCANICAELETTROMAGNETISMO"
data_test\rootfolder\università\FisicaGenerale\01-introduzione.pdf#9,9,"Misura delle grandezze fisicheMisura: processo di determinazione di una grandezza fisica Operativamente: misura=confronto della grandezza che ci interessa con uno standard (una misura campione di quel tipo di grandezza)Le grandezze Fisiche sono definite in Modo Operativo: il modo di misurare la grandezza ne fissa la definizione Le grandezze Fisiche sono definite da tutte le possibili operazioni di misurazione
!10"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#0,0,VETTORI  CdS Ingegneria Informatica A.A. 2019/20
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#1,1,"!2Grandezze fisiche•Grandezze scalari: completamente definite da un numero ed una unità di misura –Esempi: distanza, lunghezza, periodo, pressione, temperatura •Grandezze vettoriali: completamente definite da 3 numeri e da una unità di misura o da un numero, una unità di misura, una direzione ed un verso –Esempi: spostamenti, forze, velocità, accelerazione, campi elettrici e magnetici, … •Grandezze tensoriali: definite da più di 3 numeri ed una unità di misura –Esempi: momento d’inerzia, matrice di rotazione, …"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#10,10,"!11Proprietà associativa della somma
⃗a+⃗c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#11,11,"!12Differenza tra vettori•Definizione:OABOAB−⃗bvettore opposto (stesso modulo e direzione, ma con verso opposto)⃗d=⃗a−⃗b=⃗a+(−⃗b)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#12,12,"Somma e differenza
!13⃗a⃗d=⃗a−⃗b⃗b⃗c=⃗a+⃗b"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#13,13,"!14Moltiplicazione per uno scalare•Si può definire come moltiplicazione tra un numero naturale n ed un vettore     come una somma ripetuta:•Generalizzando, si può definire come  moltiplicazione tra un numero reale λ ed un vettore      come vettore di direzione pari ad      modulo pari a            e verso concorde con     se             , verso opposto se    È un vettore!"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#14,14,"!15Moltiplicazione per scalare: proprietà•La moltiplicazione per uno scalare gode delle proprietà commutative, associative e distributive sia rispetto agli scalari che ai vettori:•Inoltre:"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#15,15,"!16Prodotto scalareAssocia a due vettori arbitrari uno scalare:θa⋅b=abcosϑ
a⋅b=abb
a⋅b=aba"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#16,16,!17                   : casi notevoli•Vettori in direzione opposta:a⋅b=abcosϑ•Vettori paralleli:a⋅b=ab>0•Vettori ortogonali:a⋅b=0•La componente: –Sia      un versorea⋅ˆu=aˆucosϑ==acosϑ=au
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#17,17,"!18Prodotto scalare: proprietà•Il prodotto scalare gode della proprietà commutativa, distributiva sulla somma:•Quadrato di un vettore:DEFINIZIONE  DI MODULO!  a⋅b=b⋅aa⋅b+c()=a⋅b+a⋅cλa⋅b()=λa()⋅b=a⋅λb()   a⋅a=a2=a2=a2  ⇒a=a⋅a"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#18,18,"!19Moduli di somme e di differenze
   a+b=a+b()2=a+b()⋅a+b()=  =a⋅a+a⋅b+b⋅a+b⋅b   a+b=a2+b2+2abcosϑ   a−b=a−b()2=a−b()⋅a−b()=  =a⋅a−a⋅b−b⋅a+b⋅b   a−b=a2+b2−2abcosϑ"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#19,19,"!20Prodotto vettore•Associa a due vettori un terzo vettore:
Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destraModulo: area del parallelogrammaVerso convenzionale"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#2,2,!3Stazione: 2.2 km in direzione nord-est
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#20,20,"!21Prodotto vettore•Associa a due vettori un terzo vettore:Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destra
"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#21,21,!22Prodotto vettore: proprietà•Il prodotto vettore (o vettoriale) gode della proprietà anticommutativa e distributiva sulla somma: •Il prodotto vettore non gode della proprietà associativa: •Caso notevole:
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#22,22,"!23Doppio prodotto misto
Proprietà:V=a∧b⋅c=a∧b()⋅ch=c⋅versa∧b() a∧b⋅c=b∧c⋅a=c∧a⋅b a∧b⋅c=a⋅b∧c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#23,23,"!24Sistemi di riferimento•I vettori sono entità astratte, indipendenti da come sono rappresentate.AB•Per convenienza pratica i vettori si descrivono bene utilizzando il concetto di SISTEMA DI RIFERIMENTO, costituito in estrema sintesi da un punto privilegiato detto origine e da un insieme di vettori campione (vettori di base)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#24,24,!25Spazio unidimensionale•Ogni vettore può essere scritto come:O In uno spazio unidimensionale ogni vettore può essere espresso come uno scalare (la componente) moltiplicato il versore dell’asse (sempre lo stesso).a+b=auˆu+buˆu=au+bu()ˆua=a⋅a=auˆu⋅auˆu=au2(ˆu⋅ˆu)=au
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#25,25,"!26Spazio bidimensionale: vettori nel piano•Scelgo 2 assi ortogonali x,y: 
OXYˆi⋅ˆj=0"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#26,26,"Esempio di spazio bi-dimensionale
!27
(C; 4)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#27,27,"!28Spazio tridimensionale
•Scelgo 3 assi ortogonali x,y,z: "
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#28,28,"!29Vettori di base nello spazio
1ˆˆˆˆˆˆ=⋅=⋅=⋅kkjjii0ˆˆˆˆˆˆ=⋅=⋅=⋅ikkjjiˆi∧ˆi=ˆj∧ˆj=ˆk∧ˆk=0"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#29,29,"!30Operazioni nella rappresentazione cartesiana
a⋅b=ca⋅b=(axˆi+ayˆj+azˆk)⋅(bxˆi+byˆj+bzˆk)==axbxˆi⋅ˆi+axbyˆi⋅ˆj+axbzˆi⋅ˆk+aybxˆj⋅ˆi+aybyˆj⋅ˆj+aybzˆj⋅ˆk++azbxˆk⋅ˆi+azbyˆk⋅ˆj+azbzˆk⋅ˆk==axbx+ayby+azbz=c"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#3,3,"!4Vettore nel piano
ABModuloDirezioneVersoVettore libero 1 direzione nello spazio 1 verso 1 modulo (intensità)Prototipo: vettore spostamento"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#30,30,"!31Prodotto vettoriale
"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#31,31,"Esercizio A•Sianoˆˆˆˆˆˆ21322aijkbijk=−+=−+−!!1.Trovare i moduli 2.Trovare il vettore somma ed il vettore differenza 3.Calcolare  4.Calcolare  5.Trovare l’angolo compreso!3232,23cabdab=+=−!!!!!!abλ=⋅!!"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#32,32,"Esercizio Nel piano XY, la componente x di un vettore v vale -25, quella y +40. Quanto vale il modulo del vettore? Quanto vale l’angolo compreso fra v e l’asse delle ascisse? 
!33"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#33,33,!34Esercizio 1•Sia1.Trovare i moduli 2.Trovare l’angolo compreso 3.Trovare il vettore somma ed il vettore differenza 4.Trovare un vettore perpendicolare ad entrambi
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#34,34,"!35Esercizio 3•Una barca naviga in direzione Nord-Est per 15 km, successivamente vira in direzione Sud e prosegue per 10 km, quindi vira nuovamente in direzione Ovest e percorre altri 5 km. Trovare la distanza percorsa e la distanza dal punto di partenza.NESO"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#35,35,"Esercizio Nella somma a+b = c il vettore a ha modulo 12 e forma un angolo di 40° rispetto al semiasse positivo delle ascisse, mentre il vettore c ha modulo 15 ed è diretto con un angolo di 20° in senso antiorario rispetto al semiasse negativo delle ascisse. Calcolare il modulo e la direzione (rispetto al semiasse positivo delle ascisse) di b. 
!36"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#36,36,"Esercizio Dati nel piano cartesiano i punti A = (1, 1), B = (3, 4) e  C = (5, 2), determinare il valore dell’angolo formato dai segmenti CA e CB e l’area del triangolo ABC. 
!37"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#37,37,"EsercizioDeterminare il volume del parallelepipedo individuato dai vettori   ˆˆˆˆˆˆˆ2,3,32ajkbjcjkιι=−+=−=−+−!!!
!38"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#38,38,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it www.unibo.it/docenti/lorenzo.rinaldi
!39"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#4,4,"!5Versore•Versore: vettore di modulo unitario, adimensionaleUn versore individua un asse orientatoAB"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#5,5,"I versori dove non te li aspetti
!6"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#6,6,"!7LA componente ed IL componente
vu = v cosθla componente
(vu = v cosθ u) il componenteLA componente è una grandezza scalare!IL componente è un vettore (il vettore componente lungo una direzione)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#7,7,!8Algebra dei vettori•I vettori liberi costituiscono un’algebra –È definita l’operazione somma tra due vettori –È definita l’operazione di moltiplicazione tra un vettore ed uno scalare •Inoltre: sono definiti un prodotto esterno ed uno interno –Prodotto scalare: –Prodotto vettoriale:
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#8,8,"!9Somma tra due vettori•Prototipo: somma tra due vettori spostamentoABCD
Regola del parallelogramma: Il vettore somma è dato dalla diagonale (C-A) del  Parallelogramma costruito  con i vettori (B-A) e (C-B)B≡C⃗c=⃗a+⃗b=(D−A)"
data_test\rootfolder\università\FisicaGenerale\02-vettori.pdf#9,9,"!10Proprietà commutativa della somma•La somma gode della proprietà commutativa: 
•È un risultato sperimentale, non teorico, valido nel nostro ambiente. Ci sta dicendo che lo spazio fisico in cui viviamo è in buona approssimazione uno spazio euclideo."
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#0,0,CINEMATICA CdS Ingegneria InformaticaA.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#1,1," 2Modello base•Punto materiale: –Punto geometrico –Dotato di una proprietà chiamata massa •Valido per la descrizione del moto di ogni oggetto, quando le dimensioni dello stesso non sono importanti e possono essere trascurate"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#10,10," 11Velocità scalare, vettoriale, versore tangente
Nella rappresentazione intrinseca: v(t)=limΔt→0P(t+Δt)−P(t)Δt=dPdt v(t)=s(t)=limΔt→0s(t+Δt)−s(t)Δt⎯⎯→⎯→Δ0t)()()()(lim0tvtsttsttst==Δ−Δ+=→Δ"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#11,11," 12Velocità: derivata del vettore posizione
xyzP(t)
Nella rappresentazione cartesiana:"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#12,12," 13Derivata di un vettore⃗a=⃗a(t)=B(t)−A(t)d⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δtd⃗adt è un vettored⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δt⃗a(t)⃗a(t+Δt)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#13,13," 14Regole di derivazione
Dimostrabili tramite la rappresentazione cartesiana dei vettori"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#14,14,"se a(t)=λ costante   ⇒da2dt=0 per ipotesida2dt=da⋅a()dt=dadt⋅a+a⋅dadt=2a⋅dadt≡0⇒a⊥dadt
 15Esempi e dimostrazioni•Tutte le relazioni si dimostrano facilmente nella rappresentazione cartesiana:•Caso notevole: vettore di modulo costante.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#15,15," 16Cinematica: Riassunto•Il moto è sempre un fenomeno relativo
Moto di un punto (P) rispetto ad un sistema di riferimento (SR)TraiettoriaDescrizione cartesianaEquazioni  parametricheVettore posizionexyz"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#16,16," 17Velocità e descrizione intrinseca
xyzOΩss: ascissa/coordinata curvilinea
Velocità scalare istantanea
Velocità vettoriale  istantanea
Rappresentazione cartesianaRappresentazione intrinsecaversore tangente alla traiettoria"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#17,17," 18Accelerazione scalare media ed istantanea•Analogamente a quanto fatto per la variazione della posizione, si introduce il concetto di accelerazione per descrivere le variazioni di velocità •Data la velocità scalare istantanea   Accelerazione scalare mediaAccelerazione istantanea   a(t)=limΔt→0am(t,t+Δt)=limΔt→0v(t+Δt)−v(t)Δt=dvdt=!v   a(t)=dvdt=!v=d2sdt2=!!s  am⎡⎣⎤⎦=a⎡⎣⎤⎦=ΔvΔt⎡⎣⎢⎤⎦⎥=LT−1/T⎡⎣⎤⎦=LT−2⎡⎣⎤⎦→(m/s2)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#18,18," 19Accelerazione vettorialeAccelerazione mediaAcc. Istantanea !a=limΔt→0!am=limΔt→0!v(t+Δt)−!v(t)Δt"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#19,19," 20Esercizio 1•Il movimento di un punto dello spazio è descritto dal vettore posizione: •Trovare la velocità vettoriale e scalare •Trovare l’accelerazione vettoriale •Calcolare l’angolo tra il vettore velocità e quello accelerazione e spiegare il risultato ottenuto.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#2,2,"•La terra non ruota solo su se stessa: ruota intorno al Sole a una velocità superiore a 110.000 km/h.
Qual è la nostra VELOCITÀ?Vi sembra di essere seduti immobili mentre ascoltate la lezione?
 3•Il pianeta ruota su se stesso, il che significa che in realtà viaggiamo verso est a una velocità che può raggiungere i 1600 km/h .
•Il Sole e il Sistema Solare viaggiano nello spazio alla folle velocità di 2 milioni di km/hQual è la nostra vera VELOCITÀ? "
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#20,20," 21Esercizio 2•In un piano xy, un punto materiale si muove seguendo le leggi: •Trovare il vettore posizione •Trovare la velocità scalare al tempo t=10s •Mostrare che l’accelerazione è costante
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#21,21," 22Rapp. Intrinseca: versore normale
Traiettoria circolare
Δ̂utΔs⟶α,Δs→0d̂utds=d̂utdŝun"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#22,22," 23Componenti intrinseche dell’accelerazione
Circonferenza osculatrice (nel piano osculatore)ρ = raggio di curvatura (funzione di s)Espressione intrinseca"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#23,23," 24Rappresentazione intrinseca del moto•Traiettoria:•Legge oraria:•Versore tangente: •Versore normale: •Versore binormale: Terna intrinseca  di versori  Ortonormali  •Raggio di curvatura: •Velocità: •Accelerazione: •Legge oraria:   →!v=""s=vx2+vy2+vz2"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#24,24," 25Classificazione dei moti - I1. Moto a velocità costante:
xyzOMoto rettilineo  uniforme"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#25,25," 26Classificazione dei moti - II2. Velocità costante in direzione
xyzOEsempio: Moto uniformemente  accelerato"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#26,26," 27Classificazione dei moti - III3. Moto a modulo di velocità costanteEsempio: Moto circolare uniformeMoto uniformemente curvo
xyzOΩs"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#27,27," 28Classificazione dei moti - IV4. Moto senza vincoli sulla velocitàMoto curvo varioxyzOΩs"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#28,28," 29Osserviamo la realtà che ci circonda …Perché le curve in autostrada sono sempre molto dolci (→ hanno un raggio di curvatura di centinaia di metri), mentre in campagna mi trovo anche curve molto secche (a 90° in pochi metri)?Perché NON ESISTONO curve in autostrada con raggio inferiore a diverse centinaia di metri, ad eccezione dei raccordi per i caselli, dove, se non si rallenta opportunamente, è facile finire fuori strada?Perché i progettisti delle tratte ferroviarie dell’alta velocità considerano sempre traiettorie con raggi di curvatura di qualche km, quando in stazione ci sono curve con raggi di curvatura di qualche decina di metri?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#29,29," 30Espressioni cartesiane
 an=!s2ρ→ρ=!s2an"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#3,3," 4Cos’è il moto?•Il moto è sempre un fenomeno relativo•Moto di una macchina rispetto ad una strada•Moto di un aereo rispetto alle nuvole, al terreno•Moto di un pianeta rispetto alle stelle ﬁsse•Moto di un sistema osservato rispetto all’osservatoreESEMPIMoto di un punto (P) rispetto "
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#30,30," 31Problemi di cinematica•Problema DIRETTO della cinematica: dato il vettore posizione, trovare velocità ed accelerazione: •Problema INVERSO della cinematica: data l’accelerazione (o la velocità), trovare velocità e vettore posizione !at() noto ⇒ !vt()=?!rt()=?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#31,31," 32Problema inverso•Tipico problema: nota la velocità:
L’analisi illustra che esistono ∞3 soluzioni (moti diversi)La richiesta che il sistema di equazioni abbia  una sola soluzione richiede l’introduzione di altri dati:  le condizioni iniziali"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#32,32," 33Esempio di problema inversoCostanti arbitrarieCondizioni iniziali: Soluzioneunivoca"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#33,33," 34Esempio: problema inverso unidimensionale•ES:Sia                  , trovare il moto x(t).Soluzione: txk=-2k=0k=-1k=+1Moltitudine di moti diversi!Condizioni iniziali:  x(0)=0Un moto particolareSoluzione: k=0"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#34,34," 35Esempio•Un punto materiale si muove lungo l’asse x con una accelerazione data da •Sapendo che le condizioni iniziali sono •Trovare velocità e posizione ad ogni istante di tempo"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#35,35," 36Soluzione•Velocità:• Posizione:dv adt→=→dv∫=adt∫"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#36,36," 37Esercizio 1 La posizione di un punto materiale è individuata dal vettore posizione con t  espresso in secondi ed r in metri. Determinare la velocità e l’accelerazione ad ogni istante di tempo, la terna di versori intrinseca ed il raggio di curvatura della traiettoria per t=0 s.
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#37,37," 38Esercizio 2In un certo istante, un punto materiale è in moto lungo un arco di circonferenza. Sapendo che rispetto ad un certo SR, la velocità e l’accelerazione valgono  e determinare la velocità scalare, l’accelerazione tangenziale, il raggio di curvatura della traiettoria e la normale al piano in cui avviene il moto. 
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#38,38," 39Moti nel piano
XYP1y(t)Ox(t)Equazioni parametriche
Equazione della traiettoria"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#39,39," 40Moto rettilineo uniforme
XYP1y(t)Ox(t)Equazioni parametricheVelocità ed accelerazioneda x=x0+v0xt→t=x−x0v0xintercettapendenza"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#4,4," 5Scelta del sistema di riferimento•Lo stesso oggetto può essere descritto in modo diverso a seconda del SR:Moto della lavagna (e di tutti noi):•Ferma rispetto a noi (SR della stanza)•Moto circolare per chi ci osserva dalla luna (SR lunare; velocità circa 1200 km/h)•Moto + complesso per chi ci osserva dal Sole (SR eliocentrico; velocità circa 108000 km/h)•Moto ancora più complesso per chi ci osserva dal centro della Galassia!Scegliamo un SR a seconda di cosa si muove e di come vogliamo descrivere il moto"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#40,40," 41Moto dei gravi•Caduta di un corpo sulla superficie terrestre
XYy(t)Ox(t)costantealtoAsse orizzontaleCondizioni iniziali"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#41,41," 42Moto dei gravi: soluzione
•Traiettoria:→y=ax2+bx+c"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#42,42," 43Caduta dei graviOggetto che cade da fermo da un’altezza hCaso particolare con condizioni iniziali (con t0=0): {⃗r0=ĥ𝚥⃗v0=⃗0{x0=0y0=hv0x=0v0y=0{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2traiettoria: linea retta (asse y)XYO"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#43,43," 44Caduta dei gravi{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2
XYOTempo di caduta (da altezza h):y(tc)=0h−g2t2c=0tc=2hgVelocità d’impatto al suolo⃗v(tc)=−gtĉ𝚥⃗v(tc)=−g2hĝ𝚥=−2gĥ𝚥"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#44,44," 45Moto dei gravi:  generale•La traiettoria è una parabolaXYy(t)Ox(t)altoAsse orizzontaleCoordinate del punto di massimo della parabola?In quale punto dell’asse x atterra ? (y=0)A che istante e con che velocità ci arriva?Rappresentazione intrinseca:velocità e accelerazione?terna di versori intrinseca?raggio di curvatura?"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#45,45," 46Coordinate Polari piane
xyPvettore posizione del punto Pin coordinate cartesiane⃗r=x̂ı+ŷ𝚥
{x=rcosφy=rsinφpotremmo usare un’altra coppia di scalari: + distanza r dall’origine e angolo 𝜑 rispetto ad asse x̂ı̂𝚥φrtrasformazioni delle coordinater=x2+y2φ=arctanyx"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#46,46," 47Coordinate Polari piane
xyP{x=rcosφy=rsinφ̂ı̂𝚥φrr=x2+y2φ=arctanyxversori in coordinate polari pianêur=(̂ur⋅̂ı)̂ı+(̂ur⋅̂𝚥)̂𝚥=cosφ̂ı+sinφ̂𝚥⃗r=x̂ı+ŷ𝚥̂uφ=(̂uφ⋅̂ı)̂ı+(̂uφ⋅̂𝚥)̂𝚥=−sinφ̂ı+cosφ̂𝚥̂ur̂uφsi veriﬁca facilmented̂urdφ=̂uφd̂uφdφ=−̂urcambiano durante il moto!α=φ+π2cosα=−sinφsinα=cosφ"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#47,47," 48Coordinate polari cilindriche
xyzPϕzrP’̂ur̂uφ̂uz
̂ur̂uz{x=rcosφy=rsinφz=zr=x2+y2φ=arctanyxz=ẑur=cosφ̂ı+sinφ̂𝚥uφ=−sinφ̂ı+cosφ̂𝚥̂uz=̂k̂uφterna ortogonalêur=̂uφ∧̂k"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#48,48," 49Moto circolare
xyP(t)ascissa curvilinea s (con origine sull’asse x)s=RφTraiettoria circolare di raggio R centrata nell’origine di un SdR cartesianoRarco di circonferenzaφΩs[0≤s≤2πR]{x(φ)=Rcosφy(φ)=RsinφNel SdR cartesiano⃗r(φ)=Rcosφ̂ı+Rsinφ̂𝚥⃗r(s)=Rcos(sR)̂ı+Rsin(sR)̂𝚥|⃗r|=R
la posizione dipende solo dall’angolo 𝜑⃗r(φ)=R̂urs(t)=Rφ(t)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#49,49," 50Cinematica del moto circolare⃗r(φ(t))=Rcosφ(t)̂ı+Rsinφ(t)̂𝚥=R̂ur⃗v(φ(t))=d⃗rdt=−R·φsinφ̂ı+R·φcosφ̂𝚥=R·φ̂uφ⃗a(φ(t))=d⃗vdt==(−R··φsinφ−R·φ2cosφ)̂ı+(R··φcosφ−R·φ2sinφ)̂𝚥==R··φ(−sinφ̂ı+cosφ̂𝚥)−R·φ2(cosφ̂ı+sinφ̂𝚥)==R··φ̂uφ+R·φ2(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#5,5," 6Sistema di riferimento cartesianoTraiettoria Luogo dei punti dello spazio per cui passa un corpo P=P(t)
xyz
= Descrizione cartesianaEquazioni  parametricheOVettore posizione
r⎡⎣⎤⎦=x⎡⎣⎤⎦=y⎡⎣⎤⎦=z⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#50,50," 51Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φaccelerazione angolareα=·ω=··φ⃗v=R·φ̂uφ=Rω̂uφ=Rω̂k∧̂ur=(ω̂k)∧(R̂ur)=⃗ω∧⃗rvettore velocità angolarêuφ=̂k∧̂ur⃗v=⃗ω∧⃗r⃗ω=ω̂k⃗a=Rα̂uφ+Rω2(−̂ur)=⃗α∧⃗r−ω2⃗rvettore accelerazione angolare⃗α=α̂k⃗a=ddt(⃗ω∧⃗r)=d⃗ωdt∧⃗r+⃗ω∧d⃗rdt=ur=̂uφ∧̂k
⃗at=⃗α∧⃗r⃗an=⃗ω∧⃗v=⃗ω∧(⃗ω∧⃗r)=⃗α∧⃗r+⃗ω∧⃗v=⃗α∧⃗r+⃗ω∧(⃗ω∧⃗r)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#51,51," 52Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φ=ddt(sR)=·sR=vRaccelerazione angolareα=·ω=ddt(·sR)=··sRangoloφ=sR⃗v=Rω̂uφ=·ŝuφ⃗a=Rα̂uφ+Rω2(−̂ur)=··suφ+·s2R(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#52,52," 53Cinematica del moto circolare⃗r=R̂ur⃗v=R·φ̂uφ=Rω̂uφ⃗a=R··φ̂uφ+R·φ2(−̂ur)=xyφR̂ur̂uφ=Rα̂uφ+Rω2(−̂ur)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#53,53," 54Moto circolare uniforme⃗r=R̂ur⃗v=Rω̂uφ=⃗ω∧⃗rx̂uryφR̂uφ⃗a=−Rω2(̂ur)=−ω2⃗r=⃗ω∧(⃗ω∧⃗r)velocità costante in modulo ma varia continuamente in direzioneω=·φ=costanteα=·ω=0
accelerazione (centripeta) costante in modulo ma varia continuamente in direzione"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#54,54,"Moti periodici•Un fenomeno è detto periodico se, a partire da un istante qualsiasi t, le sue caratteristiche si ripresentano inalterate dopo un certo intervallo di tempo T, detto periodo. •Quantità caratteristiche: –       ,  periodo fondamentale; –         , frequenza (numero di T contenuti nell’unità di tempo); –          , pulsazione (numero di giri compiuti nell’unità di tempo sulla traiettoria chiusa) υ=1Tω0=2πTTmin
 55 !r(t+nT)=!r(t)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#55,55,"Esempio di moto periodicoMoto circolare uniforme:→v=costantexy !r•In coordinate cartesiane:Tutte le equazioni:hanno la stessa famiglia di soluzioni: 56
"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#56,56," 57Soluzione generale•Problema di base:Ipotesi di soluzione:f+ω2f=0→"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#57,57," 58Moto oscillatorio armonicoTraiettoria Equazione oraria 
x+l-l"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#58,58," 59Moto armonico: condizioni inizialiSia dato un moto armonico di pulsazione ω e condizioni iniziali x(0)=x0 e v(0)=v0. Trovare la legge oraria.Soluzione:  Equazione del moto armonico:Soluzione generale:Velocità:Accelerazione:Impongo le condizioni iniziali:x(0)=Acos(φ0)=x0x(0)=−ωAsin(φ0)=v0→⎧⎨⎪⎩⎪"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#59,59," 60Esercizio•Dati due moti armonici di pulsazione ω nel piano con condizioni iniziali:
Trovare leggi orarie e traiettoriaMoto A xA0()=x0!xA0()=0⎧⎨⎪⎩⎪yA0()=y0!yA0()=0⎧⎨⎪⎩⎪Moto B xB0()=x0!xB0()=0⎧⎨⎪⎩⎪yB0()=0!yB0()=ωx0⎧⎨⎪⎩⎪"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#6,6," 7TraiettoriaLuogo dei punti dello spazio per cui passa un corpo (entità unidimensionale)P=P(t)xyzOP1=P(t1)P2=P(t2)Equazione parametrica della traiettoria:ParametriVettore spostamentor⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#60,60,"Moti relativi
 61
P(')(')POOOPO−=−+−
()rrOOʹʹ=+−!!Posizioner!rʹ!
''PPOrrr=+!!""'Or!‘‘‘‘‘‘‘
SS’S: sistema di riferimento fermoS’: sistema di riferimento mobile
SS’"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#61,61,"Trasformazione della velocità (opz)
 62Velocità''Orrr=+!!!ˆˆˆˆˆˆ(')(')''''''(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!ˆˆˆ'(')''''''ˆˆˆ()(')(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!
Pr!rʹ!
'Or!’’’’’’’ˆˆˆ'''''''xiyjzk=++v!""""""ˆˆˆxiyjzk=++v!""""""ˆˆˆˆˆˆ'('''''')'''ˆˆˆ'''''''''drdxiyjzkddjdkxiyjzkxyzdtdtdtdtdtι++==+++++!""""""ˆˆˆ'''ddjdkdtdtdtιQuanto valgono                          ?
!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#62,62,"Formule di Poisson (opz)•Quindi:
 63ˆ'ddtιDerivata di un vettore di modulo costanteˆˆ''ˆˆˆ'''ddajbkdtdtιιι⊥=+drrdtω==×v!!!!Vista nel moto circolare uniforme. E’ generalizzabile !Formule di Poisson: esiste un unico       per cui:ˆ'ˆ'ˆ'ˆ'ˆ'ˆ'ddtdjjdtdkkdtιωιωω⎧=×⎪⎪⎪=×⎨⎪⎪=×⎪⎩!!!ω!ˆˆˆ''''''ˆˆˆ'(')'(')'(')ˆˆˆ('''''')'ddjdkxyzdtdtdtxyjzkxyjzkrιωιωωωιω++==×+×+×==×++=×!!!!!!ω!Descrive la rotazione di S’ rispetto ad S: asse + velocità angolare"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#63,63,"Trasformazione della velocità (opz)•Posizione:
 64''Orrr=+!!!ˆˆˆ'''''''xiyjzk=++v!""""""ˆˆˆxiyjzk=++v!""""""•Velocità:•Trasformazione:•Velocità di trascinamento:•Un punto fermo in S’ si muove di velocità     in STv!Addizione delle velocità!v=!v'+!ω×!r'+!vO'!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'=!v'+!ω×!r'+!vO'!vT=!ω×!r'+!vO'!v=!v'+!vT"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#64,64,"Trasformazione dell’accelerazione (opz)
 65Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!""""""""""""""""""""""""'ˆˆˆˆˆˆˆˆˆˆˆˆ('''''''''''')('''''''''''')Oxiyjzkxiyjzkxiyjzkxiyjzka=++++++++++++=!""""""""""""""""""""""""""""""""""""""""""""""""ˆˆˆˆˆˆˆˆˆ('''''')'(')''''('''''')'xiyjzkxiyjzkxiyjzkωωωωω++=×+×+×=×++=×v!!!!!!""""""""""""""""""""""""NB:()ˆˆˆ'(')'ˆˆˆˆ''''diddiidtdtdtωιωιωωιωωι×===×+×=×+××!""!!!!!""""""""
!v=""xˆi+""yˆj+""zˆk=""x'ˆi'+""y'ˆj'+""z'ˆk'+x'ˆ""i'+y'ˆ""j'+z'ˆ""k'+!vO'!v'=""x'ˆi'+""y'ˆj'+""z'ˆk'!a=d!vdt=ddt(""x'ˆi'+""y'ˆj'+""z'ˆk'+x'ˆ""i'+y'ˆ""j'+z'ˆ""k'+!vO')=
x'ˆ!!i'+y'ˆ!!j'+z'ˆ!!k'==x'(!""ω×ˆι'+!ω×!ω×ˆι'())+y'(!""ω×ˆj'+!ω×!ω×ˆj'())+z'(!""ω×ˆk'+!ω×!ω×ˆk'())==!""ω×(x'ˆi'+y'ˆj'+z'ˆk')+!ω×!ω×(x'ˆi'+y'ˆj'+z'ˆk')()=!""ω×!r'+!ω×!ω×!r'()"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#65,65,"Trasformazione dell’accelerazione
 66Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!""""""""""""""""""""""""()''2'''odaarradtωωωω==+×+×+××+vv!!!!!!!!!!!""()'''Toarraωωω=×+××+!!!!!!!""Accelerazione di trascinamento:Un punto fermo in S’ si muove di accelerazione     in STa!'2''TCOTaaaaaaω=+×+=++v!!!!!!!!2'COaω=×v!!!Accelerazione di Coriolis:"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#66,66,"SR in moto rettilineo uniforme
 67
''Orrr=+!!!
xyzx’y’z’'Ov!
'aa=!!P(t)O’O00COTaa==!!!!
()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!""
Trasformazioni di Galileo!vO'=costante,!ω=!0x(t)=x'(t)+vO'ty(t)=y'(t)z(t)=z'(t)!v(t)=!v'(t)+!vO'=vx(t)=vx'(t)+vO'vy(t)=vy'(t)vz(t)=vz'(t)⎧⎨⎪⎩⎪!vT=!vO'
!v=!v'+!vT!vT=!vO'+!ω×!r'"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#67,67,"Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.itwww.unibo.it/docenti/lorenzo.rinaldi
 68"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#68,68,"Argomenti opzionali
 69"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#69,69," 70Velocità areolare
A(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#7,7," 8Rappresentazione intrinseca
xyzOΩss: ascissa curvilineaDescrizione intrinseca: -Geometria della traiettoria -Origine Ω, verso della traiettoria  -Coordinata curvilinea s(t)s(t)⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)origine della traiettoriaverso"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#70,70," 71Accelerazione Areolare•Velocità areolare•Accelerazione areolare   costante in direzione à il moto si svolge su un piano   costante à                    MOTO CENTRALE à                    MOTO RETTILINEOClassiﬁcazione dei moti"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#71,71,"SR in rotazione uniforme
 72
xy  x’y’O=O’Pr
'Trrωω=×=×v!!!!!
'rr=!!
()'2'COTCOTaaaaaarωωω=++=×=××v!!!!!!!!!!!Un punto fermo in S’ ha accelerazione                                  in S()Tarωω=××!!!!
''Orrr=+!!!
()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!""
!v=!v'+!vT!vT=!vO'+!ω×!r'
!v=!v'+!ω×!r!rO'=!0,!ω=costante"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#72,72,"Esercizio•Nei pressi di un incrocio a 90° tra due strade si urtano due macchine che viaggiavano rispettivamente a 40 km/h e 50 km/h. Determinare la velocità relativa dell’urto (velocità di una macchina come misurata da un osservatore solidale con l’altra) quando: –L’urto è frontale –L’urto è un tamponamento –L’urto avviene tra due macchine che viaggiavano su due strade a 90° tra loro.
 73"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#73,73,"Caso 1: tamponamento
 74
150/kmh=v
240/kmh=vx’y’z’xyz!v2=!v'2+!vO'=40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−10km/hˆι"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#74,74,"Caso 2: urto frontale
 75
150/vkmh=
240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=−40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−90km/hˆι"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#75,75,"Caso 3: urto a 90 gradi
 76
150/vkmh=
240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=40km/h ˆk!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−50ˆι+40ˆk()km/h!v'2=502+402=64km/h"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#76,76,"Esercizio•Su una giostra costituita da una piattaforma rotante si trova un bambino con in mano una pallina. La giostra ruota con una velocità angolare pari a 0.5 s-1 quando, il bambino, che si trova a 4 m dall’asse di rotazione, lancia la pallina con una velocità iniziale pari a 3 m/s. Calcolare la velocità che ha la pallina per un osservatore solidale con il terreno quando il bambino lancia la pallina: –Verso l’asse di rotazione della giostra –In direzione radiale –In orizzontale a 90° dalla direzione radiale. 77"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#77,77,"Impostazione della soluzione
 78
xy  x’y’O=O’r
vʹ!
'vvrω=+×!!!!
Caso 2:Caso 3:5(/)vms=!!rO'=!0,!ω=costante=0.5ˆk!r=!ʹr=4ˆι(m)
!v=−3ˆι+0.5⋅4ˆk∧ˆι=−3ˆι+2ˆjCaso 1:!ʹv=3ˆk(m/s)
!v=3ˆk+0.5⋅4ˆk∧ˆι=3ˆk+2ˆj!ʹv=−3ˆι(m/s)
!ʹv=3ˆj(m/s)
!v=3ˆj+0.5⋅4ˆk∧ˆι=5ˆj!v=13 (m/s)!v=13 (m/s)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#78,78,"Esercizio •Calcolare i moduli delle velocità e dell’accelerazione di un corpo fermo sulla superficie terreste a 45° di latitudine rispetto ad un SR con origine nel centro della terra e assi rivolti verso le stelle fisse.
 79"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#8,8," 9Velocità scalare media ed istantanea
Velocità scalare istantanea
Velocità scalare mediavm⎡⎣⎤⎦=v⎡⎣⎤⎦=ΔsΔt⎡⎣⎢⎤⎦⎥=L/T⎡⎣⎤⎦=LT−1⎡⎣⎤⎦→(m/s)"
data_test\rootfolder\università\FisicaGenerale\03-cinematica.pdf#9,9," 10Velocità vettoriale media ed istantanea
Velocità vettoriale media Velocità vettoriale Istantanea"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#0,0,Moti in SR NON INERZIALI CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#1,1,"LAURA FABBRI  -
Moti in SR in moto relativo: cinematica
!7Cinematica: movimento è un concetto relativo, legato al SR scelto.ES: oggetto lasciato cadere sul vagone di un treno in moto:  - Cade lungo la verticale per un osservatore sul treno,  - Compie una traiettoria parabolica per osservatore a terra.Entrambi i moti sono veri rispetto al loro SR.  Cambia la descrizione di posizione, velocità…. Un SR può essere solo più “conveniente” computazionalmente
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#10,10,"LAURA FABBRI  -
Cosa misura una bilancia  in ascensore?
!50
Ascensore fermo:Ascensore in salita con      costante. Se l’ascensore sale, un corpo fermo in esso sentirà una forza fittizia diretta come  Ascensore in discesa con      costante. Se l’ascensore scende, un corpo fermo in esso sentirà una forza fittizia diretta come  Caso limite: caduta libera→P→/u1D445/u1D463’’"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#2,2,"LAURA FABBRI  -
Moti in SR in moto relativo: dinamica
!11Due principi fondamentali:•Tutti i sistemi di riferimento inerziali sono equivalenti;•Nei SRI le leggi della fisica sono le stesse e per il secondo principioCosa succede se studio il moto in un SR NON INERZIALE?"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#3,3,"LAURA FABBRI  -
Moti in SR Non inerziali
!14
Es: treno in moto con velocità costante. Ragazzo seduto sul treno con un cubetto di ghiaccio sul vassoio. Due SR: S solidale a un osservatore a terra    S’ solidale con l’osservatore sul trenoIn S: sul cubetto non agisce nessuna forza -> si muove con la stessa velocità del SRIn S’: sul cubetto non agisce nessuna forza -> è fermo nel SR "
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#4,4,"LAURA FABBRI  -
Moti in SR Non inerziali
!19
Se treno in moto decelera improvvisamente….In S’ il cubetto vola fuori dal vassoio come se fosse sottoposto a una forza in avanti. È reale?Forza reale: attrito esercitato tra treno e binari, che ha coinvolto tutti gli oggetti solidali al treno in moto. Forza non ha agito sugli oggetti sul treno non solidali ad esso. Moto improvviso non dovuto a forze sull’oggetto ma a forze sul SR che non è più inerziale"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#5,5,"LAURA FABBRI  -
Sistemi di riferimento non inerziali
!23•Esiste una classe di sistemi di riferimento in cui NON vale il secondo principio della dinamica: sistemi di riferimento non inerziali •I SR non inerziali sono tutti quelli in moto accelerato rispetto ad un SRI. Es: veicolo in partenza, veicolo in frenata, piattaforma rotante….•Nel SR non inerziale compaiono forze dette fittizie dovute all’accelerazione del nuovo SR.•In un SR non inerziale possiamo scrivere il secondo principio a patto di usare come risultante delle forze sia quelle reali che quelle fittizie"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#6,6,"LAURA FABBRI  -
Forze fittizie
!30
‘‘‘‘‘‘‘SS’
Forza di CoriolisForza centrifuga→/u1D439′ =/u1D45A→/u1D44E′ (/u1D461)=/u1D45A(→/u1D44E−→/u1D44E/u1D450/u1D45C−→/u1D44E/u1D461)S’: sistema di riferimento mobileS: sistema di riferimento fermoUn osservatore in S’ direbbe che sul corpo agisce una forza        tale che:Corpo in S sente una forza reale 
Forza fittizia"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#7,7,"LAURA FABBRI  -
Forza centrifuga
!35
-In S (SRI) solidale alla strada agisce una forza reale: forza centripeta;-Oggetti dentro la macchina non sentono l’azione dell’attrito fra ruote e strade e tendono a mantenere il moto rettilineo per il primo principio.  -In S’ (SR NON I) solidale alla macchina: osservatore dentro la macchina si sente spinto verso l’esterno dalla forza centrifuga: •Forza fittizia; •Stesso modulo e direzione della forza centripeta ma verso oppostoForza a cui è soggetto un corpo in moto curvilineo: es macchina in curva"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#8,8,"LAURA FABBRI  -
Forza di Coriolis
!40Piattaforma che ruota con velocità angolare costante e corpo lanciato radialmente con velocità iniziale non nulla.In S SRI solidale al terreno moto della pallina rettilineo uniforme poichè non agiscono forze (primo principio).In S’ SR non I solidale alla piattaforma: pallina risente della forza fittizia di CoriolisyxˆjˆiForza a cui è soggetto un corpo in moto in un sistema di riferimento in rotazione
Traiettoria circolare verso destra rispetto osservatore in S’→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ 
→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ =−2/u1D45A(/u1D714^/u1D458)×(/u1D463^/u1D456)=−2/u1D45A/u1D714/u1D463^/u1D457"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-MotiNonIneriziali.pdf#9,9,"LAURA FABBRI  -
Forza di Coriolis
!45
•Le masse d’aria si spostano dall’alta pressione H alla bassa pressione L: vento di ciclone; •H e L separate di 1000 km; •Emisfero settentrionale: correnti d’aria tendono verso L deviando a destra; •Vortice ciclonico che ruota in senso antiorario nell’emisfero nord e in senso orario nell’emisfero sudResponsabile di molti fenomeni visibili: •Sbilanciata usura dei binari dei treni orientati secondo i meridiani: treno da nord a sud usura maggiormente il binario di destra; •Moto dei gravi su lunghe distanze (missili…); •Circolazione dei venti→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′ "
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#0,0,"Forza: dinamometro•Definizione operativa della forza. •Dinamometro: strumento graduato contente una molla ideale, elastica, deformabile.
!1
0
01
02
03Calibrazione del dinamometro tramite peso campione: unità kg-forza"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#1,1,"Modello del filo inestensibile•Filo ideale senza massa, in grado di trasportare una forza (TENSIONE) senza allungarsi.
!2
01
01
01
01
Il filo è in grado di trasportare una tensione.  Il dinamometro si allinea al filo.Ciò che misura un dinamometro è un vettore: -Direzione (del filo) -Verso (il filo tira) -Intensità (scala graduata)La forza è un vettore"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#10,10,"Esercizio 2•Un acrobata, stando nel punto di mezzo di una fune lunga 18 m, esercita una forza di 700 N e fa abbassare la fune di 1.5 m rispetto alle estremità. Determinare la tensione T della fune.
!11
P!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#11,11,"Esercizio 3•Una sfera di peso 4 kg-f si ferma tra due piani inclinati di 30° e 60°. Determinare le reazioni vincolari delle superfici.
!12
P!
P!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#2,2,"03
Come funziona un dinamometro?•Il dinamometro misura una forza       esterna generando una forza         tale che
!3
03
F!F−!dinFkl=−Δ!!""""Legge di HookeestF!dinF!
0estdinFF+=!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#3,3,"Natura vettoriale delle forze
!4
02
03
021F!2F!3F!23FF+!!1230FFF++=!!!!In condizioni statiche! (Macchina di Atwood)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#4,4,"Quiete, equilibrio e statica
!5Equilibrio: se un sistema (insieme di punti o di corpi) inizialmente quiete in un dato SdR, pur soggetto a forze rimane in quiete, allora esso si trova in uno stato di equilibrio.Quiete: un punto (o un corpo) è in quiete in un dato SdR, se il punto (o ogni punto del corpo) ha una velocità nulla in ogni istante di tempo (è e rimane fermo). Assenza di velocità!
Statica: studio delle forze nei sistemi in stato di equilibrioEquilibrio stabile: piccole variazioni nel sistema portano a piccoli spostamenti dalla posizione di equilibrio Equilibrio instabile: piccole variazioni nel sistema portano a grandi spostamenti
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#5,5,"Statica del punto materiale•Risultato sperimentale: il punto è in quiete se:
!61F!2F!
3F!1234RFFFF=+++!!!!!
4F!
12340RFFFF=+++=!!!!!!Risultante delle forze applicate al puntoCondizione necessaria per l’equilibrio di un punto materiale è che si annulli la risultante        di tutte le forze ad esso applicate.R!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#6,6,"Studio statico delle forzeFORZA PESO
!7
01!P!FdinIdea: applicare ad un corpo una forza tramite il dinamometro, adattando verso, direzione e modulo fino a raggiungere l’equilibrio!Fdin+ EQ ⇒!R=0!R=!Fdin+ ?
Ad ogni punto materiale posto in prossimità della superficie terrestre risulta applicata una forza diretta lungo la verticale, verso il basso, con intensità dipendente dal corpo materiale.!P=−!Fdin"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#7,7,"REAZIONE VINCOLARE
!8
!P!RV!P+ EQ ⇒!R=!P+!RV!RV=−!P
!F
Quando la superficie di un corpo materiale C, giungendo a contatto con la superficie di un corpo materiale V (vincolo) esercita su tale superficie una forza perpendicolare F, determina una deformazione di V che esercita a sua volta su C una forza RV uguale e contraria ad F   㱺  RV: normale alla superficie, uscente e di modulo dipendente dalla forza applicata F  CV!RV"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#8,8,"!9Un vincolo impedisce alcuni movimenti del corpo considerato e ne consente altri (es.: rotaia treno, cardine porta, piano su cui è appoggiato un oggetto, ecc.). Per impedire i movimenti vietati dei corpi, i vincoli debbono esercitare sui corpi delle forze, dette forze vincolari o reazioni vincolari.Le forze vincolari sono a priori sconosciute, in quanto debbono adeguarsi alle circostanze per neutralizzare le forze attive che potrebbero causare movimenti vietati.
Vincolo"
data_test\rootfolder\università\FisicaGenerale\04-dinamica-integrazione.pdf#9,9,"Vincoli ideali o lisci•Vincolo ideale o liscio: vincoli che non offrono resistenza apprezzabile quando le forze tendono a produrre degli spostamenti tangenziali rispetto alla loro superficie
!10
PF!VR!
PF!VR!•In caso contrario, se c’è resistenza ai movimenti tangenziali, parleremo di vincolo scabro (forze d’attrito)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#0,0,DINAMICA CdS Ingegneria InformaticaA.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#1,1,"Concetto di forza
 2Grandezza ﬁsica vettoriale (intensità, direzione, verso e punto di applicazione): vettore applicatoLe forze possono produrre variazioni dello stato di moto degli oggetti su cui agisconoLe forze possono deformare i corpi su cui agisconoLe forze possono compensarsi, determinando situazioni di equilibrioLe forze si presentano sempre in coppia: derivano sempre da interazioni tre i corpi, che esercitano forze l’uno sull’altro"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#10,10,"Formulazione esplicita del 2° principioNewton: “La forza è uguale alla massa per l’accelerazione."" 
 11
In un sistema di riferimento inerziale, la forza complessiva (totale, risultante) che agisce su un corpo materiale di massa m è tale che:Fma=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#11,11,"Unità di misura della forza
 122o Principio Unità di misura della massa nel sistema internazionale: chilogrammo (kg) Prototipo: cilindro di platino-iridio c/o Bureau International des Poids et Mèsures a Sèvres dal 22/5/2019 nuova definizione basata sulla costante di PlankUnità di misura della forza nel sistema internazionale: Newton (N) Corrisponde alla forza che, agendo su una massa di 1 kg le imprime un’accelerazione di 1 m/s2Unità di misura della forza nel sistema tecnico: chilogrammo-forza (kgf) È il peso del cilindro di cui sopra,nei luoghi in cui g=9,80665 m/s2, detto valore “standard”Per convenzione
Derivata per definizione
1kgf9.80665N;1N0.101972kgf==Per convenzione
!F=m!a
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#12,12,"Forza peso: misura della massa inerzialeN corpi con pesi
 13
a!!P29,8 m/sag==!12,,,NPPP!!!…12Naaag====!!!…12,,,Naaa!!!…cadono con accelerazionig=!Pmg=!!Osservazione sperimentale valida (con opportune approssimazioni) in ogni punto della Terra.Approssimazioni: ignoro gli attriti, la forma non sferica della terra, considero di essere in un SRI"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#13,13,"Misura della massa inerziale
 14Presa una massa campione      ho anche un peso campionecmccPmg=!!
Pmg=!!cP!cRPλ=!!ccPRPPλ==!!!!cccPmgmmgmPλ===!!!!Condizione di equilibrio:cPRPλ==!!!
ccPmmP=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#14,14,"Principi fondamentali•Il secondo principio NON è una definizione di forza
 15•SdR: Inerziale•La forza è ciò che indica il dinamometro•La massa è una proprietà dei corpi•L’accelerazione è una caratteristica cinematicaFma=!!•In ogni SRI vale:Fma=!!
''SSaa=!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#15,15,"Indipendenza delle azioni simultanee
 16
TTFma=!!11Fma=!!22Fma=!!12FF=+=!!()12Tmaama=+=!!!2a!1a!
Ogni forza produce un effetto indipendentemente dalla presenza di altre forze.L’effetto complessivo è dato dalla risultante di tutte le forze applicate."
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#16,16,"Relazione tra moto e cause•Tutti i problemi di determinazione del moto di un corpo a partire dalle forze che agiscono sono problemi inversi di cinematica
 17Fma=!!Fam=!!nototrovare (),  ()atrt=v!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#17,17,"Moto circolare uniforme
nF!Rappresentazione intrinseca della forza
Moto rettilineo
 18
ˆtuˆnuF!tF!
ˆˆtnttnnFFFfufu=+=+!!!ˆˆ()ttnnFmamauau==+!!2forza tangenteforza centripetattnnfmafmamR===v00tnffR≠=→=+∞200/tnnffRmf=≠→=vˆˆttnnaauau=+!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#18,18,"Moto circolare uniforme
 19
F!r!v!drrdtω==×v!!!!costanterRωω===v!!!22costanteaRRωω====vv!!!??2nnFmafmamRω===!!
v!T!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#19,19,"Caduta dei graviGrave: punto materiale o oggetto in moto a causa del suo peso
 20
z
hPmg=!!ˆkProblema: studiare la caduta di un grave di massa m che parte da fermo da una quota hˆˆPmgmgkmzk==−=!!""""zg→=−!!0()(0)()tztzgdtʹ→=+−∫!!()ztgt→=−!200()(0)(')'''2ttgztzztdthgtdtht→=+=−=−∫∫!Legge oraria:2()2gztht=−Velocità:()ztgt=−!Tempo di caduta:2()0hhhzttg=→=vmax=v(th)=2gh"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#2,2,"Concetto di forza
 3Forze di contattomacroscopicamente sono associate ad un contatto tra corpi interagenti (es. spinta di un oggetto, forze elastiche)Forze a distanzaLe interazioni avvengono senza contatto (forza peso, forze elettriche e magnetiche)"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#20,20,"Tutti i corpi cadono nello stesso modo
 21Tempo di caduta:2()0hhhzttg=→=
11Pmg=!!22Pmg=!!33Pmg=!!1ag=!!2ag=!!3ag=!!vmax=v(th)=2gh"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#21,21,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
 22()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#22,22,"Piano Inclinato liscio
 23
P!
VR!tP!nP!sintPPα=!
αcosnPPα=!hcosVnNRPPα===!!
 23|⃗PT|=Psinα=mgsinα=maa=gsinαcostante:moto unif. accel.Lunghezza del pianoL=hsinαs(t)=s0+vot+12at2L=hsinα=12gsinαt2v(t)=v0+att=2Lgsinα=2hgsin2αv(t)=gsinα2hgsin2α=2ghs0=0v0=0"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#23,23,"Forza elastica / Legge di Hooke•k costante elastica della molla. [k]=[MT-2]
 24
03
0
XF!
F!0F=!!ˆ()Ffxι=!(0)0f=0,()0xfx><0,()0xfx<>ˆFkxι=−!()fxx
Fkr=−!!0()Fkrr=−−!!!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#24,24,"Oscillatore armonico unidimensionale
 25
0
mˆFkxι=−!ˆaxι=!""""Fmakxmx=→−=!!""""0mxkx→+=!!0kxxm+=!!2pongo  0kmω=>20xxω+=!!
x+l-l
0(0)cos()xlφ=
0()cos()xtltωφ=+kmω=
000arctanxφω=−v()0220lxω=+v22mTkππω==SRIEquazione oraria "
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#25,25,"Regime delle piccole oscillazioni•Osservazione: ogni sistema in prossimità di un punto di equilibrio stabile si comporta come un oscillatore armonico
 26ˆ()Ffxι=!()fxx
()0fx=Punti di equilibrioAB()0Bfxʹ>xB punto instabile
()0Afxʹ<xA punto stabile
()2()()()()()AAAAfxfxfxxxOxxʹ+−+−!()()AAxxfxkxx→⎯⎯⎯→−−Moto oscillatorio attorno al punto di equilibrio stabile xA2():;2()AAkfxmTmmfxωπʹ−===ʹ−"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#26,26,"Pendolo sempliceGalileo: osservazione del moto del lampadario nel Duomo di Pisa
 271.Ampiezza max a DX = SX2.Il periodo del pendolo (T) è  indipendente dall’ampiezza massima3.Il periodo non dipende dalla massa ma solo dalla lunghezza del ﬁlo
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#27,27,"Pendolo semplice
 28
Metodo: 1.“Inquadrare” il problema 2.Scrivere la F = ma  3.Individuare il SdR migliore  4.Scrivere le equazioni parametriche 5.Integrare 6.Calcolare le costanti arbitrarie
0v!Ol
C
θslθ=
gmP!!=VR!RgmF!!!+=
ˆtuˆnu21ˆˆtnasusuρ=+!""""""
0(0)(0)0(0)(0)lslslρθθ=====v!!ˆˆsinttmsumguθ=−!!sin0glθθ+=!!()2ˆˆcosnVnsmumgRulθ=−+!2cosVmlmgRθθ+=!
am!=
Piccole oscillazioni (sinθ ≅ θ )0glθθ+=!!
()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#28,28,"Pendolo semplice II
 292cosVRmlmgθθ=+!()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v()2221122()cos,cos11sintttθαωωθθαω=−=−!""()()222222223122cos1sin1sinVRmltmgtmgtαωωαωααω=+−=+−Durante il moto, la reazione vincolare cambia. "
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#29,29,"Nota storica•Le oscillazioni di un pendolo hanno costituito un primo sistema meccanico per misurare il tempo
 30Esercizio pratico per casa:Costruire un pendolo e misurare l’accelerazione di gravitàElementi: punto ﬁsso, ﬁlo, massa, cronometro, metro
L22/TLgππω==
224LgTπ→=22/TLgππω==
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#3,3,"Forze fondamentali
 4
La maggior parte delle forze sono riconducibili alla forza elettromagnetica •Forze di contatto (attrito, viscosità, reazioni vincolari) •Forze elastiche •Forze chimiche (molecolari e biologiche) Ad oggi sappiamo che esistono 4 forze fondamentali della natura"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#30,30,"Forza di attrito statico
 31
P!VR!
03
F!Se il corpo NON si sposta nonostante la forza orizzontale introduciamo una nuova forza di attrito: l’attrito staticoASF!Caratteristiche: E’ una forza di contatto; di entità NON nota a priori.E’ una caratteristica delle superﬁci (secche, non lubriﬁcate) Ma non dipende all’area di contatto !Dipende da tutte le forze agenti sui corpi.Quando esiste in condizioni statiche, annulla sempre la risultante.Per ogni situazione esiste un valore massimo della forza. 
Vincolo ruvido!vincoli o superﬁciNON ideali"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#31,31,"Forza di attrito statico
 32
P!VR!
03
F!ASF!0ASFF+=!!!maxmax:ASASASFFF∃≤!maxASSFNµ=N: forza perpendicolare alle superfici      forza di carico µS: coefficiente di attrito staticoVNRP==!!Tipicamente:0.011Sµ<<"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#32,32,"Piano inclinato ruvidoProblema: sapendo che                , qual è il valore massimo di α per cui il corpo NON si muove?
 33
P!
VR!tP!nP!sintPPα=!
αcosnPPα=!hSe il corpo non si muove nonostante la presenzadi una forza non bilanciata                     allora esiste una forza di attrito staticosintPPα=!ASF!0tASPF+=!!!cosVnNRPPα===!!maxcosASSSFNPµµα==maxtASASPFF==!!maxsincosASASSPFFPαµα→===!sintancosSαµαα→==0,5Sµ=arctan0,463646...0,46Sradαµα→==→=26,565...27α→==°
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#33,33,"Importanza dell’attrito statico
 34
ASF!,av!!
PF!ASF!
ASF!VR!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#34,34,"Importanza dell’attrito statico
(/)(/)1SSrocciametallogommaasfaltoµµ≈≪Indipendente dall’area di contattoASF!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#35,35,"EsercizioUn mattone è appoggiato su una scanalatura rettilinea ruvida inclinata di un angolo α=35° rispetto ad un piano orizzontale e raccordato nel punto B con un pavimento orizzontale. Le due superfici hanno lo stesso coefficiente di attrito cinetico µc = 0,4. All’istante t = 0 il mattone viene lasciato in quiete da una altezza h = 3 m (punto A). Studiare il moto del mattone calcolando la velocità massima e la lunghezza totale del percorso.
 36
αhABC
max?vLABBC=+
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#36,36,"Esercizio – Passo 1
 37
αhAB
P!
VR!tP!nP!ADF!ˆιa!iADtFFPma=+=∑!!!!ˆsintPmgαι=!ˆˆcosADCCFNmgµιµαι=−=−!ˆaxι=!""""(sincos)ADtCFPmamxmgmgαµα+=→→=−!!!""""2(sincos)2,41 m/sCxgaαµα=−==!!()(0)(')'xtxxtdtat=+=∫!!!!2()(0)(')'2txtxxtdta=+=∫!x0,/sinABxxhα==
222:()2,08 s 2sinsinBBBBthxhtxtataaαα==→===max2:()25,02 m/sBBBBxxtataaxa====v!/sin5,23 mBxhα=="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#37,37,"Esercizio – Passo 2
Distanza percorsa:  38C
ˆιADF!
P!VR!v!BiADtFFPma=+=∑!!!!0tP=!!ˆˆADCCFNmgµιµι=−=−!ADtCFPmamxmgµ+=→→=−!!!""""23,92 m/sCxgaµ=−=−=−!!()(0)(')'Bxtxxtdtat=+=−∫v!!!!2()(0)(')'2Btxtxxtdtta=+=−∫v!()0Cxt=→!/1,28 sCBta==v8,45 mBCDxx=+=xxC=vBtC−atC22=vB22a=3,22 m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#38,38,"Esercizio•  Una pallina di massa M=0,2 kg è ferma tra una superficie verticale ed un piano inclinato di un angolo α=15°, come mostrato in figura. Determinare le reazioni vincolari della superficie verticale e del piano inclinato.
 39
α2VR!1VR!1tan0,52550,526VRmgNNα===…2/cos2,03..2,03VRmgNNα==="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#39,39,"Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             
Esercizio
 40()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#4,4,"Galileo Galilei (1564-1642)Qual è il moto di un corpo non soggetto ad alcuna forza?
 5
!P!RV!v=costSe riusciamo ad eliminare tutti gli attriti PRINCIPIO DI INERZIA"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#40,40,"EsercizioUn proiettile di massa M viene sparato orizzontalmente da un cannone fermo posto su una altura che si eleva di h=50 m rispetto alla pianura circostante. Determinare: 1)il modulo v  della velocità con cui si deve sparare il proiettile affinché colpisca un bersaglio nella pianura e che dista orizzontalmente dal cannone di D=250 m; 2)l’angolo con cui il proiettile colpisce il bersaglio;  3)la velocità scalare del proiettile quando colpisce il bersaglio.
 41vf=D2g2h+2gh=84m/stanα=vyvx=2hD=0,4⇒α=21,8°v0=Dg2h=78,3m/s"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#41,41,"EsercizioUna molla ideale, di costante elastica k, è sospesa in verticale tramite un aggancio in alto. Ad un certo istante (t=0) si applica una massa m all’altro estremo della molla, che viene quindi lasciata libera. Trovare il moto del punto nella direzione verticale. In presenza di un piccolo attrito, dove si fermerà il punto?
 42
xzBOPbz
eF!
PF!"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#42,42,"EsercizioIl sistema meccanico in ﬁgura è costituito da tre corpi uguali di massa m, un ﬁlo inestensibile ed una superﬁcie ruvida con coefﬁciente di attrito statico 0.6 e coefﬁciente di attrito cinetico 0.4. Determinare: 1) se il sistema è in condizioni di staticità; 2) la tensione nel ﬁlo; 3) cosa succede se il corpo 3 è eliminato dal sistema.
 43
3
2
1
ˆTmgι=!ˆPmgj=−!ASF!max2ASASSSFFNmgµµ<==!Statica ?0ASTF+=!!!maxASASTFF=<!!?21.2cmgmgmgµ→<=1. Si, il sistema è in equilibrio statico. max1.2ASASFmgFmg=<=!ˆTmgι=!3. maxASASTFF=<!!?0.6cmgmgmgµ→<=No: il sistema non è statico e si muove"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#5,5,"Primo Principio della Dinamica
➡criterio cinematico per stabilire quando su di un punto materiale non agiscono forze. 
 6
Se in un dato sistema di riferimento la risultante delle forze applicate ad un punto materiale è nulla allora il punto materiale o rimane in quiete o si muove di moto rettilineo uniforme.Il moto è relativo:Si muove rispetto a cosa? 
Sistema di riferimento inerziale 
Formulazione moderna Esiste almeno un sistema di riferimento, detto “inerziale” (SRI), rispetto al quale un qualunque punto materiale che sia sufficientemente lontano da tutti gli altri corpi, o rimane in quiete o si muove di moto rettilineo uniforme.“Principia”  di Newton:
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#6,6,"Classe di Sistemi di Riferimento Inerziali
 7Sia dato un punto su cui non agiscono forze in un SRI   S:  il punto si muove di moto rettilineo uniforme in S:      = costante
xyzx’y’z’
''aaSS=!!P(t)O’Ov!v!SdR S’ in moto rettilineo uniforme
S’ è un sistema di riferimento inerzialeTrasformazioni di Galileo!vO'=costante,!ω=!0!vO'x(t)=x'(t)+vO'xty(t)=y'(t)+vO'ytz(t)=z'(t)+vO'zt!v(t)=!v'(t)+!vO'vx(t)=vx'(t)+vO'xvy(t)=vy'(t)+vO'yvz(t)=vz'(t)+vO'z⎧⎨⎪⎩⎪!v'=!v−!vO'=costante"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#7,7,"Esiste un SRI privilegiato?S ed S’ sono due SRI: come posso distinguerli sperimentalmente operando solo all’interno di un SRI ?
 8
''aaSS=!!
R: No, non esiste un SRI privilegiato
Principio di relatività galileiano Tutte le leggi della fisica si scrivono nello stesso modo in ogni sistema di riferimento inerziale.
"
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#8,8,"Approssimazioni di SRI1.Sistema solidale alla terra (SR principale in statica) 2.Sistema con origine nel centro della terra e assi rivolti verso le “stelle fisse”  3.Sistema con origine nel centro del Sole e assi rivolti verso le stelle fisse 4.Sistema con origine nel centro della nostra galassia e assi rivolti verso le galassie più lontane  9()'2oCOTaarraaaaωωωωʹʹʹʹʹ=+×+×+××+=++v!!!!!!!!!!!!!""22221 d,6370 km,0,035 m/sTTRarRTπω⎛⎞=====⎜⎟⎝⎠622356 d1 y,15010 km,0,0059 m/sTTRarω=====i22200 Ma,26000 al,0,00000000025 m/sTTRarω====
29.8 m/sg="
data_test\rootfolder\università\FisicaGenerale\04-dinamica.pdf#9,9,"Principi fondamentali
 10
2o Principio Un qualunque punto materiale che sia sottoposto ad una o più forze ha un’accelerazione vettorialmente proporzionale alla risultante di tali forze.
amF!!=CausaEffettoRisulta essere: -Positiva -Indipendente da posizione e velocità -Proprietà additiva dei corpi12Tmmm=+Massa inerziale "
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#0,0,"LAVORO ed ENERGIA CdS Ingegneria Informatica A.A. 2019/20
1"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#1,1,Lavoro ed Energia: definizioni intuitive•Lavoro: caratteristica di una forza di operare uno spostamento •L’energia è la capacità di produrre lavoro •Il lavoro è il processo attraverso il quale una certa quantità di energia si trasferisce da un corpo a un altro. •Ingredienti per una definizione più rigorosa di Lavoro: forza e movimento
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#10,10,"Lavoro di una forza elastica
11
Esempio: lavoro compiuto da una molla compressa da l1 fino all’ espansione l2δℒ=⃗F⋅d⃗l=(−kx̂ı)⋅(̂ıdx)=−kxdx(̂ı⋅̂ı)=−kxdxℒ1,2=∫x2x1⃗F⋅d⃗l=−k∫x2x1xdx−k[x22]x2x1=−k2x22+k2x21=−k2(l2−l0)2+k2(l1−l0)2ℒ1,2=−k2(x22−x21)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#11,11,"Lavoro della forza peso
12
SARA VALENTINETTI  -
Stessa conclusione se al posto del piano inclinato abbiamo un profilo curvo.Lavoro infinitesimoLavoro totale
𝑧1𝑧2 ℒ1,2=mghh = differenza di quota a cui si porta il punto
𝑑𝑙𝑧1𝑧2Esempio: punto materiale di massa m scivola su un piano liscio inclinato di un angolo  da un punto P1 a un punto P2 a differenza di quota hδℒ=⃗F⋅d⃗l=(−mĝk)⋅(̂ıdx+̂kdz)==−mg(̂k⋅̂ı)−mg(̂k⋅̂k)=−mgdzℒ1,2=∫P2P1⃗F⋅d⃗l=−mg∫z2z1dz=−mg(z2−z1)=mgh>0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#12,12,"Proprietà additiva dei lavori
13Punto materiale soggetto a N forze, equivale a un punto soggetto alla risultante delle forzeLavoro infinitesimo di ciascuna forza:Lavoro infinitesimo totale:Date n forze Fi , applicate allo stesso punto P, che si muove lungo una propria curva  dal punto A al punto B,  il lavoro complessivo è dato da….ℓLo spostamento è lo stesso per ogni forza perché agiscono tutte sulla stessa particella che compie un tratto di traiettoria.
Somma dei lavori delle singole forze.δℒ=⃗F⋅d⃗lδℒtot=δℒ1+δℒ2+...=⃗F1⋅d⃗l+⃗F2⋅d⃗l+...=(⃗F1+⃗F2+...)⋅d⃗l=(∑i⃗Fi)⋅d⃗l=⃗R⋅d⃗lℒℓtot=∫BAℓ⃗R⋅d⃗l=∫BAℓ(∑i⃗Fi)⋅d⃗l=∫BAℓ(∑i⃗Fi⋅d⃗l)=∑i∫BAℓ⃗Fi⋅d⃗l=∑iℒℓi"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#13,13,"Potenza di una forzaDef: capacità di produrre lavoro per unità di tempo
14•Per un punto materiale:Nuova definizione di lavoroLavoro compiuto da una forza per unità di tempo durante un intervallo di tempo infinitesimo P=δℒdtP=δℒdt=⃗F⋅d⃗ldt=⃗F⋅d⃗ldt=⃗F⋅⃗vP=⃗F⋅⃗vδℒ=Pdt⟹ℒ=∫Pdt"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#14,14,"Analisi dimensionale
15LavoroL⎡⎣⎤⎦=F⋅ds⎡⎣⎤⎦=N⋅m⎡⎣⎤⎦=kg⋅ms2⋅m⎡⎣⎢⎤⎦⎥=MLT−2L⎡⎣⎤⎦⇒L⎡⎣⎤⎦=ML2T−2⎡⎣⎤⎦Unitá di misura: SI-MKS  Joule(J)=N⋅mPotenzaP⎡⎣⎤⎦=LΔt⎡⎣⎢⎤⎦⎥=F⋅dsΔt⎡⎣⎢⎤⎦⎥=N⋅ms⎡⎣⎢⎤⎦⎥=kg⋅ms2⋅m⋅1s⎡⎣⎢⎤⎦⎥=MLT−2LT−1⎡⎣⎤⎦⇒P⎡⎣⎤⎦=ML2T−3⎡⎣⎤⎦Unitá di misura: SI-MKS  Watt(W)=Joule/s"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#15,15,"Esercizio
16Determinare la potenza istantanea sviluppata durante la caduta su un piano inclinato di un angolo  alto h da un punto A in cima al piano ad un punto B in fondo al piano da un punto materiale di massa m.α"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#16,16,"Teorema delle Forze Vive
17
Es: Corpo in moto con velocità  su piano orizzontale liscio contro molla. Corpo comprime molla perdendo velocità. Molla esercita forza tale che  e  opposti e       v⃗Fdxℒ<0•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro."
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#17,17,"Teorema delle Forze Vive
18•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.
Alla fine del moto il corpo è fermo e molla compressa esercita forza che tende a ridistenderla, in grado di rimettere in moto il corpo. In questo caso  e  hanno stesso verso e     ⃗Fdxℒ>0Relazione fra velocità e lavoroSperimentalmente  ⃗vfinale=−⃗viniziale"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#18,18,"Teorema delle Forze Vive
19Descrive il lavoro compiuto da un sistema di forze qualunque (attive, vincolari, interne, esterne, di interazione o apparenti), su un sistema meccanico qualunque (puntiforme, esteso, rigido, non rigido, vincolato, ecc.). Teorema delle forze vive per il punto materiale:Lavoro compiuto da tutte le forze per spostare corpo da A a B lungo un tratto di traiettoriaSostituisco la definizione di d⃗lProprietà delle derivate principio: risultante di tutte le forzeℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅d⃗ld⃗l=⃗vdt⟹ℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdtℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdt=∫BAm12dv2dtdt=12m∫BAdv2=12m[v2]BA=12mv2B−12mv2A"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#19,19,"Teorema delle Forze Vive
20Il lavoro compiuto dalla risultante delle forze che agiscono su un sistema meccanico qualunque, nel passaggio da una configurazione A ad un’altra B, è uguale alla corrispondente variazione dell’energia cinetica di tale sistema.Se  forza ha accelerato il corpo compiendo un lavoro positivoℒ>0⟹vB>vA→Se forza ha decelerato il corpo compiendo un lavoro negativoℒ<0⟹vB<vA→Energia Cinetica: 1. Ha le dimensioni del lavoro       2. Non è  mai negativa  (T>=0)[𝑇]=[12𝑚𝑣2]=[𝑀𝐿2𝑇−2]→JouleT=12mv2ℒA,B=12mv2B−12mv2A=TB−TA"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#2,2,"Lavoro ed Energia: MacchineUna macchina è un dispositivo vincolato capace di spostare il punto di applicazione di una forza, chiamata “resistente”, sfruttando un’altra forza chiamata “motrice”.
Una macchina “vantaggiosa” sposta il punto di applicazione di una forza resistente utilizzando una forza motrice di modulo più piccolo.carrucolapiano inclinatoleva"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#20,20,"Energia Potenziale
21
Lavoro sul corpo (teorema delle forze vive):Corpo in moto su un piano orizzontale liscio contro una molla ideale •velocità iniziale del carrello v0,  •velocità finale nulla poiché comprime una molla che esercita una forza opposta allo spostamento del corpo provocandone l’arresto.ℒcorpo=Tfin−Tin=12mv2fin−12mv2in=0−12mv20<0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#21,21,"Energia Potenziale
22•Molla inizialmente in quiete si comprime per effetto di una forza premente.  •Chi produce la forza compressiva è il carrello e l’entità della compressione è una misura della forza agente.  •Forza reagente della molla è uguale e opposta alla forza premente.Lavoro sulla molla (teorema delle forze vive):   
Dal punto di vista della molla…
ℒmolla=Tfin−Tin=12mv2fin−12mv2in=12mv20−0=−ℒcorpo>0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#22,22,"Energia Potenziale
23•Corpo in ragione della velocità compie un lavoro positivo sulla molla comprimendola; •Energia di un corpo: possibilità di un corpo di compiere un lavoro positivo; •Energia del carrello in moto si trasferisce gradualmente alla molla; •Quando il carrello si ferma, tutta la sua energia cinetica iniziale è trasferita alla molla compiendo un lavoro positivo su di essa; •Molla immagazzina l‘energia del corpo comprimendosi; •Molla poi rilascia gradualmente l’energia immagazzinata distendensosi e imprimendo al corpo una velocità uguale e contraria: restituisce energia cinetica al carrello; •energia totale immagazzinata dalla molla ridiventa interamente energia cinetica"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#23,23,"Energia Potenziale
24
0Lavoro forza elastica:Molla compressa di una certa quantità a ad un certo tempo t>0Teorema forze vive:Uguagliando:Energia iniziale: cineticaEnergia totale istantanea durante la compressioneLavoro che sarebbe in grado di fornire la molla ridistendendosi -> misura dell’energia propria immagazzinata dalla molla: Energia potenzialeLa somma dell’energia cinetica e di quella potenziale si conserva IN QUESTO moto.ℒel=Tfin−Tin=12mv2−12mv20ℒel=∫finin⃗Fel⋅d⃗l=∫finin(−kx̂ı)⋅(̂ıdx)=∫finin−kxdx=−k[x22]finin=−kx2212mv2−12mv20=−kx22⟹12mv2+kx22=12mv20kx22"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#24,24,"Esercizio
25Un blocco di ghiaccio è in moto su una salita inclinata di  Sapendo che all’inizio la sua velocità è pari a v = 9 m/s e che il coefficiente di attrito dinamico è pari a , di quanto si sposta lungo il piano inclinato il blocco di ghiaccio prima di fermarsi?α=6∘μc=0.07"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#25,25,"Esercizio
26Un blocco P di massa m = 3 kg si muove di moto rettilineo su un piano orizzontale scabro nella direzione dell’asse di una molla non deformata, di cui va a colpire uno degli estremi, mentre l’altro è bloccato a un supporto verticale fisso. La molla, di costante elastica k = 300 N/m, viene compressa di  Sapendo che il coefficiente di attrito dinamico fra P e il piano è , determinare: 1) I lavori compiuti durante tale compressione dalla forza elastica e dalla forza di attrito; 2) Il modulo della velocità di P nel momento in cui colpisce la molla. δ=8cmμc=0.25"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#26,26,"Esercizio
27Un cubetto P di massa m scivola lungo il segmento AB disposto lungo un piano inclinato di un angolo  rispetto alla direzione orizzontale. Il coefficiente di attrito dinamico passa dal valore massimo di ½ alla sommità A al valore 0 alla base B secondo una legge del tipo  dove e k sono costanti positive e s è la distanza da A di un generico punto di AB. Sapendo che  e che P è partito da fermo in A, calcolare il modulo v della sua velocità all’istante in cui arriva in B in termini di  e della variazione di quota h fra A e B.Ah𝛼B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#27,27,"Alcuni concetti matematici
28•Derivate parziali: primo e secondo ordine, miste… •Differenziali; •Campi: scalari, vettoriali…"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#28,28,"Derivate parziali
29Se una funzione esiste per ogni valore della variabile nel dominio, derivate parziali al primo ordine:Se le derivate parziale al primo ordine esistono per ogni valore della variabile nel dominio, derivate parziali al secondo ordine:
Derivate parziali miste (l’ordine non influenza)𝜕𝑧2Es: ∂f(x,y,z)∂xx0,y0,z0=limΔx→0f(x0+Δx,y0,z0)Δx∂f(x,y,z)∂yx0,y0,z0=limΔy→0f(x0,y0+Δy,z0)Δy∂f(x,y,z)∂zx0,y0,z0=limΔy→0f(x0,y0,z0+Δz)Δz∂2f(x,y,z)∂x∂y,∂2f(x,y,z)∂y∂z,∂2f(x,y,z)∂x∂zf(x,y,z)=x3−y2+3z"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#29,29,"DifferenzialiSia  una funzione a 3 variabili. Quanto varia il valore della funzione se ci spostiamo da un punto  a un punto infinitamente vicino  ?f(x0+dx,y0+dy,z0+dz)=f(x0,y0,z0)+∂f∂xP0dx+∂f∂yP0dy+∂f∂zP0dzDifferenzialedF=f(x0+dx,y0+dy,z0+dz)−f(x0,y0,z0)=∂f∂xdx+∂f∂ydy+∂f∂zdzPiù ordini successivi
30"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#3,3,"Definizione di lavoro infinitesimo
4
P1P2
xyzOLavoro infinitesimo compiuto da  durante uno spostamento infinitesimo   la quantità scalare:⃗Fd⃗lPer definire lavoro infinitesimo compiuto da una forza:In un intervallo di tempo   i, punto si sposta da P1 a P2 :    ΔtΔ⃗r=⃗r2−⃗r1-Regione di spazio in cui agisce  -Punto P si muove lungo linea curva   ⃗FℓSe  piccolo,             tangente ΔtΔ⃗r→d⃗l=̂utdlLavoro infinitesimo  perché non è un differenziale esatto (in generale non dipende solo dagli estremi in cui si integra).δLδℒ=⃗F⋅d⃗lΔ⃗rℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#30,30,"CampiCampo scalare: una grandezza scalare funzione delle coordinate spaziali U(x,y,z) definita ovunque dentro una certa regione di spazio. Superficie di livello: luogo geometrico dei punti dove la funzione scalare assume un valore costante prefissato  U(x,y,z) = costante -> infinite superficiCampo vettoriale: un vettore applicato funzione delle coordinate spaziali               definito ovunque dentro una certa regione di spazioLinee di forza: una o più linee sempre tangenti al vettore del campo. Le linee di forza sono più fitte dove il modulo del vettore è maggiore.31"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#31,31,"Campi di forze conservativi
32In generale il lavoro di una forza per spostare un punto materiale su un tratto AB di traiettoria dipende dalla traiettoriayzx0AB..12Per il teorema delle forze vive:Le velocità agli estremi sono diverse a seconda che si percorra la curva 1 o la 2.ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗l⟹ℒ1(A,B)≠ℒ2(A,B)ℒ1(A,B)=12m(vB)2−12m(vA)2ℒ2(A,B)=12m(v′ B)2−12m(v′ A)2⟹vB≠v′ B⟹vA≠v′ A"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#32,32,"Campi di forze conservativi
33Campo di forza conservativo: forza posizionale che, spostando il suo punto di applicazione da A a B, punti qualunque del dominio di esistenza, compie un lavoro che è indipendente dalla particolare traiettoria seguita, ma dipendente soltanto dagli estremi A e B. 
ℒA,B=∫BA⃗F⋅d⃗lℒ1(A,B)=ℒ2(A,B)=ℒ3(A,B)=...=ℒA,B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#33,33,"Campi di forze conservativi: 1a proprietà
34
AB12Campo conservativo:
1a Proprietà
Lavoro su una curva chiusa di una forza conservativa (circuitazione) è nulloCondizione necessaria (se il campo è conservative allora la circuitazione è nulla) e sufficiente (se la circuitazione è nulla allora il campo è conservativo)ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗lℒA,B=∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹∫BA1⃗F⋅d⃗l−∫BA2⃗F⋅d⃗l=0∫BA1⃗F⋅d⃗l+∫AB2⃗F⋅d⃗l=0⟹ℒ=∮⃗F⋅d⃗l
ℒ=∮⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#34,34,"Campi di forze conservativi: 2a proprietà 
35 funzione scalare definita in ogni punto dello spazio legata al valore della forza in quell punto. Fissata a meno di una costante additiva arbitraria: se  soddisfa la relazione anche  lo faU=U(x,y,z)U(x,y,z)U′ =U(x,y,z)+kDifferenziale esatto di una funzione scalare  è un campo scalare Analisi: integrale fra A e B di un differenziale esatto è la differenza della primitiva fra B e A.Scelgo arbitrariamente un punto in cui   (origine)U=0yzx0PU funzione solo del punto non della traiettoria∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹ℒA,B=∫BA⃗F⋅d⃗lℒA,B=∫BA⃗F⋅d⃗l=∫BAdU=U(B)−U(A)ℒA,B=U(B)−U(A)=[U′ (B)−k]−[U′ (A)−k]=U′ (B)−U′ (A)U(x,y,z)=∫P(x,y,z)0⃗F⋅d⃗l=U(P)−U(0)=U(P)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#35,35,"Campi di forze conservativi: 2a proprietà 
Esiste una  funzione scalare U(P), dipendente solo dalla posizione e dalla forza, detta potenziale tale che2a Proprietàyzx0BA..123Percorso AB: A->O->B
ℒA,B=∫BA1⃗F⋅d⃗l=∫0A2⃗F⋅d⃗l+∫03B⃗F⋅d⃗l=−∫A02⃗F⋅d⃗l+∫03B⃗F⋅d⃗l==−[U(A)−U(0)]+[U(B)−U(0)]=U(B)−U(A)ℒA,B=U(B)−U(A)36"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#36,36,"Energia potenzialeAl posto di U(P) si preferisce introdurre V(P)=−U(P)
37•V(P) misura la capacità che ha il punto P di produrre lavoro quando il punto materiale ritorna all’origine.2a ProprietàEsiste una funzione scalare V(P), dipendente solo dalla posizione e dalla forza, detta energia potenziale tale cheLe prime due proprietà devono essere mutualmente dimostrabili.ℒA,B=U(B)−U(A)=V(A)−V(B)V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#37,37,"Forze conservative 3a proprietà
38Campo conservativo è un differenziale esattoPer definizioneFxdx+Fydy+Fzdz=−∂V∂xdx−∂V∂ydy−∂V∂zdzdV=∂V∂xdx+∂V∂ydy+∂V∂zdzUguagliandoδℒ=⃗F⋅d⃗l=Fxdx+Fydy+Fzdz=dU=−dV"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#38,38,"Forze conservative 3a proprietà
39Operatore vettoriale (operatore simbolico)  nabla
3a ProprietàLa forza è col segno meno il gradiente dell’energia potenziale NB: l’operatore nabla non è un vettore, è un operatore che agisce sulle funzioni, come la derivata o l’integrale. Il risultato dell’operazione dipende al tipo di funzione a cui è applicato. "
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#39,39,"Operatore Nabla
40
Nabla:Gradiente di una funzione scalare
Divergenza di un campo vettoriale
Rotore di un campo vettoriale
È un vettoreÈ uno scalareÈ un vettoreÈ un operatore"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#4,4,"Se chiamo   la componente della forza lungo la tangente allo spostamento allora  Ft=Fcosθ
Definizione di lavoro infinitesimo
5Lavoro infinitesimo compiuto da una forza:Il lavoro infinitesimo è il prodotto dello spostamento per la componente della forza lungo lo spostamentoSe la forza è  allo spostamento:        ⊥δℒ=0Es:
NB:definizioni valgono per qualsiasi forza, non è detto sia quella che causa il moto!δℒ=⃗F⋅d⃗l=|⃗F||d⃗l|cosθ=Fdlcosθδℒ=Ftdlδℒpeso=0δℒforza⃗F≠0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#40,40,"Significato dell’operatore gradienteL’operatore gradiente restituisce un vettore diretto lungo la direzione in cui aumenta più velocemente la funzione scalare.
41Campo scalare
xy
Superfici (linee) di livello
Vettore applicato!
Diretto dove f(x,y) aumenta e       alle superfici di livello⊥"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#41,41,"Forze conservative 4a proprietà
423a proprietàRotoreSostituisco la prima nella seconda:Proprietà delle derivate parziali seconde per funzioni continue e derivabili:∂2V∂x∂y=∂2V∂y∂x∂2V∂x∂z=∂2V∂z∂x∂2V∂y∂z=∂2V∂z∂y𝜕𝑧"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#42,42,"Forze conservative 4a proprietà
4a pr oprietà:  se il campo è conservativo il suo rotore é nulloCondizione necessaria e sufficiente affinché un campo di forze sia conservativo è che il rotore si annulli in tutti i punti del campo.Modo facile e pratico per verificare se un campo è conservativo:𝜕𝑧
43"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#43,43,"ℒ=∮⃗F⋅d⃗lRiepilogo: Forze conservative
44
1a Proprietà
2a ProprietàEsiste una funzione scalare V(P) (=-U(P)), detta energia potenziale, tale che
ℒA,B=V(A)−V(B)
3a Proprietà
4a Proprietà
Tutte le proprietà sono simultaneamente necessarie e sufficienti (la verifica di una implica tutte le altre)Forze posizionali il cui lavoro non dipende mai dal percorso ma solo dal punto di partenza e dal punto di arrivo."
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#44,44,"Calcoli di energia potenziale
45yz
xP(t)O1Data una forza conservativa, trovare l’energia potenziale
2AB
V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗lℒ0,P=ℒ1(0,P)=ℒ2(0,P)=ℒ(0,A,B,P)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#45,45,"Calcoli di energia potenziale
46
1. Scelgo un percorso arbitrario su una spezzata2. Applico la definizione di energia potenziale sul percorso sceltoIn coordinate cartesiane:V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#46,46,"47Esercizio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)= 2xˆı z2ˆ| ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı zˆ| ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R: =4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵""0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10 6C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale 2sulla superﬁcie interna del guscio sferico (R: 2 Q14⇡r22= 8·10 6C/m);b) la di↵erenza di potenziale tra i due conduttori. (R: V=Q4⇡""0r2 r1r1r2= 15kV)V"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#47,47,"Esercizio   Sia dato un punto materiale di massa M su cui agisce una forza conservativa di energia potenziale:                                Sapendo che le costanti α e β sono positive, determinare:   1) l’espressione della forza;   2) le dimensioni e le unità di misura delle costanti α e β;    3) l’accelerazione del corpo quando passa per il punto P(0,L,L).
48
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#48,48,"Conservazione dell’energia meccanica
49Sistema meccanico con: -Vincoli ideali -Forze attive conservativeTeo. forze viveCampi conservativiUguagliando:Energia meccanica:E=T+VTeorema della conservazione dell’energia meccanica: Per un sistema meccanico sottoposto a vincoli tutti ideali ed a forze non vincolari tutte conservative, l’energia meccanica E si conserva, ossia la somma fra l’energia cinetica T e  l’energia potenziale totale V, rimane costante durante il moto. 
Dimensionalmente:                    JouleE⎡⎣⎤⎦=T⎡⎣⎤⎦=V⎡⎣⎤⎦NB: A e B sono punti sulla traiettoria, l’energia si conserva lungo la traiettoria
ℒA,B=V(A)−V(B)
ℒA,B=T(B)−T(A)ℒA,B=T(B)−T(A)=V(A)−V(B)⟹T(A)+V(A)=T(B)+V(B)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#49,49,"Conservazione dell’energia meccanica
50
x
x
E1E2Corpo 1: Stato liberox1x≥x1x2x3Corpo 2: Stato legatox2≤x≤x3Curva nera:  V(x) energia potenzialeIn una certa regione di spazio E è costante Se V aumenta  T diminuisce  e viceversaMoto possibile solo nelle regioni di spazio in cui                        per def di TE≥V"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#5,5,"Definizione di lavoro
6
AB
xyzOIl lavoro totale compiuto dalla forza su un punto materiale in un intervallo di tempo in cui il punto si sposta da A a B è la somma di tutti i lavori infinitesimi:d⃗l1d⃗l2d⃗l3
Il lavoro compiuto da una generica forza, il cui punto di applicazione P si sposta da A a B lungo una linea , è l’integrale esteso a tale linea del prodotto scalare fra la forza  e lo spostamento infinitesimo :⃗Fℓ⃗Fd⃗lℓℒ=∑iδℒ=∑i⃗Fi⋅d⃗liℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#50,50,"Esempi: forza elastica
51Verifichiamo se è conservativa:  ?⃗∇∧⃗F=0
Forza elastica:
La forza elastica è conservativa⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(∂(ky)∂z−∂(kz)∂y)+̂𝚥(∂(kz)∂x−∂(kx)∂z)+̂k(∂(kx)∂y−∂(ky)∂x)=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#51,51,"Potenziale elastico
52yzxP(t)OABV(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,0,0)0kxdx+∫(x,y,0)(x,0,0)kydy+∫(x,y,z)(x,y,0)kzdz==kx22+ky22+kz22=k2(x2+y2+z2)=k|⃗r2|2V(P)=k2(x2+y2+z2)=k|⃗r2|2"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#52,52,"Esempi: forza pesoForza peso:
53
La forza peso è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(−∂(−mg)∂y)+̂𝚥(∂(−mg)∂x)+0̂k=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#53,53,"Potenziale gravitazionale
54yzxP(t)OAB𝑉(𝑃)=𝑚𝑔𝑧
V(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,y,z)(x,y,0)mgdz=mgz"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#54,54,"Esempi: forza costanteForza costante:
55
Una forza costante è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂fy∂z−∂fz∂y)+̂𝚥(∂fz∂x−∂fx∂z)+̂k(∂fx∂y−∂fy∂x)=⃗0"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#55,55,"Potenziale di una forza costante
56yzxP(t)OAB𝑉(𝑃)=−𝑓𝑥𝑥−𝑓𝑦𝑦−𝑓𝑧𝑧
V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0fxdx−∫(x,y,0)(x,0,0)fydy−∫(x,y,z)(x,y,0)fzdz==−fx∫(x,0,0)0dx−fy∫(x,y,0)(x,0,0)dy−fz∫(x,y,z)(x,y,0)dz=−fxx−fyy−fzz"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#56,56,"Esempi: campo centrale  a simmetria sfericaForza centrale a simmetria sferica:
57Verifichiamo se è conservativa:
Tutti i campi centrali a simmetria sferica sono conservativixyz
O funzione scalare della sola posizione   è un’energia potenziale se è possibile trovare una funzione scalare t.c  (forza è conservativa).F(r)drF(r)dr=−dVF(r)dr=−dV⟹F(r)=−dV/drd⃗l=̂u⊥(dl⊥)+̂ur(dr)δℒ=⃗F⋅d⃗l=F̂ur⋅(̂u⊥dl⊥+̂urdr)=F(ur⋅̂u⊥dl⊥+ur⋅̂urdr)=Fdrd⃗l=(dl⊥)̂u⊥+(dlr)̂ur=0=1⃗F(⃗r)=F(r)̂ur
ℒA,B=∫BAF(r)dr=−∫BAdV=V(rB)−V(rA)AB"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#57,57,"•sono arrivato qua •(mancano le animazioni)
58"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#58,58,"Lavoro di una forza di attrito dinamico
59Lavoro lungo la traiettoria 2:
BLavoro lungo la traiettoria 1:Lavoro da A a B della forza di attrito dinamico:1
ATutte le forze di attrito (dinamico, viscoso) NON sono mai conservative⃗F=−μcN̂ut=−μcN⃗vvℒ1(A,B)=∫BA1⃗F⋅d⃗l=∫BA1(−μcN̂ut)⋅(̂utdl)2=−μcN∫BA1dl=−μcNLA1B<0ℒ2(A,B)=∫BA2⃗F⋅d⃗l=∫BA2(−μcN̂ut)⋅(̂utdl)=−μcN∫BA2dl=−μcNLA2B<0LA1B≠LA2B⟹ℒ1(A,B)≠ℒ2(A,B)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#59,59,"Lavoro di forze conservative e non
60
Teo. Forze vive ℒtot=T(B)−T(A)Lavoro totale ℒtot=ℒcons+ℒncCampi conservativi ℒcons=V(A)−V(B)Il lavoro delle forze non conservative è dato dalla variazione dell’energia meccanica totaleIn presenza di forze d’attrito, generalmente, si ha ℒnc<0⟹E(B)<E(A)Forze dissipativePunto materiale soggetto ad una forza totale: somma di 2 contributi ℒA,B=∫BA⃗F⋅d⃗l=∫BA(⃗Fcons+⃗Fnc)⋅d⃗l=∫BA⃗Fcons⋅d⃗l+∫BA⃗Fnc⋅d⃗lT(B)−T(A)=V(A)−V(B)+ℒncℒnc=[T(B)+V(B)]−[T(A)+V(A)]=E(B)−E(A)"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#6,6,"Graficamente
7
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsBIl lavoro infinitesimo in un tratto di s è pari all’area tratteggiatadlδℒ=Ftdlℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#60,60,"Esercizio•Un carrello viene lanciato con una velocità iniziale v lungo un binario orizzontale che poi presenta un avvolgimento circolare verticale di raggio R = 4 m. Calcolare, nell’ipotesi di assenza di attriti,  il minimo valore vmin che deve essere dato alla velocità v affinché il carrello compia il “giro della morte” senza staccarsi dai binari.
61
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#61,61,"EsercizioUn punto materiale di massa m=30 g è inizialmente fermo su di un profilo circolare liscio di raggio R=20 cm ad una altezza H=R/2 rispetto al piano orizzontale. Scendendo lungo il profilo il punto incontra in A un piano orizzontale liscio su cui è vincolata in B una molla di costante elastica  k =0,1 kg/s2, inizialmente a riposo. Determinare: a)le componenti tangenziale (aT) e centripeta (aN)  dell’accelerazione del punto nel punto iniziale; b)la reazione vincolare nel punto A; c)la compressione massima della molla. 
62
mRKA
R
B"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#62,62,"EsercizioUna cassa, di massa M=7 kg è  inizialmente in moto su un piano orizzontale liscio con una velocità di v =8 m/s ad una distanza D =6 m da un piano ruvido inclinato di  α=15° rispetto alla direzione orizzontale. Sapendo che la cassa si ferma dopo aver percorso L = 8 m sul piano inclinato, determinare  a)il coefficiente di attrito dinamico del piano inclinato,  b)il lavoro fatto dalla forza di attrito sul piano inclinato,  c)indicare (motivando la risposta) se, raggiunta la quota massima la cassa ridiscende il piano o si ferma.
63
"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#63,63,"EsercizioUn corpo di massa M = 12 kg scende da un piano inclinato di α=30° rispetto ad una direzione orizzontale. Sapendo che il corpo parte da fermo, che si abbassa di una quota h = 2 m, che il piano è ruvido e con un coefficiente di attrito dinamico µd=0,2, determinare la sua velocità finale.
64"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#7,7,"Graficamente
8
AB
OIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsB
Il lavoro totale è pari all’area sotto la curva compresa fra i due estremi fra cui si sposta il punto materialeℒ=∫BAFtdlℓ"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#8,8,"Esempi
91.
AB
costante in modulo, direzione e verso ℓℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFtdl=Ft∫BAℓdl=Ftℓ2. costante in moduloFt=|⃗F|cosθ=Fcosθℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFcosθdl=Fcosθ∫BAℓdl=FℓcosθIn generale in coordinate cartesiane: forza posizionale⃗F(x,y,z)=Fx(x,y,z)̂ı+Fy(x,y,z)̂𝚥+Fz(x,y,z)̂kd⃗l=dx̂ı+dŷ𝚥+dẑkIntegrale generalmente non scomponibile!
AB
𝜗𝜗𝜗𝜗ℓℒ=∫BAℓ⃗F(x,y,z)⋅d⃗l=∫BAℓ[Fx(x,y,z)dx+Fy(x,y,z)dy+Fz(x,y,z)dz]"
data_test\rootfolder\università\FisicaGenerale\05-lavoro-e-energia.pdf#9,9,"Esercizio
10Calcolare il lavoro della forzacon k e h costanti che agisce sul piano (x,y) sulle traiettorie: 1)Lungo un segmento rettilineo che congiunge l’origine con un punto A=(a,b); 2)Lungo l’arco di parabola OA avente vertice nell’origine e per asse l’asse x.xyOA"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#0,0,Terzo Principio della Dinamica CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#1,1,"Sviluppo1)Modello del punto materiale troppo povero per descrivere tutta la realtà; 2)Dinamica dei sistemi di punti materiali; 3)Riscrittura  della  in modo opportuno; 4)Terzo principio della dinamica⃗F=m⃗a
2"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#10,10,"Derivate rispetto al tempo
Rappresenta TUTTE le forze REALI che agiscono sul punto i-esimoPossiamo distinguere tra le forze dovute agli altri punti del sistema  (forze INTERNE al sistema) e forze dovute a tutto ciò che non è il sistema (forze ESTERNE al sistema, dovute all’ambiente). Analogamente per i momenti→𝑄=𝑁∑𝑖=1→𝑞𝑖=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1𝑑→𝑞𝑖𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖→𝑃𝑜=𝑁∑𝑖=1→𝑝𝑖=𝑁∑𝑖=1𝑚𝑖→𝑟𝑖∧→𝑣𝑖𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1𝑑→𝑝𝑖𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑟𝑖∧→𝐹𝑖
11"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#11,11,"Forze interne ed esterneTipiche forze interne: vincoli tra punti materiali, fili, sbarre interne al sistema, molle o sistemi di attrazione/repulsione tra punti del sistema Tipiche forze esterne: forze peso, vincoli tra il sistema e l’esterno, tensioni tra il sistema e l’esterno
Piano verticaleInterneEsterne
Piano orizzontale
Piano verticale
12"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#12,12,"Separazione tra forze interne ed esterne
Per un sistema isolato si ha:Attenzione:  risultato parziale→𝐹𝐸𝑆𝑇=0, →𝑀𝐸𝑆𝑇=0𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1(→𝐹𝐼𝑁𝑇𝑖+→𝐹𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1(→𝑀𝐼𝑁𝑇𝑖+→𝑀𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇
13"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#13,13,"Verifiche sperimentaliQuanto valgono nei sistemi isolati?Studio il sistema Terra-Luna o Giove-suoi satelliti o altri sistemi:
Risultato sperimentale nuovo: nei sistemi isolati si osserva sempre: Nei sistemi isolati la quantità di moto e il momento angolare del sistema sono costanti nel tempo.𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇
𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=014"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#14,14,"Sistema isolato semplice
Le due forze interne agiscono su una retta d’azione che passa per i due punti materiali
 e : forze interne al sistema di due punti⃗F1⃗F2
O
→𝐹𝐼𝑁𝑇=→0→→𝐹1+→𝐹2=→0⟹→𝑀𝐼𝑁𝑇=→𝑟1∧→𝐹1+→𝑟2∧→𝐹2=→0→→𝑟1∧→𝐹1+→𝑟2∧(−→𝐹1)=→0→→𝑟1∧→𝐹1−→𝑟2∧→𝐹1=(→𝑟1−→𝑟2)∧→𝐹1=→0(→𝑟1−→𝑟2)∥→𝐹115→𝐹2=−→𝐹1⃗F1⃗F2"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#15,15,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storica
16"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#16,16,Terzo principio della dinamica•Col secondo principio prevediamo il moto di un punto materiale sulla base della forza agente su di esso:  •Per avere una forza  occorre almeno un altro corpo che agisca sul punto materiale •Il secondo principio dice come si muove il punto materiale soggetto ad una forza ma non cosa succede al corpo che tale forza la provoca  serve il terzo principio→𝐹=𝑚→𝑎⃗F→17
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#17,17,"Terzo principio della dinamica  per sistemi di punti materiali•Per ogni punto si suppone di poter distinguere fra le forze agenti sul punto i-esimo quella dovuta al punto j-esimo •Si soppone valere sempre la sovrapposizione degli effetti cioè se  è la forza che 2 esercita su 1 e  è la forza che 3 esercita su 1 allora  •Se valgono queste condizioni allora il terzo principio è estendibile a N corpi applicandolo ad ogni possibile coppia di punti→𝐹1,2→𝐹1,3→𝐹1=→𝐹1,2+→𝐹1,3→𝐹𝑖=𝑁−1∑𝑗=1→𝐹𝐼𝑁𝑇𝑖,𝑗+→𝐹𝐸𝑆𝑇𝑖Sul punto i-esimo agiscono tutte le forze interne dovute agli altri N-1 punti e le forze esterneSe agiscono solo forze interne: il sistema è isolato  →𝐹𝐸𝑆𝑇𝑖=→0⟹𝑑→𝑄𝑑𝑡=018"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#18,18,"Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storicaFormulazione alternativaSe in un SRI, osserviamo che su un corpo (A) si esercita una forza allora esisterà almeno un altro corpo (B) responsabile di tale forza. Su questo corpo B agirà una forza vettorialmente opposta a quella su A e con la stessa retta d’azione.NB: le due forze sono applicate in due punti di applicazione diversi ovvero I due corpi!19"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#19,19,"Terzo principio, formulazione modernaSemplice, diretto, modernoSu sistemi isolati
Nulli per il terzo principio (sperimentale)Nulli in un sistema isolatoQuantità di moto e momento angolare si conservano per sistemi isolati.In un Sistema di Riferimento Inerziale,  e calcolato rispetto ad un polo O qualunque si conservano per sistemi isolati.→𝑄→𝑃0 𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=0
20"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#2,2,"Quantità di moto di un punto materialeSi definisce la quantità di moto di un punto come:Se la massa è costante:Secondo principio:Se la massa è variabile: quale delle due è corretta?oppure[→𝑞]=[𝑚→𝑣]=[𝑀𝐿𝑇−1]→𝑘𝑔∙𝑚𝑠→𝐹=𝑚→𝑎=𝑚𝑑→𝑣𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡
→𝐹=𝑑→𝑞𝑑𝑡→𝐹=𝑑→𝑞𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡=𝑑𝑚𝑑𝑡→𝑣+𝑚𝑑→𝑣𝑑𝑡3"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#20,20,"Conseguenze del terzo principio2 corpi su un piano orizzontale tenuti insieme da una molla compressa tramite un filo ideale
21
Terzo principio: poiché il sistema è isolatoIn diverse circostanze è possibile ottenere dei risultati di dinamica SENZA conoscere le forze in gioco
→𝑄𝑖𝑛𝑖𝑧=→0Tagliando il filo i corpi si muovono per effetto della di moto rettilineo uniforme in direzione opposta→𝐹=𝑚→𝑎 →𝑄𝑓𝑖𝑛=𝑚1→𝑣1+𝑚2→𝑣2→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛→→0=𝑚1→𝑣1+𝑚2→𝑣2→→𝑣2=−𝑚1𝑚2→𝑣1"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#21,21,Urti CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#22,22,"UrtiSi ha un urto quando due corpi, che si muovono a velocità diverse, interagiscono (p.es. vengono a contatto) e, in un intervallo di tempo molto breve (rispetto al contesto), modificano sostanzialmente le proprie velocità.
23
"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#23,23,"Forze d’urto – forze impulsive
24
Forze impulsive"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#24,24,"Urti collineari di punti materiali
25
e = 0 : urto perfettamente anelastico e = 1 : urto perfettamente elasticoEmpiricamente Prima dell’urtoDopo l’urto
NB.: Trattasi di relazioni tra le componenti dei vettori lungo l’asse x, le quali includono il segno.v0,1x−v0,2x>0→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛𝑣1,𝑥−𝑣2,𝑥=−𝑒(𝑣01,𝑥−𝑣02,𝑥)0≤𝑒≤1"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#25,25,"Urti collineari di punti materiali
26
Conservazione della quantità di moto (e del momento angolare).
Relazione fra le velocità
m1 = m2
e = 0
Urto anelastico
m1 = m2
e = 1
Urto elastico"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#26,26,"Energia cineticaFacendo un po’ di conti … :
e = 1
E = costante T=12m1v1x2+12m2v2x2T0=12m1v01x2+12m2v02x2
In un urto perfettamente elastico l’energia cinetica si conserva
e = 0
ΔE ≤  0 In un urto perfettamente anelastico l’energia cinetica diminuisce27"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#27,27,"Urti in sistemi non isolatiSe gli urti avvengono in sistemi non isolati a causa della presenza di forze esterne o vincoli esterni, il terzo principio (formulazione conservativa) non è sempre applicabileSe l’urto è quasi istantaneo, sono molto più importanti le forze impulsive e si può trascurare l’effetto della forza peso. Si ha una quasi conservazione di quantità di moto e momento angolare tra prima e dopo l’urto. Vale in generale per forze esterne LIMITATE.Se le forze esterne hanno una direzione definita, si ha la conservazione della quantità di moto nelle direzioni perpendicolari.
Esempio: urto di due palloni che si scontrano in aria. E’ presente una forza esterna: quella peso.
28"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#28,28,"Urti: riassunto
29"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#29,29,"EsercizioUn corpo di massa m=1 kg è in moto rettilineo uniforme ad una velocità v=10 m/s, su un piano liscio, quando entra in una regione permanendovi per t=0.1 s in cui perde velocità scalare. All’uscita della regione il corpo ha una velocità di v=9 m/s. Determinare:  1)la forza media che ha frenato il corpo,  2)il lavoro della forza frenante e  3)il coefficiente di attrito se si tratta di una forza di attrito cinetico. 
30"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#3,3,"Situazioni di massa variabile•Moto di una goccia d’acqua che cade in presenza di vapor d’acqua saturo  à la massa aumenta •Moto di un aereo in condizioni di tempo brutto con formazione di ghiaccio sulle ali à la massa aumenta •Moto di un razzo che si muove bruciando carburante à la massa diminuisce •Relatività: la massa dipende dalla velocità: •Dato sperimentale: la forza varia con la massa!È più generale della 
m(v)=m01−vc()2→𝐹=𝑑→𝑞𝑑𝑡4"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#30,30,"EsercizioDue punti materiali di massa m1=1 kg e m2=3 kg sono uniti da un filo inestensibile che risulta sempre in tensione. Sapendo che i due punti si muovono su un piano ideale senza attrito, che costituiscono un sistema isolato e che il punto 1 ha equazioni del moto date da :    (nelle unità del SI) trovare la tensione del filo e l’accelerazione del punto 2. 
31"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#31,31,"EsercizioDa una pistola con canna lunga L=15 cm esce un proiettile di massa m=5 g con velocità v=180 m/s. Trovare la forza media che ha spinto il proiettile dentro la canna e il tempo che impiega il proiettile a percorrere la canna della pistola dal momento dello sparo.
32"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#32,32,"EsercizioDue corpi A e B di massa 2 kg si scontrano fra loro. Le velocità prima dell’urto sono   Dopo l’urto Tutte le velocità sono date in metri al secondo. Qual è la velocità finale di B? Quanta energia cinetica guadagna o perde nell’urto il corpo B? L’urto è elastico? →𝑣𝐴,𝑖=15^𝑖+30^𝑗→𝑣𝐵,𝑖=−10^𝑖+5^𝑗→𝑣𝐴,𝑓=−5^𝑖+20^𝑗
33"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#33,33,"EsercizioUna palla di stucco con una massa di 5 g ed una velocità v1 = 4 m/s compie una collisione diretta e perfettamente anelastica con una palla da biliardo inizialmente ferma e che ha una massa di 500 g. Determinare la velocità comune delle due palle dopo l’urto e le energie cinetiche prima e dopo l’urto dei diversi corpi.  - trascurare gli effetti di rotolamento -
34"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#34,34,"EsercizioUna pallina di gomma, di massa m=20 g, viene lasciata cadere in verticale da una altezza h=100 cm misurata rispetto ad un pavimento orizzontale. La pallina rimbalza esattamente in verticale e raggiunge una altezza di h' = 90 cm.  Qual è il coefficiente di restituzione del pavimento? A che altezza arriverà il successivo rimbalzo?
35"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#35,35,"EsercizioDue carrelli, di massa rispettivamente M=50 kg e 2M si muovono uniti su un binario orizzontale rettilineo ad una velocità costante v=10 m/s. Tra i due carrelli, tenuti uniti da un gancio, vi è un respingente (molla) compresso di 25 cm e di costante elastica k=80000 N/m. Se ad un certo punto il gancio si rompe, trovare le velocità finali dei due carrelli.
36"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#36,36,"EsercizioUn proiettile di massa mP = 4 kg viene sparato in orizzontale da un cannone posto su un carrello e avente una massa complessiva di MC = 3 000 kg. Sapendo che la velocità di uscita del proiettile è di vP = 350 m/s, determinare la velocità iniziale di rinculo del cannone.
37"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#37,37,"Esercizio (pendolo balistico)Un proiettile, di massa m e velocità v diretta in orizzontale, colpisce in modo totalmente anelastico un peso di massa M appeso al soffitto tramite un filo inestensibile. A seguito dell’urto il peso inizia una oscillazione. Trovare la relazione tra la velocità del proiettile e la massima altezza del peso rispetto alla sua posizione di riposo.
38"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#38,38,"Esercizio Un corpo di 2 kg viene spinto contro una molla di costante elastica pari a 200 N/m fino a comprimerla di 15 cm. Lasciato andare, la molla lo spinge su una superficie orizzontale fino a che non si arresta dopo un percorso di 75 cm. Qual e’ il coefficiente di attrito dinamico tra blocco e superficie?
3939"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#39,39,"EsercizioDue sferette di masse m1 e m2, vincolate a muoversi su un piano verticale, sono collegate ad uno stesso punto fisso O attraverso due fili flessibili inestensibili, entrambi di lunghezza l e massa trascurabile (vincoli ideali). Inizialmente la sferetta m2 è in posizione di equilibrio stabile, mentre la sferetta m1 con il filo teso è trattenuta ad una quota h rispetto alla posizione di m2. In seguito, m1 viene lasciata libera di muoversi e va a urtare m2. Nell’ipotesi che l’urto sia istantaneo e completamente anelastico, calcolare:   1) il modulo v1 della velocità con cui m1 urta m2;   2) la quota massima h’ raggiunta dal sistema    dopo l’urto e   3) la perdita di energia cinetica.
40
"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#4,4,"ImpulsoL’azione di una forza in un intervallo di tempo dt provoca una variazione infinitesima della quantità di moto
Impulso:Viceversa: da una variazione infinitesima della quantità di moto si può risalire alla forza agente.⃗ℐ=∫t2t1⃗Fdt=∫t2t1d⃗q=⃗q(t2)−⃗q(t2)=Δ⃗q[⃗ℐ]=[Δ⃗q]=[MLT−1]5"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#40,40,"EsercizioUn sistema meccanico, che si trova inizialmente fermo ad una altezza h = 1,2 m dal pavimento, è costituito da una pallina di massa m1 = 10 g collocata in equilibrio (instabile) sopra una pallina di massa m2 = 5m1. A un certo istante, il sistema viene lasciato libero di cadere. Assumendo che ogni urto sia perfettamente elastico e trascurando le dimensioni delle palline, determinare:  1)l’altezza a cui rimbalza la pallina più leggera;  2)la velocità con cui arriva a terra la seconda pallina dopo l’urto.
41"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#41,41,"EsercizioUna pallina di massa 2m viene lanciata verso l’alto da una quota z=0 ad una velocità v=10 m/s esattamente nello stesso istante in cui un’altra pallina di massa m, posta ad una quota h=5 m viene lasciata cadere sulla verticale della prima pallina.  1) Se l’urto tra le palline e’ elastico, quanto tempo impiega la prima pallina ad arrivare a terra? 2) Se l’urto e’ completamente anelastico, quanto tempo ci mettono le palline ad arrivare a terra?    (considerare g=10 m/s2)
42"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#5,5,"Teorema dell’impulsoForze impulsive: forze che agiscono per un periodo di tempo limitato
Primo principio  con la quantità di motoSe m è costante    costante    Se m costante e     costante    Teorema dell’impulso: l’impulso di una forza applicata ad un punto materiale provoca la variazione della sua quantità di moto.Forma integrale del secondo principio della dinamica:  nota la forza anche la variazione della quantità di moto è nota; nota la variazione della quantità di moto è nota la forza media che ha agito nell’intervallo di tempo dt.⃗ℐ=∫t2t1⃗Fdt=Δ⃗q
⃗ℐ=∫t2t1⃗Fdt=Δ⃗q=m(⃗v2−⃗v1)6"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#6,6,"⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)Momento angolare
xyz
O
P
Punto materiale di massa m con velocità  ⃗vMomento angolare o  momento della quantità di moto rispetto al polo O: 
Rispetto al polo F: P
F
Osservazione: il vettore quantità di moto è un vettore applicato nel punto P
7⃗pF=(⃗r−⃗rF)∧⃗q"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#7,7,"Momento angolare nel piano
Y
O
Velocità: componente radiale più tangenziale
Il momento angolare: - Dipende dalla velocità trasversa, non da quella radiale - È un vettore  al piano definito da  e  - È diverso da zero solo quando c’è una rotazione - È costante in un moto circolare uniforme⊥→𝑟→𝑣velocità angolare
8⃗v=⃗vr+⃗vt=vr̂ur+vt̂ut=·r̂ur+r·φ̂ut̂ur̂utφ⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)⃗p0=⃗r∧⃗q=m(r̂ur)∧(·r̂ur+r·φ̂ut)=mr2·φ(̂ur∧̂ut)=mr2·φ̂k·φ=dφdt=ω"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#8,8,"d⃗p0dt=⃗r∧⃗F=⃗M0Derivata del momento angolareDerivando:La derivata del momento angolare é uguale al momento della forza agente sul punto materiale rispetto allo stesso polo.Il momento delle forze è nullo se: -La forza agente è nulla (punto isolato da altri corpi) -Vettore posizione e forza sono paralleli  Se il momento delle forze è nullo, il momento angolare è costante in modulo direzione e verso: la traiettoria giace su un piano. 9⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)d⃗p0dt=d(⃗r∧⃗q)dt=d⃗rdt∧⃗q+⃗r∧d⃗qdt=⃗v∧⃗q+⃗r∧⃗F"
data_test\rootfolder\università\FisicaGenerale\06-terzo-principio-e-urti.pdf#9,9,"Sistemi di punti materialiUn insieme di N punti materiali di masse mi costituisce un sistema di punti materiali 
xyz
OSRI
12iDef: massa del sistema di punti materiali:
NM=mii=1N∑Def: Quantità di moto del sistema di punti materiali: 
Def: Momento della quantità di moto (o momento angolare): (momento risultante del sistema)10⃗P0=N∑i=1⃗pi=N∑i=1⃗ri∧⃗qi=N∑i=1mi⃗ri∧⃗vi"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#0,0,Dinamica dei Sistemi CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#1,1,"Equazioni cardinali 
2Dal principio di indipendenza delle azioni simultanee: le forze ed i momenti interni rimangono nulli anche in presenza di forze e momenti delle forze esterni.6 equazioni scalari! Descrivono esattamente: 1.Il moto di un punto 2.Il moto di 2 punti 3.Il moto di un corpo rigido𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇Equazioni cardinali della dinamica dei sistemiChe cosa descrivono per un sistema generico di N punti materiali?"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#10,10,"Teorema del momento angolare
11A cosa sono dovute le variazioni del momento angolare totale di un sistema di punti?Consideriamo un polo O’ mobile (non necessariamente il CM)
O
O’
Derivando:=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−𝑁∑𝑖=1𝑚𝑖→𝑣𝑂′ ∧→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′ )∧→𝑎𝑖==𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−→𝑣𝑂′ ∧𝑁∑𝑖=1𝑚𝑖→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′ )∧→𝑎𝑖Quantità di moto totale del sistemaMomento delle forze agenti sul sistema rispetto polo O’Nullo perché prodotto vettoriale fra vettori paralleli⃗PO′ =N∑i=1⃗pi=N∑i=1mi⃗r′ i∧⃗vi=N∑i=1mi(⃗ri−⃗rO′ )∧⃗vid⃗PO′ dt=N∑i=1mid[(⃗ri−⃗rO′ )∧⃗vi]dt==N∑i=1mi(⃗vi−⃗vO′ )∧⃗vi+N∑i=1mi(⃗ri−⃗rO′ )∧⃗ai=−→𝑣𝑂′ ∧→𝑄+→𝑀𝑂′ "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#11,11,"Teorema del momento angolare
12O
O’
Estensione della seconda equazione cardinale al caso di un polo mobile:  seconda equazione cardinale generalizzataUsando il primo teorema del centro di massa−→𝑣𝑂′ ×𝑀→𝑣𝐶𝑀+→𝑀𝑂′ =−𝑀→𝑣𝑂′ ×→𝑣𝐶𝑀+→𝑀𝑂′ 𝑑→𝑃𝑂′ 𝑑𝑡=−→𝑣𝑂′ ×→𝑄+→𝑀𝑂′ ="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#12,12,"Teorema del momento angolare: se il polo O’ è fisso nel SRI o coincide con il CM, l’evoluzione nel tempo del momento angolare è determinata dal momento risultante delle forze esterne.Teorema del momento angolare
13Il secondo termine è nullo quando: 1- O’ è fermo nel SRI 2- il CM è fermo nel SRI 3- il polo O’ coincide con il CM 4- 
Sempre, anche  quando il CM si muove!
In uno di questi casi𝑑→𝑃𝑂′ 𝑑𝑡=→𝑀𝑂′ −𝑀→𝑣𝑂′ ×→𝑣𝐶𝑀
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#13,13,"Equazioni cardinali
14
Descrivono il moto di un sistema di N punti materiali attraverso il suo CMSistema di equazioni non completo: non si può descrivere il moto di N punti con sole 2 equazioni vettoriali, ma queste forniscono una indicazione globale su come si muove il CM e l’evoluzione del momento angolare calcolato rispetto al CM.Per un sistema di punti materialiEquazioni cardinali:  moto di 1 punto, 2 punti, corpo rigido"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#14,14,"Energie di un sistema di punti
15Osservazione: la forza ed il lavoro sono grandezze additive Anche l’energia (cinetica, potenziale, meccanica) è una grandezza additiva.Definiamo energia cinetica di un sistema:
Definiamo energia potenziale di un sistema soggetto solo a forze conservative interne o esterne:
Analogamente definiremo Energia Meccanica di un sistema:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#15,15,"Teorema di König
16
Usiamo coordinate intrinseche: 
Energia cinetica come calcolata nel SR del CM (SR intrinseco)Energia cinetica nel SRI di un punto di massa M  con velocità pari a quella del CM
TCM=
⃗Q′ =0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#16,16,"T=T′ +TCMTeorema di König
17Energia cinetica nel SR del CM (SR intrinseco)Energia cinetica di un punto di massa M con velocità pari a quella del CM
Teorema di König: l’energia cinetica di un sistema di punti materiali in moto rispetto ad un punto O è, istante per istante, uguale alla somma dell’energia cinetica del sistema rispetto al CM (T’) più l’energia che possiederebbe in quell’istante rispetto ad O il CM se in esso fosse concentrata tutta la massa (TCM).
()T′ =0TCM=12Mv2CMT′ =N∑i=112miv′ 2i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#17,17,"Sistema di punti soggetti a forza peso
18O
CM
Ricordando la definizione di CM:
⟹𝑀→𝑟𝐶𝑀=∑𝑁𝑖=1𝑚𝑖→𝑟𝑖"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#18,18,"Sistema di punti soggetti a forza peso
19O
CM
Un sistema di punti soggetto alla forza peso si comporta come un unico punto materiale coincidente con il CM avente massa M
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#19,19,"Esercizio
20
Un proiettile è lanciato con una velocità di 20 m/s ad un angolo di 30° rispetto l’orizzontale. Nel corso della sua traiettoria esplode suddividendosi in due frammenti, uno dei quali ha massa doppia rispetto quell’altro. I due frammenti colpiscono il suolo nello stesso istante. Il frammento di massa minore colpisce il suolo a 20 m dal punto di lancio. In quale punto colpisce il suolo il secondo frammento?"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#2,2,Equazioni cardinali -Per N punti materiali servono N equazioni vettoriali del tipo  quindi 3N equazioni scalari; -Le equazioni cardinali sono al massimo 6 equazioni scalari  mancano 3N-6 equazioni scalari che diano informazioni mancanti (es: vincoli che legano fra loro i punti come nel caso dei corpi rigidi)→𝐹=𝑚→𝑎⟹Per N punti materiali le equazioni cardinali forniscono solo informazioni parziali:  non forniscono informazioni sul singolo punto ma danno informazioni collettive.  Che cosa descrivono le equazioni cardinali per un sistema di N punti materiali?  È possibile trovare un elemento del sistema che sia descritto dalle equazioni cardinali? 3
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#20,20,"Sistemi continui
21Sistemi non puntiformi: insiemi “densi” di punti àsistemi continui (estesi). Per tali sistemi la grandezza (dimensione lineare) è importante.  Possiamo caratterizzarli attraverso una nuova quantità geometrica:      Volume V     [L3] àm3Anche un sistema continuo è dotato della proprietà Massa del Sistema:          Massa M     [M] àkg
M=∫dm=∫Vρ(⃗r)dτDef: densità volumetrica puntuale (locale) di massa: 
dm,dτρ(⃗r)=dmdτdm=ρ(⃗r)dτDef: densità volumetrica media di massa: 
M,τ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#21,21,"Legame tra sistemi di punti e sistemi estesi
22
Sistema di punti
Sistema esteso
Un sistema continuo può essere pensato come un sistema di N punti materiali, con Nà+∞ 
M=∫dm=∫Vρ(⃗r)dτρ(⃗r)=dmdτ
M=∫dm=∫Vρ(⃗r)dτ∫f(⃗r,⃗v)dm=∫Vf(⃗r,⃗v)ρ(⃗r)dτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#22,22,"Esempio: centro di massa
23
Sistema di punti
Sistema continuo
Esempio: cubo omogeneo di lato L
xzy⃗rCM=∫V⃗rρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫V⃗rρ(⃗r)dτMxCM=∫Vxρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vxρ(⃗r)dτMyCM=∫Vyρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vyρ(⃗r)dτMzCM=∫Vzρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vzρ(⃗r)dτM"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#23,23,"SISTEMI PIANI
24Se un sistema continuo volumetrico ha una dimensione sempre costante allora può essere trattato come un sistema continuo pianoEsempi: foglio di carta, lastra metallica, tavola di legno, muro
Def: densità superficiale media di massa: 
Def: densità superficiale puntuale (locale): 
Dimensionalmente:
Se il sistema esteso ha uno spessore costante pari a D:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#24,24,"¯λ=MLSistemi lineari
25Se un sistema continuo volumetrico ha due dimensioni sempre costanti allora può essere trattato come un sistema continuo lineareEsempi: corda, filo, sbarra, palo, colonna, pilastroDef: densità lineare media: 
Def: densità lineare puntuale (locale): 
[¯λ]=[ML−1]kg/m"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#25,25,"Esercizio
26Una sbarra di lunghezza L è collocata lungo l’asse x con un estremo nell’origine (0<x<L). Determinare la coordinata x del CM sapendo che la sbarra ha una densità lineare pari a:
xL0Caso 1:
Caso 2:
Caso 3:
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#26,26,"Esercizio
27Trovare le coordinate del CM di un triangolo rettangolo isoscele di lato L e densità superficiale σ costante.
yxO
dx
Verificare che 
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#27,27,"Corpi rigidi
28
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#28,28,"Moto del corpo rigido
29Sistema di N=1 punto 
3 variabili dinamicheSistema rigido di N=2 punti 
6 variabili dinamiche dei punti - 1 vincolo = 5 variabili dinamiche indipendenti
Sistema rigido di N=3 punti 3x3=9 variabili dei punti - 3 vincoli = 6 variabili indipendenti
Sistema rigido di N>3 punti Ogni punto in più introduce 3 variabili dinamiche del punto e 3 vincoli
Nel caso del corpo rigido il moto è descrivibile da sole 6 equazioni.
6 variabili dinamiche indipendenti"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#29,29,"Quali variabili dinamiche?
30La descrizione completa ne richiede 6. Ho la libertà di scegliere quali.
ABCon le 6 variabili così definite posso descrivere la posizione del corpo rigido nello spazio. Sono convenienti dal punto di vista della dinamica?
Suggerimento: 3 coordinate del CM + 3 variabili angolari6 eq. in 6 incogniteEsempio:  •3 coordinate del punto A + 3 coordinate del punto B – 1 vincolo sulla distanza AB = 5 variabili. •1 angolo di rotazione attorno all’asse AB
Equazioni  cardinali per sistema di punti"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#3,3,"Centro di Massa
4O
CM
Sia dato un sistema di N punti materiali descritti in un sistema di riferimento inerziale, si definisceCentro di massa:
3mmL
L/43L/4CM
Punto geometrico definito dal vettore posizione   “interno al sistema”, ma non necessariamente appartenente al sistema. E’ una caratteristica del sistema di punti e non del sistema di riferimento usato.→𝒓𝑪𝑴"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#30,30,"Moto generico di un corpo rigido
31Due possibili moti indipendenti:
2.Moto rotatorio puro attorno ad un asse passante per il CM che è fisso    Tutti i punti compiono un moto circolare attorno all’asse istantaneo di rotazione
Vale ancora:Due possibili moti indipendenti:1.Moto traslatorio puro.   - Tutti i punti hanno la stessa velocità (del CM)  - Traiettorie dei punti sono tutte parallele  - Moto descritto dalla prima equazione cardinale
CM
 Il moto più generico possibile è un moto roto-traslatorio, dove il CM si muove seguendo la prima equazione cardinale ed il corpo fa un moto rotatorio attorno ad un asse istantaneo di rotazione e solo se l’asse di rotazione passa per il CM il moto è descritto dalla seconda equazione cardinale. "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#31,31,"Moto di un corpo rigido
32
Equazioni cardinali per i sistemi sono separate per il moto del CM e per l’evoluzione del momento angolare.Prima equazione cardinale analoga a  per il punto materiale. Ben nota.→𝐹=𝑚→𝑎Seconda equazione cardinale è la vera novità per il moto dei corpi estesi. La studiamo in dettaglio nel caso più semplice: il CM non ha moto traslatorio e utilizzo il sistema di riferimento intrinseco (moto rotatorio puro)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#32,32,"Moto rotatorio puro
33
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare  ⃗ωIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Legge di trasformazione delle velocità tra due sistemi di riferimento in moto relativo⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#33,33,"Moto rotatorio puro
34
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Nulli perché i due sistemi di riferimento si muovono reciprocamente di solo moto rotatorio.⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#34,34,"Moto rotatorio puro
35
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’ perché  per la scelta del sistema S’ →𝑟𝑖=→𝑟′ 𝑖→𝑟𝑂′ =→𝑟𝐶𝑀=0⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i=ω∧⃗ri"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#35,35,"Moto rotatorio puro
36
Scelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.
Unica equazione cardinale utile:                        per il 3o teorema del CM
CM
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare 
Il sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Momento angolare per sistemi di punti materiali.Momento angolare per sistemi estesi.⃗vi=⃗v′ i+⃗vO′ +ω∧⃗r′ i=ω∧⃗ri⃗PCM=∫V⃗r∧⃗vρdτ=∫V⃗r∧(⃗ω∧⃗r)ρdτ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#36,36,"Momento angolare di un sistema rigido
37
Proprietà del doppio prodotto vettoriale:2)  ⃗ri(⃗ω⋅⃗ri)=(xîı+yî𝚥+zîk)⋅(xiωx+yiωy+ziωz)=1) ⃗ωr2i=ωxr2îı+ωyr2î𝚥+ωzr2îk⃗ri=(xîı+yî𝚥+zîk)
=̂ı(ωxx2i+ωyxiyi+ωzxizi)+̂𝚥(ωxxiyi+ωyy2i+ωzyizi)+̂k(ωxxizi+ωyyizi+ωzz2i)⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)⃗PCM=N∑i=1mi⃗ri∧(ω∧⃗ri)=N∑i=1mi⃗ωr2i−N∑i=1mi⃗ri(⃗ω⋅⃗ri)⃗a∧⃗b∧⃗c=⃗b(⃗a⋅⃗c)−⃗c(⃗a⋅⃗b)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#37,37,"Momento angolare di un sistema rigido
38Sostituisco le espressioni trovate in precedenza=N∑i=1mi(ωxr2îı+ωyr2î𝚥+ωzr2îk)+−N∑i=1mi[̂ı(ωxx2i+ωyxiyi+ωzxizi)++̂𝚥(ωxxiyi+ωyy2i+ωzyizi)++̂k(ωxxizi+ωyyizi+ωzz2i)]⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#38,38,"Momento angolare di un sistema rigido
39            =̂ı𝑁∑𝑖=1𝑚𝑖[(𝜔𝑥𝑟2𝑖−𝜔𝑥𝑥2𝑖−𝜔𝑦𝑥𝑖𝑦𝑖−𝜔𝑧𝑥𝑖𝑧𝑖)]++̂𝚥𝑁∑𝑖=1𝑚𝑖[(𝜔𝑦𝑟2𝑖−𝜔𝑥𝑥𝑖𝑦𝑖−𝜔𝑦𝑦2𝑖−𝜔𝑧𝑦𝑖𝑧𝑖)]+̂k𝑁∑𝑖=1𝑚𝑖[(𝜔𝑧𝑟2𝑖−𝜔𝑥𝑥𝑖𝑧𝑖−𝜔𝑦𝑦𝑖𝑧𝑖−𝜔𝑧𝑧2𝑖)]Raccolgo tutti i termini diretti lungo lo stesso versore⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#39,39,"Momento angolare di un sistema rigido
40
Si è sostituito: 𝑟2𝑖−𝑥2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑥2𝑖=𝑦2𝑖+𝑧2𝑖𝑟2𝑖−𝑦2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑦2𝑖=𝑥2𝑖+𝑧2𝑖𝑟2𝑖−𝑧2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑧2𝑖=𝑥2𝑖+𝑦2𝑖E ordino secondo le componenti di →𝜔⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#4,4,"Centro di Massa
5Centro di massa:
Equazione vettoriale  corrisponde a 3 equazioni scalari⇒𝑥𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑥𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑥𝑖𝑦𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑦𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑦𝑖𝑧𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑧𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑧𝑖"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#40,40,"Momento angolare di un sistema rigido
41
Compaiono dei termini uguali nelle posizioni simmetriche. ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)="
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#41,41,"Momento angolare di un sistema rigido
42
In generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎I: tensore d’inerzia Matrice 3x3 simmetrica
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#42,42,"Momento d’inerzia
43
in generale non sono paralleli.
problema agli autovalori/autovettoriI=I0100010001⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟In casi particolari il tensore d’inerzia è diagonale e proporzionale al tensore unitario
Indipendentemente dalla sua forma, per un corpo rigido generico esistono tre direzioni (detti assi principali d’inerzia) per cui  : →𝑷∥→𝝎→𝑷=𝝀→𝝎Esempi: - Sfera di raggio R e massa M:    
              - Cubo di lato L e massa M:    
⃗P=I⃗ω=λ⃗ω(I−1λ)⃗ω=0→(I−1λ)=0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#43,43,"Momento d’inerzia
44problema agli autovalori/autovettoriè la matrice d’inerzia simmetrica  esistono sempre 3 autovalori e 3 autovettori che diagonalizzano la matrice𝐼 →𝐼=𝐼𝑥𝑥000𝐼𝑦𝑦000𝐼𝑧𝑧,= momenti principali d’inerzia Per tale matrice  sono gli assi principali d’inerzia.Ixx,Iyy,Izẑı,̂𝚥,̂k(I−1λ)⃗ω=0→(I−1λ)=0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#44,44,"Momento d’inerzia
45Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z (velocità angolare solo lungo l’asse z) si ha:
Per sistemi di punti materialiPer sistemi estesi⃗P=I⃗ω=Ixx000Izz000Izz(00ω)=Izzω̂k⃗P=Izzω̂kIzz=∫V(x2+y2)ρdτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#45,45,"Rotazioni attorno all’asse z:⃗P=Iω̂k
46z
xy
Prendo un sistema di N punti materiali simmetrico rispetto all’asse z in moto rotatorio con velocità  attorno ad un asse coincidente con l’asse di simmetria. →𝜔Sistemi simmetrici rispetto ad un asse hanno nell’asse di simmetria un asse principale
Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z si ha con →𝑃=𝐼𝑧𝑧→𝜔=𝐼𝑧𝑧𝜔^𝑘 𝐼𝑧𝑧=∑𝑁𝑖=1𝑚𝑖(𝑥2𝑖+𝑦2𝑖)"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#46,46,"Rotazioni attorno all’asse ⃗P=Iω̂k
47Per un sistema di N punti materiali simmetrico rispetto all’asse z
I    (cvd)→𝑃=𝐼→𝜔=𝐼𝑥𝑥𝐼𝑥𝑦0𝐼𝑥𝑦𝐼𝑦𝑦000𝐼𝑧𝑧00𝜔^𝑘=𝐼𝑧𝑧𝜔^𝑘z
xy
Per un sistema di N puntiPer un sistema esteso
Izz=∫V(x2+y2)ρdτ"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#47,47,"Dinamica rotazionale
48Dinamica rotazionale:
Analoga a :
Stessa struttura, stesse soluzioni. in generale è una variabile dinamica vettoriale descritta da 3 variabili scalari di tipo angolare che possono essere:  •2 variabili per indicare la direzione del vettore •1 variabile per l’intensità della velocità angolare.→𝜔𝑑→𝑃𝐶𝑀𝑑𝑡=→𝑀𝐸𝑆𝑇𝐶𝑀→𝑃=𝐼→𝜔𝑑→𝑣𝐶𝑀𝑑𝑡=→𝐹𝐸𝑆𝑇𝑀⟹𝑑→𝑣𝐶𝑀=→𝐹𝐸𝑆𝑇𝑀𝑑𝑡⇒→𝑣𝐶𝑀=𝑡∫0→𝐹𝐸𝑆𝑇𝑀𝑑𝑡+→𝑣0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#48,48,"Dinamica rotazionale
49
Caso più semplice: moti con asse di rotazione fisso (z): →𝜔=𝜔^𝑘
 diretto lungo l’asse z→𝑀𝐸𝑆𝑇𝐶𝑀=𝑀𝐸𝑆𝑇𝐶𝑀^𝑘𝐼𝑧𝑧𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀→𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧⟹𝑑𝜔=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡⇒Il momento d’inerzia rappresenta per la dinamica rotazionale ciò che la massa rappresenta nel moto traslatorio: fornisce l’inerzia del corpo rigido ad essere messo in moto rotatorio.𝜗(𝑡)=𝑡∫0𝜔(𝑡)𝑑𝑡+𝜗0𝜔(𝑡)=𝑡∫0𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡+𝜔0"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#49,49,"Esempio
50Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx =2𝑚(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)=⃗v1=d⃗r1dt=−·θRsinθ̂ı+·θRcosθ̂𝚥⃗v2=d⃗r2dt=−d⃗r1dt=−⃗v1⃗PCM=m⃗r1∧⃗v1+m⃗r2∧⃗v2=m⃗r1∧⃗v1+m(−⃗r1)∧⃗(−v1)=2m⃗r1∧⃗v1=2m⃗r1∧⃗v1=2m(Rcosθ̂ı+Rsinθ̂𝚥)∧(−R·θsinθ̂ı+R·θcosθ̂𝚥)==2𝑚˙𝜃𝑅2(𝑐𝑜𝑠2𝜃+𝑠𝑒𝑛2𝜃)^𝑘=2𝑚˙𝜃𝑅2^𝑘"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#5,5,"Primo teorema del Centro di Massa
6Velocità del Centro di massa:
Centro di massa:
Derivando:
Ricordando:⟹⟹"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#50,50,"Esempio
51Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.
θ(t)
yx→𝑃𝐶𝑀=𝐼→𝜔⟹2𝑚˙𝜃𝑅2^𝑘=𝐼→𝜔⟹{𝐼=2𝑚𝑅2→𝜔=˙𝜃^𝑘Caso  MEST =0  ⟹
𝑑𝑃𝐶𝑀𝑑𝑡=𝑀𝐸𝑆𝑇→𝑃𝐶𝑀=2𝑚˙𝜃𝑅2^𝑘Seconda equazione cardinaleCaso  MEST=cost  ⟹
  ˙𝜃(𝑡)=˙𝜃0+𝛼𝑡𝜃(𝑡)=𝜃0+˙𝜃0𝑡+12𝛼𝑡2"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#51,51,"Momenti d’inerzia di solidi
52Sbarra omogenea di massa M e lunghezza L: 
I=λx2dx−L2L2∫=λx33⎡⎣⎢⎤⎦⎥−L2L2=λ2L33⋅8=MLL33⋅4=ML212Disco omogeneo di raggio R e massa M: 
σ=MS=MπR2,dS=2πrdrI=σr22πrdr0R∫=2πσr44⎡⎣⎢⎤⎦⎥0R=2πMπR2R44=MR22Piastra rettangolare omogenea di lati a e b:
σ=MS=Mab,dS=dxdy
-a/2a/2b/2-b/2-L/2L/2"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#52,52,"Teorema di Huygens-Steiner
53Calcoliamo il momento d’inerzia rispetto ad un asse passante a distanza D                            dal CM (asse lungo z) per un sistema rigido di N punti materiali.
CMxyy’x’z’z
Per definizioneIntroduco il SR intrinseco
Il momento d’inerzia rispetto ad un asse qualunque è sempre pari al momento d’inerzia calcolato rispetto ad un asse parallelo a quello dato ma passante per il CM aumentato della quantità MD2 con D distanza tra i due assi.
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#53,53,"Teorema di König per corpi rigidi
54Energia cinetica di un sistema di punti materialiVelocità dei punti nel sistema del CM
αd
T=T'+TCM=12mivi'2i∑+12MvCM2
Energia cinetica di rotazioneEnergia cinetica di traslazioneCome si calcola l’energia cinetica totale di un corpo rigido?Ipotesi semplificata: corpo in rotazione istantanea attorno a un asse passante per il CM diretto lungo z."
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#54,54,"Statica dei corpi rigidi•Quando un corpo rigido è in condizioni statiche? (ànon si muove)
55
Equazioni cardinali della Dinamica dei sistemiR: Quando ogni punto del corpo è e rimane fermo!                      il corpo non trasla e non ruota!
Controllo forze e momenti esterni e questo garantisce che il corpo resti fermo per il 1°, 2° e 3° principio!"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#55,55,"Macchina di AtwoodDiscutere il moto dei due oggetti 1 e 2 appesi tra loro su una carrucola tramite un filo ideale nel caso: 1) la carrucola sia ideale; 2) la carrucola sia reale. 
56
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#56,56,"EsercizioUn’asta omogenea di sezione trascurabile, di massa m e lunghezza l giace su un piano orizzontale liscio inizialmente ferma ed incernierata in uno degli estremi. Ad un certo istante un punto materiale di massa 2m che si muove con velocità v0 urta in modo totalmente anelastico e perpendicolarmente l’asta nel suo centro. Calcolare le espressioni:  1)Della velocità angolare del sistema dopo l’urto; 2)Della reazione vincolare che agisce sul sistema dopo l’urto.57"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#57,57,"EsercizioUna forza costante di 1960 N applicata tangenzialmente al bordo di un disco di raggio R=100 cm ne fa variare la velocità angolare da 4 s-1 a 2 s-1 in 30 s. Determinare: -il momento d’inerzia della ruota attorno al suo asse;  -il modulo della variazione del momento angolare nei 30 sec considerati;  -l’angolo descritto dalla ruota in questo intervallo di tempo -l’energia cinetica persa.
58"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#58,58,"EsercizioUn disco omogeneo di massa M = 0.4 kg e raggio R = 10 cm viene appoggiato in verticale su un piano inclinato di 30° rispetto l’orizzontale. Sapendo che il disco scende rotolando senza strisciare, determinare la velocità di traslazione del disco dopo aver compiuto 2 m sul piano inclinato.
59"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#59,59,"EsercizioDue volani assimilabili a due dischi aventi massa e raggio rispettivamente di M1 = 187,5 kg, R1 = 80 cm, M2 = 120 kg e R2 = 50 cm ruotano attorno allo stesso asse fisso orizzontale coincidente con il loro asse di simmetria con velocità angolari di  e . Ad un certo istante I due volani vengono messi a contatto. Calcolare la velocità angolare finale trascurando gli effetti transienti.𝜔1=33 𝑟𝑎𝑑/𝑠𝜔2=2𝜔1
60"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#6,6,"Secondo teorema del Centro di Massa
7Accelerazione del Centro di massa:
Prima equazione cardinale→𝑎𝐶𝑀=𝑑→𝑣𝐶𝑀𝑑𝑡=𝑑(→𝑄𝑀)𝑑𝑡=1𝑀𝑑→𝑄𝑑𝑡=1𝑀→𝐹𝐸𝑆𝑇
Analogia formale  (e sostanziale) con: 
La 1a equazione cardinale descrive il moto di un punto fittizio che è il CM. Se il sistema non è soggetto a forze esterne, il CM si muove con velocità costante. "
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#60,60,"EsercizioUna Colonna di marmo di massa M = 600 kg ha la forma di un parallelepipedo a base quadrata di lato L = 30 cm e altezza h = 2.5 m ed è appoggiata in vertical su un piano ruvido inclinato di un angolo  rispetto l’orizzontale. Schematizzando la colonna come una figura piana che appoggia sul piano inclinator nei punti A e B distanti L determinare: 1)Il valore Massimo dell’angolo che permette la stabilità 2)La forza di attrito statica necessaria alla stabilità 3)Il minimo valore del coefficiente di attrito statico necessario per tenere ferma la colonna se 𝛼𝛼=5°
61
AB"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#61,61,"EsercizioDue punti materiali di massa M ruotano nel piano (x,y) attorno all’origine seguendo le equazioni del moto: Determinare le forze esterne ed i momenti delle forze esterne che agiscono sul sistema al tempo t=0.  
62θ(t)=α2t2+ϖ0t"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#62,62,"EsercizioUn disco di massa M = 0.5 kg, raggio R = 0.2 m e spessore trascurabile ha densità superficiale . Supponendo che il disco sia disposto orizzontalmente e ruoti attorno ad un asse verticale passante per il suo centro con velocità angolare  = 4 rad/s, calcolare l’energia cinetica del sistema.σ=kr⃗ω
63"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#63,63,"Esercizio
64Una sbarra omogenea di massa M e lunghezza L è appesa al soffitto tramite un filo collegato al suo centro di massa. La sbarra si muove in un piano orizzontale (x,y) e il filo esercita un debole momento delle forze dato da                          .       Calcolare il periodo del movimento.
xy
θ
"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#7,7,"Sistema di riferimento del CM
8
Posizione del CM rispetto al CMVelocità del CM rispetto al CM
Calcoliamo la posizione del CM nel sistema intrinsecoIl CM definisce un punto importante per capire la dinamica del sistema. La prima equazione cardinale riguarda il moto di questo punto.  Che cosa descrive la seconda equazione cardinale?E’ conveniente introdurre un nuovo sistema di riferimento S’ (in generale NON inerziale) che esalti il ruolo del CM: SR Intrinseco con origine coincidente col CM.
O
CM=O’
→𝑟𝑖
→𝑟𝐶𝑀"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#8,8,"Terzo teorema del centro di massa
9Riscriviamo il momento angolare nel SRI usando il sistema intrinseco:
=𝑁∑𝑖=1𝑚𝑖(→𝑟′ 𝑖+→𝑟𝐶𝑀)∧(→𝑣′ 𝑖+→𝑣𝐶𝑀)Sostituendo:=𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣′ 𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣𝐶𝑀+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣′ 𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣𝐶𝑀=𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖∧→𝑣′ 𝑖+(𝑁∑𝑖=1𝑚𝑖→𝑟′ 𝑖)∧→𝑣𝐶𝑀+→𝑟𝐶𝑀∧(𝑁∑𝑖=1𝑚𝑖→𝑣′ 𝑖)+(𝑁∑𝑖=1𝑚𝑖)→𝑟𝐶𝑀∧→𝑣𝐶𝑀=momento angolare del sistema calcolato rispetto al SR intrinseco⃗P′ CM=𝑀⟹𝑀→𝑟𝐶𝑀∧→𝑣𝐶𝑀Momento angolare di un punto di massa M situato nel CM Nulli per dimostrazione precedente⃗P0=N∑i=1⃗pi=N∑i=1mi⃗ri∧⃗vi"
data_test\rootfolder\università\FisicaGenerale\07-dinamica-sistemi.pdf#9,9,"Terzo teorema del centro di massa
10
Spin o momento angolare intrinseco
Terzo teorema del centro di massa: il momento angolare rispetto ad un polo O di un sistema di punti materiali è in ogni istante uguale alla somma del momento angolare del sistema calcolato nel sistema di riferimento del centro di massa e del momento angolare rispetto allo stesso polo O di un punto materiale di massa pari alla massa totale M del sistema collocato nel CM.⃗P0=⃗P′ CM+M⃗rCM∧⃗vCM=⃗P′ CM+⃗rCM∧⃗Q"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#0,0,Campo Gravitazionale CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#1,1,"Moto dei pianeti
2Meccanica diventa disciplina coerente dopo un’accurata e attendibile descrizione del moto dei pianeti: moto in assenza di attriti studiabile per lungo tempo -> metodo scientifico facilmente applicabile: Comprensione del moto -> previsione del moto -> verifica sperimentale.Principali risultati grazie a : -Tycho Brahe (1546-1601): misura di precisione delle posizioni dei pianeti -Johannes Kepler (1571-1630): formulazione leggi empiriche sui moti dei pianeti a partire dai dati di Brahe
"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#2,2,"Leggi di Keplero1.I pianeti descrivono orbite piane, ellittiche, di cui il Sole occupa uno dei due fuochi. 2.Il raggio vettore che unisce il centro del Sole con il centro del pianeta descrive aree uguali in tempi uguali. 3.I quadrati dei tempi che i pianeti impiegano a percorrere le loro orbite sono proporzionali al cubo del semiasse maggiore dell’orbita.3
a2T3=costante"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#3,3,"Gravitazione universale
4•Cosa fa girare i pianeti? •Moto può avvenire anche in assenza di forza (principio di inerzia), ma serve una “spinta” centripeta per mantenere il corpo in traiettoria curva. •Newton: pianeti si muovono sottoposti alla forza di gravità che è la stessa che fa cadere i corpi a Terra. •Che forma ha questa forza?"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#4,4,"5Velocità areolare
A(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#5,5,"Gravitazione universale
61a legge di Keplero: il moto avviene su un piano.Velocità areolare2a legge di Keplero: la velocità areolare è costante in modulo.
2o principio dinamica ⃗A=12(P−O)∧⃗v=12⃗r∧⃗vd⃗Adt=12ddt(⃗r∧⃗v)=12(d⃗rdt∧⃗v+⃗r∧d⃗vdt)=12(⃗v∧⃗v+⃗r∧⃗a)=12⃗r∧⃗a=⃗0Campo centrale a simmetria sferica"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#6,6,"Gravitazione universale
73a legge di Keplero:Moto dei pianeti può essere schematizzato come moto circolare uniforme 
Stessa struttura di quanto ipotizzato dalla 2a leggeDallo studio dei moti celesti:  con M=massa attorno a cui ruota m     GM=4π2kCostante di gravitazione universaleG=6,672⋅10−11N⋅m2kg2a2T3=costanteT=2πω→ω=2πT⃗a(t)=⃗at+⃗an=··ŝut+v2ρ̂un=v2ρ̂unT2=kR3⃗Fcentripeta=m⃗ac=mv2R̂un=mω2R̂un=m4π2T2R̂un⟹⃗Fcentripeta=m4π2T2R̂un=m4π2kR3R̂un=−m4π2kR2̂ur"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#7,7,"Legge di gravitazione universale
8
Un qualsiasi punto materiale P1 di massa m1 esercita su un qualunque altro punto materiale P2 di massa m2 una forza gravitazionale F12 diretta secondo la congiungente di P1 con P2, sempre attrattiva, in modulo direttamente proporzionale al prodotto delle due masse e inversamente proporzionale al quadrato della distanza fra P1 e P2. •Per il terzo principio della dinamica se P1 esercita una forza su P2 allora P2 esercita una forza  su P1 uguale e contraria •Sul sistema agiscono due forze di risultante nulla ma applicate in punti di applicazione diversi -> il moto è uno solo •La forza gravitazionale è conservativa poiché è un campo centrale a simmetria sferica -> esiste un potenziale gravitazionale ⃗F12⃗F21conˆr=P2−P1"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#8,8,"Energia potenziale gravitazionale
9Campo conservativo
Costante arbitrariaScelgo r0→∞⇒V(∞)=−Gm1m2r0=0V(A)=−Gm1m2rAEnergia potenziale gravitazionale"
data_test\rootfolder\università\FisicaGenerale\08-gravitazione.pdf#9,9,"Velocità di fuga
10
Velocità di fuga: velocità minima che occorre imprimere ad un corpo per far si che si allontani da un altro corpo senza ricadervi.Corpo in R si allontana in modo che arrivi all’infinito con velocità nullaConservazione dell’energia meccanica
12mvfuga2−GmMR=0⇒vfuga=2GMRG"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#0,0,1 Elettrostatica CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#1,1,"2Fenomeni elettriciFenomeni elettrici (e magnetici) noti dall’antichità
Teoria completa dei fenomeni elettrici (e magnetici) nella seconda metà XIX secolo: Volta, Ampère, Faraday, Maxwell, Ørsted 
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#10,10,"11Elettrizzazione per contatto
AC++++++++12Q+AB++++++++12Q+12Q+++++++++Fino a che punto possiamo suddividere (separare) la carica elettrica?
Limite della Natura la più piccola carica elettrica osservata fino ad ora in natura è quella dell’elettrone (-) e del protone (+)Cariche elettriche frazionar ie della carica elementari sono s tate ipotizzate  (quark confinati all’interno di protoni e neutroni) ma MAI osservate fino ad ora"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#11,11,"12La carica elettricaUnità di misura della carica elettrica nel Sistema Internazionale:  C  (Coulomb) Carica dell’elettrone:   qe= −1.6 × 10-19 C   Carica del protone:      qp= +1.6 × 10-19 C Limite sperimentale:                                                                   |qe| |qp||qp|    <⇡10 21"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#12,12,13La carica elettrica - esempiCarica degli elettroni in una goccia d’acqua (1g)  Ne=(Np)=3×1023     |Qe|=(|Qp|)=5×104 C  Forza tra due cariche da 1C ad 1m di distanza 9×109 N (equivalente a 100 Titanic!!)Carica in processi triboelettrici  |Q|=10-7C (1011 elettroni)1m1C1C×100
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#13,13,"14Proprietà carica elettricaEsistono due tipi di cariche elettriche  •convenzionalmente positive e negative La carica elettrica è quantizzata •in natura le cariche sono multiple della carica elettrica elementare  |qe|= 1.6 × 10-19−19 C In un sistema isolato, la carica elettrica si conserva •il numero totale di cariche (negative e positive) rimane invariato "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#14,14,15Interazioni tra cariche elettriche~F=m~aIpotesi iniziali (per il momento…) •Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra le cariche che interagiscono •Consideriamo solo cariche ferme (ELETTROSTATICA)
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#15,15,"16Forza elettrostaticaBilancia di torsione (Coulomb, fine XVIII sec)
𝜃Avvicinando la cariche q2 e q1, si arriva ad una situazione di equilibrio in cui la forza elettrica è bilanciata dalla forza di torsione del pendolo Felettrica=Ftorsione∝𝜃  Dalla misura dell’angolo 𝜃 si ricava l'intensità della forza elettrica.q1, q2 cariche  r distanza tra le cariche 𝜃 angolo di torsione|Fel|/|q1||q2|r2Sperimentalmente si osserva: ricordiamoci che la forza è un vettore…"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#16,16,"17Legge di Coulomb
z
y
x
q1q2SdR cartesiano ortogonaleForza esercitata dalla carica q1 sulla carica q2
Costante dielettrica del vuoto:q1 e q2  puntiformi~F12=14⇡""0q1q2r3~r~F12ha stessa direzione di~re verso che dipende dal segno delle cariche⃗F12=14πε0q1q2r2̂ur
(Farad verrà introdotto in seguito)ε0=8.85×10−12C2Nm2=8.85×10−12Fm14πε0=8.99×109Nm2C2⃗r=⃗r2−⃗r1⃗r1⃗r2⃗F12=q1q24πε0⃗r2−⃗r1|⃗r2−⃗r1|3⃗F12=14πε0q1q2r3⃗r"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#17,17,"18Legge di Coulomb~F21= ~F12III principio della dinamica (sistema isolato)Il vettore forza è applicato sulla caricaStesso segnoq1q2~r=~r2 ~r1~F12=14⇡""0q1q2r3~r~F21q1q2~r=~r2 ~r1~F12=14⇡""0q1q2r3~r~F21Segni opposti"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#18,18,"19Esercizio
𝜃 l m,q m,q l Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡""0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2 12p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema.(R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡""0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2 12p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema.(R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#19,19,"20Forza elettrica vs forza gravitazionaleForza ElettrostaticaForza GravitazionaleHanno stessa forma (entrambe dipendono dall’inverso del quadrato), ma… A. la forza elettrica è molto più intensa della forza gravitazionale B.la massa è sempre positiva (forza gravitazionale sempre attrattiva)14πε0=8.99×109 Nm2C−2G=6.67×10−11kg−1m3s−2⃗FCoulomb=14πε0q1q2r2̂ur⃗FGravitazionale=−Gm1m2r2̂ur"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#2,2,"3Fenomeni elettriciOsservazioni sperimentali (note da VI secolo A.C): oggetti di diversi materiali (es. vetro, plastica, ambra), dopo strofinio su panno di lana, se posti in vicinanza: •oggetti della medesima sostanza, si respingono •oggetti di sostanze diverse possono respingersi o attrarsi 
plastica
vetro
ambra
vetro
plastica
ambra
evidenza sperimentale esistenza di una forza"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#20,20,21EsempioCalcolare il rapporto tra le intensità della forza elettrica e di quella gravitazionale fra un elettrone ed un protone qe= −1.6 × 10-19 C       me= 1.9 × 10-31 kg  qp= +1.6 × 10-19 C       mp= 1.7 × 10-27 kg  G= 6.77 × 10-11 Nm-2kg-2 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#21,21,"22Forza elettrostatica e principio di sovrapposizione
q3q2q1Sistema di N=3 cariche puntiformiForza totale sulla carica q1 è la somma vettoriale della forza        che la carica q2  eserciterebbe su q1 se q3 fosse assente e della forza          che la carica q3  eserciterebbe su q1 se q2 fosse assente⃗F1=⃗F21+⃗F31⃗F21⃗F31⃗F31⃗F1⃗F21"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#22,22,"23Forza elettrostatica e principio di sovrapposizione
q
sistema di N cariche puntiformiForza totale sulla carica q è la somma vettoriale delle forze che le cariche qi eserciterebbero singolarmente su q se qj≠i fossero assentiqi⃗F=N∑i=1⃗Fi⃗ri⃗rivettore posizione da qi a qqj=N∑i=114πε0qqir3i⃗ri"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#23,23,"24Il campo elettrostaticoLa forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza •una carica Q altera le proprietà dello spazio, introducendo un campo elettrico    di cui Q è la sorgente •una seconda carica q (carica esploratrice) sentirà una forza dovuta alla presenza della carica Q⃗E⃗F
  !=lim""V#0""q""V=dqdVDistribuzioni Continue di Carica (II) •!Infine se la carica è distribuita in un volume conviene descrivere la distribuzione della carica utilizzando la densità volumetrica di carica (misurata in C/m3): •!Vogliamo ora calcolare la forza esercitata da una distribuzione di carica descritta dalla densità volumetrica & su di una carica puntiforme q posta a una certa distanza. •!Un volumetto elementare dV situato nel punto P) di vettore posizionale    conterrà la carica elettrica: !r!!r!r!!""r  dVVqr!!   dq=!!""r()dV25!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Distribuzioni Continue di Carica (III) •!Il volumetto dV può essere considerato come una carica puntiforme e dunque possiamo applicare a esso la legge di Coulomb: •!Per il principio di sovrapposizione, la forza totale prodotta su q dalla carica contenuta nel volume V sarà la somma dei contribuiti di tutti i volumetti infinitesimi dV: d!F=14!""0#!$r()dVdq""#$%$q!r%!$r3!r%!$r()!F=14!""0q#!$r()!r%!$r3!r%!$r()dVV&'((&'((&'((26!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!r!!r!r!!""r  dVVq!F12=14!""0q1q2r3!r
Campo Elettrico •!La forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza. •!Possiamo pensare che la presenza di una carica elettrica q1 posta nel punto P1 alteri le proprietà dello spazio, introducendo in esso un campo elettrico. •!Poniamo una carica puntiforme Q nell’origine di una terna cartesiana di riferimento e una seconda carica puntiforme q a una certa distanza r. La forza agente su q si può scrivere: !rqQ!F!r()=14!""0Qqr2ˆr=q14!""0Qr2ˆr#$%&'(!E!r()""#$%$=q!E!r()27!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!F12=14!""0q1q2r2ˆr
Campo Elettrico (II) •!Possiamo allora definire campo elettrico di una carica puntiforme Q il campo vettoriale: e scrivere la forza agente su di una carica q situata nel punto di raggio vettore    come:   !F!r()=q!E!r()   !E!r()=14!""0Qr2ˆrr!
28!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!rqQQ⃗Eq⃗E=limq→0⃗Fq⃗F=q⃗Elimite va inteso in senso “fisico”: • q è quantizzata  •possiamo trascurare i fenomeni di induzione dovuti a q"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#24,24,"25Campo elettrostatico di una carica puntiforme
z
y
xQq⃗rIn un SdR cartesiano poniamo: •carica sorgente Q nell’origine •carica esploratrice q in posizione  •q≪Q (trascuriamo il campo elettrico generato da q)⃗r⃗F(⃗r)=14πε0qQr2̂ur⃗E(⃗r)=14πε0Qr2̂ur
campo elettrostatico di una carica puntiforme Qla carica q è soggetta alla forza:⃗E=q14πε0Qr2̂ur=q⃗E(⃗r)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#25,25,"26Campo elettrostatico di una carica puntiformeL’azione della carica Q sulla carica q viene separata in due fasi distinte: • La creazione, da parte della carica Q, di un campo elettrico          in ogni punto dello spazio; •L’accoppiamento nel punto     del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico.  Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (V olt/metro)⃗E(⃗r)⃗E(⃗r)⃗r"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#26,26,"27Campo elettrico di una carica puntiforme
Campo centrale: •diretto come versore -uscente da Q positiva -entrante in Q negativa •modulo dipende solo da r ̂rIl campo elettrico è un campo vettoriale: per ogni punto dello spazio è associato un vettore
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!
Campo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!
  E!""#$=F!""#$Q!""#$=MLT%3I%1!""#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!
Campo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . 
30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()""E""#""""EP()!V
Integrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!""i=1n#!vPi()iˆnPi()!""i=1n#n$%!""$0&$&&I=!vP()iˆnd""""''31!
Integrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: 
Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=P""!3;P=P#,$(),#""#1,#2%&'(,$""$1,$2%&'({}!vP()iˆnd!!""""=d#!vP#,$()()i%P""!""%#&%P""!""%$'()*+,d$$1$2""#1#2""
32!⃗E(⃗r)=14πε0Qr2̂ur"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#27,27,"28Principio di sovrapposizione del campo elettricosistema di N cariche puntiformiDimostriamo cheq
qi⃗ri⃗E⃗F=q⃗E⃗F=N∑i=1⃗Fi=qN∑i=1[14πε0qir3i⃗ri]
principio di sovrapposizione del campo elettrico ⃗E=N∑i=1⃗Ei⃗Ei=14πε0qir3i⃗ri=N∑i=114πε0qqir3i⃗ri=N∑i=1q[14πε0qir3i⃗ri]==qN∑i=1⃗Ei=q⃗E"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#28,28,"29Distribuzioni continue di caricaSpesso la carica elettrica non è puntiforme ma può essere distribuita in un volume nello spazio, su di una superficie o lungo una linea⇢=l i m ⌧!0 q ⌧=dqd⌧ =l i m l!0 q x=dqdx =l i m S!0 q S=dqdSDensità volumetrica di caricaDensità superficiale di caricaDensità lineare di carica
dS
dl
d𝜏dq=ρdτcarica contenuta nel volumetto d𝜏  dq=σdS(C/m3)(C/m2)(C/m)
qτ=∭τρdτcarica contenuta nel volume 𝜏  carica contenuta sulla sup. dS  carica contenuta sulla sup S  carica contenuta sulla linea dl  carica contenuta sulla linea l   qS=∬SσdSql=∫lλdldq=λdl"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#29,29,"30Campo elettrostatico da distribuzioni continue
z
y
x
P⃗r−⃗r′ ⃗r⃗r′ Campo elettrico nel punto P generato da una carica infinitesima dq (contenuta in d𝜏):dq=ρ(⃗r′ )dτPer il principio di sovrapposizione  (e sostituendo al limite la somma con l’integrale)volume 𝜏d⃗E(⃗r)=dq4πε0(⃗r−⃗r′ )|⃗r−⃗r′ |3=ρ(⃗r′ )dτ4πε0(⃗r−⃗r′ )|⃗r−⃗r′ |3⃗E(⃗r)=14πε0∭τρ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dτ"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#3,3,"4Elettrizzazione per strofinio (triboelettricità)In natura esistono due tipi di elettrizzazione a cui possiamo associare due tipologie di cariche elettriche Convenzionalmente: •elettrizzazione vetrosa     à carica elettrica positiva •elettrizzazione resinosa   à carica elettrica negativa • cariche dello stesso segno: forza repulsiva • cariche di segno opposto: forza attrattiva
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#30,30,"31Campo elettrostatico da distribuzioni continue
dl
dS
d𝜏Carica distribuita  in volume 𝜏Carica distribuita  su superficie SCarica distribuita  su linea l
Warning! formule generali da usare con attenzione: il calcolo degli integrali può risultare complesso, non fare confusione tra r (posizione del punto in cui si vuole calcolare il campo) e r’ (variabile di integrazione, relativa alla posizione delle cariche)⃗E(⃗r)=14πε0∫lλ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dl⃗E(⃗r)=14πε0∭τρ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dτ⃗E(⃗r)=14πε0∬Sσ(⃗r′ )(⃗r−⃗r′ )|⃗r−⃗r′ |3dS"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#31,31,32Il campo elettrico è un campo conservativo?
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#32,32,33PremessaFino ad ora ci siamo posti in condizioni statiche: le cariche sono ferme → ELETTROSTATICA Non abbiamo ancora studiato gli effetti delle cariche in moto   (esistono forze associate ai movimenti delle cariche?) Per il momento continuiamo la trattazione statica: il campo elettrostatico è conservativo?Andiamo a verificare una delle condizioni di conservatività dei campi 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#33,33,"34Circuitazione del campo elettrostaticoCalcoliamo la circuitazione del campo lungo la linea chiusa 𝛤 : circonferenza di raggio R centrata in Q 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!Qd⃗l=̂utdl
∮Γ⃗E⋅d⃗l=∮ΓQ4πε0r2̂ur⋅̂utdl`=0
Il campo elettrico (elettrostatico) generato da una carica puntiforme ferma è conservativo𝛤Circuitazione nullâr"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#34,34,"35Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi∮Γ⃗E⋅d⃗l=0⃗∇∧⃗E=⃗0Il campo elettrostatico ha sempre circuitazione nullaIl campo elettrostatico è  irrotazionale  (non esistono linee di campo chiuse su loro stesse)Equazioni fondamentali dell’elettromagnetismo, applicate al caso statico (cariche ferme)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#35,35,"36Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi
∃ una funzione scalare V(x,y,z):⃗E=−⃗∇VV(x,y,z) è il potenziale elettrostatico ⃗E⋅d⃗l=−dVè un differenziale esattoV(A)−V(B)=∫BA⃗E⋅d⃗lL’integrale non dipende dal percorsometodo per calcolare  il potenziale, partendo dal campo elettrostaticometodo per calcolare  il campo elettrico, partendo dal potenziale ∃ una funzione scalare V(x,y,z):⃗E=−⃗∇V"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#36,36,"37Il potenziale elettrostaticoIl potenziale elettrostatico V(x,y,z) è una funzione scalare in ℝ3   Dato un campo elettrostatico, operativamente il potenziale si calcola integrando il differenziale esattodV=−⃗E⋅d⃗lIl potenziale è definito a meno di una costante additiva arbitraria La differenza di potenziale tra due punti è indipendente dalla costante arbitraria (è una grandezza misurabile → circuiti) integrale indefinitointegrale definitoV(A)−V(B)=∫BA⃗E⋅d⃗lV(x,y,z)=−∫⃗E⋅d⃗l+costL’unità di misura del potenziale nel S.I. è il Volt=Joule/Coulomb  (V)=(J)/(C)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#37,37,"38Il potenziale elettrostatico: carica puntiformeV(⃗r)=−∫⃗E⋅d⃗l+cost
Qd⃗l=̂rdr+̂u⊥dl⊥̂u⊥dl⊥d⃗l̂urdr⃗E=Q4πε01r2̂urV(⃗r)=[−∫Q4πε01r2̂ur⋅(̂urdr+̂u⊥dl⊥)]+cost=[−∫Q4πε01r2(̂ur⋅̂urdr+̂ur⋅̂u⊥dl⊥]+costCalcoliamo V dall’integrale indefinito lungo una generica curva 𝛤  =[−Q4πε0∫drr2]+costV(⃗r)=14πε0Qr+cost𝛤in genere si fissa il potenziale nullo all’infinito:=−Q4πε0(−1r)+cost=14πε0Qr+cost⃗r`1`0V(⃗r→∞)=0⇒14πε0Q(r→∞)+cost=0⇒cost=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#38,38,"39Il potenziale elettrostatico: carica puntiforme
QAB⃗Ecalcoliamo la differenza di potenziale tra i punti A e BΔVAB=VA−VB=∫BA⃗E⋅d⃗l=...=Q4πε0[−1r]BA=Q4πε0(1rA−1rB)=14πε0QrA−14πε0QrBrBrAVA=V(⃗rA)=14πε0QrAVB=V(⃗rB)=14πε0QrBAssumendo il potenziale nullo all’infinito (cost=0)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#39,39,40Principio di sovrapposizione del potenzialeDemo: basta usare la proprietà distributiva del prodotto vettorialeUn campo elettrostatico generato da N cariche discrete o da una distribuzione continua di carica è conservativo⃗∇∧⃗E=⃗∇∧(∑⃗Ei)=∑⃗∇∧⃗Ei=⃗0principio di sovrapposizionecampo da carica puntiforme irrotazionaleV(⃗r)=−∫⃗E⋅d⃗l=−∫(∑⃗Ei⋅d⃗l)=∑∫−⃗Ei⋅d⃗l=∑Vi(⃗r)Il potenziale elettrostatico generato da un sistema di cariche gode del principio di sovrapposizione
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#4,4,"5La struttura microscopica della materiaTutti i  materiali formati da atomi (e molecole) Gli atomi sono composti da •nucleo formato da protoni (carichi positivamente) e neutroni (neutri) •attorno al nucleo orbitano gli elettroni (carichi negativamente)
La Forza Elettromagnetica nella Fisica Moderna (II) •!La forza elettromagnetica è la forza dominante nel mondo fisico che conosciamo: –!Tiene uniti gli elettroni al nucleo negli atomi. –!Tiene uniti gli atomi nelle molecole; –!È all’origine delle forze elastiche; –!È all’origine delle forze di tensione delle funi; –!È all’origine delle forze di attrito; –!È all’origine delle forze di resistenza; –!È all’origine delle forze di tensione superficiale dei liquidi; –!È all’origine delle forze di urto; –!È all’origine delle reazioni vincolari. 9!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
La Forza Elettromagnetica nella Fisica Moderna (III) 
10!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Non hanno origine elettromagnetica poche forze comunemente note, tra cui: –!La forza peso (forza gravitazionale); –!La forza che mantiene i pianeti sulle loro orbite (forza gravitazionale); –!La forza che tiene uniti i quark nei nuclei degli atomi (forza nucleare forte). 
La Composizione della Materia molecolaatomonucleoelettrone
protoneneutronequark10 cm!810 cm!12
10 cm!1310 cm!13(<10 cm)!1811!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
I Costituenti della Materia: le Particelle Elementari (Fermioni) 
12!Domenico Galli – Fisica Generale B – 1. Elettrostatica!1 MeV/c2 = 1.783 ! 10–30 kg  Q=23eQ=!13eu d e !e c s µ""!µ""t b #""!#""elettrone up down neutrino elettronico neutrino muonico neutrino tauonico muone tauone charm strange top bottom m = 0 m = 0 m = 0 m = 0.5 MeV/c2 m = 8 MeV/c2 m = 15 MeV/c2 
m = 170000 MeV/c2 m = 4500 MeV/c2 m = 106 MeV/c2 m = 1800 MeV/c2 m = 1600 MeV/c2 m = 300 MeV/c2 leptoni quark Esistite subito dopo il Big Bang. Ora presenti nei raggi cosmici e negli acceleratori Q=!eMateria ordinaria 
1 e = 1.602 ! 10–19 C  
La materia ordinaria risulta complessivamente neutra  (stesso numero di protoni ed elettroni) Perché?"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#40,40,"41Potenziale: sistema di N cariche puntiformisistema di N cariche puntiformi
qi⃗riP(x,y,z)V(x,y,z)=N∑i=1Vi(x,y,z)=N∑i=114πε0qiriIl potenziale in un punto P(x,y,z) è dato dalla somma algebrica dei singoli potenziali generati dalle cariche qi singolarmente "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#41,41,"42Potenziale: sistemi continui di cariche
z
y
x
P(x,y,z)⃗r−⃗r′ ⃗r⃗r′ dqCarica volumetricaCarica superficialeCarica lineare Warning! come per il campo elettrico, queste sono formule generali da usare con attenzioneV(x,y,z)=14πε0∫dq|⃗r−⃗r′ |V(x,y,z)=14πε0∭τρ(⃗r′ )dτ|⃗r−⃗r′ |V(x,y,z)=14πε0∬Sσ(⃗r′ )dS|⃗r−⃗r′ |V(x,y,z)=14πε0∫lλ(⃗r′ )dl|⃗r−⃗r′ |"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#42,42,"x
Exd2−d2
43EsempiSiano date due cariche uguali q+ posizionate sull’asse y di un SdR cartesiano a distanza d dall’origine. Determinare l’espressione del campo e del potenziale elettrostatico sull’asse x.
x
d
⃗E(x,0,0)=q2πε0x(x2+d2)3/2̂ı
y"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#43,43,44EsempioDeterminare il campo ed il potenziale elettrostatico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 ⃗E=λ2πε0r̂ur ortogonale al filo
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#44,44,"z
Ez45EsempioDeterminare il campo elettrostatico sull’asse di un anello di raggio R su cui è depositata uniformemente una carica Q⃗E=Q4πε0z(z2+R2)32̂k"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#45,45,46EsempioDeterminare il campo elettrostatico sull’asse di un disco di raggio R su cui è depositata uniformemente una carica Q⃗E=Qz2πε0R2[1|z|−1(z2+R2)12]̂k
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#46,46,"47EsempioDeterminare la differenza di potenziale elettrostatico tra due piani indefiniti paralleli, posti a distanza d, su cui è depositata uniformemente una densità superficiale di carica uguale ed opposta
  +𝜎-𝜎d"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#47,47,"48Esempio1.7Una sottile barra di plastica ha una densit` a lineare di carica positiva uniforme. La barra ` e curvata a formadi semicerchio di raggioR. Determinare:a) il potenziale elettrostatico nel centroOdel semicerchio (V= 4✏0);b) il campo elettrostatico nel puntoO(~E=  2⇡✏0Rˆ|)1.8Calcolare il campo elettrostatico nei punti dell’assexdi un anello di raggioRuniformemente carico concaricaQ. Descrivere il moto di una caricaq(opposta aQ) e massamche si trova inizialmente ferma inun punto dell’asse vicino al centro dell’anello. (R:~E=Q4⇡✏0x(x2+R2)32ˆı, oscillatore armonico con pulsazione!=qqQ4⇡✏0mR3)1.9Calcolare il campo elettrico lungo l’assexdi un disco di raggioRcaricato uniformemente con densit` a dicarica .( R :~E= x2✏0[1|x| (x2+R2) 12])1.10Sia dato un guscio sferico di raggioRe di spessore trascurabile su cui ` e distribuita uniformemente una caricatotaleQ. Calcolare il campo elettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardalcentro del sistema.1.11Sia data una sfera di raggioRin cui ` e distribuita uniformemente una carica totaleQ. Calcolare il campoelettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardal centro della sfera.1.12Sia data una sfera di raggioRnel cui volume presente una carica distribuita con densit` a di volume⇢(r)=kr,conkcostante. Calcolare:a) la carica totaleQdella sfera (R:Q=⇡kR4);b) il campo elettrostatico in tutto lo spazio, in funzione della distanzardal centro della sfera (R:~E(r<R)=kr24""0ˆr,~E(r>R)=kR44""0r2ˆr);c) il potenziale elettrostatico in un generico punto interno della sfera a distanzardal centro (R:V(r)=k12""0(4R3 r3)).1.13Sia data un cilindro di raggioRe altezza indeﬁnita in cui ` e distribuita uniformemente una carica con densit` avolumetrica di carica⇢. Calcolare:a) il campo elettrostatico in tutto lo spazio, in funzione della distanzardall’asse del cilindro;b) il potenziale elettrostatico in tutto lo spazio, imponendo che il potenziale sia nullo sulla superﬁcie delcilindro.1.14Si consideri un volume sferico di raggioRin cui ` e presente una caricaQdistribuita con densit` a⇢(r)dipendente dalla distanza radialerdal centro della sfera. Sapendo che il campo elettrico all’interno dellasfera ha modulo costante ed ` e diretto radialmente, determinare l’espressione della densit` a di carica⇢(r). (R:⇢=Q2⇡R2r)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#48,48,"49Il lavoro della forza elettrostaticaSe il campo elettrostatico è conservativo ⇒ la forza elettrostatica è conservativaℒel=∫BA⃗Fel⋅d⃗l=∫BAq⃗E⋅d⃗l=q∫BA⃗E⋅d⃗l=q(VA−VB)=qΔVAB⃗Fel=q⃗EIl lavoro fatto dalla forza elettrostatica per spostare una carica q dalla posizione A alla posizione BLa forza elettrostatica (di Coulomb) è proporzionale al campo elettrico
Dato che la forza elettrostatica è conservativa, il lavoro non dipende dal percorso"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#49,49,50L’energia elettrostaticaPossiamo definire l’energia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale VUE=qVLa variazione di energia potenziale corrisponde alla variazione di energia cinetica Tin+Uin=Tfin+Ufin⇒ΔT=−ΔUEU si misura in Joule (J) In Fisica delle Particelle si usa l’elettronvolt: (energia cinetica di una carica elementare accelerata da un V olt) 1eV = qe𝛥V =(1.6×10-19 C)×(1V)=1.6×10-19 J Forza elettrostatica conservativa ⇒ energia meccanica totale (cinetica+potenziale) si conserva        ℰ=T+UE
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#5,5,6Lo strofinio produce uno spostamento di elettroni da un materiale all’altro.  Sfregando tra di loro i due materiali: •il più alto nella lista si carica ⊕ (cede elettroni) •il più basso nella lista si carica ⊝ (acquista elettroni)Serie triboelettricacuoio vetro capelli lana seta alluminio carta legno ambra gomma argento oro plastica PVC silicone teflonperché sono gli elettroni a spostarsi e non i protoni?
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#50,50,"51Moto di una carica in un campo elettrostatico Un oggetto di massa m e carica q posto in un campo elettrostatico è soggetto alla forza elettrostatica⃗F=q⃗E=m⃗a⃗a=d2⃗rdt2=qm⃗ENote le condizioni iniziali possiamo determinare le equazioni del moto Dato che il campo elettrostatico è conservativo, si può utilizzare anche la conservazione dell’energiaΔT=−ΔUe"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#51,51,"52Esempio: moto carica in campo costante
+𝜎Campo piano indefinitoDeterminare la velocità di una particella di massa m e carica q(+), inizialmente ferma (vA=0) su un piano uniformemente carico positivamente, dopo che ha percorso una distanza D
ABa=qmE=qmσ2ε0costante, moto uniformemente acceleratovB=vA+atxB=xA+vAt+12at2v2B−v2A=2a(xB−xA)vB=qmσε0DTB−TA=UA−UBTB=12mv2BTA=0UA−UB=q(VA−VB)=q∫BA⃗E⋅d⃗l==q∫BAσ2ε0dx=qσ2ε0(xB−xA)=qσ2ε0D12mv2B=qσ2ε0Dv2B=2qmσ2ε0DDin alternativa (conservazione energia)⃗E=σ2ε0̂ıx"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#52,52,"53Esempio: deflessione in doppio strato-𝜎+𝜎
xy
m, q+⃗v0=v0x̂ı⃗E=σε0̂𝚥
𝛼Calcolare l’angolo di deflessione di una particella di massa m e carica q che attraversa con velocità iniziale v0x un doppio strato di lunghezza LL"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#53,53,"54EsempioTre particelle identiche, aventi massa m e carica q,  sono poste ai vertici di un triangolo equilatero di lato L. Inizialmente le cariche sono ferme. Ad un certo istante una delle tre cariche viene lasciata libera. Determinare la velocità che la carica acquista dopo aver percorso una distanza L (risolvere per m=2 kg, q=5𝜇C, L=3m)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#54,54,"55Integrale di superficie una funzione vettorialeSiano date in ℝ3 una funzione vettoriale e una superficie S ⃗F(x,y,z)
nel limite N→∞ e 𝛥Si→0 , definiamo l’integrale di superficie di una funzione vettoriale
S𝛥SîniPi⃗F(Pi)αîniSuddividiamo S in N superfici infinitesime 𝛥Si e consideriamo su di esse i punti Pi(xi,yi,zi), i corrispondenti versori      normali a 𝛥Si  N∑i=1⃗F(Pi)⋅̂niΔSi=N∑i=1F(Pi)cosαiΔSi∬S⃗F⋅̂ndSconsideriamo  la somma ⃗F(x,y,z)"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#55,55,"56Flusso di un campo vettorialeIl concetto di flusso viene introdotto nello studio della dinamica dei fluidi Consideriamo un tubo (di sezione infinitesima) attraversato da un fluido incompressibile (es H20) con velocità     d⃗S=̂ndS⃗vIl flusso del fluido attraverso una sezione dS del tubo è definito:dΦ=⃗v⋅̂ndSNotazione alternativa:dΦ=⃗v⋅d⃗Srisolvendo il prodotto scalare:
̂n⃗vαdSd𝛴sezione trasversa d𝛴=dS cos𝛼dΦ=vdScosα=vdΣ"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#56,56,"57Flusso di un campo vettorialeConsiderando più tubi (di flusso) su una generica superficie S 
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso del campo vettoriale     attraverso la superficie S⃗vΦs(⃗v)=∬S⃗v⋅̂ndS"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#57,57,"58Linee di flusso di un campo vettoriale
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnConsideriamo la traiettoria 𝛾 di una particella del fluido  ➡  in ogni punto la traiettoria è tangente alla velocità vettoriale della particella La linea di flusso 𝛾 è una linea sempre tangente al vettore velocità delle particelle che si trovano nei punti della linea"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#58,58,"59Linee di flusso del campo elettricoAnche per il campo elettrico possiamo rappresentare graficamente le linee di flusso (o linee di campo) • tangenti in ogni punto al vettore campo elettrico • orientate con il verso del campo elettrico • in numero (per unità di superficie trasversale), proporzionali al modulo del campo elettrico 
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#59,59,"Classificazione delle superfici • aperta: compatta e con bordo • chiusa: compatta e priva di bordo • orientabile: ha due facce
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆnAperta e orientabile
Sfera: chiusa e orientabileToroide: chiusa e orientabileNastro di Möbius: aperta e non orientabileBottiglia  di Klein: chiusa e  non-orientabile60Superfici in ℝ3"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#6,6,"7Isolanti e conduttoriisolanti  •la carica elettrica resta localizzata  •vetro, plastica, gomma conduttori  •cariche libere di muoversi •metalli warning: classificazione un po’ riduttiva (liquidi, semiconduttori,…)                  nota: inizieremo con esempi di materiali isolanti, i conduttori saranno trattati in seguito"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#60,60,"61Superfici chiuse e orientabili in ℝ3Nelle superfici chiuse e orientabili, in ogni punto della superficie  possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi si utilizza la normale esterna   :  positivo il flusso uscente dal volume delimitato dalla superficie chiusa negativo il flusso entrante nel volume delimitato dalla superficie chiusân
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n
Linee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. 
41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Linee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. 
42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1
Superfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. 
43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Aperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) 
Superfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. 
44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!
ˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#61,61,"Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('62Superfici aperte e orientabili in ℝ3Nelle superfici aperte non possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi attraverso una superficie aperta si utilizza l’orientamento    indicato dalla regola della mano destra sulla base dell’orientamento della linea del bordo:̂n"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#62,62,"63L’angolo solidorl𝛼Angolo piano rapporto tra arco di circonferenza l e raggio r
r𝛺𝛴Angolo solido rapporto tra la parte di superficie sferica 𝛴 intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera α=lr∈[0,2π[L’angolo solido si misura in steradianti (sr)Ω=Σr2∈[0,4π]dα=dlrinfinitesimoinfinitesimodΩ=dΣr2"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#63,63,64Il flusso del campo elettricod𝛴̂nαdS⃗Eprendendo la superficie d𝛴 ortogonale al campo elettrico:Flusso infinitesimo del campo elettrico attraverso una superficie dSdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso del campo elettrico attraverso una superficie estesa SΦS(⃗E)=∬S⃗E⋅̂ndS=∬SEcosαdS=∬SEdΣdΣ=dScosα
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#64,64,"65Il flusso del campo elettricoConsideriamo ora una superficie chiusa contenente al suo interno una carica elettrica puntiforme q̂n
d𝛴dSqdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso attraverso l’intera superficie S  (             ):∬SdΩ=4πil flusso dipende solo dall’angolo solido perché E è radialeΦS(⃗E)=∬S⃗E⋅̂ndS=qε0Notazione per integrale su superficie chiusaFlusso infinitesimo attraverso un elemento dS:α
ΦS(⃗E)=∬SdΦS=∬S⃗E⋅̂ndS=q4πε0∬SdΩ=qε0=(q4πε0r2)(r2dΩ)=q4πε0dΩ⃗E"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#65,65,"66Il flusso del campo elettrico
d𝛴2d𝛴1
r1r2dΩ=dΣ1r21=dΣ2r22Se q è esterna alla superficie chiusa, il numero di linee di campo che entrano nella superficie è uguale al numero di linee di campo che escono dalla superficie
d𝛴2dS2q
d𝛴1dS1̂n1̂n2α1α2⃗E1⋅̂n1=cosα1<0⃗E2⋅̂n2=cosα2>0
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(−r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)=⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2
dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0Flusso attraverso l’intera superficie:Flusso infinitesimo:=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0ΦS(⃗E)=∬S⃗E⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#66,66,"67Il flusso del campo elettricoSe all’interno della superficie chiusa ci sono N cariche qi puntiformi, per il principio di sovrapposizione del campo elettrico, il flusso vale: dove QS è la carica contenuta all’interno della superficie S q3q2q5q7q6q1q8q4qN×××S𝜏(S)QS=∑iqintQS=∭τ(S)ρdτΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Cariche discrete Cariche distribuite su continuo V olume 𝜏(S) contenuto in superficie S "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#67,67,68La Legge di Gauss del campo elettricoIl flusso del campo elettrico attraverso una superficie chiusa S è uguale al rapporto tra la carica elettrica QS contenuta all’interno della superficie e la costante dielettrica ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#68,68,69EsempiDeterminare il campo elettrico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 (usando la legge di Gauss) 
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#69,69,70EsempiDeterminare il campo elettrico generato da un piano indefinito su cui è depositata uniformemente una carica con densità superficiale 𝜎 (usando la legge di Gauss)
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#7,7,"8Elettrizzazione per induzione (elettrostatica)
Elettroscopio a foglieAvvicinando un corpo carico all’elettroscopio, le foglie metalliche (conduttori) si allontanano Le componenti metalliche “sentono"" la vicinanza di carica elettrica L’effetto svanisce quando si allontana la carica"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#70,70,71EsempiDeterminare il campo elettrico ed il potenziale generato da un guscio sferico di raggio R su cui è depositata uniformemente una carica Q
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#71,71,72EsempioSia data una sfera di raggio R contenente una carica Q distribuita uniformemente. a) Determinare il campo elettrostatico in tutto lo spazio b) Calcolare il potenziale in un generico punto  esterno alla sfera (assumendo nullo il potenziale all’infinito) c) Calcolare il potenziale in un generico punto  interno alla sfera (assumendo nullo il potenziale all’infinito) d) Calcolare la differenza di potenziale tra il centro e la superficie della sfera
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#72,72,"73La divergenza di un campo vettoriale
Consideriamo il flusso di un campo  vettoriale     attraverso una superficie chiusa S che delimita un volume 𝜏⃗FΦS(⃗F)=∬S⃗F⋅̂ndSDividiamo idealmente il volume 𝜏  in due volumi 𝜏1 e 𝜏2, usando una superficie di separazione D (diaframma). Siano S1 e S2 le superfici chiuse che delimitano 𝜏1 e 𝜏2 (D⊂S1,S2)𝜏SD𝜏2𝜏1S1S2Possiamo riscrivere il flussoΦS(⃗F)=∬S1⃗F⋅̂ndS1+∬S2⃗F⋅̂ndS2̂n2̂n1i contributi al flusso attraverso D si annullano⃗F⋅̂n1D=−⃗F⋅̂n2D"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#73,73,"74La divergenza di un campo vettorialeSuddividendo il volume 𝜏 in N volumi 𝜏i , limitatati da altrettante superfici SiDefinizione di divergenza di un campo vettorialediv⃗F=limτi→0ΦSi(⃗F)τiΦSi(⃗F)=∬Si⃗F⋅̂nidSiΦS(⃗F)=N∑i=1ΦSi(⃗F)La divergenza è il flusso uscente per unità di volume  • è una grandezza scalare, funzione delle coordinate • può variare da punto a punto𝜏iSi⃗FS𝜏⃗∇=(∂∂x,∂∂y,∂∂z)=∂∂x̂ı+∂∂ŷ𝚥+∂∂ẑkdiv⃗F=⃗∇⋅⃗FUtilizzando l’operatore “nabla”:"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#74,74,"75Il teorema della divergenzaIl flusso di un campo vettoriale attraverso una superficie S chiusa è pari all’integrale sul volume 𝜏 (delimitato da S !!!) della divergenza di tale campo vettoriale ∬S⃗F⋅̂ndS=∭τdiv⃗Fdτ=N∑i=1τi∬Si⃗F⋅̂nidSiτiNel limite N →∞ e 𝜏i →d𝜏, sostituiamo 𝛴→∫∫∫ ⟶∭τdiv⃗FdτΦS(⃗F)=∬S⃗F⋅̂ndS=N∑i=1∬Si⃗F⋅̂nidSiIl teorema della divergenza è una relazione tra un integrale di superficie e un integrale di volume"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#75,75,"76La legge di Gauss in forma localeCombiniamo il teorema della divergenza e la legge di Gauss, in presenza di una distribuzione continua di carica∭τ(S)div⃗Edτ=∭τ(S)ρε0dτdiv⃗E=ρε0∬S⃗E⋅̂ndS=∭τ(S)div⃗Edτ∬S⃗E⋅̂ndS=∭τ(S)ρε0dτLegge di GaussTeorema della divergenzaGli integrali sono sullo stesso volume"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#76,76,"77Significato fisico della divergenzaLa divergenza di un campo ci da un’informazione sul comportamento locale delle linee di campo le linee di campo si incontrano nei punti in cui la divergenza del campo è diversa da zero: • convergono nel punto se il valore della divergenza è negativo • divergono dal punto se il valore della divergenza è positivo In un punto in cui la divergenza è nulla, le linee di campo non si incontrano Se un campo ha divergenza sempre nulla, allora esso si definisce solenoidale"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#77,77,"78Significato fisico della divergenzadiv⃗E=ρε0Il campo elettrico ha divergenza non nulla solo nei punti in cui esiste una densità di carica Nel vuoto, la divergenza del campo elettrico è nulla 
z
y
x⃗r⃗r′ In tali punti, le linee di campo si incontranodiv⃗E(⃗r′ )=ρ(⃗r′ )ε0div⃗E(⃗r)=0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#78,78,"79Potenziale e legge di GaussLegge di Gauss in forma locale⃗∇⋅⃗E=ρε0⃗E=−⃗∇V⃗∇⋅(−⃗∇V)=ρε0∇2V=−ρε0Campo elettrostaticoEquazione di Poisson
Il laplaciano del potenziale è proporzionale alla densità di carica Equazione alle derivate seconde, note le condizioni al contorno ammette un’unica soluzione∂2V∂x2+∂2V∂y2+∂2V∂z2=−ρε0"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#79,79,80EsempioCalcolare la divergenza del campo e il flusso attraverso una superficie sferica di raggio R centrata nell’origine ⃗F=k⃗r
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#8,8,"9Elettrizzazione per induzione (elettrostatica)
Elettrizzazione per induzione anche su materiali isolanti
Microscopicamente, le molecole della carta “risentono” la vicinanza di cariche elettriche "
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#80,80,"81Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
"
data_test\rootfolder\università\FisicaGenerale\09-elettrostatica.pdf#9,9,"10Elettrizzazione per contatto
In caso di contatto, parte della carica si trasferisce (e resta) sul conduttoreCaso particolare: due conduttori di stessa forma e dimensione; inizialmente A ha una carica Q+Dopo aver messo in contatto A e B, la carica si ridistribuisce in parti ugualiAB++++++++++++++++Q+
AB++++++++12Q+12Q+++++++++
Carica totale si conserva!"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#0,0, Elettrostatica dei conduttori CdS Ingegneria Informatica A.A. 2019/20
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#1,1,"2Materiali isolanti e conduttoriisolanti  •le carica elettrica restano localizzate, sono vincolate a muoversi all’interno delle molecole •Un campo elettrico esterno non produce movimento di cariche, se non su piccolissima scala: deformazione e orientamento delle molecole (azioni sui dipoli) conduttori  •cariche (elettroni di conduzione) libere di muoversi sul conduttore (moto su reticolo cristallino) •comportamento degli elettroni simile ad un gas •in presenza di un campo esterno o di un eccesso di carica, le cariche si redistribuiscono sul conduttore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#10,10,"11Campo elettrico in prossimità della superficie dei conduttori
In presenza di un conduttore, le linee di campo esterne vengono deviate dalla presenza di addensamenti locali di carica sulla superficie del conduttoreVicino al conduttore le linee di campo esterne saranno sempre perpendicolari alla superficie"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#11,11,12Campo elettrico in prossimità della superficie dei conduttori⃗E=ÊnCalcoliamo il flusso attraverso un cilindretto di dimensioni infinitesime • asse ortogonale a superficie conduttore • contributo al flusso solo da base esterna⃗E=0dΦ(E)=⃗E⋅̂ndS=EdSFlusso attraverso base infinitesimaCarica contenuta nel cilindro (intersezione con la superficie del conduttore)dQS=σdSapplicando la legge di GaussEdS=σε0dSE=σε0
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#12,12,"13Teorema di Coulomb⃗E=σε0̂nIl campo elettrostatico in prossimità dei conduttori è sempre ortogonale alla superficie del conduttore ed il modulo è proporzionale alla densità superficiale di carica La densità superficiale di carica 𝜎=𝜎(x,y,z) può variare sulla superficie, di conseguenza varierà anche l’intensità del campo elettrico Il campo elettrico subisce una discontinuità nel passaggio dall’esterno all’interno del conduttore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#13,13,"14Conduttori caviSulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
S⃗E=0ΦS(⃗E)=QSε0=0La prima affermazione si dimostra applicando la legge di Gauss, utilizzando la condizione che il campo elettrico interno al conduttore è nullo"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#14,14,"15Conduttori cavi
-+++++----⃗E≠0⃗E=0𝛤Ipotesi (per assurdo): distribuzioni locali di carica sulla superficie interna⇒ campo all’interno della cavità non nullo ⇒ circuitazione lungo linea chiusa 𝛤 non-nulla⇒ violazione della conservatività del campo elettrostatico Sulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate 
"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#15,15,"16Schermo elettrostatico
  Se un conduttore dotato di cavità viene esposto a un campo elettrico esterno, il campo elettrico all’interno della cavità è comunque nullo e non vi sono cariche elettriche indotte sulla superficie della cavità stessa.    In altre parole il conduttore scherma l’interno della cavità dai campi elettrici all’esterno (gabbia di Faraday)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#16,16,"17Induzione completa
+QQ’’=+Q+++
++++
+Q’=-Q--------⃗E≠0Poniamo una carica puntiforme all’interno della cavità di un conduttore neutroLa carica genera un campo con linee radiali che poi curvano per diventare perpendicolari alla superficie interna induzione completa: tutte le linee di forza si chiudono sul conduttore Sulla superficie interna si induce una carica Q’ complessivamente uguale e opposta a +QSGauss è salvo: Q+Q’=0Conduttore neutro ⇒ carica Q’’=+Q indotta sulla superficie esterna⃗E=0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#17,17,"18Induzione completa
+QQ’’=+QQ’=-Q+++++++++++
++++
+--------⃗E≠0Poniamo all’interno della cavità una generica carica (anche su un conduttore)  Un conduttore cavo trasferisce sulla propria superficie esterna una carica uguale al valore complessivo delle cariche contenute all’interno della cavità.  "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#18,18,"BB
19Potenziale elettrostatico nei conduttoriADifferenza di potenziale tra due punti del conduttoreVA−VB=∫BA⃗E⋅d⃗l=0⃗E=0A⃗E⊥d⃗l⇒VA=VB∀A,B
Tutti i punti del conduttore sono equipotenziali  (la differenza di potenziale tra due qualsiasi punti del conduttore è sempre nulla)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#19,19,"20Potenziale di un conduttore sfericoUn conduttore carico (con carica Q), di forma sferica di raggio R è equivalente ad un guscio sferico uniformemente caricoCampo elettrico (calcolato con legge di Gauss):⃗E(r<R)=0⃗E(r>R)=14πε0Qr2̂urPer simmetria, la densità superficiale di carica deve essere uniforme (altrimenti avrei campi elettrici tangenti)
RQ"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#2,2,3Premesse~F=m~a•Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra i conduttori e le eventuali cariche esterne •Lavoriamo con conduttori solidi (es. metalli) •Poniamoci in condizioni di ELETTROSTATICA
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#20,20,21Potenziale di un conduttore sfericoCalcolo del potenziale in un generico punto a distanza r dal centro della sfera (assumendo V∞=0)V(r)=V(r)−V(∞)=∫∞r⃗E⋅d⃗rEsternamente (come carica puntiforme)V(r>R)=∫∞r⃗E⋅d⃗r=∫∞r14πε0Qr2dr=Q4πε0[−1r]∞r=14πε0QrV(r<R)=∫∞r⃗E⋅d⃗r=∫Rr⃗E(r<R)⋅d⃗l+∫∞R⃗E(r≥R)⋅d⃗l=InternamenteE(r)rRV(r)rRDiscontinuità del campo⃗E(r>R)=14πε0Qr2̂urCostante!=0+∫∞RQ4πε01r2dr=Q4πε0[−1r]∞R=Q4πε01R
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#21,21,"22Esempio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515""0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)= 2xˆı z2ˆ| ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı zˆ| ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢= 2✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R: =4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵""0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10 6C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale 2sulla superﬁcie interna del guscio sferico (R: 2 Q14⇡r22= 8·10 6C/m);b) la di↵erenza di potenziale tra i due conduttori. (R: V=Q14⇡""0r2 r1r1r2= 15kV)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#22,22,"23Esempio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1=Q2=12µC, Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ)."
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#23,23,"24Ridistribuzione delle caricheQ0
R1Siano date due sfere conduttrici di raggi R1 e R2 con R1 > R2 Inizialmente sulla prima sfera c’è una carica Q0, la seconda sfera è scarica Le sfere sono poste a distanza tale da poter trascurare effetti di induzione elettrostatica
Successivamente le sfere vengono connesse con un sottile cavo conduttore. Come si ridistribuisce la carica? 
R2"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#24,24,"25Ridistribuzione delle cariche
R1
R2Dobbiamo calcolare le cariche finali sulle due sfere: Q1 e Q2Per la conservazione della carica (il sistema è isolato): Q1 + Q2 =Q0Le due sfere unite formano un unico conduttore  ⇒ equipotenziale V1 = V2 Q1Q2V1=14πε0Q1R1V2=14πε0Q2R214πε0Q1R1=14πε0Q2R2Q1R2=Q2R1Q1R1=Q2R2"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#25,25,"26Ridistribuzione delle cariche
R1
R2Q1Q2Risolvendo il sistema: {Q1+Q2=Q0Q1R2=Q2R1{Q2=Q0−Q1Q1R2=(Q0−Q1)R1{Q2=Q0−Q1Q1(R1+R2)=Q0R1Q1=R1R1+R2Q0Q2=R2R1+R2Q0La carica si redistribuisce proporzionalmente al raggioCaso particolare R1 = R2 Q1=Q2=Q02"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#26,26,"27Potere delle punte
R1
R2Q1Q2Cosa succede alle densità di carica (e ai campi elettrici delle sfere?)σ1=Q14πR21σ2=Q24πR22Q1=σ14πR21Q2=σ24πR22V1 = V2  ⇒Q1R1=Q2R2σ14πε0R21R1=σ14πε0R22R2σ1R1=σ2R2La densità superficiale di carica è maggiore sulla sfera più piccolaσ1=(R2R1)σ2⟶R1>R2σ2>σ1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#27,27,"28Potere delle punteConsideriamo un conduttore di una forma generica, con raggio di curvatura che varia da punto a punto della superficie.⃗E=σε0̂nIn vicinanza delle punte il campo elettrico                 può essere molto intenso La densità di cariche è inversamente proporzionale al raggio di curvatura 
maggiore addensamento di carica sulle punte
+ + + + + + + + + + + + + + ++++++++++++++++"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#28,28,"29Potere delle punte
In vicinanza delle punte dei conduttori le densità di carica elettrostatica ed i campi elettrostatici possono essere molto intensi Campi molto intensi possono causare l’espulsione di cariche dal conduttoreLe cariche espulse subiscono forti accelerazioni, guadagnando energia cineticaInteragendo con l’aria, provocano un riscaldamento del mezzo per cui si osservano “scintille”"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#29,29,"30Collegamento a terra
R1
R2Q0Poniamoci nella condizione limite: R1 ≫ R2 Inizialmente carica Q0 sul conduttore piccolo.Q1=R1R1+R2Q0⟶R1≫R2Q0Q2=R2R1+R2Q0⟶R1≫R20La carica fluisce interamente sul conduttore più grandeLa Terra può essere considerata come un enorme conduttore, da cui si capisce il significato di collegamento a terra (o messa a terra, ground)VT=Q4πε0RT⟶RT≈6400km0Collegando i due conduttori:In elettrotecnica si utilizza il potenziale di terra come valore di riferimento del potenzialeSimbolo  messa a terra"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#3,3,"4Conduttori in presenza di carica esterna
+++++++
+++++++
Conduttorebacchetta caricaoscilloscopio a foglieL’oscilloscopio misura la presenza di caricaL’oscilloscopio misura una maggiore presenza di caricaInduzione elettrostatica (spostamento di cariche sul conduttore)+++++++-------"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#30,30,"31Massa e messa a terra
TerraIn elettrotecnica la massa (chassis) è la scatola metallica di un’apparecchiatura elettrica Si comporta come una gabbia di Faraday La massa è utilizzata per assegnare il potenziale di riferimento comune delle componenti elettriche
massaguasto delle componenti elettriche ⇒ eccesso di cariche sulla massa (pericolo!)Collegando la massa a terra, si scaricano pericolosi eccessi di caricacomponenti  elettrici/elettronici"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#31,31,"32Capacità di un conduttoreIl potenziale di un conduttore isolato è proporzionale alla carica presente sul conduttoreC=QVDefiniamo la capacità di un conduttoreNel S.I. la capacità si misura in Farad (F):  1F=1C/1VLa capacità quantifica l’attitudine di un conduttore ad accumulare carica ad un dato potenziale  La capacità dipende solo dalla forma e dalle dimensioni del conduttore e dal mezzo che lo circonda (nel nostro caso il vuoto, per ora)"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#32,32,"33Capacità di un conduttore sferico
RQConsideriamo una sfera conduttrice di raggio R con carica QC=QV=QQ4πε0R=4πε0RLa capacità dipende solamente da fattori geometriciEsempiCapacità di una sfera di raggio R=1m nel vuoto: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++Capacità della Terra R=6400 km: 
Capacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!""#$=Q!""#$V!""#$=IT!""#$ML2T%3I%1!""#$=M%1L%2T4I2!""#$
21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85""10#12N#1m#2C2=8.85""10#12Fm  V=14!""0QR  C=QV=Q14!""0QR=4!""0R  C=4!""0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()
Capacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!""0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!""0R=4!#8.85#10$12#6.4#106F=712µF
23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!
Capacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14""#0Qr2$(%,R)&'(ˆnidP!""!==!14""#0Qr2$(%,R1)&'(ˆnidP!""!!14""#0Qr2$(R1,R)&'(ˆnidP!""!==!0!14""#0Qr2$(R1,R)&'(ˆnidP!""!=!14""#0Qr2$(R1,R)&'(ˆnidP!""!
24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!
!!!!!!!R+++++++"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#33,33,"34CondensatoriIl condensatore è un sistema formato da due conduttori carichi per i quali si verifica induzione completa (tutte le linee di forza uscenti da un conduttore incontrano l’altro conduttore) I due conduttori sono le armature del condensatore Lo spazio interposto tra le armature è l’intercapedineLa capacità del condensatore è definita come rapporto tra la carica (presente con segno opposto sui due conduttori) e la differenza di potenziale tra i due conduttoriC=QΔV
+Q-Q++++++++++++____________La capacità di un condensatore dipende solo dalla geometria, dalla forma e dal materiale interposto tra i conduttoriSimbolo  condensatore"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#34,34,"35Capacità di un condensatore pianoIl condensatore piano (condensatore a facce piane e parallele) è costituito da due armature piane di superficie S poste parallelamente a piccola distanza d (d≪S, trascuriamo effetti di bordo)
SdSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QIl sistema è equivalente al doppio strato⃗E={σε0̂n=QS1ε0interno0esternoCapacità:C=QΔV=QQdε0S=ε0Sd• proporzionale alla superficie delle armature • inversamente proporzionale alla distanza tra le armatureΔV=∫d0Edz=Ed=QdSε0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#35,35,"36Capacità di un condensatore sferico
R1+Q-QR2Un condensatore sferico è costituito da una sfera conduttrice di raggio R1 racchiusa all’interno di una cavità sferica di raggio R2 di un conduttore sfericoΔV=V1−V2=∫R2R1⃗E⋅d⃗r=Q4πε0∫R2R1drr2=Q4πε0[−1r]R2R1=Q4πε0(1R1−1R2)Differenza di potenziale tra le armatureCapacità del condensatore sfericoC=QΔV=QQ4πε0(1R1−1R2)=4πε0(R1R2R2−R1)Nel limite R1→ R2, definendo d=R2-R1 C=4πε0(R1R2R2−R1)⟶R1→R24πε0R2d=ε0Sdcapacità del condensatore piano"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#36,36,"37Capacità di un condensatore cilindricoUn condensatore cilindrico è costituito da un cilindro conduttore di raggio R1 racchiuso all’interno di una cavità cilindrica di raggio R2 di un conduttore cilindrico (nell’approssimazione R1,R2≪h , trascurando eff. bordo)⃗E=Q2πε0hr̂rCampo elettrico internoR2R1hΔV=∫R2R1Edr=∫R2R1Qdr2πε0hr=Q2πε0hlnR2R1Differenza di potenziale tra le armatureC=QQ2πε0hlnR2R1=2πε0hlnR2R1CapacitàNel limite R1→ R2, definendo d=R2-R1 lnR2R1=lnR1+R2−R1R1=ln(1+R2−R1R1)=ln(1+dR1)≅dRC=2πε0hdR=ε02πRhd=ε0Sdcapacità del condensatore piano"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#37,37,"38Sistemi di condensatori in paralleloI condensatori sono dispositivi dipolari  (hanno due capi di connessione)Connessione in parallelo (gli elementi circuitali sono alla stessa differenza di potenziale 𝛥V1=𝛥V2=VA-VB=𝛥VAB): Q1=C1𝛥V1=C1𝛥VAB Q2=C2𝛥V2=C2𝛥VABQTOT=Q1+Q2=(C1+C2)𝛥VAB=CTOT𝛥VABCTOT=C1+C2   
la capacità del sistema formato da due (o più) condensatori collegati in parallelo è uguale alla somma delle singole capacitàCTOT=∑CiC1C2+Q2-Q1VAVB-Q2+Q1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#38,38,"39Sistemi di condensatori in serieConnessione in serie (gli elementi circuitali sono collegati con un solo polo in comune)Conduttore isolato e neutro -Q1+Q2=0 ⇒  Q1=Q2 I condensatori in serie hanno la stessa caricaC1C2+Q2+Q1VAVB-Q1-Q2VM=QC1+QC2=Q(1C1+1C2)=QCTOTVA−VB=(VA−VM)+(VM−VB)=1CTOT=1C1+1C2CTOT=C1C2C1+C21CTOT=∑1Ci
L’inverso della capacità del sistema formato da due o più condensatori collegati in serie è uguale alla somma degli inversi delle singole capacità "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#39,39,"40Esempio
serie o parallelo?"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#4,4,"5Conduttori in presenza di carica esterna
+++++++In presenza di un campo elettrostatico esterno le cariche del conduttore si spostano fino a raggiungere una nuova condizione di equilibrio (𝛥t∼10-9 s)Equilibrio ⇒ cariche ferme ⇒ forza nulla ⇒ campo elettrico complessivamente nulloLe cariche del  conduttore si dispongono in maniera tale da generare un campo interno      (indotto) che annulla il campo esterno⃗E⃗E⃗E′ Il campo elettrico interno ai conduttori è sempre nullo
+++++++-------⃗E′ ⃗E⃗Econd=⃗E+⃗E′ =0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#40,40,"41Esercizio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0a3(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ).2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡""0a3(1a 1b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 ( VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC, V1= 200V, V2= V3= 100V)ABC1C3C2ABC1C2C3
C1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 ( VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC, V1= V2=6V, V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ)."
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#41,41,"42Energia elettrostatica di un sistema di caricheEnergia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale V:  U=qV  Rappresenta il lavoro che bisogna fare sulla carica q per portarla dall’infinito al punto in cui il potenziale vale Vq1Per portare la prima carica nella posizione finale, non occorre fare lavoroPer portare la seconda carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q2⃗E1⋅d⃗l⃗r12q2=q2∫⃗E1⋅d⃗l=q2V1(r12)=q2q14πε0r12U12=q1q24πε0r12=U21Energia del sistema di due cariche:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#42,42,"43Energia elettrostatica di un sistema di caricheq1Per portare una terza carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q3⃗Etot⋅d⃗l=q3∫(⃗E1+⃗E2)⋅d⃗l⃗r12q2=q3[∫⃗E1⋅d⃗l+∫⃗E2⋅d⃗l]=q3[V1(r13)+V2(r23)]=⃗r13⃗r23q3=q3V1(r13)+q3V2(r23)=q3q14πε0r13+q3q24πε0r23U13=U31=q1q34πε0r13U23=U32=q2q34πε0r23UE=U12+U13+U23Energia elettrostatica del sistema di 3 cariche:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#43,43,44Energia elettrostatica di un sistema di caricheUij=qiqj4πε0rijUE=12(U12+U21+U13+U31+U23+U32)Energia elettrostatica del sistema di 3 cariche:Utilizzando una notazione compatta:Vi=3∑j=1j≠iqj4πε0rijUE=123∑i=1qiVi=123∑i=1qi3∑j=1j≠iqj4πε0rij
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#44,44,45Energia elettrostatica di un sistema di caricheL’energia elettrostatica totale di un sistema di N cariche puntiformi èqiqj⃗rijL’energia elettrostatica di un sistema è equivalente al lavoro necessario per portare le N cariche nella configurazione finale UE=12N∑i=1qiVi=12N∑i=1N∑j=1j≠iqiqj4πε0rij=N∑i=1N∑j>iqiqj4πε0rij
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#45,45,"46EsercizioEsercitazioni di Fisica Generale T2 - provvisorioLorenzo Rinaldi10/10/20171 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, determinare l’angolo✓che i due ﬁli formano con la verticale (risolvere nell’approssimazione✓⇡0 (R:✓=3qq216⇡✏0mgl2).1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏055+15p2+12p330=4.65J )1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1= 4·10 7C,q2=+ 2·10 7Ceq3=+ 1·10 7C, determinare l’energia elettrostatica del sistema. (R:U= 10q24⇡✏0a= 9·10 3J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R: V=q⇡✏0l(1 +p5/5 p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10 7J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare =10 5C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso. (Ex= 4⇡✏0hLph2+L2,Ey= 4⇡✏0h(hph2+L2 1))1.6Sia data una sbarretta di lunghezza L e dimensioni trasversali trascurabili, disposta lungo il semiasse dellexpositive in un sistema di riferimento avente l’origine coincidente con uno degli estremi. Sulla barretta ` edepositata una carica Q con densit` a lineare =kx. Determinare in funzione diQed iL, l’espressione delpotenziale generato dalla barretta nel puntoP=( 2L,0,0). (V=Q2⇡✏0L(ln 4 1))1"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#46,46,47Energia elettrostaticaNel caso in cui le cariche siano distribuite con una densità 𝜌 su un volume 𝜏UE=12∫τρVdτUtilizzando la legge di Gauss in forma locale: ρ=ε0⃗∇⋅⃗E⃗∇⋅(V⃗E)=V⃗∇⋅⃗E+⃗E⋅⃗∇VV⃗∇⋅⃗E=⃗∇⋅(V⃗E)−⃗E⋅⃗∇VUE=12∫τρVdτ=12∫τε0⃗∇⋅⃗EVdτUso le proprietà del prodotto scalareUE=ε02∫τ(⃗∇⋅(V⃗E)−⃗E⋅⃗∇V)dτUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#47,47,48Densità di energia del campo elettrico⃗∇V=−⃗EUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ∫div⃗Fdτ=∮⃗F⋅̂ndSUE=ε02∮SV⃗E⋅̂ndS+∫τ⃗E⋅⃗EdτGli integrali vanno calcolati su tutto lo spazio in  cui è presente il campo elettrico Il campo elettrico si estende e si annulla all’infinito se la carica 𝜌 è localizzataIl flusso all’infinito è nullo (E si annulla all’infinito) ⃗E⋅⃗E=E2uE=12ε0E2densità di energia del campo elettrostaticoUE=∫spazio12ε0E2dτUE=∫spaziouEdτ
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#48,48,"49Densità di energia del campo elettrico
uE=12ε0E2densità di energia del campo elettrostatico (quantità di energia per unità di volume) L’energia elettrostatica è localizzata nel campo elettrico (e non nella carica)UE=∫spazio12ε0E2dτUE=∫spaziouEdτUE=12∫τρVdτuE=dUEdτEspressioni dell’energia elettrostaticavolume in cui è contenuta la caricavolume in cui è presente il campo elettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#49,49,"50Energia di un condensatoreSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+q-qCondensatore (piano) carico con carica q+dqdℒ=dqΔVq=dqqCIl lavoro complessivo per caricare completamente il condensatore dalla carica 0 alla carica Q:ℒ=∫Q0dℒ=∫Q0dqqC=1C∫Q0qdq=12Q2CL’energia elettrostatica accumulata in un condensatore è Ue=12Q2C=12CΔV2=12QΔVIl lavoro (di una forza esterna) per portare una carica +dq dall’armatura di destra a quella di sinistra è:"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#5,5,"6Elettrizzazione per contatto
++++++++++++++++In caso di contatto parte della carica sulla bacchetta si trasferisce al conduttoreLa carica resta sul conduttore dopo aver rimosso il contatto (misurabile con oscilloscopio)
+++++++++++++ConduttoreConduttore⃗Econd=0Nuova situazione di equilibrio ⇒"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#50,50,"51Energia di un condensatoreIn un condensatore piano la capacità vale: Sd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QC=ε0SdRiscriviamo l’energia: La differenza di potenziale tra le armature: ΔV=EdL’energia è pari alla densità di energia integrata su tutto lo spazio dove si estende il campo (il campo è nullo esternamente al condensatore)densità di energia elettrostaticavolume interno del condensatoreUE=12CΔV2=12ε0Sd(Ed)2=12ε0dSE2=(12ε0E2)(dS)=uEτ=∫τuEdτ"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#51,51,"52Energia del condensatore
Si può pensare di utilizzare un condensatore al posto di una batteria (chimica) ricaricabile? Svantaggi: •Ingombro. La densità di energia (energia per unità di volume) di un condensatore è enormemente minore di quella di una batteria. •Potenziale non costante. Mano mano che si scarica, la differenza di potenziale ai capi di un condensatore diminuisce (proporzionalmente alla carica).Vantaggi: •Velocità. Un condensatore si può caricare molto velocemente e può produrre intensità di corrente molto elevate scaricandosi (flash macchine fotografiche) •Durata. Una batteria si esaurisce dopo alcune migliaia di cicli di carica-scarica, mentre un condensatore ha una durata teoricamente illimitata.  •Basse temperature. Funzionano anche a -40° C, temperatura alla quale le normali batterie non sono in grado di operare. "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#52,52,"53Forza tra le armature di un condensatoreLe armature di un condensatore hanno cariche opposte: si attraggonoSx+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QUE=12Q2C=12Q2xε0Steniamo fissa un’armatura e applichiamo una forza esterna opposta a quella attrattiva, in modo tale che il lavoro della forza esterna bilanci la variazione di energia del condensatore⃗F⃗FestdUE=δℒest=FestdxdUE=12Q2dxε0S=δℒest=Festdxpossiamo definire la pressione elettrostatica:Per calcolare la forza tra le armature di un condensatore piano partiamo dall’energiaForza tra le armature ⃗F=−⃗Fest=−Q22ε0Ŝnp=FS=Q22ε0S2=σ22ε0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#53,53,"54EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p. V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21 V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3
C1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10 4J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a x=D/2. Calcolare il lavoro fatto dalla forza esterna.(R:L= 12Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=""0Sa b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e ilvuoto. Successivamente si introduce nel condensatore, parallelamente alle facce del condensatore, una lastra"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#54,54,"55EsempioABC1C3C2ABC1C2C3
C1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p. V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21 V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3
C1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10 4J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a x=D/2. Calcolare il lavoro fatto dalle forze del campo elettrico.(R:L= 12Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=""0Sa b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e il"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#55,55,"56Condensatori con dielettriciCosa succede se riempiamo con un materiale isolante l’intercapedine di un condensatore?+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  ++𝜎-𝜎-𝜎P𝜎PNel dielettrico le cariche non si muovono.Però a livello microscopico le molecole (dipolari) possono orientarsiSulle superfici del dielettrico a contatto con le armature del condensatore si osserva un eccesso di carica 𝜎P (carica di polarizzazione)Le cariche di polarizzazione creano un campo elettrico opposto al campo del condensatoreIl campo elettrico totale (e di conseguenza la differenza di potenziale) diminuisce La capacità del condensatore aumenta⃗E0⃗E′ "
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#56,56,"57Il dipolo elettrico
Teorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS""!!=!""i!vdVV!!!
57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV""P{}!vSV()""##iˆndSdVV###=$tot!v()%V!!i!v()Pi()""Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Teorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: 
58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()""Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn""Sfacceesterne#!!i!vdVV%%%=!viˆndSS""%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V
Linee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()
59!  !E!r()
Domenico Galli – Fisica Generale B – 1. Elettrostatica!
Angolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido "" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr""0,2#$%$%!=Sr2""0,4#$%&'S!r
60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!-+   Il dipolo elettrico è un sistema formato da 2 cariche elettriche in quiete, di uguale valore assoluto ma segno opposto (Q e –Q), poste a una distanza fissata d.  
x
z
y+Q-QdMolti materiali isolanti sono formati da molecole che hanno una struttura “dipolare”. 
Definiamo il momento di dipolo ⃗p=(Qd)̂k
"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#57,57,"58Azioni meccaniche su un dipolo elettricoCalcoliamo il momento della forza esercitato da un campo esterno su un dipolo
⃗M=⃗p∧⃗E
Dipolo Elettrico (IV) •!Si ha: 
•!Dunque il potenziale di un dipolo elettrico decresce con la distanza come 1/r2.      !pi!r=QdversP+!P!()i!r=Qdrcos!   V!r()""d#rQ4!""0dr2cos#=14!""01r2!pi!rr   V!r()""d#r14!""0!pi!rr3
9!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!
Dipolo Elettrico (V) •!Per calcolare il campo elettrico del dipolo scriviamo il potenziale in coordinate cartesiane e calcoliamo il gradiente:    Vx,y,z()!d""r14!""0xpx+ypy+zpzx2+y2+z2()32
   Exx,y,z()=!""V""x""d#r!14#$0""""xxpx+ypy+zpzx2+y2+z2()32==!14#$0pxx2+y2+z2()32!xpx+ypy+zpz()32x2+y2+z2()122xx2+y2+z2()3==14#$03xxpx+ypy+zpz()x2+y2+z2()52!pxx2+y2+z2()32%&'''()***=14#$03!pi!r()xr5!pxr3%&''()**10!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!
Dipolo Elettrico (VI) •!Ripetendo il calcolo per le componenti y e z si ottiene: •!Il campo elettrico di un dipolo elettrico decresce con la distanza come 1/r3:    !Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())
11!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!!Ex,y,z()""d#r14!""03!pi!r()!rr5#!pr3$%&&'())=14!""01r33!piˆr()ˆr#!p$%'(
Dipolo Elettrico (VII) •!Calcoliamo ora il momento della forza esercitato da un campo elettrico esterno su di un dipolo elettrico. •!Trattandosi di due forze di uguale modulo QE, medesima direzione e verso opposto, le cui rette di azione distano d sin !, si ha: 
Q!Qd– !pF!!F!!!Esind!+    !M=!p!!E   M=Fb=QE()dsin!()=Qd()Esin!()=pEsin!
12!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!M=FEdsinθ=(QE)dsinθ=(Qd)Esinθ=pEsinθLe due forze hanno stesso modulo QE, stessa direzione e verso opposto il momento delle forze (prendendo come polo una delle due cariche) è⃗M=⃗rd∧⃗FE"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#58,58,"59Elettrostatica dei dielettrici+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |⃗E0−  +⃗pOgni singolo atomo/molecola del dielettrico ha un momento di dipolo elettrico ⃗p(⃗p=q⃗d)Ogni dipolo sentirà un momento delle forze e tenderà ad allinearsi con il campo:⃗M=⃗p∧⃗E0Definiamo il momento di dipolo medio          (media di tutti i dipoli) ⟨⃗p⟩sia                 il numero di atomi/molecole per unità di volumen=NΔτSi definisce il vettore polarizzazione ⃗P=n⟨⃗p⟩[C/m2] come densità di carica • indica il grado di allineamento degli atomi/molecole in un dielettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#59,59,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L+𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
60Elettrostatica dei dielettrici|⃗P|=σpIl modulo del vettore polarizzazione è la densità di carica di polarizzazione⃗P=σp̂n⃗P=σp̂nIn un dielettrico isotropo e omogeneo le cariche di polarizzazione sono distribuite solo superficialmente (±𝜎P)Chiamiamo la carica libera (±𝜎L) quella sulle armature del condensatoreSi definisce il vettore spostamento elettrico⃗D=σL̂n⃗D=σL̂n"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#6,6,"7Carica interna al conduttore
SConsideriamo una generica superficie chiusa S interna al conduttore  ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Per la legge di GaussInternamente al conduttore il campo elettrico è nullo, quindi la carica interna ad S sarà sempre nullaQS=∭τ(S)ρdτ=0All’interno del conduttore non ci sono cariche in eccesso (cariche positive e negative hanno uguale densità)⃗E=0"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#60,60,"+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +
|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L𝜎P-𝜎P
+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
61Elettrostatica dei dielettriciIl campo all’interno del dielettrico⃗E=⃗E0+⃗EP⃗EP=−σPε0̂n⃗E0=σLε0̂n⃗D=ε0⃗E+⃗P=⃗Dε0−⃗Pε0=σL̂nε0−σP̂nε0In un dielettrico isotropo e omogeneo i vettori campo elettrico, polarizzazione e spostamento sono paralleliIn un dielettrico isotropo e omogeneo si definisco le due quantità adimensionali suscettività dielettrica 𝜒 (𝜒≥0) e la costante dielettrica relativa 𝜀R (𝜀R≥1), legati dalla relazione 𝜒=𝜀R-1Il campo elettrico ed il vettore polarizzazione sono legati dalla relazione⃗P=ε0χ⃗E=ε0(εR−1)⃗E"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#61,61,"62Elettrostatica dei dielettrici⃗P=ε0χ⃗E=ε0(εR−1)⃗E⃗D=ε0⃗E+⃗P⃗D=ε0⃗E+ε0(εR−1)⃗E=ε0εR⃗EUtilizzando il vettore spostamento elettrico, formuliamo la legge di Gauss (in forma locale e integrale) in funzione delle sole cariche libere 𝜌L e QL :⃗∇⋅⃗D=ρL∬⃗D⋅̂ndS=QLIn un dielettrico isotropo e omogeneo il vettore spostamento elettrico è proporzionale al campo elettrico"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#62,62,"Capacità di un condensatore piano con dielettrico63Condensatori con dielettriciΔV=ΔV0εrC=QΔV=εrQΔV0=εrC0C=ε0εrSdSe riempiamo un condensatore con un dielettrico isotropo e omogeneo, il campo elettrico totale vale:
Capacità di un condensatore con dielettricoDi conseguenza, la differenza di potenziale tra le armature⃗E=⃗Dε0εR=σL̂nε01εR=⃗E0εRcampo elettrico con condensatore vuoto"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#63,63,64Costanti dielettriche relativematerialecostante dielettrica relativa 𝜀R Aria1.00059Acqua distillataca. 80Etanolo25Petrolio2.1Vetro comune5 ÷ 10Plexiglas3.40Mica8Ebanite2Paraffina2.1Glicerolo42.6Ossido di titanio90 ÷ 170Titanati di Ba-Sr1000 ÷ 10000
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#64,64,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
65"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#7,7,"8Carica superficiale di un conduttore La carica in eccesso (dovuto ad elettrizzazione per induzione o per contatto) si  dispone sulla superficie del conduttore Microscopicamente la carica occupa uno spessore di 10-10 m (dimensioni atomiche)Nei conduttori le cariche in eccesso si dispongono in superficie, in una configurazione tale che il campo elettrico interno al conduttore sia nullo
+++++++++++++++++++++++Conduttore elettrizzato
--++++++++++-----------Conduttore polarizzato per induzione elettrostatica100 pm"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#8,8,"9Campo elettrico in prossimità della superficie dei conduttoriIn equilibrio elettrostatico le cariche si dispongono in superficieIl campo generato da tali cariche non può avere componenti tangenti alla superficie, altrimenti si osserverebbero movimenti di cariche⃗EEnEt⃗F⃗E=Ên
Il campo elettrico è sempre normale alla superficie dei conduttori"
data_test\rootfolder\università\FisicaGenerale\10-conduttori.pdf#9,9,"10Campo elettrico in prossimità della superficie dei conduttoriIl campo elettrico è sempre normale alla superficie dei conduttoriSi dimostra in maniera formale calcolando la circuitazione del campo lungo una linea chiusa 𝛤 che interseca la superficieIl campo è nullo all’interno del conduttoreConservatività del campo elettrostatico⇒∫BA⃗E⋅d⃗l=∫BA⃗E⋅̂utdl=0⟺⃗E=ÊnSABCD0=∮L⃗E⋅d⃗l=∫BA⃗E⋅d⃗lAB+∫CB⃗E⋅d⃗lBC+∫DC⃗E⋅d⃗lCD+∫AD⃗E⋅d⃗lDA∫DC⃗E⋅d⃗lCD=0∫CB⃗E⋅d⃗lBC,∫AD⃗E⋅d⃗lDA⟶BC,AD→00d⃗lAB=̂utdlABSia 𝛤 un rettangolo di vertici ABCD • lati AB e CD sufficientemente piccoli e paralleli a S • lati BC e AD infinitesimi di ordine superiore rispetto a AB e CD
"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#0,0,1 Correnti elettriche CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#1,1,"2Corrente elettricaIn condizione statiche, il campo elettrico all’interno dei conduttori è sempre nullo altrimenti gli elettroni sarebbero accelerati e addio condizione staticaCosa succede se tramite un artificio esterno (generatore) si pone una differenza di potenziale (d.d.p.) tra due punti del conduttore?Gli elettroni di conduzione si mettono in moto ed il conduttore risulta percorso da una corrente elettrica "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#10,10,11EsempioDeterminare numero di elettroni di conduzione e velocità di deriva in un filo di rame di raggio r=0.8mm percorso uniformemente da una corrente i=15A Il rame ha densità di massa 𝛿=8.96 g/cm3 e peso atomico A=6335 g/mol mediamente si avrà nC=1 elettrone di conduzione per atomon=nCδNAA=1×8.96 g cm−3×6.022×1023mol−16355 g mol−1=8.45×1022cm−3j=iS=iπr2=15Aπ×0.82×10−6 m=7.46×106 Am−2elettroni di conduzione per unità di volumedensità di correntevelocità di derivavd=jnqe=7.46×106Am−28.45×1022 cm−3×1.6×10−19As=0.55mmsquantità di carica in moto per unità di volumenqe=8.45×1022cm−3×1.6×10−19C=13.6×103 C/m3≈14 C/mm3
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#11,11,"12Conservazione della carica elettrica
Consideriamo una superficie S chiusa e orientata, interna ad un conduttoreil flusso di una corrente di densità j attraverso S è dato da⃗𝚥⃗𝚥̂ncarica che passa attraverso S nell’unità di tempo (corrente uscente) flusso positivo ⇒ carica diminuisce
Principio di conservazione della carica elettrica La carica che attraversa la superficie chiusa S è pari alla variazione di carica complessiva contenuta in SΔq=qout−qinΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=i=qin−qoutΔt=−ΔqΔt→Δt→0−dqdt=iuscente"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#12,12,13Equazione di continuitàLa carica interna alla superficie S può essere scritta in funzione della densità di carica: q=∭τSρdτ𝜏S è il volume delimitato dalla superficie S=−∂∂t∭τSρdτ=∭τS(−∂ρ∂t)dτ∬S⃗𝚥⋅̂ndS=∭τS⃗∇⋅⃗𝚥dτΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=−dqdtteorema della divergenzastesso dominio di integrazione 𝜏S⃗∇⋅⃗𝚥=−∂ρ∂tequazione di continuità 
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#13,13,14Equazione di continuità⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza del vettore densità di corrente bilancia la variazione di caricaL’equazione descrive una situazione locale (o differenziale) in ogni punto del volume in cui scorre corrente.  Una variazione di cariche corrisponde ad un moto di cariche non solenoidale  (le cariche non si muovono su linee chiuse)
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#14,14,"15Condizioni stazionarie
Si hanno condizioni stazionarie se la carica entrante è pari alla carica uscente⃗𝚥⃗𝚥̂nΔq=qout−qin=0La carica q internamente a S si mantiene costanteΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0⃗∇⋅⃗𝚥=0Il flusso della densità di corrente è nulloIl campo densità di corrente è solenoidale (linee di campo sempre chiuse)−dqdt=iuscente=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#15,15,"16Prima legge di OhmConsideriamo un conduttore filiforme ai cui estremi c’è una differenza di potenziale Internamente al filo scorre una corrente proporzionale alla differenza di potenzialeLa costante di proporzionalità tra l’intensità di corrente e la differenza di potenziale è la resistenza elettricaΔV=RiTale relazione (prima legge di Ohm) è una legge empirica, valida a temperature ordinarie costanti La resistenza si misura in Ohm (Ω)    1Ω=1V/1Asimbolo circuitale della resistenza"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#16,16,"17Seconda legge di OhmLa resistenza di un conduttore omogeneo, filiforme di lunghezza l e sezione S vale R=ρRlSR=ρRlSresistività elettrica dipende dalla natura del materiale si misura in ΩmMaterialeResistività (Ωm)Argento1,62 × 10−8Rame1,68 x 10−8Oro2,35 × 10−8Alluminio2,75 × 10−8Tungsteno5,25 × 10−8Ferro9,68 × 10−8Platino10,6 × 10−8Acqua di mare2.00 × 10−1Acqua potabiletra 2.00×101 e 2.00×103Silicio puro (non drogato)2,5 × 103Vetrotra 1010   e 1014Ariatra 1.30×1016 e 3.30×1016Quarzo fusocirca 1016"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#17,17,"18Leggi di Ohm in forma locale
dSdl⃗𝚥Nell’interno di un conduttore, consideriamo un sottile cilindro di base dS e lunghezza dl percorso da una corrente di densità ⃗𝚥VAVBsia dV=VA-VB la differenza di potenziale ai capi del cilindro (VA>VB)dV=Rdi=ρRdldSdiper le due leggi di Ohmdi=jdSdV=Edl⃗𝚥=σC⃗E⃗E=ρR⃗𝚥E=ρRjσC=1ρRConduttività  (o conducibilità) elettricail vettore densità di corrente ha stessa direzione e verso del campo elettrico"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#18,18,"19Resistenze in serieVA
VBVMDue (o più) resistenze in serie sono attraversate dalla stessa corrente i (per equazione di continuità)R1R2i{VA−VM=R1iVM−VB=R2i(VA−VM)+(VM−VB)=VA−VB=(R1+R2)isomma membro a membroRTOT=∑iRiRTOT=R1+R2
la resistenza del sistema formato da due (o più) resistenze collegate in serie è uguale alla somma delle singole resistenzeApplicando la legge di Ohm (caduta ohmica) ai capi di ciascuna resistenza"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#19,19,"20Resistenze in parallelo
VBVAR1R2i1i2Due (o più) resistenze in parallelo hanno la stessa differenza di potenziale VA-VBi1=VA−VBR1i2=VA−VBR2i=(VA−VB)(1R1+1R2)=VA−VBRTOTi=i1+i2=VA−VBR1+VA−VBR2=
L’inverso della resistenza del sistema formato da due o più resistenze collegate in parallelo è uguale alla somma degli inversi delle singole resistenze Applicando la legge di Ohm ai capi di ciascuna resistenza1RTOT=1R1+1R21RTOT=∑i1Ri"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#2,2,"3Modello di Drude-LorentzSe la d.d.p. è costante nel tempo, lo sarà anche il campo elettrico e la forza sugli elettroniCi si aspetta che il moto sia uniformemente accelerato (forza e accelerazioni costanti)Sperimentalmente, però, si trova che la velocità media degli elettroni è proporzionale al campo⟨⃗ve⟩∝⃗E⟨⃗ae⟩∝⃗EModello di Drude-Lorentz  gli elettroni si comportano come cariche libere di un gas nel reticolo cristallino, soggette al campo elettrico ed interagenti con le cariche del reticolo 
_
_
+
+
+
+
+
+
+
+
+
+
+
+⃗E=−⃗∇V"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#20,20,"Esempio
21
Esempio
22metallica quadrata di spessored/2 e latoL/2. Determinare il lavoro fatto per introdurre interamente lalastra all’interno del condensatore. (R:L= DQ210""0L2)2.12Tre condensatori di capacit` aC1=0.5µF,C2=0.8µF,C3=0.1µF, sono collegati in serie (vedi ﬁgura 4). IpuntiAeBsono collegati inizialmente ad un generatore di tensioneV0=100 V.a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccatidal generatore e il puntoBviene collegato ad un punto tra i condensatoriC1eC2.b) determinare la variazione di energia nelle↵ettuare il nuovo collegamento.   FISICA GENERALE II  -  TEST di VERIFICA     (27-10-2015)  Costanti: c = 3x108  m/s  ε0 = 8.85x10-12    F/m  G = 6.67x10-11  Nm2/kg2 e= 1.60x10-19  C me = 9.11x10-31 kg  mp = 1.67x10-27 kg   ESERCIZIO 1  Si consideri il campo F(x,y,z)=2xi-zj-ayk. Determinare: a) per quali valori di a il campo risulta conservativo; b) il potenziale generato dal campo F.  ESERCIZIO 2  Tre cariche positive puntiformi identiche q1= q2=q3=4mC sono disposte su un piano cartesiano ortogonale rispettivamente nei punti di coordinate (0,3m), (0,-1m) e (-1m,1m). Una quarta carica positiva q4=2mC  è posta nel punto di coordinate (1m,1m). Determinare: a) la forza a cui è sottoposta la carica q4; b) l’energia necessaria a spostare la carica q4 dalla posizione iniziale (1m,1m) all’origine del sistema di riferimento.  ESERCIZIO 3 Si consideri un sistema formato da un volume sferico di raggio a in cui è contenuta una carica +Q distribuita uniformemente nel volume, e da un sottile guscio di materiale conduttore di raggio b (b>a), concentrico al volume sferico, sul quale è depositata una carica –Q. Determinare: a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanza r dal centro del sistema, disegnando un grafico qualitativo dell’andamento del campo; b) l’espressione del potenziale sulla superficie del volume sferico (in r=a, considerando nullo il potenziale all’infinito).   ESERCIZIO 4  Tre condensatori di capacità C1=0.5 µF, C2=0.8 µF,  C3=0.1 µF, sono collegati in serie (vedi figura). I punti A e B sono collegati inizialmente ad un generatore di tensione V0=100 V. a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccati dal generatore e il punto B viene collegato ad un punto tra i condensatori C1 e C2. b) determinare la variazione di energia nell’effettuare il nuovo collegamento.              
Figure 4:3 Correnti elettriche3.1Un conduttore cilindrico cavo di lunghezzad=2cm ha raggia=2mm eb=5mm; esso ` e costituito da unasostanza con resistivit` a⇢=2⌦m. Una f.e.m.E=20 V pu` o essere applicata al conduttore in modo chela corrente ﬂuisca parallelamente all’asse del cilindro oppure radialmente dalla superﬁcie interna a quellaesterna. Calcolare nei due casi l’intensit` a di correnteiche percorre il conduttore, la potenza dissipata e ladensit` a di corrente sulle superﬁci terminali.3.2Un resistore di forma cilindrica di sezioneA` e composto da una parte di lunghezzal1fatta di materiale diresistivit` a⇢1=⇢e da un’altra parte di lunghezzal2fatta di materiale di resistivit` a⇢2=3⇢. Il resistore ` eattraversato da una correnteIuniformemente sulla sezioneA. Determinare:a) l’intensit` a dei campi elettriciE1eE2nelle due parti del resistore;b) la di↵erenza di potenziale ai capi del resistore;c) il valore della carica elettrica presente sulla superﬁcie di separazione tra i due materiali che formano ilresistore.3.3Nel circuito in ﬁgura 5, calcolare l’intensit` a di correntei, il potenziale nei quattro vertici e il bilancioenergetico (R= 50⌦,E1=50 V,r1= 20⌦,E2=100 V,r2= 30⌦)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#21,21,"22Effetto JouleQuando una corrente i scorre attraverso un conduttore filiforme, la carica che attraversa una sezione S in un tempo dt è: dq=i dt Il lavoro compiuto dal campo elettrico nello spostamento della carica nell’intervallo dt èδℒ=dU=ΔVdq=ΔVidt=(Ri)idt=Ri2dtLa potenza (energia per unità di tempo) spesa dal campo elettrico per sostare la carica èP=dUdt=Ri2La potenza viene persa negli urti degli elettroni di conduzione con gli atomi del conduttore, i  quali aumentano la propria energia vibrazionale (la potenza viene dissipata in calore)
Effetto Joule aumento della temperatura del conduttore attraversato da correnteP=iΔV=ΔV2R"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#22,22,"23Effetto Joule: interpretazione microscopicaLavoro compiuto dal campo sugli N elettroni contenuti in un volume d𝜏 in un tempo dt=ndτqe⃗E⋅d⃗l=⃗E⋅⃗𝚥dτdtdPdτ=δℒdτdt=⃗E⋅⃗𝚥
Effetto Joule in forma locale Relazione locale che esprime la potenza per unità di volume come prodotto scalare del campo elettrico per la densità di correnten=Ndτδℒ=NqeΔV=ndτqe⃗E⋅⃗vddt=⃗E⋅(nqe⃗vd)dτdt"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#23,23,"24Superconduttori
La resistività è funzione lineare della temperaturaρR=ρ0(1+αT)Alcuni metalli (Hg, Al, Pb, Ti, Zn, …) o altre leghe al di sotto di una temperatura critica Tc prossima allo zero assoluto (0°K=-273.15 °C) mostrano una resistività nullaIn tali condizioni di superconduttività, le correnti circolano senza dissipazione di energia e i superconduttori non si riscaldano, anche con correnti molto intense𝜌0,𝛼 costanti T temperatura in °K "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#24,24,"25Generatori di forza elettromotriceSi è  detto che per avere una corrente in un conduttore è necessario stabilire una differenza di potenziale in due punti del conduttore  Per loro natura i conduttori sono equipotenziali. Per forzare una d.d.p occorre connettere il conduttore ad un generatore di forza elettromotrice (o generatore elettrico)Consideriamo un semplice circuito formato da un generatore (pila o batteria) e da una resistenzaIn tale circuito la circuitazione del campo elettrico è diversa da zero (altrimenti non avremmo corrente)
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG∮⃗E⋅d⃗l=∮ρR⃗𝚥⋅d⃗l≠0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#25,25,"26Generatori di forza elettromotriceNel circuito il campo avrà due componenti
Generatori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. 
29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG⃗E=⃗Es+⃗Em⃗Es⃗E=⃗Es+⃗EmAll’interno del generatore si deve aggiungere il campo elettromotore        (NON conservativo)⃗EmLe forze interna ai generatori sono non conservative (di natura chimica o altro). Il loro effetto è quello di trasportare e mantenere le cariche interne ad una differenza di potenziale 𝛥V=V2-V1Nei conduttori si avrà solo campo elettrostatico⃗Es"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#26,26,"27Generatori di forza elettromotrice∮⃗E⋅d⃗l=∮(⃗Es+⃗Em)⋅d⃗l=∮⃗Es⋅d⃗l+∮⃗Em⋅d⃗lV2V1⃗Es⃗Em⃗EsIl campo elettromotore è definito solo internamente al generatore, non è conservativo e la sua circuitazione è definita forza elettromotrice =ℰ
ℰ=∫21⃗Em⋅d⃗l=−∫21⃗ES⋅d⃗l=V2−V1=ΔVIn condizioni stazionarie (generatore non connesso al circuito) le cariche sono ferme, pertanto ∮(⃗Es+⃗Em)⋅d⃗l=0La forza elettromotrice è uguale alla differenza di potenziale (Tensione del generatore)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#27,27,"28Generatori di forza elettromotriceGeneratori ideali  • la tensione ai capi del generatore si mantiene costanteGeneratori reali  • la tensione ai capi del generatore presenta una caduta ohmica • occorre considerare la resistenza interna del generatore (in serie al circuito)+_
+_simbolo circuitale generatore idealesimbolo circuitale generatore reale"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#28,28,"Prima legge di Kirchhoff (dei nodi)
29+i1
S1
+i2-i3-i4-i5S
S2S5S4S3In condizioni stazionarie (fissato un intervallo 𝛥t, la carica entrante deve bilanciare la carica uscente) ΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0=∑entrantiik−∑uscentiik∬Sk⃗𝚥k⋅̂nkdSk={+ikentrantenelnodo−ikuscentedalnodo∬S⃗𝚥⋅̂ndS=∑k∬Sk⃗𝚥k⋅̂nkdSkConsideriamo N fili che si congiungono in un nodo Siano Si le superfici di intersezione tra S e le sezioni dei fili 
Prima legge di Kirchhoff (dei nodi) In qualunque nodo di un circuito la corrente totale entrante è uguale alla corrente uguale uscente∑nodoik==∑entrantiik−∑uscentiik=0i1+i2−i3−i4−i5=0i1+i2=i3+i4+i5"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#29,29,"Legge di Ohm generalizzata
30Prendiamo in considerazione un circuito aperto (ramo)iA+_+_BCDRR1R2𝓔1𝓔2Fissiamo arbitrariamente un verso di percorrenza della corrente ( es. da A verso D)In condizioni stazionare la corrente entrante in A è pari a quella uscente da DCiascun elemento del circuito è percorso dalla stessa corrente i (tutti gli elementi sono in serie)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#3,3,"4
_
_
+
+
+
+
+
+
+
+
+
+
+
+Gli elettroni subiscono urti, cedendo energia cineticaModello di Drude-Lorentz
⃗ae=qeme⃗EII principio dinamicaNell’intervallo di tempo tra due urti consecutivi l’elettrone si muove di moto uniformemente accelerato:Nell’urto sulle cariche positive, l’elettrone cede energia • l’elettrone rallenta • gli atomi del reticolo aumentano la loro energia vibrazionale (gli atomi del reticolo vibrano sempre a T>0° K)"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#30,30,"Legge di Ohm generalizzata
31A+_+_BCDRR1R2𝓔1𝓔2Applichiamo la prima legge di Ohm ai capi dei vari elementiVA-VB=Ri              Caduta di potenziale ai capi di RVB-VC=R1i-𝓔1       Caduta di potenziale ai capi di R1, il generatore 𝓔1 fa salire il potenzialeVC-VD=R2i+𝓔2     Caduta di potenziale ai capi di R2, il generatore 𝓔2 fa scendere il potenzialeVA-VD=Ri+R1i+R2i+𝓔2-𝓔1 =(R+R1+R2)i+𝓔2-𝓔1  Differenza di potenziale ai capi dell’intero ramo   "
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#31,31,"Legge di Ohm generalizzata
32A+_+_BCDRR1R2𝓔1𝓔2+_VA-VD+(𝓔1-𝓔2)=RTOT i “Fissato”  il verso della corrente, stabiliamo anche il verso in cui diminuisce il potenziale (le cariche positive della corrente fluisco dal potenziale maggiore a quello minore)Convenzione dei generatori in un circuito (segno della tensione) + se la corrente “entra” nel polo negativo ed “esce” dal polo positivo -  se la corrente “entra” nel polo positivo ed “esce” dal polo negativo +_+_"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#32,32,"Legge di Ohm generalizzata
33 V+XkEk=RTOTiLegge di Ohm su un ramo di un circuito apertoLa differenza di potenziale ai capi di un ramo aperto di un circuito sommata alle tensioni erogate dai generatori è uguale alla caduta di tensione sulla resistenza totale del ramoN.B. Se dai calcoli numerici:  • la corrente ha segno positivo, allora essa circola nello stesso verso che si era supposto inizialmente • la corrente ha segno negativo, allora essa circola nel verso opposto a quello che si era supposto inizialmente"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#33,33,"Seconda legge di Kirchhoff (delle maglie)
34A+_+_BCDRR1R2𝓔1𝓔2RConsideriamo un ramo chiuso (maglia)Connettendo i due capi, la differenza di potenziale si annulla: 𝛥V=0La legge di Ohm viene riformulata:XkEk=RTOTi
Seconda legge di Kirchhoff (o delle maglie) Su qualunque maglia di un circuito la caduta di potenziale è uguale  alla somma delle tensioni erogate dai generatori"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#34,34,"Circuiti ideali e reali
35+_Circuiti elettrici costituiti da fili conduttori, resistenze, generatori e altri elementi collegati tra loroIn un circuito ideale, gli elementi hanno resistenza interna nulla (escluso resistenza)filo conduttoreresistenzacondensatoregeneratore+_In un circuito reale, gli elementi sono schematizzati introducendo elementi resistivi"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#35,35,"Circuiti RC in regime transitorio
36+_T𝓔CRConsideriamo il circuito (ideale) formato da una resistenza, un condensatore a da un generatore di forza elettromotriceInizialmente l’interruttore T è aperto, il condensatore è scaricoAd un dato istante iniziale t=0 l’interruttore viene chiuso. Cosa succede nel circuito? Circola corrente? Potenziale ai capi di resistenza e condensatore? Carica sul condensatore?"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#36,36,"Circuiti RC in regime transitorio
37𝛥VC𝛥VR+_T𝓔CRLe differenze di potenziale ai capi di R e C varieranno al passare del tempo:ΔVR(t)=Ri(t)ΔVC(t)=Q(t)Ci(t) corrente che circola nel circuitoQ(t) carica sul condensatore all’istante t=0 il condensatore è scarico Q(0)=0Applicando la legge delle maglie: ℰ=ΔVR(t)+ΔVC(t)ℰ=Ri(t)+Q(t)C"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#37,37,"Circuiti RC in regime transitorio
38𝛥VC𝛥VR+_T𝓔CRℰ=Ri(t)+Q(t)CLa carica Q(t) che dal generatore fluisce verso il condensatore è legata alla corrente che circola nel circuito dalla relazionei(t)=dQ(t)dtQ(t)=∫t0i(t′ )dt′ L’equazione delle maglie è a tutti gli effetti un’equazione integro-differenziale0=Rdidt+1CdQdt=Rdidt+iCderivando tutto rispetto a t"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#38,38,"390=Rdidt+1CdQdt=Rdidt+iCCircuiti RC in regime transitorio𝛥VC𝛥VR+_T𝓔CRdidt=−iRCRisolviamo per separazione delle variabiliEquazione omogenea in i(t)dii=−dtRC∫i(t)i(0)di′ i′ =−1RC∫t0dt′ lni(t)i(0)=−tRCi(t)i(0)=e−tRCi(t)=i(0)e−tRCAll’instante iniziale si haℰ=Ri(0)+Q(0)Ci(0)=ℰRi(t)=ℰRe−tRCQ(0)=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#39,39,"Carica di un condensatore
40i(t)=ℰRe−tRC𝛥VC𝛥VR+_T𝓔CRCorrente che circola nel circuito in funzione del tempo=ℰR[−RCexp(−t′ RC)]t0=−ℰC(e−tRC−1)=ℰC(1−e−tRC)Q(t)=∫t0i(t′ )dt′ =∫t0ℰRexp(−t′ RC)dt′ Q(t)=ℰC(1−e−tRC)ΔVR(t)=ℰe−tRCDifferenza di potenziale ai capi della resistenzaCarica sul condensatore in funzione del tempoΔVC(t)=ℰ(1−e−tRC)Differenza di potenziale ai capi del condensatoreτ=RCCostante di tempo del circuito RC"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#4,4,"5Modello di Drude-LorentzSupponiamo che l’elettrone abbia un urto all’istante t. Sia  p(t)dt la probabilità di avere un urto in un intervallo [t, t+dt]. ⟨t⟩=∫∞0tp(t)dtIl tempo medio che intercorre tra due urti:nel tempo tra due urti consecutivi, la velocità aumenterà linearmente con l’accelerazione⃗ve=qeme⃗Etla velocità media di un elettrone sara:⟨⃗ve⟩=∫∞0⃗ve(t)p(t)dt=∫∞0qeme⃗Etp(t)dt=qeme⃗E⟨t⟩"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#40,40,"41Carica di un condensatore
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰRi(t)=ℰRe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ΔVR(t)=ℰe−tRCΔVR(t)=ℰe−tRC
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰΔVC(t)=ℰ(1−e−tRC)
Transitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ
13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci""t()d""t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt""d#i#ii0i$%&=!1RCd#t0t'""ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC""i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f""i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=""fe""t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=""1CfRe""#t/RCd#t0t$+f==""fRC""RCe""#t/RC%&'(0t+f=""f1""e""t/RC()+f=fe""t/RCQt()=C!VCt()=Cfe""t/RC!VRt()=""fe""t/RC!VCt()=fe""t/RCQt()=Cfe""t/RC!VRt()t""#$""$$0!VCt()t""#$""$$0Qt()t""#$""$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0Q(t)=ℰC(1−e−tRC)ℰC"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#41,41,"42Scarica di un condensatoreTCRSia dato un circuito formato da un condensatore e una resistenza Q(0)=Q0Inizialmente l’interruttore T è aperto, il condensatore è carico con Q(0)=Q0Calcoliamo quanto vale l’energia dissipata sulla resistenza i(t)=dQ(t)dtL’equazione della maglia alla chiusura dell’interruttore èΔVR(t)+ΔVC(t)=0Ri(t)+Q(t)C=0RdQdt+QC=0"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#42,42,43Scarica di un condensatoreTCRQ(0)=Q0RdQdt+QC=0dQdt=−QRCdQQ=−dtRCPer separazione delle variabiliEq differenziale omogeneaQ(t)=Q0e−tRCCarica sul condensatorei(t)=−Q0RCe−tRC=−VcRe−tRCCorrente che circola nel circuitolnQ(t)Q(0)=−tRC
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#43,43,"44Scarica di un condensatore
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
i(t)=−VcRe−tRC
Transitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. 
17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
Transitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ
18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0
http://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica 
Q0Q(t)=Q0e−tRC
−Q0RC=−VcR"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#44,44,45Scarica di un condensatoreTCRQ(0)=Q0UR=∫∞0PRdt=∫∞0Ri2dt=∫∞0R[−VCRe−tRC]2dtL’energia dissipata è pari all’integrale della potenza nel tempo=12CV2C[−e−∞RC+e−0RC]=V2CR∫∞0e−2tRCdt=V2CR[−RC2e−2tRC]∞0UR=12CV2C=UCL’energia che era inizialmente accumulata nel condensatore viene interamente dissipata sulla resistenza
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#45,45,"DRAM 
46
Il condensatore può essere utilizzato come cella di memoria in alternativa al flip-flop Cella di memoria formata da condensatore + transistor Lo stato di carica del condensatore determina lo stato logico Il transistor è usato per pilotare la lettura/scrittura (funziona come un interruttore) Ad ogni lettura/scrittura, tutti i C di un array vengono ri-caricati/scaricatiLinea indirizziLinea dati"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#46,46,"DRAM 
47
PRO economicità, alta densità, velocità di accesso ~10 ns (un po’ più lente delle SRAM)
CONS carica sui C diminuisce nel tempo (effetti dissipativi) necessario un circuito di “refresh” che faccia delle letture/scritture “fittizie” (con frequenza del kHz)  Problemi in ambienti ad elevata radiazione (centrali nucleari, detector, spazio): particelle cariche da raggi cosmici o da decadimenti radioattivi possono alterare gli stati  logici"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#47,47,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
48"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#5,5,"6Modello di Drude-LorentzVelocità media o velocità di deriva proporzionale al campo: stessa direzione e verso opposto gli elettroni possiedono anche una velocità dovuta all’agitazione termica, ma si può dimostrare che essa ha valore medio nullo (perché casuale in ogni direzione) Valori tipici: velocità di termica a temperatura ambiente ~100 km/s velocità di deriva: qualche mm/s⃗vd=⟨⃗ve⟩=qeme⃗E⟨t⟩"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#6,6,"7Intensità di correnteConsideriamo un conduttore all’interno del quale è mantenuta una differenza di potenziale VA-VB
Nel S.I. l’unità di misura della corrente è l’Ampere (A) (grandezza fisica fondamentale) 
SdqVAVBi=limΔt→0ΔqΔt=dqdtData una sezione S, interna al conduttore, definiamo la corrente elettrica come la quantità di carica che attraversa il conduttore per unità di tempo"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#7,7,"8Intensità di correntei=dqdtLa carica che attraversa la superficie S è al netto delle cariche positive e negative Dal punto di vista sperimentale, in elettromagnetismo, il moto di una carica positiva è equivalente al moto di una carica negativa che procede in verso opposto
Sdq=dq++dq-VAVBConvenzione: verso positivo delle correnti quello in cui si muovono i portatori di carica positivi  la corrente ha verso opposto alla velocità di deriva degli elettroni"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#8,8,"9Intensità di corrente
̂nα
dSdS´VAVB⟨⃗v+⟩Consideriamo un tubo (di flusso) cilindrico di sezione infinitesimafissiamo il verso della corrente concorde alla velocità di derivain un intervallo dt, avremo una quantità di carica dq (positiva) che attraversa il volume d𝜏 delimitato dalle superfici orientate S e S´  n=Ndτnumero di portatori di carica N per unità di volumecarica elementare (positiva)d𝜏dq=Ne+=nq+edτdτ=[(⃗vd⋅̂n)dt]dS(⃗vd⋅̂n)dtaltezza del cilindretto obliquo"
data_test\rootfolder\università\FisicaGenerale\11-correnti.pdf#9,9,"10Densità di correnteDefiniamo il vettore densità di corrente elettricai=dqdt=∬S⃗𝚥⋅̂ndSRiscriviamo la carica che attraversa il volume d𝜏
̂nα
dSdS´VAVB⃗𝚥d𝜏
Corrente (infinitesima) che attraversa una superficie dSL’intensità di corrente è pari al flusso della densità di corrente attraverso la sezione del conduttore
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
Flusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: 
37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=""v!t!""!v()=#V#t=""v#t#t=""v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v
Flusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: 
38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos""!viˆn=!vˆn1""cos""=vcos""#S!v()=!v=Svcos""=!viˆnS!ˆn!Sr!v
Flusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: 
39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS""""d!=dScos""d!!SdSd!!vd#dS!v()=vd!=vdScos""=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) 
Flusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. 
40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) 
dSdS!viˆnd!!S!v()=!viˆndSS""""
⃗𝚥di=(dqdt)dS=⃗𝚥⋅̂ndSdq=nqe[(⃗vd⋅̂n)dt]dS=[(nqe⃗vd)⋅̂n]dSdt⃗𝚥=nqe⃗vd"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#0,0,1 Cmpi magnetici stazionari CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#1,1,"2Fenomeni magneticiI fenomeni magnetici sono noti dall’antichità  (Talete, Archimede, Cinesi…) Il minerale magnetite (FeO+Fe2O3+FeO4) ha la capacità di attrarre oggetti contenenti ferro o materiali ferrosi
Esistenza forze magnetiche
Limatura di ferro vicino ad una calamita è attratta maggiormente dagli estremi (poli magnetici) in cui sembra si concentri la forza"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#10,10,"Rotore e circuitazione del campo magnetico
11
Le linee del campo magnetico sono sempre chiuse  𝛤La circuitazione lungo una generica linea chiusa 𝛤 sarà in generale non nullaAnche il rotore del campo magnetico (thm Stokes) sarà in generale non nullo⃗∇∧⃗B≠0
Il campo magnetico NON è conservativo∮Γ⃗B⋅d⃗l≠0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#11,11,"Magneti, cariche elettriche, correnti
12Le forze a cui sono sottoposti gli aghi magnetici corrispondono a quelle dei dipoli elettrici, piuttosto che a quelle delle cariche singoleNon ci sono interazioni tra magneti e cariche elettriche fermeCosa succede se avviciniamo un magnete a delle cariche in movimento ? (filo percorso da corrente)
Consideriamo un esperimento in cui colleghiamo un filo conduttore ad un generatore  di f.e.m. Poniamo un ago magnetico vicino al tratto di filo rettilineo"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#12,12,"Esperimento di Oersted (1820)
13
A circuito aperto, l’ago non sente nessuna forza e resta fermoChiudendo il circuito, nel filo passa corrente e l’ago si orienta perpendicolarmente al filoInvertendo la polarità del generatore, l’ago ruota in senso opposto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#13,13,"Esperimento di Faraday (1821)
14
Poniamo un filo conduttore in un campo magneticoSe nel conduttore passa corrente, esso sente una forzapossiamo bilanciare (→ misurare) la forza con dei pesi"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#14,14,"Esperimento di Ampère (1820)
15
Esperimento con due fili rettilinei e paralleli percorsi da corrente
I fili si attraggono se le correnti hanno lo stesso versoI fili si respingono se le correnti hanno verso opposto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#15,15,"Cariche in movimento e campi magnetici
16Si osservano interazioni di tipo magnetico tra: •magneti •magneti e fili percorsi da corrente  •fili percorsi da correntePossiamo concludere che le correnti generano dei campi magneticiMa le correnti sono cariche in movimento
I campi magnetici sono generati da cariche in movimento sia macroscopicamente (correnti) che microscopicamente (magneti)Domanda: cariche in movimento sono l’unico modo per generare campi magnetici?I movimenti possono essere anche microscopici (elettroni che orbitano attorno ai nuclei, all’interno delle calamite)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#16,16,"Magnetostatica nel vuoto
17Consideriamo un circuito in corrente stazionaria i e consideriamo un piccolo tratto      che sia  •libero di muoversi su connessioni flessibili e mediante un dinamometro. •elettricamente neutro •orientato con il verso della corrente •immerso in un campo magnetico d⃗ld⃗FIl tratto di filo     subisce una forza     con le seguenti caratteristiche:d⃗l|d⃗F|∝i|d⃗l|d⃗F⊥d⃗ld⃗F=0Quando la corrente (    )  e il campo magnetico sono parallelid⃗l
iRdinamometro a molle𝓔(entrante nel piano)⃗Bd⃗l"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#17,17,"Seconda legge di Laplace
18d⃗F=id⃗l∧⃗BUn tratto di filo percorso da corrente ed immerso in un campo di induzione magnetica subisce una forza descritta da:
Definizione operativa del campo induzione magnetica⃗Bla direzione ed il verso di       sono determinati dalla corrente che circola nel filod⃗l
Regola della mano destra"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#18,18,19Seconda legge di Laplaced⃗F=id⃗l∧⃗BCosa succede a livello microscopico nel filo?Una sezione dS del filo sarà attraversata da una densità di corrente di modulo j=i/dSid⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτdi=⃗𝚥⋅̂ndS⃗𝚥 orientato come d⃗lForza magnetica sull’intero volume del filodτ volume infinitesimo⃗F=∫filo⃗𝚥∧⃗BdτForza magnetica su un volume infinitesimod⃗Fτ=⃗𝚥∧⃗Bdτ
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#19,19,"Forza magnetica su cariche puntiformi
20La densità di corrente era stata definita come:⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di derivaLa forza magnetica per unità di volume diventad⃗Fτ=⃗𝚥∧⃗Bdτ=nq⃗vd∧⃗Bdτ=Nq⃗vd∧⃗B⃗F=q⃗v∧⃗BIn base a questa relazione, possiamo generalizzare al caso di una singola carica puntiforme q che in moto con velocità    , in presenza di un campo di induzione magnetica    , subisce una forza  (forza di Lorentz)  ⃗B⃗v"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#2,2,"Fenomeni magnetici
3Le calamite esercitano forze tra di loro, che possono essere attrattive o repulsive In analogia con l’elettrostatica, possiamo introdurre la definizione di poli magnetici NORD e SUD La definizione deriva dal fatto che la Terra si comporta come una calamita in una calamita il polo sud si orienta verso il sud geografico e il polo nord con il nord terrestre
S
N"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#20,20,"Forza di Lorentz
21⃗F=q⃗v∧⃗BMetodo alternativo per definire il campo induzione magnetica (usando una singola carica)Tale relazione è puntuale (vale in ciascun punto dello spazio) ed è più precisa della seconda legge di Laplace (definita su un tratto     )d⃗lDall’espressione della Forza di Lorentz ricaviamo che il campo magnetico ha le dimensioni di una forza su carica e velocità. Nel S.I. il campo magnetico si misura in Tesla (T)  1T=1V 1s/1m2 "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#21,21,"Forza di Lorentz
22⃗F=q⃗v∧⃗BIn presenza di un campo di induzione magnetica: •Cariche ferme non soggette a forza di Lorentz  •Cariche in movimento soggette a forza di Lorentz 
La forza di Lorentz è sempre perpendicolare al campo induzione magnetica 
La forza di Lorentz è sempre perpendicolare alla velocità  (centripeta)  
La forza di Lorentz non compie lavoro sulla carica in moto (è conservativa???)
direzione della forza data dalla regola della mano destraF=qvBsinαModulo della forza di Lorentz𝛼"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#22,22,"Forza di Lorentz generalizzata
23⃗F=q⃗E+q⃗v∧⃗BSe sono presenti sia un campo elettrico che un campo magnetico la forza di Lorentz si scrive⃗F=q(⃗E+⃗v∧⃗B)Le cariche elettriche interagiscono con il campo elettrico ed il campo magnetico •Cariche ferme sentono solo gli effetti del campo elettrico •Cariche in moto sentono sia l’effetto del campo elettrico che del campo magneticoCosa succede che se cambiamo Sistema di Riferimento? (esempio, se scegliamo un SdR solidale con la carica in moto?)Le leggi della Fisica devono essere invarianti: non devono dipendere dal SdR.  Importante indizio del fatto che campo elettrico e campo magnetico sono strettamente legati: sono due aspetti della stessa entità fisica: il campo elettromagnetico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#23,23,"Moto di cariche in campi magnetici
24Studiamo il moto di una carica q che si muove con velocità costante, perpendicolare ad un campo magnetico uniformeLa forza di Lorentz è ortogonale a velocità e campo magnetico. Forza e velocità sono complanari. ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗F⃗FPer calcolare il raggio di curvatura R dell’orbita ricordiamo che nella cinematica di un moto curvilineo l’accelerazione è⃗a=dvdt̂ut+v2R̂n⃗vcostanteForza centripeta: moto circolare uniforme⃗v⃗vR"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#24,24,"Moto di cariche in campi magnetici
25⃗F=m⃗a=mv2R̂n⃗F=q⃗v∧⃗B=qvB̂n̂n=⃗v∧⃗Bvbsinα=1mv2R=qvBForza centripetaForza di Lorentzdirezione e verso della forza di LorentzLa forza di Lorentz è centripetaR=mvqBRaggio di curvatura⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BR⃗F⃗F⃗v⃗v"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#25,25,"Moto di cariche in campi magnetici
26Calcoliamo il periodo di rotazione⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ La velocità angolare (o frequenza angolare)ω=vR=vqBmv=qBm(T=2πω)Il periodo e la frequenza non dipendono né dal raggio né dalla velocità T=2πRv=2πvmvqB=2πmqB⃗F⃗F⃗v⃗v⃗BR"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#26,26,"Circuito in campo magnetico
27Utilizziamo la seconda legge di Laplace per determinare le azioni meccaniche cui è soggetto un circuito percorso da corrente  immerso in un campo magnetico  d⃗F=id⃗l∧⃗BSupponiamo che il circuito sia: •rigido (non cambia forma) •la corrente i sia mantenuta costante da un generatore di f.e.m. (anche se vedremo che B tende a modificare la corrente nel circuito…)La forza totale sul circuitoIl momento (delle forze) totale sul circuito⃗rDistanza tre dl e il polo⃗F=i∮d⃗l∧⃗B⃗M=∮⃗r∧d⃗F=i∮⃗r∧(d⃗l∧⃗B)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#27,27,"Spira in un campo magnetico
28Consideriamo il caso semplice di una spira rettangolare di lati a e b immersa in un campo induzione magnetica uniforme (diretto lungo l’asse z).⃗B̂n1ba234𝜃Calcoliamo la forza agente su ogni lato⃗F1=∫1id⃗l∧⃗B=∫1iBdl̂𝚥=ilB̂𝚥i⃗F1l=axy⃗F2=∫2id⃗l∧⃗B=∫2iBdl(−̂ı)=−ilB̂ıl=b⃗F3=∫3id⃗l∧⃗B=∫3iBdl(−̂𝚥)=−ilB̂𝚥=−⃗F1⃗F4l=al=b⃗Ftot=∑⃗Fi=0La forza totale sulla spira è nulla⃗F2⃗F3⃗F4=∫4id⃗l∧⃗B=∫4iBdl̂ı=ilB̂ı=−⃗F2z"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#28,28,"Spira in un campo magnetico
29zSe il sistema è visto dall’alto:⃗B̂n1ba234𝜃ixyzTuttavia il momento delle forze sarà non nulloCalcoliamo il momento rispetto al centro della spira⃗r1⃗M1=⃗r1∧⃗F1=0⃗F1⃗r1//⃗F1⃗F4⃗r2⃗B
̂n𝜃ixb/2b/2𝜃𝜃⃗M3=⃗r3∧⃗F3=0⃗r3//⃗F3⃗F2⃗M2=⃗r2∧⃗F2=(b2)(iaB)sinθ(̂𝚥)⃗M4=⃗r4∧⃗F4=(b2)(iaB)sinθ(̂𝚥)⃗r4⃗Mtot=⃗M1+⃗M2=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è diretto verso l’alto (lungo asse di rotazione)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#29,29,"Momento magnetico di una spira
30⃗M=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è proporzionale alla corrente e al prodotto vettoriale tra superficie della spira orientata e campo induzione magneticaDefiniamo il momento magnetico della spira di area S percorsa da corrente i ⃗m=iŜnS=ab superficie della spiraè il versore normale alla spira orientato in verso tale che esso vede circolare la corrente in verso antiorario (regola della mano destra)̂n
̂n⃗M=⃗m∧⃗BIl momento delle forze è uguale al prodotto vettoriale del momento magnetico della spira per il campo induzione magnetica(si dimostra che la relazione vale per spire di qualsiasi forma                     )d⃗m=îndS"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#3,3,"Interazioni tra calamite
4
Poli opposti (N-S) si attraggonoPoli stesso segno (N-N o S-S) si respingono"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#30,30,"Teorema di equivalenza di Ampère
31
Una spira percorsa da corrente immersa in un campo magnetico si comporta come un dipolo magnetico elementare (ago magnetico) di momento                , perpendicolare al piano della spira e orientato con la regola della mano destra⃗m=iŜnSulla spira agisce un momento di forze solo se il campo magnetico ed il momento della spira formano un angolo 𝜃≠0 La coppia di forze è nulla quando campo magnetico e momento magnetico sono allineati (𝜃=0)La relazione tra momento delle forze su una spira e campo induzione è analoga al dipolo elettrico immerso in un campo elettrico⃗M=⃗p∧⃗E"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#31,31,"Esempio
32v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#32,32,"Galvanometro
33Il galvanometro è uno strumento utilizzato per misurare piccole intensità di corrente
Il momento delle forze magnetiche sulla spira è bilanciato dal momento delle forze elasticheMolla a spiraleMmolla=−kαk costante elastica 𝛼 angolo di aperturaAll’equilibrio⃗Mmolla=⃗MMi=kαSBSistema fatto in modo che 𝜃≈90° 𝜃≈90° MM=−iSBsinθ≃−iSBMisura della corrente"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#33,33,"Motore elettrico
34Il motore elettrico trasforma energia elettrica in energia meccanica
La spira percorsa da corrente è messa in rotazione dall’interazione con il campo magneticoPer mantenere la rotazione sempre nello stesso senso si usano delle spazzole in contatto sul commutatore per invertire il verso della corrente nella spira"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#34,34,"Altoparlante
35
impulso elettrico modulato dalla frequenza sonoraIl filo è collegato rigidamente al cono di cartoneQuando nel filo passa corrente (variabile nel tempo, modulata sulla frequenza sonora), esso sente la forza magnetica e mette in vibrazione l’altoparlante La vibrazione del cono produce onde sonore (conversione di energia elettrica in energia meccanica delle onde sonore)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#35,35,"Prima legge di Laplace
36
Evidenze sperimentali mostrano che i fili percorsi da corrente generano campi magneticid⃗B=μ0i4πd⃗l∧̂urr2d⃗B=μ0i4πd⃗l∧⃗rr3Consideriamo un tratto di filo infinitesimo      percorso da corrente i. Sperimentalmente si osserva che il campo magnetico generato a distanza    vale: ⃗rd⃗ld⃗lentrante se     e nel piano del foglio⃗rd⃗lxyz⃗r⃗B⨂iLa costante 𝜇0 è la permeabilità magnetica del vuotoμ0=4π×10−7VsmA=4π×10−7NA2=4π×10−7HmHenry (H)  1H=1𝛺 1s"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#36,36,"Prima legge di Laplace
37d⃗lxyz⃗Bi⨂⃗r−⃗r′ ⃗r⃗r′ d⃗B=μ0i4πd⃗l∧(⃗r−⃗r′ )(⃗r−⃗r′ )3Notazione in forma più generale⃗B=μ04π∫lid⃗l∧(⃗r−⃗r′ )(⃗r−⃗r′ )3Il campo generato da un intero circuito l si ottiene integrandoVerifichiamo che il campo B è solenoidale⃗∇⋅⃗B=⃗∇⋅(μ0i4πd⃗l∧⃗rr3)=μ0i4π[(⃗∇∧d⃗l)⋅⃗rr3−d⃗l⋅(⃗∇∧⃗rr3)]=0⃗∇⋅(⃗A∧⃗B)=(⃗∇∧⃗A)⋅⃗B−⃗A⋅(⃗∇∧⃗B)=0  un vettore costante è irrotazionale=0  un vettore radiale è irrotazionale"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#37,37,"Prima legge di Laplace
38|d⃗B|=μ0i4πdlsinθr2Modulo del campo magnetico:d⃗lxyz⃗r⃗B⨂iθL’angolo 𝜃 è tra la direzione della corrente e la posizione del punto in cui calcoliamo il campo magnetico se sin𝜃=0;180°  ⇒ dB=0: lungo la direzione della corrente non viene generato campo magnetico dB∝1r2come la legge di Coulomb per le cariche puntiformidB∝idipende dall’intensità della corrente, e quindi dal numero di portatori di caricadB⊥d⃗ldB⊥d⃗rperpendicolare al piano definito da corrente e posizione"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#38,38,"Legge di Biot-Savart
39Determinare il campo induzione magnetica generato da un filo rettilineo di lunghezza indefinita, percorso da corrente i 
⃗B=μ0i2πr̂utLegge di Biot-Savart• il campo magnetico ha intensità inversamente proporzionale alla distanza dal filo • le linee di campo sono circonferenze nel piano trasverso al filo, centrate sul filo stesso • L’orientazione delle linee di campo segue la regola della mano destra "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#39,39,"Forza tra due fili percorsi da corrente
40
L’esperimento di Ampère evidenzia la forza tra due fili percorsi da correnteConsideriamo due fili rettilinei di lunghezza indefinita, paralleli, posti a distanza d, percorsi da correnti i1 e i2 (iniziamo con il caso di correnti equiverse)di1i2Il filo 1 genera a distanza d un campo magnetico ⃗B1⨂B1=μ0i12πdun tratto di filo dl2 sente una forza magneticad⃗F12=i2d⃗l2∧⃗B1d⃗l2(II Legge Laplace)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#4,4,"Campo magnetico
5In analogia con l’elettrostatica, viene naturale introdurre un campo vettoriale      detto  campo magnetico⃗Bconvenzione: le linee di forza del campo magnetico entrano nel polo sud e escono dal polo nord Le linee di campo sono tangenti alla direzione lungo la quale si allineano gli aghi magneticiL’intensità è proporzionale al momento delle forze sull’ago
S
N
S
N
S
N
S
N
S
N
S
NIl campo      può essere anche definito come campo induzione magnetica⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#40,40,"41d⨂d⃗F12=i2d⃗l2∧⃗B1Forza tra due fili percorsi da correntedF12=i2dl2B1sinθ=i2dl2μ0i12πd𝜃=90°Forza sul filo 2:Modulo della forzadF12=μ02πi1i2ddl2i1i2Direzione di dF12: perpendicolare ai fili, diretta da 2 verso 1 Analogamente, sul filo 1dF21=μ02πi1i2ddl1d⃗F21=iid⃗l1∧⃗B2=−d⃗F21La forza dF21 esercitata dal filo 2 sul filo 1 è uguale e opposta (attrattiva)d⃗F12d⃗l2⃗B1"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#41,41,"Forza tra due fili percorsi da corrente
42d𝜃=90°i1i2⨂Se le correnti correnti i1 e i2 sono dirette in verso opposto le forze tra i fili saranno anch’esse opposte e repulsivePer il terzo principio della dinamica, le forze tra i due fili interagenti devono sempre essere uguali e opposteSu un tratto di filo L finito, basta integrare su dl|⃗F|=μ02πi1i2dLForza per unità di lunghezzadFdl=μ02πi1i2dd⃗F12d⃗l2⃗B1"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#42,42,"Definizione operativa della corrente
43Un ampere è l'intensità di corrente elettrica che, se mantenuta in due conduttori lineari paralleli, di lunghezza infinita e sezione trasversale trascurabile, posti a un metro di distanza l'uno dall'altro nel vuoto, produce tra questi una forza pari a 2 × 10-7 N per ogni metro di lunghezza.Tale definizione fissa anche il valore di 𝜇0 . La definizione operativa della corrente (e quindi della carica elettrica) sono fatte attraverso la misura di una forza  "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#43,43,"Campi magnetici da cariche puntiformi in moto
44d⃗B=μ0i4πd⃗l∧̂urr2Se esprimiamo la corrente in funzione della densità di corrente:id⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτ⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di deriva=μ04π⃗𝚥∧⃗rr3dτ=Nμ04πq⃗vd∧⃗rr3La prima legge di Laplace può essere riformulataCampo magnetico generato da N portatori di caricaUna singola carica in movimento genera un campo magnetico che a distanza r dalla carica vale⃗B=μ04πq⃗v∧⃗rr3"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#44,44,"Campi magnetici da cariche puntiformi in moto
45⃗B=μ04πq⃗v∧⃗rr3Tale formula vale in un Sistema di Riferimento in cui q si muove con velocità vIn un SdR in cui la carica è ferma si ha che B=0 !!!Ricordiamo che a distanza r, la carica genera un campo elettrico⃗E=q4πε0⃗rr3Ammettendo che questa relazione sia valida anche per cariche in motoq⃗rr3=4πε0⃗E⃗B=μ04π⃗v∧q⃗rr3=⃗B=μ0ε0⃗v∧⃗E=1c2⃗v∧⃗Ec=1μ0ε0Chiara relazione tra campi elettrico e magnetico generati da una carica in motovelocità della luce nel vuoto…=3×108m/sμ04π⃗v∧⃗E4πε0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#45,45,"Campo da spira circolare
46Determinare il campo induzione magnetica sull’asse di una spira circolare di raggio R percorsa da corrente i 
Bz==μ0i2R2(R2+z2)3/2=μ02πm(R2+z2)3/2⃗m=iŜk=iπR2̂k"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#46,46,"Esempio
474.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .
Evi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#47,47,"Esempio
484.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .
Evi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni.v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#48,48,"Esempio
49v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai."
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#49,49,"Flusso del campo magnetico
50Abbiamo già dimostrato che il campo magnetico è solenoidale⃗∇⋅⃗B=0Per il teorema della divergenza, il flusso del campo magnetico attraverso una qualsiasi superficie chiusa sarà nullo: NON esistono cariche magnetiche isolateIl flusso attraverso una superficie aperta avrà un suo valore, non necessariamente nullo, ci torneremo in seguito…∬Saperta⃗B⋅̂ndS∬Schiusa⃗B⋅̂ndS=∭τ(S)⃗∇⋅⃗B=0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#5,5,"6Campo magnetico
La limatura di ferro si orienta con il campo magnetico delle calamite
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#50,50,"Circuitazione del campo magnetico
51Dal momento che le linee di forza del campo magnetico sono sempre chiuse, ci aspettiamo che la circuitazione può essere non-nullaSemplificando, calcoliamo la circuitazione del campo magnetico generato da un filo rettilineo indefinito percorso da corrente iCalcoliamo la circuitazione lungo una linea chiusa e orientata 𝛤 che concatena il filo. Su un tratto infinitesimo:îtrd𝜙=μ0i2πrrdϕ̂ut⋅d⃗l=rdϕProiezione su circonferenza (arco di circonferenza) ∮Γ⃗B⋅d⃗l=∫2π0μ0i2πdϕ=±μ0iSegno dipende da corrente (regola mano destra)𝛤d⃗l⃗B⋅d⃗l=μ0i2πr̂ut⋅d⃗l⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#51,51,"Circuitazione del campo magnetico
52Se invece la linea chiusa 𝛤  non “concatena” il filo:i𝛤⃗B⋅d⃗l1=μ0i2πr1̂ut⋅d⃗l1=μ0i2πr1r1dϕd⃗l1⃗B⋅d⃗l2=μ0i2πr2̂ut⋅d⃗l2=μ0i2πr2r2(−dϕ)per ogni angolo d𝜙 ci saranno sempre due tratti precorsi in verso oppostole due proiezioni sottendono lo stesso angolo, quindi il contributo alla circuitazione è nullo∮Γ⃗B⋅d⃗l=0d𝜙d⃗l2⃗B⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#52,52,"Legge di Ampère
53Il segno delle correnti si valuta usando la regola della mano destra, rispetto al verso di percorrenza della curva orientata 𝛤
La circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate ∮Γ⃗B⋅d⃗l=μ0conc∑kikLegge di Ampère fornisce un metodo per il calcolo del campo magnetico in particolari condizioni di simmetria"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#53,53,"54Circuitazione del campo magneticoPossiamo prendere un numero qualsiasi di correnti concatenate, su circuiti di forma arbitraria
∮Γ1⃗B⋅d⃗l=0∮Γ2⃗B⋅d⃗l=μ0(i1−i2)∮Γ3⃗B⋅d⃗l=μ0(−i1+i2−i3)∮Γ1⃗B⋅d⃗l=μ0i1∮Γ2⃗B⋅d⃗l=μ0(−i2−i3)∮Γ3⃗B⋅d⃗l=0"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#54,54,"Densità di corrente concatenata
55Consideriamo N fili, ciascuno di sezione Sk, percorsi da correnti ikCiascuna corrente può essere scritta in funzione della densità di corrente:ik=∬⃗𝚥k⋅̂nkdSk
i1-i2i3𝛤SS1S2S3La somma delle correnti concatenate alla curva 𝛤 conc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSDove S è una generica superficie orientata che ha per bordo 𝛤 e  jc è la densità di corrente concatenata "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#55,55,"56Il teorema di StokesConsideriamo una superficie S aperta orientata avente come bordo una linea chiusa orientata 𝛤 
𝛤S(𝛤)̂n̂n
Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: 
45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!
Flusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146
!tot!v()=!viˆndSStot""""""==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146
L’Operatore Divergenza 
48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı""""x+ˆ!""""y+ˆk""""z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk
Esempio:""vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V""""i""v()x,y,z()=2x+1!!!!i!v=div!v=""vx""x+""vy""y+""vz""z!!i!v=ˆı""""x+ˆ!""""y+ˆk""""z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()""v""#""""vP()!VP!!3()""$i""v""#""""""$i""v()P()!!%&'('𝛤∮Γ⃗F⋅d⃗lDefiniamo la circuitazione del campo lungo la linea chiusa orientata 𝛤 "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#56,56,57Il teorema di StokesIl flusso del rotore di un campo vettoriale attraverso una superficie S aperta e orientata è uguale alla circuitazione del campo vettoriale lungo il bordo 𝛤 di tale superficie∬S(Γ)(⃗∇∧⃗F)⋅̂ndS=∮Γ⃗F⋅d⃗lIl teorema di Stokes mette in relazione un integrale di superficie con un integrale di linea 
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#57,57,"Il rotore del campo magnetico
58Riscriviamo la legge di Ampère in funzione della densità di corrente concatenataconc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSS è una generica superficie con bordo 𝛤 Applichiamo il teorema di Stokes:∮Γ⃗B⋅d⃗l=μ0conc∑kik=μ0∬S⃗𝚥C⋅̂ndS∮Γ⃗B⋅d⃗l=∬S⃗∇∧⃗B⋅̂ndS=μ0∬S⃗𝚥C⋅̂ndSL’uguaglianza è vera per qualsiasi superficie S con bordo 𝛤 
Legge di Ampère in forma locale ⃗∇∧⃗B=μ0⃗𝚥In ogni punto dello spazio, il rotore del campo magnetico è proporzionale alla densità di corrente in quel punto"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#58,58,"Esempio
59Calcolare il campo di un filo di lunghezza indefinita percorso da corrente i utilizzando la legge di Ampère"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#59,59,"Esempio
60Determinare in tutto lo spazio il campo magnetico generato da un cilindro conduttore di raggio R e lunghezza indefinita percorso uniformemente da una corrente di intensità i "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#6,6,"Campo magnetico terrestre
7
Un ago magnetico libero di ruotare si orienta  con la linea di campo che esce dal polo nord (del magnete) e entra dal polo sud (del magnete)Ciò significa che la Terra si comporta come un magnete le cui linee di campo escono dal polo sud geografico ed entrano nel polo nord geografico.Convenzionalmente il polo nord magnetico coincide con il polo sud geografico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#60,60,"Esempio
61v	v	v	v	v	v	v	v	R1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.
rεv	v	v	v	Rxy
Figure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.
⃗B=μonîk=μ0NLîk̂kCampo interno al solenoide (ideale)Esternamente il campo è nullo"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#61,61,"Esempio
626.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2 r2)(c2 b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=""0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0""0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2 S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e t/⌧dR⌧))
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#62,62,"Magnetismo nella materia
63Cosa succede se riempiamo la parte interna di un solenoide rettilineo ideale?Si osserverà una variazione del campo magnetico: alluminio, platino, sodio: leggero aumento   → materiali PARAMAGNETICIferro, nichel, cobalto: considerevole aumento → materiali FERROMAGNETICI
materiali organici, rame, argento: leggera diminuzione  → materiali DIAMAGNETICII materiali ferromagnetici restano magnetizzati "
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#63,63,"64Momento magnetico orbitalePer spiegare il magnetismo nella materia occorre partire dalla struttura microscopicaIn un modello molto semplificato possiamo pensare gli elettroni più esterni in rotazione intorno al nucleoPartiamo dal caso più semplice: l’atomo di idrogenoEssendo la forza coulombiana centripetaricaviamo la velocità di rotazione:14πε0qeqpr2H=mev2rHRH=5.3×10−11m
RH=5.3×10−11mme=9.1×10−31kg|qe|=|qp|=1.6×10−19Cv=14πε0qeqpmerH=2.2×106m/s"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#64,64,65Momento magnetico orbitalepossiamo pensare che un elettrone che ruota intorno al nucleo genera una correnteil momento magnetico dell’elettronei=−qeTdove il periodoT=2πRHvdefinendo il momento angolare orbitale:⃗po=⃗RH∧me⃗vmo=iS=iπR2H=−qev2πRHπR2H=−qev2RHmememo=iS=iπR2H=−qev2πRHπR2H==−qev2RHmeme⃗mo=−qe2me⃗po
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#65,65,"Momento magnetico di spin
66Oltre al momento magnetico orbitale, si può osservare che gli elettroni hanno un ulteriore momento magnetico di spin (come se gli elettroni ruotassero intorno al proprio asse)⃗ms=−qeme⃗psIl momento magnetico totale (o intrinseco) è dato da una combinazione di momento orbitale e momento di spin. L’accoppiamento è descritto dalle leggi della meccanica quantisticaIn un generico atomo, il momento magnetico dipende dagli elettroni più esterniIn assenza di campi magnetici esterni, il momento magnetico totale macroscopico è nullo, perché i momenti magnetici degli atomi sono orientati casualmente e la loro somma vettoriale è nulla
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#66,66,"Materiali diamagnetici
67In presenza di campo magnetico esterno occorre fare delle distinzioniLa maggior parte dei materiali ha atomi con momento magnetico nullo. In questi materiali, l’effetto di un campo esterno è quello di deviare la traiettoria degli elettroni in moto (forza di Lorenz), inducendo una variazione di velocità (l’elettrone si allontana dal nucleo) e quindi una diminuzione della frequenza di rotazione (precessione di Larmor)L’effetto complessivo è una diminuzione del momento magnetico, che va ad opporsi leggermente al campo magnetico esternoTali materiali sono chiamati diamagnetici (in genere hanno un numero pari di elettroni e struttura simmetrica)
"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#67,67,"Materiali paramagnetici
68I materiali paramagnetici hanno atomi con momento angolare intrinseco diverso da zero
I materiali paramagnetici sono caratterizzati da un numero dispari di elettroni  o da strutture atomiche asimmetricheGli atomi si comportano come dipoli magnetici che per effetto di un campo magnetico esterno tendono ad allinearsi  con il campo magnetico esterno, contribuendo ad aumentarne leggermente il valore
B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#68,68,"Vettore magnetizzazione
69Definiamo il vettore magnetizzazione come il prodotto del momento angolare intrinseco medio del materiale per il numero di atomi per unità di volume⟨⃗m⟩⃗M=n⟨⃗m⟩=Ndτ⟨⃗m⟩dipende dai momenti magnetici orbitali e di spinIl campo magnetico totale nella materia dipenderà dal vettore magnetizzazione:⃗B=⃗B0+μ0⃗MPossiamo definire la densità di corrente di magnetizzazione⃗jM=⃗∇∧⃗MDa cui ricaviamo le relazione⃗∇∧⃗B=⃗∇∧(⃗B0+μ0⃗M)==⃗∇∧⃗B0+μ0⃗∇∧⃗M=Legge di Ampère in forma locale=μ0⃗J+μ0⃗JM"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#69,69,"Il vettore H
70⃗∇∧⃗B=μ0(⃗J+⃗JM)Il campo magnetico totale B è generato dalle correnti di conduzione e dalle correnti di magnetizzazione
Partendo dalla relazione⃗∇∧⃗B=μ0⃗J+μ0⃗∇∧⃗M⃗∇∧(⃗B−μ0⃗Mμ0)=⃗JDefiniamo il vettore H che descrive il campo magnetico nella materia,  in funzione solo delle correnti di conduzione lungo i fili⃗H=⃗B−μ0⃗Mμ0=⃗Bμ0−⃗M⃗∇∧⃗H=⃗J⃗B=μ0⃗H+μ0⃗M"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#7,7,"Poprietà del campo magnetico
8La forza magnetica tra due calamite potrebbe essere descritta con una formula simile alla legge di Coulomb (fine 1700)⃗FM=kMm1m2r2̂urm1 e m2 sono le “cariche magnetiche” kM è una costante magneticaLa forza magnetica è proporzionale al prodotto delle cariche magnetiche ed inversamente proporzionale al quadrato della distanza Attrattiva per cariche magnetiche opposte, repulsiva per cariche magnetiche ugualiUnica analogia con forza elettrostatica di Coulomb!!"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#70,70,"Magnetismo nella materia
71Nei materiali diamagnetici e paramagnetici, omogenei e isotropi i campi B H e M sono paralleli, e vengono espressi dalle relazioni⃗B=μrμ0⃗HDove:μrPermeabilità magnetica relativa⃗M=(μr−1)⃗H=χm⃗Hχm=(μr−1)Suscettività magnetica   {negativa per diamagneticipositiva per paramagnetici(molto piccola 10-4 —10-6)⃗M=(1μ0−1μ0μr)⃗B"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#71,71,"Materiali ferromagnetici
72I materiali ferromagnetici microscopicamente hanno una configurazione elettronica per cui si creano forti interazioni tra momenti orbitali e momenti di spinTali interazioni comportano che momenti magnetici di atomi adiacenti si “accoppiano”, aumentando considerevolmente il loro effetto magnetico rispetto al singolo atomoAll’interno del materiale si creano regioni formate da numerosi dipoli allineati (domini di Weiss) I domini di Weiss hanno tipicamente volumi di 10-12 —10-12 m3 e contengono 1017 —1011 atomi 
Se il materiale non ha subito magnetizzazione, le direzioni dei momenti sono casuali"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#72,72,"73Materiali ferromagneticiQuando un materiale ferromagnetico viene posto in un campo magnetico esterno i momenti si allineano con il campo magnetico, generando un allargamento (una fusione) dei domini di Weiss
Ponendo campi magnetici sempre più intensi, si arriva ad una condizione di saturazioneIl materiale mantiene una magnetizzazione residua anche fuori dal campo magneticoI domini di Weiss vengono distrutti se il materiale viene riscaldato fino ad una temperatura critica (di Curie),che per il Fe vale ~1000°K"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#73,73,"Ciclo di isteresi
74Per i materiali ferromagnetici la permeabilità magnetica non è costante, può essere molto elevata e dipende dalle correnti che generano il campo esterno e dalla storia di magnetizzazione. Inseriamo un cilindro di materiale ferromagnetico in un solenoide:
La curva a è detta di prima magnetizzazionediminuendo il campo H fino ad azzerarlo (curva b) nel materiale si ha una magnetizzazione residuaInvertendo il campo H, si raggiunge un valore critico HC per cui la magnetizzazione è nulla H generato da corrente nel solenoideCampo B del ferromagneteCampo M del ferromagnete"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#74,74,"Memorie di massa magnetiche
75I supporti magnetici sono largamente utilizzati per l’archiviazione dei datiPer esempio gli hard disk sono formati da dischi di alluminio o vetro rivestiti da una pellicola di materiale ferromagneticoLa memorizzazione dell’informazione avviene associando un bit di magnetizzazione (verso di magnetizzazione) su un certo numero di domini di WeissLa densità di informazione è data dal numero di domini di Weiss che costituiscono un singolo bit, moltiplicato per la loro estensione superficiale media, rapportato alla superficie di archiviazione disponibileL’accesso ai dati avviene utilizzando testine magnetoresistive che variano la resistenza al variare del campo magnetico (in lettura) e viceversa (in scrittura)"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#75,75,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
76"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#8,8,"Poli magnetici
9
Sperimentalmente, se si spezza una calamita si otterranno due nuove calamiteI poli magnetici esistono sempre a coppie di eguale valore e segno opposto: dipoli magneticiFino ad ora non è stato mai osservato un polo magnetico isolato (monopolo magnetico)Conseguenza: il campo magnetico ha proprietà molto diverse dal campo elettrostatico"
data_test\rootfolder\università\FisicaGenerale\12-magnetostatica.pdf#9,9,"Legge di Gauss per il campo magnetico
10
Le linee del campo magnetico sono sempre chiuse  (non possiamo isolare singoli poli magnetici)Il campo magnetico è solenoidale⃗∇⋅⃗B=0Di conseguenza (thm divergenza) scegliendo una qualunque superficie chiusa∬S⃗B⋅̂ndS=0La densità volumetrica di cariche magnetiche è sempre nulla (solo dipoli)S"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#0,0,1 Campi elettrici e magnetici variabili nel tempo CdS Ingegneria Informatica A.A. 2019/20 
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#1,1,"Campi elettrici in condizioni stazionarie
2⃗∇⋅⃗E=ρε0Legge di Gauss per il campo elettrico Forma integrale: il flusso del campo elettrico attraverso una superficie chiusa è proporzionale alla carica elettrica contenuta nella superficie Forma differenziale: Le cariche elettriche generano il campo elettricoΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#10,10,"Legge di Ampère e equazione di continuità
11⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza della densità di corrente compare nell’equazione di continuità (si veda cap. su correnti)In condizioni stazionarie (indipendenti dal tempo), la densità di carica è costante e la sua derivata è nulla.  In tale situazione , quindi ritroviamo che la legge di Ampère continua ad essere valida in condizioni stazionarie. Cosa succede nel caso più generale, in condizioni non necessariamente stazionarie?⃗∇⋅⃗𝚥=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#11,11,"Legge di Ampère in condizioni non stazionarie
12⃗∇⋅⃗𝚥+∂ρ∂t=0Sostituiamo nell’equazione di continuità e invertiamo gli ordini di derivazioneDalla legge di Gauss in forma locale                             ricaviamo  ⃗∇⋅⃗E=ρε0ρ=ε0⃗∇⋅⃗E⃗∇⋅⃗𝚥+∂∂t(ε0⃗∇⋅⃗E)=0⃗∇⋅⃗𝚥+ε0⃗∇⋅∂⃗E∂t=0⃗∇⋅(⃗𝚥+ε0∂⃗E∂t)=0il vettore  ha sempre divergenza nulla!(⃗𝚥+ε0∂⃗E∂t)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#12,12,"tale vettore è la somma di due termini: • densità di corrente di conduzione    (dovuta a cariche in moto) • densità di corrente di spostamento              (dovuta a variazione di campo elettrico)Legge di Ampère-Maxwell
13(⃗𝚥+ε0∂⃗E∂t)⃗𝚥ε0∂⃗E∂t⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tAggiungendo il termine di densità di corrente di spostamento nell’equazione di Ampere, otteniamo la legge di Ampère-Maxwell"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#13,13,"Legge di Ampère-Maxwell
14⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tIl rotore del campo magnetico è proporzionale alla somma della densità di corrente di conduzione  e alla variazione del campo elettrico⃗∇⋅(μ0⃗𝚥+μ0ε0∂⃗E∂t)=0In altre parole, il campo magnetico può essere generato da cariche in moto e da campi elettrici variabili nel tempoLa legge di Ampère-Maxwell è valida sempre, sia in regime stazionario che non stazionario. Infatti la divergenza della somma dei termini di densità di corrente di spostamento e conduzione è sempre nulla"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#14,14,"Corrente di spostamento
15A partire dalla densità di corrente di spostamento ⃗𝚥S=ε0∂⃗E∂tDefiniamo la corrente di spostamento come il flusso della densità di corrente attraverso una superficie aperta S: La corrente di spostamento è proporzionale alla variazione del flusso del campo elettrico e non dipende da cariche in movimento.Si osserva una corrente di spostamento nelle regioni di spazio in cui c’è un campo elettrico variabile. Esempio: all’interno di un condensatore in regime transotorio (carica/scarica)is=∬S⃗𝚥s⋅̂ndS=∬Sε0∂⃗E∂t⋅̂ndS=ε0ddt∬S⃗E⋅̂ndS=ε0dΦS(⃗E)dt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#15,15,"Legge di Ampère-Maxwell in forma integrale
16In forma integrale, la circuitazione del campo magnetico lungo una linea chiusa rimane proporzionale alla somma delle correnti concatenate, considerando sia le correnti di conduzione che le correnti di spostamento∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#16,16,"Corrente di spostamento in condensatore
17Consideriamo un circuito RC in fase di scarica. Inizialmente sul condensatore si ha una carica Q0.  Alla chiusura dell’interruttore la carica sul condensatore varia con la legge:TCRQ(0)=Q0Q(t)=Q0e−tRCNel circuito si avrà una corrente di conduzione (dovuta alle cariche che fuoriescono dal condensatore):ic(t)=dQ(t)dt=−Q0RCe−tRC"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#17,17,"Corrente di spostamento in condensatore
18Q(t)Supponiamo che il condensatore sia a facce piane e parallele. Nel condensatore carico con carica Q(t) c’è un campo elettrico (normale alla superficie S delle armature):Il campo elettrico dipende dal tempo, quindi nel condensatore si ha una densità di corrente di spostamento:  ⃗E=σε0̂n=Q(t)ε0Ŝn=Q0e−tRCε0Ŝn⃗𝚥s=ε0∂⃗E∂t=ε0∂∂t(Q0e−tRCε0S)̂n=−Q0SRCe−tRĈned una corrente di spostamento:is(t)=∬S⃗𝚥s⋅̂ndS=∬S−Q0SRCe−tRĈn⋅̂ndS=−Q0SRCe−tRC∬SdS=−Q0RCe−tRC⃗E"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#18,18,"Corrente di spostamento in condensatore
19ic(t)=is(t)=−Q0RCe−tRCNell’esempio del condensatore si trova che la corrente di conduzione e la corrente di spostamento hanno lo stesso valoreTale risultato è conseguenza dell’equazione di continuità, che lega le correnti alle variazioni di carica.𝛴⃗Eic(t)is(t)
S1S2𝛤Se infine poniamo 𝛴=S1+S2, ritroviamo la validità generale della legge di Ampère (Maxwell) Considerando una qualsiasi superficie chiusa 𝛴 che “avvolge” metà condensatore∮Γ⃗B⋅d⃗l=μ0∬S1⃗𝚥c⋅̂ndS=μ0∬S2⃗𝚥s⋅̂ndS∬Σ(⃗𝚥c+⃗𝚥s)⋅̂ndS=∬Σ(⃗𝚥c⋅̂n+⃗𝚥s⋅̂n)dS=∬Σ(jc−js)dS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#19,19,"Esempio
206.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2 r2)(c2 b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=""0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0""0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2 S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e t/⌧dR⌧))"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#2,2,"Campi elettrici in condizioni stazionarie
3Conservatività del campo elettrostatico⃗∇∧⃗E=0La circuitazione del campo elettrostatico lungo qualsiasi linea chiusa è nullaIrrotazionalità del campo elettrostatico: implica che il campo è conservativo e che possiamo definire il potenziale elettrostatico V tale che ⃗E=−⃗∇V∮Γ⃗E⋅d⃗l=0Il campo elettromotore in una pila non è conservativo. Tale relazione è verificata solamente nel caso stazionario. "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#20,20,"Interazioni tra magneti e circuiti
21Abbiamo visto che le correnti generano campi magnetici (prima legge di Laplace, Biot-Savart) E’ vero anche il contrario?Se teniamo un magnete fermo vicino ad un circuito, in esso non si osserva corrente
Se muoviamo il magnete verso il circuito, allora si osserva una corrente (nell’intervallo in cui il magnete è in movimento)
Il movimento in verso opposto, “induce” nel circuito una corrente di segno opposto"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#21,21,"Interazioni tra circuiti percorsi da corrente
22
Un effetto analogo si osserva tra due circuiti posti in vicinanzaNel circuito di sinistra si osserva una corrente per un breve intervallo di tempo dopo la chiusura/apertura dell’interruttore (effetto transitorio con corrente variabile nel tempo)
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#22,22,"Correnti indotte
23
Estraendo una spira fatta di materiale conduttore da una regione in cui è presente un campo magnetico, si misura una corrente sulla spira  • si ha corrente anche se il campo magnetico è uniforme• la corrente è massima se il piano della spira è ortogonale al campo magnetico• la corrente è nulla se il piano della spira è parallelo al campo magneticoDal momento che sul conduttore ci sono cariche libere, proviamo a spiegare il fenomeno in termini di forza di Lorentz"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#23,23,"Correnti indotte
24⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BConsideriamo un sistema formato da due binari conduttori, paralleli e connessi elettricamente⃗vPoniamo una barretta conduttrice ortogonale ai binari e mettiamola in movimento con velocità costanteSe il sistema è posto in un campo magnetico (costante, uniforme, ortogonale al piano del circuito) nel circuito circola corrente, come se ci fosse un generatore di forza elettromotrice"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#24,24,"Correnti indotte
25⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗FLe cariche libere sulla barretta sentono una forza di Lorentz:⃗v⃗F=qe⃗v∧⃗BLe cariche in un tratto dl è come se fossero sottoposte agli effetti di un campo elettromotoreN.B. gli elettroni si muovono verso l’alto, quindi la corrente convenzionalmente circola in verso orariod⃗ldℰ=⃗E⋅d⃗l=⃗Fqe⋅d⃗l=⃗v∧⃗B⋅d⃗l"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#25,25,"Correnti indotte
26⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BLa velocità può essere scritta come d⃗ld⃗x⃗v=d⃗xdtIn un intervallo dt, la barretta si sarà spostata di un tratto dxdℰ=(⃗v∧⃗B)⋅d⃗l=(d⃗xdt∧⃗B)⋅d⃗lUtilizzando le proprietà del prodotto misto:dℰ=(d⃗xdt∧⃗B)⋅d⃗l=(d⃗l∧d⃗xdt)⋅⃗B=solo dx dipende dal tempo, B e  dl sono costanti=ddt[(d⃗l∧d⃗x)⋅⃗B]⃗v"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#26,26,"Induzione elettromagnetica
27⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗Bd⃗ld⃗x
d⃗l∧d⃗x=−̂n(dldx)=−̂ndSNegativo, perché “entrante” (verso opposto a B)dℰ=ddt[⃗B⋅(d⃗l∧d⃗x)]dℰ=−ddt[⃗B⋅̂ndS]⃗B⋅̂ndS=dΦS(⃗B)⃗vdSFlusso infinitesimo del campo magnetico attraverso dS"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#27,27,"Induzione elettromagnetica
28⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ 
ℰ=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtNel circuito si genera una forza elettromotrice indotta opposta (segno meno) alla variazione del flusso del campo magnetico concatenato con la spiraIntegrando su tutta l’area S spazzata dalla barretta 
Si può dimostrare che tale relazione è valida ogni volta in cui si verifica una variazione temporale del flusso concatenato del campo magnetico⃗Bd⃗ld⃗x⃗vS"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#28,28,"Legge di Faraday-Neumann-Lenz
29La variazione temporale del flusso di un campo magnetico “induce” una forza elettromotriceℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtLa forza elettromotrice indotta si oppone alla variazione del flusso che l’ha generata Tale legge rappresenta un ulteriore metodo per generare una corrente in un conduttore  (in aggiunta a forze elettrochimiche di pile e batterie)Il segno meno nell’equazione (storicamente attribuito di Lenz) è conseguenza del 3° principio della dinamica (azione-reazione) e quindi della conservazione dell’energia"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#29,29,"Induzione elettromagnetica
30ℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dt1)area della spira variabile nel tempo 2)campo magnetico variabile nel tempo 3)moto relativo di una spira rispetto ad  campo magnetico  Con aggiunta di tutte le possibili combinazioni delle situazioni elencateConsiderando un generico circuito chiuso (una spira), il flusso del campo magnetico concatenato con la spira può variare al verificarsi di tre tre principali situazioni:"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#3,3,"Campi magnetici in condizioni stazionarie
4⃗∇⋅⃗B=0Legge di Gauss per il campo magnetico Il flusso del campo magnetico attraverso una superficie chiusa è sempre nullo non possiamo isolare cariche magnetiche (monopoli)Il campo magnetico ha sempre divergenza nulla (è solenoidale). Le linee di campo sono sempre chiuse su loro stesse∬⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#30,30,"Esempio
31Si consideri un circuito rettangolare con un lato di lunghezza L in movimento con velocità v0 costante. La resistenza totale del circuito vale R. Il circuito è completamente immerso in un campo magnetico costante ed uniforme, ortogonale al piano del circuito. Calcolare: a)l’espressione della corrente indotta nel circuito b)la forza necessaria per mantenere la velocità costanteCampo magnetico costante (e uniforme) e area della spira variabile⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ V0 L L6. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza 2R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza L dal conduttore fisso e si muove con velocità V0 costante verso destra. Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   7. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza 2L dal conduttore fisso e  s i  m u o v e  c o n  v e l o c i t à  2 V0 c o s t a n t e  v e r s o  d e s t r a .  Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   8. Un circuito elettrico è costituito da due binari conduttori paralleli di resistenza trascurabile posti ad una distanza 2D, da una conduttore fisso di resistenza 2R e da un’asta metallica AB di resistenza trascurabile che può scorrere senza attrito sui due binari (vedi figura). La posizione dell’asta AB varia nel tempo secondo la r e l a z i o n e  x ( t )  =  2 x0(1 - cosωt), con x0 ed ω costanti positive note. Il circuito è immerso in un campo induzione magnetica B, diretto perpendicolarmente al piano del circuito, la cui intensità varia nel tempo secondo la relazione B(t)=2B0(1 + cosωt), con B0 costante positiva nota. Determinare: a. la forza elettromotrice indotta nel circuito; b. il valore massimo iM dell’intensità di corrente che circola nel circuito; c. la forza che agisce sull’asta AB.       2V0 2L L
V(t) 2R xB2D A⃗B"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#31,31,"Campo magnetico variabile nel tempo e spira ferma
32S2S1Figure 15:7.3Una spira quadrata conduttrice di latol=20 cm e resistenzaR=0.1⌦si trova ad una distanza ﬁssaa=80cm da un ﬁlo rettilineo indeﬁnito percorso da una correntei. Due dei lati della spira sono paralleli al ﬁlo.Calcolare:a) il ﬂusso del campo magnetico generato dal ﬁlo , supponendo che la corrente sia costantei0=3A ( =µ0li02⇡lna+la=2.68·10 8Wb);b) la f.e.m. massima indotta sulla spira supponendo che la corrente sul ﬁlo vari con secondo la leggei(t)=i0cos(!t), con!= 2 rad/s; (Emax=µ0li0!2⇡lna+la=5.36·10 8V)c) la massima potenza dissipata dalla spira, nel caso di corrente variabile nel tempo. (Pmax=E2maxR=2.9·10 14W)7.4Una bacchetta conduttrice di lunghezzaL=9.83cmer e s i s t e n z aR= 415 m⌦viene fatta muovere con velocit` acostantev=4.86 m/s su dei binari conduttori (di resistenza trascurabile) paralleli. La bacchetta si muovein un campo magnetico generato da una correntei= 110Ache scorre in un ﬁlo parallelo ai binari, a distanzaa= 10.2mm. Calcolare:a) la corrente indotta che scorre nella spira; (iind= µ0iv2⇡Rln a+La )b) la forza che bisogna applicare esternamente alla bacchetta per tenerla in moto uniforme; (Fest=µ0iiind2⇡ln a+La )c) confrontare la potenza dissipata sulla bacchetta con la potenza fornita dalla forza esterna. (P=Ri2ind=Fv)7.5Una spira quadrata di latoL=30 cm, resistenzaR=2⌦e massam= 10g, si muove senza attrito suun piano orizzontale con velocit` av0=1 m/s, perpendicolare ad un lato. Ad un certo istantet0la spiraentra in una regione in cui presente un campo magnetico uniforme e costante di moduloB=0.5 T, direttoperpendicolaremente al piano della spira (il bordo della regione con il campo magnetico ` e parallelo al latodella spira che sta entrando, come mostrato in ﬁgura 16). Calcolare:a) la velocit` a della spira nell’istantet0in cui essa ` e entrata completamente nella regione con campomagnetico; (v(t0)=v0 B2L3mR)b) la corrente che percorre la spira nell’istantet0;(i(t0)= BLv(t0)R)c) la potenza dissipata all’istantet0.(P=B2L2v(t0)2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#32,32,"33Campo magnetico costante (non uniforme) e spira in movimento F1) Un circuito rigido quadrato, di lato L=100cm, è costituito di un filo di alluminio (resistività ρ=2.56 10-8 Ωm) di sezione S=10 mm2. Esso si trova nel piano xy con i lati paralleli ai due assi, ed è immerso (nel vuoto) in un campo di induzione magnetica uniforme di modulo Bz= 0,5T diretto lungo l’asse z nel verso positivo, limitato all’area grigia di figura. Il circuito, inizialmente tutto immerso nel campo magnetico, trasla con parallelamente all’asse x con velocità che viene mantenuta costante di modulo V0= 20 cm/s. Calcolare, giustificando:  1) il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) l’intensità  di tale corrente nel circuito durante il moto; 3) l’energia totale dissipata nel circuito per effetto Joule; 4) il lavoro effettuato per portare il circuito completamente fuori del campo.              F2) Una spira rigida a forma di triangolo equilatero di lato L=2m, massa M=100g, e resistenza R=10 Ω ,  s i  m u o v e  c o n  v e l o c i t à  c o s t a n t e  V0 =  1 0  m / s  l u n g o  l ’ a s s e  x .  N e l semipiano delle x positive è presente un campo induzione magnetica uniforme di modulo B=0.5 T diretto lungo z nel verso positivo, mentre nel semipiano delle x negative B è identicamente nullo. Calcolare: 1)  il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) il flusso di B c o n c a t e n a t o  c o n  i l  c i r c u i t o ,  n e l l ’ i s t a n t e  i n  c u i  m e t à  d e l l ’ a r e a  d e l  3) la corrente massima che circola nel circuito durante il moto; 4) l’espressione vettoriale della forza che agisce sul lato BC del circuito, all’istante       ijBv0L
ijBLABCUna spira quadrata conduttrice di lato L e resistenza R si muove con velocità costante v0 in una regione dove è presente un campo magnetico uniforme, limitato ad una regione rettangolare. a)determinare la corrente indotta sulla spira  b)il lavoro per estrarre la spira fuori dalla regione in cui è presente il campo magnetico c)l’energia dissipata per effetto Joule"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#33,33,"Generatore elettrico
34
Consideriamo un sistema di N spire rotanti con velocità angolare costante in un campo magnetico uniformesia S=area delle spire, 𝜑=𝜔t angolo tra vettore normale al piano della spira e campo magneticoin ogni istante il flusso valeΦ(⃗B)=N⃗B⋅̂nS=NBScosφ=NBScosωtnelle spire ci sarà una fem indotta:ℰ=−dΦ(⃗B)dt=−NBS(−ωsinωt)=NBSωsinωt
fem alternata
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#34,34,"Correnti di Foucault
35Le correnti di Foucault (o correnti parassite) si osservano nei conduttori in presenza di campi magnetici il cui flusso varia nel tempo. Esse sono una conseguenza del fenomeno dell’induzione magnetica. Tali correnti sono dovute al moto degli elettroni causato dalle fem indotte nel conduttore
L’effetto di tali correnti è quello di creare campi magnetici che si oppongono alla variazione che le hanno generate: effetto “frenante”Per minimizzare gli effetti delle correnti parassite, occorre “tagliare” il conduttore
"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#35,35,"Correnti di Foucault
36Le correnti di Foucault possono anche generare calore per effetto JouleTale meccanismo è alla base dei fornelli ad induzione
Perché non tutte le pentole funzionano sulle cucine ad induzione?"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#36,36,"Forma locale della legge di FNL
37ℰ=∮Γ⃗E⋅d⃗l=∬SΓ⃗∇∧⃗E⋅̂ndSℰ=∮Γ⃗E⋅d⃗l=−ddt∬SΓ⃗B⋅̂ndS=∬SΓ−∂⃗B∂t⋅̂ndS⃗∇∧⃗E=−∂⃗B∂tApplichiamo il teorema di StokesCombinando con la legge di Faraday-Neumann-LenzIl campo E è detto campo elettrico indotto  Un campo magnetico variabile nel tempo è una sorgente di campo elettrico "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#37,37,"Forma locale della legge di FNL
38⃗∇∧⃗E=−∂⃗B∂t• Il campo elettrico indotto dalla variazione di un campo magnetico ha rotore non-nullo: non è conservativoIn ogni punto dello spazio in cui è presente un campo magnetico variabile nel tempo, in quel punto si genera un campo elettrico• Il campo elettrico generato da cariche elettriche ha sempre rotore nullo ed è conservativo (campo elettrostatico)Il campo elettrico può essere generato da campi magnetici variabili nel tempo oppure da cariche elettriche"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#38,38,"Induzione mutua
39Per la prima legge di Laplace, il campo magnetico dipende linearmente dalla corrente che l’ha generato:d⃗B=μ0i4πd⃗l∧̂rr2Il flusso del campo magnetico sarà dunque proporzionale alla corrente:Φ(⃗B)=MiDove M è un coefficiente che dipende solamente dalla geometria (forma) del circuito percorso da correntei⃗B
Se le correnti sono variabili nel tempo:ℰind=−dΦ(⃗B)dt=−Mdidt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#39,39,"Induzione mutua
40Consideriamo due circuiti percorsi da correnti i1 e i2, che generano rispettivamente i campi magnetici B1 e B2 Il flusso di B1 attraverso il circuito 2 èΦ1(⃗B2)=M21i2Φ2(⃗B1)=M12i1Il flusso di B2 attraverso il circuito 1 èi1i2Si può dimostrare che M12=M21=MM è detto coefficiente di mutua induzioneNel sistema internazionale si misura in Henry (H)  1H=Tm2/A"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#4,4,"Campi magnetici in condizioni stazionarie
5∮Γ⃗B⋅d⃗l=μ0conc∑kik⃗∇∧⃗B=μ0⃗𝚥Legge di Ampère la circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate con la linea di circuitazioneIn forma locale, il rotore del campo magnetico è proporzionale alla densità di corrente. Il campo magnetico NON è conservativo Il campo magnetico è generato da correnti (cariche in movimento)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#40,40,"Esempio
41habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#41,41,"Autoinduzione
42i⃗BUn circuito percorso da corrente genera un campo magnetico Tale campo avrà un flusso concatenato con il circuito stessoSe la corrente varia nel temp, nel circuito si genererà una fem autoindottaΦ(⃗B)=LiL è detto coefficiente di autoinduzione (o induttanza) e si misura in Henryℰind=−dΦ(⃗B)dt=−LdidtLa fem autoindotta si oppone alla variazione di corrente che l’ha generata "
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#42,42,"Esempio
43Calcolare l’induttanza di un solenoide cilindrico ideale di lunghezza l formato da N spire circolari di raggio r 
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2SlSupponiamo che il solenoide sia percorso da una corrente i(t) variabile nel tempo. Internamente al solenoide vi è un campo magnetico (dipendente dal tempo): Il flusso del campo attraverso una singola spira vale ⃗BS=πr2area di una spiraB(t)=μ0Nli(t)Φspira(⃗B(t))=B(t)S=μ0Nli(t)πr2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#43,43,"Esempio
44Il flusso attraverso l’intero solenoide sarà pari ad N volte il flusso attraverso una singola spira  
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BΦsolenoide(⃗B(t))=NΦspira(⃗B(t))=Nμ0Nli(t)πr2=μ0N2li(t)πr2L’induttanza L si calcola come il rapporto tra il flusso “autoindotto”  (autoflusso) e la corrente:L=Φsolenoide(⃗B)i(t)=μ0N2lπr2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#44,44,"Esempio
45habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#45,45,"Circuiti con induttanze
46
Un solenoide inserito all’interno di un circuito percorso da corrente variabile nel tempo si comporta come un generatore di forza elettromotrice (fem autoindotta) con polarità opposta alla variazione di corrente
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BSimbolo circuitale dell’induttanza +_𝓔(t)ℰautoindotta=−dΦsolenoide(⃗B(t))dt=−Ldi(t)dtREquazione del circuitoℰ(t)−Ldi(t)dt=Ri(t)ℰ(t)+ℰautoindotta=Ri(t)La fem autoindotta si “oppone” alla variazione di corrente che l’ha generata"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#46,46,"Induttanze in serie
47+_𝓔(t)RL1L2In serie, le due induttanze sono percorse dalla stessa correnteΔV=ΔV1+ΔV2=−L1di(t)dt−L2di(t)dt=−(L1+L2)di(t)dt=−Ltotdi(t)dtDifferenza di potenziale ai capi delle due induttanze
L’induttanza del sistema formato da due (o più) induttanze collegate in serie è uguale alla somma delle singole induttanzeLtot=∑iLitrascuriamo gli effetti di mutua induzione"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#47,47,"Induttanze in parallelo
48
+_𝓔(t)RL1L2In parallelo, le due induttanze sono alla stessa differenza di potenzialetrascuriamo gli effetti di mutua induzionedi1dt=−ΔVL1di2dt=−ΔVL2=−ΔVL1−ΔVL2=i=i1+i2Per la legge dei nodididt=di1dt+di2dt
L’inverso dell’induttanza del sistema formato da due o più induttanze collegate in parallelo è uguale alla somma degli inversi delle singole induttanza 1Ltot=1L1+1L2=−ΔV(1L1+1L2)=−ΔVLtot1Ltot=∑i1Li"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#48,48,"Energia magnetica
49
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗B+_𝓔(t)RL’induttanza percorsa da corrente variabile nel tempo si comporta come un generatore con polarità opposta alla variazione correnteInnalzare la corrente di un valore di equivale a far passare nell’induttanza una carica q in un tempo dt (dq=idt)Per spostare la carica occorre contrastare la fem autoindottaℰautoindotta=−Ldidtδℒ=−ℰautoindottadq=−(−Ldidt)(idt)Occorre fare un lavoro “contro” la forza elettromotrice autoindotta"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#49,49,"Energia magnetica
50Se inizialmente nell’induttanza non circola corrente i(0)=0, per portare il circuito a corrente i occorre compiere un lavoroℒ=∫i0Lidi=12Li2δℒ=−ℰautoindottadq=−(−Ldidt)(idt)Lavoro per aumentare la corrente di un valore di
Il lavoro accumula energia nell’induttanza.Energia magnetica accumulata in un’induttanzaUB=12Li2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#5,5,"Equazioni di Maxwell (caso stazionario)
6⃗∇⋅⃗E=ρε0⃗∇∧⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗B=μ0⃗𝚥Forma locale(differenziale)"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#50,50,"Densità di energia magnetica
51
9. Circuiti in Corrente Alternata Fisica Generale B 
http://campus.cib.unibo.it/2482/ March 29, 2011 
Autoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!
Autoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d""solenoide!Bt()()dt=!µ0N2Sldidt
4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BS=πr2Ricordando l’espressione dell’induttanza di un solenoideL=μ0N2lSIl campo magnetico vale:B=μ0Nlii=Blμ0NL’energia magnetica sarà pari aUB=12Li2=12(μ0N2lS)(Blμ0N)2=12(μ0N2lS)(B2l2μ20N2)=B22μ0(lS)volume del solenoideL’energia magnetica è il prodotto di una densità di energia per il volume del solenoide"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#51,51,"Densità di energia magnetica
52uB=B22μ0Definiamo la densità di energia del campo magnetico:L’energia magnetica è localizzata in ogni punto dello spazio in cui è presente il campo magneticoUB=∭spaziouBdτL’energia del campo magnetico si calcola come l’integrale sul volume in tutto lo spazio in cui è presente il campo magnetico"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#52,52,"Circuiti RL in regime transitorio
53Come abbiamo fatto per i condensatori, analizziamo un circuito composto da un generatore di forze elettromotrice costante, una resistenza e un’induttanza 
+_T𝓔LR
Inizialmente l’interruttore è aperto (non circola corrente i(0)=0, l’induttanza è scarica)Ad un dato istante iniziale t=0 l’interruttore viene chiuso. Scriviamo l’equazione della maglia:ℰ+ℰind=Riℰ−Ldidt=Ri"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#53,53,"Circuiti RL in regime transitorio
54ℰ−Ldidt=Rididt=−RL(i−ℰR)Separiamo le variabilidi(i−ℰR)=−RLdtIntegriamo tra i(0) e i(t) e tra t=0 e t∫i(t)i(0)di(i−ℰR)=∫t0−RLdtln(i−ℰR)i(t)i(0)=−RLtlni(t)−ℰRi(0)−ℰR=−RLti(t)−ℰRi(0)−ℰR=e−RLtImponendo la condizione iniziale i(0)=0i(t)−ℰR=−ℰRe−RLt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#54,54,"Circuiti RL in regime transitorio
55i(t)=ℰR(1−e−RLt)
Transitori in un Circuito RL. Chiusura del Circuito (IV) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!La quantità # = L/R, che ha le dimensioni di un tempo, viene detta costante di tempo del circuito. i0()=0""fR+i0e!RL0=fR+i0=0""i0=!fRit()=fR!fRe!RLt  it()=fR1!e!RLt""#$%&'
45!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
 Transitori in un Circuito RL. Chiusura del Circuito (V) •!Si ottiene inoltre: VR=Rit()=f1!e!RLt""#$%&'VL=Ldidtt()=LfR!e!RLt""#$%&'!RL""#$%&'=fe!RLtit()=fR1!e!RLt""#$%&'VRt()=f1!e!RLt""#$%&'VLt()=fe!RLt()****+****it()t!""#!##fRVRt()t!""#!##fVLt()t!""#!##046!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Chiusura del Circuito (VI) tfRi
tfRVfLVt47!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito •!Consideriamo il circuito in figura e supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con l’induttanza L percorsa da una corrente di intensità costante (i = f /R). •!Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione differenziale: •!L’integrale generale è: Ldidtt()+Rit()=0i0()=fR!""##$##  it()=i0e!RLt48!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0ℰRAndamento nella corrente in un circuito RL alla chiusura dell’interruttore L/R ha le dimensioni du un tempo (costante di tempo)inizialmente la corrente è nulla e si porta ad un valore asintoticoℰind=−Ldidt=−LℰRRLe−RLt⟶t→∞0in regime stazionario (t→∞ ) la fem autoindotta si annullal’induttanza si comporta come un filo a resistenza nullanell’induttanza vi è immagazzinata un’energia magneticaUB=12Li2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#55,55,"56Circuiti RL in regime transitorioSia dato un circuito formato da un condensatore e un’induttanza Inizialmente l’interruttore T è aperto, l’induttanza è carica con UB=UoCalcoliamo quanto vale l’energia dissipata sulla resistenza L’equazione della maglia alla chiusura dell’interruttore èTLR
ℰind=Ri−Ldidt=Rididt=−RLiRisolvendo l’eq. differenziale per separazione delle variabili:dii=−RLdti(t)=i(0)e−RLtlni(t)i(0)=−RLt"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#56,56,"57Circuiti RL in regime transitorioi(t)=i(0)e−RLtUB=12Li(0)2La corrente iniziale si ricava dalla condizione iniziale di energia immagazzinata nell’induttanza
Transitori in un Circuito RL. Apertura del Circuito (II) •!Per trovare la costante i0, imponiamo la condizione iniziale: 
•!Si ottiene inoltre: i0()=fR""i0e!RL0=i0=fR""i0=fR it()=fRe!RLtVR=Rit()=fe!RLtVL=Ldidtt()=LfRe!RLt!RL""#$%&'=!fe!RLt
49!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (III) •!Riassumendo: 
•!La corrente che scorre nel circuito dopo che è stato escluso il generatore di tensione prende il nome di extracorrente di apertura. it()=fRe!RLtVRt()=fe!RLtVLt()=!fe!RLt""#$$$%$$$it()t!""#!##0VRt()t!""#!##0VLt()t!""#!##0
50!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (IV) fRti
tfRVf!LVt51!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0
Transitori in un Circuito RL. Apertura del Circuito (V) •!Se dopo avere escluso il generatore il circuito rimane aperto, si osserva una scarica elettrica tra i contatti dell’interruttore. •!Il motivo è nel fatto che il flusso del campo magnetico nell’induttanza passa in un tempo estremamente breve dal valore iniziale f/R al valore finale 0. •!Segue che la derivata          è estremamente elevata, e con essa è estremamente elevata la f.e.m. autoindotta: ft()=!L""i""t=!L0!fR""t""t#0$#$$%  didt
52!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0i(0)=2UBLi(0)L’energia dissipata sulla resistenza per effetto Joule durante l’intero processo di scarica:UR=∫∞0Ri2dt=R∫∞0(i(0)e−RLt)2dt=R∫∞0i2(0)e−2RLtdt=R2UBL∫∞0e−2RLtdt=R2UBL[−L2Re−2RLt]∞0=UBTutta l’energia accumulata nell’induttanza viene dissipata per effetto Joule sulla resistenza"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#57,57,"Esempio
58habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF= tcon = 100A/s. Calcolare:a) il ﬂusso T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; ( T(BF)=µ0N tr2R)b) la f.e.m indotta nel toroide; (E= µ0N r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.= µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind= µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1 e RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#58,58,"Esempio
59  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B 
R3 L2 T 
A L1 ε R2 R1R3L2 L3 C1 C2 
A L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B 
R1R3L2T 
Figure 20:4"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#59,59,"Le equazioni di Maxwell
60⃗∇⋅⃗E=ρε0∬S⃗E⋅̂ndS=QSε0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t∮Γ⃗E⋅d⃗l=−ddt∬S⃗B⋅̂ndS∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tForma differenzialeForma integrale∬S⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#6,6,"Equazioni di Maxwell (caso stazionario)
7∮Γ⃗E⋅d⃗l=0∮Γ⃗B⋅d⃗l=μ0conc∑kikForma integrale∬S⃗E⋅̂ndS=QSε0∬S⃗B⋅̂ndS=0"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#60,60,"Le equazioni di Maxwell
61Le quattro equazioni di Maxwell descrivono completamente l’elettromagnetismo A partire da esse è possibile ricavare tutte le leggi dell’elettromagnetismo, dall’elettrostatica, alle correnti, alle forze elettriche e magnetiche Dalle equazioni di Maxwell si evince che i campi elettrico e magnetico sono strettamente legati tra di loro e che essi sono due modi di manifestarsi della stessa entità chiamata campo elettromagnetico Partendo dalle equazioni di Maxwell, si dimostra che il campo elettromagnetico si propaga attraverso onde elettromagnetiche, le quali hanno sempre una componente di campo elettrico e una di campo magnetico"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#61,61,"Argomenti Facoltativi
62• Equazione delle onde elettromagnetiche • Onde elettromagnetiche piane • Teorema di Poynting ed energia trasportata dalle onde elettromagnetiche"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#62,62,"Onde elettromagnetiche
63Prendiamo in considerazione le quattro equazioni di Maxwell in  assenza di cariche e di correnti di conduzione⃗∇⋅⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t⃗∇∧⃗B=μ0ε0∂⃗E∂t∇2⃗E=ε0μ0∂2⃗E∂t2Combinando le quattro relazioni e utilizzando le proprietà delle operazioni tra operatori si ricavano le due equazioni di D’Alambert per campo elettrico e magnetico∇2⃗B=ε0μ0∂2⃗B∂t2ε0μ0=1c2c=3×108 m/s velocità della luce nel vuoto"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#63,63,"Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/
64"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#7,7,"Legge di Ampère su condensatore
8Scriviamo la legge di Ampère in funzione della densità di corrente ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSTale legge deve essere vera per qualsiasi superficie aperta S avente per bordo la linea chiusa 𝛤Applichiamo tale legge in un circuito con condensatore:
S1S2𝛤S1 interseca il filo  S2 passa nell’intercapedine del condensatore (senza intersecare il filo) Entrambe hanno come bordo la linea chiusa 𝛤"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#8,8,"Legge di Ampère su condensatore
9
S1S2𝛤In condizioni stazionarie, nei rami di circuiti con condensatori non circola corrente quindi la circuitazione è nulla: legge di Ampère è soddisfatta per entrambe le superfici Cosa succede in regime transitorio, quando si ha una corrente:                   
La legge di Ampère                                         è valida solo in condizioni stazionarie ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSi(t)=ℰRe−tRCIn tal caso il flusso attraverso S1 è diverso da zero, mentre risulta nullo attraverso S2"
data_test\rootfolder\università\FisicaGenerale\13-elettromagnetismo.pdf#9,9,"Legge di Ampère
10Oltre al caso del condensatore, la legge di Ampère presenta un altro problema formale⃗∇∧⃗B=μ0⃗𝚥⃗∇⋅(⃗∇∧⃗B)=μ0⃗∇⋅⃗𝚥⃗∇⋅(⃗∇∧⃗B)=0Si dimostra facilmente che la divergenza del rotore di un campo vettoriale è sempre nulla (qualunque sia il campo)⃗∇⋅⃗𝚥=?Non è vero invece che la divergenza della densità di corrente sia sempre nulla In quali condizioni è nulla? (il vettore densità di corrente è solenoidale?) Applicando l’operatore divergenza ad entrambi i membri dell’equazione di Ampère in forma differenziale:"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al Machine Learning  
 
1"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#1,1,"Introduzione al  
machine Learning
Intuitivamente, un sistema è in grado di apprendere se, 
attraverso la sua attività, è in grado di migliorare le 
proprie prestazioni.
Nell’IA, il miglioramento delle prestazioni coincide in 
generale con l’acquisizione di nuove conoscenze.
 2"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#10,10," 11
Applicazioni Finanziarie  
Applicazioni in Medicina (e.g., rilevamento di tumori nelle 
scansioni cerebrali)
Recommender Systems (e.g., raccomandare un prodotto a cui 
un cliente potrebbe essere interessato, sulla base di acquisti 
passati)
Rilevamento di frodi con carte di credito  
Rilevamento di pattern di accesso anomali a un sito Web
Segnalazione automatica di commenti offensivi nei forum  
Identiﬁcazione di fake news
Esempi di applicazione"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#11,11," 12
Applicazioni in vari campi dell’ingegneria (Civile, 
Aeronautica, Telecomunicazioni, ecc. ecc.)
Marketing (e.g., segmentazione dei clienti in base ai loro 
acquisti in modo da poter progettare una strategia di 
marketing diversa per ogni segmento)  
Previsione dei ricavi della tua azienda per il prossimo anno, 
sulla base di varie metriche di performance
Costruire un bot intelligente per un gioco  
Far reagire la tua app ai comandi vocali  
Creare un chatbot o un assistente personale
Esempi di applicazione"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#12,12,"metodi di apprendimento
Apprendimento supervisionato
Richiede che si apprenda una funzione partendo da esempi di input 
e output
Apprendimento non supervisionato
Richiede di imparare a riconoscere pattern o schemi nell’input 
senza alcuna indicazione speciﬁca dei valori di uscita.
Apprendimento per rinforzo
L’agente apprende in base al rinforzo (ricompensa) ottenuto.
 13"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#13,13,"Tipici problemi di  
Machine Learning
Regression 
Classiﬁcation  
ClusteringUna tipica classiﬁcazione dei problemi affrontati in ML  
è la seguente:
 14"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#14,14,"Applicazioni di  
Machine Learning
DEMO
 15"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#2,2,"Introduzione al  
machine Learning
Qualsiasi cambiamento in un sistema che gli permetta di 
avere prestazioni migliori la seconda volta, nella 
ripetizione dello stesso compito o di un altro compito 
tratto dalla stessa popolazione.
(Simon, 1984)
 3"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#3,3,"Introduzione al  
machine Learning
A computer program is said to learn from experience E 
with respect to some class of tasks T and performance 
measure P, if its performance at tasks in T, as measured 
by P, improves with experience E .
(Mitchell, 1997)
 4"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#4,4,"Definizioni
Task T : obiettivo del sistema
Giocare a dama
Guidare un autoveicolo
Riconoscere parole pronunciate
Experience E : Insieme di addestramento dal quale apprendere
Partite giocate
Percorsi
.........
Performance measure P : misura della capacità di eseguire il 
task
Numero di partite vinte
Numero di parole classiﬁcate correttamente
 5"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#5,5,"Introduzione al  
machine Learning
Un elemento fondamentale dell’apprendimento è la 
capacità di valutare le proprie prestazioni, o almeno di 
accettare una valutazione dall’esterno.
Senza una valutazione, infatti, non sarebbe possibile 
parlare di miglioramento.
A sua volta, la valutazione delle prestazioni richiede la 
capacità di accettare un certo tipo di informazioni 
dall’ambiente esterno.
 6"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#6,6,"Progetti Rilevanti nello 
Sviluppo del Machine Learning
1989 : Guida autoveicolo - ALVINN system (Pomerlau, 1989)
1995 : Classiﬁcazione nuove strutture astronomiche - NASA: classiﬁcazione 
oggetti celesti (Fayyad et al., 1995)
1992-95 : Backgammon - TD-Gammon (Tesauro, 1992, 1995): 
apprendimento su 1 milione di partite giocate contro se stesso.
2004 : DARPA introduce la “DARPA Grand Challenge”, una sﬁda per la 
guida autonoma di veicoli.
2006 : Geoffrey Hinton dell’Università di Toronto introduce un algoritmo di 
apprendimento veloce  per reti neurali artiﬁciali, che dà il via alla 
rivoluzione del Deep Learning.
 7"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#7,7," 8
2006 : Netﬂix lancia la “Netﬂix Prize competition”, con una borsa di 
un milione di dollari, sﬁdando i gruppi di ricerca ad usare il Machine 
Learning per migliorare la accuracy del proprio Recommender 
System  di almeno il 10%. Un gruppo ha vinto il premio nel 2009.
2010 : ImageNet lancia un concorso annuale - la “ImageNet Large 
Scale Visual Recognition Challenge (ILSVRC)” - in cui i team 
utilizzano il Machine Learning per rilevare e classiﬁcare 
correttamente gli oggetti in un set di dati di immagini ampio e ben 
curato. L’errore di classiﬁcazione migliora dal 25% nel 2011 a pochi 
punti percentuali nel 2015, grazie ai progressi nelle deep 
convolutional neural networks.
Progetti Rilevanti nello 
Sviluppo del Machine Learning"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#8,8," 9
2011 : IBM Watson, un sistema di question-answering, batte i 
campioni del gioco Jeopardy!   Brad Rutter e Ken Jennings. IBM 
Watson è ora utilizzato in diversi settori, tra cui l’assistenza sanitaria 
e la vendita al dettaglio. 
2014 : Facebook pubblica un lavoro su DeepFace, un sistema basato 
su reti neurali artiﬁciali in grado di identiﬁcare volti con 
un’accuratezza del 97%, una prestazione al livello “umano”, che 
migliora di circa il 27% le prestazioni di sistemi precedenti.
2014 : Il Il consumo di energia per il raffreddamento dei Data Center 
è stato ridotto del 40% con un modello di Machine Learning:
Progetti Rilevanti nello 
Sviluppo del Machine Learning
Gao,	J.	(2014) .	Machine	Learning	Applica:ons	for	Data	Center	Op:miza:on.	 Google	Research.  
hCps://sta:c.googleusercontent.com/media/research.google.com/it//pubs/archive/42542.pdf"
data_test\rootfolder\università\MachineLearning\1-Introduzione ML-sbloccato.pdf#9,9," 10
2015 : AlphaGo di DeepMind batte il giocatore Fan Hui nel gioco del 
Go. Nel 2016 , batte Lee Sedol e, nel 2017 , batte Ke Jie.
2017 : Il software per analizzare le immagini delle galassie sotto lenti 
gravitazionali è stato velocizzato di un fattore di 10 milioni  con un 
modello di Machine Learning:
Progetti Rilevanti nello 
Sviluppo del Machine Learning
Hezaveh,	 Y.D.,	 Levasseur,	 I.P .,	 Marshall,	 P .J.	 (2017).	 Fast	 Automated	 Analysis	 of	 Strong	
Gravita:onal	Lenses	with	Convolu:onal	Neural	networks.	 Nature ,	548,	pp.	555-557.  
hCps://arxiv.org/abs/1708.08842
Recentemente David Patterson (Turing Award winner) e Jeff Dean (Google AI 
head) hanno dichiarato l'alba di una ""età dell'oro"" per l'architettura dei computer 
grazie al Machine Learning . "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Algoritmo K-NN
Machine Learning "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#1,1,"Sommario
Ripasso su Information Retrieval 
Algoritmo k-NN 
kd-trees per k-NN
 
2"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#10,10,"Modello Bag-of-Words
Un problema che emerge in questa semplice rappresentazione è 
relativa ai termini poco frequenti (“rare words”). 
In effetti, in tale rappresentazione tutti i termini sono considerati 
ugualmente importanti.  
In realtà certi termini hanno poca capacità discriminante ai ﬁni 
della determinazione della rilevanza di un documento (e.g., 
quando ne calcoliamo la distanza rispetto ad un altro).  
Ad esempio, nel caso di una collezione di documenti relativi 
all’industria automobilistica, è piuttosto probabile avere il termine 
“automobile” in quasi ogni documento. 
Tali termini dominerebbero dunque quelli più rari. 
 
11"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#11,11,"Modello TF-IDF
Una rappresentazione alternativa che possiamo considerare è 
quella chiamata 
 tf-idf
. 
Come vedremo, questa rappresentazione enfatizza i termini 
“importanti”, individuati dalle seguenti caratteristiche: 
•
 appaiono frequentemente in un documento (“common locally”) 
•
 appaiono raramente nel corpus (“rare globally”) 
 
12"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#12,12,"Modello TF-IDF
Deﬁniamo 
 Document Frequency
  (
df
) per il termine 
 t
 come il 
numero di documenti nel corpus che contengono 
 t
. 
Deﬁniamo inoltre l’
 Inverse Document Frequency
  come segue: 
dove N è la cardinalità del corpus. 
 
13idf t= logN
dft"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#13,13," 
14termine dft idft
car 18.165 1,65
auto 6.723 2,08
insurance 19.241 1,62
best 25.235 1,5ESEMPIO: 
Nella seguente tabella sono riportati alcuni esempi di valori df e idf 
relativi alla collezione Reuters, costituita da 806.791 documenti:
Modello TF-IDF"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#14,14,"Modello TF-IDF
Il tf-idf è deﬁnito come segue: 
In sostanza il 
 tf-idf
 per un termine 
 t
 in un documento 
 d
 assegna al 
termine un peso nel documento che è: 
•
 molto elevato quando 
 t
 è molto frequente in un piccolo numero 
di documenti; 
•
 più basso quando il termine è poco frequente nel documento, 
oppure quando è presente in molti documenti; 
•
 il più basso quando il termine compare in tutti i documenti. 
 
15tf-idf t,d=t f t,d ·idft"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#15,15,"Metriche
Vediamo ora come possiamo calcolare la distanza tra due 
 item
.
 
16distanza( xi,xq)= |xi xq|
distanza( xi,xq)=q
(xi[1] xq[1])2+···+(xi[d] xq[d])2
distanza( xi,xq)=q
(xi xq)T·(xi xq)
Nel semplice caso di una dimensione possiamo deﬁnire la 
funzione distanza come segue (Distanza Euclidea):
Nel caso di 
 d 
dimensioni, la funzione 
 distanza
  può assumere la 
seguente forma (Distanza Euclidea):
che possiamo riscrivere come segue, in forma matriciale:"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#16,16,"Metriche
 
17distanza( xi,xq)=q
a1(xi[1] xq[1])2+···+ad(xi[d] xq[d])2
distanza( xi,xq)=q
(xi xq)T·A ·(xi xq)
Nel caso in cui vogliamo pesare in modo diverso le varie 
dimensioni, possiamo usare una 
 Scaled Euclidean distance
 :
A=2
664a10 ... 0
0 a2 ... 0
... ... ... ...
00 ... a d3
775
che possiamo riscrivere come segue, in forma matriciale:
dove:"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#17,17,"Cosine Similarity
Una metrica largamente utilizzata per quantiﬁcare la similarità tra 
due documenti 
 x
i 
e 
x
q 
è la 
 cosine similarity
 , che si avvale della 
rappresentazione vettoriale dei documenti: 
 
18sim(xi,xq)=xT
i·xq
kxik·kxqk
dove il numeratore rappresenta il prodotto scalare tra i due vettori 
e il denominatore il prodotto tra i moduli dei due vettori. 
L’effetto del denominatore è dunque quello di normalizzare i 
vettori 
 x
i 
e 
x
q 
ottenendone i corrispondenti versori. Possiamo 
dunque riscrivere la precedente espressione come segue: 
sim(xi,xq)=ˆxT
i·ˆxq"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#18,18,"Consideriamo ad esempio i documenti in ﬁgura a), rappresentati 
mediante i vari 
 tf
. La quantità: 
 
19Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17Doc1 Doc2 Doc3
car 0,88 0,09 0,58
auto 0,10 0,71 0
insurance 0 0,71 0,70
best 0,46 0 0,41
Cosine Similarity
ha i valori 30,56, 46,84 e 41,30 per Doc1, Doc2 e Doc3. 
Applicando la normalizzazione otteniamo la ﬁgura b): 
a) 
 b) kxk=vuutdX
j=1x2
j"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#19,19,"La similarità deﬁnita in precedenza corrisponde al coseno 
dell’angolo tra i due vettori: 
 
20θ
01
1sim(xi,xq)=xT
i·xq
kxik·kxqk= cos( ✓)
ˆxi
ˆxq
Cosine Similarity"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#2,2,"Document Retrieval
 
3Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..
Supponiamo di avere disponibile un corpus di documenti: Come 
possiamo misurare la similarità tra di loro? Come possiamo 
effettuare ricerche? "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#20,20,"K-NN: Complessità della ricerca 
 
21Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Il calcolo delle distanze tra documenti può essere molto pesante 
computazionalmente quando N è molto elevato: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#21,21,"K-NN: Complessità della ricerca 
 
22
Dato un 
 query point
 , il costo della scansione su tutti i punti è: 
•
 O(N) per una query per 1-NN 
•
 O(N log k) per una query per k-NN 
Per rendere più efﬁciente la ricerca è possibile utilizzare una 
particolare struttura dati, i 
 KD-Trees
 . "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#22,22,"KD-Trees
 
23
Permette un’organizzazione strutturata degli item: 
•
 partiziona ricorsivamente i data point in “axis aligned boxes”. 
Comporta un più efﬁciente pruning dello spazio di ricerca. 
Ottiene buoni risultati in dimensioni “low-medium”. 
Riferimenti: 
Bentley, J.L. “Multidimensional Binary Search Trees Used for Associative Searching”, in: 
Communications of the ACM , 18(9), 1975, pp. 509-517.
Friedman, J.H., Bentley, J.L., Finkel, R.A. “An Algorithm for Finding Best Matches in 
Logarithmic Expected Time”, in: ACM Transactions on Mathematical Software , 3(3), 1977, pp. 
209-226."
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#23,23,"KD-Trees
 
24
Costruzione dell’albero: 
Data Point x[1] x[2]
1 0,00 0,00
2 1,00 4,31
3 0,13 2,85
… … …
feature 1feature 2"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#24,24,"KD-Trees
 
25
Split relativo alla prima feature: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#25,25,"KD-Trees
 
26
Consideriamo ora la parte sinistra: 
Data Point x[1] x[2]
2 1,00 4,31
… … …Data Point x[1] x[2]
1 0,00 0,00
3 0,13 2,85
… … …x[1] > 0,5
0,5x[1] ≤ 0,5
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#26,26,"KD-Trees
 
27
Split relativo alla seconda feature: 
Data Point x[1] x[2]
3 0,13 2,85
… … …Data Point x[1] x[2]
1 0,00 0,00
… … …x[2] > 0,1 x[2] ≤ 0,1
0,1
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#27,27,"KD-Trees
 
28
Si procede in tal modo ﬁno a completare l’albero: 
•split feature 
•split value 
•bounding box
x[1] > 0,5 x[1] ≤ 0,5
x[2] ≤ 0,1 x[2] > 0,1"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#28,28,"KD-Trees
 
29
Esempi di bounding box: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#29,29,"KD-Trees
 
30
Euristiche per effettuare le decisioni sugli splitting: 
•
 Scelta della dimensione (la più ampia, dim. alternate) 
•
 Valore della feature a cui effettuare lo split (mediana, centro 
del box) 
•
 Condizione di terminazione (numero di punti sotto una 
determinata soglia, larghezza del box sotto una determinata 
soglia)"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#3,3,"Nearest Neighbor
 
4Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare l’articolo più simile nel 
corpus di documenti disponibili: 
documento xqnearest neighbor"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#30,30,"KD-Trees
 
31
Dato un query point (in verde), attraversiamo l’albero alla ricerca 
del nearest neighbor. 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#31,31,"KD-Trees
 
32
Prima metà dell’area: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#32,32,"KD-Trees
 
33
.. e così via … 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#33,33,"KD-Trees
 
34
Abbiamo raggiunto la foglia che contiene il query point: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#34,34,"KD-Trees
 
35
Calcolo della distanza del NN tra i punti contenuti nella foglia: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#35,35,"KD-Trees
 
36
Backtrack e proviamo altri rami per ogni nodo visitato: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#36,36,"KD-Trees
 
37
Valutiamo la distanza dal bounding box: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#37,37,"KD-Trees
 
38
La distanza è minore di quella corrente, perciò visitiamo i 
sottoalberi (in questo caso le foglie). La prima ha distanza 
minore: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#38,38,"KD-Trees
 
39
Backtrack e visitiamo l’altra foglia: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#39,39,"KD-Trees
 
40
La distanza dal bounding box è superiore alla minima, perciò 
possiamo potare il ramo: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#4,4,"Algoritmo 1-NN
 
5dist min = 1
nearest doc = ;
for i=1,. . . ,N
 = distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o
if <dist min
nearest doc = xi; documento pi` u vicino corrente
dist min =   ; distanza minima corrente
return nearest doc
Input: documento 
 x
q
 per la query e documenti 
 x
1
 , 
x
2
, … , 
 x
N 
Output: documento 
 x
i
 più vicino (nearest_doc) a 
 x
q "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#40,40,"KD-Trees
 
41
Backtrack e proviamo altri rami per ogni nodo visitato: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#41,41,"KD-Trees
 
42
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: "
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#42,42,"KD-Trees
 
43
Backtrack e proviamo altri rami per ogni nodo visitato: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#43,43,"KD-Trees
 
44
La distanza dal bounding box è superiore alla minima corrente, 
perciò possiamo potare il ramo: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#44,44,"KD-Trees
 
45
Pruning complessivo: 
"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#45,45,"Riferimenti
 
46
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#5,5," 
6Diversamente dagli esseri umani,
che presumibilmente …
Questo è un esempio di quello
che gli informatici ….L’approccio ai sistemi simbolici
non è affatto ………
Per rispondere a questa domanda
l’approccio migliore …..
Provate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando
la sostituzione del capitale …..
Potrebbe valere la pena correre dei
 rischi  ……
In precedenza, nel tentativo di
deﬁnire l’IA, …….Dopo la conferenza di Dartmouth,
l’interesse …….
Per affrontare la lettura occorre
 una certa dimestichezza …….
Nel testo si trovano inseriti  …….La relazione tra matrici ora
deﬁnita è riﬂessiva,  …….
Una trasformazione può  …….
Per questa ragione gran parte
degli psico-proseliti …….
Per tutti costoro il massimo  …….Le ragioni per cui si è instaurata
una stretta connessione ….Il lettore può essere sorpreso  dalla
quantità di spazio …..
Molta della utilità di questo …….
Galton si era convinto che i
caratteri mortali si ereditassero …..
Oltre a ciò Galton, memore dei  …….
Storicamente, il modo più semplice
per assistere i clienti …..
Anche se quasi tutti i sistemi 
sperimentali  …..La situazione è tuttavia comple-
tamente diversa …..
Un’area in pieno sviluppo è  …..
Obiettivo: dato un documento 
 x
q
, trovare i k articoli più simili nel 
corpus di documenti disponibili: 
documento xqk nearest neighbors
k Nearest Neighbors"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#6,6,"Algoritmo k-NN
 
7
Input: documento 
 x
q
 per la query e documenti 
 x
1
 , 
x
2
, … , 
 x
N 
Output: lista dei k documenti più vicini a 
 x
q 
lista kdist min = sort(  1, 2,...,  k)
lista knearest doc = sort( x1,x2,..., xk)
for i=k+1,. . . ,N
 = distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o
if <lista kdist min[ k]
inserisci  in lista kdist min ; inserimento in lista ordinata
inserisci xiin lista knearest doc ; inserimento in lista ordinata
return lista knearest doc"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#7,7,"Criticità nella NN search
Per effettuare una ricerca dei nearest neighbors occorre risolvere i 
seguenti problemi: 
•
Come rappresentare gli item coinvolti (nel nostro esempio i 
documenti). 
•
Come valutare la distanza tra gli item, ossia deﬁnire una metrica 
che consenta di calcolare la similarità tra i vari item. 
 
8"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#8,8,"Richiami su 
Rappresentazione dei Documenti
Vediamo ora due possibili metodi per la rappresentazione dei 
documenti non strutturati: 
•
 bag of words 
•
 tf-idf 
 (term frequency - inverse document frequency)  
 
9"
data_test\rootfolder\università\MachineLearning\10-Algoritmo K-NN-sbloccato.pdf#9,9,"Modello Bag-of-Words
In questo modello è ignorato l’esatto ordine dei termini nel 
documento. 
Viene preso in considerazione solo il numero di occorrenze (
 term 
frequency
 : 
tf
) di ogni termine nel documento. 
In tal modo è possibile rappresentare ogni documento mediante 
un vettore di occorrenze: 
 
10Doc1 Doc2 Doc3
car 27 4 24
auto 3 33 0
insurance 0 33 29
best 14 0 17"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Machine Learning con Python: 
Introduzione  
 
1"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#1,1,"Introduzione al 
Machine Learning con Python   
Testo consigliato:
 2Andreas C. Müller,  Sarah Guido
“Introduction to Machine Learning with Python - A guide for Data Scientists”
O’Reilly, 2017.
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#10,10," 11
Caricamento del  
Dataset IRIS
Il nostro obiettivo è quello di realizzare un modello di 
machine learning che apprenda, dagli esempi disponibili, 
come classiﬁcare la specie di un nuovo ﬁore iris partendo 
dalle 4 misure relative ai suoi petali e sepali.
Il dataset Iris è incluso in scikit-learn  nel modulo 
datasets . E’ possibile caricarlo chiamando la funzione 
load_iris :
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#11,11," 12
L’oggetto iris restituito da load_iris  è un Bunch  object, ed 
è simile a un dizionario. Esso contiene chiavi e valori:
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#12,12," 13
Bunch objects
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#13,13," 14
Il valore associato alla chiave DESCR  è una descrizione 
sintetica del dataset. Vediamo i primi caratteri di tale 
descrizione:
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#14,14," 15
Vediamo i valori associati alle chiavi target_names  e 
feature_names :
Dataset IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#15,15," 16
I dati sono contenuti nei campi data e target . Vediamo il 
tipo e lo shape di data:
Dataset IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#16,16," 17
L’array target  contiene le specie di ciascuno dei ﬁori del 
dataset ( 0 per setosa , 1 per versicolor , 2 per virginica ): 
Dataset IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#17,17,"I dati che useremo per il training e il test possono essere 
visti come segue:
 18
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#18,18,"Esempi di valori delle feature presenti in data:
 19
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2
X"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#19,19,"Esempi di valori delle specie presenti in target :
 20
Data Set IRIS
sepal 
lengthsepal 
widthpetal 
lengthpetal 
widthTarget 
(Iris species)
5.9 3.0 4.2 1.5 1
5.8 2.6 4.0 1.2 1
6.8 3.0 5.5 2.1 2
4.7 3.2 1.3 0.2 0
6.9 3.1 5.1 2.3 2
y"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#2,2," 3https://github.com/amueller/introduction_to_ml_with_python
Gli esempi di codice presentati nel libro sono disponibili 
nel seguente sito :
Introduzione al 
Machine Learning con Python   "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#20,20," 21
Suddivisione in 
Training Set e Test Set 
scikit-learn  contiene una funzione che mescola il dataset 
delle osservazioni disponibili e ne fa la suddivisione in  
training set e test set . Si tratta della funzione:
train_test_split
Questa funzione estrae il 75% degli esempi per formare il 
training set , costituito quindi dal 75% delle righe in data 
e le corrispondenti label in target .
Il rimanente 25% degli esempi va a costituire il test set ."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#21,21," 22
Istruzioni per lo split:
ndarray da ripartire tra  
X_train e X_testfunzione per lo split
ndarray da ripartire tra  
y_train e y_test
Suddivisione in 
Training Set e Test Set "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#22,22," 23
Shape delle variabili relative al training set e al test set:
Suddivisione in 
Training Set e Test Set "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#23,23," 24
Ispezione dei Dati
Prima di costruire un modello di machine learning è 
sempre opportuno ispezionare i dati disponibili, intanto 
per capire se il problema è risolvibile mediante tecniche 
di machine learning.
L’ispezione è utile anche per la individuazione di 
eventuali anomalie, inconsistenze, ecc.
Un ottimo metodo per effettuare tale ispezione è quello 
di visualizzare i dati in questione (e.g., scatter plot).
Nella ﬁgura che segue viene rappresentato un “pair plot” 
delle feature relativamente alle osservazioni del training 
set per il nostro esempio."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#24,24," 25
Ispezione dei Dati"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#25,25," 26
K-Nearest Neighbors 
Costruzione del Modello 
L’algoritmo k-NN  in scikit-learn  è implementato nella 
classe KNeighborsClassiﬁer  nel modulo neighbors .
Prima di usare il modello, dobbiamo istanziare la classe in 
un oggetto. In tal modo impostiamo i parametri del 
modello.
Il parametro più importante di KNeighborsClassiﬁer è il 
numero del neighbors, che in questo caso impostiamo a 1:
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#26,26," 27
K-Nearest Neighbors 
Costruzione del Modello 
L’oggetto knn incapsula l’algoritmo che sarà utilizzato per 
costruire il modello a partire dai dati di training, così 
come l’algoritmo per fare le previsioni su nuovi data 
points.
Nel caso di KNeighborsClassiﬁer  verrà semplicemente 
memorizzato il training set."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#27,27," 28
Addestramento del Modello
Per addestrare il modello sul training set, scikit-learn  
mette a disposizione il metodo ﬁt da chiamare 
sull’oggetto knn:
metodo per l’addestramento"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#28,28," 29
Uso del Modello  
per effettuare Previsioni 
Dato un nuovo data point da classiﬁcare:
features del nuovo ﬁore da classiﬁcare "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#29,29," 30
… possiamo usare il metodo predict per la predizione 
della sua specie:
metodo per la predizione
Uso del Modello  
per effettuare Previsioni "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#3,3,"Testo consigliato:
 4A. Géron
“Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow”
O’Reilly, 2019.
Introduzione al 
Machine Learning con Python   "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#30,30," 31
Valutazione del Modello 
Per valutare il modello possiamo richiamare il metodo 
predict  su tutti gli esempi del test set:
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#31,31," 32
Calcolo del punteggio:
Valutazione del Modello "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#32,32," 33
Sintesi della esercitazione
Deﬁnizione di un task di machine learning (classiﬁcazione delle specie Iris 
mediante k-NN ).
Individuazione dei data points  (esempi, osservazioni) disponibili per 
addestrare il sistema (supervised learning task)
Split  del dataset, import  della classe, che poi è istanziata su un oggetto (setting 
parameters)
Fase di addestramento (metodo ﬁt) e valutazione  (metodo score ):
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#4,4," 5
Scikit-learn  è uno dei package più popolari per il 
Machine Learning in Python.
Mette a disposizione efﬁcienti implementazioni di 
numerosi algoritmi di ML e un gran numero di utili 
strumenti per attività di pre- e post- processing relative a 
task di ML.
E’ possibile trovare la documentazione necessaria nel 
seguente sito: 
http://scikit-learn.org
Scikit-Learn "
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#5,5," 6
Jupiter Notebook : ambiente interattivo per eseguire 
codice nel browser.
NumPy : è uno dei package fondamentali per il calcolo 
scientiﬁco in Python.
Librerie e Strumenti 
pandas : libreria per data wrangling e analisi.
matplotlib : libreria per il plotting.
mglearn : libreria di utility functions che gli autori (Müller 
& Guido) hanno scritto per il loro libro, in modo da non 
“intasare” il codice presentato con dettagli di plotting e di 
data loading."
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#6,6,"Versioni linguaggio e librerie:
 7
Ambiente di Sviluppo 
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#7,7,"Cominciamo con un semplice esempio di classiﬁcation, 
utilizzando il data set Iris.
Questo è un famoso data set che contiene 150 esempi di 
ﬁori iris, descritti da 4 features (lunghezza e larghezza di 
petali e sepali) e appartenenti ad una di tre specie 
differenti:
Iris setosa
Iris versicolor  
Iris virginica  
 8
Una prima applicazione:  
Classificazione delle specie IRIS"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#8,8,"Ecco un esempio di ﬁori iris relativo alle tre specie:
 9
Una prima applicazione:  
Classificazione delle specie IRIS
"
data_test\rootfolder\università\MachineLearning\11-ML con Python - Introduzione-sbloccato.pdf#9,9," 10
Una prima applicazione:  
Classificazione delle specie IRIS
Petal
Sepal
La classiﬁcazione può essere fatta in base ai valori delle 4 
features, ossia lunghezza e larghezza dei petali e sepali:"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#0,0,"Intelligenza Artiﬁciale 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione (Ex02)
1"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Dataset Better Life Index 
Richiami: Model Selection, Simple Linear Regression, Funzione di Costo 
Libreria Scikit-learn 
Linear Regression in Python 
Esempio: Dataset Diabete 
Linear Regression e Predizione 
Esercitazione su dataset Better Life Index"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#10,10,"Il modulo 
 linear_model
  di 
sklearn
  implementa l'addestramento basandosi 
su un modello lineare. La funzione di costo di default è la 
 RSS
. 
La funzione 
 ﬁt()
 prende come parametri due arrays 
 X
 e 
y
, effettua 
l'addestramento (o 
 ﬁtting
 ) e memorizza i coefﬁcienti nella variabile 
 coef_
 . 
Ad esempio: 
>>> 
from 
sklearn 
import
 linear_model 
>>> 
reg 
=
 linear_model
 .
LinearRegression() 
>>> 
reg
.
fit([[
0
, 
0
], [
1
, 
1
], [
2
, 
2
]], [
0
, 
1
, 
2
]) 
LinearRegression()  
>>> 
reg
.
coef_ 
array([0.5, 0.5]) 
Nell'esempio si impiegano 2 valori (cioè 2 features) per punto, e la retta ha 
2 coefﬁcienti 
 w
1
. Il valore di 
 w
0
 si ottiene con la variabile 
 intercept_
  del 
modello. 
Nota
 : l'underscore nel nome delle variabili indica che i valori sono ottenuti 
durante l'addestramento, e perciò non sono iperparametri del modello.
Linear Regression in Python
11"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#11,11,"Il modulo 
 metrics
  di 
sklearn
  implementa varie misure di performance. 
https://scikit-learn.org/stable/modules/model_evaluation.html  
Nota: troviamo MSE ma non RSS.
Scikit-learn e le misure di performance
12
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#12,12,"Un dataset diabete è un dataset 
 toy 
(cioè utile per scopi didattici e per 
testare il codice)  
 disponibile all'interno della libreria scikit-learn. 
URL: 
 https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html   
https://scikit-learn.org/stable/datasets/toy_dataset.html   
442 istanze 
10 features reali normalizzate ove richiesto -.2 < x < .2 
age age in years
sex
bmi body mass index
bp average blood pressure
s1 tc, total serum cholesterol
s2 ldl, low-density lipoproteins
s3 hdl, high-density lipoproteins
s4 tch, total cholesterol / HDL
s5 ltg, possibly log of serum triglycerides level
s6 glu, blood sugar level
Target: intero nell'intervallo 25 - 346 che indica quanto la malattia sia 
accresciuta dopo 1 anno
Esempio: dataset diabete
13"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#13,13,"Codice per impiegare il dataset: 
import 
matplotlib.pyplot  
as 
plt 
import 
numpy 
as 
np 
from 
sklearn 
import
 datasets, linear_model 
from 
sklearn.model_selection  
import
 train_test_split 
from 
sklearn.metrics  
import 
mean_squared_error
 , 
r2_score  
# Carico il dataset  
diabetes_X, diabetes_y 
 = 
datasets
 .
load_diabetes
 (return_X_y
 =
True
) 
# Mantengo solo la terza feature  
diabetes_X 
 =
 diabetes_X[:, 
 np
.
newaxis
, 
2
] 
# Suddivido il dataset in training/test 80/20%  
diabetes_X_train,diabetes_X_test,diabetes_y_train, diabetes_y_test 
 =    
  train_test_split(diabetes_X, diabetes_y,test_size=0.2) 
... 
Esercizio
 : completa il codice impiegando un modello lineare, 
visualizzando il valore dei coefﬁcienti e l'errore MSE.
Esempio Python: diabete (1)
14"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#14,14,"# Istanzia un modello di regressione lineare  
regr 
= 
linear_model
 .
LinearRegression
 () 
# Addestramento con funzione di costo RMSE  
regr
.
fit(diabetes_X_train, diabetes_y_train) 
# Ricava le predizioni sul test set  
diabetes_y_pred 
 =
 regr
.
predict(diabetes_X_test) 
# Stampa i parametri del modello  
print
(
""Coefficients: 
 \n
""
, regr
.
coef_) 
# Valuto il MSE  
print
(
""Mean squared error: 
 %.2f
"" 
% 
mean_squared_error
 (diabetes_y_test, diabetes_y_pred)) 
plt
.
scatter
(diabetes_X_test, diabetes_y_test, color
 =
""black""
) 
plt
.
plot
(diabetes_X_test, diabetes_y_pred, color
 =
""blue""
, linewidth
 =
3
) 
plt
.
xticks
(()) 
plt
.
yticks
(()) 
plt
.
show
() 
# Coefficients:   [938.23786125]  
# Mean squared error: 2548.07
Esempio Python: diabete (2)
15
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#15,15,"Il modulo 
 linear_model
  permette facilmente di fare predizione sui dati. 
La funzione 
 predict()
  prende un array di istanze (una o più features) e 
ricava il valore in base al modello addestrato. 
X_new = [[
 22587
]] 
print
(model.predict(X_new))
Linear Regression e predizione
16"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#16,16,"Il problema consiste nel determinare i due parametri 
 w
. Chiaramente il 
modello può solo approssimare la correlazione tra i valori.  
Se facciamo più ipotesi, cioè creiamo più modelli, ci occorre una misura di 
performance (o di costo) per confrontarli e scegliere il più adatto.
Esempio: dataset Better Life Index (3)
17PIL pro capiteLivello di soddisfazione
PIL pro capitew0=8w1=-5×10-5
w0=4w1=5×10-5 w0=0w1=2×10-5w0=?
w1=?Livello di soddisfazione"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#17,17,"Accedi al seguente notebook dove i dati sono già caricati e formattati per gli step 
successivi:  
https://colab.research.google.com/drive/1apLqC0KAveOkkCT8JuO5kNQyj1GT5Hz9?usp=sharing   
Risolvi i seguenti esercizi: 
Esercizio #1
 : crea e addestra un modello lineare con funzione di costo RSS 
Esercizio #2
 : visualizza i parametri del modello 
Esercizio #3
 : prendi tre campioni random dal dataset e ricava la predizione in base 
al modello addestrato 
Esercizio #4
 : calcola RSS MSE e RMSE valutando i tre campioni 
Esercizio #5
 : suddividi il dataset in input in train e test con un rapporto 80/20 
Esercizio #6
 : addestra nuovamente il modello, e ricava RSS MSE e RMSE sui test set 
Esercizio #7
 : suddividi nuovamente il dataset ma con un rapporto 50/50. Valuta 
nuovamente le performance del modello e discuti eventuali differenze nei valori 
ottenuti.
Esercizio Python: Better Life Index
18"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#18,18,"Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016
Testi di Riferimento
19"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami
Le tecniche di 
 Regressione
  ricadono nell'ambito dell'apprendimento 
Model-based
 , dove  
Si costruisce un modello che rappresenta le caratteristiche dei dati in 
ingresso (es. andamento).  
Tale modello verrà poi impiegato nella fase di 
 predizione
  su istanze in 
ingresso distinte da quelle impiegate durante l'apprendimento.
3
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#3,3,"Datasets
Durante le esercitazioni faremo uso di vari datasets, alcuni reali, altri 
sintetici che ci permetteranno di mettere in evidenza vari aspetti e 
problematiche rilevanti nell'ambito dell'apprendimento automatico.
4"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#4,4,"Esempio: dataset Better Life Index (1)
Dataset che lega il benessere (life satisfaction) con indicatori giudicati essenziali 
nella vita quotidiana (es. salario, livello istruzione), suddivisi per nazione. 
https://stats.oecd.org/index.aspx?DataSetCode=BLI  
5
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#5,5,"Esempio: dataset Better Life Index (2)
Valore del PIL (GDP) annuale 
https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD
6
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#6,6,"Se prendiamo i due dataset e creiamo un join, possiamo mettere in 
correlazione due variabili, es. PIL pro capite e livello di soddisfazione 
percepito. 
Si nota come i due valori siano correlati, sebbene non esattamente, con un 
legame lineare. 
Possiamo supporre che esista un modello 
 lineare
  (o 
ordinary least squares
 ) 
che leghi la soddisfazione con il valore del PIL (fase di 
 model selection
 ).
Richiami: Model selection
7
PIL pro capiteLivello di soddisfazione
"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#7,7,"Richiami: Simple Linear Regression Model
I parametri del modello lineare sono 
 w
0
 e 
w
1
. 
Attenzione: non esiste un formalismo standard per rappresentare i 
parametri, a volte si impiega 
 θ
 o altri simboli. 
I parametri del modello lineare sono 
 w
0
 e 
w
1
.  
Adattando tali valori possiamo deﬁnire qualsiasi modello lineare.
8yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
x
PIL pro capiteLivello di soddisfazione"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#8,8,"Tipicamente is impiega una misura di costo basata sulla distanza tra valore 
esatto e valore determinato dal modello, come la 
 Residual Sum of Squares  
(RSS), sempre positiva, chiamata anche 
 Sum of Squared Residuals
  (SSR) o 
Sum of Squared estimate of Errors
  (SSE): 
Valori prossimi allo 
 0
 indicano un modello ideale. 
La 
Mean Square Error 
 (MSE), chiamata anche 
 Mean Squared Deviation  
(MSD), corrisponde alla RSS normalizzata sul numero di campioni.  
È utile per valutare il modello ﬁnale dopo l'addestramento.
Richiami: funzione di costo
9RSS( w0,w1)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0+w1xi)]2"
data_test\rootfolder\università\MachineLearning\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#9,9,"È la libreria con licenza aperta (BSD) più conosciuta di machine learning in 
Python. La prima release risale al 2010.  
https://scikit-learn.org/stable/   
Include gli algoritmi più popolari di classiﬁcazione, regressione, clustering 
(es. support-vector machines, random forests, gradient boosting, k-means e 
DBSCAN). 
Alcune parti del codice sono state scritte in modo altamente efﬁciente con 
varie tecnologie (vedi Cython) 
È facilmente interfacciabile con altre librerie per la gestione e il calcolo 
numerico di dati, es. NumPy (algebra lineare), SciPy (ottimizzazione, 
algebra lineare, analisi dei segnali, etc) e Pandas.
Richiami: la libreria Scikit-learn
10"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex03)
1"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#1,1,"Sommario
Richiami: Classiﬁcazione e Regressione, overﬁtting, underﬁtting 
4 datasets: Forge, Wave, Wisconsin breast cancer, Boston housing 
Classiﬁcazione k-Neighbors e Scikit-learn, decision boundaries 
Misura R
2 
k-Neighbors regression e Scikit-learn 
Esercizi su linear, Ridge e LASSO regressioni su vari dataset"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#10,10,"Regression: Boston housing dataset
Il dataset di 506 istanze mira a predire il costo degli immobili residenziali in 
vari quartieri di Boston nel 1970, impiegando 13 features (es. il tasso di 
crimine, vicinanza al ﬁume, accessibilità alle autostrade). 
from 
sklearn.datasets 
 import 
load_boston
boston 
= 
load_boston
 ()
print
(
""Data shape: {}""
 .
format
(
boston
.
data
.
shape
))
> Data shape: (506, 13)
È possibile combinare due o più features creandone ulteriori non presenti nel 
dataset originale, attività che rientrano nella fase di 
 feature engineering, 
 dove 
si identiﬁcano o costruiscono le caratteristiche salienti. 
In questo esempio combiniamo 2 features alla volta: 
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
> X.shape: (506, 104)
Ora abbiamo 104 features, ottenute dalle 13 originali con tutte le 91 possibili 
combinazioni di coppie.
11"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#11,11,"Classiﬁcazione k-Neighbors (k-NN)
Nel caso più semplice l'algoritmo k-NN considera solo 1 vicino (k=1), che 
risulta il più vicino all'istanza su cui vogliamo esprimere una predizione. 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
1
)
Per k=3: 
mglearn
.
plots
.
plot_knn_classification
 (
n_neighbors
 =
3
)
Per il forge dataset otteniamo:
12
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#12,12,"Esercizio: Scikit-learn, k-NN e valutazione
La libreria Scikit-learn rende disponibile la classe 
 KNeighborsClassiﬁer
  per 
creare modelli basati sull'algoritmo k-NN. 
La funzione 
 score
 ()
 valuta l'accuracy media, cioè il numero di label 
correttamente stimate rispetto al totale delle istanze valutate. 
from 
sklearn.neighbors 
 import 
KNeighborsClassifier
model 
= 
KNeighborsClassifier
 (
n_neighbors
 =
3
)
model
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
clf
.
score
(
X_test
, 
y_test
)))
Esercizio
 : (1) prendere il dataset forge, (2) creare una partizione training/
test, (3) addestrare un classiﬁcatore KNeighborsClassiﬁer  
e (4) valutarne 
l'accuratezza. 
13"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#13,13,"k-NN e decision boundaries
In presenza di 2 features è possibile rappresentare su un piano 
 2d
 la classe 
che verrebbe assegnata dal modello per ogni punto del piano, così da 
riconoscere il conﬁne tra una label e l'altra. Sfruttiamo la libreria 
 mglearn
 : 
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
10
, 
3
))
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
 
 clf 
= 
KNeighborsClassifier
 (
n_neighbors
 =
n_neighbors
 )
.
fit
(
X
, 
y
)
  
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
True
, 
eps
=
0.5
, 
ax
=
ax
, 
alpha
=.
4
)
  
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
  
ax
.
set_title
 (
""{} neighbor(s)""
 .
format
(
n_neighbors
 ))
  
ax
.
set_xlabel
 (
""feature 0""
 )
  
ax
.
set_ylabel
 (
""feature 1""
 )
axes
[
0
]
.
legend
(
loc
=
3
)
Quali considerazioni possiamo fare?
14
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#14,14,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?
15
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#15,15,"k-NN e decision boundaries
1-NN segue in modo migliore i dati di addestramento.  
Per k > 1 crea un conﬁne più ""dolce"" e un modello più semplice.  
Cosa succede se k corrisponde al numero di istanze del dataset?  
Tutte le istanze avrebbero lo stesso neighbors e le predizioni sarebbero 
sempre le stesse.
16
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#16,16,"Esercizio: studio dell'accuracy
Colleziona le accuracy del classiﬁcatore KNeighborsClassiﬁer sul training 
set sia sul test set, al variare di k in [1,10], e valuta gli andamenti. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
66
)
training_accuracy 
 = 
[]
test_accuracy 
 = 
[]
...
plt
.
plot
(
neighbors_settings
 , 
training_accuracy
 , 
label
=
""training accuracy""
 )
plt
.
plot
(
neighbors_settings
 , 
test_accuracy
 , 
label
=
""test accuracy""
 )
plt
.
ylabel
(
""Accuracy""
 )
plt
.
xlabel
(
""n_neighbors""
 )
plt
.
legend
()
17"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#17,17,"Esercizio: studio dell'accuracy
Con k=1 si ha una accuracy massima per il training set. Con 
 k
 più grandi la 
complessità del modello si riduce e l'accuracy decrementa. 
Al contrario, con 
 k=1 
l'accuracy sul test set è più bassa (circa 0.90), 
sintomo che il modello è 
 troppo complesso
 . Allo stesso modo con 
 k
 elevati 
l'accuracy 
 non è soddisfacente 
 poiché il  
modello è 
 troppo semplice
 . 
Per questo dataset un valore ottimale si ottiene intorno a k=6. 
Attenzione:  solitamente i graﬁci non sono sempre così 
 smooth
 .
18
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#18,18,"k-neighbors regression
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
1
)
19
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#19,19,"k-neighbors regression (2)
Richiami: per 
 k=1
, il valore predetto corrisponde al valore associato 
all'istanza più vicina. Nel caso k > 1, si mediano i valori. 
mglearn
.
plots
.
plot_knn_regression
 (
n_neighbors
 =
3
)
20
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#2,2,"Richiami: classiﬁcazione e regressione
Finora abbiamo visto problemi di regressione, dove si richiede di predire 
un valore numerico a partire da una istanza in ingresso. 
L'obiettivo della classiﬁcazione è assegnare una 
 label
 ad una istanza in 
ingresso.  
Se le label sono due si parla di 
 binary classiﬁcation
 , altrimenti 
 multiclass
 . 
Il dataset 
 iris
 è un esempio di multiclass classiﬁcation. 
Un modello ben addestrato mostra la capacità di generalizzare sui dati del 
test set, e in fase di produzione. 
Chiaramente se training set e test set hanno molte caratteristiche in 
comune, allora ci aspettiamo che il modello addestrato, se ben progettato, 
sia anche accurato.
3"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#20,20,"Performance: la misura 
 R
2
21
R
2
 è il 
coefﬁciente di determinazione
 , e indica la porzione di varianza della 
variabile y correttamente predetta dal modello (cioè dalle features impiegate), 
perciò è una misura di accuratezza. 
Assume valori in [0,1]. Per valori prossimi a 
 1
 il modello predice 
accuratamente il valore della variabile dipendente 
 y
 in base al valore delle 
features.  
Ad esempio: per 
 R
2
=0.83, il 17% della variazione nei dati non è rappresentato dal 
modello, o perché è dovuto al caso, o perché dipende da un features che non sono stata 
considerate. 
Per valori vicini a 0, il modello si comporta come un predittore che assume 
sempre il valor medio come output, perciò non tiene conto della varianza 
La funzione 
 score()
  del modello Python valuta il valore 
 R
2
 sui dati in input.R2=1−RSS
∑N
i=1(yi−¯y)2=1−∑N
i=1(yi−̂yi)2
∑N
i=1(yi−¯y)2=∑N
i=1(̂yi−¯y)2
∑N
i=1(yi−¯y)2"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#21,21,"scikit-learn: k-neighbors regression
La classe KNeighborsRegressor implementa l'algoritmo di regressione k-neighbors. 
Il parametro 
 n_neighbors
  corrisponde a 
 k
. 
reg 
= 
KNeighborsRegressor
 (
n_neighbors
 =
k
)
Esercizio
 : completa il codice con la classe suddetta e valuta i graﬁci che ottieni:  
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
3
, 
figsize
=
(
15
, 
4
))
# create 1,000 data points, evenly spaced between -3 and 3
line 
= 
np
.
linspace
 (
-
3
, 
3
, 
1000
)
.
reshape
(
-
1
, 
1
)
# make predictions using 1, 3, or 9 neighbors
for 
n_neighbors
 , 
ax 
in 
zip
([
1
, 
3
, 
9
], 
axes
):
...
ax
.
plot
(
line
, 
reg
.
predict
(
line
))
ax
.
plot
(
X_train
, 
y_train
, 
'^'
, 
c
=
mglearn
.
cm2
(
0
), 
markersize
 =
8
)
ax
.
plot
(
X_test
, 
y_test
, 
'v'
, 
c
=
mglearn
.
cm2
(
1
), 
markersize
 =
8
)
ax
.
set_title
 (
""{} neighbor(s)\n train score: {:.2f} test score: {:.2f}""
 .
format
(
n_neighbors
 , 
reg
.
score
(
X_train
, 
y_train
),
reg
.
score
(
X_test
, 
y_test
)))
ax
.
set_xlabel
 (
""Feature""
 )
ax
.
set_ylabel
 (
""Target""
 )
axes
[
0
]
.
legend
([
""Model predictions""
 , 
""Training data/target""
 ,
         
 ""Test data/target""
 ], 
loc
=
""best""
)
22"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#22,22,"scikit-learn: k-neighbors regression
Considerando più istanze durante la predizione si ottiene chiaramente una 
curva più 
 smooth
 .
23
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#23,23,"k-NN nella pratica
L'algoritmo ha due parametri principali: 
 k
 e la 
 misura di distanza
 . 
In generale, si possono usare bassi valori per 
 k
 (es. 5) sebbene occorra 
sperimentare il valore esatto in base al dataset.  
La 
misura euclidea
  si adatta bene in molti scenari. 
Il k-NN è spesso la scelta iniziale per la sua semplicità, ma in alcuni 
contesti non è adatto: 
Per training set molto grandi (numero di istanze e/o features) che 
causano tempi di predizione lenti, a meno di non precomputare 
l'output in una fase preliminare prima di impiegare l'algoritmo in 
produzione. 
Dataset sparsi, cioè con features spesso senza valore.
24"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#24,24,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
.
25"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#25,25,"Esercizio: linear regression e wave dataset
Esercizio
 : applicare la 
 linear regression
  al wave dataset con 60 istanze. 
Ricavare i parametri del modello. Valutare il valore 
 R
2
. 
from 
sklearn.linear_model 
 import 
LinearRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
60
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
42
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""lr.coef_: {}""
 .
format
(
lr
.
coef_
))
print
(
""lr.intercept_: {}""
 .
format
(
lr
.
intercept_
 ))
> lr.coef_: [ 0.394]
> lr.intercept_: -0.031804343026759746
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.67
> Test set score: 0.66
Nota: coef_ è di tipo NumPy array, avendo dimensione pari al numero di 
features per istanza. 
Cosa possiamo dire con i valori di performance ottenuti?
26"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#26,26,"Esercizio: linear regression e wave dataset
> Training set score: 0.67
> Test set score: 0.66
Sono valori piuttosto bassi.  
I valori sul training e test set sono molto simili, sintomo di 
 underﬁtting
 .  
Per modelli lineari e dataset semplici (es. mono-dimensionali) esiste un 
rischio minore di fare overﬁtting data la semplicità del modello. 
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.
27"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#27,27,"Esercizio: linear regression e wave dataset
Esercizio
 : prova lo stesso approccio con il Bostong housing dataset e 
confronta le performance.  
X
, 
y 
= 
mglearn
.
datasets
 .
load_extended_boston
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
random_state
 =
0
)
lr 
= 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.2f}""
 .
format
(
lr
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.2f}""
 .
format
(
lr
.
score
(
X_test
, 
y_test
)))
> Training set score: 0.95
> Test set score: 0.61
La differenza tangibile tra training e test set è sintomo di overﬁtting. 
Occorre adattare il modello. 
28"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#28,28,"Richiami: Ridge regression
Nella 
 ridge regression
  si implementa un forma semplice di 
regolarizzazione
 , cioè tecniche per affrontare il problema del overﬁtting. 
I parametri 
 w
 del modello lineare devono rispettare un vincolo 
aggiuntivo: il valore assoluto dei singoli parametri deve essere piccolo.  
Intuitivamente:
  ogni feature può avere un effetto limitato sul valore 
predetto dal modello. 
Prende il nome di L2 regularization. 
La funzione che rappresenta il costo nella ridge è la seguente:
29
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#29,29,"Scikit-learn: Ridge regression
La classe 
 Ridge
  nel modulo sklearn.linear_model implementa la ridge 
regression: 
clf 
=
 Ridge(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro 
 alpha,
  che per default assume valore 1. 
30"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#3,3,"Richiami: overﬁtting e underﬁtting
Supponiamo di avere il seguente dataset che rappresenta la possibilità che 
un cliente acquisti una barca in base a certe sue caratteristiche: 
Se guardi questi dati, che proﬁlo di cliente potenzialmente interessato a 
comprare puoi identiﬁcare dalle features riportate?
4
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#30,30,"Esercitazione: Ridge regression
Esercizio
 : impiegare la ridge regression nel Boston housing dataset.  
Cosa ti aspetti dalle performance che ottieni rispetto alla linear regression 
senza regolarizzazione? 
Esercizio
 : ricava gli score per 
 λ
 pari a 0.1 e 10. Cosa ti aspetti? 
Esercizio
 : crea un graﬁco 2d dove visualizzi i parametri dei tre modelli 
ridge
 , 
ridge10
  e 
ridge01
 . Cosa ti aspetti nella distribuzione dei parametri? 
Esercizio
 : Come pensi che vari lo score 
 R
2
, sul training e sul test set, al 
variare del numero di istanze usate durante l'addestramento?
31"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#31,31,"Richiami: LASSO
Nel modello 
 LASSO
  si impiega la 
 L1-regularization
 , dove alcuni parametri 
assumono valore esattamente pari a 0, ignorando perciò alcune features. 
Può essere interpretato come una sorta di 
 feature selection
 , cioè un 
processo per selezionare le feature più rilevanti nel task in esame. 
Il vantaggio è avere un modello più semplice, più veloce da addestrare, che 
considera solo le features più rilevanti.
32
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#32,32,"Scikit-learn: LASSO
La classe 
 Lasso
  nel modulo sklearn.linear_model implementa il modello 
LASSO:  
clf 
=
 Lasso(alpha
 =
1.0
) 
Il parametro 
 λ
 che controlla il peso della regolarizzazione è deﬁnito 
mediante il parametro alpha, che per default assume valore 1. 
Esercizio
 : impiegare LASSO nel Boston housing dataset. Cosa ti aspetti 
dalle performance che ottieni rispetto alla linear e Ridge regression?
33"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#33,33,"Esercitazione: LASSO
Esercizio
 : impiega LASSO nel Boston housing dataset 
Esercizio
 : prova a variare nuovamente 
 λ
 per migliorare le performance. 
34"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#34,34,"Ridge e LASSO: considerazioni
Solitamente si impiega la Ridge come primo approccio.  
Nel caso ci siano molte features, ma solo un sottoinsieme verosimilmente 
rilevanti, LASSO risulta la scelta migliore. 
LASSO inoltre produce modelli più semplici e più facilmente interpretabili 
rispetto a Ridge, utile per investigare il dataset nelle fasi iniziali. 
Scikit-learn implementa la classe 
 ElasticNet
  che combina i due approcci e 
ottiene ottime performance, ma con due iperparametri da impostare, uno 
per L1 e uno per L2 regularization.
35"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#35,35,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
36"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#4,4,"Richiami: overﬁtting e underﬁtting (2)
Cliente di 
 45 anni o più
 , 
meno di 3 ﬁgli
  o 
non divorziato
 . 
Questa ""regola"" è al 
 100%
  accurata. 
Ma una regola sull'età del tipo età=66 OR 52 OR 53 OR 58 è altrettanto 
accurata. 
Dobbiamo ricordarci che il modello dovrà funzionare altrettanto 
accuratamente su dati mai visti in precedenza. 
Le regole che abbiamo escogitato sembrano funzionare, ma sono troppo 
speciﬁche per le istanze del nostro dataset. Se nel test set abbiamo istanze 
simili, allora questo semplice modello può funzionare, ma non è detto che 
funzioni anche in produzione.
5"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#5,5,"Richiami: overﬁtting e underﬁtting (3)
Il nostro obiettivo è sempre trovare il modello più semplice che abbia 
buone performance anche sul test set. 
Costruire un modello troppo complesso rispetto ai dati disponibili crea 
overﬁtting
 .  
Il modello è troppo speciﬁco per le istanze nel training set ma non è capace di 
generalizzare sui dati nel test set. 
Un modello troppo semplice rispetto ai dati disponibili può creare 
fenomeni di 
 underﬁtting
 , cioè scarse performance perﬁno nel training set 
poiché non riesce a catturare tutte le caratteristiche e legami tra le features.
6
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#6,6,"4 datasets
Introduciamo 4 datasets utili per osservare come si comportano diversi 
algoritmi di machine learning implementati in scikit-learn. 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Wisconsin Breast Cancer dataset
  (classiﬁcazione) 
Boston housing dataset
  (regressione)
7"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#7,7,"Classiﬁcazione: Forge dataset
26 istanze, 2 features per istanza, e 2 classi: 
# codice per ottenere il dataset
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
# grafico le istanze
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 ], 
loc
=
4
)
plt
.
xlabel
(
""First feature""
 )
plt
.
ylabel
(
""Second feature""
 )
print
(
""X.shape: {}""
 .
format
(
X
.
shape
))
8
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#8,8,"Regressione: wave dataset
Singola feature per istanza, singolo valore reale in output. 
X
, 
y 
= 
mglearn
.
datasets
 .
make_wave
 (
n_samples
 =
40
)
plt
.
plot
(
X
, 
y
, 
'o'
)
plt
.
ylim
(
-
3
, 
3
)
plt
.
xlabel
(
""Feature""
 )
plt
.
ylabel
(
""Target""
 )
Per dataset così piccoli è sempre utile studiare le caratteristiche delle 
istanze su graﬁci.
9
"
data_test\rootfolder\università\MachineLearning\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#9,9,"Classiﬁcazione: Wisconsin Breast Cancer dataset
Misure cliniche associate a patologie tumorali, con label '
 benigno
 ' '
maligno
 '  
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
print
(
""cancer.keys(): \n{}""
 .
format
(
cancer
.
keys
()))
> cancer.keys():
> dict_keys(['feature_names', 'data', 'DESCR', 'target', 'target_names'])
print
(
""Shape of cancer data: {}""
 .
format
(
cancer
.
data
.
shape
))
> Shape of cancer data: (569, 30)
print
(
""Sample counts per class:\n{}""
 .
format
(
{
n
: 
v 
for 
n
, 
v 
in 
zip
(
cancer
.
target_names
 , 
np
.
bincount
 (
cancer
.
target
))}))
> Sample counts per class: {'benign': 357, 'malignant': 212}
print
(
""Feature names:\n{}""
 .
format
(
cancer
.
feature_names
 ))
> Feature names:
['mean radius' 'mean texture' 'mean perimeter' 'mean area'
'mean smoothness' 'mean compactness' 'mean concavity'
'mean concave points' 'mean symmetry' 'mean fractal dimension'
'radius error' 'texture error' 'perimeter error' 'area error'
'smoothness error' 'compactness error' 'concavity error'
'concave points error' 'symmetry error' 'fractal dimension error'
'worst radius' 'worst texture' 'worst perimeter' 'worst area'
'worst smoothness' 'worst compactness' 'worst concavity'
'worst concave points' 'worst symmetry' 'worst fractal dimension']
10"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Alberi di Decisione
Machine Learning "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#1,1,"Sommario
Introduzione ai Decision Trees 
Esempio di applicazione 
Feature split learning 
Decision Stump 
Algoritmo greedy decision tree learning 
Classiﬁcazione mediante Decision Trees
 
2"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#10,10,"Learning Goal 
 
11
Il nostro obiettivo è dunque quello di costruire un albero di 
decisione che minimizzi il Classiﬁcation Error sui dati di 
training, calcolato mediante la metrica di qualità che 
abbiamo deﬁnita. 
Purtroppo questo è un task estremamente difﬁcile: 
•abbiamo un numero esponenziale di possibili alberi da considerare  
•problema NP-hard 
•possiamo però utilizzare delle euristiche che funzionano bene in 
pratica"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#11,11,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto” e consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai diversi valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
12Vediamo informalmente come poter procedere per costruire un albero di 
decisione:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#12,12,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
13Primo problema:
feature
 selection"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#13,13,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
14Secondo problema:
stopping conditions"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#14,14,"Algoritmo greedy  
decision tree learning 
1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi 
disponibili. 
2. Selezioniamo la feature “migliore” con la quale possiamo 
partizionare (split) i dati in base ai vari valori che essa può assumere. 
3. Per ogni split: 
•
Se non ci sono altre operazioni da fare, costruire foglia con la 
previsione. 
•
Altrimenti, continua la costruzione dell’albero a partire dallo 
split che stiamo considerando. 
 
15Chiamata ricorsiva:
chiamata ricorsiva"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#15,15,"Predizioni con Decision Stump 
[feature selection]
 
1622  18
SicuroRoot node: relativo a tutte le osservazioni. 
22: output “Sicuro” 
18: output “Rischioso” 
Ora dobbiamo selezionare una feature  
(feature selection problem)"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#16,16,"Predizioni con Decision Stump 
[feature: Reputazione]
 
17Reputazione22  18
SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Se scegliamo “Reputazione”:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#17,17,"Decision Stump 
[feature: Reputazione]
 
18SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
set  ŷ = “majority value” "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#18,18,"Decision Stump 
[feature: Reputazione]
 
19SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#19,19,"Decision Stump 
[feature: Durata]
 
20SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14Se scegliamo “Durata”:
4 errori 6 errori"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#2,2,"Alberi di Decisione 
Vediamo ora un altro metodo per la classiﬁcazione, molto 
utile nella pratica. 
Un albero di decisione prende come ingresso un oggetto o 
una situazione descritta da un insieme di attributi (features) e 
restituisce una “decisione”. 
Effettua dunque una “classiﬁcazione” della situazione 
presentata in input.  
 
3"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#20,20,"Selezione della migliore feature 
[feature selection]
 
21SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14Dobbiamo deﬁnire un criterio per la scelta della migliore feature:
vs."
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#21,21,"Selezione della migliore feature 
[feature selection]
 
22SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 erroriPer far questo consideriamo gli errori già visti in precedenza …….
vs."
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#22,22," 
23SicuroDurata22  18
Rischioso5 anni 3 anni
16    4 6    14
SicuroReputazione22  18
Rischioso SicuroScarsa EccellenteSufﬁciente
9    0 9    4 4    14
0 errori 4 errori 4 errori 4 errori 6 errori…… e usiamoli per calcolare il Classiﬁcation Error per ogni feature:
vs.4+4
22 + 18=0 .24+6
22 + 18=0 .25
Scegliamo la feature con il Classiﬁcation Error più basso.
Selezione della migliore feature 
[feature selection]"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#23,23,"Calcolo Classiﬁcation Error 
Abbiamo dunque diviso il calcolo del Classiﬁcation Error in 
due fasi: 
1.
 Per ogni nodo relativo ad un sottoinsieme dei dati, ottenuto 
considerando uno dei possibili valori della feature 
d’interesse, assegniamo il valore della majority class del 
nodo (
 ŷ
 = “majority class”). 
2.
 Calcolo del Classiﬁcation Error considerando come  
predizione per ogni nodo considerato quella assegnata nel 
passo precedente. 
 
24"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#24,24,"Algoritmo per  
Feature Split Selection 
Dato un sottoinsieme M di osservazioni disponibili (nodo 
dell’albero): 
• 
∀
 feature 
 ɸ
j
(
x
): 
•
 Split dei dati M in  base ai valori della feature 
 ɸ
j
(
x
). 
•
 Calcolo del Classiﬁcation Error per il Decision Stump 
della feature 
 ɸ
j
(
x
). 
•
 Scelta della feature 
 ɸ
j*
(
x
) con il Classiﬁcation Error più 
basso. 
 
25"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#25,25,"Tree Learning 
[recursive stump learning]
 
26SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9    0 9    4 4    14
costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Sufﬁciente costruire un decision 
stump con il sotto-
insieme dei dati in cui: 
Reputazione = Scarsa 
foglia dell’alberoLa costruzione dell’albero si effettua come segue:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#26,26,"Tree Learning 
[secondo livello]
 
27SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#27,27,"Tree Learning 
[secondo livello]
 
28SicuroReputazione22  18
Scarsa EccellenteSufﬁciente
9     0 9     4 4    14
Durata
Rischioso Sicuro3 anni 5 anni
0     4 9     0Reddito
RischiosoAlto Modesto
0     9 4     5
altro 
decision 
stump"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#28,28,"Tree Learning 
[terzo livello]
 
29Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#29,29,"Tree Learning 
[stopping conditions]
 
30Scarsa
4    14
Reddito
RischiosoAlto Modesto
0     9 4     5
Sicuro RischiosoDurata
3 anni 5 anni
0     2 4     3 stopping conditions?"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#3,3,"Esempio di applicazione 
[valutazione richiesta prestito]
 
4Richiesta 
PrestitoModello di 
ClassiﬁcazioneSicuro
Rischioso
Input: xi(Output: y i = +1)
(Output: y i = -1)
Vediamo un esempio di applicazione, relativo alla 
valutazione di richieste di prestito da parte di un cliente alla 
propria banca:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#30,30,"Stopping Conditions 
La costruzione di un ramo dell’albero si ferma quando arriviamo 
ad un nodo nel quale si veriﬁca una delle seguenti condizioni: 
1.
 Gli esempi relativi al nodo sono tutti di uno stesso tipo (e.g., 
tutti 
Sicuro
  o tutti 
 Rischioso
 ): scegliamo come foglia il valore in 
questione. 
2.
 Gli esempi relativi al nodo sono di tipo diverso, e non ci sono 
più feature da considerare: scegliamo come foglia il majority 
value. 
3.
 Nel nodo non ci sono più esempi, ma c’è ancora qualche 
feature non considerata nel percorso che porta a quel nodo: 
valore di default (e.g., maggioranza nodo genitore). 
 
31"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#31,31,"Algoritmo greedy decision tree 
learning 
1. Start da un nodo relativo a M esempi 
2. Feature Selection 
3. Per ogni split: 
if
  Stopping Condition 
then
: costruire la foglia con la previsione 
 ŷ 
else
:  decision_tree_learning(nodo relativo allo split) 
 
32decision_tree_learning (nodo) 
Chiamata RicorsivaNon ci sono altre 
operazioni da fareSelezione Feature  
per dividere i dati"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#32,32,"Algoritmo per fare previsioni 
mediante Decision Tree 
Vediamo ora il semplice algoritmo che implementa la funzione 
T(
x
), ossia l’algoritmo che, a fronte di un ingresso 
 x
i
, visita l’albero 
di decisione costruito nella fase di training e fornisce in output una 
previsione 
 ŷ
i
: 
 
33 
if
 tree_node corrente è una foglia 
         
 then
: 
return
  majority class dei punti relativi alla foglia 
        
 else
: 
•
next_node = ﬁglio di tree_node il cui valore della feature 
corrisponde all’input 
•
return
  predict(next_node, input) predict (tree_node, input) "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#33,33,"Riferimenti
 
34
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#4,4,"Esempio di applicazione 
Nel formulare questo problema come un problema di 
apprendimento dobbiamo anzitutto decidere quali proprietà, 
o attributi (features), sono disponibili per descrivere esempi 
(osservazioni) nel dominio. 
In genere, alcune delle caratteristiche prese in considerazione 
i tali casi sono le seguenti: 
•
  reputazione cliente (e.g., ha pagato regolarmente vecchi prestiti?) 
•
reddito cliente 
•
durata prestito  
•
  altre informazioni personali (età, motivo per il prestito, ecc.)  
 
5"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#5,5,"Decision Tree Classiﬁer 
 
6Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniEsempio di decision tree per il problema in esame:"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#6,6,"Valutazione richiesta prestito 
 
7
Sicuro
DurataRedditoReputazioneStart
Sicuro
Rischioso
Rischioso
Rischioso
SicuroDurataScarsa
Eccellente
Sufﬁciente
Alto
Modesto
3 anni
5 anni
3 anni
5 annixi = (Reputazione = Scarsa , Reddito = Alto, Durata = 5 anni)  "
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#7,7," 
8Richiesta 
PrestitoModello di 
Classiﬁcazione
Input: xiSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1)
Sicuro Durata RedditoReputazioneStart
Sicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente
Sufﬁciente
Alto Modesto3 anni 5 anni
3 anni 5 anniRichiesta 
PrestitoSicuro
Rischioso(Output: y i = +1)
(Output: y i = -1) Input: xi
Decision Tree Model 
T(xi)"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#8,8,"Apprendimento albero dai dati
 
9
Reputazione Durata Reddito yi
eccellente 3 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
sufﬁciente 3 anni alto Rischioso
scarso 5 anni alto Sicuro
sufﬁciente 5 anni modesto Sicuro
scarso 3 anni alto Rischioso
scarso 5 anni modesto Rischioso
sufﬁciente 3 anni alto Rischioso
eccellente 3 anni modesto SicuroT(xi)
Vediamo come sia possibile costruire (ossia apprendere) un decision 
tree a partire da un certo numero di osservazioni:  
Minimizzazione  
funzione di costo"
data_test\rootfolder\università\MachineLearning\14-Classification - Decision Trees-sbloccato.pdf#9,9,"Metrica di Qualità 
[quality metric]
 
10Errore =#previsioni errate
#esempi
La metrica che si usa misura la frazione delle previsioni 
errate fornite dall’albero:
Ovviamente: 
• miglior valore possibile: 0.0 
• peggior valore possibile: ?"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Algoritmo C4.5"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#1,1,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error  
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5
2"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#10,10,"Guadagno
Introduciamo ora il Guadagno (Gain)  di un attributo A 
Calcolo di Gain(S,A) per ciascun attributo A 
•Riduzione di Entropia attesa a seguito dell’ordinamento del 
set di istanze S basato su A 
Scelta dell’attributo con il valore di Guadagno più elevato 
come nodo dell’albero 
Gain(S,A) = Entropy(S) – Expectation(A)  
 
 
 
dove {S1 ... Si ... Sn} sono le partizioni di S secondo i valori 
dell’attributo A, n il numero di valori distinti di A, |Si| il 
numero di istanze nella partizione Si e |S| il numero totale di 
istanze in S)( )( ),(
1in
iiS EntropySSS Entropy AS Gain ∗ − = ∑
=
11"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#11,11,"Scelta Nodo Radice
Se Outlook è radice dell’albero ci 
sono 3 partizioni sulle istanze (S1 per 
Sunny , S2 per Cloudy, S3 per Rainy ) 
S1 (Sunny) = {istanze 1,2,8,9,11} 
|S1| = 5 (di queste 5 istanze, i 
valori per Play sono 3 No e 2 Yes) 
Entropy(S1) =  
= -2/5 (log2 2/5) – 3/5 (log2 3/5) =        
= -0.4 (-1.322) – 0.6 (-0.737) =  
= 0.53 +0.44 = 0.97 
Analogamente si ottiene  
 Entropy(S2) = 0  
 Entropy(S3) = 0.97 
 12"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#12,12,"Scelta Nodo Radice
Gain(S,Outlook) = Entropy(S) – Expectation(Outlook) = 
= Entropy(S) – [|S1|/|S| * Entropy(S1) + |S2|/|S| * Entropy(S2) +  
+ |S3|/|S| * Entropy(S3)] = 0.94 – [5/14 * 0.97 + 4/14 * 0 + 5/14 * 0.97]  
da cui si ottiene 
Gain(S,Outlook) = 0.247 
Analogamente 
Gain(S,Temperature) = 0.029 
Gain(S,Humidity) = 0.152 
Gain(S,Windy) = 0.048  
In conclusione Gain(S,Outlook)  è il guadagno più elevato e quindi 
Outlook dovrebbe essere scelto come radice dell’Albero di Decisione  
13"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#13,13,"Scelta Nodi Successivi 
Ripetiamo il procedimento per il ramo 
 Sunny
  …
temperatureoutlook
rainy sunnycloudy
hot mild cold?
0    2 1    1 1    04    0
windyoutlook
rainy sunnycloudy
false?
true
1    2 1    14    0 humidityoutlook
rainy sunnycloudy
high?
normal
0    3 2    04    0
14
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#14,14,"Scelta Nodi Successivi 
… e per il ramo Rainy
humidityoutlook
rainy sunnycloudy
high normalMild High False Yes
Cool Normal False Yes
Cool Normal True No
Mild Normal False Yes
Mild High True NoNo Yes Yes 
15
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#15,15,"humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normal
Decision Tree 
windy
high
No Yes falseIn conclusione, si ottiene il seguente Albero di Decisione
16
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#16,16,"Scelta Nodo Radice 
La selezione dell’attributo come nodo radice è eseguita 
valutando il Guadagno di Informazione (Information Gain)  per 
ciascun attributo e scegliendo quello che dà il valore maggioreQual è l’attributo migliore per essere nodo radice dell’albero?
outlook
rainy sunnycloudyhumidity
low hightemperature
cold hotmildwindy
false true
2     
34     
04     
23     
13     
23     
46     
12     
26     
23     
3
17"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#17,17,"Algoritmo C4.5
N.B. Pure: all instances in the subset fall in the same classSet di dati (tabella) attributo-valore
18"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#18,18,"Algoritmo C4.5
Salvatore Ruggieri. 2000. Efficient C4.5.  Technical Report. University of 
Pisa.  
Abstract: We present an analytic evaluation  of the run-time behavior  of the 
C4.5 algorithm which highlights some efficiency improvements. We have 
implemented a more efficient version of the algorithm, called EC4.5, that 
improves on C4.5 by adopting the best among three strategies at each node 
construction. The first strategy uses a binary search of thresholds instead of 
the linear search of C4.5. The second strategy adopts a counting sort method 
instead of the quicksort of C4.5. The third strategy uses a main-memory 
version of the RainForest algorithm for constructing decision trees. Our 
implementation computes the same decision trees as C4.5 with a 
performance gain of up to 5 times.
19"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#19,19,"Esercizio
Creare l’Albero di Decisione (Indice) per la  
Previsione di Rischio per Richieste di Prestito
20"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#2,2,"Algoritmo C4.5
 J. Ross Quinlan. 1993. C4.5: Programs for Machine Learning.   
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. 
 X. Wu, V. Kumar, J. R. Quinlan , J. Ghosh, Q. Yang, H. Motoda, G. J. 
McLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J. 
Hand, and D. Steinberg. 2007. Top 10 Algorithms in Data Mining.  
Knowledge and Information Systems , Volume 14, Issue 1, December 
2007, Pages 1-37, Springer-Verlag New York, Inc. New York, NY, USA.  
DOI=http://dx.doi.org/10.1007/s10115-007-0114-2  
3"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#20,20,"Esercizio
21"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#21,21,"Esercizio
( ) )( )( ,)( )(log )(
12
1
An Expectatio S Entropy AS GainS EntropySSAn Expectatiop p S Entropy
in
iiin
ii
− =∗ =∗− =
∑∑
==
22"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#22,22,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer  
23"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#23,23,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
24"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#24,24,"Algoritmo CART
Breiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984). 
Classification and Regression Trees.  Monterey, CA: Wadsworth & 
Brooks/Cole Advanced Books & Software. 
25"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#25,25,"Algoritmo CART
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Si basa sul Gini Index (o Indice di Gini) 
In corrispondenza di un certo nodo t dell’albero in costruzione, e rispetto alla 
corrispondente partizione del dataset di training, si definisce l’Indice di Gini 
come segue: 
 
      dove p(j/t) è la frequenza relativa (proporzione) della classe j  al nodo t  
L’Indice di Gini misura l’ impurezza ( o disordine)  del dataset corrispondente a t 
•Massimo valore ( 1-1/n c, con nc=numero di classi equiprobabili) quando i 
record sono equamente distribuiti fra tutte le classi 
•Minimo valore (0) quando tutti i record appartengono a una sola classeGini(t)=1−∑
j[p(j/t)]2
26"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#26,26,"Indice di Gini
           
Nel caso di una sola classe: 
                                                     
Nel caso di nc classi equiprobabili 
                                               
 
       dove n è il numero di record del dataset al nodo tGini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−12=0
Gini(t)=1−∑
j((n/nc)/n)2=1−∑
j(1/nc)2=1−nc(1/nc)2=1−1/nc
27"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#27,27,"Indice di Gini
           
C1=0, C2=6 —> P(C1)=0/6=0 , P(C2)=6/6=1  
                             
C1=1, C2=5 —> P(C1)=1/6 , P(C2)=5/6  
                                    
C1=2, C2=4 —> P(C1)=2/6 , P(C2)=4/6  
                                    
C1=3, C2=3 —> P(C1)=3/6=0.5 , P(C2)=3/6=0.5  
                                   Gini(t)=1−∑
j[p(j/t)]2
Gini(t)=1−P(C1)2−P(C2)2=1−0−1=0
Gini(t)=1−1/62−5/62=0.278
Gini(t)=1−2/62−4/62=0.444
Gini(t)=1−0.52−0.52=0.500
28"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#28,28,"Algoritmo CART
29
Criterio di Splitting: Minimizzare l’Indice di Gini della suddivisione  
Quando un nodo t è suddiviso in k partizioni (figli), la qualità della suddivisione è 
calcolata come:  
 
 
 
 
dove  
   ni = numero di record della partizione (figlio) i 
   n = numero di record del dataset al nodo t 
   n i/n = peso dei vari Gini(i) 
Dato il dataset associato al nodo t, si sceglie l’attributo che fornisce il più piccolo 
Gini split(t) per partizionare il dataset 
•E’ necessario enumerare tutti i possibili punti di splitting per ciascun attributo, 
ovverosia tutte le possibili partizioni   
 Ginisplit=k
∑
i=1ni/n*Gini(i)"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#29,29,"Algoritmi Induzione DT
Algoritmo Greedy Decision Tree Learning  
•Scelta della migliore feature utilizzando come metrica il Classification Error 
sui dati di training —> problema NP-Hard —> servono euristiche 
Algoritmo C4.5  
•Scelta della migliore feature utilizzando come metrica l’ Information Gain   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
Algoritmo CART  
•Scelta della migliore feature utilizzando come metrica il Gini Index   
sui dati di training —> problema risolvibile tramite strategia divide&conquer 
30"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#3,3,"Algoritmo C4.5
4"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#4,4,"Algoritmo C4.5
Obiettivo: generare un Albero di Decisione da una Tabella di Dati  
Sviluppato da J. R. Quinlan nel 1993 come estensione dell’ Algoritmo ID3   
L’Albero ottenuto può essere usato per la classificazione, per cui 
l’Algoritmo C4.5  è spesso indicato come Statistical Classifier 
Basato sulla Teoria dell’Informazione (Claude E. Shannon, A Mathematical 
Theory of Communication , 1948) 
Strategia “divide and conquer” (suddivisione del problema in 
sottoproblemi più semplici e loro risoluzione ricorsiva):  
•Scelta di uno degli attributi come nodo radice 
•Creazione ramo per ciascun valore di quell’attributo 
•Suddivisione delle istanze lungo i rami 
•Ripetizione del processo per ciascun ramo finché tutti le istanze nel ramo hanno 
la stessa classe di appartenenza (si dice che tutti i sottoalberi sono “puri”)  
Assunzione di fondo: quanto più semplice  è l’albero che classifica le 
istanze, tanto meglio  è
 5"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#5,5,"Entropia
Introduciamo il concetto di Entropia (Entropy) [(dal greco antico ἐν   
en, ""dentro"", e τροπή  tropé, “trasformazione"")] 
Entropia in Meccanica Statistica: grandezza interpretata come 
misura del disordine presente in un sistema fisico qualsiasi, 
incluso - come caso limite - l’universo 
Entropia in Teoria dell’Informazione: quantità di incertezza o 
informazione presente in un segnale aleatorio 
•Primo Teorema di Shannon (Codifica di Sorgente): “Una 
sorgente casuale d’informazione non può essere rappresentata 
con un numero di bit (da cui la base 2 del logaritmo) inferiore 
alla sua entropia, cioè alla sua autoinformazione media.”  
Tale teorema ha quindi un’implicazione in termini di 
rappresentazione dati, in quanto l’Entropia può essere 
interpretata anche come la minima complessità descrittiva di 
una variabile aleatoria, ovvero il limite inferiore della 
compressione dei dati 
 6"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#6,6,"Tabella di Dati
7
"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#7,7,"Decision Tree
8humidityoutlook
rainy sunnycloudy
true
No Yes
Yes normalwindy
high
No Yes false
Nodi interni = test sugli attributi (feature) 
Archi uscenti = risultati dei test 
Nodi foglia = etichette classe di appartenenza"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#8,8,"Entropia
Intro duciamo il concetto di Entropia (Entropy) di un set di istanze  
S è un set di istanze (i.e., record della tabella) 
A è una feature (Play nell’esempio) 
{S1 ... Si ... Sn} sono le partizioni  di S secondo gli n valori che può 
assumere A (“Yes” e “No”  nell’esempio) 
{p1 ... pi ... pn} sono le proporzioni  di {S1 ... Si ... Sn} in S 
Si definisce Entropia di S la seguente grandezza
( ) ∑
=∗− =n
ii i p p S Entropy
12log )(
9"
data_test\rootfolder\università\MachineLearning\15-Alberi C4.5-sbloccato.pdf#9,9,"Entropia
Nel caso dell’esempio 
S è il set di 14 istanze 
L’obiettivo è classificare le istanze secondo i valori della 
feature Play, ossia “Yes” e “No”  
La proporzione delle istanze con valore “Yes” è 9 su 14 
(9/14=0.64) 
La proporzione delle istanze con valore “No” è 5 su 14 
(5/14=0.36) 
L’Entropia misura l’ impurezza di S e in questo caso vale  
Entropy(S)= - 0.64 (log2 0.64) – 0.36 (log2 0.36)=  
= - 0.64 (- 0.644) – 0.36 (- 1.474) = 0.41 + 0.53 = 0.94 
10"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcation:  
Boosting"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#1,1,"Sommario
Introduzione 
Ensemble Learning 
Boosting 
AdaBoost
 
2"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#10,10,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
11
Ogni classiﬁcatore esprime un voto in base al valore della 
feature relativa. 1
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
f1(xi) = -1 f2(xi) = +1 f3(xi) = -12 3
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#11,11,"Ensemble Model 
I vari voti espressi dai classiﬁcatori sono combinati insieme 
come segue per formulare la previsione ﬁnale: 
 
12
Se il segno è positivo la previsione vale +1, se è negativo vale -1. 
Questo è un semplice esempio di Ensemble Classiﬁer. 
Si segnala l’importanza dei pesi w
 i
, che devono essere 
individuati mediante un processo di training. F(xi) = sign[w 1 * f 1(xi) + w 2 * f 2(xi) + w 3 * f 3(xi)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#12,12,"Riepilogo sugli 
Ensemble Classiﬁer 
Obiettivo: 
•
 predire un output 
 ŷ
 (+1 o -1 nell’esempio) a partire da un 
input 
 x 
 
13
Apprendimento dell’Ensemble Model: 
• Classiﬁers: f 1(x), f2(x), …, f T(x) 
• Coefﬁcienti: ŵ1, ŵ2, …, ŵT 
Predizione: 
ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#13,13,"Boosting 
xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizionef1(xi)
ŷi = sign[f 1(xi)]
Consideriamo un problema di apprendimento automatico per  
la classiﬁcazione: 
 
14"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#14,14," 
15Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#15,15," 
16Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#16,16," 
17Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#17,17," 
18Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
4     3 3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#18,18," 
19Credito Reddito yi
A 130K $ Sicuro
B 80K $ Rischioso
C 110K $ Rischioso
A 110K $ Sicuro
A 90K $ Sicuro
B 120K $ Sicuro
C 30K $ Rischioso
C 60K $ Rischioso
B 95K $ Sicuro
A 60K $ Sicuro
A 98K $ SicuroApprendimento di un 
Decision Stump 
≤100K$ >100K$Reddito
Sicuro4     3 3     1
Sicuro"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#19,19,"L’esempio precedente ci mostra che il decision stump non è 
riuscito a catturare adeguatamente le informazioni dal numero 
limitato di dati disponibili. 
 
20
Quello che fa il Boosting è considerare il decision stump, lo 
valuta, vede come classiﬁca i vari punti, e addestra un 
successivo decision stump (un successivo classiﬁcatore) con il 
quale si focalizza soprattutto sui punti dove il precedente 
classiﬁcatore era debole. Boosting: focus sugli “hard points” "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#2,2,"Boosting question 
 
3
Can a set of weak learners be combined to create a stronger learner? 
(Kearns e Valiant, 1988, 1989)
Sì!!  —>  Boosting  
(Schapire, 1990)
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#20,20," 
21xi
(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
Valutazione
Individuazione
punti critici
(2° classiﬁcatore)Apprendimentoyif1(xi)
… e così viaŷiBoosting:  focus sugli “hard points” 
l’algoritmo di apprendimento 
focalizza l’attenzione 
sui punti “critici”"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#21,21,"Apprendimento su Dati Pesati 
[weighted data]
L’idea è quella di dare maggiore attenzione ai data points 
ritenuti maggiormente importanti: 
•
 ogni data point (
 x
i
, y
i
) è pesato mediante un 
 α
i 
•
 più il punto è ritenuto importante, più è elevato il peso 
 α
i  
•
 l’algoritmo di apprendimento rimane lo stesso 
 
22"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#22,22," 
23Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Redditopeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#23,23," 
24Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9≤100K$ >100K$Reddito
2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#24,24," 
25Credito Reddito yi Peso α
A 130K $ Sicuro 0.5
B 80K $ Rischioso 1.5
C 110K $ Rischioso 1.2
A 110K $ Sicuro 0.8
A 90K $ Sicuro 0.6
B 120K $ Sicuro 0.7
C 30K $ Rischioso 3
C 60K $ Rischioso 2
B 95K $ Sicuro 0.8
A 60K $ Sicuro 0.7
A 98K $ Sicuro 0.9Rischioso≤100K$ >100K$Reddito
3     6.5 2     1.2
Sicuropeso α incrementato per i punti  
erroneamente classiﬁcati
Apprendimento su Dati Pesati 
[weighted data]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#25,25,"Apprendimento su Dati Pesati 
[weighted data]
Tale approccio comporta che: 
•
 Ogni punto i (
 x
i
, y
i
) conta come 
 α
i
 punti.  
•
 L’algoritmo di apprendimento rimane lo stesso. 
L’apprendimento su dati pesati non è solo relativo ai decision 
stumps. 
Esso si può applicare a molti algoritmi di Machine Learning  
•
 ad esempio, nel gradient ascent per la logistic regression: 
 
26w(t+1)
j w(t)
j+⌘·NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
↵i w(t+1)
j w(t)
j+⌘·NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#26,26,"Boosting   
Algoritmo Greedy per l’apprendimento di “ensemble” dai 
dati. 
Si avvale di weak learners usati come black box.  
Weak Learning Assumption
 : ciascun weak learner deve 
avere prestazioni migliori di un classiﬁcatore “random”. 
Nel Boosting i base classiﬁers sono addestrati in sequenza.  
Per migliorare le prestazioni di un weak learner, l’algoritmo 
deve poter manipolare i dati in ingresso, altrimenti si 
ottengono sempre gli stessi risultati 
 
27"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#27,27,"Boosting framework 
Step principali: 
 
28xi(N esempi)Dati di Training
(1° classiﬁcatore)Apprendimento
Predizione
(2° classiﬁcatore e ŵ)Apprendimentof1(xi)
… e così viaŷi = sign[f1(xi)]
ŷi = sign[ŵ1*f1(xi) + ŵ 2*f2(xi)]Individuazione
punti critici
e ricalcolo pesi
Predizioneŵ, f2(xi)weighted data
Idea del Boosting: aggiungere via via 
nuovi classiﬁcatori ottimizzando i pesi 
per focalizzarsi sui punti critici per poi 
apprendere i coefﬁcienti dei diversi 
classiﬁcatori. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#28,28,"AdaBoost 
[Adaptive Boosting]
Proposto da Yoav Freund e Robert E. Schapire nel 1996. 
I due autori hanno vinto il Gödel Prize nel 2003. 
Algoritmo estremamente utile e facile da implementare.  
 
29Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese Society 
for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. Riferimenti:
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in:  Thirteenth  
International Conference on Machine Learning , 1996, pp. 148-156. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#29,29,"AdaBoost 
[Adaptive Boosting]
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
(
minimizza funzione di costo
 ) 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
30ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#3,3,"Introduzione al Boosting 
Il Boosting è una potente tecnica per combinare molti 
classiﬁcatori “di base” (detti anche “weak learners”) per produrre 
una forma di comitato le cui prestazioni sono di gran lunga 
migliori di ciascuno dei classiﬁcatori. 
Originariamente progettato per risolvere problemi di 
classiﬁcazione, può anche essere esteso alla regressione 
(Friedman, 2001).  
 
4"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#30,30,"Evidenziamo qui il processo di training dei vari classiﬁcatori, basato su 
una forma pesata dei punti del training set (linee rosse). 
Ogni peso dipende dalle prestazioni del precedente classiﬁcatore (linee 
verdi)
 
31f1(x) fT(x){↵(1)
i} {↵(T)
i}
f2(x)······
······{↵(2)
i}
ˆy= sign[TX
t=1ˆwtft(x)]
Boosting framework "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#31,31,"Dobbiamo risolvere i seguenti due problemi: 
1. come calcolare il coefﬁciente 
 ŵ
t  
(qual è la mia 
“ﬁducia” in f
 t
(
x
) ?) 
2. come ricalcolare i pesi 
 α
i 
(individuare i punti “critici”) 
 
32
AdaBoost 
[Adaptive Boosting]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#32,32,"Il peso 
 ŵ
t
 rappresenta un “grado di ﬁducia” nella 
 f
t
. Pertanto:
 
33
1° problema: 
Calcolo del coefﬁciente 
 ŵ
t 
ft(x) buona?
ŵt elevato ŵt bassosi no
Una funzione è considerata “buona” se ha un basso training error 
Vediamo come misurare l’errore nel caso di dati “pesati” (“weighted 
classiﬁcation error”) "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#33,33,"Weighted Classiﬁcation Error 
La misura di un errore pesato è simile a quella di un errore calcolato 
su dati non pesati. 
 
34
Vediamo un semplice esempio: 
Data point i yi αi ŷi risultato
1 +1 1.2 +1
 👍
2 -1 0.5 +1
 👎
3 -1 0.7 -1
 👍
… … … …
peso previsioni corrette 1.9
peso previsioni errate 0.5"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#34,34,"Weighted Classiﬁcation Error 
Peso totale degli errori = 
 
35NX
i=1↵iI[ˆyi 6=yi]
NX
i=1↵i
 Peso totale di tutti i data points = 
L’errore “pesato” misura la frazione del peso degli errori: 
weighted error =peso totale degli errori
peso totale di tutti i data points=PN
i=1↵iI[ˆyi 6=yi]
PN
i=1↵i
Miglior valore: 0.0    Peggior valore: random classiﬁer "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#35,35,"Calcolo del coefﬁciente 
 ŵ
t 
[per il classiﬁcatore f
 t
(
x
)]
La formula usata in 
AdaBoost è la seguente:
 
36   
sui training dataŵt
0.01 (1 - 0.01)/0.01 = 99 +2.3
0.5 (1 - 0.5)/0.5 = 1 0
0.99 (1 - 0.99)/0.99 = 0.01 -2.31 weighted error (ft)
weighted error (ft)weighted error (ft)ˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘
Vediamo un esempio: 
ft(x) buona?si
no"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#36,36,"2° problema: Ricalcolo pesi alfa
Come sappiamo, dobbiamo focalizzarci soprattutto sui data point 
dove la funzione commette errori: 
 
37↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yift(xi) classiﬁca 
 bene xi?
decrementa αisi no
incrementa αi
"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#37,37,"2° problema: Ricalcolo pesi alfa 
Vediamo un esempio:
 
38↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yi
  ft(xi) = y i ? ŵtmoltiplicare α i per: implicazioni
SI (corretto) +2.3 0.1 diminuisci l’importanza del punto
SI (corretto) 0 1 mantieni la stessa importanza
NO (errore) +2.3 9.98 aumenta l’importanza del punto
NO (errore) 0 1 mantieni la stessa importanza"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#38,38,"Normalizzazione pesi alfa 
La normalizzazione dei pesi 
 α
i
 è suggerita dal fatto che:  
•
 se la funzione sbaglia spesso la classiﬁcazione di 
 x
i
, il peso 
 α
i 
tende ad assumere valori molto alti 
•
 se la funzione prevede spesso correttamente la classiﬁcazione 
di 
x
i
, il peso 
 α
i 
tende ad assumere valori molto bassi 
Tutto ciò può causare instabilità numerica dopo varie iterazioni. 
Si normalizza come segue in modo tale che, dopo ogni iterazione, 
la somma dei pesi 
 α
i
 risulti sempre uguale ad 1:
 
39↵i ↵iPN
j=1↵j"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#39,39,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
40ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#4,4,"Introduzione al Boosting 
Suo impatto per il Machine Learning: 
approccio di default per molti task di computer vision (e.g., 
face detection) 
numerose applicazioni nell’industria 
vince molte “ML competitions” (Kaggle, KDD Cup, ecc.): 
•   
malware classiﬁcation 
•
credit fraud detection 
•
sales forecasting 
•
Higgs boson detection, ecc., ecc.  
Si basa sul concetto di Ensamble Learning  
 
5"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#40,40,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
41ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#41,41,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
42ˆy= sign[TX
t=1ˆwtft(x)]ˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#42,42,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
43ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#43,43,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
44ˆy= sign[TX
t=1ˆwtft(x)]↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yi"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#44,44,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
45ˆy= sign[TX
t=1ˆwtft(x)]"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#45,45,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
46ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#46,46,"AdaBoost
for
 i = 1, 2, …, N: 
α
i 
= 1\N 
for
 t = 1, 2, … T: 
•
 apprendi f
 t
(
x
) con i pesi 
 α
i 
•
 calcola il coefﬁciente 
 ŵ
t  
•
 ricalcola i pesi 
 α
i 
•
 normalizza i pesi 
 α
i 
Calcola la predizione ﬁnale: 
 
47ˆy= sign[TX
t=1ˆwtft(x)]↵i ↵iPN
j=1↵j↵i ⇢↵i·e ˆwtseft(xi)=yi
↵i·eˆwt seft(xi)6=yiˆwt=1
2ln⇣
1 weighted error( ft)
weighted error( ft)⌘"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#47,47,"Riferimenti 
 
48Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese 
Society for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. 
Schapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in: 
Thirteenth  International Conference on Machine Learning , 1996, pp. 148-156. 
Friedman, J.H. “Greedy Function Approximation: A Gradient Boosting Machine”, in: 
Annals of Statistics , 29(5), 2001, pp. 1189-1232. Schapire, R.E.  “The Strength of Weak Learnability”, in: Machine Learning , 5(2), 1990, 
pp. 197–227.
Machine Learning: Classiﬁcation, University of Washington - Coursera, 2017."
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#5,5,"Weak Classiﬁers
L’idea è quella di partire da Simple (o Base o Weak) 
Classiﬁers, come ad es.:  
 
6SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente+
++++-
--
-+
+
Logistic Regression 
con semplici featuresShallow 
Decision TreeDecision Stump
Essi in genere sono caratterizzati da bassa varianza (scarso 
overﬁtting) ma alto bias. "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#6,6,"Andamento Errori  
e Bias-Variance Trade-off
 
7
L’andamento del training error e del true error per la classiﬁcation è in 
genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e variance.True Error
Training Error
Model ComplexityClassiﬁcation
Error
(Weak Learner)"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#7,7," 
8
Un approccio per migliorare un classiﬁcatore può essere quello di 
aggiungere più features al classiﬁcatore, ad es.: 
•
 logistic regression: polinomio di grado più elevato, cercando di 
evitare l’overﬁtting 
•
 decision trees: aumentare la profondità dell’albero 
Nel Boosting si fa qualcosa di diverso: si parte da un insieme di weak 
classiﬁers i cui risultati sono opportunamente combinati per ottenere 
uno strong classiﬁer.
Introduzione al Boosting "
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#8,8,"Ensemble Classiﬁer 
Alla base del Boosting c’è l’idea dell’Ensemble Classiﬁer, che 
ora vedremo. 
Consideriamo un weak classiﬁer, ad esempio un Decision 
Stump:  
 
9
Esso, a fronte del valore della feature d’interesse, restituisce 
un risultato (+1 o -1). SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Input: xi
Output: ŷ = f( xi)"
data_test\rootfolder\università\MachineLearning\16-Classification - BoostingAdaBoost-sbloccato.pdf#9,9,"Ensemble Classiﬁer 
L’idea è quella di considerare un certo numero di classiﬁcatori 
che, a fronte di un input, forniscono una loro previsione: 
 
101
SicuroReputazione
Rischioso SicuroScarsa EccellenteSufﬁciente
Rischioso3 anni 5 anniDurata
Sicuro Rischiosocattive buoneCondizioni di 
mercato
SicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)
2 3"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Classiﬁcazione:  
Overﬁtting e Regularization
Machine Learning "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#1,1,"Sommario
Introduzione 
Overﬁtting nella Classiﬁcazione 
Regolarizzazione 
L2 Penalty 
L1 Penalty (sparse solutions)
 
2"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#10,10,"Funzione di Qualità 
nel caso L
 2
 Penalty
 
11
Questo è il caso in cui usiamo la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L2 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.    
                                           Qualit` a totaleL2=l n L(w)  ·kwk2
2
<latexit sha1_base64=""3dst1017rZDOv7BwzXBseJyVJLg="">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#11,11," 
12Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞: 
0<kˆwk2
2<kˆwMLEk2
2
<latexit sha1_base64=""GbN8PXIxssjt4tSdrVsj583mbQM="">AAACT3icdVBNSyNBFOyJ3/Erq0cvjUHwFGaioAcP4rLgQUHBRCEThzedpzbp+aD7ja408+P2J+zRg2ev7mlv4kycg0YtaCiq6vFeV5gqach1H5zaxOTU9MzsXH1+YXFpufFjpWuSTAvsiEQl+iIEg0rG2CFJCi9SjRCFCs/D4c/SP79FbWQSn9F9iv0IrmN5JQVQIQWNnsv3uK+6qIn7YaIG1r8Bsnd5/iYGtp1fFu+7VGB9wt9kj49+jY/Ug0bTbbkj8M/Eq0iTVTgJGo/+IBFZhDEJBcb0PDelvgVNUijM635mMAUxhGvsFTSGCE3fjkrI+UZmgBKeouZS8ZGI7ycsRMbcR2GRjIBuzLhXil95vYyudvtWxmlGGItyEUmFo0VGaFm0i3wgNRJBeTlyGXMBGohQSw5CFGJW1F324Y3//jPptlveVqt9ut3cP6iamWVrbJ1tMo/tsH12yE5Yhwn2hz2xZ/bP+ev8d15qVbTmVGSVfUBt7hUB/7VE</latexit>
Funzione di Qualità 
nel caso L
 2
 Penalty"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#12,12," 
13Come già visto nel caso della Regressione, per la 
determinazione del parametro λ non usiamo mai il Test Set. Ci 
avvaliamo invece: 
del Validation Set , se abbiamo a disposizione un 
numero sufﬁcientemente elevato di osservazioni; 
della Cross-Validation , se abbiamo a disposizione un 
numero limitato di osservazioni. 
Scelta del Parametro di Tuning 
 λ"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#13,13,"Bias-Variance Tradeoff
 
14
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., maximum likelihood (MLE) 
ﬁt per polinomi di grado elevato per λ = 0) Il parametro λ controlla la complessità del modello: "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#14,14,"L
2
 Regularization 
Esempio
 
15
Vediamo l’effetto della L 2 regularization nel caso visto in 
precedenza (caso con 20 features):
Regularization:
Range coefﬁcienti: 
Decision boundary:"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#15,15,"Gradient Ascent 
con la L
 2
 Regularization 
 
16
Come è noto, nell’algoritmo Gradient Ascent dobbiamo 
aggiornare il vettore dei pesi w come segue:
w(t+1) w(t)+↵·rQualit` a totaleL2(w(t))
<latexit sha1_base64=""TzTwdt9I3sAyHV9gN7z7vrC1WrU="">AAAC0nicfVFNb9NAEB2bj5bw0QBHLisipFaVIjtUKscKOHDg0EpNWykJ0XgzaZeuvdbuGChWDogrf5BDpf4Uxk4O0AJjaefNvDc7452stCZwkvyM4lu379xdW7/Xuf/g4aON7uMnR8FVXtNQO+v8SYaBrCloyIYtnZSeMM8sHWfnbxr++BP5YFxxyBclTXI8LczcaGRJua6DMWTgwMIMavgMC/ggfhMYtiGFLYmVKCwQzCWH4OVzolP/rFvWbLcKFL6EM/FNpEXrRNHgQnKZsEuG5f4vctZwAFVbZSS6EmYq3rWdmxkWEtfwXs6B4M3/zrAFHehMu72kn7SmboJ0BXqwsv1p93I8c7rKqWBtMYRRmpQ8qdGz0ZYWnXEVqER9jqc0ElhgTmFSt3tYqBdVQHaqJK+MVW2Sfq+oMQ/hIs9EmSOfhetck/wbN6p4/mpSm6KsmArdNGJjqW0UtDeyYFIz44kZm8lJmUJp9MhM3ijUWpKVbLx5j/T6398ER4N++rI/ONjp7b1evcw6PIPn8rYp7MIevIN9GIKO3kYfoxBxfBh/jb/F35fSOFrVPIU/LP7xC+iqucA=</latexit>
Dobbiamo dunque calcolare il gradiente della funzione di 
qualità totale ( L2 regularized log-likelihood ):
Qualit` a totaleL2=l n L(w)  ·kwk2
2
<latexit sha1_base64=""3dst1017rZDOv7BwzXBseJyVJLg="">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#16,16,"Gradient Ascent 
con la L
 2
 Regularization 
 
17
Nell’algoritmo l’aggiornamento dei pesi possiamo farlo per 
ogni componente w j:
w(t+1)
0 w(t)
0+↵·@Qualit` a totaleL2(w(t))
@w0
w(t+1)
1 w(t)
1+↵·@Qualit` a totaleL2(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j+↵·@Qualit` a totaleL2(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D+↵·@Qualit` a totaleL2(w(t))
@wD
<latexit sha1_base64=""DNhBsTO/Fo42FgAscBocdQBJt+Y="">AAAHvXic3VVLb9NAEJ4GiEt4pXDksiKiKlRK7XCAGxXkwIFDK5G2Up1G680k3dQvvGtCZOWHckDiwA9hdm1BmxQkokpFbGTvvL7sN/NJ3iANpdKu+2WtduPmrbqzfrtx5+69+w+aGw8PVJJnAnsiCZPsKOAKQxljT0sd4lGaIY+CEA+Ds7cmf/gJMyWT+IOepdiP+DiWIym4plCyUfsODfAhAIQxSIihIOsj7Rwy+nGYwXOYU80UBpRzyT6hfQs0bIMHz8hnsEmPDyEhRxQvkQkhyswyskRtWxQnXAqntBtPwJCQmmxmeY0sB0E4n6rMP2tiaTAmounEz/QuYB9yG5XkfaPMgPbEcjGs5pbBe3p3yN6y/SaUGVJ0usDLPKbfy0781cncdsAsZ7+ySs5ljbfynLy/ntOfpsSucU7ezzmZGTXOsVYXelC2/82l2KJ/FV7JpOQ3WVmjyZVqdH0KTf5xhborK9T9TxTqVgoZbZC+ysPffp8bg2bLbbt2sWXDq4wWVGtv0PzqDxORRxhrEXKljj031f2CZ1qKEOcNP1eYcnHGx3hMZswjVP3CXjlz9jRXXCcsxYzJkNkgnkcUPFJqFgVUGXF9qhZzJnhZ7jjXo1f9QsZprjEW5iAtQ7QHKZFJusuQDWWGWnPDHJmMmeAZ1xozybgQFMzpcjPz8Ba7XzYOOm3vRbuz32ntvqkmsw6P4Qlp5MFL2IV3sAc9EPWdeq9+Uh84rx10QicuS2trFeYRXFjO9AeM558S</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#17,17,"Gradient Ascent 
con la L
 2
 Regularization 
 
18
La derivata parziale della funzione di qualità totale rispetto al 
termine generico w j è la seguente:
Componente MLE Componente L 2 Penalty@Qualit` a totaleL2(w(t))
@wj= derivata parziale[ j] 2 w(t)
j
<latexit sha1_base64=""qwKQWDz8o+RHfQa5roWAERrRYkA="">AAAC/HicbVI7b9RAEB47PMLxOkJJs+KEFApO9gUJGqQIGgqKROKSSHfmtF7PhU3WD+2OE4J1VPwEWqjoorT8FwokfgqzjosjyUqz8+033zy83rQy2lEU/Q7ClWvXb9xcvdW7fefuvfv9B2s7rqytwrEqTWn3UunQ6ALHpMngXmVR5qnB3fTwjY/vHqF1uize00mFSS73Cz3XShJTZf8r9GAKc7AgQUHDuGJkgUCzNy1DgPCJ9wa2oW5Zzae/HJmxL9k8h7DgcwPveB8xXud4ylEDGbPHzHxgv87qp4y9LUBc2fG4rXPQKrzmFdvyFBkjy+oj1vvefo7zGp+7Gn6WCVdIOPMZ24g1hiM5T5SxF22Pg+WJZv1BNIzaJS6DuAMD6NbWrP9nmpWqzrEgZaRzkziqKGmkJa0MLnrT2mEl1aHcxwnDQubokqb9YwvxpHaSSlGhFdqIlsTljEbmzp3kKStzSR/dxZgnr4pNapq/TBpdVDVhoXwj0gbbRk5ZzU8BRaYtEkk/OQpdCCWtJEKrhVSKyZrfRo/vI7749ZfBzmgYbwxH288Hm6+7m1mFR/CYbzWGF7AJb2ELxqCCIvgWfA9+hF/Cn+FpeHYuDYMu5yH8t8Jf/wA0VMWQ</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#18,18,"Gradient Ascent 
con la L
 2
 Regularization 
 
19
Questa è la versione dell’algoritmo:
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrQualit` a totaleL2(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1 j(xi){I[yi= +1] P(y=+ 1 |xi,w(t))}
w(t+1)
j w(t)
j+↵⇤(derivata parziale[ j] 2 w(t)
j)
t t+1
<latexit sha1_base64=""2zh0FCvD+/2VMpyTakbuiEO167M="">AAAGWXicnVTLbhMxFL0taSjl1dIlmxEVqC+iTBCCTVEFLEBCqJXoQ8qEyHGc1O28NPa0TUO+kC9ACIlfYAsbjh0zbdoGKsayfX1f5/rY41YaSqWr1S8Tk9dKU+Xr0zdmbt66fefu7Ny9bZXkGRdbPAmTbLfFlAhlLLa01KHYTTPBolYodloHr4x951BkSibxB91LRSNi3Vh2JGcaqmRuskYBtUhQlyTF1CdGIaQu5GUa0Aw9svYE2jasR9B9xLxIPi1B9mgNvYoe2K6R6Rij8UgoRcspg85DfILRYEg6QR/inDg5Kqyeldt2zWFRyGB8hcMLLJKpywPOEN93+ovV7iGniR0UFYa0jXVmYwPgMfiHGEer33SoEqvvsDQxJ+jMZWvC5x3Gms28OIYjbWteGkE1kbWinhd2FuBJ2UoTy8DpXvagT4HK4dMHzxV6Cjly8aeYHUjZmV16tF+czaplyIwV24z0+i8o/hmEU0batn5Jh/AzPBhOTExWnKbhpQ7chkM28eb0IrtnCZ3vmHmPOUC0OR1j28d6lMNjx7G0/JlMfXqL7L1Cu0YryGewHqNvIL7ndJ/GZlr95zkNrsDKUVHzn+iV4m8ILA8dy1CGlsD7soih94qNMNwZLpjlbNndp/9l3rBRc5WY/6qFeDa2hqUr3jU9dm/a7cNHFnOTY8vtuVekObtQrVTt510UfCcskPs2mrPfgnbC80jEmodMqbpfTXWjzzIteSgGM0GuRMr4AeuKOsSYRUI1+vY5HHgPc8V04qUi82ToWaU4G9FnkVK9qAXPiOk9dd5mlJfZ6rnuPG/0ZZzmWsTcAGkZCgukeCbxzgqvLTOhNTOVC0/GHmcZ01pk0mOcQ5nj4TV8+Od3f1HYrlX8J5XaZm1h/aVjZpru0wP7+j6jdXqDe79FvPS59KP0s/Rr6mt5ojxdnhm6Tk64mHka+crzvwEKslZZ</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#19,19,"Funzione di Qualità 
nel caso L
 1
 Penalty
 
20
Questo è il caso in cui usiamo la somma dei valori assoluti 
per la penalty ( L1 Regularization ). E’ in genere chiamata 
“sparse logistic regression ”. 
La funzione che rappresenta la qualità totale nel caso della 
logistic regression ( L1 regularized logistic regression ) è la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i 
due termini.                                              Qualit` a totaleL1=l n L(w)  ·kwk1
<latexit sha1_base64=""kVQvjmORbVIpZXR5YRGRGxnE/j0="">AAACzHicbVFNb9QwEJ2Ej5bla4EjF4sVEhxYJS1SuYAquHBAqJXYbaXd1cpxpq1V24nsCVBFufIfOSDxUxinOWxbRrI98948z9hT1EYHyrLfSXrr9p27W9v3RvcfPHz0ePzk6TxUjVc4U5Wp/HEhAxrtcEaaDB7XHqUtDB4V558if/QdfdCV+0YXNa6sPHX6RCtJDFVjA0sgQPjJewuH0IAEA5qjv8ys+ax4RQyh47iFL7zn7At4z2tTbcD1eEQtawjOQPXaqOrgFeMF32egZOQHI6/77De9wnCmZb7kM8aKvVj7kptzFT9EV+/YZGN/sbcRjNbjSTbNehM3nXxwJjDYwXr8Z1lWqrHoSBkZwiLPalq10pNWBrvRsglYS3UuT3HBrpMWw6rtJ9CJl02QVIkavdBG9CBuKlppQ7iwBWdaSWfhOhfB/3GLhk7erVrt6obQqViItMG+UFBe82hRlNojkYydo9BOKOklEXotpFIMNjzr+B/59dffdOY703x3unP4drL/cfiZbXgOL3h2OezBPnyGA5iBSj4kZWITl35NKW3T7jI1TQbNM7hi6a9/TBq4og==</latexit>"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#2,2,"Metriche di Qualità 
[quality metric]
 
3Errore =#previsioni errate
#esempi
Una metrica che si usa misura la frazione delle previsioni errate 
fornite:
miglior valore possibile: 0.0
Accuracy =#previsioni corrette
#esempi
<latexit sha1_base64=""NDG+msvJ/lTBIqDvf5G5eA2dVhE="">AAACPXicbVA9TxtBEN0jBIiTEBPKNCusSKmsO4JEGiRIGtIRCQOSz7LmhjEZsfeh3TmEdbrfxE/Ir0hBAanoEG1a9oyF+HrV03vzdnZeUhh2Eobnwcyr2ddz8wtvWm/fvV/80F76uOfy0iL1MDe5PUjAkeGMesJi6KCwBGliaD85/tH4+ydkHefZrowLGqRwlPGIEcRLw/bPWOhUqi3E0gKOa72h45FnVdy5c/xrJ9zEOR5ibi2JUF3f2+QoLbiuW61huxN2wwn0cxJNSUdNsTNsX8SHOZYpZYIGnOtHYSGDCqwwGqpbcemoADyGI+p7mkFKblBNTq7159KB5Logq9noiUgPExWkzo3TxE+mIL/dU68RX/L6pYy+DSrOilIow2aRsKHJIoeWfZekD7mpAZqfk+ZMI1jwtVjWgOjF0pfb9BE9vf452VvtRl+7q7/WOpvfp80sqE9qRX1RkVpXm2pb7aieQnWm/qpL9S/4E1wF18HN3ehMMM0sq0cI/t8C0Zew6Q==</latexit>
Un’altra metrica possibile misura la frazione delle previsioni 
corrette:
miglior valore possibile: 1.0"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#20,20," 
21Anche in questo caso vediamo cosa accade a fronte di diversi valori 
del parametro λ: 
Se λ = 0: 
ci riconduciamo alla soluzione standard, ossia massimizzazione 
del likelihood( w) → ŵMLE 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → - ∞ 
l’unica soluzione per massimizzare la qualità è: ŵ = 0 
Se 0 < λ < ∞:  
si va verso soluzioni “sparse”, in cui vari w j sono uguali a zero.
Funzione di Qualità 
nel caso L
 1
 Penalty"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#21,21,"Pesi nella regolarizzazione 
 
22
Nelle ﬁgure seguenti riportiamo un esempio di andamento 
dei pesi w j al variare di 𝜆 per i due tipi di penalty:
L2 Penalty
 L1 Penaltyλ λ "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#22,22,"Riferimenti
 
23
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#3,3," 
4
Overﬁtting 
Apprendimento della Decision Boundary 
j 𝜱j wj
0 1 0.23
1 x{1} 1.12
2 x{2} -1.07
x[1] x[1]x[2] x[2]
Data Points dell’esempio Decision Boundary:
0.23 + 1.12 x[1] - 1.07 x[2] = 0Score( x) < 0 Score( x) > 0"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#4,4," 
5
j 𝜱j wj
0 1 1.68
1 x{1} 1.39
2 x{2} -0.59
3 x{1}^2 -0.17
4 x{2}^2 -0.96
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
1.68 + 1.39 x[1] - 0.59 x[2] - 0.17 x[1]^2  - 0.96 x[2]^2 = 0Score( x) < 0 Score( x) > 0
Decision Boundary:"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#5,5," 
6
j 𝜱j wj
0 1 21.6
1 x{1} 5.3
2 x{2} -42.7
3 x{1}^2 -15.9
4 x{2}^2 -48.6
5 x{1}^3 -11.0
6 x{2}^3 67.0
… … …
11 x[1]^6 0.8
12 x[2]^6 -8.6
x[2]
x[1] x[1]x[2]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
I valori assoluti di vari coefﬁcienti 
wj sono aumentati(chiaro overﬁtting)Decision Boundary"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#6,6," 
7
x[2]
x[1]x[2]
x[1]
Data Points dell’esempio
Overﬁtting 
Apprendimento della Decision Boundary 
Score( x) < 0 Score( x) > 0
(overﬁtting ancora più evidente)j 𝜱j wj
0 1 8.7
1 x{1} 5.1
2 x{2} 78.7
… … …
11 x{1}^6 -7.5
12 x{2}^6 3803
13 x{1}^7 21.1
14 x{2}^7 -2406
… … …
39 x[1]^20 -2*10^-8
40 x[2]^20 0.03
I valori assoluti di vari coefﬁcienti 
wj sono aumentati ancora di piùDecision Boundary"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#7,7,"Andamento Errori  
e Bias-Variance Trade-off
 
8
L’andamento del training error e del true error per la 
classiﬁcation è in genere il seguente:
Dobbiamo come al solito considerare il trade-off tra bias e varianza.True Error
Training Error
Model ComplexityClassiﬁcation
Error
Dato un modello con parametri ŵ, si ha overﬁtting 
se esiste un modello con i parametri stimati w’ tale 
che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
ŵ w’
"
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#8,8,"Regularization 
nella Classiﬁcazione
 
9
L’idea è quella di limitare il valore assoluto dei coefﬁcienti w i 
deﬁnendo come segue la funzione di qualità totale (da 
massimizzare nella fase di training): 
Qualità_totale  = misura del “ﬁt” - misura grandezza coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la MLE. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. "
data_test\rootfolder\università\MachineLearning\17-Classification - Overfitting e Regularization-sbloccato.pdf#9,9,"Misura dei Coefﬁcienti 
 
10
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Regressione e Classiﬁcazione (Ex04)
1"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#1,1,"Sommario
Esercizi su Linear models per la classiﬁcazione"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#10,10,"LinearLogistic: Breast cancer dataset
Esercizio
 : visualizza i parametri del modello. Cosa ti aspetti? 
plt
.
plot
(
logreg
.
coef_
.
T
, 
'o'
, 
label
=
""C=1""
)
plt
.
plot
(
logreg100
 .
coef_
.
T
, 
'^'
, 
label
=
""C=100""
)
plt
.
plot
(
logreg001
 .
coef_
.
T
, 
'v'
, 
label
=
""C=0.001""
 )
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
ylim
(
-
5
, 
5
)
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
legend
()
11"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#11,11,"LinearLogistic: Breast cancer dataset
Regolarizzazioni alte spingono i parametri a 0.  
In alcuni casi (
 mean perimeter
 ), per C=100 e C=1 il coefﬁciente è negativo, 
positivo per C=0.001.  
12
Attenzione: 
 È sbagliato 
pensare che i parametri 
suggeriscano quali features 
determinino direttamente la 
classe (tumore maligno o 
meno). L'importanza della 
feature dipende strettamente 
dal modello preso in 
considerazione."
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#12,12,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature 
impiegando la L1 regularization. 
13"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#13,13,"LinearLogistic: Breast cancer dataset
Esercizio
 : cerca di interpretare meglio l'importanza delle feature impiegando la L1 
regularization. 
for 
C
, 
marker 
in 
zip
([
0.001
, 
1
, 
100
], [
'o'
, 
'^'
, 
'v'
]):
lr_l1 
= 
LogisticRegression
 (
C
=
C
, 
penalty
=
""l1""
)
.
fit
(
X_train
, 
y_train
)
print
(
""Training accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_train
, 
y_train
)))
print
(
""Test accuracy of l1 logreg with C={:.3f}: {:.2f}""
 .
format
(
C
, 
lr_l1
.
score
(
X_test
, 
y_test
)))
plt
.
plot
(
lr_l1
.
coef_
.
T
, 
marker
, 
label
=
""C={:.3f}""
 .
format
(
C
))
plt
.
xticks
(
range
(
cancer
.
data
.
shape
[
1
]), 
cancer
.
feature_names
 , 
rotation
 =
90
)
plt
.
hlines
(
0
, 
0
, 
cancer
.
data
.
shape
[
1
])
plt
.
xlabel
(
""Coefficient index""
 )
plt
.
ylabel
(
""Coefficient magnitude""
 )
plt
.
ylim
(
-
5
, 
5
)
plt
.
legend
(
loc
=
3
)
> Training accuracy of l1 logreg with C=0.001: 0.91
> Test accuracy of l1 logreg with C=0.001: 0.92
> Training accuracy of l1 logreg with C=1.000: 0.96
> Test accuracy of l1 logreg with C=1.000: 0.96
> Training accuracy of l1 logreg with C=100.000: 0.99
> Test accuracy of l1 logreg with C=100.000: 0.98
14"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#14,14,"LinearLogistic: Breast cancer dataset
L'effetto della L1 regularization dipende dal valore del parametro, in modo 
simile al caso della regressione. 
15
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#15,15,"Linear models per la classiﬁcazione multiclass
Alcuni modelli non si adattano facilmente al caso multiclass.  
Un approccio piuttosto semplice è il
  one-vs-rest:
  si creano vari modelli, 
dove ogni modello si addestra a riconoscere una speciﬁca classe. Durante 
la predizione vengono valutati tutti i modelli e quello con score più alto 
determina la classe in output. 
Chiaramente si avranno un insieme di parametri da addestrare per ogni 
classe. 
16"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#16,16,"Linear models per la classiﬁcazione multiclass
Esempio
 : creiamo un dataset con 2 features e 3 classi e impieghiamo il 
Linear SVM per la classiﬁcazione. Il dataset è creato seguendo una 
distribuzione gaussiana. 
from 
sklearn.datasets 
 import 
make_blobs
X
, 
y 
= 
make_blobs
 (
random_state
 =
42
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
""Class 0""
 , 
""Class 1""
 , 
""Class 2""
 ])
17
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#17,17,"Linear models per la classiﬁcazione multiclass
linear_svm 
 = 
LinearSVC
 ()
.
fit
(
X
, 
y
)
print
(
""Coefficient shape: ""
 , 
linear_svm
 .
coef_
.
shape
)
print
(
""Intercept shape: ""
 , 
linear_svm
 .
intercept_
 .
shape
)
> Coefficient shape: (3, 2)
>Intercept shape: (3,)
Ogni riga di 
 _coef
  rappresenta il vettore dei parametri per una delle 3 
classi, e le colonne sono le 2 features. 
 intercept_
  è un array 1d che 
memorizza l'intercetta per ogni classe. 
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
[
'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
ylim
(
-
10
, 
15
)
plt
.
xlim
(
-
10
, 
8
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
18"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#18,18,"Linear models per la classiﬁcazione multiclass
Ogni istanza etichettata con la classe 0 è al di sopra della 
 boundary  
deﬁnita dal classiﬁcatore per la class 0. Le istanze delle altre classi al di 
sotto. Stessa cosa per la classe 1 e 2, e i relativi classiﬁcatori. 
Cosa succede se una istanza si trova nel triangolo centrale? 
19
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#19,19,"Linear models per la classiﬁcazione multiclass
Cosa succede se una istanza si trova nel triangolo centrale? 
La classe associata corrisponde alla linea più vicina. 
20
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#2,2,"Richiami: Linear models per la classiﬁcazione
I modelli lineari possono essere impiegati per la classiﬁcazione con 
decision boundary
  che rappresento linee, piani o iperpiani.  
Nella logisitic regression si impiega un modello lineare tradizionale il cui 
output è valutato da una funzione 
 logistic
  (s
igmoid function
 ) che restituisce 
un valore in [0,1] ed indica la probabilità di appartenenza ad una certa 
classe (> 0.5) o meno (< 0.5). 
Il 
gradient descent
  è impiegato per minimizzare la funzione di costo. 
I due algoritmi di classiﬁcazione lineari più famosi sono la 
 logistic 
regression
 , e i 
linear support vector machine
  (o Linear SVM) che vedremo 
in seguito. 
Scikit-learn fornisce la classe 
 linear_model.LogisticRegression
  e 
svm.LinearSVC
  che implementa i due algoritmi.
3"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#20,20,"Linear models per la classiﬁcazione multiclass
Il seguente codice mostra le regioni associate alle predizioni 
mglearn
.
plots
.
plot_2d_classification
 (
linear_svm
 , 
X
, 
fill
=
True
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
)
line 
= 
np
.
linspace
 (
-
15
, 
15
)
for 
coef
, 
intercept
 , 
color 
in 
zip
(
linear_svm
 .
coef_
, 
linear_svm
 .
intercept_
 ,
                            [
 'b'
, 
'r'
, 
'g'
]):
plt
.
plot
(
line
, 
-
(
line 
* 
coef
[
0
] 
+ 
intercept
 ) 
/ 
coef
[
1
], 
c
=
color
)
plt
.
legend
([
'Class 0'
 , 
'Class 1'
 , 
'Class 2'
 , 
'Line class 0'
 , 
'Line class 1'
 ,
      
'Line class 2'
 ], 
loc
=
(
1.01
, 
0.3
))
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#21,21,"Linear models per la classiﬁcazione multiclass
22
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#22,22,"Considerazioni sul tuning
Gli iperparametri C e 
 λ
 sono solitamente campionati su scala logaritmica. 
Se si assume che il dataset contenga solo alcune feature rilevanti si può 
testare la L1 regularization, altrimenti si tende a preferire la L2.  
La L1 regularization è utile anche per dare una interpretazione del modello.   
I modelli lineari sono veloci da addestrare, anche su dati sparsi. 
Per dataset con >100.000 istanze si può impiegare il parametro 
 solver='sag'  
nella LogisticRegression e Ridge, che rende l'apprendimento più veloce. 
Altre opzioni sono SGDClassiﬁer e SGDRegressor che implementano 
versioni più scalabili dei relativi algoritmi. 
I parametri possono indicare quali feature siano più rilevanti, nei casi in cui 
le feature sono indipendenti tra loro. 
I modelli lineari hanno buone performance quando il numero di features è 
grande rispetto al numero di istanze. Sono impiegati anche su grandi dataset 
perché spesso gli altri modelli non sono facilmente addestrabili.
23"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#3,3,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
...
4"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#4,4,"Linear models per la classiﬁcazione: forge dataset
Esercizio
 : impiega il forge dataset e la LogisticRegression per la 
classiﬁcazione. Valuta le performance. 
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
LinearSVC
X
, 
y 
= 
mglearn
.
datasets
 .
make_forge
 ()
fig
, 
axes 
= 
plt
.
subplots
 (
1
, 
2
, 
figsize
=
(
10
, 
3
))
for 
model, 
ax 
in 
zip
([
LinearSVC
 (), 
LogisticRegression
 ()], 
axes
):
clf 
= 
model
.
fit
(
X
, 
y
)
mglearn
.
plots
.
plot_2d_separator
 (
clf
, 
X
, 
fill
=
False
, 
eps
=
0.5
,
ax
=
ax
, 
alpha
=.
7
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
y
, 
ax
=
ax
)
ax
.
set_title
 (
""{}""
.
format
(
clf
.
__class__
 .
__name__
 ))
ax
.
set_xlabel
 (
""Feature 0""
 )
ax
.
set_ylabel
 (
""Feature 1""
 )
axes
[
0
]
.
legend
()
Nota: 
 Impieghiamo entrambe le implementazioni, anche se l'algoritmo SVM 
lo vedremo in dettaglio in seguito. 
5"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#5,5,"Linear models per la classiﬁcazione: forge dataset
In questo dataset la decision boundary è rappresentata da una retta. 
6
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#6,6,"Scikit-learn: Logistic regression
In Scikit-learn, la Logistic regression impiega la 
 L2
 di default. 
Il parametro 
 penalty
  speciﬁca quale regolarizzazione impiegare {‘l1’, ‘l2’, 
‘elasticnet’, ‘none’}.  
Il parametro 
 C
 indica il peso della regolarizzazione (valori bassi 
rappresentano una regolarizzazione maggiore), il default è C=1.0  
7"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#7,7,"Richiami: Linear models per la classiﬁcazione
Al variare di 
 C
 si può notare l'effetto sul dataset considerato. 
Con alta regolarizzazione (C basso) il modello sbaglia a classiﬁcare 2 
istanze cercando di considerare la ""maggioranza"" durante la scelta della 
decision boundary. 
Per valori più alti di C la retta si inclina dando più importanza ai 2 punti. 
Un punto rimane comunque non classiﬁcato, ed è impossibile considerarlo 
con una semplice linea retta. 
8
"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#8,8,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la 
 linera logistic 
 nel caso del Breast cancer dataset, 
considerando valori di C pari a 0.01, 1 e 100. Commenta i risultati ottenuti 
in termini di accuracy e potenziali fenomeni di over o underﬁtting.
9"
data_test\rootfolder\università\MachineLearning\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#9,9,"LinearLogistic: Breast cancer dataset
Esercizio
 : valuta la linera logistic nel caso del Breast cancer dataset, 
considerando valori di C pari a 1, 100 e 0.01. 
from 
sklearn.datasets 
 import 
load_breast_cancer
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
logreg 
= 
LogisticRegression
 (C=1)
.
fit
(
X_train
, 
y_train
)
print
(
""Training set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_train
, 
y_train
)))
print
(
""Test set score: {:.3f}""
 .
format
(
logreg
.
score
(
X_test
, 
y_test
)))
Training set score: 0.953
Test set score: 0.958
Training set score: 0.972
Test set score: 0.965
Training set score: 0.934
Test set score: 0.930
Per C=1 c'è un probabile underﬁtting. Per C=100 (modello più complesso) 
migliorano le performance. Per C=0.01 si incrementa l'underﬁtting iniziale.
10"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Decision Trees (Ex05)
1"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#1,1,"Sommario
Richiami 
scikit-learn e decision trees 
Visualizzazione 
Feature importance 
Decision trees e regressione 
Pruning"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#10,10,"scikit-learn e decision trees
tree 
= 
DecisionTreeClassifier
 (
max_depth
 =
4
, 
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 0.988
> Accuracy on test set: 0.951
Più bassa sul training, ma migliora (meno overﬁtting) sul test.
11"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#11,11,"scikit-learn: visualizzare i decision trees
La funzione 
 export_graphviz
  del modulo 
 tree
 permette di visualizzare 
l'albero. Salva un ﬁle .dot che può essere importato per la visualizzazione. 
from 
sklearn.tree 
 import 
export_graphviz
export_graphviz
 (
tree
, 
out_file
 =
""tree.dot""
 , 
class_names
 =
[
""malignant""
 , 
""benign""
 ], 
feature_names
 =
cancer
.
feature_names
 , 
impurity
 =
False
, 
filled
=
True
)
import 
graphviz
with 
open
(
""tree.dot""
 ) 
as 
f
:
dot_graph 
 = 
f
.
read
()
graphviz
 .
Source
(
dot_graph
 )
Visualizzare il ""comportamento"" di un algoritmo di ML è molto utile per 
spiegarne l'output (
 explaination
 ), in questo caso anche ai non-esperti.
12"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#12,12,"scikit-learn: visualizzare i decision trees
L'albero generato:
13
samples  indica il numero di 
istanze, value  la rispettiva 
suddivisione in base alle label, 
class  la classe majoriy."
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#13,13,"scikit-learn: visualizzare i decision trees
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile feature_importances_ del modello è un array con valori in [0,1] 
dove 1 indica ""predice perfettamente in valore target"". 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
14"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#14,14,"Decision trees e feature importance
Un altro modo per esplorare i decision trees è assegnare una misura di 
importanza
  alle feature in base al funzionamento dell'algoritmo. 
La variabile 
 feature_importances_
  del modello è un array con valori in 
[0,1] dove 1 indica ""predice perfettamente in valore target"". È valutata 
mediante la metrica GINI. 
print
(
""Feature importances:\n{}""
 .
format
(
tree
.
feature_importances_
 ))
Out[62]:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01
0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046
0. 0. 0.014 0. 0.018 0.122 0.012 0. ]
def 
plot_feature_importances_cancer
 (
model
):
n_features 
 = 
cancer
.
data
.
shape
[
1
]
plt
.
barh
(
range
(
n_features
 ), 
model
.
feature_importances_
 , 
align
=
'center'
 )
plt
.
yticks
(
np
.
arange
(
n_features
 ), 
cancer
.
feature_names
 )
plt
.
xlabel
(
""Feature importance""
 )
plt
.
ylabel
(
""Feature""
 )
plot_feature_importances_cancer
 (
tree
)
15"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#15,15,"Decision trees e feature importance
Si può notare come worst radius è la feature più discriminante. Questo 
indica anche che l'albero è ben costruito avendo questa feature in cima. 
Puoi dire che una 
 feature
  con bassa importance è poco discriminante?
16
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#16,16,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
Esercizio: 
 In questo esempio come costruiresti l'albero di decisione?
17
X[0]X[1]"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#17,17,"Esempio: feature importance
tree 
= 
mglearn
.
plots
.
plot_tree_not_monotone
 ()
display
(
tree
)
In questo esempio, l'informazione rilevante è contenuta in X[1]. Infatti non 
possiamo dire che un valore alto per la feature X[0] identiﬁca la classe 0, e 
uno basso la classe 1. L'albero effettivamente impiega la feature corretta.
18
X[0]X[1]"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#18,18,"scikit-learn: decision tree per la regressione
La classe DecisionTreeRegressor impiega lo stesso algoritmo in ambito di 
regressione 
import 
pandas 
as 
pd
ram_prices 
 = 
pd
.
read_csv
 (
""data/ram_price.csv""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
ram_prices
 .
price
)
plt
.
xlabel
(
""Year""
)
plt
.
ylabel
(
""Price in $/Mbyte""
 )
19
https://github.com/amueller/introduction_to_ml_with_python/blob/master/data/ram_price.csvSu scala logaritmica per le y si può 
ipotizzare una relazione lineare"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#19,19,"scikit-learn: decision tree per la regressione
Confrontiamo i decision trees con un modelli lineare, con l'accortezza di 
convertire i dati in valori logaritmo altrimenti il modello lineare non può 
funzionare. 
from 
sklearn.tree 
 import 
DecisionTreeRegressor
# use historical data to forecast prices after the year 2000
data_train 
 = 
ram_prices
 [
ram_prices
 .
date 
< 
2000
]
data_test 
 = 
ram_prices
 [
ram_prices
 .
date 
>= 
2000
]
# predict prices based on date
X_train 
 = 
data_train
 .
date
[:, 
np
.
newaxis
]
# we use a log-transform to get a simpler relationship of data to target
y_train 
 = 
np
.
log
(
data_train
 .
price
)
tree 
= 
DecisionTreeRegressor
 ()
.
fit
(
X_train
, 
y_train
)
linear_reg 
 = 
LinearRegression
 ()
.
fit
(
X_train
, 
y_train
)
# predict on all data
X_all 
= 
ram_prices
 .
date
[:, 
np
.
newaxis
]
pred_tree 
 = 
tree
.
predict
(
X_all
)
pred_lr 
 = 
linear_reg
 .
predict
(
X_all
)
# undo log-transform
price_tree 
 = 
np
.
exp
(
pred_tree
 )
price_lr 
 = 
np
.
exp
(
pred_lr
)
Cosa ti aspetti?
20"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#2,2,"Richiami: Decision Trees
Impiegati spesso per la classiﬁcazione e regressione.  
In sintesi creano una albero di nodi if/else che porta ad una certa 
decisione.  
Si può rappresentare come un albero dove le foglie contengono la risposta.
3
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#20,20,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Ma che succede dopo l'ultima data presente nel dataset?
21
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#21,21,"scikit-learn: decision tree per la regressione
plt
.
semilogy
 (
data_train
 .
date
, 
data_train
 .
price
, 
label
=
""Training data""
 )
plt
.
semilogy
 (
data_test
 .
date
, 
data_test
 .
price
, 
label
=
""Test data""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_tree
 , 
label
=
""Tree prediction""
 )
plt
.
semilogy
 (
ram_prices
 .
date
, 
price_lr
 , 
label
=
""Linear prediction""
 )
plt
.
legend
()
Il modello lineare approssima con una retta. Il decision tree è molto più 
accurato nella predizione. 
Attenzione: 
 L'algoritmo decision tree non è in grado di fare predizioni su 
nuovi dati con la data oltre a quella contenuta nel dataset. 
22
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#22,22,"scikit-learn: decision tree e pruning
Per limitare l'overﬁtting e la complessità, solitamente è sufﬁciente 
impiegare una tecnica di pre-pruning con uno dei seguenti parametri: 
max_depth
 , 
max_leaf_nodes
 ,  o.  
min_samples_leaf
Nota: 
 min_samples_leaf indica il minimo numero di istanze per foglia. 
Esercizio
 : prova ad addestrare nuovamente il decision trees sul breast 
cancer dataset impostano a turno uno di questi valori e valutare le 
variazioni di accuracy.
23"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#3,3,"Richiami: Decision Trees
In ML, ogni ""domanda"" in un nodo è chiamata comunemente 
 test
, ed è 
spesso codiﬁcata con feature su domini continui, ad esempio: 
la feature 
 i
 è maggiore del valore 
 a
? 
L'algoritmo si focalizza nello scegliere le sequenze if/else che portano ad 
una riposta più velocemente, ovvero sono più 
 informative
  per la variabile 
target.
4"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#4,4,"Dataset two_moons
Toy dataset generato da scikit-learn 
sklearn.datasets.make_moons(
 n_samples=100
 , 
*
, 
shuﬄe=True
 , 
noise=None
 , 
random_state=None
 )
Ogni istanza ha 2 valori. 
Ad esempio, per 75 istanze otteniamo: 
Per la profondità 0 dell'albero, quale test immagineresti?
5
"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#5,5,"Decision Trees su two_moons dataset
Depth = 1 
Depth = 2 
...
6
dove [2,32] indica che 2 istanze appartengono 
alla classe 1 e 32 alla classe 2
Se in una foglia ci sono istanze appartenenti 
ad una sola classe allora la foglia si chiama 
pure."
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#6,6,"Richiami: Decision Trees
Ogni test considera una singola feature, perciò la relativa decisione è 
rappresentata come una asse parallelo ad uno degli assi. 
Nella predizione, una volta arrivati ad una foglia, si assegna la classe target 
che appare più spesso nella regione associata. In modo simile per la 
regressione si opera una media dei valori delle istanze nella regione. 
Per dataset grandi, creare foglie pure è molto dispendioso in termini di 
risorse computazione e può creare fenomeni di overﬁtting. 
Si possono implementare tecniche di early stopping limitando la 
profondità dell'albero (
 pre-pruning
 ), oppure rimuovere o fondere foglie 
che contengono poca informazione (
 post-pruning
  o 
pruning
 )
7"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#7,7,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
...
8"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#8,8,"scikit-learn e decision trees
La classe 
 DecisionTreeClassiﬁer
  del modulo 
 DecisionTreeRegressor  
implementa l'algoritmo. 
Esercizio
 : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy 
sul training e test set 
from 
sklearn.tree 
 import 
DecisionTreeClassifier
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
stratify
 =
cancer
.
target
, 
random_state
 =
42
)
tree 
= 
DecisionTreeClassifier
 (
random_state
 =
0
)
tree
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
tree
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
tree
.
score
(
X_test
, 
y_test
)))
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%?
9"
data_test\rootfolder\università\MachineLearning\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#9,9,"scikit-learn e decision trees
> Accuracy on training set: 1.000
> Accuracy on test set: 0.937
Ti aspettavi una accuracy del 100%? Sì, per come funziona l'algoritmo 
l'albero cresce ﬁno a creare foglie pure che rappresentazione perfettamente 
l'appartenenza delle istanze alle relative label.  
L'accuracy sul test set è leggermente inferiore ai modelli lineari (95% ca). 
Esercizio
 : Prova a impostare una profondità col parametro 
 max_depth  
durante la costruzione dell'oggetto DecisionTreeClassiﬁer. Cosa ti aspetti 
sulle due accuracy?
10"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#0,0,"Machine Learning 
Anno Accademico 2021 - 2022 
  
Richiami di Matematica"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#1,1,"Sommario
Richiami sulle Funzioni Convesse 
Funzioni di più Variabili (Derivate Parziali) 
Gradiente di una Funzione 
Algoritmo di Gradient Descent 
Cenni di Calcolo delle Probabilità
 
2"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#10,10,"Funzioni Convesse 
 11
wg(w)
v wg(w)
g(v)
..g(v)+rg(v)T(w v)g(v)+dg(v)
dw(w v)
caso  
monodimensionale
Per una funzione convessa g(
 w
) differenziabile, il “piano” tangente giace sempre al 
di sotto del graﬁco della funzione:
g(w) g(v)+rg(v)T(w v)"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#11,11,"Funzioni di più Variabili
 
12"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#12,12,"Derivate Parziali di 
Funzioni di più Variabili 
 13g(w0+ w0,w1) g(w0,w1)
 w0
<latexit sha1_base64=""+SgtUNqNwOjhFnklqk6DFaFtyzI="">AAACZXicbVHJTsMwEHXCXrayiAsHLCokEFAlgARHBBw4gkShUlNVEzMtFs6CPaGqonwn4sCZr0AiKT10YU7P772ZsZ/9WElDjvNp2VPTM7Nz8wulxaXlldXy2vqjiRItsCYiFem6DwaVDLFGkhTWY40Q+Aqf/NfrQn96R21kFD5QL8ZmAJ1QtqUAyqlW+c1raxBpZ9+LclsxJe1mrdTJ+CH3blAR8G5xPOKjBjc74Md8su0fX5YOD8pa5YpTdfrFJ4E7ABU2qLtW+ct7jkQSYEhCgTEN14mpmYImKRRmJS8xGIN4hQ42chhCgKaZ9qPJ+F5igCIeo+ZS8T6Jwx0pBMb0Aj93BkAvZlwryP+0RkLti2YqwzghDEWxiKTC/iIjtMwzQP4sNRJBcXPkMuQCNBChlhyEyMkk/4RSnoc7/vpJ8HhSdU+rJ/dnlcurQTLzbJvtsn3msnN2yW7ZHasxwT7YjzVrzVnf9rK9aW/9WW1r0LPBRsre+QVEDroO</latexit>0< | w0|< 
<latexit sha1_base64=""u356CZIh7btrlBj4nRu25R6OhAY="">AAACG3icbVC7TgJBFJ3FF+ILtbSZSIxWZBdNtLAwamGJiTwSIOTucMEJs4/M3NWYDZ/gJ/gVtlrZGVsLC//FATFR8FQn55ybe8/1YyUNue6Hk5mZnZtfyC7mlpZXVtfy6xtVEyVaYEVEKtJ1HwwqGWKFJCmsxxoh8BXW/P7Z0K/doDYyCq/oLsZWAL1QdqUAslI7v+vyY95UNkK8eY6KgN+2U3fwo1nTyF4A7XzBLboj8GnijUmBjVFu5z+bnUgkAYYkFBjT8NyYWilokkLhINdMDMYg+tDDhqUhBGha6ajQgO8kBijiMWouFR+J+HsihcCYu8C3yQDo2kx6Q/E/r5FQ96iVyjBOCEMxXERS4WiREVraysg7UiMRDC9HLkMuQAMRaslBCCsm9nU5+w9vsv00qZaK3n6xdHlQODkdfybLttg222MeO2Qn7IKVWYUJds8e2RN7dh6cF+fVefuOZpzxzCb7A+f9C3UZoAU=</latexit>
Consideriamo una funzione                 di 2 variabili deﬁnita in un campo A.
g(w0,w1)
<latexit sha1_base64=""0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U="">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>
che si chiama rapporto incrementale parziale rispetto a       della     , perché in 
esso consideriamo incrementata soltanto la      , mantenendo inalterata la      .
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
g
<latexit sha1_base64=""M1D3T4qT4zLethYLQWkyJspQDuA="">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
si ha                                 e si può considerare il seguente rapporto incrementale:
(w0+ w0,w1)2A
<latexit sha1_base64=""MtP2/MU/+3Vkqc9/VVk+7SdRHu8="">AAACLXicbVDLSgNBEJz1bXxFPXoZDIKihN0oqLf4OHiMYFTIhtA7tjpk9sFMr0GW/RY/wa/wqicPgnr1N5yNOfiqU01VFz3VQaKkIdd9cYaGR0bHxicmS1PTM7Nz5fmFUxOnWmBTxCrW5wEYVDLCJklSeJ5ohDBQeBZ0Dwr/7Aa1kXF0QrcJtkO4iuSlFEBW6pR3V/3Y+kU86+WdzM35OvcPURHwXvHc4D8HvHyN+zLie51yxa26ffC/xBuQChug0Sm/+RexSEOMSCgwpuW5CbUz0CSFwrzkpwYTEF24wpalEYRo2lm/Ys5XUgMU8wQ1l4r3RfyeyCA05jYM7GQIdG1+e4X4n9dK6XKnnckoSQkjUSwiqbC/yAgtbXXkF1IjERQ/R267C9BAhFpyEMKKqT1myd7D+93+LzmtVb3Nau14q1LfH1xmgi2xZbbKPLbN6uyINViTCXbHHtgje3LunWfn1Xn/Gh1yBplF9gPOxyfAg6f7</latexit>
Sia                    .   Esiste allora un intorno circolare di centro       e 
opportuno raggio 𝜎, contenuto in A. Ne segue che, se:
P
<latexit sha1_base64=""Vg7Q1rv1rOgh7aYWrlRKdHDIMjA="">AAAB/3icbVC7TsNAEDzzDOEVoKQ5ESFRRXZAgjKChjJI5CElVnS+bMIp57O5WyNFVgq+ghYqOkTLp1DwL5yNC0iYajSzo92dIJbCoOt+OkvLK6tr66WN8ubW9s5uZW+/baJEc2jxSEa6GzADUihooUAJ3VgDCwMJnWBylfmdB9BGROoWpzH4IRsrMRKcoZX8fmTNLJs2Z3RQqbo1NwddJF5BqqRAc1D56g8jnoSgkEtmTM9zY/RTplFwCbNyPzEQMz5hY+hZqlgIxk/zo2f0ODEMIxqDpkLSXITfiZSFxkzDwE6GDO/MvJeJ/3m9BEcXfipUnCAoni1CISFfZLgW9mGgQ6EBkWWXAxWKcqYZImhBGedWTGw9ZduHN//9ImnXa95prX5zVm1cFs2UyCE5IifEI+ekQa5Jk7QIJ/fkiTyTF+fReXXenPef0SWnyByQP3A+vgGy5pat</latexit>
P⌘(w0,w1)2A
<latexit sha1_base64=""JoT9dMpAcV9D5gyTs2M1a0HUaxE="">AAACLnicbVDLSgNBEJz1bXxFPXoZDEIECbtRUDz5uHiMYBIhG8LspBMHZx/O9EbCkn/xE/wKr3oSPASvfoaz64IarVNNVTc9VV4khUbbfrOmpmdm5+YXFgtLyyura8X1jYYOY8WhzkMZqmuPaZAigDoKlHAdKWC+J6Hp3Z6nfnMASoswuMJhBG2f9QPRE5yhkTrFYzc0drqd1EbUhbtYDGj5W7wfdew9+uvt7FJXBPS0UyzZFTsD/UucnJRIjlqnOHa7IY99CJBLpnXLsSNsJ0yh4BJGBTfWEDF+y/rQMjRgPuh2kmUc0Z1YMwxpBIoKSTMRfm4kzNd66Htm0md4oye9VPzPa8XYO2onIohihICnh1BIyA5proQJDrQrFCCy9OdATXbOFEMEJSjj3IixabNg+nAm0/8ljWrF2a9ULw9KJ2d5Mwtki2yTMnHIITkhF6RG6oSTB/JEnsmL9Wi9WmPr/Wt0ysp3NskvWB+fwZ2pFA==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#13,13," 14
Se esiste determinato e ﬁnito il seguente limite:
lim
 w0!0g(w0+ w0,w1) g(w0,w1)
 w0
<latexit sha1_base64=""JRgIcRMvmpBtpSOD2ft2HVySLE8="">AAACh3icbVHLTsMwEHTCu7wKHDlgUSEVASUBBBx5HTiCRAGpqaKN2RYL5yF7Q4WifAVfx4EP4UYSeqCUPY1nZzzJOEiUNOQ4H5Y9MTk1PTM7V5tfWFxarq+s3ps41QLbIlaxfgzAoJIRtkmSwsdEI4SBwofg5bLcP7yiNjKO7ugtwW4I/Uj2pAAqKL/+7ikZ+pl3hYqAD/zMybmnZf+ZQOt4wMtjT4PI+k0vLi4qc7JBXul2+G/bLh8VuPk23+Pjtn90+Uh+7tcbTsupho8DdwgabDg3fv3Te4pFGmJEQoExHddJqJuBJikU5jUvNZiAeIE+dgoYQYimm1Xl5XwrNUAxT1BzqXhF4m9HBqExb2FQKEOgZ/N3V5L/7Top9U67mYySlDASZRBJhVWQEVoWHSB/khqJoPxy5DLiAjQQoZYchCjItHimWtGH+/fvx8H9Qcs9bB3cHjXOLobNzLJ1tsmazGUn7IxdsxvWZoJ9WRtW09q25+x9+9g+/ZHa1tCzxkbGPv8G8XPF8g==</latexit>Derivate Parziali di 
Funzioni di più Variabili 
la funzione   si dice parzialmente derivabile rispetto a       nel punto            .
g
<latexit sha1_base64=""M1D3T4qT4zLethYLQWkyJspQDuA="">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>
w0
<latexit sha1_base64=""sgHalUL2H+5/2ELVE3iy+BBsRNs="">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>
(w0,w1)
<latexit sha1_base64=""Hc3a+9D9w2RpqKTtwd9bdjillWY="">AAACGHicbVC7TsNAEDyHVwgvAyXNiYAUJBTZAQnKCBrKIJGHlFjR+bIJJ84P3a1BkeUf4BP4Clqo6BAtHQX/gm1SkISpRjM72p11Qyk0WtaXUVhYXFpeKa6W1tY3NrfM7Z2WDiLFockDGaiOyzRI4UMTBUrohAqY50pou3eXmd++B6VF4N/gOATHYyNfDAVnmEp986DSC1I/i8cPST+2kmM6rdjJUd8sW1UrB50n9oSUyQSNvvndGwQ88sBHLpnWXdsK0YmZQsElJKVepCFk/I6NoJtSn3mgnThvk9DDSDMMaAiKCklzEf4mYuZpPfbcdNJjeKtnvUz8z+tGODx3YuGHEYLPs0UoJOSLNFciLQ10IBQgsuxyoMKnnCmGCEpQxnkqRunfSuk/7Nn286RVq9on1dr1abl+MflMkeyRfVIhNjkjdXJFGqRJOHkkz+SFvBpPxpvxbnz8jhaMSWaXTMH4/AEzF6Cm</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#14,14," 15
Supponiamo ora che la funzione g sia parzialmente derivabile rispetto a w
 0 
in ogni punto del campo A.  
Per ogni punto di A resta ben determinato il corrispondente valore della 
derivata parziale rispetto a w
 0
. 
Nasce così in A una nuova funzione di due variabili w
 0
, w
 1
 che si chiama 
derivata parziale rispetto a 
 w
0
 della funzione g 
 e si denota ad esempio come 
segue:Derivate Parziali di 
Funzioni di più Variabili 
@g
@w0
<latexit sha1_base64=""VQx8u7rzFuG6k3KXt2wTraBjelE="">AAACI3icbZC5TsNAEIbX3IQrQEmzIkKiCjYgQRlBQxkkApFiyxpvJmHF+tDumEOWH4NH4ClooaJDNBR5F2wTiXOqX98/s7PzB4mShmz73ZqYnJqemZ2bry0sLi2v1FfXzk2caoEdEatYdwMwqGSEHZKksJtohDBQeBFcHZf+xTVqI+PojO4S9EIYRnIgBVCB/PqOO9AgMjcBTRJU5hLeUjbM87z2BW/8zC4I57zm1xt2066K/xXOWDTYuNp+feT2Y5GGGJFQYEzPsRPysvJloTCvuanBBMQVDLFXyAhCNF5WHZbzrdQAxTxBzaXiFcTvExmExtyFQdEZAl2a314J//N6KQ0OvUxGSUoYiXIRSYXVIiO0LBJD3pcaiaD8OXIZcQEaiFBLDkIUMC0iLPNwfl//V5zvNp295u7pfqN1NE5mjm2wTbbNHHbAWuyEtVmHCXbPHtkTe7YerBfr1Xr7bJ2wxjPr7EdZow9TRaVm</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#15,15," 16Derivate Parziali di 
Funzioni di più Variabili 
supposto determinato e ﬁnito.
Analogamente si deﬁnisce la derivata parziale rispetto a      , nel punto    ,  
come il limite
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
P
<latexit sha1_base64=""RzOqhOyvtYvEmUKPvym5XynVJro="">AAAB/nicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBIg8pjqLzZRNOOZ+tuzVSZEXiK2ihokO0/AoF/8LZuICEqUYzO9rdCWIpDLrup1NaWV1b3yhvVra2d3b3qvsHHRMlmkObRzLSvYAZkEJBGwVK6MUaWBhI6AbT68zvPoA2IlJ3OIthELKJEmPBGVrJ9yNrZtm0NR9Wa27dzUGXiVeQGinQGla//FHEkxAUcsmM6XtujIOUaRRcwrziJwZixqdsAn1LFQvBDNL85jk9SQzDiMagqZA0F+F3ImWhMbMwsJMhw3uz6GXif14/wfHlIBUqThAUzxahkJAvMlwL+y/QkdCAyLLLgQpFOdMMEbSgjHMrJradiu3DW/x+mXQade+s3rg9rzWvimbK5Igck1PikQvSJDekRdqEk5g8kWfy4jw6r86b8/4zWnKKzCH5A+fjG1b5loM=</latexit>
lim
 w1!0g(w0,w1+ w1) g(w0,w1)
 w1
<latexit sha1_base64=""AAg1+BW2nr0op9Oj8OQeUTZZmyE="">AAACiHicjVFNTxsxEPVuaaHpB6E99jIiqkT6Ee0CEvSGoAeOIDWAlI1Ws2YSLLwfsmeJkLX/on+uh/6RnvCmORDgwJye38ybZz9nlVaWo+hPEL5Yeflqde11583bd+/XuxsfzmxZG0lDWerSXGRoSauChqxY00VlCPNM03l2fdT2z2/IWFUWv/i2onGO00JNlET2VNr9nWiVpy75SZoRZqmLG0iMml4xGlPOIPLHiUHppltJ6Re1Pm7WpC5qvsEy45Vf4f6iPnyH58j6zZJ/00m7vWgQzQseg3gBemJRJ2n3b3JZyjqngqVGa0dxVPHYoWElNTWdpLZUobzGKY08LDAnO3bz9Br4XFvkEioyoDTMSbqvcJhbe5tnfjJHvrIPey35VG9U82R/7FRR1UyFbI1YaZobWWmUD4HgUhlixvbmBKoAiQaZyShAKT1Z+39q84gfvv4xONsexDuD7dPd3sHhIpk18Ulsii0Riz1xII7FiRgKKf4FEPSDL2EnjMK98Mf/0TBYaD6KpQoP7wB2TsYJ</latexit>
E se avviene che tale derivata esista in ogni punto                , resta ivi 
deﬁnita una nuova funzione delle variabili            che si chiama la derivata 
parziale rispetto a       della                  e si indica ad esempio come segue:
(w0,w1)2A
<latexit sha1_base64=""tqi9PhFGSNkmscV0Id0WgsEszQ0="">AAACBHicbVC7TsNAEDyHVwgvAyXNiQgpSCiyAxKUARrKIJGHlFjW+bIJp5wfulsniqK0fAUtVHSIlv+g4F+wjQsITDWa2dXOjhdJodGyPozC0vLK6lpxvbSxubW9Y+7utXQYKw5NHspQdTymQYoAmihQQidSwHxPQtsbXad+ewxKizC4w2kEjs+GgRgIzjCRXNOsTFzrhE5c+5j2REAvXbNsVa0M9C+xc1ImORqu+dnrhzz2IUAumdZd24rQmTGFgkuYl3qxhojxERtCN6EB80E7syz5nB7FmmFII1BUSJqJ8HNjxnytp76XTPoM7/Wil4r/ed0YBxfOTARRjBDw9BAKCdkhzZVIKgHaFwoQWZocaPI7Z4ohghKUcZ6IcdJRKenDXvz+L2nVqvZptXZ7Vq5f5c0UyQE5JBVik3NSJzekQZqEkzF5JE/k2XgwXoxX4+17tGDkO/vkF4z3L2CgljI=</latexit>
w0,w1
<latexit sha1_base64=""vH1j0jv1BCwogwzrtRh5C1k41l0="">AAAB+nicbVC7TsNAEDzzDOEVoKQ5ESFRoMgOSFBG0FAGiTykxLLOl0045Xy27tZEkclP0EJFh2j5GQr+Bdu4gISpRjO72tnxIykM2vantbS8srq2Xtoob25t7+xW9vbbJow1hxYPZai7PjMghYIWCpTQjTSwwJfQ8cfXmd95AG1EqO5wGoEbsJESQ8EZplJ34tmndOI5XqVq1+wcdJE4BamSAk2v8tUfhDwOQCGXzJieY0foJkyj4BJm5X5sIGJ8zEbQS6liARg3yfPO6HFsGIY0Ak2FpLkIvzcSFhgzDfx0MmB4b+a9TPzP68U4vHQToaIYQfHsEAoJ+SHDtUiLADoQGhBZlhyoUJQzzRBBC8o4T8U4baac9uHMf79I2vWac1ar355XG1dFMyVySI7ICXHIBWmQG9IkLcKJJE/kmbxYj9ar9Wa9/4wuWcXOAfkD6+MbgT2TrA==</latexit>
w1
<latexit sha1_base64=""SMv9N8e7smYx2+Jzvx4lA9b269Q="">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>
g(w0,w1)
<latexit sha1_base64=""0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U="">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>
@g
@w1
<latexit sha1_base64=""hykhrxvVEe3yRLuSCDFkAUXCvfY="">AAACFXicbVC7TgJBFJ3FF+ILtbQZJSZWZBdNtCTaWGIijwQIuTtccMLsIzN3NWSztZ/gV9hqZWdsrS38F3eRRAVPdeac+5h73FBJQ7b9YeUWFpeWV/KrhbX1jc2t4vZOwwSRFlgXgQp0ywWDSvpYJ0kKW6FG8FyFTXd0kfnNW9RGBv41jUPsejD05UAKoFTqFfc7Aw0i7oSgSYKKh0ny87jrOUnSK5bssj0BnyfOlJTYFLVe8bPTD0TkoU9CgTFtxw6pG2czhcKk0IkMhiBGMMR2Sn3w0HTjySkJP4wMUMBD1FwqPhHxd0cMnjFjz00rPaAbM+tl4n9eO6LBWTeWfhgR+iJbRFLhZJERWqYZIe9LjUSQ/Ry59LkADUSoJQchUjFKQyukeTiz18+TRqXsHJcrVyel6vk0mTzbYwfsiDnslFXZJauxOhPsnj2yJ/ZsPVgv1qv19l2as6Y9u+wPrPcvW36gVg==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#16,16," 17
Osserviamo che, mentre per le funzioni di una variabile la derivabilità in un 
punto implica la continuità in tale punto, non sussiste il fatto analogo per le 
funzioni di due variabili.Derivate Parziali di 
Funzioni di più Variabili 
Possono cioè in un punto esistere le due derivate parziali senza che la 
funzione g sia continua in esso.
Tutte le considerazioni fatte ﬁno ad ora sulle funzioni di due variabili si 
estendono immediatamente al caso delle funzioni di più di due variabili:
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#17,17,"Gradiente
 
18"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#18,18,"Gradiente di una Funzione 
 19
Il gradiente di una funzione è una diretta generalizzazione della nozione di 
derivata per una funzione a più variabili.
rg(w)=2
6666666664@g(w)
@w0
@g(w)
@w1
···
@g(w)
@wn3
7777777775
<latexit sha1_base64=""06VfDqyZDj5rj/n4a5yMYNZXbn4="">AAADBnicpVI9j9QwEHXCxx3L1y6UNBYrpKNZJQcSNCedoKE8JPbupPVqNXFmc9Y5TmRPuFtZ6fkVtFDRIVr+BgX/BWeJBOxSwcjF6L158zxjZ7VWjpLkWxRfuXrt+s7ujcHNW7fv3B2O7h27qrESp7LSlT3NwKFWBqekSONpbRHKTONJdv6y40/eonWqMm9oVeO8hMKopZJAAVqMopEwkGkQhJfki3ZPZJXO/UX7mB9woXFJM85FhoUyHqyFVetlywc8hFhakF7UYEmB9tsd2vYXe7HwSdu2XIhw/kmebshlXpH7j34m9BsINHk/FxdWFWc0HyyG42SSrINvJ2mfjFkfR4vhd5FXsinRkNTg3CxNapr7zkpqDCaNwxrkORQ4C6mBEt3cr9+u5Y8aB1TxGi1Xmq9B/F3hoXRuVWahsgQ6c5tcB/6NmzW0fD73ytQNoZGdESmNayMnrQqfAnmuLBJBd3PkynAJFojQKg5SBrAJv6TbR7o5/XZyvD9Jn0z2Xz8dH77oN7PLHrCHbI+l7Bk7ZK/YEZsyGV1G76MP0cf4Xfwp/hx/+VkaR73mPvsj4q8/AIJp+C8=</latexit>
g(w0,w1,...,w n)= g(w)
<latexit sha1_base64=""iUBK7+RA0FYb7PAax0+9XxEzqiQ="">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>
Data la seguente funzione:
deﬁniamo gradiente di g il vettore le cui componenti sono le derivate 
parziali della funzione:"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#19,19," 
20
w0w1ŵ
ŵ0ŵ1gradiente:
ijrg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
W(t)gGradiente di una Funzione "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#2,2,"Richiami sulle 
Funzioni Convesse
 
3"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#20,20," 
21
w0w1ŵ
ŵ0ŵ1
ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>W(t)gGradiente di una Funzione "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#21,21," 
22w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#22,22,"Derivata Direzionale 
 23
Si può dimostrare che la derivata direzionale secondo n è:
@g
@n=↵·@g
@w0+ ·@g
@w1
<latexit sha1_base64=""+Er6gFVcrheB4cs8jHX92VkksPI="">AAACdXicjVHBbtNAEF2btqSBlgBSOSCkFSkIqVKw00gth0oVvXAMUpNWii1rvJmkq67Xq91xUWX5wGdy4MwncK2dBkFpqZjT2/fe7Oy+SY2SjoLgm+c/WFlde9habz96vLH5pPP02djlhRU4ErnK7WkKDpXUOCJJCk+NRchShSfp+VGjn1ygdTLXx3RpMM5gruVMCqCaSjpfo5kFUUYGLElQ5byqfh90VfEDHoEyZ8AjMc2J32f/kgR1ww6PUqT/84dV1U463aDXH3zo7+3z2yDsBYvqsmUNk873aJqLIkNNQoFzkzAwFJfNpUJh1Y4KhwbEOcxxUkMNGbq4XERV8TeFA8q5Qcul4gsS/+woIXPuMktrZwZ05v7WGvIubVLQbD8upTYFoRbNIJIKF4OcsLLeAfKptEgEzcuRS80FWCBCKzkIUZNFvZQmj1+f5v8G434v3O31Pw+6hx+XybTYS/aavWMh22OH7BMbshET7Ie34W15L7yf/it/2397bfW9Zc9zdqP891efxMJr</latexit>
Detto 
 n
 il versore della direzione 
 n
, la    è il prodotto scalare dei due 
vettori:@g
@n
<latexit sha1_base64=""g3oVOo0czFVRrXmUUHD+5Uu0VMQ="">AAACFHicdVC7TsNAEDzzDOEVoKQ5ESFRWXaIBHQRNJRBIoCURNH62IQT57N1t0aKLLd8Al9BCxUdoqWn4F+wQxDvqeZm9nE7QaykJc97cSYmp6ZnZktz5fmFxaXlysrqiY0SI7AlIhWZswAsKqmxRZIUnsUGIQwUngaXB4V/eoXGykgf0zDGbggDLftSAOVSr8I7fQMi7cRgSIJKB1n2+dBZVu5Vqp5bq+/Vdnb5b+K73ghVNkazV3ntnEciCVGTUGBt2/di6qbFSKEwK3cSizGISxhgO6caQrTddHRJxjcTCxTxGA2Xio9E/NqRQmjtMAzyyhDowv70CvEvr51Qf7ebSh0nhFoUi0gqHC2ywsg8IuTn0iARFD9HLjUXYIAIjeQgRC4meWZFHh9H8//JSc31t93aUb3a2B8nU2LrbINtMZ/tsAY7ZE3WYoJds1t2x+6dG+fBeXSe3ksnnHHPGvsG5/kN2TSgHQ==</latexit>
rg·n
<latexit sha1_base64=""HmMzMEElHE9OTkg5/sPKXqpLV5A="">AAACF3icdVC7TsNAEDzzDOEVoKQ5ESFRRU6IlNAhaCiDRCBSHEXryyacOJ+tuzUCWfkAPoGvoIWKDtFSUvAv2CZIPKe50cys9nb8SElLrvvqTE3PzM7NFxaKi0vLK6ultfVTG8ZGYFuEKjQdHywqqbFNkhR2IoMQ+ArP/IvDzD+7RGNlqE/oOsJeACMth1IApVK/VPY0+Ar4iHtiEBL3CK/IHyb5KynR43ExTbmVWn2v1mjy36RacXOU2QStfunNG4QiDlCTUGBtt+pG1EvAkBQKx0UvthiBuIARdlOqIUDbS/Jjxnw7tkAhj9BwqXgu4teJBAJrrwM/TQZA5/anl4l/ed2Yhs1eInUUE2qRLSKpMF9khZFpS8gH0iARZD9HLjUXYIAIjeQgRCrGaW1ZH59H8//Jaa1S3a3Ujuvl/YNJMwW2ybbYDquyBttnR6zF2kywG3bH7tmDc+s8Ok/O80d0ypnMbLBvcF7eAZzfoGg=</latexit>
cioè è la componente del gradiente sulla retta orientata 
 n
. Questo signiﬁca 
che la derivata direzionale della funzione 
 g 
è massima secondo la 
direzione e verso del vettore gradiente.
Si può avere una visione globale di tutte queste possibili derivate, 
collegando al punto 
 P 
il gradiente della funzione g in tale punto."
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#23,23," 
24w0w1gDerivata Direzionale 
nPw1
w0
Q
w0 + 𝛼𝜌w1 + 𝛽𝜌
gradiente:
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n
ij"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#24,24," 25
La proprietà citata in precedenza del vettore gradiente, ossia il fatto che il 
gradiente fornisce direzione della pendenza più ripida, è alla base di 
algoritmi di Ricerca Locale che operano in spazi continui.
Tali algoritmi si dividono in due classi principali: 
•
Algoritmi a Salita più Ripida (Hill-Climbing) 
•
Algoritmi a Discesa del Gradiente (Gradient Descent)
Algoritmo Gradient Descent"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#25,25," 
26
w0w1g
ŵ
ŵ0ŵ1
ij
W(t+1)W(t)
- 𝛼 * gradiente
Algoritmo Gradient Descent"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#26,26,"Algoritmo Gradient Descent
 
27w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrg(w(t))k2>✏
w(t+1) w(t) ↵⇤rg(w(t))
t t+1
<latexit sha1_base64=""C1wbNEwaiOAK1Ma17wL9dfyBIzQ="">AAADRnichVJNbxMxEPWmfJTw1cKRy4iIKmlFtBuE4AKq4MKxlUhaKQ6R15kmVr32yp6ltKv9X/wE/gIHuMKJG+KKN42qpEViDtZ4Zt574/GkuVae4vhr1Fi7dv3GzfVbzdt37t67v7H5YOBt4ST2pdXWHabCo1YG+6RI42HuUGSpxoP0+G2dP/iIzitr3tNpjqNMTI06UlJQCI03o32e4lSZUmg1NdtVc4unVk/Kk+pD2U46FbyCGDhwwk9Utm2eFw5BW1BGnamAOQtnVl8hsxMLUvhCaAw4zqG5BRTwSfAvaGdKY1UT6gE6Am5EqsWCflq1l8SpU3XOq8Zlr4a8Bo65V9qac8KZz4XEMpFZyC7hduq2ucYjEs7ZE1jlhKfAhc5nAmAb/qe/IhR3n9dStMxNsANJk6OZXAywOd5oxd14bnDVSRZOiy1sb7zxjU+sLDI0JLXwfpjEOY1K4UjJMK0mLzyGDo7FFIfBNSJDPyrnf1/Bk8ILspCjA6VhHsRlRCky70+zNFRmgmb+cq4O/is3LOjo5ahUJi8IjayFKPzdXMhLp8JSIUyUQyJRd471DkjhBBE6BULKECzCltXzSC6//qoz6HWTZ93efq+1+2YxmXX2iD1mbZawF2yXvWN7rM9k9Dn6Hv2Ifja+NH41fjf+nJc2ogXmIVuxNfYXr1EImg==</latexit>"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#27,27,"Algoritmo Gradient Descent
 
28
Funzione non convessa di due variabili:"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#28,28,"Richiami di Probabilità
 
29"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#29,29,"Variabili Aleatorie
Le quantità di interesse che sono determinate dal risultato di 
un esperimento casuale sono dette 
 variabili aleatorie
 . 
Poiché il valore di una variabile aleatoria è determinato 
dall’esito di un esperimento, possiamo assegnare delle 
probabilità ai suoi valori possibili. 
Esempi di v.a.: risultato del lancio di un dado, risultato del 
lancio di una moneta, ecc.
 
30"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#3,3,"Insiemi Convessi 
 4Un insieme C in uno spazio vettoriale è convesso  se, comunque si scelgano 
due punti v e w appartenenti a C, il segmento che unisce i due punti 
appartiene a C.
Più formalmente:
Un insieme C in uno spazio vettoriale è convesso  se, ∀ v, w ∈ C, e ∀ λ ∈ [0, 1], si 
ha:
 v+( 1  )w2C"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#30,30,"Valore Atteso
Il concetto di Valore Atteso è uno dei più importanti concetti 
in tutta la teoria della probabilità. 
Sia X una variabile aleatoria discreta che può assumere i 
valori x
 1
, x
2
, …, x
 N
. Il Valore Atteso di X è il numero: 
 
31E[X],NX
i=1[xi·P(X=xi)]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#31,31,"Valore Atteso
 
32
Si tratta della media pesata dei valori possibili di X, usando 
come pesi le probabilità che tali valori vengano assunti da X. 
Per questo E[X] è anche detto 
 media
  di X (termine che però è 
sconsigliabile), oppure 
 aspettazione
  (
expectation
 ). "
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#32,32,"Valore Atteso
Sia X il punteggio che si ottiene lanciando un dado non 
truccato. Quanto vale E[X]?
 
33E[X]=1 ·1
6+2 ·1
6+3 ·1
6+4 ·1
6+5 ·1
6+6 ·1
6=7
2=3.5
ESEMPIO: lancio di un dado"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#33,33,"Valore Atteso
Si noti che in questo esempio il valore atteso di X non è uno 
dei possibili valori che X può assumere.  
Perciò, anche se E[X] è chiamato 
 valore atteso
  di X, ciò non 
vuole affatto dire che noi ci attendiamo di vedere questo 
valore, ma piuttosto che ci aspettiamo che sia il limite a cui 
tende il punteggio medio del dado su un numero crescente di 
ripetizioni.
 
34
ESEMPIO: lancio di un dado"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#34,34,"Valore Atteso
ESEMPIO: Indicator Function
 
35E[I]=1 ·P(I= 1) + 0 ·P(I= 0) = P(I= 1) = P(A)
Se I[A] è la funzione indicatrice di un evento A, ossia se:
     allora:
Quindi il valore atteso della indicator function di un evento è 
la probabilità di quest’ultimo.I[A],8
<
:1 se A si veriﬁca
0 se A non si veriﬁca"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#35,35,"Valore Atteso
Proprietà di E
 
36
Si riportano qui di seguito alcune proprietà della funzione E (a e 
b sono variabili aleatorie):
E[a+b]= E[a]+E[b]
E[k·a]= k·E[a] (k costante)
E[a·b]= E[a]·E[b]( aebi n d i p e n d e n t i )"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#36,36,"Varianza
 
37
Sia X una variabile aleatoria con media 
 μ
. La varianza di X è la 
quantità:
Var(X),E[(X µ)2]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#37,37,"Varianza
 
38
Esiste una formula alternativa per la varianza, che si ricava in 
questo modo:
ossia:
Var(X)=E[X2] E[X]2Var(X),E[(X µ)2]=
=E[X2 2µX+µ2]=
=E[X2] 2µ·E[X]+µ2=
=E[X2] µ2"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#4,4,"Insiemi Convessi 
 5Vediamolo nel caso a due dimensioni:L’espressione: 
corrisponde dunque ai punti appartenenti al  segmento che unisce i due punti 
v e w, al variare di λ ∈ [0, 1]. v+( 1  )w"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#5,5," 
6wv
λv + (1-λ)wλ(v - w)
λv + (1- λ)w = w + λ(v-w)
λ = 1
λ = 0Insiemi Convessi 
[caso a due dimensioni]
λ > 1
λ < 0λ = 0.6
C"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#6,6," 7Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si ?
si
 noInsiemi Convessi 
[caso a due dimensioni]"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#7,7," 8Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di 
spazio a due dimensioni:
si no
si
 noInsiemi Convessi 
[caso a due dimensioni]
"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#8,8,"Funzioni Convesse 
 9con 2[0,1]
wg(w)
v wg(w)
g(v)
.. .
.. g(v)+( 1  )g(w)
g( v+( 1  )w)
 v+( 1  )wg( v+( 1  )w) g(v)+( 1  )g(w)Sia C un insieme convesso. Una funzione                     si dice convessa se, per 
ogni v e w appartenenti al suo dominio di deﬁnizione, vale la seguente proprietà:g:C!R
g:R!R"
data_test\rootfolder\università\MachineLearning\2-Richiami di Matematica-sbloccato.pdf#9,9,"Deﬁnizione di Funzione  
Strongly Convex
 
10
Una funzione 
 g
 è detta 
 λ
-strongly convex
  se, per ogni 
 w
, 
v
 e 
α 
∈
 (0, 1), si ha:
Ovviamente, ogni funzione convessa è 0
 -strongly convex.g(↵v+( 1 ↵)w)↵g(v)+( 1  ↵)g(w)  
2↵(1 ↵)kv wk2
wg(w)
v wg(w)
g(v)
.. .
..  
2↵(1 ↵)kv wk2
↵v+( 1 ↵)wg(↵v+( 1 ↵)w)↵g(v)+( 1 ↵)g(w)"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Ensembles di Decision Trees (Ex 06)
1"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#1,1,"Sommario
Ensembles 
Random Forests 
Gradient boosted regression trees"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#10,10,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT.
11"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#11,11,"Scikit-learn: Random forests e breast cancer dataset
Esercizio
 : crea un RF per il dataset breast cancer con 100 alberi, e valuta 
l'accuracy nel training e test set, confrontandola con quella ottenuta con 
un singolo DT. 
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
100
, 
random_state
 =
0
)
forest
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
forest
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
forest
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.972
L'accuracy è più alta rispetto al modello lineare e al DT. 
È possibile fare un tuning con i parametri max_features e l'approccio 
pruning, ma su alcuni dataset i valori di default possono essere già 
sufﬁcienti.
12"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#12,12,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
13"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#13,13,"Scikit-learn: Random forests e breast cancer dataset
Cosa ti aspetti dalla feature importance ottenuta mediando i valori dei 
singoli trees?  
plot_feature_importances_cancer
 (
forest
)
Il valore aggregato ha più variabilità e tendenzialmente è più accurato. Il 
modello considera più features dando meno importanza alle singole (es. 
worst radius
 )
14
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#14,14,"Considerazioni sui Random forests (1)
I RF sono modelli di ML molto utilizzati essendo versatili, non richiedono 
lunghe fasi di tuning degli iperparametri e il rescaling dei dati. 
D'altro canto se hai bisogno di una rappresentazione compatta, il singolo 
DT è la soluzione migliore. È impossibile interpretare il valore di centinaia 
o più DT, soprattutto se hanno profondità elevate. 
Le implementazione dei RF possono essere facilmente parallelizzate su più 
CPU. Il parametro 
 n_jobs
  imposta il numero di core da impiegare (un 
valore pari a -1 indica l'uso di tutti i core). 
L'approccio random nei RF rende i modelli generati sugli stessi dati anche 
molto diversi tra loro. Se vuoi ottenere risultati riproducibili, imposta il 
parametro 
 random_state
 . 
I RF non mostrano buone prestazioni su dati sparsi e/o con molte features, 
es. dati testuali. I modelli lineare sono da preferire.
15"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#15,15,"Considerazioni sui Random forests (2)
Un parametro elevato di n_estimators solitamente migliora le performance, 
ma richiede più tempo e memoria per il training. 
Una indicazione per il parametro 
 max_features
  è impostarlo pari a 
sqrt(n_features)
  per la classiﬁcazione, e 
 log2(n_features)
  per la 
regressione.
16"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#16,16,"Ensembles: Gradient boosted regression trees
I 
Gradient boosted regression trees
  (
gradient boosting machines
 ) 
GBRT  
sono un approccio di 
 ensembles
 , e possono essere impiegate sia per la 
classiﬁcazione sia per la regressione.  
A differenza dei RF, gli alberi sono costruiti in modo sequenziale, dove 
ogni albero tenta di risolvere i problemi mostrati in precedenza. 
L'algoritmo è basato sull'approccio 
 boosting
  visto in precedenza.  
Al posto dell'elemento casuale, è impiegato l'approccio pre-pruning. Gli 
alberi prodotti non sono profondi (tipicamenti depth da 1 a 5), e questo 
rende il modello più compatto e veloce nelle predizioni. 
I singoli alberi sono modelli 
 semplici
  (in ML sono spesso chiamati 
 weak 
learners
 ) che producono buone performance su alcune istanze dei dati. 
Rispetto ai RF sono più sensibili alla scelta degli iperparametri, ma possono 
produrre risultati migliori, per questo sono spesso impiegati in scenari reali.
17"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#17,17,"Ensembles: Gradient boosted regression trees
Oltre al pre-pruning e al numero di alberi (
 n_estimators
 ), un altro 
iperparametro fondamentale è il 
 learning_rate,
  che controlla quanto un 
albero deve correggere gli errori prodotti dal precedente. Un valore elevato 
genera modelli più complessi. Allo stesso modo, un valore elevato di 
n_estimators
  incrementa la complessità e può ridurre gli errori commessi. 
In scikit-learn, la classe 
 GradientBoostingClassiﬁer
  implementa gli GBRT. 
Nel caso del Breast cancer dataset, con 100 alberi, con profondità max pari 
a 3 e un learning rate pari a 0.1: 
from 
sklearn.ensemble 
 import 
GradientBoostingClassifier
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 1.000
Accuracy on test set: 0.958
18"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#18,18,"Gradient boosted regression trees
Otteniamo una accuracy pari al 100%, potrebbe indicare un possibile 
overﬁtting.  
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate.
19"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#19,19,"Gradient boosted regression trees
Esercizio
 : prova ad incrementare il pre-pruning o ridurre il learning rate. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.991
Accuracy on test set: 0.972
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
learning_rate
 =
0.01
)
gbrt
.
fit
(
X_train
, 
y_train
)
print
(
""Accuracy on training set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_train
, 
y_train
)))
print
(
""Accuracy on test set: {:.3f}""
 .
format
(
gbrt
.
score
(
X_test
, 
y_test
)))
Accuracy on training set: 0.988
Accuracy on test set: 0.965
Entrambi gli approcci riducono la complessità e l'accuracy sul training set. 
In questo scenario, ridurre la profondità migliora maggiormente le 
performance.
20"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#2,2,"Ensembles
In ML, l'
 ensembles
  un approccio che combina più modelli di ML per 
creare un nuovo modello più soﬁsticato, che potenzialmente aggrega i 
beneﬁci dei singoli modelli.  
Esistono vari approcci di ensembles. Due approcci basati sui decision trees 
(
DT
) si sono dimostrati molto adatti in vari domini: 
Random forests 
Gradient boosted decision trees.
3"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#20,20,"Gradient boosted regression trees
Avendo impiegato 100 alberi, è poco pratico visualizzare le decision 
boundaries di ognuno, ma possiamo analizzare le feature importance. 
gbrt 
= 
GradientBoostingClassifier
 (
random_state
 =
0
, 
max_depth
 =
1
)
gbrt
.
fit
(
X_train
, 
y_train
)
plot_feature_importances_cancer
 (
gbrt
)
Noti differenze rispetto ai RF?
21
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#21,21,"Gradient boosted regression trees
I generale otteniamo 
 importance
  simili, ma in questo caso alcune features 
hanno peso pari a 0, cioè sono completamente ignorate dal modello.
22
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#22,22,"Gradient boosted regression trees: considerazioni (1)
Entrambi gli approcci ensembles mostrano buoni risultati su dati simili. Si 
può applicare prima l'approccio RF, piuttosto robusto.  
I GBRT richiedono un tuning degli iperparametri più lungo rispetto ai RF. 
Se il tempo impiegato per la predizione non è soddisfacente, o è 
fondamentale raggiungere una accuracy massima, si può considerare il 
GBRT. 
Come per i RF, i GBRT funzionano bene senza rescaling, e su combinazioni 
di feature binary o continous. Ma non sono efﬁcienti per dataset con molte 
features. 
I due iperparametri fondamentali sono 
 n_estimators
  e 
learning_rate
 . Sono 
dipendenti l'uno dall'altro. Un basso learning rate richiede più alberi per 
raggiungere la stessa complessità. Un valore elevato di 
 n_estimators  
migliora il modello, ma fa tendere il modello all'overﬁtting. 
Tipicamente si imposta 
 n_estimators
  in base alle risorse a disposizione, 
dopodiché si ottimizza il valore 
 learning_rates
 .
23"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#23,23,"Gradient boosted regression trees: considerazioni (2)
Altro iperparametro fondamentale è 
 max_depth
  (o alternativamente 
max_leaf_nodes
 ) per ridurre la complessità per ogni albero. Tipicamente si 
imposta a un valore molto basso, es. < 5.  
Con dataset di larghe dimensioni, si può considerare anche la libreria 
xgboost
 , che possiede una implementazione più ottimizzata.
24"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#24,24,"Esercizio su ensembles
Esercizio
 : impiegare i due approcci ensembles sui restanti dataset introdotti 
nelle precedenti esercitazioni: 
Forge dataset
  (classiﬁcazione) 
wave dataset
  (regressione) 
Boston housing dataset
  (regressione) 
Valutare la accuracy rispetto all'approccio basato sulla regressione lineare 
e al singolo decision tree.  
Operare un tuning degli iperparametri per incrementare le performance. 
25"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#25,25,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
26"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#3,3,"Ensembles: Random forests
I 
random forests
  (
RF
) sono una collezione di DTs, ognuno costruito in 
modo leggermo diverso dall'altro durante il training. 
I DTs tendono a mostrare overﬁtting. I RF tendono ad affrontare questa 
problematica: ogni albero può mostrare overﬁtting su certi dati, ma se ne 
costruiamo diversi in modo indipendente e mediamo i risultati complessivi, 
l'effetto dell'overﬁtting si riduce.  
Per creare diversi DTs, introduciamo un elemento casuale durante il 
processo di training, ad esempio selezionando: 
diversi set di training 
diverse features in ogni split test
4"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#4,4,"Scikit-learn: Random forests
In scikit-learn esiste una implementazione dei RF per la classiﬁcazione e 
per la regressione: 
 RandomForestClassiﬁer
  e 
RandomForestRegressor
 . 
Il numero di DTs è un iperparametro del modello RF e si imposta col 
parametro 
 n_estimators
  del costruttore (es. 10). 
Inizialmente si costruisce un 
 bootstrap sample
  dei dati.  
Dal training set estraiamo 
 n_samples
  istanze in modo casuale, con 
ripetizione, e ripetiamo n_samples volte. 
Il dataset che si ottiene è grande come quello originale, ma alcune 
istanze si possono ripetere, altre sono mancanti (approssimativamente 
1/3)  
Es.: se il dataset = ['a', 'b', 'c', 'd'], un possibile bootstrap è ['b', 'd', 'd', 
'c'], un altro ['d', 'a', 'd', 'a']. 
Dopodiché si addestra un DT per ogni boostrap sample.
5"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#5,5,"Scikit-learn: Random forests
Un ulteriore elemento casuale è introdotto in ogni nodo dell'albero. 
Durante la costruzione, invece di scegliere il test migliore, si selezionando 
un modo casuale un sottoinsieme di features e si seleziona la migliore 
considerando tale sottoinsieme.  
Il numero di features è impostato col parametro del costruttore 
max_features
  (ulteriore iperparametro del modello). 
Un valore alto di 
 max_features
  riduce la casualità nel modello RF, ma 
migliora il ﬁt sui dati. Un valore basso produce degli alberi molto 
complessi per raggiungere lo stesso livello di ﬁt. 
Per generare l'output, ogni DT è valutato sull'istanza in input e i risultati 
sono sottoposti a 
 soft voting, 
 cioè le probabilità per ogni 
 label
 ottenute dai 
singoli DT sono mediate e la classe con probabilità più alta è l'output del 
RF.
6"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#6,6,"Scikit-learn: Random forests e two_moons
Esercizio
 : col dataset 
 two_moons
  crea un modello RF con 5 alberi. 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
...
7"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#7,7,"Scikit-learn: Random forests e two_moons
Col dataset two_moons creiamo un modello RF con 5 alberi: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
100
, 
noise
=
0.25
, 
random_state
 =
3
)
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X
, 
y
, 
stratify
 =
y
,
random_state
 =
42
)
forest 
= 
RandomForestClassifier
 (
n_estimators
 =
5
, 
random_state
 =
2
)
forest
.
fit
(
X_train
, 
y_train
)
I parametri sono salvati nella variabile 
 estimator_
  del modello. 
Possiamo rappresentare i decision boundary per ogni modello: 
fig
, 
axes 
= 
plt
.
subplots
 (
2
, 
3
, 
figsize
=
(
20
, 
10
))
for 
i
, (
ax
, 
tree
) in 
enumerate
 (
zip
(
axes
.
ravel
(), 
forest
.
estimators_
 )):
ax
.
set_title
 (
""Tree {}""
 .
format
(
i
))
mglearn
.
plots
.
plot_tree_partition
 (
X_train
, 
y_train
, 
tree
, 
ax
=
ax
)
mglearn
.
plots
.
plot_2d_separator
 (
forest
, 
X_train
, 
fill
=
True
, 
ax
=
axes
[
-
1
, 
-
1
],
alpha
=.
4
)
axes
[
-
1
, 
-
1
]
.
set_title
 (
""Random Forest""
 )
mglearn
.
discrete_scatter
 (
X_train
[:, 
0
], 
X_train
[:, 
1
], 
y_train
)
8"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#8,8,"Scikit-learn: Random forests e two_moons
Cosa puoi notare riguardo i modelli e i training set? 
9
"
data_test\rootfolder\università\MachineLearning\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#9,9,"Scikit-learn: Random forests e two_moons
Ogni modello ha decision boundaries distinti, dove alcune istanze non sono 
correttamente classiﬁcati.  
Ogni modello ha un training set leggermente distinto: alcune istanze del 
training set complessivo non sono presenti. 
Le boundaries del modello ﬁnale sono più ""smooth"". 
10
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Voting e Stacking ensembles (Ex 07)
1"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#1,1,"Sommario
Voting 
Stacking 
Mutilayer Stacking 
Datasets MNIST e notMNIST 
Altri dataset di immagini 
Esercitazioni"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#10,10,"Multilayer Stacking ensemble
È possibile considerare più blender, ognuno basato su un modello distinto 
(es. regressione lineare, random forest, etc), ottenendo un nuovo layer. 
In questo caso si suddivide il training set in 3 parti. La prima usata nel 
primo layer, come nel caso precedente. La seconda usata dai modelli che 
combinano le predizioni del primo layer. E la restate parte che combina le 
predizioni del secondo layer. 
Nota: scikit-learn non supporta lo stacking.  
Ma ci sono librerie open source, es.  
https://github.com/viisar/brew   
https://github.com/Menelau/DESlib  
11
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#11,11,"MNIST
E’ un dataset molto conosciuto (rielaborato da 
 NIST
 ) di cifre per addestrare sistemi 
di classiﬁcazione basati sulle immagini. 
""If it doesn't work on MNIST, it won't work at all”; ""Well, if it does work on 
MNIST, it may still fail on others."" 
Contiene 60K immagini di addestramento e 10K di training. 
1998: un linear classiﬁer ha ottenuto 7.6% di errore rate. 
2012: per mezzo di una architettura DL (convolutional neural networks) si è 
arrivati al 0.23%. 
Ogni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono centrate 
in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare una cifra. 
http://yann.lecun.com/exdb/mnist/  
https://www.kaggle.com/c/digit-recognizer/data   
Implementazione online JS (ott’17) 
 http://myselph.de/neuralNet.html
12"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#12,12,"MNIST: train.csv e test.csv
Il ﬁle train.csv contiene una matrice con 785 colonne. La prima 
colonna è il 
 label
 della cifra (es. 3) e le restanti colonne sono la 
rappresentazione sequenziale dell’immagine: 
Il ﬁle test.csv ha la stessa rappresentazione senza la prima colonna. 
Esempio di immagini:
13
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#13,13,"MNIST: Considerazioni
Non è impiegato per sistemi avanzati poiché è un task semplice. 
Algoritmi classici di ML raggiungono i 97% di precisione, 
approcci Deep Learning il 99.7% 
Troppo utilizzato: si rischia di ideare nuovi approcci adatti solo per 
questo dataset. 
Molto diverso dai task studiati oggi.
14"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#14,14,"MNIST dataset
scikit-learn include il dataset che può essere facilmente usato: 
from
 sklearn.datasets 
 import
 fetch_openml
import
 numpy 
as
 np
mnist = fetch_openml(
 'mnist_784'
 , version=
 1
, as_frame=
 False
)
mnist.target = mnist.target.astype(np.uint8)
from
 sklearn.model_selection 
 import
 train_test_split
# 50K instanze per il training, 10K validation e 10K test
X_train_val, X_test, y_train_val, y_test = train_test_split(
    mnist.data, mnist.target, test_size=
 10000
, random_state=
 42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=
 10000
, random_state=
 42
)
15"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#15,15,"notMNIST
Simile a MNIST, contiene 10 labels (lettere da A a J), ma ogni lettera 
nel dataset occorre con font diversi, es: 
http://yaroslavvb.blogspot.ﬁ/2011/09/notmnist-dataset.html   
Download 
 http://yaroslavvb.com/upload/notMNIST/  
notMNIST_large.tar.gz -> training e validazione 
notMNIST_small.tar.gz -> test 
16
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#16,16,"fashion-MNIST
Fornito da Zalando. 10 classi che fanno riferimento a generi di vestiario (es. 
sandali, t-shirt, borse, etc). 
Contiene 60K immagini di addestramento e 10K di training.  
Ogni immagine è rappresentata in scala di grigi di 28x28 pixel  
https://github.com/zalandoresearch/fashion-mnist   
Side-by-side accuracy MNIST vs fashion MNIST: 
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#
17
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#17,17,"Altri dataset popolari sulle immagini
CIFAR-10 (e 100)
 : 60K 32x32 colour images in 10 classes. 
ImageNet
 : 1,5 milioni di immagini organizzate etichettate su 
WordNet. In media 1K immagini per concetto. 
ILSVRC2012 task 1
 : 10 milioni di immagini e +1K classi. 
Open Image
 : 9 milioni di URLs di immagini annotate con bounding 
boxes e migliaia di classi. 
VisualQA
 : open-ended questions su 265K immagini. In media 5.4 
questions per immagini con 10 ground truth answers per question. 
The Street View House Numbers
 : 600K immagini di numeri civici. 
Risultati sperimentali ottenuti per varie architetture avanzate: 
http://rodrigob.github.io/are_we_there_yet/build/#datasets  
18"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#18,18,"Esercitazione: Voting Classiﬁer
Impiega il dataset MNIST con uno split 50K/10K/10K. Scegli almeno tre 
classiﬁcatori e addestrali singolarmente.  
Crea un ensemble Voting, e valutalo sia con approccio soft che hard voting, 
sia sul validation sia sul test set.  
Confronta i risultati con i classiﬁcatori singoli. 
Prova a rimuovere il classiﬁcatore che si comporta meglio e valuta 
nuovamente le prestazioni.
19"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#19,19,"Esercitazione: Stacking Ensemble
Esegui i singoli classiﬁcatori scelti in precedenza e colleziona gli output sul 
validation set. 
Crea un nuovo training set con tali predizioni. Ogni istanza del set è una 
vettore che contiene l'insieme di predizioni per una certa immagine, e il 
target e la classe associata all'immagine. Addestra un classiﬁcatore con tale 
training set. Valutalo sul test set. 
Hai appena realizzato un Stacking ensemble.
20"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#2,2,"Ensembles: Voting
L'approccio voting si ispira alla ﬁlosoﬁa 
 wisdom of the crowd.
  Supponiamo 
di avere più classiﬁcatori (es. Logistic regression, SVM, Random forest, k-
NN). Prendiamo la predizione di ognuno e scegliamo quella che riceve 
""più voti"". Questa forma di aggregazione prende il nome di 
 hard-voting
 . 
Se partiamo da weak classiﬁers con accuracy non soddisfacente, il 
classiﬁcatore risultante può raggiungere accuracy elevate.
3
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#20,20,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
21"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#3,3,"Scikit-learn: Voting
La classe 
 VotingClassiﬁer
  di scikit-learn implementa l'approccio.  
Esercizio
 : completa il seguente frammento di codice basandoti sulla 
documentazione online di VotingClassiﬁer. 
from 
sklearn.ensemble 
 import 
VotingClassifier
(... importa gli altri classificatori ...)
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
...
voting_clf 
 = 
VotingClassifier
 (
    
...
, 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
4"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#4,4,"Scikit-learn: Voting
Impieghiamo SVM, RandomForest e LogisticRegression: 
from 
sklearn.ensemble 
 import 
RandomForestClassifier
from 
sklearn.ensemble 
 import 
VotingClassifier
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.svm 
 import 
SVC
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 make_moons
X, y = make_moons(n_samples=
 500
, noise=
 0.30
, random_state=
 42
)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=
 42
)
log_clf 
 = 
LogisticRegression
 ()
rnd_clf 
 = 
RandomForestClassifier
 ()
svm_clf 
 = 
SVC
()
voting_clf 
 = 
VotingClassifier
 (
    
estimators
 =
[(
'lr'
, 
log_clf
), (
'rf'
, 
rnd_clf
), (
'svc'
, 
svm_clf
)], 
    
voting
=
'hard'
)
voting_clf
 .
fit
(
X_train
, 
y_train
)
5"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#5,5,"Scikit-learn: Voting
(segue)
from 
sklearn.metrics 
 import 
accuracy_score
for 
clf 
in (
log_clf
, 
rnd_clf
, 
svm_clf
, 
voting_clf
 ):
    
clf
.
fit
(
X_train
, 
y_train
)
    
y_pred 
= 
clf
.
predict
(
X_test
)
    
print
(
clf
.
__class__
 .
__name__
 , 
accuracy_score
 (
y_test
, 
y_pred
))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.888
VotingClassifier 0.904
6"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#6,6,"Scikit-learn: Voting
Se i classiﬁcatori impiegati sono in grado di stimare probabilità di 
appartenenza alle singole label, cioè implementano la funzione 
predict_proba(), il voting può valutare le medie delle probabilità prodotte 
da ogni classiﬁcatore.  
L'approccio si chiama 
 soft voting,
  e si seleziona col parametro voting del 
costruttore: 
    
voting
=
'soft'
Esercizio
 : controlla che i classiﬁcatori impiegati in precedenza 
implementino predict_proba() e, in caso affermativo, lancia nuovamente il 
codice precedente e valuta la differenza di performance.
7"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#7,7,"Scikit-learn: Voting
og_clf = LogisticRegression(solver=
 ""lbfgs""
, random_state=
 42
)
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
svm_clf = SVC(gamma=
 ""scale""
, probability=
 True
, random_state=
 42
)
voting_clf = VotingClassifier(
    estimators=[(
 'lr'
, log_clf), (
 'rf'
, rnd_clf), (
 'svc'
, svm_clf)],
    voting=
 'soft'
)
voting_clf.fit(X_train, y_train)
VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),
                             ('rf', RandomForestClassifier(random_state=42)),
                             ('svc', SVC(probability=True, random_state=42))],
                 
 voting='soft'
 )
from
·
sklearn.metrics
 ·
import
·
accuracy_score
for
·
clf
·
in
·
(log_clf,
 ·
rnd_clf,
 ·
svm_clf,
 ·
voting_clf):
    
clf.fit(X_train,
 ·
y_train)
    
y_pred
·
=
·
clf.predict(X_test)
    
print
(clf.__class__.__name__,
 ·
accuracy_score(y_test,
 ·
y_pred))
from sklearn.metrics import accuracy_score
for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.896
VotingClassifier 0.92
8"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#8,8,"Ensembles: Stacking
Un ulteriore approcio ensembles è lo 
 stacking
 , che sta per 
 stacked 
generalization
 . 
Invece di aggregare il risultato con una tecnica di voting, addestriamo un 
ulteriore modello per questo scopo, chiamato 
 blender
  o 
meta learner
 . 
9
"
data_test\rootfolder\università\MachineLearning\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#9,9,"Stacking
Un approccio che spesso si impiega per addestrare il blender è il 
 hold-out 
set
. Inizialmente il training set è suddiviso in 2. Il primo è usato per 
addestrare i modelli nel primo layer, mentre il secondo (held-out) è usato 
per creare le predizioni. Per ogni istanza ci sono 3 predizioni. Tali 
predizioni costituiscono le features di una istanza in un 
 nuovo training set
 , 
il cui valore target è quello originale. Il blender è addestrato sul nuovo set.
10
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione al 
Clustering
Machine Learning "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#1,1,"Sommario
Supervised e Unsupervised Learning 
Introduzione al Clustering 
Algoritmo k-means  
Algoritmo k-means++
 
2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#10,10,"k-means Clustering 
 
11
Vediamo un esempio di esecuzione dell’algoritmo nel caso in cui i 
data points siano quelli riportati in ﬁgura. 
Supponiamo di scegliere come numero di cluster: k=3 "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#11,11,"k-means Clustering 
 
12
µ1,µ2,...,µ k
Scelta del numero di cluster k e inizializzazione dei k centroidi:
Esempio per k = 3
μ1
μ2
μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#12,12,"Voronoi Tesselation 
 
13
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#13,13,"k-means Clustering 
 
14
zi argmin
jkµj xik2
Assegnazione delle osservazioni al più vicino centroide:
μ1
μ2
μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#14,14,"k-Means Clustering 
 
15
Si ricalcolano i centroidi come media delle osservazioni assegnate 
ad ogni cluster:
µj=1
njX
i:zi=jxi
μ1
μ2μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#15,15,"k-Means Clustering 
 
16
zi argmin
jkµj xik2
Si riassegnano le osservazioni al centroide più vicino:
… e così via ﬁno al raggiungimento di una cond. di terminazione.μ1
μ2μ3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#16,16,"Algoritmo k-means 
 
17
L’algoritmo può essere pertanto sintetizzato come segue:
Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj xik2; assegniamo i data points al cluster center pi` u vicino
for j=1,. . . ,k
µj=1
njX
i:zi=jxi; aggiorniamo ciascun cluster center come media dei suoi data points"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#17,17,"Algoritmo k-means 
come Coordinate Descent 
 
18µj argmin
µX
i:zi=jkµ xik2
Si noti che la formula per il calcolo delle medie: 
è equivalente alla seguente espressione: µj=1
njX
i:zi=jxi"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#18,18,"Algoritmo k-means 
come Coordinate Descent 
 
19
Abbiamo dunque la seguente versione equivalente dell’algoritmo:
dove si alternano le minimizzazioni (a): z dato 
 μ
 e (b): 
 μ
 dato z. Scegliamo il numero kdei cluster
Inizializziamo i centroidi µ1,µ2,...,µ k
while not converged
for i=1,. . . ,N
zi argmin
jkµj xik2; assegniamo i data points al cluster center pi` u vicino
for j=1,. . . ,k
µj argmin
µX
i:zi=jkµ xik2; calcolo centroidi che minimizzano la somma del
; quadrato delle norme per i loro data points"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#19,19,"In genere k-means converge ad un ottimo locale. 
L’algoritmo è molto sensibile all’inizializzazione dei centroidi. 
Vediamo un esempio: 
 
20
Convergenza di k-means "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#2,2,"Supervised vs. Unsupervised 
Learning
Come sappiamo, molti problemi e metodi di Machine Learning 
rientrano in una delle due seguenti categorie: apprendimento 
supervisionato
  o 
non supervisionato
 . 
Gli esempi visti ﬁno ad ora rientrano nel dominio 
dell’apprendimento supervisionato: 
•
In quei casi (linear regression, logistic regression, ecc.) si 
hanno delle osservazioni che, a fronte di una certa 
conﬁgurazione delle features, ci dicono quale sia la 
soluzione corretta.
 
3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#20,20," 
21
Convergenza di k-means 
Data la scelta dei centroidi iniziali mostrata nella ﬁgura a sinistra, 
si ottiene il risultato mostrato a destra:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#21,21," 
22
Convergenza di k-means 
Altra scelta dei centroidi iniziali:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#22,22," 
23
Convergenza di k-means 
Altra scelta dei centroidi iniziali:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#23,23,"k-means++ 
 
24Arthur, D. e Vassilvitskii, S. “k-means++: the advantages of careful seeding”, in Proc. of the 
18th ACM-SIAM Symp. on Discrete Algorithms , 2007, pp. 1027-1035.
Bahmani, B., Moseley, B., Vattani, A., Kumar, R. e Vassilvitskii, S. “Scalable k-means++”, in 
Proc. of VLDB , 2012.
Come abbiamo visto, l’inizializzazione di k-means è critica ai ﬁni 
della qualità dell’ottimo locale trovato. 
Ora vediamo k-means++, un metodo che consiste in una 
particolare inizializzazione dei centroidi che in genere dà buoni 
risultati. 
Riferimenti:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#24,24,"k-means++ 
 
25
Smart initialization
 : 
1.
 Scegliere il primo centroide in modo casuale tra tutti i data 
points. 
2.
 Per ogni osservazione 
 x
i
, calcolare la distanza d(
 x
i
) tra 
x
i
 e il più 
vicino centroide. 
3.
 Scegliere il nuovo centroide tra i data point, con la probabilità 
di 
x
i
 di essere scelto proporzionale a d(
 x
i
) , ossia al quadrato 
della distanza tra 
 x
i
 e il centroide più vicino già scelto. 
4.
 Ripeti gli step 2 e 3 ﬁno ad arrivare a scegliere k centroidi.
2 "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#25,25,"k-means++: esempio 
 
26
Vediamo un esempio di inizializzazione con k=3, relativo alle 
osservazioni in ﬁgura:"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#26,26," 
27
Scelta random del primo cluster center:
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#27,27," 
28
Scelta del secondo cluster center. Si sceglie il punto con la 
probabilità maggiore, dove la probabilità è proporzionale a d(
 x
). 
In ﬁgura sono mostrate le varie distanze. 
2 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#28,28," 
29
Supponiamo che venga scelto il secondo cluster center in verde: 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#29,29," 
30
Scelta dell’ultimo cluster center. Di nuovo, si sceglie il punto con 
la probabilità maggiore, dove la probabilità è proporzionale a 
d(
x
i
), quadrato della distanza tra il punto i e il più vicino 
centroide: 
2 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#3,3,"Supervised vs. Unsupervised 
Learning
Nel caso non supervisionato ci troviamo in una situazione più 
impegnativa, nella quale abbiamo le varie osservazioni 
caratterizzate dai vari valori delle 
 features
 , ma per le quali non 
abbiamo disponibili le soluzioni. 
In questa situazione, in un certo senso dobbiamo lavorare alla 
cieca. 
La situazione è deﬁnita 
 unsupervised
  proprio perché nei 
 data 
points
  disponibili ci manca la risposta che può supervisionare la 
nostra analisi. 
 
4"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#30,30," 
31
Supponiamo che il cluster center scelto sia quello in blu. I tre 
centroidi scelti sono quelli con cui inizializziamo l’algoritmo k-
means. 
k-means++: esempio "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#31,31,"k-means++: pros & cons 
 
32
Eseguire k-means++ per individuare i centroidi iniziali è 
certamente più oneroso computazionalmente rispetto alla scelta 
random dei suddetti centroidi. 
Per contro, l’esecuzione di k-means con l’inizializzazione di k-
means++ è spesso più efﬁciente, nel senso che converge in genere 
più rapidamente. 
In generale possiamo dire che k-means++ tende a migliorare la 
qualità dell’ottimo locale trovato e diminuire il tempo di 
esecuzione. "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#32,32,"Cluster Heterogeneity 
 
33
L’algoritmo k-means cerca di minimizzare la somma dei quadrati 
delle distanze (
 distortion
 ): 
Come abbiamo visto, in genere l’algoritmo trova un minimo 
locale. costo kmeans =kX
j=1X
i:zi=jkµj xik2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#33,33,"Cluster Heterogeneity 
 
34
Confrontiamo i seguenti due risultati: la ﬁgura a destra è 
sicuramente migliore. La ﬁgura a sinistra è più “eterogenea”. 
"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#34,34,"Cosa accade al crescere di k 
 
35
Consideriamo il caso estremo k = N: 
•
 Signiﬁca che ogni cluster center è un data point. 
•
 Il costo (heterogeneity) è uguale a zero. 
Il costo (heterogeneity) decresce al crescere di k. "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#35,35,"Scelta del numero di cluster k 
 
36
“Elbow Method”: Un’euristica usata è quella di scegliere un punto 
che si trova nel “gomito” della curva: 
k (# di cluster)(minimo della 
cluster heterogeneity)costo_k_means 
minimo
123456"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#36,36,"Riferimenti
 
37
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 3a edizione, 
2015. 
Machine Learning: Clustering & retrieval
 , University of Washington - Coursera, 
2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#4,4,"Clustering 
Dobbiamo chiederci quale tipo di analisi sia possibile in tale 
contesto. 
Possiamo ad esempio cercare di comprendere le relazioni tra le 
osservazioni. 
Un approccio che possiamo usare in tali situazioni è quello della 
cluster analysis
 , o 
clustering
 . 
L’obiettivo del 
 clustering
  è quello di veriﬁcare, date le features in 
input, se le osservazioni disponibili ricadono all’interno di gruppi 
relativamente distinti tra di loro. 
 
5"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#5,5,"Clustering 
Il 
clustering
  è in effetti una delle tecniche più utilizzate per la 
exploratory data analysis
 . 
In tante discipline, dalle scienze sociali alla biologia alla computer 
science, gli studiosi cercano di avere delle prime “intuizioni” sui 
dati di cui dispongono identiﬁcando gruppi signiﬁcativi dei data 
points: 
•
i venditori cercano di identiﬁcare cluster di clienti, in base ai loro proﬁli, 
per migliorare l’attività di marketing (
 market segmentation
 ); 
•
i medici cercano di raggruppare i pazienti in base alle loro condizioni 
cliniche; 
•
gli astronomi identiﬁcano cluster di stelle in base alla loro prossimità 
spaziale; 
•
ecc. ecc.
 
6"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#6,6,"Clustering 
Esempio in due dimensioni: individuare la 
 cluster structure
  solo 
dagli input: 
 
7
feature 1feature 2"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#7,7,"Clustering 
Ogni cluster è deﬁnito dal 
 centroide
  (
cluster center
 ) e dalla forma 
(shape/spread): 
 
8
feature 1feature 2
1 2
3"
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#8,8,"Ciascuna osservazione 
 x
i
 è assegnata al cluster 
 k
 se: 
•
 Il punteggio (
 score
 ) di 
x
i
 sotto il cluster 
 k
 è migliore rispetto agli 
altri cluster. 
Per semplicità, spesso si deﬁnisce lo 
 score
  come la distanza dal 
centroide
  del cluster (si ignora lo shape). 
 
9
Clustering "
data_test\rootfolder\università\MachineLearning\22-Clustering-sbloccato.pdf#9,9,"k-means Clustering 
L’algoritmo 
 k-means
  assume come 
 score
  proprio la distanza di una 
osservazione dal 
 centroide
 . Più bassa è la distanza, “migliore” è lo 
score
 . 
Deﬁnizione dei simboli utilizzati nell’esempio che segue: 
 
10nj: numero di  elementi nel cluster jµj: centroide  del cluster j
zi: label del cluster a cui appartiene xiN: numero delle osservazioni
j: indice dei cluster 
k: numero dei clusterxi: osservazione i-esima (              ) xi2Rd"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 08)
1"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Preprocessing: Scaling 
Scaling in Scikit-learn 
Scaling e classiﬁcazione 
Scikit-learn e K-Means  
Esempi di limiti dell'algoritmo K-Means "
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#10,10,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set? 
Le istanze nel test set sono state scalate in modo improprio rispetto ai valori 
originali, e si trovano in posizioni relative diverse da quelle originali.
11
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#11,11,"Scikit-learn: Scaling
Nota: In scikit-learn, gli scaler hanno spesso il metodo ﬁt_transform() che 
combina le 2 operazioni: 
from 
sklearn.preprocessing 
 import 
StandardScaler
scaler 
= 
StandardScaler
 ()
X_scaled 
 = 
scaler
.
fit
(
X
)
.
transform
 (
X
)
# stesso risultato ma più efficient
X_scaled_d 
 = 
scaler
.
fit_transform
 (
X
)
12"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#12,12,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler sul dataset breast cancer e impiega 
l'algoritmo di classiﬁcazione SVC(C=100). Confronta la performance senza 
scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
...
13"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#13,13,"Scikit-learn: Scaling e Classiﬁcazione
Esercizio: Impiega il MinMaxScaler e StandardScaler sul dataset breast cancer 
e impiega l'algoritmo SVC(C=100). Confronta la performance senza scaling. 
from 
sklearn.svm 
 import 
SVC
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
, 
random_state
 =
0
)
svm 
= 
SVC
(
C
=
100
)
svm
.
fit
(
X_train
, 
y_train
)
print
(
""Test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test
, 
y_test
)))
>> Test set accuracy: 0.63
# con scaling
scaler 
= 
MinMaxScaler
 ()
scaler
.
fit
(
X_train
)
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
svm
.
fit
(
X_train_scaled
 , 
y_train
)
print
(
""Scaled test set accuracy: {:.2f}""
 .
format
(
svm
.
score
(
X_test_scaled
 , 
y_test
)))
>> Scaled test set accuracy: 0.97 (con StandardScaler si ottiene 0.96)
14"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#14,14,"Scikit-learn: K-means
Scikit-learn implementa l'algoritmo con la classe 
 KMeans
 . Il parametro 
n_clusters
  è richiesto per speciﬁcare il numero di cluster.  
Supponiamo di avere il seguente  
dataset: 
L'output dell'algoritmo può essere  
rappresentato col diagramma  
Voronoi Tesselation. 
from 
sklearn.cluster 
 import 
KMeans
k 
= 
5
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
y_pred 
= 
kmeans
.
fit_predict
 (
X
)
print (
y_pred)
>> array([4, 0, 1, ..., 2, 1, 0],  
dtype=int32)
print (y_pred 
 is 
kmeans
.
labels_)
>> True
15
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#15,15,"Scikit-learn: Limiti K-means
Possiamo ottenere le coordinate dei 5 centroidi: 
kmeans
.
cluster_centers_
>> array([[-2.80389616, 1.80117999],
[ 0.20876306, 2.25551336],
[-2.79290307, 2.79641063],
[-1.46679593, 2.28585348],
[-2.80037642, 1.30082566]])
E predire la classe di nuove istanze: 
X_new 
= 
np
.
array
([[
0
, 
2
], [
3
, 
2
], [
-
3
, 
3
], [
-
3
, 
2.5
]])
kmeans
.
predict
(
X_new
)
>> array([1, 1, 2, 2], dtype=int32)
Nota
 : K-Means non si comporta molto bene con cluster che hanno 
diametri molto distinti tra loro, poiché l'algoritmo valuta solo la distanza 
col centroide.
16"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#16,16,"Scikit-learn: K-means
Invece dell'
 hard clustering
  visto ﬁnora, dove l'output è un singolo cluster, 
possiamo ottenere uno score (anche chiamato 
 similarity score
  o 
afﬁnity
 ) per 
ogni cluster col 
 soft clustering
  mediante la funzione 
 transform
 (): 
kmeans
.
transform
 (
X_new
)
>> array([[2.81093633, 0.32995317, 2.9042344 , 1.49439034, 2.88633901],
[5.80730058, 2.80290755, 5.84739223, 4.4759332 , 5.84236351],
[1.21475352, 3.29399768, 0.29040966, 1.69136631, 1.71086031],
[0.72581411, 3.21806371, 0.36159148, 1.54808703, 1.21567622]])
È possibile impostare i centroidi iniziali in modo manuale col parametro 
init
: 
good_init 
 = 
np
.
array
([[
-
3
, 
3
], [
-
3
, 
2
], [
-
3
, 
1
], [
-
1
, 
2
], [
0
, 
2
]])
kmeans 
= 
KMeans
(
n_clusters
 =
5
, 
init
=
good_init
 , 
n_init
=
1
)
L'iperparametro 
 n_init
  speciﬁca quante volte l'algoritmo deve essere 
eseguito prima di selezionare la soluzione migliore ottenuta.
17"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#17,17,"Scikit-learn: K-means
Per valutare la bontà della soluzione si misura il costo basato sulla cluster 
heterogeneity, chiamato anche 
 inertia
  del modello, cioè la distanza 
quadratica media con i centroidi. 
kmeans
.
inertia_
>> 211.59853725816856
kmeans
.
score
(
X
)
>> -211.59853725816856
Nota
 : di default KMeans() usa l'inizializzazione dei centroidi proposta in K-
Means++. Se vuoi impiegare quella dell'algoritmo originale, imposta il 
parametro 
 init='random'
 .
18"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: K-means
Esempio con un dataset toy: 
from 
sklearn.datasets 
 import 
make_blobs
from 
sklearn.cluster 
 import 
KMeans
# generate synthetic two-dimensional data
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
19
n_clusters=2 n_clusters=4 n_clusters=3"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
20Secondo te è un output ideale?
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#2,2,"Clustering
Ci focalizziamo sugli algoritmi di 
 clustering
 . Esistono anche 
 trasformazioni 
unsupervised
 , utili per creare nuove rappresentazioni utili per analizzare 
dati o per darli in input a successivi algoritmi. Un approccio comune è la 
riduzione di dimensionalità
 , dove le N dimensioni corrispondenti alle 
features vengono ""compresse"" in poche dimensione (es. 2 o 3). 
La challenge del clustering è capire se l'algoritmo applicato su dati non 
etichettati (cioè senza output) riesce comunque a trovare qualcosa di utile. 
Esempio: Classiﬁcation (sx) e Clustering senza label (dx) 
3
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Limiti K-means
X_varied
 , 
y_varied 
 = 
make_blobs
 (
n_samples
 =
200
,
cluster_std
 =
[
1.0
, 
2.5
, 
0.5
],
random_state
 =
170
)
y_pred 
= 
KMeans
(
n_clusters
 =
3
, 
random_state
 =
0
)
.
fit_predict
 (
X_varied
 )
mglearn
.
discrete_scatter
 (
X_varied
 [:, 
0
], 
X_varied
 [:, 
1
], 
y_pred
)
plt
.
legend
([
""cluster 0""
 , 
""cluster 1""
 , 
""cluster 2""
 ], 
loc
=
'best'
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
21K-means assume che ogni cluster abbia lo 
stesso diametro, e deﬁnisce la boundary tra i 
cluster esattamente a metà tra i due centroidi. 
Alcuni punti del graﬁco potevano essere 
classiﬁcati in modo diverso.
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
22
Secondo te è un output ideale?"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Limiti K-means
X
, 
y 
= 
make_blobs
 (
random_state
 =
170
, 
n_samples
 =
600
)
rng 
= 
np
.
random
.
RandomState
 (
74
)
# trasforma i dati per mezzo di una distribuzione gaussiana
transformation 
 = 
rng
.
normal
(
size
=
(
2
, 
2
))
X 
= 
np
.
dot
(
X
, 
transformation
 )
kmeans 
= 
KMeans
(
n_clusters
 =
3
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
)
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm3
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
0
, 
1
, 
2
], 
s
=
100
, 
linewidth
 =
2
, 
cmap
=
mglearn
.
cm3
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
23
I dati sono distribuiti (""allungati"") sulla diagonale, 
non seguono una distribuzione sferica. 
L'algoritmo valuta solo la distanza dal centroide."
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#23,23,"Scikit-learn: Limiti K-means
from 
sklearn.datasets 
 import 
make_moons
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
kmeans 
= 
KMeans
(
n_clusters
 =
2
)
kmeans
.
fit
(
X
)
y_pred 
= 
kmeans
.
predict
(
X
))
plt
.
scatter
(
X
[:, 
0
], 
X
[:, 
1
], 
c
=
y_pred
, 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
scatter
(
kmeans
.
cluster_centers_
 [:, 
0
], 
kmeans
.
cluster_centers_
 [:, 
1
],
marker
=
'^'
, 
c
=
[
mglearn
.
cm2
(
0
), 
mglearn
.
cm2
(
1
)], 
s
=
100
, 
linewidth
 =
2
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
24
Shape complesse non sono 
valutate correttamente."
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#24,24,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
25"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#3,3,"Preprocessing: Scaling
Alcuni algoritmi di ML sono sensibili allo 
 scaling
  dei dati. Per tale motivo 
spesso si opera un rescaling e shifting. 
Vediamo qualche esempio dalla libreria mglearn: 
mglearn
.
plots
.
plot_scaling
 ()
4
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#4,4,"Preprocessing: Scaling
Il diagramma mostra 4 scaler della libreria scikit-learn.  
StandardScaler
 : garantisce media 0 e varianza 1  
Non garantisce alcun intervallo max e min 
RobustScaler
 : approccio statistico simile,  
usa mediana e quartili, è meno sensibile  
agli 
outliers
 . 
MinMaxScaler
 : sposta i dati nell'intervallo [0,1] 
Normalizer
 : effettua un rescaling in modo che  
la distanza euclidea sia pari a 1, cioè proietta  
i punti su una circonferenza (o sfera) di raggio 1.  
Ogni punto è scalato per l'inverso della lunghezza.  
Utile quando si ha interesse soprattutto riguardo la direzione, piuttosto 
che della lunghezza del feature vector.
5
"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Scaling
Usiamo il breast cancer dataset per testare i vari scaling su un contesto 
supervised con algoritmo SVM/SVC: 
from 
sklearn.datasets 
 import 
load_breast_cancer
from 
sklearn.model_selection 
 import 
train_test_split
cancer 
= 
load_breast_cancer
 ()
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
cancer
.
data
, 
cancer
.
target
,
random_state
 =
1
)
print
(
X_train
.
shape
)
print
(
X_test
.
shape
)
>> (426, 30)
>> (143, 30)
from 
sklearn.preprocessing 
 import 
MinMaxScaler
scaler 
= 
MinMaxScaler
 ()
# consideriamo solo X_train, 
 non il y_train
scaler
.
fit
(
X_train
)
>> MinMaxScaler(copy=True, feature_range=(0, 1))
# trasformiamo i dati
X_train_scaled 
 = 
scaler
.
transform
 (
X_train
)
6"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#6,6,"Scikit-learn: Scaling
# stampa i valori delle features prima e dopo il rescaling
print
(
""transformed shape: {}""
 .
format
(
X_train_scaled
 .
shape
))
print
(
""per-feature minimum before scaling:\n {}""
 .
format
(
X_train
.
min
(
axis
=
0
)))
print
(
""per-feature maximum before scaling:\n {}""
 .
format
(
X_train
.
max
(
axis
=
0
)))
print
(
""per-feature minimum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:\n {}""
 .
format
(
X_train_scaled
 .
max
(
axis
=
0
)))
>> transformed shape: (426, 30)
per-feature minimum before scaling:
[ 6.98 9.71 43.79 143.50 0.05 0.02 0. 0. 0.11
0.05 0.12 0.36 0.76 6.80 0. 0. 0. 0.
0.01 0. 7.93 12.02 50.41 185.20 0.07 0.03 0.
0. 0.16 0.06]
per-feature maximum before scaling:
[ 28.11 39.28 188.5 2501.0 0.16 0.29 0.43 0.2
0.300 0.100 2.87 4.88 21.98 542.20 0.03 0.14
0.400 0.050 0.06 0.03 36.04 49.54 251.20 4254.00
0.220 0.940 1.17 0.29 0.58 0.15]
per-feature minimum after scaling:
[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
per-feature maximum after scaling:
[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
7"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#7,7,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?
8"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#8,8,"Scikit-learn: Scaling
Applichiamo lo scaling anche sul X_test 
# transform test data
X_test_scaled 
 = 
scaler
.
transform
 (
X_test
)
# print test data properties after scaling
print
(
""per-feature minimum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
min
(
axis
=
0
)))
print
(
""per-feature maximum after scaling:
\n{}""
.
format
(
X_test_scaled
 .
max
(
axis
=
0
)))
>> per-feature minimum after scaling:
[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006
-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007
0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]
per-feature maximum after scaling:
[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037
0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391
0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]
Non sono nel range [0,1], è corretto?  
Sì, perché il max e min sono stati ricavati dal training set, e possono 
essere distinti da quelli nel X_test.
9"
data_test\rootfolder\università\MachineLearning\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#9,9,"Scikit-learn: Scaling
Cosa succede se applicassimo due distinti rescaling sul training e sul test 
set?
10
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 09)
1"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Agglomerative clustering 
Hierarchical clustering 
Dendograms 
DBSCAN 
Accelerated K-Means e Mini-batch K-Means 
Silhoutte score"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#10,10,"DBSCAN
DBSCAN (density-based spatial clustering of applications with noise) è un 
algoritmo che non richiede la scelta del numero di cluster a priori, inoltre può 
gestire conﬁgurazioni complesse dei dati (es. non sferiche). a differenza degli 
approcci visti ﬁnora. 
È generalmente più lento ma può scalare su dataset molto grandi. 
L'algoritmo identiﬁca i punti nel feature space che si trovano in regioni 
""popolate"" o 
 dense 
 e costruisce i cluster in base ad esse. I punti in queste 
regioni si chiamano 
 core samples
 .  
Ci sono 2 iperparametri: 
 min_samples
  e 
eps
. Se esistono almeno 
 min_samples  
punti con distanza inferiore a 
 eps
 rispetto a un punto X, allora  X è un 
 core 
sample
 . I core sample che sono vicini tra loro (distanza < eps) sono inseriti 
nello stesso cluster. Un cluster deve avere almeno min_samples punti. 
I punti che non sono assegnati a nessun cluster diventano i punti di partenza 
per una nuova iterazione. Quelli che non sono assegnati ad alcun cluster 
sono considerati rumore.
11"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#11,11,"DBSCAN
Nota
 : anche in DBSCAN la funzione predict() non è implementata. 
Esempio: 
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
Perché l'output è sempre -1?
12"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#12,12,"DBSCAN
from 
sklearn.cluster 
 import 
DBSCAN
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X
)
print
(
""Cluster memberships:\n{}""
 .
format
(
clusters
 ))
Cluster memberships:
[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
L'algoritmo usa il valore di default per eps che non è adatto per il piccolo dataset 
analizzato. 
mglearn
.
plots
.
plot_dbscan
 ()
min_samples: 2 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 2 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 2 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 2 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 3 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]
min_samples: 3 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]
min_samples: 3 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]
min_samples: 3 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
min_samples: 5 eps: 1.000000 cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]
min_samples: 5 eps: 1.500000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 2.000000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]
min_samples: 5 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]
13"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#13,13,"DBSCAN
Diverse conﬁgurazioni variando gli iperparametri (i punti in bianco sono 
considerati rumore). Cosa noti? 
14
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#14,14,"DBSCAN
Incrementando 
 eps
 ci sono più punti che appartengono a clusters, e si 
riducono anche il numero di clusters. 
Nota: è più facile impostare il valore di eps operando prima la normalizzazione delle features con 
StandardScaler
  o 
MinMaxScaler.  
Incrementando 
 min_samples
 , meno punti saranno core points, e più punti 
saranno etichettati come rumore. 
15
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#15,15,"DBSCAN - Esercizio
Esercizio
 : impiega l'algoritmo DBSCAN sul moon dataset, con o senza la 
normalizzazione. Valuta i cluster ottenuti.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
...
16"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#16,16,"DBSCAN - Esercizio
Esercizio: impiega l'algoritmo DBSCAN sul moon dataset.  
X
, 
y 
= 
make_moons
 (
n_samples
 =
200
, 
noise
=
0.05
, 
random_state
 =
0
)
# media 0 e varianza unitaria
scaler 
= 
StandardScaler
 ()
scaler
.
fit
(
X
)
X_scaled 
 = 
scaler
.
transform
 (
X
)
dbscan 
= 
DBSCAN
()
clusters 
 = 
dbscan
.
fit_predict
 (
X_scaled
 )
plt
.
scatter
(
X_scaled
 [:, 
0
], 
X_scaled
 [:, 
1
], 
c
=
clusters
 , 
cmap
=
mglearn
.
cm2
, 
s
=
60
)
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
17"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#17,17,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
Esercizio
 : Cosa succede se decrementiamo il valore di default di eps (0.5) a 
0.2, o lo incrementiamo a 0.7?
18
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#18,18,"DBSCAN - Esercizio
Questa volta il clustering ottimale è identiﬁcato. 
eps = 0.2 -> 8 clusters 
eps = 0.7 -> 1 cluster
19
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#19,19,"Accelerated K-Means e Mini-batch K-Means
L'algoritmo 
 accelerated
  K-Means evita di calcolare distanze non 
necessarie.  
Impiega la 
 triangle inequality 
  AC< AB+BC, dove A,B e C sono 3 punti, e 
tiene traccia del valore del upper e lower bounds delle distanze tra 
centroidi e istanze. È l'approccio normalmente impiegato 
nell'implementazione KMeans di scikit-learn. 
L'approccio 
 Mini-batch
  seleziona un piccolo insieme di istanze su cui 
valutare le distanze, creando una 
 inerzia
  nella modiﬁca dei clusters. 
Incrementa la velocità, ma se il numero di cluster è elevato si ottengono 
conﬁgurazioni meno ottimali. 
from 
sklearn.cluster 
 import 
MiniBatchKMeans
minibatch_kmeans 
 = 
MiniBatchKMeans
 (
n_clusters
 =
5
)
minibatch_kmeans
 .
fit
(
X
)
20"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#2,2,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
Quali criteri di unione (merge) puoi immaginare?
3"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#20,20,"Accelerated K-Means e Mini-batch K-Means
Mini-batch vs K-Means tradizionale impiegando diversi numeri di clusters 
k. Con un numero elevato di clusters l'inerzia si riduce notevolmente, e si 
limita il tempo di training. 
Ricordiamo che l'
 inertia
  del modello e' la distanza quadratica media con i 
centroidi, cioè la
  cluster heterogeneity 
 (vedi lezione sul clustering).
21
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#21,21,"Il numero ottimale di clusters
Alcuni algoritmi richiedono di speciﬁcare il numero di clusters, che 
possono produrre risultati molto diversi anche con valori simili: 
Potremmo scegliere il modello con minore inertia, ma nell'esempio con 
k=3 otteniamo 653.2, mentre con k=8 si ha inertia=119.1. Più cluster 
abbiamo, più si riduce la distanza col rispettivo centroide e la rispettiva 
inertia del modello. 
22
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#22,22,"Richiami: elbow method
Se graﬁchiamo il valore dell'inertia in funzione del numero di clusters 
 k
 si 
vede chiaramente con dopo un ""drop"" elevato, il decremento si riduce 
notevolmente. 
23
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#23,23,"Silhoutte score
Un metodo più formale è il calcolo del valore della silhoutte su tutte le 
istanze. Si ricava con
  (b-a)/max(a,b)
  dove 
 a
 è la distanza media rispetto 
alle altre istanze nel cluster, 
 b
 è la 
 mean nearest-cluster distance
 , cioè la 
distanza media delle istanze rispetto al cluster più vicino. 
Il coefﬁciente varia in [-1,+1], dove un valore vicino:  
a +1 indica una istanza vicina al proprio cluster e lontana dagli altri,  
allo 0, istanza vicina al boundary del cluster 
a -1 l'istanza potrebbe essere stata assegnata al cluster sbagliato. 
from 
sklearn.metrics 
 import 
silhouette_score
silhouette_score
 (
X
, 
kmeans
.
labels_
)
0.655517642572828
24"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#24,24,"Silhoutte score
Un valore pari a 4 di cluster massimizza il valore della silhoutte
25
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#25,25,"Silhoutte diagram
Graﬁci del valore di silhoutte per ogni istanza, ordinati per il cluster di 
appartenenza. Per k=4 abbiamo che gran parte delle istanze sorpassano il 
valore di silhoutte associato a quella conﬁgurazione (linea rossa)
26
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#26,26,"Silhoutte: Esercizio
Esercizio
 : riprendi il dataset blobs e l'approccio agglomerative e ricava il 
numero ottimale di cluster col approccio 
 Agglomerative
 . 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
...
27"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#27,27,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
28"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#3,3,"Agglomerative Clustering
L'algoritmo segue i seguenti passi: 
Deﬁniamo una serie di cluster, ognuno con una serie di istanze al suo 
interno.  
Ad ogni iterazione 
 uniamo
  i due cluster valutati maggiormente simili.  
Al raggiungimento di un certo 
 criterio di stop
  ci fermiamo. Tipicamente 
il criterio è basato sul numero di cluster desiderato. 
In scikit-learn la fusione di cluster può seguire uno dei seguenti criteri: 
ward
  (default): si scelgono i cluster i cui merge riducono al massimo 
l'incremento di varianza tra tutti i cluster. Di solito porta ad avere 
cluster di dimensione confrontabile. 
average
 : i due cluster che hanno distanza media tra tutti punti minore 
complete
 : i due cluster che hanno distanza massima tra due punti 
minore.
4"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#4,4,"Agglomerative Clustering
Esempio libreria 
 mglearn
 : 
mglearn
.
plots
.
plot_agglomerative_algorithm
 ()
5
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#5,5,"Scikit-learn: Agglomerative Clustering
Esempio scikit-learn: 
from 
sklearn.cluster 
 import 
AgglomerativeClustering
X
, 
y 
= 
make_blobs
 (
random_state
 =
1
)
agg 
= 
AgglomerativeClustering
 (
n_clusters
 =
3
) # parametro obbligatorio
assignment 
 = 
agg
.
fit_predict
 (
X
)
mglearn
.
discrete_scatter
 (
X
[:, 
0
], 
X
[:, 
1
], 
assignment
 )
plt
.
xlabel
(
""Feature 0""
 )
plt
.
ylabel
(
""Feature 1""
 )
Nota
 : l'agglomerative clustering non può predire un cluster per nuovi dati, 
perciò non è possibile usare la funzione predict().
6
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#6,6,"Hierarchical clustering
Ad ogni passo dell'algoritmo agglomerative si creano diverse 
conﬁgurazioni che possono essere rilevanti per analizzare i dati, soprattutto 
se si hanno poche features. 
mglearn
.
plots
.
plot_agglomerative
 ()
7
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#7,7,"Dendrograms
Per dataset con molte features è comunque possibile rappresentare i dati 
sottoforma di dendogrammi. Scikit-learn non implementa tale funzionalità, 
usiamo la libreria 
 scipy
 : 
from 
scipy.cluster.hierarchy 
 import 
dendrogram
 , 
ward
X
, 
y 
= 
make_blobs
 (
random_state
 =
0
, 
n_samples
 =
12
)
# ward clustering sui dati
# la funzione restituisce un array che contiene le distanze ricavate
# durante il clustering agglomerative
linkage_array 
 = 
ward
(
X
)
# Visualizziamo il dendogramma con le distanze tra i cluster
dendrogram
 (
linkage_array
 )
# Nel plot aggiungiamo il numero di clsuter
ax 
= 
plt
.
gca
()
bounds 
= 
ax
.
get_xbound
 ()
ax
.
plot
(
bounds
, [
7.25
, 
7.25
], 
'--'
, 
c
=
'k'
)
ax
.
plot
(
bounds
, [
4
, 
4
], 
'--'
, 
c
=
'k'
)
ax
.
text
(
bounds
[
1
], 
7.25
, 
' two clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
ax
.
text
(
bounds
[
1
], 
4
, 
' three clusters'
 , 
va
=
'center'
 , 
fontdict
 =
{
'size'
: 
15
})
plt
.
xlabel
(
""Sample index""
 )
plt
.
ylabel
(
""Cluster distance""
 )
8"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#8,8,"Dendrograms
Dal seguente diagramma come immagini che si sia comportato l'algoritmo 
di clustering?
9
"
data_test\rootfolder\università\MachineLearning\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#9,9,"Dendrograms
Sulle ascisse abbiamo le istanze numerate (da 0 a 11). Salendo si notano i 
nuovi cluster che uniscono le istanze, oppure cluster già presenti. 
Es. al principio si uniscono 1 e 4 in un cluster, poi 6 e 9 in un altro, etc. 
In cima abbiamo 2 cluster, uno con 11,0,5,10,7,6 e 9; l'altro coi 
restanti punti. 
La lunghezza in verticale delle linee rappresentano le distanze tra i due 
cluster o punti che si fondono. 
10
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Clustering (Ex 10)
1"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#1,1,"Sommario
Image segmentation 
Clustering per il preprocessing 
Grid search 
Active learning 
Gaussian Mixtures"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#10,10,"Clustering per il semi-supervised learning
Soluzione: 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
X_digits_dist 
 = 
kmeans
.
fit_transform
 (
X_train
)
representative_digit_idx 
 = 
np
.
argmin
(
X_digits_dist
 , 
axis
=
0
)
X_representative_digits 
 = 
X_train
[
representative_digit_idx
 ]
# facciamo un labeling manuale delle 50 cifre
y_representative_digits 
 = 
np
.
array
([
4
, 
8
, 
0
, 
6
, 
8
, 
3
, 
...
, 
7
, 
6
, 
2
, 
3
, 
1
, 
1
])
l
og_reg 
= 
LogisticRegression
 ()
log_reg
.
fit
(
X_representative_digits
 , 
y_representative_digits
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9244444444444444
11
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#11,11,"Clustering per il preprocessing
Etichettiamo le restanti istanze nei cluster con le label che abbiamo creato 
in modo manuale (
 label propagation
 ), e proviamo nuovamente ad 
addestrare la logistic regression: 
y_train_propagated 
 = 
np
.
empty
(
len
(
X_train
), 
dtype
=
np
.
int32
)
for 
i 
in 
range
(
k
):
  
y_train_propagated
 [
kmeans
.
labels_
==
i
] 
= 
y_representative_digits
 [
i
]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
, 
y_train_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9288888888888889
Un leggero incremento. Non conviene propagare le label alle istanze 
lontano dal centroide e vicine al boundary.
12"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#12,12,"Clustering per il preprocessing
Proviamo a fare propagation solo al 20% delle istanze più vicine al centroide 
percentile_closest 
 = 
20
X_cluster_dist 
 = 
X_digits_dist
 [
np
.
arange
(
len
(
X_train
)), 
kmeans
.
labels_
]
for 
i 
in 
range
(
k
):
in_cluster 
 = 
(
kmeans
.
labels_ 
 == 
i
)
cluster_dist 
 = 
X_cluster_dist
 [
in_cluster
 ]
cutoff_distance 
 = 
np
.
percentile
 (
cluster_dist
 , 
percentile_closest
 )
above_cutoff 
 = 
(
X_cluster_dist 
 > 
cutoff_distance
 )
X_cluster_dist
 [
in_cluster 
 & 
above_cutoff
 ] 
= -
1
partially_propagated 
 = 
(
X_cluster_dist 
 != -
1
)
X_train_partially_propagated 
 = 
X_train
[
partially_propagated
 ]
y_train_partially_propagated 
 = 
y_train_propagated
 [
partially_propagated
 ]
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train_partially_propagated
 , 
y_train_partially_propagated
 )
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.9422222222222222
94.2% è molto vicino al risultato ottenuto con l'addestramento sull'interno 
dataset etichettato (96.7%). In effetti le istanze etichettate automatichemente 
con 
label propagation
  sono corrette al 99%.
13"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#13,13,"Active Learning
È un approccio iterativo dove l'algoritmo propone alcune istanze per essere 
etichettate manualmente. Ci sono diverse strategie per selezionare queste 
istanze: 
quelle su cui l'algoritmo mostra maggiore incertezza,  
quelle che potenzialmente riducono maggiormente il tasso di errore, 
quelle su cui diversi modelli (es. SVM, Random forest, etc) trovano 
maggiore disaccordo. 
Il procedimento continua ﬁnché non si hanno miglioramenti di 
performance tangibili. 
14"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#14,14,"Gaussian Mixtures
Il 
Gaussian mixture model (GMM)
  suppone che le istanze siano generate 
da un mix di diverse distribuzioni gaussiano i cui parametri sono incogniti. 
Le istanze generate da una singola distribuzione formano un cluster a 
forma di ellissoide, con diverse forme, dimensioni, densità e orientamenti.  
Al principio non sappiamo quali distribuzioni generino una speciﬁca 
istanza. Occorre stimarle durante la fase di training. 
15
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#15,15,"Gaussian Mixtures
La classe 
 GaussianMixture
  suppone di conoscere in anticipo il numero 
 k
 di 
distribuzioni. 
Per ogni istanza, prendiamo casualmente un cluster dei 
 k
. La probabilità di 
scegliere il 
 j
-mo cluster e deﬁnita dal peso del cluster 
 ϕ
(j)
. L'indice del 
cluster selezionato per l'istanza 
 i
-ma è 
 z
(i)
. 
Se 
z
(i)
=
j
, la posizione della istanza 
 x
(i)
 è campionata in modo casuale da 
una distribuzione gaussiana con media 
 μ
(j)
 e matrice di covarianza 
 Σ
(j)
, e la 
indichiamo con:
16
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#16,16,"Gaussian Mixtures
Rappresentiamo il modello graﬁcamente dove si notano le dipendenze tra le 
variabili casuali. Le circonferenze sono le variabili casuali, i quadrati i parametri. 
I rettangoli sono 
 plates
 , e indicano che i loro contenuti sono ripetuti diverse volte 
(es. 
m
 volte corrispondenti al numero di variabili casuali, o 
 k
 volte, cioè il 
numero di medie e covarianze, ed un solo array di parametri 
 ϕ
). 
Ogni variabile 
 z
(i) 
è ricavata da una distribuzione 
 categorical
  con pesi 
 ϕ
. 
Ogni 
variabile 
 x
(i)
 è ricavata da una distribuzione gaussiana con media e matrice di 
covarianza deﬁnita dal suo cluster 
 z
(i)
.
17
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#17,17,"Gaussian Mixtures
(cont...) Le frecce rappresentano dipendenze tra le variabili. Ad esempio, 
z
(i)
 dipende dal vettore dei pesi 
 ϕ
, per ogni 
 i
. 
A seconda del valore di 
 z
(i)
, l'istanza 
 x
(i)
 è campionata da una diversa 
distribuzione (freccia ondulata).  
I nodi colorati rappresentano dati noti, gli altri contengono parametri da 
stimare.
18
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#18,18,"Scikit-learn: Gaussian Mixtures
Una volta addestrato il modello impiegando la classe 
 GaussianMixture
 () 
possiamo ottenere facilmente i parametri 
 ϕ
, 
μ
 e 
Σ
: 
from 
sklearn.mixture 
 import 
GaussianMixture
gm 
= 
GaussianMixture
 (
n_components
 =
3
, 
n_init
=
10
)
gm
.
fit
(
X
)
# mostriamo i parametri stimati
gm
.
weights_
>>> array([0.20965228, 0.4000662 , 0.39028152])
gm
.
means_
>>> array([[ 3.39909717, 1.05933727],
[-1.40763984, 1.42710194],
[ 0.05135313, 0.07524095]])
gm
.
covariances_
>>> array([[[ 1.14807234, -0.03270354],
[-0.03270354, 0.95496237]],
[[ 0.63478101, 0.72969804],
[ 0.72969804, 1.1609872 ]],
[[ 0.68809572, 0.79608475],
[ 0.79608475, 1.21234145]]])
E ora?
19"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#19,19,"Scikit-learn: Gaussian Mixtures
Impieghiamo l'algoritmo di Expectation Maximization (EM), simile come 
idea al K-Means. Inizializza i parametri dei cluster in modo casuale, e 
iterativamente raggiunge lo stato di convergenza. Assegna le istanze ai 
cluter (
 expectation step
 ) e poi aggiorna i cluster (
 maximization step
 ). Ricava 
i valori del centro dei cluster (medie), la loro dimensione, forma e 
orientazione (matrice di covarianze) e il relativo peso (
 Φ
). 
EM usa un soft clustering, stimando la probabilità di appartenenza. Durante 
il 
maximization step
  ogni cluster è aggiornato con tutte le istanze nel 
dataset, dove ogni istanza è pesata con la relativa probabilità di 
appartenenza (chiamata anche 
 responsability
  del cluster per l'istanza). 
Perciò ogni cluster viene aggiornato maggiormente dalle istanze che più 
verosimilmente appartengono ad esso. 
L'algoritmo richiede diversi run (es. n_init=10), poiché può facilmente 
produrre cattive conﬁgurazioni.
20"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#2,2,"Image segmentation e Instance segmentation
Nella 
 Image segmentation
  si suddivide una immagine in porzioni, dove 
ogni porzione contiene pixel che rappresentano un oggetto associato alla 
porzione (es. pedone, portiera di un auto, etc). Una porzione può 
contenere istanze multiple di un oggetto. 
Nella Instance segmentation ogni porzione contiene una singola istanza 
(es. ogni pedone ha una segmentation distinta). 
Affrontiamo il problema con un approccio basato sulla 
 color segmentation.  
Non è il più efﬁcace, ma per alcuni domini è sufﬁciente (es. analizzare la 
percentuale di zone verdi da immagini satellitari). 
Associamo un pixel ad un segmento se ha colore simile. 
3"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#20,20,"Scikit-learn: Gaussian Mixtures
Possiamo valutare la convergenza e il numero di iterazioni: 
gm
.
converged_
>> True
gm
.
n_iter_
>> 3
Una volta ricavati i parametri possiamo predire il cluster (hard clustering) o 
i clusters (soft clustering) più adatti per una certa istanza: 
gm
.
predict
(
X
)
>> array([2, 2, 1, ..., 0, 0, 0])
gm
.
predict_proba
 (
X
)
>> array([[2.32389467e-02, 6.77397850e-07, 9.76760376e-01],
[1.64685609e-02, 6.75361303e-04, 9.82856078e-01],
[2.01535333e-06, 9.99923053e-01, 7.49319577e-05],
...,
[9.99999571e-01, 2.13946075e-26, 4.28788333e-07],
[1.00000000e+00, 1.46454409e-41, 5.12459171e-16],
[1.00000000e+00, 8.02006365e-41, 2.27626238e-15]])
21"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#21,21,"Scikit-learn: Gaussian Mixtures
Essendo un modello generativo, puoi anche generare nuove istanze dal 
modello: 
X_new
, 
y_new 
= 
gm
.
sample
(
6
)
X_new
>> array([[ 2.95400315, 2.63680992],
[-1.16654575, 1.62792705],
[-1.39477712, -1.48511338],
[ 0.27221525, 0.690366 ],
[ 0.54095936, 0.48591934],
[ 0.38064009, -0.56240465]])
y_new
>>array([0, 1, 2, 2, 2, 2])
oppure stimare la densità del modello per un certo punto. Col metodo 
score_samples
 () si ricava la log della 
 probability density function 
 (PDF): 
gm
.
score_samples
 (
X
)
>> array([-2.60782346, -3.57106041, -3.33003479, ..., -3.51352783,
-4.39802535, -3.80743859])
Per stimare la prob che una istanza cada in una certa regione occorre 
integrare la funzione sull'intervallo.
22"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#22,22,"Scikit-learn: Gaussian Mixtures
Il graﬁco precedente rappresenta la densità per mezzo dei colori: 
È stato facile rappresentare i dati perché abbiamo usato una gaussiana 2D. 
Per altri dataset occorrono più dimensioni (e molte più istanze). Se 
l'algoritmo non riesce a convergere si possono impostare vincoli sulla 
forma e orientazione delle distribuzioni (es. parametro 
 covariance_type
 )
23
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#23,23,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
24"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#3,3,"Scikit-learn: Image segmentation
Carichiamo una immagine, che sarà memorizzata in un array 3d, dove la 
profondità (numero di canali) rappresenta l'intensità RGB in [0,1], o 
[0,255] se si impiega imageio.imread() 
from 
matplotlib.image 
 import 
imread
import
 urllib2
f = 
urllib2.urlopen
 (
'
http://.../image.png
 '
)
f = 
os
.
path
.
join
(
""images""
 ,
""image.png""
 )       # in alternativa
image 
= 
imread
(f)
image
.
shape
>> (533, 800, 3)
Nota: alcune immagini hanno meno canali (es. scala di grigio), o più canali 
(es. alpha channel, segnale infrared).
4"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#4,4,"Scikit-learn: Image segmentation
Il seguente codice ridimensiona l'array come un array 1D, dove ogni 
elemento è una tripla. Dopodiché fa clustering raggruppando pixel con 
colori simili. Inﬁne ricava il colore ""medio"" per mezzo del centroide e 
riordina il risultato come le dimensioni dell'immagine iniziale: 
X 
= 
image
.
reshape
(
-
1
, 
3
)
kmeans 
= 
KMeans
(
n_clusters
 =
8
)
.
fit
(
X
)
segmented_img 
 = 
kmeans
.
cluster_centers_
 [
kmeans
.
labels_
]
segmented_img 
 = 
segmented_img
 .
reshape
(
image
.
shape
)
5
"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#5,5,"Clustering per il preprocessing
Il clustering può essere usato anche come tecnica di 
 dimensionality 
reduction
 , ad esempio per rendere più adatto un dataset per un approccio 
supervised, riducendo il numero di features e la dimensione totale.  
Es. prendiamo il MNIST dataset (1797 immagini 8x8 in scala di grigio) e 
impieghiamo la logistic regression per la classiﬁcazione: 
from 
sklearn.datasets 
 import 
load_digits
X_digits
 , 
y_digits 
 = 
load_digits
 (
return_X_y
 =
True
)
from 
sklearn.model_selection 
 import 
train_test_split
X_train
, 
X_test
, 
y_train
, 
y_test 
= 
train_test_split
 (
X_digits
 , 
y_digits
 )
from 
sklearn.linear_model 
 import 
LogisticRegression
log_reg 
 = 
LogisticRegression
 (
random_state
 =
42
)
log_reg
.
fit
(
X_train
, 
y_train
)
log_reg
.
score
(
X_test
, 
y_test
)
0.9666666666666667
6"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#6,6,"Clustering per il preprocessing
Usiamo inizialmente il cluster per raggruppare le immagini simili usando 
50 clusters (usarne solo 10 non è ottimale poiché esistono molti modi per 
rappresentare la stessa cifra), e usiamo la distanza da questi cluster come 
input al posto dell'immagine originale: 
from 
sklearn.pipeline 
 import 
Pipeline
pipeline 
 = 
Pipeline
 ([
    (
""kmeans""
 , 
KMeans
(
n_clusters
 =
50
)),
    (
""log_reg""
 , 
LogisticRegression
 ()),
])
pipeline
 .
fit
(
X_train
, 
y_train
)
pipeline
 .
score
(
X_test
, 
y_test
)
0.9822222222222222
Abbiamo dimezzato il tasso d'errore! 
Nota: Pipeline combina più operazioni di 
 trasformazione
  sui dati, cioè 
devono comparire classi che implementano 
 ﬁt
() e 
transform
 (). Per ultimo 
c'è l'estimator che deve includere l'implementazione di 
 ﬁt
().
7"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#7,7,"Tuning degli iperparametri: grid search
Per il tuning degli iperparametri (numero di cluster) possiamo impiegare lo 
score della fase supervised, senza il bisogno di calcolare la silhoutte. 
La classe GridSearchCV ottimizza il valore degli iperparametri in modo 
esaustivo iterando su intervalli (approccio grid-search con cross-
validazione). 
from 
sklearn.model_selection 
 import 
GridSearchCV
# dizionario chiave->valore, dove la chiave è il nome del iperparametro,
# il valore è il range di valori da valutare
param_grid 
 = 
dict
(
kmeans__n_clusters
 =
range
(
2
, 
100
))
grid_clf 
 = 
GridSearchCV
 (
pipeline
 , 
param_grid
 , 
cv
=
3
, 
verbose
=
2
)
grid_clf
 .
fit
(
X_train
, 
y_train
)
grid_clf
 .
best_params_
>> {'kmeans__n_clusters': 90}
grid_clf
 .
score
(
X_test
, 
y_test
)
>> 0.9844444444444445
8"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#8,8,"Clustering per il semi-supervised learning
Potremmo avere dataset poche istanze con label (etichettate), e molte 
istanze senza label. Non è sufﬁciente per l'addestramento supervised. 
Ad esempio, impiegando solo 50 istanze dal dataset delle cifre otteniamo 
una accuracy piuttosto bassa: 
n_labeled 
 = 
50
log_reg 
 = 
LogisticRegression
 ()
log_reg
.
fit
(
X_train
[:
n_labeled
 ], 
y_train
[:
n_labeled
 ])
log_reg
.
score
(
X_test
, 
y_test
)
>> 0.826666666666666
9"
data_test\rootfolder\università\MachineLearning\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#9,9,"Clustering per il semi-supervised learning
Esercizio: prova a fare il clustering del dataset delle cifre (split X_train) 
usando 50 clusters impiegando KMeans. Per ogni cluster trova la cifra con 
distanza minima dal centroide dal cluster. Usa queste cifre come il nuovo 
dataset di 50 immagini per addestrare la logistic regressione e valuta la 
differena nelle performance. 
k 
= 
50
kmeans 
= 
KMeans
(
n_clusters
 =
k
)
...
10"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alle  
Reti Neurali Artiﬁciali
1"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#1,1,"Sommario
Introduzione alle Reti Neurali Artiﬁciali 
Unità di Calcolo nelle Reti Neurali  
Reti Neurali a uno strato alimentate in avanti (percettroni) 
Reti Neurali multistrato alimentate in avanti 
Algoritmo di Back-propagation 
Esempio di esecuzione dell’algoritmo
2"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#10,10,"ReLU 
(Rectiﬁed Linear Unit)
gg(in i) = max(in i,0)
<latexit sha1_base64=""fdZuD83MuMKqvRY6gR2pKYYhfhM="">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>
ini 0
11"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#11,11,"Funzione Gradino
La motivazione biologica è che un 1 rappresenta 
l’emissione di un impulso lungo l’assone, mentre uno 0 
rappresenta l’assenza di una tale emissione.
La soglia individua l’ingresso pesato minimo che fa in 
modo che il neurone invii l’impulso.
La funzione a gradino ha una soglia t tale che il 
risultato è 1 quando l’ingresso supera questa soglia.
12"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#12,12,"Funzione Gradino
In molti casi risulterà dal punto di vista matematico 
conveniente sostituire la soglia con un peso d’ingresso 
extra.
Questo consentirà di avere un elemento di 
apprendimento più semplice in quanto si dovrà 
preoccupare solo di modiﬁcare dei pesi anziché 
modiﬁcare sia dei pesi che delle soglie.
Quindi, invece di avere una soglia t, considereremo per 
ciascuna unità un ingresso aggiuntivo, la cui attivazione 
a
0
 è ﬁssata a -1.
13"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#13,13,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
14"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#14,14,"Unità di Calcolo nelle Reti Neurali 
Il peso extra W
 0,i
 associato ad a
 0
 ricopre il ruolo della 
soglia t, dove W
 0,i
 = t e a
 0 
= -1. 
In questo modo tutte le unità possono avere una soglia 
ﬁssata a 0.ai=gradinot0
@nX
j=1Wj,iaj1
A=gradino00
@nX
j=0Wj,iaj1
A
<latexit sha1_base64=""bnb4YwLA9yDvbdcHkbSf+9auugw="">AAACfXicfVFNb9NAEF2brxI+moI4IcGIqFKRosgulcqlUgUXjkUiTaU4WOPNJJ12vbZ2x4jK8g/gJ3LgN/ATwA45QFrxTk9v5r3ZnclKw16i6HsQ3rp95+69rfu9Bw8fPd7u7zw59UXlNI11YQp3lqEnw5bGwmLorHSEeWZokl2+7+qTL+Q8F/aTXJU0y3FpecEapZXS/jdMGY4gEfrauuulwznbokkFEkML2YPEV3laXxzFzefaNjBp+ZAbSIaA6QUkjpfn8vqmhGgzIfpvQi/tD6JRtAJcJ/GaDNQaJ2n/RzIvdJWTFW3Q+2kclTKr0QlrQ00vqTyVqC9xSdOWWszJz+rVyhrYrTxKASU5YAMrkf521Jh7f5VnbWeOcu43a514U21ayeLtrGZbVkJWd4OEDa0Gee24vQXBnB2JYPdyArag0aEIOQbUuhWr9jjdPuLN318np/uj+M1o/+PB4PjdejNb6rl6pfZUrA7VsfqgTtRYafUzeBa8CF4Gv8LdcBiO/rSGwdrzVP2D8PA3NkzAIQ==</latexit>
15"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#15,15,"Funzione Gradino 
(con soglia zero)
g
0g(in i)=⇢1i f i n i 0
0 otherwise
<latexit sha1_base64=""xUm3gk/S64XZW4FVFriL5T2ehIM="">AAACfnicbVHLbtNAFB2bR4t5BSqxYcEVKVVZkNoFqd0gVbBhWSTSVspE0Xhy41x1PDYz19DI8g/whyz4Bz4BO7VQaTmro3PuY+bctDTkOY5/BuGt23fubmzei+4/ePjo8eDJ0xNfVE7jWBemcGep8mjI4piJDZ6VDlWeGjxNzz92/uk3dJ4K+4VXJU5zlVlakFbcSrPBj2xXMl5wTbaZ0WuA9yANLljWADLFjGytnFOrpjamgQhaJLADMk+Li5oWsH2lG2SGXyHebkDKy9L4b2nBS3TfyWNnRhLtvJ8L0lG25BFEs8EwHsVrwE2S9GQoehzPBr/kvNBVjpa1Ud5PkrjkaTuXSRtsIll5LJU+VxlOWmpVjn5arzNr4FXlFRdQogMysBbxaketcu9XedpW5oqX/rrXif/zJhUvDqdtIGXFaHW3iMngepHXjtpjIMzJIbPqXo5AFrRyihkdgdK6Fav2Ol0eyfXf3yQn+6Pk7Wj/87vh0Yc+mU3xXLwUuyIRB+JIfBLHYiy0+B08C14EEIpwJ3wT7l2WhkHfsyX+QXj4B8OsvNA=</latexit>
ini
16"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#16,16," Vediamo adesso alcuni semplici esempi di 
reti neurali per la realizzazione di
Porte Logiche
17"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#17,17,"Porte logiche
Lavorando in modo  adeguato sui pesi si possono realizzare 
porte logiche con una rete neurale formata da un solo 
neurone:
18"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#18,18,"Porta AND
•
(Soglia t =1.5) 
•
 W
0
=1.5 
•
W
1
=1 
•
W
2
=1 
•
a
0
= -1 
•
Per a
1
=1 e a
2
= 1si ha: in=0.5 => 
 g(in)=1
  (funzione g a gradino) 
•
Per a
1
=1 e a
2
= 0 si ha: in=-0,5 => 
 g(in)=0   
19"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#19,19,"Porta OR
•
(Soglia t = 0.5)
•
 W
0
=0.5
•
W
1
=1
•
W
2
=1
•
a
0
= -1
•
Per a
1
=1 e a
2
= 1si ha: in=1.5 => 
 g(in)=1
  (funzione g a gradino)
•
Per a
1
=1 e a
2
= 0 si ha: in=0.5 => 
 g(in)=1
•
 Per a
1
=0 e a
2
= 0 si ha: in=-0.5 => 
 g(in)=0
20"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#2,2,"Il cervello
•Costituito da circa 1011 neuroni
•1014 sinapsi
•Segnali basati su potenziale elettrochimico
 Quando il potenziale 
sinaptico supera una certa 
soglia la cellula emette un 
impulso
3"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#20,20,"Porta NOT
•
(Soglia t = - 0.5)
•
 W
0
= - 0.5
•
W
1
= - 1
•
a
0
= -1
•
Per a
1
=1 => 
 g(in)=0
  (funzione g a gradino)
•
Per a
1
=0 si ha: in=0.5 => 
 g(in)=1
21"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#21,21,"Strutture di Rete
•
Ci sono due categorie principali di strutture di reti 
neurali:
•
Feed-forward 
 (o acicliche o alimentate in avanti)
•
Ricorrenti
  (o cicliche)
•
Noi ci occuperemo solo di reti feed-forward.
•
Esse sono una tipologia di reti neurali caratterizzate 
dall’avere un verso delle sinapsi, dallo strato di input allo 
strato di output.
22"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#22,22,"Esempio di Rete Feed-Forward
•
Una rete alimentata in avanti rappresenta una funzione dei 
suoi input:
a5
23"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#23,23,"•
L’output dell’intera rete 
 a
5
 è funzione dei suoi input 
 a 
•
I pesi 
 W
 agiscono da parametri della funzione. 
•
La rete calcola una funzione 
 f
W
(x) 
•
La funzione 
 f
W 
rappresenta una funzione dello 
 spazio 
delle ipotesi 
 H 
che può essere booleana o continua. 
•
Se i pesi vengono modificati, cambia la funzione 
rappresentata dalla rete. 
•
Le reti feed-forward sono in genere organizzate a strati, 
in modo tale che ogni unità riceva gli input solo dalle 
unità dello strato immediatamente precedente.
Esempio di Rete Feed-Forward
24"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#24,24,"•
Si tratta di una rete feed-forward in cui 
 tutti
 gli input sono 
collegati direttamente a 
 tutti
 gli output.
•
Esempio:
• 3 unità di output
• 5 unità di input
• 1 unità di output
• 2 unità di input
Reti Feed-Forward a Strato Singolo 
(percettroni)
25"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#25,25,"•
Esaminiamo lo spazio delle ipotesi che un percettrone 
può rappresentare.
•
Se ha una funzione di attivazione a soglia, si può 
pensare che il percettrone rappresenti una funzione 
booleana. 
•
Oltre alle funzioni elementari AND, OR e NOT viste 
prima, un percettrone può rappresentare funzioni 
booleane “complesse” in modo molto compatto. 
•
Vedi, ad esempio, la 
 funzione di maggioranza
 .
Reti Feed-Forward a Strato Singolo 
(percettroni)
26"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#26,26,"La Funzione di Maggioranza
•
Percettrone a soglia 
•
Restituisce 1 se e solo se più della metà dei suoi 
 n
 input binari 
vale 1 
•
Basta porre: W
j
=1 per ogni input e W
0
=n/2 
•
Un albero di decisione necessiterebbe di 
 O(2
n
)
 nodi per 
rappresentare la stessa funzione. 
27"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#27,27,"•Un percettrone a soglia non può rappresentare tutte le 
funzioni booleane. 
•Infatti restituisce 1 se e solo se la somma pesata dei suoi 
input è positiva: 
•L’equazione                 deﬁnisce un iperpiano  nello spazio 
degli input. 
•Il percettrone restituisce 1 se e solo se l’input si trova da 
una parte speciﬁca rispetto a tale iperpiano. 
•Per questo il percettore a soglia è chiamato anche 
separatore lineare .nX
j=0Wjxj>0 oppure:
Separabilità Lineare di un Percettrone a Soglia
WT·x>0
<latexit sha1_base64=""d9P2mD7Jg+O+gyHjQQ5KI5NUFrA="">AAACFnicbVC7TsNAEDyHVwgvAyXNKRESVWQHJKhQBA1lkPKSkhCdL5twyvmhuzVKZKXnE/gKWqjoEC0tBf+CbYwECVONZna1O+MEUmi0rA8jt7S8srqWXy9sbG5t75i7e03th4pDg/vSV22HaZDCgwYKlNAOFDDXkdByxpeJ37oDpYXv1XEaQM9lI08MBWcYS32z2EWYoDOMWrObOu3ygY/0R5rM6Dm1Cn2zZJWtFHSR2BkpkQy1vvnZHfg8dMFDLpnWHdsKsBcxhYJLmBW6oYaA8TEbQSemHnNB96I0y4wehpqhTwNQVEiaivB7I2Ku1lPXiSddhrd63kvE/7xOiMOzXiS8IETweHIIhYT0kOZKxCUBHQgFiCz5HKjwKGeKIYISlHEei2HcWtKHPZ9+kTQrZfu4XLk+KVUvsmby5IAUyRGxySmpkitSIw3CyT15JE/k2XgwXoxX4+17NGdkO/vkD4z3LwRxnsk=</latexit>
WT·x=0
<latexit sha1_base64=""ChE2zA/JsnaGrMeC8O8z0h7ASAE="">AAACFnicbVC7SgNBFJ2Nrxhfq5Y2Q4JgFXajoI0QtLGMkBckMcxObuKQ2QczdyVhSe8n+BW2WtmJra2F/+LuuoImnupwzr3ce44TSKHRsj6M3NLyyupafr2wsbm1vWPu7jW1HyoODe5LX7UdpkEKDxooUEI7UMBcR0LLGV8mfusOlBa+V8dpAD2XjTwxFJxhLPXNYhdhgs4was1u6rTLBz7SH2kyo+fUKvTNklW2UtBFYmekRDLU+uZnd+Dz0AUPuWRad2wrwF7EFAouYVbohhoCxsdsBJ2YeswF3YvSLDN6GGqGPg1AUSFpKsLvjYi5Wk9dJ550Gd7qeS8R//M6IQ7PepHwghDB48khFBLSQ5orEZcEdCAUILLkc6DCo5wphghKUMZ5LIZxa0kf9nz6RdKslO3jcuX6pFS9yJrJkwNSJEfEJqekSq5IjTQIJ/fkkTyRZ+PBeDFejbfv0ZyR7eyTPzDevwAC357I</latexit>
28"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#28,28,"• Percettrone elementare (senza strati nascosti): non può classificare 
pattern che non siano linearmente separabili.
• Questi casi però sono frequenti: ad esempio problema dello XOR .
• Caso particolare della classificazione di punti nell’ipercubo unitario: 
ogni punto è in classe 0 o in classe 1.
• Per lo XOR si considerano gli angoli del quadrato unitario (i punti 
(0,0), (0,1), (1,0) e (1,1))
Separabilità Lineare di un Percettrone a Soglia
29"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#29,29,"Marvin Minsky
Limiti del Percettrone 
30"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#3,3," Warren Sturgis McCulloch  (1899 – 1969) Neurofisiologo e cibernetico 
americano.  
 Walter Pitts  (1923 – 1969) fu un logico che lavorò nel campo della 
psicologia conoscitiva.  
Primo modello matematico di una cellula nervosa descritto in un famoso 
articolo: A Logical Calculus of the Ideas Immanent in Nervous Activity 
(1943).  
 Nello scritto del 1943 tentarono di dimostrare che il programma della 
macchina di Turing poteva essere effettuato anche in una rete finita di 
neuroni  e che il neurone fosse l’unità logica di base del cervello. I pionieri
4"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#30,30,"Marvin Minsky
1969 : Minsky e Papert, Perceptrons
Limiti del Percettrone 
31"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#31,31,"Apprendimento nel Percettrone
•
Nonostante il loro potere espressivo limitato, esiste un semplice 
algoritmo di apprendimento capace di adattare un percettrone a 
soglia a qualsiasi insieme di addestramento linearmente 
separabile (noi vedremo una versione dell’algoritmo per 
l’apprendimento nei percettroni a sigmoide). 
•
L’idea base dell’algoritmo è quella di calcolare i pesi della rete in 
modo tale da minimizzare una determinata funzione di costo 
sull’insieme di training. 
•
In tal modo il processo di apprendimento è formulato come una 
ricerca di ottimizzazione nello spazio dei pesi.
32"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#32,32,"•
La funzione di costo sull’insieme di training che viene usata 
tradizionalmente è la 
 somma dei quadrati degli errori
 , dove 
il singolo errore è la differenza tra l’output desiderato y e 
l’output della rete f
W
(
x
)
. 
Il quadrato dell’errore per un singolo 
esempio di training è il seguente: 
essendo 
 x
 il vettore relativo ai dati di input dell’esempio,            
y il valore corretto della funzione di output e f
 w
(
x
) il valore di 
output ottenuto dalla rete avente in input 
 x
.
E=1
2Err2=1
2(y fw(x))2
Apprendimento nel Percettrone
33"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#33,33,"Possiamo usare tale metodo per ridurre il quadrato dell’errore 
(ricerca del minimo globale) calcolando la derivata parziale di E 
rispetto ad ogni peso:
dove g’ è la derivata della funzione di attivazione.
Per la sigmoide:
Metodo della Discesa del Gradiente
34"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#34,34," α = step size  o tasso di apprendimento .Il peso deve essere aggiornato in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E vista in precedenza:
L’aggiornamento del peso è pertanto il seguente:
Metodo della Discesa del Gradiente
35"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#35,35,"Algoritmo completo di apprendimento 
a discesa di gradiente per percettroni
Metodo della discesa del gradiente
36"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#36,36," Gli esempi di addestramento vengono fatti passare attraverso la 
rete uno per volta, modificando leggermente i pesi a ogni 
iterazione per ridurre l’errore.  
 Ogni ciclo attraverso tutti gli esempi prende il nome di epoca . 
 Le epoche sono ripetute secondo un ben preciso criterio di 
terminazione (e.g., quando le modifiche dei pesi sono piccole). 
Altri metodi calcolano il gradiente per l’intero training set, 
sommando tutti i contributi dati dall’equazione precedente prima 
di aggiornare i pesi. 
Metodo della Discesa del Gradiente
37"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#37,37,"Percettrone a soglia
 Per percettroni a soglia  la g’(in)  è indefinita.
 In questo caso la regola di apprendimento del percettrone 
originale sviluppata da Rosenblatt (1957) è la seguente:
Essa è simile a quella vista, tranne per il fatto che la g’(in) è 
omessa. 
Poiché g’(in) è la stessa per tutti i pesi, la sua omissione 
cambia solo la dimensione e non la direzione 
dell’aggiornamento globale dei pesi.
38"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#38,38,"Il Percettrone di Rosemblatt
39"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#39,39,"Reti Feed-Forward Multistrato
 Si tratta di reti con unità nascoste, in cui esiste un 
verso di propagazione del segnale dall’input 
all’output. 
 Ciascun nodo dello strato i-mo è collegato con tutti 
i nodi dello strato i+1-mo. 
 Percettrone multistrato . 
40"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#4,4,"John McCarthy ha indicato il lavoro di Nicolas Rashevsky  (1936, 
1938) come il primo modello matematico di apprendimento neurale. 
 Alan Turing  (1948) scrisse un rapporto di ricerca intitolato Intelligent 
Machinery  che inizia con la frase "" I propose to investigate the 
question as to whether it is possible for machinery to show intelligent 
behaviour "" e prosegue descrivendo un'architettura di rete neurale 
ricorrente che ha definito "" B-type unorganized machines  ""e un 
approccio per addestrarla. 
Sfortunatamente, tale rapporto non è stato pubblicato fino al 1969 ed 
è stato quasi ignorato fino a poco tempo fa.I pionieri
5"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#40,40,"Esempio di Rete Neurale Feed-Forward Multistrato 
41"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#41,41,"Spazio delle ipotesi H per il  
percettrone multistrato
•
Il vantaggio di aggiungere strati nascosti è quello di 
ampliare lo spazio delle ipotesi rappresentabili dalla rete. 
•
Possiamo infatti considerare ogni unità nascosta come un 
percettrone che rappresenta una funzione a soglia 
morbida nello spazio di input (vedi figura seguente). 
•
Ogni unità di output può dunque rappresentare una 
combinazione lineare (a soglia morbida) di molte 
funzioni simili.
42"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#42,42,"Output di un Percettrone  
a due Input (con sigmoide)
43"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#43,43,"• Fig. (a): cresta  prodotta da due funzioni a 
soglia morbida rivolte in direzioni opposte 
e limitando il risultato con un’altra soglia.
• Fig. (b): protuberanza  prodotta dalla 
combinazione di due creste ad angolo retto 
(cioè, combinando le uscite di quattro unità 
nascoste).
(a) (b)⇓
Combinazione di Funzioni  
a Soglia Morbida
fw(x 1,x2) fw(x 1,x2)
44"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#44,44,"Con un solo strato nascosto sufficientemente grande 
possiamo rappresentare qualsiasi funzione continua degli 
input con accuratezza arbitraria. 
Con due strati nascosti possono essere rappresentate anche 
funzioni discontinue (il numero delle unità nascoste cresce 
esponenzialmente con il numero degli input).
Purtroppo, data una qualsiasi struttura di rete prefissata , è 
difficile stabilire esattamente quali funzioni possano essere 
rappresentate e quali non possano esserlo.
Reti Feed-Forward Multistrato
45"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#45,45,"Apprendimento nelle Reti  
Multistrato Feed-Forward 
Gli algoritmi per l’apprendimento per le reti multistrato sono 
simili all’algoritmo di apprendimento per i percettroni visto in 
precedenza.
Una differenza è costituita dal fatto che nelle reti multistrato 
avremo in generale più unità di output.
Ciò comporta che avremo un vettore di output fw(x) calcolato 
dalla rete anziché un valore singolo e, per ogni esempio, un 
vettore di output y.
46"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#46,46,"•L’idea base rimane la stessa, che è quella di calcolare i pesi della 
rete in modo da minimizzare la somma dei quadrati degli errori che, 
per un singolo esempio, è definita come segue:
•Dato un certo esempio, il vettore di errore in output è il seguente:
•Indichiamo come segue l’i-esimo componente del suddetto vettore:
•E’ inoltre utile definire come segue un errore modificato:
 
Apprendimento nelle Reti  
Multistrato Feed-Forward 
y fw(x)
47"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#47,47,"Back-propagation
 : strato di output
Per lo strato di output, il peso deve essere aggiornato
 in questo modo:
L’idea è quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 52 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
48"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#48,48,"Back-propagation
 : strato nascosto  
(versione intuitiva)
Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
Dobbiamo però definire una quantità analoga all’errore per i nodi di 
output.
E’ a questo punto che entra in gioco la retropropagazione :
L’idea  è  che  il  nodo  nascosto  j  sia  “responsabile”  per  una  parte  
dell’errore ∆i in ognuno dei nodi di output ai quali è collegato.
In tal modo i valori ∆ sono suddivisi in base alla forza delle connessioni 
tra nodo nascosto e nodo di output e passati all’indietro per fornire i 
valori ∆j allo strato nascosto.
49"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#49,49,"La regola di propagazione per i valori       è dunque la seguente:
L’aggiornamento del peso è pertanto il seguente, identica a quella 
che riguarda lo strato di output:
Back-propagation
 : strato nascosto  
(versione intuitiva)
50"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#5,5,"Da altri
neuroni
Unità di Calcolo nelle Reti Neurali
6"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#50,50,"Anche per lo strato nascosto il generico peso deve essere aggiornato in 
questo modo:
L’idea è, di nuovo, quella di modificare il peso proporzionalmente 
al negativo della derivata dell’errore E 
(vedi lucido n. 53 per i dettagli della derivazione ):
L’aggiornamento del peso è pertanto il seguente:
Back-propagation
 : strato nascosto  
(versione formale)
51"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#51,51,"Calcolo del gradiente  
(strato di output)
52"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#52,52,"Calcolo del gradiente  
(strato nascosto)
53"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#53,53,"Processo di Retropropagazione
In sintesi, il processo di retropropagazione può essere descritto 
come segue: 
•
Si calcolano i valori 
 ∆ 
per le unità di output usando l’errore 
osservato. 
•
Cominciando dallo strato di output, si ripete quanto segue per 
ogni strato della rete fino a raggiungere l’ultimo strato 
nascosto: 
o
si propagano all’indietro i valori ∆ verso lo strato 
precedente; 
o
si aggiornano i pesi tra i due strati.
54"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#54,54,"Back-propagation
1. Presentazione pattern d’ingresso 
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
55"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#55,55,"Unità di input akUnità di output ai
Unità nascoste aj2. Propagazione dell’input in avanti sullo strato nascosto 
Wk,jWj,i
Back-propagation
56"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#56,56,"3. Propagazione dallo strato nascosto allo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
57"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#57,57,"4. Calcolo dei valori DELTA per lo strato di output
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
58"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#58,58,"5. Retropropagazione dell’errore
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
L’errore si retropropaga  su 
ciascun nodo proporzionalmente  
alla forza  di connessione tra il 
nodo nascosto e il nodo di output
Back-propagation
59"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#59,59,"6. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
60"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#6,6," Ogni unità i calcola per prima cosa una somma pesata 
dei propri input:
 Successivamente si applica una funzione di attivazione  
g alla somma per derivare l’output:
Unità di Calcolo nelle Reti Neurali
ini=nX
j=1Wj,iaj
<latexit sha1_base64=""eWDCyQ6ONiLa3NNG6gCYSqPL4Ko="">AAACI3icbVC7TsNAEDzzDOEVoKQ5ESFRoGADEjRIETSUIBGCFAdrfSxwcD5bd2sEsvwZfAJfQQsVHaKh4F+4hBS8phrN7Gp3Js6UtOT7797Q8Mjo2Hhlojo5NT0zW5ubP7ZpbgS2RKpScxKDRSU1tkiSwpPMICSxwnZ8vdfz2zdorEz1Ed1l2E3gQstzKYCcFNXWQsJbt1dIXUaS73Ae2jyJiqudoDwtdMnbjq/KkoerHKIrHtXqfsPvg/8lwYDU2QAHUe0jPEtFnqAmocDaTuBn1C3AkBQKy2qYW8xAXMMFdhzVkKDtFv1gJV/OLVDKMzRcKt4X8ftGAYm1d0nsJhOgS/vb64n/eZ2czre7LnOWE2rRO0RSYf+QFUa6xpCfSYNE0PscudRcgAEiNJKDEE7MXYVV10fwO/1fcrzeCDYa64eb9ebuoJkKW2RLbIUFbIs12T47YC0m2D17ZE/s2XvwXrxX7+1rdMgb7CywH/A+PgGXqaO/</latexit>
ai=g(ini)=g0
@nX
j=1Wj,iaj1
A
<latexit sha1_base64=""L8MWGsH2A4rKpI1HGBXATIbImqQ="">AAACOnicbVDBShxBEO3RxOjG6MYcvTRZAivIMqOB5CKIguRoIOsKO+tQ09aOpT09Q3dNUIb5o3xCvsKbJF68idd8QHo3e0g07/R4rx5V9dJSk+MwvAnm5p89X3ixuNR6ufxqZbX9eu3IFZVV2FeFLuxxCg41Gewzscbj0iLkqcZBerE/8Qdf0ToqzBe+KnGUQ2ZoTArYS0n7ABKSOzLrxoyXPl+TaRLa8JLMYo1j7srYVXlSn+9EzUltGjnwfJMaGW9KSM5jS9kZbyTtTtgLp5BPSTQjHTHDYdK+jU8LVeVoWGlwbhiFJY9qsExKY9OKK4clqAvIcOipgRzdqJ7+28h3lQMuZIlWkpZTEf9O1JA7d5WnfjIHPnOPvYn4P29Y8fjjyFdQVoxGTRYxaZwucsqSLxLlKVlkhsnlKMlIBRaY0ZIEpbxY+WZbvo/o8fdPydFWL9rubX1+39ndmzWzKNbFW9EVkfggdsUncSj6Qolv4lr8ED+D78FdcB88/BmdC2aZN+IfBL9+A3R4rDw=</latexit>
7"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#60,60,"7. Aggiornamento dei pesi
Unità di input akUnità di output ai
Unità nascoste aj
Wk,jWj,i
Back-propagation
61"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#61,61,"Esempio di Esecuzione
• Vediamo un esempio di esecuzione dell’algoritmo di Back-
propagation applicato sulla seguente rete:
a1 a2
0 1U1 U2
1 1U3 U4U5
1a5
W3,5=1.5 W4,5=-1.0
a3 a4
W1,3=1 W2,4=2W1,4=-1 W2,3=0.51 11Target = 1
Output Layer
Hidden Layer
Input Layer
62"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#62,62,"Esempio di Esecuzione
•Eseguiamo l’algoritmo su un solo esempio di addestramento e, per il 
quale dunque conosciamo l’output corretto ( Target = 1 ) a fronte di un 
certo input  X.
• Supponiamo che i valori dell’input per l’esempio e in questione 
siano i seguenti:
•  Input U1: 
•  Input U2:  
63"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#63,63,"Esempio di Esecuzione
1. Presentazione del pattern in ingresso :
64"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#64,64,"Esempio di Esecuzione
2. Passo Feed-Forward ( hidden layer ):
65"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#65,65,"Esempio di Esecuzione
3. Passo Feed-Forward ( output layer ):
66"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#66,66,"Esempio di Esecuzione
• A fronte di questo risultato in uscita possiamo calcolare il quadrato 
dell’errore:  
• L’errore non è molto alto, ma applicando l’algoritmo alla rete 
possiamo cercare di ridurlo.  
67"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#67,67,"Esempio di Esecuzione
4. Calcolo del valore ∆ in uscita ( output layer ):
68"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#68,68,"Esempio di Esecuzione
  5. Passo di Backward Propagation dell’errore ( hidden layer ):
69"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#69,69,"Esempio di Esecuzione
6. Passo di aggiornamento dei pesi ( link in ingresso all’output layer ):
70"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#7,7,"Unità di Calcolo nelle Reti Neurali
Usando funzioni diverse come 
 g
 si possono ottenere 
modelli differenti. Ad esempio:
g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
Funzione a gradino:
g(in i) = tanh(in i)
<latexit sha1_base64=""Cms3QN8iP8ejsRthjNVvwV/Syf0="">AAACH3icbVDLSgNBEJz1GeMr6tHLYBAUIexGQS9C0ItHBRMDSQi9Y5sMmZ1dZnrFEPIRfoJf4VVP3sSrB//F3c0ejFqnmqpueqr8SElLrvvpzMzOzS8sFpaKyyura+uljc2GDWMjsC5CFZqmDxaV1FgnSQqbkUEIfIU3/uA89W/u0VgZ6msaRtgJoKflnRRAidQtHfT22oQPNJJ63JX7nJ/yyZtA98dTXrFbKrsVNwP/S7yclFmOy27pq30bijhATUKBtS3PjagzAkNSKBwX27HFCMQAethKqIYAbWeUhRrz3dgChTxCw6XimYg/N0YQWDsM/GQyAOrb314q/ue1Yro76SSZophQi/QQSYXZISuMTNpCfisNEkH6c+RScwEGiNBIDkIkYpzUl/bh/U7/lzSqFe+wUr06KtfO8mYKbJvtsD3msWNWYxfsktWZYI/smb2wV+fJeXPenY/J6IyT72yxKTif33PtosY=</latexit>
 Tangente iperbolica:
Sigmoide: g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>
ReLU:g(in i) = max(in i,0)
<latexit sha1_base64=""fdZuD83MuMKqvRY6gR2pKYYhfhM="">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>
8"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#70,70,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
71"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#71,71,"Esempio di Esecuzione
7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):
72"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#72,72,"Esempio di Esecuzione
• Ciò completa l’aggiornamento dei pesi per il training example 
corrente.
• Per verificare che l’algoritmo abbia effettivamente ridotto 
l’errore in output, eseguiamo la parte feed-forward ancora una 
volta per confrontare l’uscita attuale con la precedente.
73"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#73,73,"Esempio di Esecuzione
• Nuovo  Passo Feed-Forward ( hidden layer ):
74"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#74,74,"Esempio di Esecuzione
• Nuovo Passo Feed-Forward ( output layer ):
75"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#75,75,"Esempio di Esecuzione
• Il nuovo quadrato dell’errore è il seguente:
• La differenza con il vecchio valore è:
76"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#76,76,"Esempio di Esecuzione
• L’esecuzione dell’algoritmo di Backpropagation che abbiamo 
visto è relativo ad un solo passaggio per un solo esempio di 
addestramento.  
• Si ricorda che l’algoritmo completo fa passare gli esempi di 
addestramento attraverso la rete uno per volta, modificando 
leggermente i pesi a ogni iterazione per ridurre l’errore.  
  
• Ogni ciclo attraverso tutti gli esempi prende il nome di epoca .  
• Le epoche sono ripetute fino a quando non viene soddisfatto un 
criterio di terminazione (in genere, quando le modifiche ai pesi 
sono diventate molto piccole).  
77"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#77,77,"Sintesi degli Argomenti 
Trattati nella Lezione 
Una Rete Neurale è un modello computazionale che presenta alcune proprietà del cervello: consiste di molte 
unità semplici che lavorano in parallelo senza alcun controllo centralizzato.  Le connessioni tra le unità hanno 
pesi numerici che possono essere modiﬁcati dall’elemento di apprendimento.  
Il comportamento di una rete neurale è determinato dalla topologia delle connessioni e dalla natura delle 
singole unità. Le reti alimentate in avanti  in cui le connessioni formano un grafo diretto aciclico, sono le più 
semplici da analizzare. Le reti alimentate in avanti implementano funzioni senza stato. 
Un percettrone è una rete alimentata in avanti con un singolo strato di unità e può rappresentare solo funzioni 
linearmente separabili . Se i dati sono linearmente separabili si può utilizzare la regola di apprendimento del 
percettrone  per modiﬁcare i pesi della rete in modo da farli corrispondere esattamente ai dati. 
Le reti alimentate in avanti multistrato possono rappresentare qualsiasi funzione, dato un sufﬁciente numero di 
unità. 
L’algoritmo di apprendimento backpropagation (propagazione all’indietro ) funziona su reti multistrato 
alimentate in avanti effettuando una discesa del gradiente nello spazio dei pesi per minimizzare l’errore in 
uscita. Esso converge a una soluzione localmente ottima ed è stato usato con successo in un’ampia varietà di 
applicazioni. La sua convergenza è spesso molto lenta.
78"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#8,8,"Funzione Gradino
g
t0g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
ini
9"
data_test\rootfolder\università\MachineLearning\26-Reti-Neurali-sbloccato.pdf#9,9,"Sigmoide
g
01g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>
ini
10"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 11)
1"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Richiami percettrone e MLP 
Sci-kit learn e percettrone 
MLP e regressione 
MLP e classiﬁcazione 
Keras 
Esempio fashion_mnist 
Keras: Sequential models, parametri, metriche, training, predizione"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Richiami: Multi-Layer Perceptron (MLP)
Perché è fondamentale inserire una funzione di attivazione? 
Se combiniamo diversi layer e unità otteniamo semplicemente una 
sequenza di combinazioni lineari, perciò una trasformazione lineare 
input-output. È come ottenere un singolo layer. Non possiamo 
rappresentare funzioni complesse non lineari.
11"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché nella MLP si preferisce la funzione logistica (o sigmoide) 
alla funzione gradino (o step function)?
12g(in i)=⇢1i f i n i t
0i f i n i<t
<latexit sha1_base64=""3dhiPmh/49rcUH3TuNXPStviJU0="">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>
Funzione a gradino:
Sigmoide: g(in i)=1
1+e ini
<latexit sha1_base64=""of82qDQd5scNysrZocadTZaCmmw="">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Richiami: Multi-Layer Perceptron (MLP)
Perché nella MLP si preferisce la funzione logistica (o sigmoide) alla 
funzione gradino (o step function)? 
Con la funzione gradino i gradienti genererebbero una superﬁcie piatta, 
che non permetterebbe di adattare i parametri. 
La funzione logistica è deﬁnita ed ha derivata ovunque.  
La ReLU non è differenziabile per 
 in=0
, e ha derivata 0 per 
 in<0
. Ma 
empiricamente mostra buone performance ed è rapido il calcolo della 
derivata. Inoltre non avendo un valore max in output riduce alcune 
problematiche nelle architetture più complesse.
13
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"MLP e regressione
Una MLP può essere usata per produrre un singolo valore, es. creando un 
layer di output con una singola unità. Nel caso di 
 multivariate regression
 , il 
layer può contenere più unità. 
Solitamente non si inserisce la funzione di attivazione in output in modo da 
non imporre intervalli. Se c'è bisogno di valori positivi si può inserire una 
ReLU
  o una 
 softplus activation function
  (una versione smooth della ReLU). 
La loss function usata durante il training è la 
 mean squared error
 . Nel caso 
di molti outlier nel training set è possibile considerare anche la 
 mean 
absolute error
 . La Huber loss è una combinazione di entrambe.
14"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"MLP e regressione: architettura tipica
Conﬁgurazione tipica degli iperparametri di una MLP usata per la 
regressione:
15
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"MLP e classiﬁcazione
Inserendo un layer con una singola unità e con funzione di attivazione 
logistica possiamo stimare la probabilità di appartenenza dell'input a una 
certa classe (binary classiﬁcation). Nel caso 
 multilabel binary classiﬁcation
 , 
(es. email spam/no_spam, urgent/no_urgent) si avranno più unità di output. 
Se una istanza può appartenere ad una di n possibili classi (es. una cifra da 
0 a 9), l'output layer conterrà n unità con una funzione 
 softmax
  che 
garantisce che ogni unità produca una probabilità la cui somma sia 1. In 
questo caso si impiega la 
 cross-entropy
  come funzione di loss. 
16
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"Keras
Keras (
 https://keras.io
 ) 
sono API per il Deep Learning ad alto livello per 
costruire ed addestrare architetture di reti neurali. 
Si basa a sua volta su librerie che permettono di eseguire le reti su varie 
piattaforme, es. TensorFlow, Microsoft Cognitive Toolkit (CNTK), Theano; 
Apache MXNet, Apple’s Core ML, Javascript o Typescript (Keras code in 
web browsers), or PlaidML (on GPUs). 
TensorFlow integra Keras e lo arricchisce di altre funzionalità (es. 
TensorFlow’s Data API) 
Installazione (via PIP):  
python3 -m pip install --upgrade tensorﬂow
17"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Keras: esempio 
 fashion_mnist
Entrambe le versioni corrispondono alla 2.8.0 
import
 tensorflow 
 as
 tf
from
 tensorflow 
 import
 keras
print
(tf.__version__)
print
(keras.__version__)
Impieghiamo il dataset fashion_mnist: 
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
print
(X_train_full.shape)
print
(X_train_full.dtype)
>> (60000, 28, 28)
>> uint8
X_valid, X_train = X_train_full[:
 5000
] / 
255.0
, X_train_full[
 5000
:] / 
255.0
y_valid, y_train = y_train_full[:
 5000
], y_train_full[
 5000
:]
class_names = [
 ""T-shirt/top""
 , 
""Trouser""
 , 
""Pullover""
 , 
""Dress""
, 
""Coat""
,
""Sandal""
 , 
""Shirt""
, 
""Sneaker""
 , 
""Bag""
, 
""Ankle boot""
 ]
print
(class_names[y_train[
 0
]])
>> 
'Coat'
18"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Keras: sequential models
Il modello 
 Sequential
  è il più semplice e consiste in una singolo stack di 
layers connessi sequenzialmente: 
model = keras.models.Sequential()
# converto le istanze in input in array 1D
# equivale a una operazione: X.reshape(-1,1)
# è obbligatorio specificare il input_shape
model.add(keras.layers.Flatten(input_shape=[
 28
, 
28
]))
# layer denso con 300 unità e ReLU come activation function
# ogni layer contiene i propri parametri (pesi e bias) riferiti alle 
connessioni
# con il layer precedente
model.add(keras.layers.Dense(
 300
, activation=
 ""relu""
))
# layer denso di 100 unità
model.add(keras.layers.Dense(
 100
, activation=
 ""relu""
))
# layer di output con 10 unità (una per classe) e softmax activation function
model.add(keras.layers.Dense(
 10
, activation=
 ""softmax""
 ))
19"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Keras: sequential models
In alternativa, invece di creare un layer alla volta, possiamo passare una 
lista al costruttore:  
model = keras.models.Sequential([
keras.layers.Flatten(input_shape=[
 28
, 
28
]),
keras.layers.Dense(
 300
, activation=
 ""relu""
),
keras.layers.Dense(
 100
, activation=
 ""relu""
),
keras.layers.Dense(
 10
, activation=
 ""softmax""
 )
])
Sono possibile varie forme di import, tutte equivalenti: 
from 
keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow.keras.layers 
 import 
Dense
output_layer 
 = 
Dense
(
10
)
from 
tensorflow 
 import 
keras
output_layer 
 = 
keras
.
layers
.
Dense
(
10
)
20"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Richiami: Percettrone
Una delle architetture più semplici, dove un singolo layer è connesso con 
tutti gli input dello strato precedente (
 fully connected 
 o
 dense layer
 ), cioè 
l'
input layer
 : 
Nota
 : nei precedenti lucidi si è usata la notazione dove gli input 
 x
 sono 
anche indicati con la lettera 
 a
. La step function 
 step()
  corrisponde alla 
funzione di attivazione 
 g(in).
3
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Keras: parametri
Per monitorare l'architettura creata usiamo la funzione summary():  
model
.
summary()
Nota: i layer densi contengono molti parametri (es. 235.500!)
21
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Keras: parametri
Per accedere ai singoli layers usiamo il parametro 
 layers
 , e le funzioni 
get_weights
 () e 
set_weights
 (): 
>>> 
model
.
layers
[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,
<tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,
<tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,
<tensorflow.python.keras.layers.core.Dense at 0x13240d240>]
>>> 
model
.
layers
[
1
]
.
name
'dense_3'
>>> 
model
.
get_layer
 (
'dense_3'
 )
.
name
'dense_3'
>>> 
weights
, 
biases 
= 
hidden1
.
get_weights
 ()
>>> 
weights
array([[ 0.03854964, -0.04054524, 0.00599282, ..., 0.02566582,
0.01032123, 0.06914985],
...,
[ 0.02632413, -0.05105981, -0.00332005, ..., 0.04175945,
0.0443138 , -0.05558084]], dtype=float32)
>>> 
weights
.
shape
(784, 300)
>>> 
biases
array([0., 0., 0., 0., 0., 0., 0., 0., 0., ..., 0., 0., 0.], dtype=float32)
>>> 
biases
.
shape
(300,)
22"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Keras: parametri
A cosa può servire una funzione set_weights()?
23"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Keras: parametri
A cosa può servire una funzione set_weights()? 
Possiamo operare regolarizzazioni manuali, oppure sovrascrivere i 
valori iniziali random con valori ottenuti da precedenti fasi di training. 
Per impiegare altri criteri di inizializzazione dei kernel (cioè delle matrici 
dei parametri della rete) consultare 
 https://keras.io/initializers/
24"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Keras: metriche
La funzione compile() prende in input la 
 loss 
function
  e il 
optimizer
 , cioè 
l'algoritmo per stimare i parametri, ed eventuali altri parametri, come la 
metrica per stimare l'errore:  
model
.
compile
(
loss
=
""sparse_categorical_crossentropy""
 ,
optimizer
 =
""sgd""
,
metrics
=
[
""accuracy""
 ])
Dove:  
loss=""sparse_categorical_crossentropy"" è equivalente a  
loss=keras.losses.sparse_categorical_crossentropy.  
optimizer=""sgd"" è equivalente a optimizer=keras.optimizers.SGD()  
metrics=[""accuracy""] è equivalente a 
metrics=[keras.metrics.sparse_categorical_accuracy]  
Per una lista completa consultare 
 https://keras.io/losses/  
https://keras.io/
optimizers/
   e  
https://keras.io/metrics/  
25"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"Keras: metriche
Nell'esempio impieghiamo 
 sparse_categorical_crossentropy
  loss perché 
abbiamo label sparse, cioè per ogni istanza abbiamo solo una target class 
da 0 a 9, e ogni classe è esclusiva.  
Se avessimo avuto un target on vettore di 10 reali, es [0,0,...,1.0,...,0] 
avremmo dovuto impiegare la 
 categorical_crossentropy 
 loss. Per convertire 
label sparse in vettori impiegare 
 keras.utils.to_categorical()
 . 
Per la binary classiﬁcation avremmo usato la 
 sigmoid
  activation invece 
della softmax, e la 
 binary_crossentropy
  loss.
26"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Keras: training
Inﬁne non ci resta che addestrare il modello: 
# il validation set è opzionale
>>> 
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
... 
validation_data
 =
(
X_valid
, 
y_valid
))
...
Train on 55000 samples, validate on 5000 samples
Epoch 1/30
55000/55000 [==========] - 3s 55us/sample - loss: 1.4948 - acc: 0.5757
- val_loss: 1.0042 - val_acc: 0.7166
Epoch 2/30
55000/55000 [==========] - 3s 55us/sample - loss: 0.8690 - acc: 0.7318
- val_loss: 0.7549 - val_acc: 0.7616
[...]
Epoch 50/50
55000/55000 [==========] - 4s 72us/sample - loss: 0.3607 - acc: 0.8752
- val_loss: 0.3706 - val_acc: 0.8728
Otteniamo una accuracy del 87% sul validation set dopo 50 epoche, simile 
all'accuracy del training set, perciò non dovrebbe esserci overﬁtting. 
27"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Keras: training
Sel nel dataset ci sono classi meno frequenti di altre, si può impiegare il 
parametro 
 class_weight
  nella funzione 
 ﬁt
() in modo da diminuire l'effetto 
delle classi più rappresentate.  
Si può fare lo stesso ma per le singole istanze col parametro 
 sample_weight 
Il parametro 
 history
  è creato dopo il ﬁt, e contiene un oggetto 
 History
  con 
dati utili relativi all'addestramento: 
import 
pandas 
as 
pd
pd
.
DataFrame
 (
history
.
history
)
.
     
plot
(
figsize
=
(
8
, 
5
))
plt
.
grid
(
True
)
# set the vertical range to [0-1]
plt
.
gca
()
.
set_ylim
 (
0
, 
1
) 
plt
.
show
()
Cosa puoi dire dal graﬁco?
28
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Keras: training
Conferma il probabile scarso overﬁtting.  
Al principio il modello si comporta meglio col validation set, ma spesso è 
dovuto al caso. 
Il ﬁtting termina con l'accuracy sul training leggermente migliori rispetto al 
validation, fenomeno che capita spesso per training lunghi. 
Il validation error è ancora in discesa quando termina il training. Conviene 
aumentare le epoche.
29
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#29,29,"Keras: training e test
Una volta terminato il training è possibile validare il modello sul test set: 
>>> 
model
.
evaluate
 (
X_test
, 
y_test
)
8832/10000 [==========================] - ETA: 0s - loss: 0.4074 - acc: 
0.8540
[0.40738476498126985, 0.854]
Le performance sono leggermente minori poiché gli iperparametri li 
abbiamo scelti in base al training e validation set. 
Ricordati di non modiﬁcarli in base al test set.
30"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Richiami: Percettrone
Un singolo percettrone, indicato anche con Threshold logic unit (TLU) o 
Linear threshold unit (LTU), può essere usato come classiﬁcatore.  
Se la combinazione lineare degli input è oltre una certa soglia l'output 
assumerà la classe ""positiva"", altrimenti ""negativa"". 
Il training consiste nel trovare i pesi 
 w
 (parametri). 
Una rappresentazione alternativa indica esplicitamente un layer 
passthtough
  per i valori in input, e una unità 
 bias
 che restituisce sempre 1. 
Nell'esempio ci sono 3 outputs, perciò 3 distinte classi binarie in output: 
4
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#30,30,"Keras: predizione
Una volta addestrato possiamo fare predizione: 
>>> 
X_new 
= 
X_test
[:
3
]
>>> 
y_proba 
 = 
model
.
predict
(
X_new
)
>>> 
y_proba
.
round
(
2
)
array([[0. , 0. , 0. , 0. , 0. , 0.09, 0. , 0.12, 0. , 0.79],
[0. , 0. , 0.94, 0. , 0.02, 0. , 0.04, 0. , 0. , 0. ],
[0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]],
dtype=float32)
Dall'esempio: class 9 (ankle boot) prob=79%, class 7 (sneaker) prob=12%, 
class 5 (sandal) prob=9% 
Se ci interessa solo la classe con probabilità più alta: 
>>> 
y_pred 
= 
model
.
predict_classes
 (
X_new
)
>>> 
y_pred
array([9, 2, 1])
>>> 
np
.
array
(
class_names
 )[
y_pred
]
array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')
31"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#31,31,"Esercizio
Impiegare il dataset MNIST (cifre numeriche) e una architettura simile 
all'esempio precedente.  
Valutare l'accuracy dopo 50 epoche. 
# import dataset
from
 keras.datasets 
 import
 mnist
# load dataset
(x_train, y_train),(x_test, y_test) 
 =
 mnist
.
load_data()
32
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#32,32,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
33"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Sci-kit learn: Perceptron
La classe Perceptron implementa un singolo TLU: 
import 
numpy 
as 
np
from 
sklearn.datasets 
 import 
load_iris
from 
sklearn.linear_model 
 import 
Perceptron
iris 
= 
load_iris
 ()
X 
= 
iris
.
data
[:, (
2
, 
3
)] 
# petal length, petal width
y 
= 
(
iris
.
target 
== 
0
)
.
astype
(
np
.
int
) 
# Iris Setosa?
per_clf 
 = 
Perceptron
 ()
per_clf
.
fit
(
X
, 
y
)
y_pred 
= 
per_clf
.
predict
([[
2
, 
0.5
]])
La classe Perceptron implementa un singolo TLU.  
L'apprendimento è basato sull'algoritmo Stochastic Gradient Descent, cioè 
sulla classe SGDClassiﬁer con i seguenti parametri: 
 loss
=""perceptron"", 
learning_rate
 =""constant"", 
 eta0
=1 (
learning rate
 ), and 
 penalty
 =None 
(
nessuna regolarizzazione
 ). Per ogni istanza in input i pesi sono aggiornati 
in base all'errore prodotto.
5"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Richiami: Multi-Layer Perceptron (MLP)
Al contrario della classiﬁcazione basata sulla logistic regression, il 
percettrone non produce probabilità, ma effettua predizioni in base ad una 
soglia preﬁssata. Per tale motivo si preferisce la logistic regression. 
Per stimare funzioni anche non lineare, si possono ""impilare"" più TLU 
raggruppati in singoli layer creando architetture 
 deep
 . Il ﬂusso dei segnali è 
monodirezionale (
 feedforward
 ).
6
"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Richiami: Multi-Layer Perceptron (MLP)
L'algoritmo per stimare i pesi è 
 backpropagation
  training algorithm ed è 
basato sul calcolo dei gradienti degli errori rispetto ad ogni singolo 
parametro (
 automatic differentation
  o 
autodiff
 ).  
In particolare viene impiegato il 
 reverse-mode autodiff
 , adatto quando ci 
sono molte connessioni (pesi) e pochi output. 
In sintesi si analizzano 
 mini-batch
  di istanze estratte dal training set (es. 32). 
Alla ﬁne di una 
 epoca
  si è analizzato l'intero dataset. Il processo itera ﬁno 
alla convergenza. 
Il mini-batch viene dato in input alla rete e per ogni istanza viene ricavato 
l'output (
 forward pass
 ).  
Per mezzo della loss function è ricavato l'errore commesso dalla rete. 
La 
chain rule
  determina quanto ogni output contribuisce all'errore. Il 
processo è ripetuto anche per i layer precedenti, ﬁno all'input (
 reverse pass
 ). 
Inﬁne il 
 gradient descent
  impiega tali error gradients per aggiornare i pesi.
7"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: L'inizializzazione dei pesi deve essere random. Se tutti i pesi e 
bias fossero impostati a 0 cosa accadrebbe?
8"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Richiami: Multi-Layer Perceptron (MLP)
L'inizializzazione dei pesi deve essere random. Se tutti i pesi e bias fossero 
impostati a 0 cosa accadrebbe? 
Tutte le unità di un layer si comporterebbero nello stesso modo.  
Il backpropagation inﬂuenzerebbe tutte le unità allo stesso modo. 
Potremmo avere 100ia di unità per layer, ma è come se ne avessimo 
una sola. 
L'assegnazione casuale dei pesi evita la simmetria e, il backpropagation 
""addestra"" gruppi di unità in modo diverso.
9"
data_test\rootfolder\università\MachineLearning\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Richiami: Multi-Layer Perceptron (MLP)
Domanda: Perché è fondamentale inserire una funzione di attivazione?
10"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reti Neurali (Ex 12)
1"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#1,1,"Sommario
Architetture non sequenziali e Keras 
Output multipli 
Keras: Modelli statici e dinamici  
Save & Restore 
Callbacks 
Early stopping 
TensorBoard 
Fine tuning degli iperparametri 
Numero hidden layers, numero nodi per layers 
TensorFlow playground"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#10,10,"Keras: Modelli dinamici
Si crea una subclass di 
 Model
 , nel costruttore si deﬁnisce il modello (cioè i 
layers) e nella funzione 
 call()
  si deﬁnisce come saranno elaborati i dati, e 
può comprendere loop, istruzioni if-else, etc. 
Per esempio, per il Wide & deep model: 
class 
WideAndDeepModel
 (
keras
.
models
.
Model
):
def 
__init__
 (
self
, 
units
=
30
, 
activation
 =
""relu""
, 
**
kwargs
):
super
()
.
__init__
 (
**
kwargs
) 
# standard args (e.g., name)
self
.
hidden1 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
hidden2 
 = 
keras
.
layers
.
Dense
(
units
, 
activation
 =
activation
 )
self
.
main_output 
 = 
keras
.
layers
.
Dense
(
1
)
self
.
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)
def 
call
(
self
, 
inputs
):
input_A
, 
input_B 
 = 
inputs
hidden1 
 = 
self
.
hidden1
(
input_B
)
hidden2 
 = 
self
.
hidden2
(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
main_output 
 = 
self
.
main_output
 (
concat
)
aux_output 
 = 
self
.
aux_output
 (
hidden2
)
return 
main_output
 , 
aux_output
model 
= 
WideAndDeepModel
 ()
11"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#11,11,"Keras: Modelli dinamici
I modelli dinamici hanno lo svantaggio che 
 non
 possono essere facilmente 
ispezionati da Keras, tantomeno essere salvati o clonati. 
Il metodo summary() restituisce una lista di layer ma non come sono 
connessi. 
12"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#12,12,"Keras: Save & Restore
Addestrare i modelli può richiedere molto tempo. È fondamentale poter 
salvare i parametri durante (
 checkpoints
 ) o alla ﬁne dell'addestramento. 
model
.
save
(
""my_keras_model.h5""
 )
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
Il salvataggio interessa i parametri, l'architettura, e gli iperparametri. 
Per il Model subclassing si usano le funzioni save_weights() e 
load_weights(), che interessano però solo i pesi.
13"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#13,13,"Keras: callbacks
È possibile deﬁnire una funzione 
 callback
  che verrà invocata al principio e 
alla ﬁne di ogni epoca, o batch. Nell'esempio la funzione 
ModelCheckpoint salva il modello a intervalli regolari (default: alla ﬁne di 
ogni epoca): 
[
...
] 
# dopo la compilazione del modello
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
 (
""my_keras_model.h5""
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
10
, 
callbacks
 =
[
checkpoint_cb
 ])
Se impiego un validation set, posso usare il parametro save_best_only=True 
in ModelCheckpoint per salvare il modello quando le prestazioni sono le 
migliori. Se interrompo e incomincio di nuovo l'addestramento, riparto 
dall'ultimo modello potenzialmente privo di overﬁtting. 
Si può deﬁnire la propria callback agganciandola agli eventi 
on_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_begin(), 
on_batch_end(), on_batch_end()
 , es.: 
class 
PrintValTrainRatioCallback
 (
keras
.
callbacks
 .
Callback
 ):
  
def 
on_epoch_end
 (
self
, 
epoch
, 
logs
):
      
print
(
""\nval/train: {:.2f}""
 .
format
(
logs
[
""val_loss""
 ] 
/ 
logs
[
""loss""
]))
14"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#14,14,"Keras: early stopping
Con la stessa tecnica possiamo interrompere il training se, dopo un certo 
numero di epoche (parametro 
 patience
 ), non ci sono incrementi di 
prestazioni tangibili: 
checkpoint_cb 
 = 
keras
.
callbacks
 .
ModelCheckpoint
                                    
 (
""my_keras_model.h5""
 ,
save_best_only
 =
True
)
early_stopping_cb 
 = 
keras
.
callbacks
 .
EarlyStopping
                                    
 (
patience
 =
10
, 
restore_best_weights
 =
True
)
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
                    
 validation_data
 =
(
X_valid
, 
y_valid
),
                    
 callbacks
 =
[
checkpoint_cb
 , 
early_stopping_cb
 ]) 
# rollback al best model 
model 
= 
keras
.
models
.
load_model
 (
""my_keras_model.h5""
 )
15"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#15,15,"TensorBoard
Un tool utile per visualizzare l'andamento dell'addestramento. Aggiorna la 
visualizzazione in base a un ﬁle binario chiamato event ﬁle.  
Si possono salvare i dati di ogni training in una directory distinta, così è 
possibile caricarli e confrontarli. Di seguito TensorBoard si occupa di 
creare la directory e salvarci i dati: 
root_logdir 
 = 
os
.
path
.
join
(
os
.
curdir
, 
""my_logs""
 )
def 
get_run_logdir
 ():
import 
time
run_id 
= 
time
.
strftime
 (
""run_
%Y
_
%m
_
%d
-
%H
_
%M
_
%S
""
)
return 
os
.
path
.
join
(
root_logdir
 , 
run_id
)
run_logdir 
 = 
get_run_logdir
 () 
# es. './my_logs/run_2019_01_16-11_28_43'
[
...
] 
# Build and compile your model
tensorboard_cb 
 = 
keras
.
callbacks
 .
TensorBoard
 (
run_logdir
 )
history 
 = 
model
.
fit
(
X_train
, 
y_train
, 
epochs
=
30
,
                    
 validation_data
 =
(
X_valid
, 
y_valid
), 
                    
 callbacks
 =
[
tensorboard_cb
 ])
16"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#16,16,"TensorBoard
TensorBoard può funzionare come server in locale: 
$ 
tensorboard --logdir
 =
./my_logs --port
 =
6006
TensorBoard 2.0.0 at http://mycomputer.local:6006 
 (
Press CTRL+C to quit
 )
Per l'interfacciamento con Colab consultare: 
https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/
docs/get_started.ipynb
17
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#17,17,"Fine tuning degli iperparametri
Rispetto ad altri modelli le reti neurali hanno numerosi iperparametri da 
deﬁnire. Un approccio spesso usato è quello di esplorare lo spazio delle 
conﬁgurazioni con le classi 
 GridSearchCV
  o 
RandomizedSearchCV.  
Deﬁniamo una funzione che prende in input gli iperparametri da 
ottimizzare:  
def 
build_model
 (
n_hidden
 =
1
, 
n_neurons
 =
30
, 
learning_rate
 =
3e-3
, 
input_shape
 =
[
8
]):
model 
= 
keras
.
models
.
Sequential
 ()
# necessario per far si che il primo layer sia inizializzato correttamente
options 
 = 
{
""input_shape""
 : 
input_shape
 }
for 
layer 
in 
range
(
n_hidden
 ):
model
.
add
(
keras
.
layers
.
Dense
(
n_neurons
 , 
activation
 =
""relu""
, 
**
options
))
options 
 = 
{}
model
.
add
(
keras
.
layers
.
Dense
(
1
, 
**
options
))
optimizer 
 = 
keras
.
optimizers
 .
SGD
(
learning_rate
 )
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
optimizer
 )
return 
model
...
18"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#18,18,"Fine tuning degli iperparametri
Dopodiché istanziamo una regressione per Keras; 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default.  
Abbiamo appena creato un modello, e possiamo seguire i soliti step: 
keras_reg
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
, 
              
 validation_data
 =
(
X_valid
, 
y_valid
),
              
 callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)])
mse_test 
 = 
keras_reg
 .
score
(
X_test
, 
y_test
)
y_pred 
= 
keras_reg
 .
predict
(
X_new
)
Qualsiasi parametro aggiuntivo passato a ﬁt() sarà inoltrato al modello 
Keras. 
19"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#19,19,"Fine tuning degli iperparametri
Miglioriamo l'esplorazione con un comportamento random, e deﬁnendo 
degli intervallo per i parametri impiegati: 
keras_reg 
 = 
keras
.
wrappers
 .
scikit_learn
 .
KerasRegressor
 (
build_model
 )
Non speciﬁcando altri parametri, build_model() userà quelli di default. 
Possiamo deﬁnire intervalli da cui campionare casualmente i valori degli 
iperparametri che abbiamo deﬁnito in build_model(): 
from 
scipy.stats 
 import 
reciprocal
from 
sklearn.model_selection 
 import 
RandomizedSearchCV
param_distribs 
 = 
{
""n_hidden""
 : [
0
, 
1
, 
2
, 
3
],
""n_neurons""
 : 
np
.
arange
(
1
, 
100
),
""learning_rate""
 : 
reciprocal
 (
3e-4
, 
3e-2
),
}
# RandomizedSearchCV usa la K-fold cross-validation, ignora X/y_valid
rnd_search_cv 
 = 
RandomizedSearchCV
 (
keras_reg
 , 
param_distribs
 , 
n_iter
=
10
, 
cv
=
3
)
rnd_search_cv
 .
fit
(
X_train
, 
y_train
, 
epochs
=
100
,
validation_data
 =
(
X_valid
, 
y_valid
),
callbacks
 =
[
keras
.
callbacks
 .
EarlyStopping
 (
patience
 =
10
)]) 
20"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#2,2,"Architetture non sequenziali: wide & deep
Si possono impiegare architetture più complesse di quelle viste ﬁnora, ad 
esempio quelle non sequenziali. 
Nella 
 wide & deep 
 l'input è connesso direttamente con l'output. Questo 
permette di apprendere sia patterns 
 deep
  (con la pipeline MLP 
tradizionale), sia regole semplici, per mezzo del percorso breve.
3
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#20,20,"Fine tuning degli iperparametri
I valori degli iperparametri si ottengono alle variabili: 
>>> 
rnd_search_cv
 .
best_params_
{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}
>>> 
rnd_search_cv
 .
best_score_
-0.3189529188278931
>>> 
model 
= 
rnd_search_cv
 .
best_estimator_
 .
model
Si possono impiegare per validare il modello sul test set. 
Se lo spazio degli iperparametri è molto grande, si parte con una 
esplorazione grossolana degli intervalli, e successivamente si rafﬁna lo 
spazio limitandolo agli intervalli potenzialmente più promettenti. 
21"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#21,21,"Fine tuning degli iperparametri
Altre librerie per il tuning degli iperparametri: 
• 
Hyperopt
 : a popular Python library for optimizing over all sorts of complex 
search spaces (including real values such as the learning rate, or discrete values 
such as the number of layers).
• 
Hyperas
 , 
kopt 
 or 
Talos
 : optimizing hyperparameters for Keras model (the ﬁrst 
two are based on Hyperopt).
• 
Scikit-Optimize 
 (skopt): a general-purpose optimization library. The 
BayesSearchCV 
 class performs Bayesian optimization using an interface 
similar to 
Grid
 SearchCV .
• 
Spearmint
 : a Bayesian optimization library.
• 
Sklearn-Deap
 : a hyperparameter optimization library based on evolutionary 
algorithms, also with a 
 GridSearchCV
 -like interface.
22"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#22,22,"Numero di hidden layers
Una MLP con 1 hidden layer e un numero sufﬁciente di nodi può 
modellare qualsiasi funzione complessa. Ma le deep networks usano i nodi 
in modo più efﬁcienti, perciò richiedono meno potenza computazionale. 
Gli strati più vicini all'input possono rappresentare forme semplici e relative 
caratteristiche (es. segmenti, orientazioni), i layer intermedi combinano questi 
elementi per forme più complesse (es. quadrati, cerchi), mentre i layer ﬁnali si 
focalizzano sulle forme ad alto livello (es. viso delle persone). 
Inoltre le architetture deep riescono più facilmente a generalizzare a nuovi 
datasets.  
Una parte dei layers di una rete addestrata a riconoscere facce possono essere 
impiegati in una nuova rete per riconoscere tagli di capelli, evitando una scelta 
random dei parametri iniziali (
 transfer learning
 ). 
In generale si parte con pochi hidden layer (1 o 2) per task semplici, 
incrementandoli per task complessi, ﬁnché si raggiunge l'overﬁtting. Per i 
task molto complessi si cercano modelli pre-addestrati da cui partire con 
nuovi addestramenti. 
23"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#23,23,"Numero di nodi per layers
Il numero di nodi per l'input layer è determinato dalle istanze in entrata. 
I restanti layer tipicamente formano una piramide, dove i nodi si riducono 
all'avvicinarsi del layer di output. L'idea è che gli ultimi layer 
rappresentano poche e salienti features ad alto livello. 
Ma sperimentazioni più recenti suggeriscono di mantenere costante il 
numero di nodi per layer, ottenendo un singolo iperparametro da 
ottimizzare. 
Anche per il numero di nodi si può partire da un numero basso e 
incrementarlo ﬁno a quando può comparire l'overﬁtting.
24"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#24,24,"Altri iperparametri
Learning rate: il valore ottimale è solitamente la metà di quello massimo, 
cioè quello che genera divergenza nell'algoritmo di training.  
Si parte da un valore alto, dove si ha sicura divergenza, e poi si divide 
per 3 e si ripete ﬁno a quando la divergenza scompare. 
Batch size: inﬂuisce sia sulle performance che su tempo di addestramento. 
Solitamente inferiore a 32. Un valore basso garantisce una iterazione di 
training veloce. Un valore alto più precisione nella stima dei gradienti. 
Per altre raccomandazioni:  
Practical recommendations for gradient-based training of deep 
architectures   
 https://arxiv.org/abs/1206.5533  
25"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#25,25,"TensorFlow Playground
Tool interattivo per sperimentare reti neurali 
https://playground.tensorﬂow.org/   
26
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#26,26,"Esercitazione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, 
cosa puoi constatare?  
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. 
Addestrala varie volte, cosa noti? 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
Aumenta i nodi a 8. Riprova. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 
8 nodi. Cosa noti?
27"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#27,27,"Esercitazione - soluzione
Addestra la rete di default. Analizza i patterns riconosciuti dai vari layers, cosa puoi constatare?  
Gli strati più vicini all'output sono più complessi. 
Rimpiazza la Tanh con la ReLU. Cosa cambia?  
Si accelera il training, ma ora i boundaries sono lineari. 
Modiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. Addestrala varie volte, cosa noti? 
I tempi di apprendimento variano molto e spesso ci si blocca in minimi locali. 
Rimuovi un nodo (ne rimagono 2). Riprova, cosa noti? 
La rete non trova soluzioni buone. Troppi pochi parametri generano underﬁtting. 
Aumenta i nodi a 8. Riprova. 
Più veloce, e non ferma più come nel caso precedente. Reti più complesse hanno più chance di 
trovare soluzioni ottime o tendenti all'ottimo, anche se possono comunque rimanere ""bloccate"" su 
plateaus. 
Usa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 8 nodi. Cosa noti? 
Training time più lungo, spesso rallentanti da plateaus. I nodi nei layer verso l'output si aggiornano 
più velocemente degli altri. È il 
 vanishing gradinets
  problem. Si può risolvere con una 
inizializzazione più accurata dei pesi, altri ottimizzatori (es. AdaGrad e Adam) e con la Batch 
normalization.
28"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#28,28,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
29"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#3,3,"Architetture non sequenziali e Keras
Impieghiamo le 
 functional API
  di Keras.  
Quando creiamo un layer possiamo passargli un parametro aggiuntivo che 
corrisponde all'input del layer, es: 
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
Il layer 
 Concatenate
  permette di concatenare e creare un input composito 
per un certo layer. 
input 
= 
keras
.
layers
.
Input
(
shape
=
X_train
.
shape
[
1
:])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
Concatenate
 ()[
input
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input
], 
outputs
=
[
output
])
4"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#4,4,"Architetture non sequenziali e Keras
Se volessimo suddividere l'input in 2 parti, eventualmente in 
sovrapposizione, e mandare su 2 strati distinti, allora dobbiamo creare 2 
input layers: 
input_A 
 = 
keras
.
layers
.
Input
(
shape
=
[
5
])
input_B 
 = 
keras
.
layers
.
Input
(
shape
=
[
6
])
hidden1 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
input_B
)
hidden2 
 = 
keras
.
layers
.
Dense
(
30
, 
activation
 =
""relu""
)(
hidden1
)
concat 
= 
keras
.
layers
.
concatenate
 ([
input_A
, 
hidden2
])
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
]
, 
outputs
=
[
output
])
5
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#5,5,"Architetture non sequenziali e Keras
Avendo creato due input, dobbiamo speciﬁcarli esplicitamente nella 
funzione ﬁt(), dopo aver compilato il modello: 
model
.
compile
(
loss
=
""mse""
, 
optimizer
 =
""sgd""
)
X_train_A
 , 
X_train_B 
 = 
X_train
[:, :
5
], 
X_train
[:, 
2
:]
X_valid_A
 , 
X_valid_B 
 = 
X_valid
[:, :
5
], 
X_valid
[:, 
2
:]
X_test_A
 , 
X_test_B 
 = 
X_test
[:, :
5
], 
X_test
[:, 
2
:]
X_new_A
, 
X_new_B 
 = 
X_test_A
 [:
3
], 
X_test_B
 [:
3
]
history 
 = 
model
.
fit
(
(
X_train_A
 , 
X_train_B
 )
, 
y_train
, 
epochs
=
20
,
validation_data
 =
((
X_valid_A
 , 
X_valid_B
 ), 
y_valid
))
mse_test 
 = 
model
.
evaluate
 ((
X_test_A
 , 
X_test_B
 ), 
y_test
)
y_pred 
= 
model
.
predict
((
X_new_A
, 
X_new_B
))
6"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#6,6,"Output multipli
Perché costruire architetture con output multipli? 
Il task lo potrebbe richiedere, es. localizzare e classiﬁcare un oggetto in 
una foto, cioè un problema di regressione e classiﬁcazione.  
Lo stesso vale per task più distinti. Sebbene si possano addestrare reti 
distinte, conviene condividere i parametri che in qualche modo 
rappresentano potenziali features che sono di interesse per entrambi i 
task, in modo da dover addestrare una sola volta la rete. 
Implementare una forma di regolarizzazione dei parametri per ridurre 
l'overﬁtting. Se per esempio aggiungiamo un secondo output in una 
certa parte della rete, imponiamo che  
la sottorete si addestri in modo autonomo,  
senza dipendere dalla restante parte della rete.
7
"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#7,7,"Output multipli e Keras
Per aggiungere un secondo output (aux) è sufﬁciente collegarlo al layer 
giusto e aggiungerlo alla lista degli output: 
[
...
] # Stesso codice visto fino al layer di output
output 
= 
keras
.
layers
.
Dense
(
1
)(
concat
)
aux_output 
 = 
keras
.
layers
.
Dense
(
1
)(
hidden2
)
model 
= 
keras
.
models
.
Model
(
inputs
=
[
input_A
, 
input_B
],
                             
 outputs
=
[
output
, 
aux_output
 ])
Ogni output deve possedere la propria 
 loss function
 , da indicare quando 
compiliamo. Solitamente si da più peso alla loss dell'output ﬁnale: 
model
.
compile
(
loss
=
[
""mse""
, 
""mse""
], 
loss_weights
 =
[
0.9
, 
0.1
], 
optimizer
 =
""sgd""
)
Nella architettura vogliamo che entrambi gli output producano lo stesso 
risultato (y_train): 
history 
 = 
model
.
fit
([
X_train_A
 , 
X_train_B
 ], [
y_train
, 
y_train
], 
epochs
=
20
,
                    
 validation_data
 =
([
X_valid_A
 , 
X_valid_B
 ], [
y_valid
, 
y_valid
])) 
8"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#8,8,"Output multipli e Keras
Durante l'addestramento, oltre alla loss totale, sarà prodotta anche la loss 
del layer di output principale e aux: 
total_loss
 , 
main_loss
 , 
aux_loss 
 = 
model
.
evaluate
 (
                             [
 X_test_A
 , 
X_test_B
 ], [
y_test
, 
y_test
])
Anche la funzione predict() produrrà un doppio output: 
y_pred_main
 , 
y_pred_aux 
 = 
model
.
predict
([
X_new_A
, 
X_new_B
])
9"
data_test\rootfolder\università\MachineLearning\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#9,9,"Keras: Modelli statici e dinamici
Entrambe le API, sequential e functional, seguono un approccio 
dichiarativo
 , dove prima si deﬁniscono i layer, come sono connessi, e 
successivamente viene avviato il ﬂusso dei dati. Si hanno i seguenti 
vantaggi: 
il modello può facilmente essere salvato, clonato e condiviso 
la struttura può essere visualizzata 
il framework può inferire il tipo di dati e controllare i tipi (favorisce il 
debug) 
Ma non si possono prevedere loop, architetture dinamiche, conditional 
branching e altri comportamenti dinamici. 
Per tale motivo si impiega il Subclassing API.
10"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Classiﬁcatore di Bayes"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#1,1,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#10,10,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#11,11,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#12,12,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
ℜ1eℜ2rappresentano due regioni disgiunte
dell’insieme deinumeri reali .
Sipuò dimostrare che esiste unpunto x*per il
quale l’errore èminimo .
Infatti per x*=x B(dove Bstaper Bayes) l’area
indicata come reducible error èpari a0.
Ciascuno dei due integrali esprime laparte
della distribuzione diprobabilità diuna classe
che cade nell’area dell’altra classe (errata) .
Inquesto caso, lasuperficie decisionale (vedi
dopo) èunpunto sull’asse deinumeri reali ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#13,13,"Classificatore di Bayes30 CHAPTER 2. BAYESIAN DECISION THEORY
2.7 Error Probabilities and Integrals
We can obtain additional insight into the operation of a general classiﬁer — Bayes or
otherwise — if we consider the sources of its error. Consider ﬁrst the two-category
case, and suppose the dichotomizer has divided the space into two regions R1andR2
in a possibly non-optimal way. There are two ways in which a classiﬁcation error can
occur; either an observation xfalls in R2and the true state of nature is ω1, orxfalls
inR1and the true state of nature is ω2. Since these events are mutually exclusive
and exhaustive, the probability of error is
P(error )= P(x∈R2,ω1)+P(x∈R1,ω2)
=P(x∈R2|ω1)P(ω1)+P(x∈R1|ω2)P(ω2)
=/integraldisplay
R2p(x|ω1)P(ω1)dx+/integraldisplay
R1p(x|ω2)P(ω2)dx. (68)
This result is illustrated in the one-dimensional case in Fig. 2.17. The two in-
tegrals in Eq. 68 represent the pink and the gray areas in the tails of the functions
p(x|ωi)P(ωi). Because the decision point x∗(and hence the regions R1andR2) were
chosen arbitrarily for that ﬁgure, the probability of error is not as small as it might
be. In particular, the triangular area marked “reducible error” can be eliminated if
the decision boundary is moved to xB. This is the Bayes optimal decision boundary
and gives the lowest probability of error. In general, if p(x|ω1)P(ω1)>p(x|ω2)P(ω2),
it is advantageous to classify xas in R1so that the smaller quantity will contribute
to the error integral; this is exactly what the Bayes decision rule achieves.
ω2 ω1
x
x* R2 R1p(x|ωi)P(ωi)
reducible
error
∫p(x|ω1)P(ω1)dx
R2∫p(x|ω2)P(ω2)dx
R1xB
Figure 2.17: Components of the probability of error for equal priors and (non-optimal)
decision point x∗. The pink area corresponds to the probability of errors for deciding
ω1when the state of nature is in fact ω2; the gray area represents the converse, as
given in Eq. 68. If the decision boundary is instead at the point of equal posterior
probabilities, xB, then this reducible error is eliminated and the total shaded area is
the minimum possible — this is the Bayes decision and gives the Bayes error rate.
In the multicategory case, there are more ways to be wrong than to be right, and
it is simpler to compute the probability of being correct. Clearly
P(correct )=c/summationdisplay
i=1P(x∈Ri,ωi)"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#14,14,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )
!Vogliamo eseguire la stima (grossolana) delle probabilità a priori 
delle classi wie delle densità di probabilità condizionali per un nuovo 
pattern xdata la classe wi  a partire dal training set (per la seconda 
stima consideriamo l’intorno del pattern xcerchiato in figura)"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#15,15,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#16,16,"Esempio
4prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio
Una stima (grossolana) delle probabilità a priori e delle densità può 
essere effettuata a partire dal training set come segue (si vedranno in 
seguito tecniche più rigorose per effettuare tale stima):
Probabilità a priori
 : si considera semplicemente l’occorrenza dei 
pattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18
Densità di probabilità condizionali
 per un nuovo pattern 𝐱da 
classificare: si contano le occorrenze dei pattern del training set 
delle due classi in un intorno di 𝐱:
𝑝
𝐱𝑤1=1/8
𝑝
𝐱𝑤2=Τ210=1/5
𝑝
𝐱=1
8×8
18+1
5×10
18=1
18+2
18=1
6
Si ottiene quindi :
𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1
𝑝𝐱=𝟏/𝟏𝟖
𝟏/𝟔=𝟏
𝟑
𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2
𝑝𝐱=𝟐/𝟏𝟖
𝟏/𝟔=𝟐
𝟑
L’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).
x
PesoAltezzaClassificare le persone in
maschi/femmine in base a 
peso e all’altezza , a partire 
dal training set in figura.
𝐕
è uno spazio a 2 
dimensioni ( 𝑑=2)
W=𝑤1,𝑤2
𝑤1= maschi ( blu),
𝑤2= femmine ( rosso )"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#17,17,"Approccio Bayesiano
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes : approccio parametrico e
non-parametrico
Mentre
 lastima delle probabilità apriori èabbastanza semplice
(senon sihanno elementi sipossono ipotizzare leclassi
equiprobabili) ,laconoscenza delle densità condizionali è
possibile “solo inteoria”;nella pratica duesoluzioni :
Approccio
 parametrico :sifanno ipotesi sulla forma delle
distribuzioni (es.distribuzione multinormale )esiapprendono i
parametri fondamentali (vettore medio ,matrice dicovarianza )
daltraining set.
Approccio
 nonparametrico :siapprendono ledistribuzioni dal
training set(es.attraverso ilmetodo Parzen Window ).
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere unaragionevole certezza (osperanza )chelaforma della
distruzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
L’approccio
 parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#18,18,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#19,19,"Approccio Bayesiano
Generalmente l’approccio parametrico siutilizza quando, oltre ad
avere una ragionevole certezza (osperanza )che laforma della
distribuzione siaadeguata, ladimensione deltraining setnon è
sufficiente perunabuona stima della densità .
!L’approccio parametrico èinfatti generalmente caratterizzato
daunminor numero digradi dilibertà eilrischio dioverfitting
deidati, quando iltraining setèpiccolo, èminore ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#2,2,"Probabilità
Quando un agente conosce l’ambiente circostante , l’approccio
logico gliconsente di derivare piani efficaci . Ma gliagenti non 
hanno quasi maiaccesso a tutta l’informazione necessaria : 
devono quindi agire in condizioni di incertezza .
La teoria della probabilità èilmodo migliore di ragionare in 
condizioni di incertezza ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#20,20,"Distribuzione Normale (d=1)
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
6prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale (d=1) 
La
densità diprobabilità della distribuzione normale (𝑑=1)è:
𝑝𝑥=1
𝜎2𝜋𝑒−𝑥−𝜇2
2𝜎2
dove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto
quadratico medio )eilsuoquadrato 𝜎2lavarianza .
Solo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+
2𝜎].
Solitamente siassume che ladistribuzione valga 0adistanze
maggiori di3𝜎dalvalore medio .
N.B. La funzione p(x) sopra nonvaconfusa con la densità di probabilità assoluta 
checompare a denominatore del Teorema di Bayes. Sono due grandezze diverse !"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#21,21,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza!Vogliamo eseguire la stima dei parametri tramite il Metodo 
della Massima Verosimiglianza ( Maximum Likelihood )
Il metodo consiste nel massimizzare la funzione di verosimiglianza, definita in 
base alla probabilità di osservare una data realizzazione campionaria , 
condizionatamente ai valori assunti dai parametri statistici oggetto di stima"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#22,22,"Esempio Stima di µes(d=1)
7prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=1)
Dato
 untraining setdipattern mono -dimensionali composto da
𝑛=10elementi :
3,7,9,−2,15,54,−11,0,23,−8
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )sidimostra [1]essere :
Stima
 per𝜇:media campionaria deivalori .
Stima
 per𝜎2:varianza campionaria deivalori .
  91090
108 230 11 54 152 973 1
1    ¦
 n
iixnP
¦
    n
iixn 12 21P V
8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2
  
[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#23,23,"Esempio Stima di µes(d=1)
8prof. Davide Maltoni –Università di Bologna
ML
Classificazione…in forma grafica

01495.07559.441
1416.32 855.171)25(4015.0 8.31829252
   
  e e p
ATTENZIONE SIAMO NEL 
CONTINUO :
𝑝è unadensità di 
probabilità : 𝑝(25) non è la 
probabilità del valore 25 
(questa vale 0!) ma la 
densità di probabilità nel
punto 25. Solo considerando
un intervallo di valori (anche
piccolo) sulla base possiamo
parlare di probabilità . 
In altre parole l’intervallo
𝑥,𝑥+𝑑𝑥ha probabilità
𝑝𝑥𝑑𝑥.N.B. Siamo nelcontinuo: p(25) è una densità di probabilità , non una probabilità !  "
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#24,24,"Esempio Stima di µes(d=1)
"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#3,3,"Spazio di Probabilità
Uno spazio di probabilità èuna terna (Ω, !, P) dove
!Ωèun insieme qualunque (in genere pensato come l’insieme
deirisultati possibili di un esperimento casuale );!!èdetta σ-algebra , ovvero un insieme di insiemi (glieventi ) 
per iquali sipuòcalcolare una probabilit à;
!P()èappunto una misura di probabilit àsuΩ(P:Ω → [0, 1]).
Per la precisione , una σ-algebra èuna famiglia di insiemi taliche
!∅∈!;!se A ∈!allora anche ilsuocomplementare Āèin!;
!unioni numerabili di elementi di !appartengono ancora ad !."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#4,4,"Spazio di Probabilità
Ad esempio : nell’esperimento “lancio di un dado”,
Ω= {1, 2, 3, 4, 5, 6}, !èla σ-algebra generata dagli
eventi elementari di Ω, cioè di fatto, quelli per iquali è
possibile calcolare una probabilit à.
Ad esempio E= “numero pari” = {2, 4, 6}, F= “numero
maggiore di 4” = {5, 6}. 
G = “ numero 7” appartiene a !?"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#5,5,"Esempio di Misura di Probabilità
Se ildado non ètruccato , cioèglieventi elementari sono
equiprobabili , allora
""#=#&'() *'+,-.+,/) '#
#&'() 0,(()1)/) 2)Ω
cioè, negli esempi precedenti
""#=#2,4,6
#1,2,3,4,5,6=3
6=1
2
"";=#5,6
#1,2,3,4,5,6=2
6=1
3"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#6,6,"Probabilità
Una probabilità (grado di credenza) èuna misura su un insieme di 
eventi che soddisfa tre assiomi (assiomi di Kolmogorov [1]):
!La misura di ogni evento è compresa fra 0 e 1;
!La misura dell’ intero insieme di eventi è 1;
!La probabilità dell’ unione di eventi disgiunti (o mutuamente
esclusivi )è pari alla somma delle probabilità dei singoli eventi .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
disgiunti quando la lorointersezione èvuota .
Dato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono
indipendenti se P(A∩B) = P(A) ⋅P(B). 
[1] S. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , Pearson, 2020."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#7,7,"Probabilità
Un modello probabilistico consiste in uno spazio di possibili esiti
(cioè descrizioni complete di stati) mutuamente esclusivi insieme 
alla misura di probabilità associata ad ogni esito. 
Probabilità condizionata P(A/B) , dove Ae Bsono proposizioni (cioè 
enunciati che affermano che qualcosa è verificato): “la probabilità 
di A, posto che tutto quello che sappiamo èB”.
In altritermini, la probabilità condizionata P(A/B) esprime una 
“correzione ” delle aspettative per A, dettata dall’osservazione di B.
Esempio: P(carie/maldidenti)=0.8 indica che se un paziente ha il mal di 
denti e non è disponibile nessun’altra informazione, la probabilità che 
abbia una carie sarà 0.8.
N.B. La probabilità condizionata P(A/B) ha senso solo se Bha 
probabilità non nulla di verificarsi ."
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#8,8,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1"
data_test\rootfolder\università\MachineLearning\29-CB(1)-sbloccato.pdf#9,9,"Approccio Bayesiano
2prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApproccio Bayesiano
Ilproblema èposto intermini probabilistici .Setutte ledistribuzioni
ingioco sono notel’approccio Bayesiano costituisce lamigliore
regola diclassificazione possibile :soluzione OTTIMA !
Sia
𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠
uninsieme di𝑠classi disgiunte costituite daelementi di𝐕
Per
ogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la
densità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,
ovvero ladensità diprobabilità che ilprossimo pattern sia𝐱
sottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖
Per
ogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di
𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,
cheilprossimo pattern daclassificare siadiclasse𝑤𝑖
Per
 ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità
assoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo
pattern daclassificare sia𝐱
Per
ogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la
probabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che
avendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.
Perilteorema diBayes :
𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
𝑝𝐱𝑝𝐱=෍
𝑖=1𝑠
𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍
𝒊=𝟏𝒔
𝑃𝑤𝑖=1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione alla  
Regressione
Machine Learning "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Regressione 
Simple Linear Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo) 
Multiple Regression 
•
 Fase di Training (minimizzazione della funzione di 
costo)
 
2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#10,10,"Il Processo di Training
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione
tra valori 
osservati e 
previsti ∀ iyi osservatoxi ŷi previsto
 11xi
Funzione  
di Costopesi ŵ 0 e ŵ 1  
calcolati(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#11,11," 12Il Processo di Training
•Dati di training : insieme di esempi ( xi, yi) relativi a casi conosciuti 
(i punti nel piano x-y), da utilizzare per calcolare la funzione di 
costo RSS. 
•Estrazione di features : in questo caso tale funzione è inattiva, nel 
senso che riproduce in uscita il suo ingresso xi. 
•Modello di ML : ipotesi f scelta, istanziata con i valori dei pesi più 
opportuni. 
•Comparazione tra dati osservati e dati previsti : per ogni esempio 
abbiamo il valore vero yi e il valore previsto ŷi, da utilizzare per il 
calcolo della funzione RSS. 
•Algoritmo di Apprendimento : algoritmo che calcola i pesi che 
minimizzano la funzione di costo RSS, da utilizzare per deﬁnire il 
modello di ML."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#12,12,"Minimizzazione  della funzione RSS
In sintesi, il processo di apprendimento è formulato come una 
ricerca di ottimizzazione (ricerca del minimo) nello 
 spazio dei 
pesi
. 
A tal ﬁne possiamo calcolare e avvalerci del 
 gradiente
  della 
“misura d’errore” 
 RSS
 deﬁnita in precedenza.  
Si può dimostrare che la 
 RSS
 è una funzione convessa.  
Ricordiamoci che, per funzioni convesse, quando il gradiente è 
uguale a zero si ha un minimo globale. 
 
13"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#13,13,"Minimo  di una funzione convessa
 
14
w0w1g
ŵ
w
ŵ0ŵ1
gradiente:ij
rg(w)=@g(w)
@w0i+@g(w)
@w1j
<latexit sha1_base64=""UbdTBP63qiqYyxQKEMwdHSMgLt8="">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#14,14,"Gradiente della funzione RSS
Il gradiente della funzione RSS: 
    
   è deﬁnito come segue:
 
15rRSS( w0,w1)=2
4@RSS
@w0
@RSS
@w13
5RSS( w0,w1)=NX
i=1[yi (w0+w1xi)]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#15,15,"Calcolo del Gradiente  
della funzione RSS
 
16rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5@RSS
@w1=NX
i=12[yi (w0+w1xi)]1·( xi)= 2NX
i=1[yi (w0+w1xi)]xi@RSS
@w0=NX
i=12[yi (w0+w1xi)]1·( 1) = 2NX
i=1[yi (w0+w1xi)]"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#16,16,"Algoritmi per adattare il modello 
Una volta calcolato il gradiente della funzione 
 RSS
, ci sono 
due possibili approcci per minimizzare la funzione di 
costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero (ossia al vettore nullo) e si 
risolvono le equazioni (non sempre è possibile o conveniente dal punto di 
vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
17"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#17,17,"Forma Chiusa (1/4)
Poniamo il gradiente uguale al vettore nullo: 
ossia:
 
18 2NX
i=1[yi (w0+w1xi)] = 0
 2NX
i=1[yi (w0+w1xi)]xi=0rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5=0"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#18,18,"Forma Chiusa (2/4)
Dalla prima equazione otteniamo:
 
19PN
i=1yi ˆw0PN
i=11 ˆw1PN
i=1xi=0
ˆw0=PN
i=1yi
N ˆw1PN
i=1xi
N
da cui si ha:"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#19,19,"Forma Chiusa (3/4)
Dalla seconda equazione otteniamo: 
da cui si ha:
 
20PN
i=1xiyi ˆw0PN
i=1xi ˆw1PN
i=1x2
i=0
ˆw1=PN
i=1xiyi ˆw0PN
i=1xiPN
i=1x2
i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#2,2,"Introduzione alla Regressione
 
3I modelli a regressione vengono utilizzati per prevedere 
variabili target su scala continua , il che li rende 
interessanti per risolvere molte questioni in ambito 
scientiﬁco e anche industriale, come ad esempio:
• trovare relazioni fra variabili 
• valutare tendenze 
• effettuare previsioni ( e.g., vendite di una azienda nei prossimi mesi )"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#20,20,"Forma Chiusa (4/4)
e con facili passaggi otteniamo: 
che, insieme a: 
vista in precedenza, ci consente di calcolare i valori dei due 
pesi che minimizzano la funzione RSS.
 
21ˆw1=PN
i=1xiyi PN
i=1xiPN
i=1yi
NPN
i=1x2
i (PN
i=1xi)2
N
ˆw0=PN
i=1yi
N ˆw1PN
i=1xi
N"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#21,21,"Gradient Descent (1/3)
Come sappiamo, con questo approccio dobbiamo 
aggiornare i pesi in modo tale da spostarci nella direzione 
opposta al gradiente:
 
22w(t+1) w(t) ↵·rRSS(w(t))
w=w0
w1 
dove:
ossia:
w(t+1)
0 w(t)
0 ↵·@RSS(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@RSS(w(t))
@w1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#22,22,"Gradient Descent (2/3)
Rivediamo l’espressione del gradiente di RSS: 
L’aggiornamento dei due pesi può dunque essere effettuato 
come segue, scegliendo un opportuno 
 step size
 :
 
23rRSS( w0,w1)=2
4 2PN
i=1[yi (w0+w1xi)]
 2PN
i=1[yi (w0+w1xi)]xi3
5=2
4 2PN
i=1[yi ˆyi(w0,w1)]
 2PN
i=1[yi ˆyi(w0,w1)]xi3
5
w(t+1)
0 w(t)
0+2↵·NX
i=1[yi ˆyi(w(t))]
w(t+1)
1 w(t)
1+2↵·NX
i=1[yi ˆyi(w(t))]xi"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#23,23,"Gradient Descent (3/3)
Dobbiamo inﬁne scegliere un 
 criterio di convergenza
 . 
Come già detto, per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
24krRSS(w(t))k2✏"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#24,24,"Algoritmo di Gradient Descent 
 
25w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
w(t+1)
0 w(t)
0+2↵·NX
i=1[yi ˆyi(w(t))]
w(t+1)
1 w(t)
1+2↵·NX
i=1[yi ˆyi(w(t))]xi
t t+1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#25,25,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Fino ad ora abbiamo ipotizzato, per la funzione 
 f(
x
)
, un andamento 
lineare per il nostro caso di studio relativo ai prezzi degli appartamenti. 
Tuttavia l’esperienza comune ci induce a pensare che la relazione tra 
le due variabili (area e prezzo di un appartamento) non sia proprio 
lineare. In genere, all’aumentare della metratura il prezzo aumenta ma 
non in modo esattamente proporzionale. Potremmo ipotizzare ad 
esempio una funzione quadratica o addirittura polinomiale di grado p: 
 
26f(x)=w0+w1x+w2x2
f(x)=w0+w1x+w2x2+···+wpxpy
Areax
y
Areax
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#26,26,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
In quest’ultimo caso avremmo una 
 Polinomial Regression
 , 
il cui modello è il seguente: 
 
27yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
In genere, le potenze della x sono trattate come differenti 
features
 : 
feature 1 = 1
feature 2 = x
feature 3 = x2
······ ···
feature p+1 = xp"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#27,27,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, con un solo input x
 i
, è il seguente: 
 
28yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i
dove le features che compaiono possono assumere forme 
diverse (non necessariamente solo potenze della x). "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#28,28,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Inoltre, è importante considerare anche il caso in cui ci 
siano più input. 
Per l’esempio degli appartamenti potremmo voler 
considerare non solo l’area ma anche altre caratteristiche 
(#bagni, #camere da letto, anno di costruzione, ecc.). 
In tal caso avremmo in input un vettore 
 x
i
 per ogni 
esempio noto, le cui componenti sono appunto l’area, il 
#bagni, ecc. 
    
 
29"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#29,29,"Multiple Regression 
[caso di Linear Regression con Multiple Features]
Il caso generale, che ha in input un vettore 
 x
i
, è pertanto il 
seguente: 
 
30
dove le features che compaiono, ciascuna delle quali è 
funzione del vettore 
 x
i
, possono assumere forme diverse. yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#3,3,"Modello a 
Regressione Lineare Semplice
 
4L’obiettivo di un modello a Regressione Lineare 
Semplice ( univariata ) consiste nell’individuare le 
relazioni esistenti tra un’unica caratteristica (la variabile 
descrittiva x) e una risposta continua (variabile target y)."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#30,30," 
31Anche in questo caso possiamo utilizzare, come funzione di 
costo da minimizzare, la RSS deﬁnita come segue, a partire 
da N osservazioni disponibili:
Il problema di addestrare il nostro modello è dunque quello 
di trovare i valori dei pesi ŵ0 ,ŵ1 ,…, ŵD che minimizzano la 
funzione RSS (convessa anche in questo caso).
Multiple Regression 
[caso di Linear Regression con Multiple Features]
RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0 0(xi)+ ···+wD D(xi))]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#31,31,"Il Processo di Training 
[caso di Linear Regression con Multiple Features]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
Comparazione 
tra valori 
osservati e 
previsti ∀ iyi osservato(xi) ŷi previsto
 32xi
Funzione  
di Costovettore di pesi 
 ŵ calcolatoɸ
(N esempi)
Algoritmo di 
Apprendimento
Calcolo vettore 
dei pesi ŵ"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#32,32,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In molti casi può essere conveniente usare una 
notazione matriciale. 
L’espressione: 
 
33
relativa all’i-esimo valore per y, può essere scritta 
come segue: yi=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#33,33,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
 
34
oppure: yi=[w0w1···wD]·2
664 0(xi)
 1(xi)
···
 D(xi)3
775+✏i
yi=[ 0(xi) 1(xi)··· D(xi)]·2
664w0
w1
···
wD3
775+✏i"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#34,34,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
In sintesi: 
 
35yi=DX
j=0wj j(xi)+✏i=wT· (xi)+✏i= T(xi)·w+✏i
w=2
664w0
w1
···
wD3
775 (xi)=2
664 0(xi)
 1(xi)
···
 D(xi)3
775
dove: 
xi=2
664xi,1
xi,2
···
xi,d3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#35,35,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Possiamo inﬁne rappresentare tutte le osservazioni y in 
modo compatto come segue: 
 
36
    ossia: 
y=  ·w+✏2
664y1
y2
···
yN3
775=2
664 0(x1) 1(x1)...  D(x1)
 0(x2) 1(x2)...  D(x2)
... ... ... ...
 0(xN) 1(xN)...  D(xN)3
775·2
664w0
w1
···
wD3
775+2
664✏1
✏2
···
✏N3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#36,36,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
dove: 
    
 
37✏=2
664✏1
✏2
···
✏N3
775 y=2
664y1
y2
···
yN3
775
 =2
664 0(x1) 1(x1) ...  D(x1)
 0(x2) 1(x2) ...  D(x2)
... ... ... ...
 0(xN) 1(xN) ...  D(xN)3
775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#37,37,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora la funzione RSS: 
 
38RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1✏2
i=✏T·✏
che possiamo scrivere anche così: RSS(w)=NX
i=1(yi ˆyi)2=NX
i=1[yi ( 0(xi)w0+...+ D(xi)wD)]2=NX
i=1[yi  T(xi)·w]2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#38,38,"Regression Model 
 in notazione matriciale 
[caso di Linear Regression con Multiple Features]
Da una precedente espressione per 
 y
 ricaviamo il vettore 
 ε
: 
 
39✏=y  w y= w+✏)
La funzione RSS assume pertanto la seguente forma in notazione 
matriciale: 
RSS(w)=(y  w)T(y  w)"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#39,39,"Gradiente della funzione RSS 
[caso di Linear Regression con Multiple Features]
Calcoliamo ora il gradiente della funzione RSS, partendo dalla 
precedente espressione matriciale. 
Applicando una nota regola di calcolo differenziale matriciale 
si ottiene: 
 
40rRSS(w)=r[(y  w)T(y  w)] = 2 T(y  w)"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#4,4,"Esempio 
 
5A titolo di esempio possiamo considerare il caso della 
previsione del prezzo di un appartamento (variabile target y) 
data la sua metratura (variabile descrittiva x).
Tipicamente, in casi come questo abbiamo a disposizione un 
certo numero di esempi (osservazioni), costituiti da 
appartamenti già venduti per ciascuno dei quali abbiamo a 
disposizione l’area in mq o in sq.ft. ( x) e il prezzo pagato per 
l’acquisto ( y).
Ciascuna delle suddette osservazioni può essere rappresentata 
da un punto in un piano cartesiano x-y, come illustrato nella 
ﬁgura che segue."
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#40,40,"Algoritmi per adattare il modello 
[caso di Linear Regression con Multiple Features]
Anche in questo caso, una volta calcolato il gradiente della 
funzione 
 RSS
, ci sono due possibili approcci per 
minimizzare la funzione di costo: 
“Forma chiusa”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
41"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#41,41,"Forma Chiusa 
[caso di Linear Regression con Multiple Features]
Poniamo il gradiente uguale al vettore nullo: 
 
42ˆw=( T ) 1 Ty
da cui si ha:  2 Ty+2 T ˆw=0
 T ˆw= Ty
( T ) 1( T )ˆw=( T ) 1 Ty
Iˆ w =( T ) 1 TyrRSS(w)= 2 T(y  w)=0"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#42,42,"Gradient Descent (1/4) 
[caso di Linear Regression con Multiple Features]
Dobbiamo aggiornare il vettore dei pesi in modo tale da 
spostarci nella direzione opposta al gradiente:
 
43w(t+1) w(t) ↵·rRSS(w(t))
dove:
rRSS(w(t))=2
66664@RSS
@w0
@RSS
@w1
···
@RSS
@wD3
77775w(t)=2
6664w(t)
0
w(t)
1
···
w(t)
D3
7775"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#43,43,"Gradient Descent (2/4) 
[caso di Linear Regression con Multiple Features]
I singoli pesi devono dunque essere aggiornati come segue:
 
44w(t+1)
0 w(t)
0 ↵·@RSS(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@RSS(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j ↵·@RSS(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D ↵·@RSS(w(t))
@wD"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#44,44,"Gradient Descent (3/4) 
[caso di Linear Regression con Multiple Features]
Per comprendere gli aggiornamenti da fare per i singoli pesi, 
calcoliamo la derivata parziale di RSS, espressa in questa 
forma:
 
45
rispetto al generico peso j-esimo:
@RSS(w(t))
@wj=NX
i=12[yi ˆyi(w(t))]·[ @ˆyi(w(t))
@wj]=
=2NX
i=1[yi ˆyi(w(t))]·[  j(xi)] = 2NX
i=1 j(xi)[yi ˆyi(w(t))]RSS(w(t))=NX
i=1[yi ˆyi(w(t))]2=NX
i=1{yi [ 0(xi)w(t)
0+···+ j(xi)w(t)
j+···+ D(xi)w(t)
D]}2"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#45,45,"Gradient Descent (4/4) 
[caso di Linear Regression con Multiple Features]
Anche in questo caso dobbiamo inﬁne scegliere un 
 criterio 
di convergenza
 . 
Sappiamo che per funzioni convesse si ha un minimo 
globale quando il gradiente è uguale a zero. 
In pratica, possiamo terminare l’elaborazione quando:
 
46krRSS(w(t))k2✏"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#46,46,"Algoritmo di Gradient Descent 
[caso di Linear Regression con Multiple Features]
 
47w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrRSS( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
w(t+1)
j w(t)
j ↵⇤derivata parziale[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#47,47,"Riferimenti
 
48
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#5,5,"Esempio
 
6Il problema da risolvere è il seguente: scegliere lo spazio delle 
ipotesi  H (e.g., insieme di polinomi di grado massimo k) e la 
funzione f(x) (ipotesi) che approssima meglio le osservazioni 
disponibili di una funzione sconosciuta, da utilizzare per 
prevedere i prezzi di altri appartamenti (diversi dagli esempi).
y
Area xy
Area x
y
Area x
"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#6,6,"Apprendimento induttivo 
(Inductive Learning method)
La difﬁcoltà che si incontra in tale attività è dovuta al 
fatto che non è facile stabilire se una particolare f sia una 
buona approssimazione della funzione sconosciuta. 
Una buona ipotesi si potrà generalizzare  bene, ossia 
potrà predire correttamente esempi che non ha ancora 
incontrato.Il problema dell’induzione
 7"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#7,7,"Simple Linear Regression Model
 
8In ﬁgura è rappresentato un modello lineare per f(x), dove il 
peso wo rappresenta l’intercetta e il peso w1 rappresenta la 
pendenza della retta. Si noti l’offset verticale che costituisce 
l’errore che in genere esiste tra la previsione e il valore effettivo. 
Abbiamo dunque, per il valore vero e quello previsto per un 
certo valore dell’ascissa:
yi=w0+w1xi+✏i
ˆyi=f(xi)=w0+w1xiy
Area x
Prezzo"
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#8,8,"Simple Linear Regression Model
 
9Supponiamo di scegliere il modello lineare. Una volta 
deﬁnito tale modello, ossia la forma della funzione f(x), 
occorre determinare i due pesi incogniti, ossia l’intercetta e la 
pendenza, che deﬁniscano la f(x) “migliore” secondo un certo 
criterio.
Un criterio possibile è quello di minimizzare gli errori che si 
hanno sulle osservazioni. "
data_test\rootfolder\università\MachineLearning\3-Regression-Introduzione-sbloccato.pdf#9,9,"Simple Linear Regression Model
 
10Una delle funzioni utilizzate a tal ﬁne, che deve essere per 
l’appunto minimizzata, è la Residual Sum of Squares (RSS) , 
deﬁnita come segue, a partire da N osservazioni disponibili:
RSS( w0,w1)=NX
i=1(yi ˆyi)2=NX
i=1[yi (w0+w1xi)]2
Il problema di addestrare il nostro modello è dunque quello 
di trovare i valori dei due pesi ŵ0 e ŵ1 che minimizzano la 
funzione RSS."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#0,0,"Distribuzione Normale Multivariata (Multinormale)
9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#1,1,"Richiami
!La Matrice di Covarianza si indica di solito con Σed è una generalizzazione del 
concetto di varianza al caso di dimensione maggiore di uno
!E’ una matrice che rappresenta la variazione di ogni variabile rispetto alle altre 
(inclusa se stessa)
!E’ sempre simmetrica e definita positiva (i.e., ha tutti gli autovalori strettamente 
positivi) ---> ammette sempre Matrice Inversa
!La Matrice Simmetrica è una matrice quadrata che ha la proprietà di essere la 
trasposta (vedi sotto) di se stessa 
!La Matrice Inversa di una matrice A è pari alla sua Matrice Aggiunta (i.e., Matrice 
Trasposta Coniugata) diviso il det(A)
!La Matrice Trasposta di una matrice è la matrice ottenuta scambiando le righe con 
le colonne
!La Matrice Trasposta Coniugata di una matrice a valori complessi è la matrice 
ottenuta effettuando la trasposta e scambiando ogni valore con il suo complesso 
coniugato"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#10,10,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#11,11,"Esempio Stima di µes(d=2)
13prof. Davide Maltoni –Università di Bologna
ML
Classificazione…prosegue
 ¦
   
»»»»»
¼º
«««««
¬ª
 
n kj j
ki i
kij
dd dd
x xn ...1
122 211 12 11
1       ,  
... ...... ... ... ...... ......
P P V
V VVVV VV
Σ
»¼º
«¬ª »
¼º
«
¬ª 456.1732.2532.25 44.66
22 2112 11
VVVVΣ
44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2
21 11   VV
32.25
52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12   VV
456.17
52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2
22 22   VV
»¼º
«¬ª
 
1281.0 0488.00488.0 0337.01Σ   674.518 32.2532.25 456.1744.66   Σo,innotazione vettoriale :
𝚺=1
𝑛෍
𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,
ciascuna ottenuta come vettore
colonna pervettore riga."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#12,12,"Esempio Stima di µes(d=2)
14prof. Davide Maltoni –Università di Bologna
ML
Classificazionein forma grafica
vista 
dall’alto
vista 
laterale"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#13,13,"Classiﬁcatore di Bayes con Distribuzioni Multinormali
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#14,14,"15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes con 
distribuzioni Multinormali
Nell’esempio
 sono visualizzate ledensità condizionali di2classi
dipattern (distribuiti condistribuzione normale 2-dimensionale)
corrette sulla base delle rispettive probabilità apriori .
La
classificazione èeseguita utilizzando laregola Bayesiana .Lo
spazio èsuddiviso inregioni nonconnesse .Nelcaso specifico
2ècostituita daduecomponenti disgiunte .
Un
decision boundary odecision surface (superficie decisionale)
èunazona diconfine traregioni cheilclassificatore associa a
classi diverse .Sulboundary laclassificazione èambigua .
Le
superfici decisionali possono assumere forme diverse .Nel
caso specifico sitratta didueiperboli .Ingenerale :
Se
le2matrici dicovarianza sono uguali traloro:lasuperficie
decisionale èuniper-piano .
Se
le2matrici dicovarianza sono arbitrarie :lasuperficie
decisionale èuniper-quadratica .
Classiﬁcatore di Bayes con Distribuzioni Multinormali"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#15,15,"Altri Esempi di Superfici Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadraticheStessa Matrice di Covarianza: Iper-piani
Iper-piano: sottospazio di dimensione inferiore di uno rispetto allo spazio in cui è 
contenuto"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#16,16,"Altri Esempi di Superﬁci Decisionali
16prof. Davide Maltoni –Università di Bologna
ML
Classificazione…altri esempi di superfici decisionali
Stessa 
matrice
di 
covarianza:
iper-piani
Differenti 
matrici
di covarianza:
iper-
quadratiche
Differenti Matrici di Covarianza: Iper-quadratiche
Iper-quadratica: (iper -)superficie di uno spazio d -dimensionale sui complessi o sui 
reali rappresentata da un'equazione polinomiale del secondo ordine nelle variabili 
spaziali (coordinate)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#17,17,"Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
Obiettivo: stimare la classe di appartenenza del pattern x (57,168)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#18,18,"17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:Esempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#19,19,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)
17prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes parametrico ( multinormali )
>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º
«¬ª ¦9.343.233.232.35
1 »¼º
«¬ª ¦0.139.89.81.10
2

»¼º
«¬ª¦
¦ 
11
1 1 2/1
12/121exp
π21| μxμx xt
dw p

»¼º
«¬ª¦
¦ 
21
2 2 2/1
22/221exp
π21| μxμx xt
dw p
x
PesoAltezza
1|w px
 2|w pxStima dei parametri dal training set:"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#2,2,"Richiami
!Premessa :lanozione diautovalore siriferisce alle sole matrici
quadrate ,ossia alle matrici aventi lostesso numero dirighe edi
colonne .
!Chiarito ciò,siaAuna matrice quadrata diordine nacoefficienti in
uncampo !(dove !potrebbe essere ilcampo ℝdeinumeri reali oil
campo ℂdeinumeri complessi ).
!Sidice cheloscalare λ0∈!èunautovalore della matrice quadrata
Aseesiste unvettore colonna non nullo v∈!ntale che
Av=λ0v
!Ilvettore vèdetto autovettore relativo all’autovalore λ0"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#20,20,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#21,21,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#22,22,"Bayes e Confidenza di Classificazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#23,23,"Bayes Parametrico In Pratica
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.
20prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes parametrico in pratica
Molto
 spesso sifanno ipotesi azzardate sulla normalità delle
densità diprobabilità delle classi delproblema senza aver
sperimentalmente eseguito nessuna verifica ;ciòporta ad
ottenere cattivi risultati diclassificazione .
Pertanto, dato unproblema con𝑠classi edato untraining set
(significativo), deve essere innanzitutto valutata larispondenza
alla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:
in
modo formale (es:teststatistico diMalkovich -Afifi [1]
basatosull’indice diKolmogorov -Smirnov )
in
modo empirico ,visualizzando invarimodi lenuvole dei
dati (esistono deitool giàpredisposti perquesto tipo di
analisi finoa3D)ogliistogrammi sulle diverse componenti
econfrontandoli conlecurve teoriche .
Una
 volta provata una (seppur vaga) normalità delle
distribuzioni, sistimano apartire daidati, vettore medioPe
matrice dicovarianza 6(maximum likelihood ).
Per
 quanto riguarda leprobabilità apriori queste possono
essere estratte dalle percentuale dicampioni cheneltraining
setappartengono allediverse classi, oincaso diassenza di
informazioni possono essere poste tutte uguali traloro.
Ogni
 nuovo pattern daclassificare ,èassegnato auna delle
possibili classi inaccordo conlaregola diBayes nella quale
media ecovarianza sono oranote.
[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#24,24,"Bayes Parametrico In Pratica
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#25,25,"Problemi Closed e Open Set
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#26,26,"Problemi Closed e Open Set
"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#3,3,"Richiami
!E’utile osservare chesevèunautovettore relativo all’autovalore λ0,
allora anche %v,con%∈!e%≠0,èunautovettore relativo aλ0.
!Infatti moltiplicando ambo imembri della relazione
Av=λ0v
perloscalare %≠0,siottiene
%(Av)=%(λ0v)⟺A(%v)=λ0(%v)
!Ciòdimostra cheanche %vèunautovettore associato aλ0."
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#4,4,"9prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistribuzione Normale Multivariata 
(Multinormale ) 
Notazione
 :perevitare confusione utilizziamo apedicel’indice del
pattern e(ove necessario) adapice lacomponente (scalare) :
•𝐱𝑖pattern i-esimo (vettore)
•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)
La
densità diprobabilità nella distribuzione multinormale (𝑑>1):
𝑝𝐱=1
2𝜋𝑑/2Σ1/2𝑒−1
2𝐱−𝛍𝑡Σ−1𝐱−𝛍
dove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di
covarianza (𝑑×𝑑).
Si
assume che ivettori siano ditipo «colonna» .L’apice𝑡
(trasposto) litrasforma inrighe .
|6|e6-1sono rispettivamente ildeterminante el’inversa di6.
La
matrice dicovarianza èsempre simmetrica edefinita
positiva, pertanto ammette inversa .Essendo simmetrica il
numero diparametri cheladefinisce è𝑑∙𝑑+1/2
Gli
elementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖
(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le
covarianze tra𝑥𝑖e𝑥𝑗:
•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0
•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0
•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#5,5,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#6,6,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti (!12=0) 
non siavera in generale , iClassificatori Naïve Bayes sidimostrano lavorare bene su
molti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#7,7,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#8,8,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ!Vogliano eseguire la stima dei parametri tramite il Metodo della 
Massima Verosimiglianza ( Maximum Likelihood )campioni in blu
vettore medio da 
stimare in rosso"
data_test\rootfolder\università\MachineLearning\30-CB(2)-sbloccato.pdf#9,9,"Esempio Stima di µes(d=2)
12prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempio stima di 𝜇e 𝜎(d=2)
Dato
 untraining setdipattern bi-dimensionali composto da𝑛=
5elementi :
La
stima deiparametri permassima verosimiglianza (maximum
likelihood )è:
o,innotazione vettoriale :
𝛍=1
𝑛෍
𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t
¦
  
»»»»
¼º
««««
¬ª
 
n ki
ki
dxn ...121
1    ,    
...P
PPP
μ »¼º
«¬ª 
»»»
¼º
«««
¬ª

 2.99.8
58.1542.71275231135.43
μ"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#0,0,"Sommario
!Approccio parametrico (distribuzione MultiNormale)
!Approccio non parametrico (Parzen Window) "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#1,1,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#10,10,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
Ricordiamo che x è il pattern da classificare, xisono i pattern del 
Training Set"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#11,11,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili hanno più
probabilità diesserlo inunospazio apiùdimensioni .
Qualsiasi modello lineare può essere trasformato inunmodello non
lineare applicando ilkernel trick (stratagemma del kernel) almodello :
sostituendo lesuefeature (predittori) conunafunzione kernel ."
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#12,12,"Kernel Trick
!Le funzioni kernel sono usate per operare nello spazio delle 
feature senza calcolare le coordinate dei dati nello spazio di 
input, ma piuttosto calcolando il prodotto scalare fra le immagini 
di tutte le copie di dati nello spazio funzione!Tale operazione è spesso computazionalmente più economica 
che l’esplicito calcolo delle coordinate, in quanto il prodotto 
scalare gode di alcune proprietà speciali!Infatti spesso si può calcolare φ(xi)""φ(xj) senza prima calcolare il 
valore di φ in ogni punto [dove x è il pattern nell’ input space (con 
ddimensioni) e φ(x) è il corrispondente pattern nel feature space 
(con m>d dimensioni)!Le funzioni kernel sono state introdotte per sequenze di dati, 
grafi, testi, immagini e vettori"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#13,13,"Parzen Window con Soft Kernel
23prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window con Soft kernel
Nella pratica, invece difunzioni finestra ipercubo siutilizzano kernel
function piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla
stima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In
questo modo lesuperfici decisionali risultano molto piùregolari
(smoothed ).
Lekernel function devono essere funzioni densità (sempre ≥0e
conintegrale sututto lospazio uguale a1).Utilizzando lafunzione
multinormale (con𝛍=[0…0]eΣ=I):
𝜑𝐮=1
2𝜋𝑑/2𝑒−𝐮𝑡𝐮
2
n=15
n=40
n=120h=3 h=8
 h=15
In questo caso il valore 
dell’iperparametro h
non è legato alla 
lunghezza di uno 
spigolo dell’ipercubo, 
ma all’ ampiezza della 
funzione multinormale "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#14,14,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(N.B. In questo caso il valore dell’iperparametro hè legato alla lunghezza 
dello spigolo dell’ ipercubo )
(N.B. In questo caso il valore dell’iperparametro hè legato all’ampiezza della 
funzione multinormale )"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#15,15,"Esempio con Parzen Window
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP
24prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMaschi/Femmine
con Bayes + Parzen Window
Stima non -parametrica della densità attraverso Parzen Window
(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)
PesoAltezza
>@T168 ,57 x
PesoAltezza
>@T168 ,57 x
¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)
¾Funzione Kernel normale con ℎ=3 (grafico a destra)0.0038 |1 wpx  0040.0 |2 wpx  0039.0 w w|is
1ii    ¦
 P p p x x

43.0w w||w1 1
1 # xxxpP pP 
57.0w w||w2 2
2 # xxxpP pP
0.0024 |1 wpx  0041.0 |2 wpx  0033.0 w w|is
1ii    ¦
 P p p x x

32.0w w||w1 1
1 # xxxpP pP 
68.0w w||w2 2
2 # xxxpP pP(con hlegato alla lunghezza dello spigolo dell’ ipercubo )
(con hlegato all’ampiezza della funzione normale )
Sipuò notare come nelcaso della Funzione Kernel normale ,lesuperfici
decisionali risultino molto piùregolari (smoothed)"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#16,16,"Riferimenti
!S.J. Russell, and P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!R. O. Duda, P. Hart, and D. G. Stork Pattern Classification , 
Wiley -Interscience, 2000.
!D. Maltoni, Machine Learning , Università di Bologna, 2021.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#17,17,"Matlab
Questo esempio mostra come eseguire la classificazione in Matlab tramite 
NaÏve Bayes Classifier
MATLAB > Help > Examples > Statistics and Machine Learning Toolbox > 
Classification
Dataset: Fisher’s Iris Data
Fisher's iris data consists of measurements on the sepal length, sepal width, 
petal length, and petal width for 150 iris specimens. There are 50 specimens 
from each of three species. Load the data and see how the sepal 
measurements differ between species. You can use the two columns 
containing sepal measurements.
load fisheriris
gscatter(meas(:,1), meas(:,2), species,'rgb','osd');
xlabel('Sepal length');
ylabel('Sepal width');
N = size(meas,1);
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#18,18,"Matlab
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#19,19,"Matlab
Approccio Parametrico: modelliamo ciascuna variabile in ciascuna classe tramite 
una distribuzione Gaussiana. Ci calcoliamo il resubstitution error (errore sul 
training set, di solito stima ottimistica dell’errore reale sul test set) e il cross -
validation error (in cui si suddivide il training set in gruppi di eguale numerosità, 
si esclude iterativamente un gruppo alla volta e lo si cerca di predire con i gruppi 
non esclusi)
nbGau = fitcnb(meas(:,1:2), species);
nbGauResubErr = resubLoss(nbGau)
[x,y] = meshgrid(4:.1:8,2:.1:4.5);
x = x(:);
y = y(:);
cp = cvpartition(species,'KFold',10)
nbGauCV = crossval(nbGau, 'CVPartition',cp);
nbGauCVErr = kfoldLoss(nbGauCV)
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbGauResubErr = 0.2200
nbGauCVErr = 0.2200
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#2,2,"Appr occi Non Parametrici e Stima della Densità
L'ipercubo (o n-cubo) è una forma geometrica regolare immersa in 
uno spazio di quattro o piùdimensioni
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#20,20,"Matlab
Approccio Non Parametrico: in questo caso modelliamo ciascuna variabile in 
ciascuna classe tramite una stima della densità di probabilità mediante funzione 
kernel (settata a ‘box’)
nbKD = fitcnb(meas(:,1:2), species, 'DistributionNames','kernel', 'Kernel','box');
nbKDResubErr = resubLoss(nbKD)
nbKDCV = crossval(nbKD, 'CVPartition',cp);
nbKDCVErr = kfoldLoss(nbKDCV)
labels = predict(nbKD, [x y]);
gscatter(x,y,labels,'rgb','osd')
labels = predict(nbGau, [x y]);
gscatter(x,y,labels,'grb','sod')
nbKDResubErr = 0.2067
nbKDCVErr = 0.2133
"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#21,21,"Esercizio 1
5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 5) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#22,22,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#23,23,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#24,24,"Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[1,03
1,03] 
𝚺0−1=[52,56−10,05
−10,0536,88] 
|𝚺0|=0,000544  
𝑃(𝑤0)=0,6 𝝁1=[2,02
1,53] 
𝚺1−1=[100,58−22,34
−22,3437,85] 
|𝚺1|=0,000302  
𝑃(𝑤1)=0,4 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60
1,25]: 
x le densità di probabilità condizionali;  
x le probabilità a posteriori ; 
x l’indice della classe restituita in output.  
 
Si ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) 
 
Svolgimento  
 
𝒙−𝝁0=[1,60
1,25]−[1,03
1,03]=[0,57
0,22] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√0,000544⋅𝑒−1
2⋅[0,570,22]⋅[52,56−10,05
−10,0536,99]⋅[0,57
0,22] 
 
[52,56−10,05
−10,0536,88]⋅[0,57
0,22]=[52,56⋅0,57+(−10,05)⋅0,22
(−10,05)⋅0,57+36,88⋅0,22]=[27,7482
2,3851] 
 
[0,570,22]⋅[27,7482
2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  
 
𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412
2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[1,60
1,25]−[2,02
1,53]=[−0,42
−0,28] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√0,000302⋅𝑒−1
2⋅[−0,42−0,28]⋅[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28] 
 
[100,58−22,34
−22,3437,85]⋅[−0,42
−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)
(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884
−1,2152] 
 
[−0,42−0,28]⋅[−35,9884
−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  
 
𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554
2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,00193⋅0,6
0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,00403⋅0,4
0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 1 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#25,25,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#26,26,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#27,27,"Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  
 
x 6 neuroni per l’input layer  
x 8 neuroni per l’hidden layer  
x 5 neuroni di output  
 
Quante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le 
operazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di 
operazioni per livello.  
 
Svolgimento  
 
Per ogni neurone del livello corrente si deve calcolare la seguente formula:  
𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗
𝑗=1..𝑑+𝑤0𝑖 
 
che comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale 
del bias. Pertanto:  
 
 
 
 
 
Numero operazioni l ivello hidden: 8⋅(6+6+1)=104 
 
Numero operazioni livello di output: 5⋅(8+8+1)=85 
 
Totale: 189 
 
 
6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  
 
{[6,1
8,1],[6,5
1,9],[8,8
4,2],[5,2
9,7],[0,8
5,4]} 
 
Calcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  
 
Si ricorda che ogni elemento della matrice di covarianza può essere calcolato come  
𝜎𝑖𝑗=1
𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛
𝑘=1   
dove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  
 
Svolgimento  
 
𝛍=[6,1+6,5+8,8+5,2+0,8
5
8,1+1,9+4,2+9,7+5,4
5]=[5,5
5,9] 
 
𝚺=[6,9−1,4
−1,47,7] 
 
 Machine Learning                        Matricola: ___________________  
20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 
Neuroni livello 
corrente  Somma Bias  Una somma  per ogni 
neurone livello 
precedente  Una moltiplicazione 
per ogni neurone 
livello precedente  
NOTA:  Il calcolo a lato è eseguito t rascurando il fatto che 
un’implementazione ottimizzata della sommatoria potrebbe 
evitare una somma per il primo elemento della sommatoria 
(somma con 0).  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#28,28,"Esercizio 3
7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#29,29,"Esercizio 37) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  
𝝁1=[0,75
4,69
9,57] 
 𝝁2=[1,74
0,80
9,59] 
 𝝁3=[6,32
7,94
1,82] 
 
𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). 
Indicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la 
risposta):  
 
𝐩1=[0,85
5,12
9,52],𝐩2=[9,73
4,30
5,41] 
 
Svolgimento  
 
La regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a 
posteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)
𝑝(𝐱). 
Dato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a 
posteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . 
Pertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  
𝑝(𝐱|𝑤𝑖)=1
(2𝜋)𝑑
2⋅|𝚺𝑖|1
2⋅𝑒−1
2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) 
e che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di 
Bayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al 
quadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). 
 
𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 
 
𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 
 
𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#3,3,"Appr occi Non Parametrici e Stima della Densità
!In Teoria della Probabilità, la distribuzione binomiale è una 
distribuzione di probabilità discreta che descrive il numero di 
successi in un processo di Bernoulli!Tale processo vale nel caso di esperimenti di prove ripetute (i.e., 
esperimenti in cui si vuole misurare quante volte si verifichi un 
certo esito su tutte le prove effettuate)!E’ necessario che il risultato di una prova non influenzi le 
successive, ossia che le singole prove siano fra loro indipendenti!La formula da utilizzare in questi casi è la Formula di Bernoulli : 
se l’evento da noi indagato ha una probabilità p di verificarsi per 
ciascuna prova ed effettuiamo n prove indipendenti, la probabilità 
che l’evento si verifichi kvolte (con k ≤ n) è data da
P(k successi su n prove)=n
k⎛
⎝⎜⎜⎞
⎠⎟⎟pk⋅(1−p)n−k"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#30,30,"Esercizio 4 
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
  
5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda 
count come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella 
seguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). 
Completare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e 
alla quarta 2.  
 
 𝐶1 𝐶2 𝐶3 
 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 
𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 
𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 
 
 Punteggi Classi  Classe 
scelta  1 2 3 4 
 𝒑1 20 22 6 24 4 
𝒑2 27 22 17 6 1 
𝒑3 9 24 25 14 3 
 
 
6) Data un rete neurale MLP a 3 livelli  con bias  composta da : 
 
• 6 neuroni di Input  
• 8 neuroni Intermedi  
• 5 neuroni di Output  
 
Calcolare, motivandone la risposta, il numero di pesi totale.  
 
Svolgimento  
 
Nel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di 
connessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  
del numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il 
numero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. 
 
Pertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. 
 
 
7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  
𝝁0=[10,90
−0,43] 
𝚺0−1=[1,531,27
1,271,61] 
|𝚺0|=1,170996  
𝑃(𝑤0)=0,55 𝝁1=[2,87
2,90] 
𝚺1−1=[0,41−0,14
−0,140,35] 
|𝚺1|=8,005816  
𝑃(𝑤1)=0,45 
Nell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05
0,96]: 
le densità di probabilità condizionali;  
x le probabilità a posteriori;  
x l’indice della  classe restituita in output.  
 
Si ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  
𝑝(𝒙)=1
(2𝜋)𝑑
2⋅|𝚺|1
2⋅𝑒−1
2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  
17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#31,31,"Esercizio 4
Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#32,32,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#33,33,"Esercizio 4Svolgimento  
 
𝒙−𝝁0=[7,05
0,96]−[10,90
−0,43]=[−3,85
1,39] 
 
𝑝(𝒙|𝑤0)=1
2𝜋⋅√1,170996⋅𝑒−1
2⋅[−3,851,39]⋅[1,531,27
1,271,61]⋅[−3,85
1,39] 
 
[1,531,27
1,271,61]⋅[−3,85
1,39]=[1,53⋅(−3,85)+1,27⋅1,39
1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252
−2,6516] 
 
[−3,851,39]⋅[−4,1252
−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  
 
𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296
2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) 
 
𝒙−𝝁1=[7,05
0,96]−[2,87
2,90]=[4,18
−1,94] 
 
𝑝(𝒙|𝑤1)=1
2𝜋⋅√8,005816⋅𝑒−1
2⋅[4,18−1,94]⋅[0,41−0,14
−0,140,35]⋅[4,18
−1,94] 
 
[0,41−0,14
−0,140,35]⋅[4,18
−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)
(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854
−1,2642] 
 
[4,18−1,94]⋅[1.9854
−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  
 
𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152
2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) 
 
𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) 
 
𝑝(𝑤0|𝒙)=0,000330⋅0,55
0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) 
 
𝑝(𝑤1|𝒙)=0,000260⋅0,45
0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) 
 
Indice della classe restituita: 0 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#34,34,"Si supponga di partecipare a un gioco 
a premi, in cui si può scegliere fra tre 
porte: dietro una di esse c’è 
un’automobile, dietro le altre, due 
capre. 
Si sceglie una porta, diciamo la numero 
1. A quel punto, il conduttore del gioco 
a premi, che sa cosa si nasconde 
dietro ciascuna porta, ne apre un’altra, 
diciamo la 3, rivelando una capra. 
Quindi domanda: “vorresti scegliere la 
numero 2 o conservare la tua scelta 
iniziale?”
Ti conviene cambiare la tua scelta 
originale?
Problema"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#35,35,"Dal quiz televisivo americano Let’s Make a Deal , 
condotto dal presentatore Maurice Halprin , noto
con lo pseudonimo di Monty Hall. 
4500 puntate dal 1963 al 1991.
Il concorrente deve scegliere una delle tre
porte chiuse cheha davanti a sé: dietro a due 
di esse c’èuna capra , dietro l’altra c’èuna 
automobile . 
Ovviamente , né luiné ilpubblico sanno dietro
a quale porta sitrova l’auto .
Il concorrente fa la suascelta .
Problema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#36,36,"A questo punto, ilpresentatore apre
una delle altre due porte , rivelando
una capra .
Quindi chiede al concorrente se vuole
mantenere la porta scelta , o se vuole
cambiarla .
Domanda : al concorrente conviene
cambiare ? 
La risposta sembra ovvia : sono rimaste
due porte , e dietro una di esse c’è
l’auto . Cambiare porta non dovrebbe
influenzare le probabilità di vincita chea 
questo punto èlogico ritenere pari a 1/2, 
chesidecida di cambiare o meno .Problema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#37,37,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#38,38,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#39,39,Problema di Monty Hall
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#4,4,"Appr occi Non Parametrici e Stima della Densità
!Esempi di casi di distribuzione binomiale sono i risultati di una 
serie di lanci di una stessa moneta o di una serie di estrazioni 
da un'urna (con reintroduzione o reimbussolamento), ognuna 
delle quali può fornire due soli risultati : il successo con 
probabilità pe il fallimento con probabilità q=1−p!Reimbussolamento: dovendo estrarre un certo numero di 
carte/palline/numeri da un mazzo/urna/bussolo, ogni oggetto 
estratto è immesso nuovamente prima di estrarre 
carte/palline/numeri successivi"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#40,40,"h""ps ://www.youtube.com /watch?v =nYX8DMG8_ywProblema di Monty Hall"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#5,5,"Appr occi Non Parametrici e Stima della Densità
21prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneApprocci non parametrici e
Stima della Densità
Non vengono fatte ipotesi sulle distribuzioni deipattern eledensità
diprobabilità sono stimate direttamente daltraining set.
Ilproblema della stima accurata della densità èritenuto damolti un
problema piùcomplesso della classificazione .Pertanto perché
risolvere come sotto -problema unproblema che èpiùcomplesso
dell’intero compito diclassificazione ?
Ingenerale lastima della densità èaffrontabile inspazi a
dimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della
dimensionalità (curse ofdimensionality ):ilvolume dello spazio
aumenta così tanto cheipattern diventato troppo sparsi .
Stima Densità
Laprobabilità cheunpattern𝐱cadaall’interno diè:
𝑃1=න
𝑝𝐱′𝑑𝐱′
Dati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano
nella regioneècalcolabile attraverso ladistribuzione binomiale :
𝑃𝑘=𝑛
𝑘𝑃1𝑘1−𝑃1𝑛−𝑘
ilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)
Assumendo che laregione (divolume𝑉)siapiccola eche
quindi𝑝∙nonvarisignificativamente all’interno diessa :
𝑃1=න
𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉
𝑝𝐱=𝑃1
𝑉=𝑘
𝑛∙𝑉"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#6,6,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#7,7,"Parzen Window
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro
22prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneParzen Window
Laregione ,denominata finestra (Window ),ècostituita daun
ipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:
𝜑𝐮=ቐ1𝑢𝑗≤1
2,𝑗=1…𝑑
0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖
Dato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi
volume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono
all’interno dell’iper-cubo èdato da:
𝑘𝑛=෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛
sostituendo 𝑘𝑛(vedi lucido precedente) siottiene :
𝑝𝑛𝐱=1
𝑛∙𝑉𝑛෍
𝑖=1𝑛
𝜑𝐱𝑖−𝐱
ℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑
Ovviamente, specie nelcaso incuiilnumero dipattern non sia
elevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun
forte impatto sulrisultato, infatti :
Se
lafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,
molto attratta daicampioni estatisticamente instabile .
Se
lafinestra ègrande lastima èpiùstabile mapiuttosto vaga
esfuocata .
Sidimostra che perottenere convergenza ,ladimensione della
finestra deve essere calcolata tenendo conto del numero di
campioni deltraining set:
𝑉𝑛=𝑉1
𝑛,dove𝑉1oℎ1èuniperparametro"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#8,8,"Iperparametri
14prof. Davide Maltoni –Università di Bologna
ML
FondamentiIperparametri
Molto
 algoritmi richiedono didefinire, primadell’apprendimento
vero eproprio, ilvalore deicosiddetti iperparametri H.
Esempi
 diiperparametri :
Il
numero dineuroni inunareteneurale .
Il
numero divicini kinunclassificatore k-NN.
Il
grado diunpolinomio utilizzato inunaregressione .
Il
tipodilossfunction .
Si
procede con unapproccio adue livelli nelquale perogni
valore «ragionevole » degli iperparametri si esegue
l’apprendimento, ealtermine della procedura siscelgono gli
iperparametri chehanno fornito prestazioni migliori .
Ma
come sivalutano leprestazioni ,esuquali dati?"
data_test\rootfolder\università\MachineLearning\31-CB(3)-sbloccato.pdf#9,9,"Iperparametri
!Ricordiamo che
!Il Training Set è l’insieme di pattern su cui addestrare il 
sistema, trovando il valore ottimo per i parametri (e.g., i pesi 
delle connessioni in una rete neurale)!Il Validation Set è l’insieme di pattern su cui tarare gli 
iperparametri (ciclo esterno)!Il Test Set è l’insieme di pattern su cui valutare le prestazioni 
finali del sistema
!N.B. Sempre forte è la tentazione di tarare gli iperparametri 
direttamente sul Test Set, ma questo dovrebbe essere evitato, 
pena sovrastima delle prestazioni! "
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2019 -2020
Bayes & Nearest Neighbor"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#1,1,"Classiﬁcatore Nearest Neighbor (NN)
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#10,10,"Da NN a k-NN
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#11,11,"Da NN a k-NN
28prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDa NN a k-NN
La
regola nearest neighbor produce unpartizionamento dello
dello spazio, noto come tassellazione diVoronoi :
Ogni elemento 𝐱𝑖∈TSdetermina untassello, all’interno delquale i
pattern saranno assegnati allastessa classe di𝐱𝑖.
La
regola diclassificazione nearest neighbor èpiuttosto radicale ;
infatti basta che unelemento deltraining setnon siamolto
“affidabile” (outlier )affinché tuttiipattern nelle suevicinanze siano
inseguito etichettati noncorrettamente .
Che
 errore commette ilclassificatore NNsultraining set?
Un
modo generalmente piùrobusto ,chepuòessere visto come
estensione della regola nearest -neighbor (inquesto caso detta
1-nearest neighbor )èilcosiddetto classificatore k-nearest
neighbor (k-NN).
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#12,12,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#13,13,"k-Nearest Neighbor ( k-NN)4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#14,14,"k-Nearest Neighbor ( k-NN)
29prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-Nearest -Neighbor (k-NN)
La
regola k-Nearest Neighbor (k-NN)determina ikelementi più
vicini alpattern𝐱daclassificare (kèuniperparametro );ogni
pattern traikvicini vota perlaclasse cuiesso stesso appartiene ;
ilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior
numero divoti.
Per
TSinfiniti laregola diclassificazione k-NNsidimostra migliore
di1-NN, eall’aumentare dik,l’errore Pconverge all’errore
Bayesiano .
Nella
 pratica (TSlimitati), aumentare ksignifica estendere l’iper-
sfera diricerca andando asondare laprobabilità aposteriori
lontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente
<10)deve essere determinato suunvalidation setseparato .
nella figura il classificatore 5-NN,
assegna 𝐱alla classe “nera”
in quanto quest’ultima ha ricevuto 3 
voti su 5.
Nel caso di 2 classi è bene 
scegliere k dispari per evitare 
pareggi."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#15,15,"k-Nearest Neighbor ( k-NN)28 CHAPTER 4. NONPARAMETRIC TECHNIQUES
Here the summation over the ﬁrst bracketed term represents the probability of error
due to ipoints coming from the category having the minimum probability and k−i>i
points from the other category. The summation over the second term in the brackets
is the probability that k−ipoints are from the minimum-probability category and
i+1<k−ifrom the higher probability category. Both of these cases constitute
errors under the k-nearest-neighbor decision rule, and thus we must add them to ﬁnd
the full probability of error (Problem 18).
Figure 4.16 shows the bounds on the k-nearest-neighbor error rates for several
values of k. As kincreases, the upper bounds get progressively closer to the lower
bound — the Bayes rate. In the limit as kgoes to inﬁnity, the two bounds meet and
thek-nearest-neighbor rule becomes optimal.
0 0.1 0.2 0.3 0.40.10.20.30.4
Bayes Rate
P*P
1
3
5
9
150.5
Figure 4.16: The error-rate for the k-nearest-neighbor rule for a two-category problem
is bounded by Ck(P∗) in Eq. 55. Each curve is labelled by k; when k=∞, the
estimated probabilities match the true probabilities and thus the error rate is equal
to the Bayes rate, i.e., P=P∗.
At the risk of sounding repetitive, we conclude by commenting once again on the
ﬁnite-sample situation encountered in practice. The k-nearest-neighbor rule can be
viewed as another attempt to estimate the a posteriori probabilities P(ωi|x) from
samples. We want to use a large value of kto obtain a reliable estimate. On the
other hand, we want all of the knearest neighbors x′to be very near xto be sure
thatP(ωi|x′) is approximately the same as P(ωi|x). This forces us to choose a
compromise kthat is a small fraction of the number of samples. It is only in the limit
asngoes to inﬁnity that we can be assured of the nearly optimal behavior of the
k-nearest-neighbor rule.
4.5.5 Computational Complexity of the k–Nearest-Neighbor
Rule
The computational complexity of the nearest-neighbor algorithm — both in space
(storage of prototypes) and time (search) — has received a great deal of analy-
sis. There are a number of elegant theorems from computational geometry on the
construction of Voronoi tesselations and nearest-neighbor searches in one- and two-
dimensional spaces. However, because the greatest use of nearest-neighbor techniques
is for problems with many features, we concentrate on the more general d-dimensional
case.
Suppose we have nlabelled training samples in ddimensions, and seek to ﬁnd
the closest to a test point x(k= 1). In the most naive approach we inspect each
stored point in turn, calculate its Euclidean distance to x, retaining the identity only
of the current closest one. Each distance calculation is O(d), and thus this search4.5. THE NEAREST-NEIGHBOR RULE 27
by examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We
shall not go into a thorough analysis of the k-nearest-neighbor rule. However, by
considering the two-class case with kodd (to avoid ties), we can gain some additional
insight into these procedures.
x
x1x2
Figure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-
ical region until it encloses ktraining samples, and labels the test point by a majority
vote of these samples. In this k= 5 case, the test point xwould be labelled the
category of the black points.
The basic motivation for considering the k-nearest-neighbor rule rests on our ear-
lier observation about matching probabilities with nature. We notice ﬁrst that if
kis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of
theknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor
cases, the labels on each of the k-nearest-neighbors are random variables, which in-
dependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)
is the larger a posteriori probability, then the Bayes decision rule always selects ωm.
The single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-
neighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an
event of probability
k/summationdisplay
i=(k+1)/2/parenleftbiggk
i/parenrightbigg
P(ωm|x)i[1−P(ωm|x)]k−i. (54)
In general, the larger the value of k, the greater the probability that ωmwill be
selected.
We could analyze the k-nearest-neighbor rule in much the same way that we
analyzed the single-nearest-neighbor rule. However, since the arguments become more
involved and supply little additional insight, we shall content ourselves with stating
the results. It can be shown that if kis odd, the large-sample two-class error rate for
thek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)
is deﬁned to be the smallest concave function of P∗greater than
(k−1)/2/summationdisplay
i=0/parenleftbiggk
i/parenrightbigg/bracketleftbig
(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig
. (55)Inparticolare ,sipuò dimostrare (vedi Duda etal.,2000 )che Ck(P*) èdefinita come
lapiùpiccola funzione concava diP*maggiore di"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#16,16,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#17,17,"Esempi k-NN
30prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi k-NN
Nell’esempio visto in precedenza, 
 la regola k -NN con k=3 
assegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )
L’animazione (scomposta nel lucido successivo) mostra il 
partizionamento dello spazio operato dalla regola k-NN sul 
training set con 5 classi visto in precedenza al variare di k
PesoAltezza
>@T168 ,57 x
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#18,18,"Espansione Lucido Precedente (k=1,3)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#19,19,"Espansione Lucido Precedente (k=5,7)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#2,2,"Classiﬁcatore Nearest Neighbor (NN)
26prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore Nearest Neighbor (NN)
Data una metrica 𝑑𝑖𝑠𝑡(∙)nello spazio multidimensionale (es.
distanza euclidea )ilclassificarore nearest neighbor (letteralmente “il
piùvicino traivicini”),classifica unpattern𝐱conlastessa classe
dell’elemento 𝐱′adesso piùvicino neltraining setTS:
𝑑𝑖𝑠𝑡𝐱,𝐱′=𝑚𝑖𝑛
𝐱𝑖∈TS𝑑𝑖𝑠𝑡𝐱,𝐱𝑖
Invece
 diderivare daidatiledistribuzioni condizionali delle classi
perpoifaruso della regola diBayes perlaclassificazione,
questo classificatore cerca inmodo piuttosto pragmatico di
massimizzare direttamente laprobabilità aposteriori ;infatti se𝐱′
èmolto vicino a𝐱èlecito supporre che:
𝑃𝑤𝑖𝐱≈𝑃𝑤𝑖𝐱′
In
effetti, sipuòdimostrare (solo però nelcaso diTSpopolato da
infiniti campioni) chelaprobabilità dierrore P(nella figura sotto)
della regola nearest neighbor nonèmaipeggiore deldoppio del
minimo errore possibile P*(quello Bayesiano ).
Nella
 pratica ,questo non significa però chel’approccio
Bayesiano fornisca sempre risultati migliori dinearest neighbor ,
infatti selastima delle densità condizionali èpoco accurata i
risultati delclassificatore Bayesiano possono essere peggiori .
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#20,20,"Espansione Lucido Precedente (k=9,11)
31prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEspansione dell’animazione
lucido precedente (k=1,3,5,7,9,11)
k=1 k=3
k=5 k=7
k=9 k=11"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#21,21,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#22,22,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
In figura un 
esempio con
s=5 classi"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#23,23,"Bayes e Conﬁdenza di Classiﬁcazione
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#24,24,"k-NN e Conﬁdenza di Classiﬁcazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#25,25,"k-NN e Confidenza di Classificazione
32prof. Davide Maltoni –Università di Bologna
ML
Classificazionek-NN e Confidenza di Classificazione
Daunclassificatore k-NNrisulta piuttosto semplice estrarre una
confidenza (probabilistica) circa laclassificazione eseguita ;siano
𝑣1,𝑣2…𝑣𝑠,෍
𝑖=1𝑠
𝑣𝑖=𝑘
ivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in
figura sotto )possono essere semplicemente ottenute dividendo
per𝑘ivotiottenuti :
𝑣1
𝑘,𝑣2
𝑘…𝑣𝑠
𝑘
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#26,26,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#27,27,"NN e Complessità Computazionale
33prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e complessità computazionale
L’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi
elevate dimensioni puòdiventare problematico :
Necessario
 memorizzare tuttiipattern delTraining Set
Per
ogni classificazione ènecessario calcolare ladistanza del
pattern daclassificare datutti ipattern deltraining sete
ordinare (parzialmente ledistanze) perottenere lepiùpiccole
Tecniche diediting/ condensing (lucido successivo) possono
alleviare questo problema, maquando l’efficienza èimportante è
consigliabile indicizzare idati attraverso strutture spaziali (es.
kd-tree)checonsentono diindividuare ivicini senza effettuare una
scansione esaustiva .
Lalibreria FLANN (C++) consente dieffettuare ricerche nearest
neighbor approssimate molto efficientemente .
http://www .cs.ubc.ca/research/flann/
https ://github.com /mariusmuja /flann"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#28,28,"NN e Complessità ComputazionaleFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS
WITH AUTOMATIC ALGORITHM CONFIGURATION
Marius Muja, David G. Lowe
Computer Science Department, University of British Columbia, Vancouver, B.C., Canada
mariusm@cs.ubc.ca, lowe@cs.ubc.ca
Keywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.
Abstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-
ing in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional
problems that are faster than linear search. Approximate algorithms are known to provide large speedups with
only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on
selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that
answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system
will take any given dataset and desired degree of precision and use these to automatically determine the best
algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical
k-means trees, which we have found to provide the best known performance on many datasets. After testing a
range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other
datasets. We are releasing public domain code that implements these approaches. This library provides about
one order of magnitude improvement in query time over the best previously available software and provides
fully automated parameter selection.
1 INTRODUCTION
The most computationally expensive part of many
computer vision algorithms consists of searching for
the closest matches to high-dimensional vectors. Ex-
amples of such problems include ﬁnding the best
matches for local image features in large datasets
(Lowe, 2004; Philbin et al., 2007), clustering local
features into visual words using the k-means or sim-
ilar algorithms (Sivic and Zisserman, 2003), or per-
forming normalized cross-correlation to compare im-
age patches in large datasets (Torralba et al., 2008).
The nearest neighbor search problem is also of major
importance in many other applications, including ma-
chine learning, document retrieval, data compression,
bioinformatics, and data analysis.
We can deﬁne the nearest neighbor search prob-
lem as follows: given a set of points P={p1,..., pn}
in a vector space X, these points must be preprocessed
in such a way that given a new query point q∈X,
ﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that
Xis an Euclidean vector space, which is appropriate
for most problems in computer vision. We will de-
scribe potential extensions of our approach to general
metric spaces, although this would come at some cost
in efﬁciency.
For high-dimensional spaces, there are often no
known algorithms for nearest neighbor search that
are more efﬁcient than simple linear search. As lin-
ear search is too costly for many applications, this
has generated an interest in algorithms that perform
approximate nearest neighbor search, in which non-
optimal neighbors are sometimes returned. Such ap-
proximate algorithms can be orders of magnitude
faster than exact search, while still providing near-
optimal accuracy.
There have been hundreds of papers published on
algorithms for approximate nearest neighbor search,
but there has been little systematic comparison to
guide the choice among algorithms and set their inter-
nal parameters. One reason for this is that the relative"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#29,29,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi non appartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#3,3,"Classiﬁcatore di Bayes
3prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneClassificatore di Bayes
Dato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di
cuisono note:
le
probabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠
ledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠
laregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui
èmassima laprobabilità aposteriori :
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑃𝑤𝑖𝐱
Massimizzare laprobabilità aposteriori significa massimizzare la
densità diprobabilità condizionale tenendo comunque conto della
probabilità apriori delle classi .
La
regola sidimostra ottima inquanto minimizza l’errore di
classificazione .Adesempio nelcaso di2classi e𝑑=1:
𝑃𝑒𝑟𝑟𝑜𝑟=න
1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න
2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#30,30,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#31,31,"NN e Prototipi di Classi
34prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Prototipi di Classi
Talvolta nella classificazione nearest neighbor invece dimantenere
tuttiipattern delTSecalcolare ladistanza daciascuno diessi, si
preferisce selezionare/derivare daessi uno (opiù) prototipi per
ciascuna classe eutilizzare questi ultimi perlaclassificazione come
sefossero isolielementi diTS:queste tecniche prendono ilnome di:
editing
 :quando sicancellano solo pattern daltraining set,senza
derivare nuovi pattern
condensing
 :seiprototipi nonappartenevano alTSesono stati
derivati
Ciòcomporta solitamente iseguenti vantaggi :
non
ènecessario calcolare unelevato numero didistanze .
iprototipi sono spesso piùaffidabili erobusti disingoli pattern (si
riduce ilrischio diaffidarsi adoutlier ).
Unsingolo prototipo diclasse può essere derivato come vettore
medio deivettori diquella classe nelTS.Processi divector
quantization oclustering consentono diottenere piùprototipi perogni
classe .sebbene il pattern di 
TS più vicino a 𝐱sia 
“blu”, 𝐱viene 
classificato come 
rosso, in quanto il 
prototipo più vicino è 
quello rosso.x"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#32,32,"NN e Metriche
35prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNN e Metriche
Il
comportamento della regola k-NNèstrettamente legato alla
metrica (funzione distanza )adottata .
La
distanza euclidea ,cherappresenta ilcaso L2nella definizione
dimetriche diMinkowski ,èsicuramente lametrica piùspesso
utilizzata .
𝐿𝑘𝐚,𝐛=෍
𝑖=1𝑑
𝑎𝑖−𝑏𝑖𝑘1/𝑘
Nella
 pratica ,prima diadottare semplicemente ladistanza
euclidea èbene valutare lospazio divariazione delle componenti
(ofeature )elapresenza dieventuali forti correlazioni trale
stesse .
Supponiamo
 adesempio divoler classificare lepersone sulla
basedell’altezza edella lunghezza delpiede .Ogni pattern𝐱
(bidimensionale) risulta costituito dadue feature (𝑥1=altezza,
𝑥2=lunghezza delpiede) .
Lospazio divariazione dell’altezza (210-140 =70cm) risulta
maggiore diquello della lunghezza delpiede (40-20=20cm).
Pertanto selasimilarità trapattern venisse misurata consemplice
distanza euclidea lacomponente altezza“peserebbe ”piùdella
componente lunghezza delpiede .𝑥2140 cm 210 cm𝑥1
20 cm40 cm"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#33,33,"NN e Metriche
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#34,34,"Normalizzazione
36prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneNormalizzazione
Perevitare iproblemi legati adiversi spazi divariazioni delle feature ,
particolarmente fastidiosi peralcune tecniche (es.retineurali), si
consiglia dinormalizzare ipattern .
Lenormalizzazioni piùcomuni sono :
Min
-Max scaling :per ogni feature 𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcolano il
massimo 𝑚𝑎𝑥𝑖eilminimo𝑚𝑖𝑛𝑖esiapplica una trasformazione
lineare (scaling )che«tipicamente» mappa𝑚𝑖𝑛𝑖a0e𝑚𝑎𝑥𝑖a1.
𝑥′=𝑥−𝑚𝑖𝑛𝑖/𝑚𝑎𝑥𝑖−𝑚𝑖𝑛𝑖
Standardization
 :perogni feature𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcola lamedia
𝑚𝑒𝑎𝑛𝑖eladeviazione standard 𝑠𝑡𝑑𝑑𝑒𝑣 𝑖esitrasformano ivalori
come :
𝑥′=𝑥−𝑚𝑒𝑎𝑛𝑖/𝑠𝑡𝑑𝑑𝑒𝑣 𝑖
Dopo latrasformazione tutte lefeature hanno (sul training set)
media 0edeviazione standard 1.
Attenzione :iparametri della normalizzazione (es.minimi, massimi) si
calcolano sulsolo training setelatrasformazione siapplica siaatutti
idati(training, validation ,test).
Lesemplici tecniche sopra descritte operano sulle singole feature
indipendentemente .Una tecnica dinormalizzazione efficace (mapiù
costosa) che opera simultaneamente sututte lefeature tenendo
conto della lorocorrelazione èlaWhitening transform ."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#35,35,"Normalizzazione
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#36,36,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, matraloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#37,37,"Distanza Mahalanobis
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2
11prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneDistanza Mahalanobis
La
distanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :
𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍
definisce ibordi adensità costante inuna distribuzione
multinormale .Tale distanza viene spesso utilizzata in
sostituzione della distanza euclidea ,essendo ingrado di
“pesare”lediverse componenti tenendo conto deirelativi spazi
divariazione edella lorocorrelazione .
𝑟=1
𝑟=2
𝑟=3
𝑟=4
𝑥1𝑥2"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#38,38,"Whitening Transform
37prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneWhitening transform
Un’efficace normalizzazione rispetto agli spazi divariazione, in
grado anche ditener conto delle correlazioni trafeature èpossibile :
pre
-normalizzando lospazio delle feature attraverso
Whitening transform (che vedremo meglio inseguito)
utilizzando
 come metrica ladistanza diMahalanobis .
Ledue alternative sono equivalenti .Nelprimo casol’ellissoide
corrispondente allospazio delle feature viene“sfericizzato ”apriori
eviene inseguito usata ladistanza euclidea ;nelsecondo la
distanza diMahalanobis normalizza ogni componente sulla base
della matrice dicovarianza 6.
Danon sottovalutare l’importanza della correlazione trafeatures
come aspetto negativo perlaclassificazione .Infatti,l’utilizzo di
feature correlate riduce (anche drasticamente) ilpotere
discriminante .Nelcaso ideale tutte lefeature sono staticamente
indipendenti (ellissoide assiparalleli aquelli cartesiani) .
Due feature altamente discriminanti seprese individualmente, ma traloro
fortemente correlate, sono nelcomplesso meno discriminanti diuna terza
feature leggermente piùdidiscriminante diognuna delle precedenti .
Ladistanza diMahalanobis (olasfericizzazione dello spazio) tiene
conto delle correlazioni epesa maggiormente feature non
correlate .𝑥1𝑥2
distribuzione
originaledopo Whitening
transform"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#39,39,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#4,4,"Classiﬁcatore Nearest Neighbor (NN)
Quando laprobabilità aposteriori diuna classe èvicina a1,la
probabilità dierrore Bayesiano P*èpiccola ,così come la
probabilità dierrore Pdella regola nearest neighbor .Quando
ciascuna classe èquasi ugualmente probabile ,siaBayes cheNN
hanno untasso dierrore ~(1-1/c),con cnumero diclassi .Nel
mezzo, iltasso dierrore NNèlimitato daltasso dierrore diBayes :
!∗≤!≤!∗2−%
%−1!∗(Eq.52)"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#40,40,"10prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneRappresentazione grafica
Normale Multivariata
Per
𝑑=2laforma della distribuzione èquella diun’ellisse .
𝛍
=𝜇1,𝜇2controlla laposizione delcentro .
𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .
𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi
cartesiani .
•se=0(matrice dicovarianza diagonale ),ladistribuzione
multinormale èdefinita come prodotto di𝑑normali
monodimensionali .Intalcaso gliassidell’ellisse sono
paralleli agliassicartesiani (es.Naive Bayes Classifier ).
•Se >0(come nel caso della figura )𝑥1e𝑥2sono
positivamente correlate (quando aumenta 𝑥1aumenta
anche𝑥2).
•Se<0𝑥1e𝑥2sono negativamente correlate (quando
aumenta 𝑥1cala𝑥2).
Gli
assidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi 
individuano 
luoghi di punti a 
densità costante
𝑥1𝑥2
Distribuzione Normale Multivariata (Multinormale)
N.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti
(!12=0) non siavera in generale , iClassificatori Naive Bayes sidimostrano lavorare
bene sumolti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#41,41,Whitening Transform
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#42,42,"Metric Learning
38prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneMetric Learning
Unapproccio piùgenerale allascelta della metrica dautilizzare in
unadeterminata applicazione, consiste nellearning supervisionato
della metrica stessa daidatideltraining set.
Obiettivo èdeterminare unatrasformazione degli input che:
«avvicini »pattern della stessa classe
«allontani »pattern diclassi diverse
Ladistanza euclidea nella spazio originale è:
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐚−𝐛𝑡𝐚−𝐛=𝐚−𝐛2
Untipico approccio dimetric learning lineare determina (con
training supervisionato) una matrice 𝐆che trasforma gliinput, e
continuare adapplicare ladistanza euclidea agliinput trasformati
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝐚−𝐆𝐛2
Vedremo una possibile soluzione diquesto problema nell’ambito
della riduzione didimensionalità con LDA (Linear Discriminant
Analysys ).
Sono anche possibili approcci nonlineari :
𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝜙𝐚−𝐆𝜙𝐛2
dove𝜙èunafunzione nonlineare ."
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#43,43,"Metric Learning
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#44,44,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#45,45,"Similarità /Distanza Coseno
39prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSimilarità Coseno e Distanza Coseno
Una similarità/distanza piuttosto utilizzata inapplicazioni di
information retrieval ,data mining etext mining èla
similarità/distanza coseno .
Geometricamente, dati due vettori𝐚e𝐛lasimilarità coseno
corrisponde alcosenodell’angolo tradiessi:
𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛
𝐚∙𝐛
ènoto infatti cheilprodotto scalare traduevettori è:
𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃
Due vettori identici hanno similarità 1eduevettori opposti -1.
Ladistanza coseno èsemplicemente :
𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
Esempio Confronto ditesti:Untesto può essere codificato daun
vettore numerico dove ogni dimensione contiene ilnumero di
occorrenze diuna certa parola rispetto aundato dizionario .La
similarità dicontenuto tradue testi non dipende dal numero
assoluto diparole madalla frequenza relativa diciascuna diesse .
Ladistanza coseno «sconta» lalunghezza deivettori .
Ladistanza coseno non èuna metrica (es.non rispetta la
diseguaglianza triangolare ).Sesièinteressati aunametrica sipuò
passare alladistanza angolare :
𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛
𝜋"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#46,46,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (3 ed.) , Pearson, 2009.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. "
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#5,5,"Esempi NN
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#6,6,"18prof. Davide Maltoni –Università di Bologna
ML
Classificazione…continua
Supponendo di non avere altre informazioni, si possono stimare le 
probabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18

0.003321exp
π21|11
1 1 2/1
12/ 1  »¼º
«¬ª¦
¦ μxμx xt
dwp

 0045.021exp
π21|21
2 2 2/1
22/2  »¼º
«¬ª¦
¦ μxμx xt
dw p
PesoAltezza
>@T168 ,57 x
 0040.0 w w|is
1ii   ¦
 P p p x x

36.0w w||w1 1
1 # xxxpP pP

64.0w w||w2 2
2 # xxxpP pPEsempi Bayes"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#7,7,"Esempi NN
27prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneEsempi NN
Nell’esempio visto in precedenza, 
 la regola NN assegna il 
pattern 𝐱alla classe 𝑤1(maschi -blu)
La figura seguente mostra il partizionamento dello spazio 
operato dalla regola NN su un training set con 5 classi:
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#8,8,"Esempi Bayes
19prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneBayes e confidenza di classificazione
Ungrande vantaggio delclassificatore diBayes ,rispetto adaltri
classificatori, èlegato alfatto cheesso produce unvalore dioutput
probabilistico (unvero eproprio valore diprobabilità tra0e1,con
somma 1sulle diverse classi )che può essere utilizzato come
confidenza (visualizzata nella figura come sfumatura colore ):
Infatti, unclassificatore puòassegnare unpattern𝐱aunaclasse
𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere
impiegati per:
scartare pattern in applicazioni open
 -setcon soglia
costruire 
 un multi -classificatore
Se non si è interessati alla confidenza, nella formula di Bayes non 
è necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è 
semplicemente:
𝑏=𝑎𝑟𝑔𝑚𝑎𝑥
𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖
"
data_test\rootfolder\università\MachineLearning\32-CBNN-sbloccato.pdf#9,9,"Da NN a k-NN
"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Classiﬁcatore Bayesiano (Ex 13)
1"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#1,1,"Sommario
..."
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#10,10,"Naive Bayes classiﬁer: step 2
Per ogni dataset ricaviamo 2 statistiche: media e deviazione standard. 
La media può essere ricavata così: 
 μ
 = sum(x)/n * count(x) 
    
dove x è la lista dei valori (o colonna) sui cui stiamo stimando la media.  
# Calculate the mean of a list of numbers
def mean
 (
numbers
)
:
return 
sum
(
numbers
)
/
float
(
len
(
numbers
))
Per la deviazione standard 
 σ
 si ha: 
 sqrt( 
Σ
i
(x
i
 – 
μ
(x))
2
 / N-1)  
from math import 
 sqrt
 
# Calculate the standard deviation of a list of numbers
def stdev
 (
numbers
)
:
avg
 = 
mean
(
numbers
)
variance
  = 
sum
([(
x
-
avg
)
**
2 
for 
x 
in 
numbers
])
 / 
float
(
len
(
numbers
)
-
1
)
return 
sqrt
(
variance
 )
Media e deviazione standard devono essere calcolate per ogni feature e 
considerando tutte le istanze.
11"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#11,11,"Naive Bayes classiﬁer: step 2
Media e deviazione standard devono essere calcolate per ogni feature e considerando 
tutte le istanze. 
La funzione 
 zip(*...)
  separa le colonne del dataset e restituisce una tupla per ogni 
colonna contenente i relativi valori delle features. 
 def summarize_dataset
 (
dataset
)
:
summaries
 =
[(
mean
(
column
),
stdev
(
column
),
len
(
column
)) 
for 
column 
in 
zip
(
*
dataset
)]
del
(
summaries
 [
-
1
])
return 
summaries
Ad esempio: 
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summary
 = 
summarize_dataset
 (
dataset
)
print
(
summary
)
> [(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]
12"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#12,12,"Naive Bayes classiﬁer: step 3
Vogliamo ricavare le statistiche per ogni classe (o label). Sfruttiamo la funzione 
separate_by_class()
  deﬁnita in precedenza:  
def summarize_by_class
 (
dataset
)
:
separated
  = 
separate_by_class
 (
dataset
)
summaries
  = 
dict
()
for 
class_value
 , 
rows 
in 
separated
 .
items
()
:
summaries
 [
class_value
 ]
 = 
summarize_dataset
 (
rows
)
return 
summaries
Ad esempio:  
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
13
>>>
0
(2.7420144012, 0.9265683289298018, 5)
(3.0054686692, 1.1073295894898725, 5)
1
(7.6146523718, 1.2344321550313704, 5)
(2.9914679790000003, 1.4541931384601618, 5)"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#13,13,"Naive Bayes classiﬁer: step 4
Assumiamo che la probabilità che un certo valore 
 x
 osservato sia funzione 
da una distribuzione gaussiana, descritta interamente dai due valori: media 
e deviazione standard.  
La funzione di densità di probabilità sarà così ricavata (vedi lezione; la y 
corrisponde alla media): 
f(x) = (1 / sqrt(2 * PI) * Σ) * exp(-((x-
 μ
)^2 / (2 * Σ^2)))
Dove 
 Σ
 è la matrice di covarianza (con d =1 coincide con la varianza). 
Esercizio
 : deﬁnire la funzione 
 calculate_probability(x, mean, stdev) 
 per il 
calcolo della densità di probabilità.
14
"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#14,14,"Naive Bayes classiﬁer: step 4
Esercizio
 : deﬁnire la funzione calculate_probability(x, mean, stdev) per il 
calcolo della densità di probabilità. 
from math import sqrt
from math import pi
from math import 
 exp
def calculate_probability
 (
x
, 
mean
, 
stdev
)
:
exponent
  = 
exp
(
-
((
x
-
mean
)
**
2
 / 
(
2
 * 
stdev*
*
2 
)))
return 
(
1
 / 
(
sqrt
(
2
 * 
pi
)
 * 
stdev
))
 * 
exponent
print
(
calculate_probability
 (
1.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
2.0
, 
1.0
, 
1.0
))
print
(
calculate_probability
 (
0.0
, 
1.0
, 
1.0
))
> 
0.3989422804014327
> 
0.24197072451914337
> 
0.24197072451914337
Notare come per x=1, e media e varianza pari a 1, l'apice della campana 
assume valore 0.39. Per x=2 e x=0, e medesime statistiche, il valore è 0.24.
15"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#15,15,"Naive Bayes classiﬁer: step 5
Ora impieghiamo le statistiche ricavate dal training data per nuovi dati. La 
stima delle probabilità viene stimata per ogni classe. 
P(class|data) = P(X|class) * P(class) 
Attenzione: Avendo eliminato la frazione, il risultato non è strettamente 
una probabilità.  
Vogliamo massimizzare tale valore, ovvero prendere la classe con valore di 
probabilità massimo. 
L'approccio naive implica l'indipendenza, es: 
P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)
16"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#16,16,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Esempio: 
# Test calculating class probabilities
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
summaries
  = 
summarize_by_class
 (
dataset
)
probabilities
  = 
calculate_class_probabilities
 (
summaries
 , 
dataset
[
0
])
print
(
probabilities
 )
> {0: 0.05032427673372075, 1: 0.00011557718379945765}
17"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#17,17,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
Calcola il numero totale di istanze a partire dalle statistiche passate 
come parametro. 
Valuta il valore P(class) come frazione tra il numero di istanze per una 
classe e il numero di istanze nel dataset 
Stima la probabilità per ogni valore in input impiegando la funzione 
densità di probabilità, e le statistiche per ogni colonna associata ad una 
certa classe. Le probabilità saranno moltiplicate se associate alla stessa 
classe. 
Il processo sarà ripetuto per ogni classe nel dataset. 
Restituire un dizionario classe->probabilità
18"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#18,18,"Naive Bayes classiﬁer: step 5
Esercizio
 : deﬁnire 
 calculate_class_probabilities()
  che prende in input le 
statistiche restituite da 
 summarize_by_class()
  e valuta la probabilità per una 
certa istanza data sempre in input. 
def calculate_class_probabilities
 (
summaries
 , 
row
)
:
 
# numero totale di istanze di training
 
total_rows
  = 
sum
([
summaries
 [
label
][
0
][
2
] 
for 
label 
in 
summaries
 ])
 
# output
probabilities
  = 
dict
()
 
# per ogni chiave (classe) e valore (istanze di quella classe)
for 
class_value
 , 
class_summaries 
 in 
summaries
 .
items
()
:
   
# probabilità calcolata in base alle frequenze
probabilities
 [
class_value
 ]
 = 
summaries
 [
class_value
 ][
0
][
2
]
/
float
(
total_rows
 )
   
# per ogni istanza in summaries associata ad una classe
for 
i 
in 
range
(
len
(
class_summaries
 ))
:
      
# ricava le statistiche di quella classe
mean
, 
stdev
, 
count
 = 
class_summaries
 [
i
]
      
# aggiorna la probabilità per quella classe
probabilities
 [
class_value
 ]
 *= 
calculate_probability
 (
row
[
i
], 
mean
, 
stdev
)
return 
probabilities
19"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#19,19,"Naive Bayes classiﬁer: esercitazione
Considerare il dataset Kaggle Adult income dataset:  
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html   
Contiene 16 colonne: 
Target ﬁled: Income  
-- The income is divide into two classes: <=50K and >50K   
Number of attributes: 14  
-- These are the demographics and other features to describe a person 
Analizza il dataset passo passo seguendo le considerazioni su: 
https://www.kaggle.com/code/prashant111/naive-bayes-classiﬁer-in-python/notebook  
Applica l'algoritmo Naive Bayes classiﬁer per i suddetto dataset.  
Nota
 : alcuni attributi potrebbero dover essere normalizzati oppure convertiti in valori 
numerici.
20"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#2,2,"Scikit-learn: Classiﬁcatori Naive Bayes
Un approccio di classiﬁcazione molto veloce nell'addestramento, che non 
richiede che il training set sia caricato interamente in memoria, anche se a 
volte mostrano performance peggiori rispetto agli approcci lineare (es. 
LogisticRegression e LinearSVC). 
Naive
  perché basato sull'assunzione che le feature siano indipendenti dal 
punto di vista statistico, spesso inesatta. 
Es. un problema cardiovascolare può dipendere dal colesterolo, peso, livelli di 
diabete, etc; se presenti contemporaneamente possono aumentarne il rischio, ma 
l'approccio naive le valuta singolarmente. 
Si ricavano i parametri del modello analizzando le features singolarmente, e 
collezionando statistiche per ogni feature per ogni classe. 
Ricavare la classe più verosimile (con più alta probabilità 
 a posteriori
 ) si 
ottiene mediante il 
 Teorema di Bayes
 . 
L'approccio naive (indipendenza tra features) ci porta a non interpretare la probabilità 
in output poiché risulta essere una approssimazione troppo grossolana rispetto a 
quella reale. 
3"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#20,20,"Naive Bayes classiﬁer: esercitazione
Alcune funzioni di supporto: 
# Load a CSV file
def 
load_csv
 (
filename
 ):
  dataset = 
 list
()
  
with 
open
(filename, 
 'r'
) 
as 
file
:
    csv_reader = reader(
 file
)
    
for
 row 
in
 csv_reader:
      
if 
not
 row:
        
 continue
      dataset.append(row)
  
return
 dataset
# Convert string column to float
def 
str_column_to_float
 (
dataset
, 
column
):
  
for
 row 
in
 dataset:
    row[column] = 
 float
(row[column].strip())
# Convert string column to integer
def 
str_column_to_int
 (
dataset
, 
column
):
  class_values = [row[column] 
 for
 row 
in
 dataset]
  unique = 
 set
(class_values)
  lookup = 
 dict
()
  
for
 i, value 
 in 
enumerate
 (unique):
    lookup[value] = i
  
for
 row 
in
 dataset:
    row[column] = lookup[row[column]]
  
return
 lookup
21"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#21,21,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017 
Tutorial 
 https://machinelearningmastery.com/naive-bayes-classiﬁer-scratch-
python/  
Dataset: 
https://www.kaggle.com/datasets/wenruliu/adult-income-dataset  
http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html  
Testi di Riferimento
22"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#3,3,"Classiﬁcatori Naive Bayes: pregi e difetti
Semplice implementazione (basata sulle occorrenze) 
Può funzionare anche su dataset piccoli 
È veloce e richiede poca memoria 
Gestiste il caso di valori mancanti nei dati  
Poco sensibile a dati rumorosi 
L'assunzione dell'indipendenza statistica è raramente soddisfatta; il modello non 
considera le dipendenze tra features 
I dati nel continuo devono essere spesso rielaborati (es. binning) 
Non raggiunge prestazioni ottimali rispetto ad altri approcci 
Non supporta l'
 online learning
 : occorre riaddestrare il modello in presenza di 
nuovi dati. 
Non funziona correttamente se i dati nel test set non sono presenti nel training.
4"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#4,4,"Scikit-learn: Classiﬁcatori Naive Bayes
Ci sono vari classiﬁcatori implementati in Scikit-learn: 
GaussianNB: adatto a dati nel continuo 
CategoricalNB: features discrete distribuite su categorie predeﬁnite 
BernoulliNB: assume dati binari 
MultinomialNB: assume feature che accumulano valori (es. frequenza) 
ComplementNB: variazione del Multinomial per correggere alcune 
assunzioni sui dati. 
BernoulliNB e MultinomialNB sono spesso usati per dati testuali. 
Per dataset di training molto grandi e sparsi si può usare il parametro 
 partial_ﬁt
  che 
riduce la richiesta di memoria. 
È una valida alternativa a 
 logistic regression
  e 
decision trees
 .
5"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#5,5,"Scikit-learn: BernoulliNB
Conteggia quante volte una feature non è pari 0 per ogni classe. 
Ad esempi, 4 istanze con 4 feature binarie ciascuna. La 1a e 3a istanza 
hanno classe '0', mentre la 2a e 4a hanno classe '1'. 
X 
= 
np
.
array
([[
0
, 
1
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
1
],
[
0
, 
0
, 
0
, 
1
],
[
1
, 
0
, 
1
, 
0
]])
y 
= 
np
.
array
([
0
, 
1
, 
0
, 
1
])
Effettuando il conteggio per entrambe le classi si ha: 
counts 
= 
{}
for 
label 
in 
np
.
unique
(
y
):
# iterate over each class
# count (sum) entries of 1 per feature
counts
[
label
] 
= 
X
[
y 
== 
label
]
.
sum
(
axis
=
0
)
print
(
""Feature counts:\n{}""
 .
format
(
counts
))
Feature counts:
{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}
6"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#6,6,"Scikit-learn: MultinomialNB e GaussianNB
 ,
MultinomialNB
  tiene conto del valor medio per ogni feature per ogni 
classe. 
 GaussianNB
  ricava valor medio e varianza. 
La predizione su una istanza è ricavata valutando tutte le classi e 
scegliendo quella ottimale. 
MultinomialNB e BernoulliNB hanno un singolo parametro 
 alpha
 , che 
determina la complessità del modello. Ai dati sono aggiunti 
 alpha
  istanze 
virtuali che hanno valori positivi per tutte le features. Questo genera uno 
""smoothing"" sulle statistiche calcolate.  
Valori elevati di 
 alpha
  creano smoothing elevati e modelli meno 
complessi.  
GaussianNB
  è più adatto a dataset con molte features. 
 MultinomialNB
  è 
migliore rispetto a 
 BernoulliNB
  con dataset con un numero elevato di 
features diverse da 0 (es. grandi documenti testuali).
7"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#7,7,"Naive Bayes classiﬁer da zero
Proviamo a fare l'implementazione del classiﬁcatore 
Step 1: Separate By Class.  
Step 2: Summarize Dataset.  
Step 3: Summarize Data By Class.  
Step 4: Gaussian Probability Density Function.  
Step 5: Class Probabilities 
Immaginiamo di impiegare il dataset 
 Iris
: 
lunghezza e larghezza sepalo (reali) 
lunghezza e larghezza petalo (reali) 
classe di appartenenza = {Iris-setosa, Iris-versicolor, Iris-virginica}
8"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#8,8,"Naive Bayes classiﬁer: step 1
Calcoliamo la probabilità di appartenenza di una istanza ad una certa 
classe. 
Separiamo i dati in ingresso in base alla classe di appartenenza.  
# Split the dataset by class values
# Restituisce un dizionario classe -> lista di istanze
# Funziona per ogni dataset il cui ultimo valore è la classe di appartenenza
def separate_by_class
 (
dataset
)
:
separated
  = 
dict
()
for 
i 
in 
range
(
len
(
dataset
))
:
vector
 = 
dataset
[
i
]
class_value
  = 
vector
[
-
1
]   # ultimo valore
if 
(
class_value 
 not 
in 
separated
 )
:
separated
 [
class_value
 ]
 = 
list
()
separated
 [
class_value
 ].
append
(
vector
) 
return 
separated
9"
data_test\rootfolder\università\MachineLearning\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#9,9,"Naive Bayes classiﬁer: step 1
# Iris dataset
dataset
 = 
[[
3.393533211
 ,
2.331273381
 ,
0
],
[
3.110073483
 ,
1.781539638
 ,
0
],
[
1.343808831
 ,
3.368360954
 ,
0
],
[
3.582294042
 ,
4.67917911
 ,
0
],
[
2.280362439
 ,
2.866990263
 ,
0
],
[
7.423436942
 ,
4.696522875
 ,
1
],
[
5.745051997
 ,
3.533989803
 ,
1
],
[
9.172168622
 ,
2.511101045
 ,
1
],
[
7.792783481
 ,
3.424088941
 ,
1
],
[
7.939820817
 ,
0.791637231
 ,
1
]]
separated
  = 
separate_by_class
 (
dataset
)
for 
label 
in 
separated
 :
print
(
label
)
for 
row 
in 
separated
 [
label
]
:
print
(
row
)
0
[3.393533211, 2.331273381, 0]
[3.110073483, 1.781539638, 0]
[1.343808831, 3.368360954, 0]
[3.582294042, 4.67917911, 0]
[2.280362439, 2.866990263, 0]
1
[7.423436942, 4.696522875, 1]
[5.745051997, 3.533989803, 1]
[9.172168622, 2.511101045, 1]
[7.792783481, 3.424088941, 1]
[7.939820817, 0.791637231, 1]
10"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Support Vector Machine (SVM)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#1,1,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#10,10,"SVM50 CHAPTER 5. LINEAR DISCRIMINANT FUNCTIONS
transformation ϕ() that well separates the data — so the expected number of support
vectors is small — then Eq. 107 shows that the expected error rate will be lower.
y1y2
R1
R2
optimal hyperplanemaximummargin b
maximummargin b
Figure 5.19: Training a Support Vector Machine consists of ﬁnding the optimal hy-
perplane, i.e., the one with the maximum distance from the nearest training patterns.
The support vectors are those (nearest) patterns, a distance bfrom the hyperplane.
The three support vectors are shown in solid dots.
5.11.1 SVM training
We now turn to the problem of training an SVM. The ﬁrst step is, of course, to choose
the nonlinear ϕ-functions that map the input to a higher dimensional space. Often
this choice will be informed by the designer’s knowledge of the problem domain. In
the absense of such information, one might choose to use polynomials, Gaussians or
yet other basis functions. The dimensionality of the mapped space can be arbitrarily
high (though in practice it may be limited by computational resources).
We begin by recasting the problem of minimizing the magnitude of the weight
vector constrained by the separation into an unconstrained problem by the method
of Lagrange undetermined multipliers. Thus from Eq. 106 and our goal of minimizing
||a||, we construct the functional
L(a,α)=1
2||a||2−n/summationdisplay
k=1αk[zkatyk−1]. (108)
and seek to minimize L() with respect to the weight vector a, and maximize it with
respect to the undetermined multipliers αk≥0. The last term in Eq. 108 expresses
the goal of classifying the points correctly. It can be shown using the so-called Kuhn-
Tucker construction (Problem 30) (also associated with Karush whose 1939 thesis
addressed the same problem) that this optimization can be reformulated as maximiz-
ing
L(α)=n/summationdisplay
k=1αi−1
2n/summationdisplay
k,jαkαjzkzjyt
jyk, (109)
subject to the constraintsVedi Duda et al., Pattern Classification , 2000, pg. 262"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#11,11,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#12,12,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  ℜd: spazio vettoriale di d
dimensioni ( d=3 in figura)
xi: vettore di d componenti 
relativo al pattern i-esimo 
del TS
yi: etichetta relativa al 
pattern i-esimo del TS
w: vettore che indica la 
direzione ortogonale a tutti 
i vettori dell’iperpiano H
b : coefficiente del termine 
noto che compare nell’eq. 
del iperpiano H"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#13,13,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Iperpiano : sottospazio inferiore di una dimensione allo spazio in cui è 
definito (e.g., nello spazio 3D gli iperpiani sono i piani)
!Equazione cartesiana di un piano:
Il luogo delle soluzioni (x,y,z) che verificano l’equazione è il luogo dei 
punti P = (x,y,z) che appartengono al piano
!L’equazione del piano specifica due elementi
!la terna (w1,w2,w3) dei coefficienti detti parametri direttori del piano
che individua la direzione ortogonale a tutti i vettori del piano
!il coefficiente del termine noto b
!In sintesi, per individuare univocamente un piano nello spazio è 
sufficiente disporre della direzione ortogonale al piano we del 
coefficiente bw1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#14,14,"Qualche Richiamo
!Sia      uno spazio vettoriale di dimensione n sul campo    . 
Il prodotto scalare fra due vettori di      è un’operazione che 
generalmente si indica con il simbolo “ •” ed è definita come segue:
ovvero associa ad una coppia di vettori x=(x 1,x2,...,x n)e y=(y 1,y2,...,y n) 
un numero reale così definito 
x∙y = <x,y> = x1y1+x 2y2,..., +x nyn
!Alle volte il prodotto scalare è definito anche come
x∙y = = < x,y> = xty
dove xtyè il prodotto riga per colonna tra il vettore trasposto xte il 
vettore y
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
ℜn
ℜn
•: ℜn×ℜn→ℜℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#15,15,"Qualche Richiamo
!La norma di un vettore                                    è un’applicazione che 
ad un vettore associa un numero reale
Essa è pari alla radice quadrata della somma del quadrato delle 
componenti del vettore o, equivalentemente, alla radice quadrata del 
prodotto scalare del vettore con se stesso
!Fra le proprietà di cui gode la norma vi è quella di omogeneità : x=x1,x2,...,xn ( )∈ ℜn
•: ℜn→ℜ
x=x12+x22+...+xn2=x•x
per ogni x∈ ℜn e per ogni λ∈ ℜ si ha
λx=λx
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#16,16,"Qualche Richiamo
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
!Dato un piano P di equazione
la sua distanza dall’origine degli assi è pari a
!
""!""+""""""+""#""=!
%
!Si può dimostrare che la distanza !di un punto ""da un piano P è pari a
&=%'(+!
""!""+""""""+""#""=%'(+!
%=)(+)
%
mentre se il punto ""appartiene al piano, cioè se ""∈P, allora la 
distanza !é per definizione zero w1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#17,17,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
In altri termini, D(x) è la funzione distanza dall’iperpiano, cioè indica 
quanto il pattern xè distante dalla superficie decisionale "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#18,18,"SVM Lineari: Pattern Separabili
182 4. LINEAR MODELS FOR CLASSIFICATION
Figure 4.1 Illustration of the geometry of a
linear discriminant function in two dimensions.
The decision surface, shown in red, is perpen-
dicular to w, and its displacement from the
origin is controlled by the bias parameter w0.
Also, the signed orthogonal distance of a gen-
eral point xfrom the decision surface is given
byy(x)/∥w∥.x2
x1wx
y(x)
∥w∥
x⊥
−w0
∥w∥y=0
y<0y>0
R2R1
an arbitrary point xand let x⊥be its orthogonal projection onto the decision surface,
so that
x=x⊥+rw
∥w∥. (4.6)
Multiplying both sides of this result by wTand adding w0, and making use of y(x)=
wTx+w0andy(x⊥)=wTx⊥+w0=0, we have
r=y(x)
∥w∥. (4.7)
This result is illustrated in Figure 4.1.
As with the linear regression models in Chapter 3, it is sometimes convenient
to use a more compact notation in which we introduce an additional dummy ‘input’
value x0=1and then deﬁne /tildewidew=(w0,w)and/tildewidex=(x0,x)so that
y(x)=/tildewidewT/tildewidex. (4.8)
In this case, the decision surfaces are D-dimensional hyperplanes passing through
the origin of the D+1-dimensional expanded input space.
4.1.2 Multiple classes
Now consider the extension of linear discriminants to K> 2classes. We might
be tempted be to build a K-class discriminant by combining a number of two-class
discriminant functions. However, this leads to some serious difﬁculties (Duda and
Hart, 1973) as we now show.
Consider the use of K−1classiﬁers each of which solves a two-class problem of
separating points in a particular class Ckfrom points not in that class. This is known
as a one-versus-the-rest classiﬁer. The left-hand example in Figure 4.2 shows an4.1. Discriminant Functions 181
(McCullagh and Nelder, 1989). Note, however, that in contrast to the models used
for regression, they are no longer linear in the parameters due to the presence of the
nonlinear function f(·). This will lead to more complex analytical and computa-
tional properties than for linear regression models. Nevertheless, these models are
still relatively simple compared to the more general nonlinear models that will be
studied in subsequent chapters.
The algorithms discussed in this chapter will be equally applicable if we ﬁrst
make a ﬁxed nonlinear transformation of the input variables using a vector of basis
functions φ(x)as we did for regression models in Chapter 3. We begin by consider-
ing classiﬁcation directly in the original input space x, while in Section 4.3 we shall
ﬁnd it convenient to switch to a notation involving basis functions for consistency
with later chapters.
4.1. Discriminant Functions
A discriminant is a function that takes an input vector xand assigns it to one of K
classes, denoted Ck. In this chapter, we shall restrict attention to linear discriminants ,
namely those for which the decision surfaces are hyperplanes. To simplify the dis-
cussion, we consider ﬁrst the case of two classes and then investigate the extension
toK>2classes.
4.1.1 Two classes
The simplest representation of a linear discriminant function is obtained by tak-
ing a linear function of the input vector so that
y(x)=wTx+w0 (4.4)
where wis called a weight vector , andw0is abias (not to be confused with bias in
the statistical sense). The negative of the bias is sometimes called a threshold .A n
input vector xis assigned to class C1ify(x)/greaterorequalslant0and to class C2otherwise. The cor-
responding decision boundary is therefore deﬁned by the relation y(x)=0 , which
corresponds to a (D−1)-dimensional hyperplane within the D-dimensional input
space. Consider two points xAandxBboth of which lie on the decision surface.
Because y(xA)=y(xB)=0 ,w eh a v e wT(xA−xB)=0 and hence the vector wis
orthogonal to every vector lying within the decision surface, and so wdetermines the
orientation of the decision surface. Similarly, if xis a point on the decision surface,
theny(x)=0 , and so the normal distance from the origin to the decision surface is
given by
wTx
∥w∥=−w0
∥w∥. (4.5)
We therefore see that the bias parameter w0determines the location of the decision
surface. These properties are illustrated for the case of D=2in Figure 4.1.
Furthermore, we note that the value of y(x)gives a signed measure of the per-
pendicular distance rof the point xfrom the decision surface. To see this, consider
Vedi Bishop, Pattern Recognition and Machine Learning , 2006, pg. 182In questo caso la notazione è 
y(x) = wTx + w0  = D(x) = w · x + b
cioè
wTx =w · x = <w,x>
w0 = b"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#19,19,"SVM Lineari: Pattern Separabili
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
4 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili  
Date  due classi  di pattern  (linearmente  separabili ), e un training  set 
TS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i 
pattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  
esistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . 
Un generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): 
 
 
 
 
 
 
 
 
 
 
La distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱
𝐰 
Gli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  
minima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : 
𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 
𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 
o in modo  più compatto : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 
 
 
 
 
Iperpiano  
𝐷𝐱=𝐰∙𝐱+𝑏 
𝐰: vettore normale all’iperpiano  
𝑏/𝐰: distanza dall’origine  
𝐷𝐱=0: luogo dei vettori sul piano  
𝐱=𝐱𝑝+𝑟𝐰
𝐰,𝐷𝐱𝑝=𝟎 
 
 
𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 
 
per semplicità 
omettiamo il trasposto 
nel prodotto scalare  
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Vincoli da soddisfare"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#2,2,"Dilemma
Reti Neurali a un solo strato :
Pro: algoritmo di apprendimento semplice ed efficiente
Cons : potere espressivo limitato (i.e., possono apprendere solo 
“confini” decisionali lineari nello spazio di input)
Reti Neurali multistrato :
Pro: potere espressivo elevato (i.e., possono rappresentare funzioni        
generiche non lineari)
Cons : algoritmo di apprendimento complicato (a causa della 
abbondanza di minimi locali e dell’alto numero di dimensioni  
dello spazio dei pesi)
?:
Pro: potere espressivo elevato
Pro: algoritmo di apprendimento efficiente"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#20,20,"SVM Lineari: Pattern Separabili
5prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM lineari: Pattern Separabili (2)
Laminima distanza tral’iperpiano diseparazione eunpattern del
training setèdetta margine (W).
Ladistanza dei punti che giacciono sull’iperpiano 𝐷𝐱=+1
dall’iperpiano diseparazione (𝐷𝐱=0)è1/𝐰;lostesso vale peri
puntisull’iperpiano 𝐷𝐱=−1.
Pertanto ilmargine èW=2/𝐰.
L’iperpiano ottimo secondo SVM èquello soddisfa ivincoli di
separazione dei pattern emassimizza ilmargine W(o
alternativamente minimizza ilsuoinverso) :
Minimizza :𝐰2/2
Vincoli :𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0𝑝𝑒𝑟𝑖=1…𝑛
Ipattern deltraining setchegiacciono sulmargine (cerchi pieni in
figura) sono detti support vector .Talipattern, checostituiscono icasi
più complessi, definiscono completamente lasoluzione del
problema, che può essere espressa come funzione disolo tali
pattern ,indipendentemente dalla dimensionalità dello spazio𝑑edal
numero𝑛dielementi inTS.𝐷𝐱=+11/𝐰
𝐷𝐱=0
𝐷𝐱=−1𝐷𝐱>+1
𝐷𝐱<−11/𝐰Laminima distanza trapattern del training set didue classi
differenti piùvicini all’iperpiano diseparazione èdetta margine (-)."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#21,21,"SVM Lineari: Pattern Separabili
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 
"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#22,22,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
5 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (2)  
La minima  distanza  tra l’iperpiano  di separazione  e un pattern  del 
training  set è detta  margine  (W). 
 
 
 
 
 
 
 
 
La distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 
dall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i 
punti  sull’iperpiano  𝐷𝐱=−1. 
Pertanto  il margine  è  W= 2/𝐰.  
L’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di 
separazione  dei pattern  e massimizza  il margine  W (o 
alternativamente  minimizza  il suo inverso) : 
Minimizza : 𝐰2/2 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 
I pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in 
figura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi 
più complessi,  definiscono  completamente  la soluzione  del 
problema,  che può essere  espressa  come  funzione  di solo tali 
pattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal 
numero  𝑛 di elementi  in TS.    
 𝐷𝐱=+1 1/𝐰 
𝐷𝐱=0 
𝐷𝐱=−1 𝐷𝐱>+1 
𝐷𝐱<−1 1/𝐰 Funzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#23,23,"6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 SVM Lineari: Pattern Separabili
VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#24,24,"SVM Lineari: Pattern Separabili
6 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (3)  
Il problema  di ottimizzazione  precedente , può essere  risolto  
passando  innanzitutto  a una formulazione  Lagrangiana  e 
successivamente  a una formulazione  duale .  
La formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  
𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  
il vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : 
𝑄𝐰,𝑏,𝛂=1
2𝐰∙𝐰− 𝛼𝑖𝑛
𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 
da minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. 
 
Utilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  
può essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in 
funzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  
funzione  obiettivo  rispetto  ai soli 𝛼𝑖: 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  
 
Per approfondimenti  e derivazione  delle  equazioni : 
S. Gunn,  Support  Vector  Machines  for Classification  and Regression  
C. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  
 
 
prodotto scalare fra 
coppie di vettori del TS 
VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#25,25,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#26,26,"SVM Lineari: Pattern Separabili
7 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Il problema  di ottimizzazione  precedente  può essere  risolto  
attraverso  un algoritmo  di programmazione  quadratica  (disponibile  in 
librerie  numeriche) . 
La soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ 
Le condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non 
sono  support  vector . 
L’iperpiano  ottimo  è dunque  parametrizzato  da:  
     𝐰∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐱𝑖 
e   𝑏∗=𝑦𝑠− 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 
dove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  
 
La funzione  distanza  dall’iperpiano  è: 
𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ 
 
Si noti che: 
Il segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  
pattern  𝐱.  
Le sommatorie  sono  riducibili  ai soli support  vector . 
Nel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, 
conservare/memorizzare  i support  vectors .   
 
 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#27,27,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#28,28,"SVM Lineari: Pattern Separabili
8 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern Separabili (4)  
Vantaggi  dell’approccio  SVM :  
Definizione  della  soluzione  sulla base  di un numero  ridotto  di 
support  vector  (solitamente  pochi) . 
Il numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  
e può essere  dimostrato  che l’errore  medio  (sui possibili  training  
set) è limitato  da 𝑛𝑠𝑣/𝑛. 
SVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  
spazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  
computazionale  nel training  è quadratica  rispetto  al numero  𝑛 di 
pattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 
e per 𝑛 fino a 104. 
 
 
Esempio :  
i support vectors 
(cerchiati ) 
definiscono  la 
soluzione . "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#29,29,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
Vi saranno quindi tante
variabili di slack (scarto)
quanti sono ipattern del
Traning Set(TS) .
Tali variabili saranno, però,
diverse dazero (>0)solo per
ipattern non separabili, cioè
classificati erroneamente"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#3,3,"Support Vector Machine (SVM)
LeMacchine aVettori diSupporto oMacchine Kernel (Support Vector Machine,
SVM) costituiscono uninsieme dimetodi diapprendimento supervisionato .
Possono essere utilizzate siaperfare Classificazione ,siaperfare Regressione .
Inunbreve lasso temporale dalla loro prima implementazione hanno trovato
applicazione inunnutrito numero dibranche scientifiche come Fisica, Biologia,
Chimica :
!Preparazione difarmaci
!Ricerca direlazioni quantitative sulle proprietà distrutture
!Chemiometria
!Sensoristica
!Ingegneria chimica
!Computer vision (e.g.,face detection erecognition inimmagini evideo)
!..."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#30,30,"SVM Lineari: Pattern Non Separabili
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 
9 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili  
In questo  caso  non tutti i pattern  possono  essere  separati  da un 
iperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far 
sì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il 
confine  della  classe . 
A tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si 
modificano  i vincoli  di separazione : 
𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 
Per ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal 
margine . Per i pattern  separabili  del TS le corrispondenti  variabili  di 
slack  assumeranno  valore  0. 
 
 
 
 
 
 
 
L’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il 
margine , ma allo stesso  tempo  minimizzare  il numero  di elementi  
non correttamente  classificati . La funzione  obiettivo,  e di 
conseguenza  il problema  di ottimizzazione  vengono  così modificati : 
Minimizza : 𝐰2
2+𝐶  ξ𝑖 𝑖=1…𝑛 
Vincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  
classificati: [ > 0 "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#31,31,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  -Se C ---> ∞  : non ammettiamo violazioni del margine (hard -margin SVM)
-Se C è finito : ammettiamo violazioni del margine e pattern misclassificati 
(soft-margin SVM)VincoliFunzione 
Obiettivo"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#32,32,"SVM Lineari: Pattern Non Separabili
10 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM lineari: Pattern non Separabili (2)  
Il coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  
l’importanza  relativa  degli  errori  di classificazione  rispetto  
all’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che 
l’utente  deve  scegliere  per il tuning  di SVM . 
Passando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  
uguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  
del limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : 
𝑄𝛂= 𝛼𝑖
𝑖=1…𝑛−1
2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗
𝑖,𝑗=1…𝑛 
 
con vincoli     𝑦𝑖𝛼𝑖=0
𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  
Il metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  
l’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . 
Esempi : 
𝐶=200 
1 solo errore, margine minore  𝐶=10 
2 errori, margine maggiore  
All’aumentare del valore di C
!diminuisce il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#4,4,"SVM
!In1936 ,R.A.Fisher suggested the first algorithm forPattern Recognition
(Fisher 1936 ).
!Aronszajn (1950 )introduced the“Theory ofReproducing Kernels” .
!In1957 Frank Rosenblatt invented alinear classifier called the perceptron (the
simplest kind offeedforward neural network) .
!Vapnik and Lerner (1963 )introduced the Generalized Portrait algorithm (the
algorithm implemented by support vector machines isanonlinear
generalization oftheGeneralized Portrait algorithm) .
!Aizerman, Braverman and Rozonoer (1964 )introduced the geometrical
interpretation ofthekernels asinner products inafeature space .
!Vapnik and Chervonenkis (1964 )further developed the Generalized
Portrait algorithm .
!...
!SVMs close totheir current form were first introduced with apaper attheCOLT
1992 conference (Boser, Guyon and Vapnik 1992 ).
!In1995 thesoft margin classifier was introduced byCortes and Vapnik (1995 );
inthe same year the algorithm was extended tothe case ofregression by
Vapnik (1995 )inThe Nature ofStatistical Learning Theory .
fonte: https://www.svms.org/history.html"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#5,5,"SVM! SVMs (Vapnik, 1990’s) choose the linear separator with the 
largest margin  
• Good according to intuition, theory, practice  
• SVM became famous when, using images as input, it gave 
accuracy comparable to neural-network with hand-designed 
features in a handwriting recognition task Support Vector Machine (SVM) 
V. Vapnik Robust to 
outliers! 
A. Chervonenkis    XXV «                         »   * 1 
1964 
    5 1 9 . 9 5 
                             
 .  .       ,  .  .             
(      ) 
                                  ,                          -
                    .                -                              
                          .                                         -
                                                                
                           . 
1.          
  1 9 5 7  .                                                     -
                                   ,                            -
      . 
                                              ,                
                                                                     
               ,        ,   -       ,                                -
  ,     -       ,                                                    -
     . 
  
      
   . 1 
  1 9 5 7  .                                                  .   -
                                  ,                                  
                   .     -                                    . 1. 
                        ,                                        , 
                                  -        . 
   ,                                                ,        -
        ,                                                        . 
               ,                                      ,             -
    ,          % ,...,  ,                             ,              , 
                   .                                                
        .                                                        
[1].          [ 1]                                           ,           
                                                     .               , 
                                                                     
                                 ,                                  
         .              ,                    U                      
                   
£*= ejx     §2   . . .   cnfn, 
112 
                        
1.              .  . ,              .  .                                     -
             .                          ,  . X X I V ,   6, 1 9 6 3 . 
2. X        .  ,              .  ,              .  .                - 1 ,     
                            .                        ,   4.    -          . 
     . , 1 9 6 2 . 
3.            .  .                                                      . 
 .         ,        .            .    . ,  . 2,   2, 1 9 6 2 . 
4.                .    .                                                    -
            .                        ,   4.    -          .      . , 1 9 6 2 . 
5.            .                                               .          -
              ,   4.    -          .      . , 1 9 6 2 . 
ON A P E R C E P T R O N C L A S S 
V. N . V A P N I K , A . Y A . C H E R V O N E N K I S 
A c l a s s of p e r c e p t r o n s d i f f e r i n g f r o m p e r c e p t r o n s in e x i s t e n c e w i t h t h e l e a r n i n g m e t -
hod is c o n s i d e r e d . S u c h a p e r c e p t r o n is d e s c r i b e d , i t s b l o c k - s c h e m e a n d t h e l e a r n i n g m e t -
hod s a r e p r o p o s e d . T h e a l g o r i t h m s f o r v a r i o u s c l a s s e s of p e r c e p t r o n s a r e c o m p a r e d w i t h 
the t h e o r y of p a t t e r n r e c o g n i t i o n w i t h t h e h e l p of a g e n e r a l i z e d p o r t r a i t . Journal of Machine Learning Research 16 (2015) 2067-2080 Published 9/15
Alexey Chervonenkis’s Bibliography
Alex Gammerman alex@cs.rhul.ac.uk
Vladimir Vovk v.vovk@rhul.ac.uk
Computer Learning Research Centre, Department of Computer Science
Royal Holloway, University of London
This bibliography does not contain Alexey’s patents (he has at least two), technical reports,
unpublished manuscripts, and collections edited by him. ""NA"" indicates that a journal paper
was not assigned to a volume; e.g., it is common for Russian journals (such as Проблемы
управления and, in some years, Автоматика и телемеханика ) not to have volumes, and
also to have pages numbered separately inside each issue. All papers published by Alexey
before 2001 (and afterwards in the case of papers whose original language was Russian) have
author lists ordered according to the Cyrillic alphabetic order; for other papers the order
may reﬂect the authors’ contributions (people who contributed most tend to be listed ﬁrst)
and administrative positions (bosses tend to be listed last).
The bibliography is given by the year of the original publication (which may be di ﬀerent
from the year of the English translation, always given ﬁrst when available).
1964
[1] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of perceptrons. Au-
tomation and Remote Control ,2 5 ( 1 ) : 1 0 3 – 1 0 9 ,1 9 6 4 . R u s s i a no r i g i n a l : В.Н.Вапник ,
А.Я.Червоненкис .Об одном классе персептронов .Автоматика и телемеханика ,
25(1):112–120, 1964; with English summary entitled “On a perceptron class”. The orig-
inal article submitted on 21 February 1963.
[2] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of pattern-recognition
learning algorithms. Automation and Remote Control ,2 5 ( 6 ) : 8 3 8 – 8 4 5 ,1 9 6 4 . R u s s i a n
original: В.Н.Вапник ,А.Я.Червоненкис .Об одном классе алгоритмов обучения
распознаванию образов .Автоматика и телемеханика , 25(6):937–945, 1964; with
English summary entitled “A class of algorithms for pattern recognition learning”. The
submission date is not given.
[3] Vladimir N. Vapnik, Lyudmila M. Dronfort, and Alexey Ya. Chervonenkis. Some ques-
tions of the self-organization of recognizing systems (in Russian). In Theory and Appli-
cation of Automatic Systems (Russian), pages 172–177. Nauka, Moscow, 1964. In the
original language: В.Н.Вапник ,Л.М.(Людмила Михайловна )Дронфорт ,А.Я.
Червоненкис .Некоторые вопросы самоорганизации распознающих устройств .
Теория и применение автоматических систем ,сс.1 7 2 – 1 7 7 . Наука ,Москва ,1 9 6 4 .
c 2015 Alex Gammerman and Vladimir Vovk."
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#6,6,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#7,7,"SVM
Le SVM si fondano su tre idee chiave
!L’adozione di tecniche di ottimizzazione matematica per 
individuare soluzioni (i.e., iperpiani) con un basso tasso di errori
!La ricerca di un separatore con margine largo per migliorare la 
generalizzazione 
!L’impiego dello stratagemma del kernel (kernel trick) per rendere 
computazionalemente efficienti ampi spazi di feature1.  Use optimization to find solution (i.e. a hyperplane) 
with few errors 
2.  Seek large margin separator to improve 
generalization 
3.  Use kernel trick to make large feature 
spaces computationally efficient Support vector machines: 3 key ideas "
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#8,8,"SVM
2 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Support Vector  Machines  (SVM)  
La teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  
introdotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e 
perfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. 
SVM  è uno degli  strumenti  più utilizzati  per la classificazione  di 
pattern . 
Invece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  
suggerisce  di risolvere  direttamente  il problema  di interesse  (che 
considera  più semplice),  ovvero  determinare  le superfici  decisionali  
tra le classi  (classification  boundaries ). 
 
andiamo per gradi …  
SVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più 
classi . Affrontiamo  la trattazione  per gradi : 
SVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e 
pattern  del training  set linearmente  separabili  (i.e., esiste  per 
ipotesi  almeno  un iperpiano  in grado  di separarli) . 
SVM  lineare  e pattern  non linearmente  separabili . Ci saranno  
inevitabilmente  errori  di classificazione  nel training  set non 
esistendo  alcun  iperpiano  in grado  di separare  i pattern . 
SVM  non lineare  (i.e., superficie  di separazione  complessa ) 
senza  ipotesi  sulla separabilità  dei pattern . 
Estensione  multiclasse . 
 Iperpiano: sottospazio di dimensione inferiore di uno (n-1) rispetto allo spazio in 
cui è contenuto (n) (e.g., se lo spazio ha dimensione 3, i suoi iperpiani sono i piani)"
data_test\rootfolder\università\MachineLearning\34-SVM(1)-sbloccato.pdf#9,9,"3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
3 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: l’idea  
Date  due classi  di pattern  multidimensionali  linearmente  separabili,  
tra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in 
grado  di separare  le classi  con il maggior  margine  possibile . 
Il margine  è la distanza  minima  di punti  delle  due classi  nel training  
set dall’iperpiano  individuato . Definizione  formale  in seguito . 
 
 
 
 
 
 
 
 
 
 
 
La massimizzazione  del margine  è legata  alla generalizzazione . Se i 
pattern  del training  set sono  classificati  con ampio  margine  si può 
«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  
siano  gestiti  correttamente .  
SVM"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#0,0,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#1,1,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#10,10,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Si può vedere che il kernel RBF (o gaussiano) equivale a eseguire 
il prodotto interno dei dati di input mappati in un feature space a 
dimensione infinita "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#11,11,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 Il kernel 2-layer Neural Network è anche detto kernel Sigmoid"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#12,12,"SVM Non Lineari: Kernel Function
!Inoltre spesso viene chiamato kernel lineare il kernel
che equivale a utilizzare una funzione di mapping φtale 
che φ(x)=x, cioè a nonutilizzare un kernelK(x,x')=(x⋅x')"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#13,13,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  All’aumentare del valore dell’iperparametro q (grado del polinomio)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#14,14,"SVM Non Lineari: Esempi
13 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Esempi  
Polinomio 𝑞 = 2 Polinomio 𝑞 = 10 
RBF V = 1 RBF V = 0.2  
Al diminuire del valore dell’iperparametro !(deviazione standard)
!aumenta il numero di support vector (i.e., complessità del problema)
!diminuisce il numero di errori sul Traning Set (da 1 a 0)
!diminuisce il margine di separazione (i.e., capacità di generalizzazione)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#15,15,"Sommario
!SVM Lineari: Pattern Linearmente Separabili e Non
!SVM Non Lineari
!SVM Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#16,16,"SVM: Multiclasse
14 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: estensione multiclasse  
SVM  è in grado  di determinare  la superficie  di separazione  tra 2 
classi  di pattern ; come  gestire  allora  i problemi  con più di 2 classi  ? 
Si tratta  di un problema  ancora  aperto  anche  se esistono  diverse  
soluzioni ; le più utilizzate  sono : 
 
One-Against -One: che studieremo  in seguito  nell’ambito  dei multi -
classificatori . 
 
One-Against -All: 
Date  𝑠 classi , 𝑤1,𝑤2…𝑤𝑠 
Per ogni classe  𝑤𝑘, si determina  con SVM  la superficie  di 
separazione  tra i pattern  di 𝑤𝑘 (etichettati  +1) da una parte,  e i 
pattern  di tutte le rimanenti  classi  𝑤ℎ,ℎ≠𝑘 (etichettati  -1) 
dall’altra,  ottenendo  la funzione  𝐷𝑘𝐱 che indica  quanto  𝐱 è 
distante  dalla  superficie  decisionale  in direzione  di 𝑤𝑘. 
Maggiore  è 𝐷𝑘𝐱 più confidenti  siamo  dell’appartenenza  di 𝐱 a 
𝑤𝑘.  
Al termine  del training,  si assegna  il pattern  𝐱 alla classe  𝑘∗ per 
cui è massima  la distanza  dalla  superficie  decisionale :  
𝑘∗=𝑎𝑟𝑔 𝑚𝑎𝑥
𝑘𝐷𝑘𝐱 
Nota : È necessario  eseguire  𝑠 training  SVM   
 
 
 !One-Against -One
!One-Against -All"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#17,17,"One-Against -One
E’ingenere piùaccurato diOne-Against -All(vedi dopo), anche se
meno efficiente inquanto richiede l’addestramento diunnumero
maggiore diclassificatori
24 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  One-Against -One 
L’approccio  One-Against -One, consente  di risolvere  un problema  di 
classificazione  multi -classe , attraverso  classificatori  binari . 
È l’approccio  adottato  dalla  libreria  LIBSVM  (usata  in BioLab ). 
Se 𝑠 sono  le classi  del problema,  si addestrano  
𝑠×𝑠−1/2 classificatori  binari : tutte le possibili  coppie , 
indipendentemente  dall’ordine . 
Durante  la classificazione,  il pattern  𝐱 viene  classificato  da ogni 
classificatore  binario,  che assegna  un voto alla classe  (tra le due) 
più probabile .  
Al termine  il pattern  𝐱 è assegnato  alla classe  che ha ricevuto  più 
voti (majority  vote rule).  
 
È in genere  più accurato  di One-Against -All (discusso  in precedenza  
per SVM),  anche  se meno  efficiente  in quanto  richiede  
l’addestramento  di un numero  maggiore  di classificatori . 
 
 (Numero di combinazioni di classe k=2)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#18,18,"14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
 ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVMSVM: Multiclasse
(con x pattern da classificare 
e k=1, 2 ... s)  
14prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: estensione multiclasse
SVM èingrado dideterminare lasuperficie diseparazione tra2
classi dipattern ;come gestire allora iproblemi conpiùdi2classi ?
Sitratta diunproblema ancora aperto anche seesistono diverse
soluzioni ;lepiùutilizzate sono :
One
-Against -One:chestudieremo inseguitonell’ambito deimulti -
classificatori .
One
-Against -All:
Date
𝑠classi ,𝑤1,𝑤2…𝑤𝑠
Per
ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di
separazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei
pattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)
dall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è
distante dalla superficie decisionale indirezione di𝑤𝑘.
Maggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a
𝑤𝑘.
Al
termine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per
cuièmassima ladistanza dalla superficie decisionale :
𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥
𝑘𝐷𝑘𝐱
Nota :Ènecessario eseguire 𝑠training SVM"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#19,19,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#2,2,"Kernel Trick
SVM Classification
Ovviamente le SVM possono essere
usate per separare classi che non
potrebbero essere separate con un
classificatore lineare, altrimenti la loro
applicazione a casi di reale interesse
non sarebbe possibile. In questi casi le
coordinate degli oggetti sono mappate
in uno spazio detto “feature space”
utilizzando funzioni non lineare,
chiamate “feature function” ϕ.Ilfeature
 chiamate “feature function” ϕ.Ilfeature
space è uno spazio fortemente
multidimensionale in cui le due classi
possono essere separate con un
classificatore lineare.
Quindi lo spazio iniziale viene rimappato
nel nuovo spazio, a questo punto viene
identificato il classificatore che poi viene
riportato nello spazio iniziale, come
illustrato in figura.Fonte: Stefano Cavuoti
SVM Classification
La funzione ϕcombina quindi lo spazio iniziale (le 
caratteristiche originali degli oggetti) nello spaz io 
delle features che potrebbe in linea di principio 
avere anche dimensione infinita. A causa del fatto 
che questo spazio ha molte dimensioni non 
sarebbe pratico utilizzare una funzione generica 
per trovare l’iperpiano di separazione, quindi 
vengono usate delle funzioni dette “kernel” e si 
identifica la funzione ϕtramite una combinazione 
di funzioni di kernel.
Fonte: http://www.ivanciuc.org/
di funzioni di kernel.
L’implementazione più famosa delle SVM (libSVM) 
usa quattro possibili kernel:
Fonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg
Kernel trick–(1)
•Possiamo trasformare i dati nell' input space in un nuovo 
spazio, detto feature space , a più alta dimensionalità
•I vettori che prima non erano linearmente separabili hanno più 
probabilità di esserlo in uno spazio a più dimensioni
25
Idea:trasformare idati nell’Input Space inunnuovo spazio, detto
Feature Space ,apiùaltadimensionalità .
Ipattern che prima non erano linearmente separabili nello spazio di
partenza hanno piùprobabilità diesserlo inuno spazio apiùdimensioni,
essendo ilnumero digradi dilibertà piùelevato ."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#20,20,"SVM: Implementazione
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
 15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM  (wrapped  da BioLab ) 
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 
15 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM: implementazione  
 
Il training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di 
risolvere  un problema  di programmazione  quadratica .  
Alcune  implementazioni  sono  disponibili  on-line. Ad esempio : 
LIBSVM   
http://www .csie.ntu.edu.tw/~cjlin/libsvm  
Attenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  
diverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). 
In particolare  si fa uso del generico  parametro  gamma  (𝛾) per 
regolare  la complessità  della  superficie  decisionale . 
Aumentando  γ la superficie  può assumere  forme  più 
complesse . 
N.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. 
Inserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e 
Coef 0) 
Per la classificazione  multiclasse  utilizza  internamente  One-
Against -One [2] (accurato  ma inefficiente  per molte  classi ). 
[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  
Classification,  disponibile  sul sito web di LIBSVM  
[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . 
ACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, 
2011 , disponibile  sul sito web di LIBSVM  
 
LIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / 
Stessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  
dimensionalità  ed elevato  numero  di pattern . 
SVM -light - http://svmlight .joachims .org 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#21,21,"SVM: Implementazione
27LIBSVM :AL i b r a r yf o rS u p p o r tV e c t o rM a c h i n e s
CHIH-CHUNG CHANG and CHIH-JEN LIN ,N a t i o n a lT a i w a nU n i v e r s i t y
LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package
since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained
wide popularity in machine learning and many other areas. In this article, we present all implementation
details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass
classiﬁcation probability estimates and parameter selection are discussed in detail.
Categories and Subject Descriptors: I.5.2 [ Pattern Recognition ]: Design Methodology— Classiﬁer design
and evaluation ;G . 1 . 6[ Numerical Analysis ]: Optimization— Quadratic programming methods
General Terms: Algorithms, Performance, Experimentation
Additional Key Words and Phrases: Classiﬁcation LIBSVM optimization regression support vector machines
SVM
ACM Reference Format:
Chang, C.-C. and Lin, C.-J. 2011. LIBSVM : A library for support vector machines. ACM Trans. Intell. Syst.
Technol. 2, 3, Article 27 (April 2011), 27 pages.
DOI=10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
1. INTRODUCTION
Support Vector Machines (SVMs) are a popular machine learning method for clas-
siﬁcation, regression, and other learning tasks. Since the year 2000, we have been
developing the package LIBSVM as a library for support vector machines.1LIBSVM is
currently one of the most widely used SVM software. In this article,2we present all
implementation details of LIBSVM .H o w e v e r ,t h i sa r t i c l ed o e sn o ti n t e n dt ot e a c ht h e
practical use of LIBSVM . For instructions of using LIBSVM ,s e et h e README ﬁle included
in the package, the LIBSVM FAQ ,3and the practical guide by Hsu et al. [2003].
LIBSVM supports the following learning tasks.
(1) SVC: support vector classiﬁcation (twoclass and multiclass);
(2) SVR: support vector regression.
(3) One-class SVM.
1The Web address of the package is at http://www.csie.ntu.edu.tw/ ∼cjlin/libsvm.
2This LIBSVM implementation document was created in 2001 and has been maintained at
http://www.csie.ntu.edu.tw/ ∼cjlin/papers/libsvm.pdf.
3LIBSVM FAQ :h t t p : / / w w w . c s i e . n t u . e d u . t w / ∼cjlin/libsvm/faq.html.
This work was supported in part by the National Science Council of Taiwan via the grants NSC 89-2213-E-
002-013 and NSC 89-2213-E-002-106.
Authors’ addresses: C.-C. Chang and C.-J. Lin (corresponding author), Department of Computer Science,
National Taiwan University, Taipei 106, Taiwan; email: cjlin@csie.ntu.edu.tw.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that
copies show this notice on the ﬁrst page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior speciﬁc permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1( 2 1 2 )
869-0481, or permissions@acm.org.
c⃝2011 ACM 2157-6904/2011/04-ART27 $10.00
DOI 10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199
ACM Transactions on Intelligent Systems and Technology, Vol. 2, No. 3, Article 27, Publication date: April 2011.
15prof. Davide Maltoni –Università di Bologna
ML
ClassificazioneSVM: implementazione
Iltraining diSVM, richiede algoritmi numerici nonbanali ingrado di
risolvere unproblema diprogrammazione quadratica .Alcune
implementazioni sono disponibili on-line:
LIBSVM
 -http://www .csie.ntu.edu.tw/~cjlin/libsvm
Attenzione
 iKernel (RBF, ecc.)sono parametrizzati inmodo
diverso daquello comune (vedi Readme .txtdiLibSvm e[1]).In
particolare sifausodelparametro gamma (𝛾)perregolare la
complessità della superficie decisionale .Aumentando γla
superficie puòassumere forme piùcomplesse .
N.B.Con kernel RBFγopera inmodo inverso rispetto a𝜎.
Inserito
γanche nelkernel polinomiale (oltre algrado polinomio e
Coef 0)
Per
 laclassificazione multiclasse utilizza internamente One-
Against -One [2](accurato mainefficiente permolte classi ).
Wrapped
 daScikit -Learn→sklearn .svm.SVC
[1]C.W.Hsu, C.C.Chang, andC.J.Lin,APractical Guide toSupport Vector
Classification, disponibile sulsitoweb diLIBSVM
[2]C.C.Chang andC.J.Lin.LIBSVM :alibrary forsupport vector machines .
ACM Transactions onIntelligent Systems andTechnology, 2:27:1--27:27,
2011 ,disponibile sulsitoweb diLIBSVM
LIBLINEAR
 -https ://www .csie.ntu.edu.tw/~cjlin/liblinear /
Stessi
 autori diLIBSVM, consigliata nelcaso lineare perelevata
dimensionalità edelevato numero dipattern .
Wrapped
 daScikit -Learn→sklearn .svm.LinearSVC
SVM
 -light -http://svmlight .joachims .org"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#22,22,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaSVM Lineare"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#23,23,"Esempi LIBSVM
16 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Esempi LibSvm  (1) 
«maschi -femmine»  
 
Lineare , 𝐶=10 Lineare , 𝐶=500 
Polinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
SVM Non Lineare (Kernel Polinomiale)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#24,24,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#25,25,"Esempi LIBSVM
17 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 
RBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezza
PesoAltezzaEsempi LibSvm  (2) 
«maschi -femmine»  
 
SVM Non Lineare (Kernel RBF)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#26,26,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Lineare e Non Lineare (Kernel Polinomiale)
Caso Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#27,27,"Esempi LIBSVM
18 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  Lineare , 𝐶=100 
Polinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 
Esempi LibSvm  (3) 
multiclasse  
 
SVM Non Lineare (Kernel Polinomiale e Kernel RBF)
Caso Multiclasse"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#28,28,"Esempi LIBSVM
Una semplicissima applicazione sviluppata
daicreatori della libreria LIBSVM che ne
illustra ilfunzionamento èdisponibile allink
seguente :
https://www.csie.ntu.edu.tw/~cjlin/libsvm/
Inparticolare, cliccando col mouse si
tracciano dei punti sullo schermo,
premendo suChange sicambia laclasse (il
colore deipunti relativi) ;infine, premendo
suRun, una semplice SVM attribuisce al
piano l’appartenenza alle varie classi
mostrandole colorate inmaniera diversa .
LIBSVM is an integrated software for support vector classification, (C -SVC, nu -SVC), 
regression (epsilon -SVR, nu -SVR) and distribution estimation (one -class SVM). 
It supports multi -class classification. "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#29,29,"Esempi LIBSVM
This isasimple graphical interface which
shows how SVM separate data inaplane .
You canclick inthewindow todraw data
points .Use ""change"" button tochoose
class 1,2or3(i.e.,uptothree classes are
supported), ""load"" button toload data from
afile,""save"" button tosave data toafile,
""run"" button toobtain anSVM model, and
""clear"" button toclear thewindow .Youcan
enter options inthebottom ofthewindow,
thesyntax ofoptions isthesame as`svm -
train' .Note that""load"" and""save"" consider
data inthe classification but not the
regression case .Each data point hasone
label (the color) which must be1,2,or3
and two attributes (x-axis and y-axis
values) in[0,1].Type `make' inrespective
directories tobuild them ..."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#3,3,"!Dato un insieme              , una funzione                           è un kernel se 
risulta che  
dove                     e   è uno spazio di Hilbert
!Lo Spazio di Hilbert è uno spazio vettoriale che generalizza la nozione 
di Spazio Euclideo
!φ è la funzione di mapping dall’Input Space al Feature Space
!Si può dimostrare che una funzione                           è un kernel se, e 
solo se, comunque si scelgano r elementi x1, x 2, ..., x r∈X, la matrice 
K=[k(x i,xj)]i,j=1,...,r è simmetrica e semidefinita positiva
!Ogni matrice simmetrica semidefinita positiva ha tutti gli autovalori non 
negativik(x,y)=φ(x),φ(y)   ∀x,y∈XX⊂ ℜ k:X×X→ℜ
ϕ:X→ΗΗ
k:X×X→ℜKernel"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#30,30,Esempi LIBSVM
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#31,31,"Esempi LIBSVM
Q:What isthedifference between
nu-SVC and C-SVC? Basically they
arethesame thing butwith different
parameters .The range ofCisfrom
zero toinfinity but nu isalways
between [0,1].Anice property ofnuis
thatitisrelated totheratio ofsupport
vectors and theratio ofthetraining
error.
Additionally one-class SVM type is
supported fordistribution estimation .
The one-class SVM type gives the
possibility tolearn from justone class
ofexamples and later ontest ifnew
examples match theknown ones ."
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#32,32,"SVM in pratica
19 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM in pratica  
Lineare  o Non-lineare?   
se la dimensionalità  𝑑 dello  spazio  è molto  elevata  (es. 5000  
feature ) si utilizza  generalmente  SVM  lineare . Infatti  in uno 
spazio  così grande  i pattern  sono  tipicamente  molto  sparsi  e 
anche  «semplici»  iperpiani  sono  in grado  di separare  le 
classi  efficacemente . Il solo iperparametro  da tarare  è 𝐶.  
per bassa  dimensionalità  (es. 20 feature ) la scelta  primaria  è 
SVM  non lineare  con kernel  RBF. Gli iperparametri  da tarare  
sono  𝐶 e V (o γ se si utilizza  LIBSVM ). 
Per media  dimensionalità  (es. 200 features ) in genere  si 
provano  entrambe  le tipologie  (i.e., anche  questa  scelta  
diventa  un iperparametro ). 
Come  sempre  gli iperparametri  si tarano  su un validation  set 
separato,  oppure  attraverso  cross -validation  sul training  set. 
 
Come  gestire  il caso  multi -classe?   
Tipicamente  ci si affida  alla soluzione  disponibile  nella  libreria  
utilizzata  (One-Agaist -One per LIBSVM ). 
Se però il numero  di classi  è molto  elevato,  il costo  può 
diventare  inaccettabile  per certe  applicazioni . In questo  caso  
One-Against -All diventa  la scelta  obbligata .  
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#33,33,"SVM in pratica
"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#34,34,"SVM in sintesi
!Vantaggi
!Si basa su una teoria ben fondata
!Presenta eccellenti proprietà di generalizzazione
!La funzione obiettivo non presenta minimi locali
!Può essere impiegata per individuare funzioni discriminanti non lineari
!La complessità del classificatore è caratterizzata dal numero di su pport 
vector piuttosto che dalla dimensionalità dello spazio trasformato
!Svantaggi
!Tende ad essere più lenta rispetto ad altri metodi
!La programmazione quadratica è computazionalmente onerosa "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#35,35,"!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , 
Pearson, 2020.
!C. Burges, A Tutorial on Support Vector Machines for Pattern Recognition , 
1998.
!S. Gunn, Support Vector Machines for Classification and Regression , 1998.
!D. Maltoni, Machine Learning , Università di Bologna, 2017.
!C.W. Hsu, C.C. Chang, and C.J. Lin, A Practical Guide to Support Vector 
Classification , Last updated: May 19, 2016.
!C.C. Chang and C.J. Lin, LIBSVM: A Library for Support Vector Machines , ACM 
Transactions on Intelligent Systems and Technology, 2:27:1 —27:27, 2011.
!G. Raiconi, Support Vector Machines: Concetti ed Esempi , Università di 
Salerno 2016.
!R.O. Duda, P.E. Hart, and D.G. Stork. 2000. Pattern Classification (2nd 
Edition). Wiley -Interscience, New York, NY, USA. 
!C.M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.Riferimenti"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#4,4,"Kernel
!Uno spazio di Hilbert     è uno spazio vettoriale Hreale o 
complesso sul quale è definito un prodotto interno tale che, detta d 
la distanza indotta da       su H, lo spazio metrico ( H, d) sia completo
!Uno spazio metrico è un insieme di elementi, detti punti , nel quale è 
definita una distanza , detta anche metrica (lo spazio metrico più 
comune è lo spazio euclideo di dimensione 1, 2 o 3)
!Uno spazio metrico completo è uno spazio metrico in cui tutte le 
successioni di Cauchy sono convergenti ad un elemento dello spazio
!Una successione di Cauchy è una successione tale che, comunque si 
fissi una distanza arbitrariamente piccola ε> 0, da un certo punto in poi 
tutti gli elementi della successione hanno distanza reciproca inferiore 
ad ε=(H,⋅,⋅) Η
⋅,⋅
⋅,⋅"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#5,5,"SVM Non Lineari
11 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari  
SVM  prevede  un’importante  estensione  della  teoria  inizialmente  
sviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei 
pattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in 
modo  molto  semplice :    
Viene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  
di partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  
(𝑚>𝑑): 
Φ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 
Nello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  
Φ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da 
un iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i 
pattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  
Analizzando  la formulazione  del problema  lagrangiano -duale , si nota 
che i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  
tra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di 
evitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  
raggiungere  dimensione  108 e anche  assumere  valore  infinito) . 
Infatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  
scalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 
(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  
Φ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ 
Ciò consente  di risolvere  il problema  di ottimizzazione  senza  
particolari  complicazioni  rispetto  al caso  lineare . Una volta  
determinati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di 
classificazione)  è esprimibile  come :  
𝐷𝐱= 𝛼𝑖∗
𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ 
 
 "
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#6,6,"SVM Non Lineari
!In altri termini, possiamo calcolare w*, b*e funzione di 
decisione in maniera analoga a quanto visto in precedenza
!Utilizzando il kernel evitiamo l’operazione costosa di 
trasformazione e prodotto interno nello spazio trasformato, 
essendo il kernel una funzione dei pattern originali definiti 
nell’Input Space ℜd
!Possiamo inoltre effettuare trasformazioni in spazi a 
dimensione infinita
!In sintesi, le proprietà del prodotto scalare consentono di 
esprimere il prodotto scalare dei pattern immagine (""(x) ∈ℜm) 
corrispondenti ai pattern in input (x ∈ℜd) semplicemente come 
funzioni kernel dei pattern in input (x ∈ℜd)"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#7,7,"Kernel Trick
!Pattern linearmente non separabili possono diventare 
linearmente separabili se trasformati, o mappati, in uno spazio 
dimensionale superiore
!Il calcolo della matematica vettoriale (cioè i prodotti scalari) in 
uno spazio dimensionale assai elevato è costoso dal punto di 
vista computazionale
!Il trucco del kernel consente di calcolare in modo efficiente 
prodotti scalari di dimensioni molto elevate
!Esso consente di mappare in pattern in input in modo implicito 
in uno spazio dimensionale più elevato (possibilmente infinito) 
con un overhead computazionale ridotto
!“In modo implicito”, in quanto i vettori a dimensionalità 
superiore non sono mai effettivamente costruiti"
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#8,8,"Kernel Function: Esempio
!Supponiamo di avere i seguenti due vettori bidimensionali 
""=$!,$""e &='!,'""
!La funzione seguente ((*)mappa vettori bidimensionali in vettori 
tridimensionali
!Il modo standard per calcolare
è prima mappare i pattern in input nello spazio delle feature e poi 
eseguire il prodotto scalare nello spazio a dimensione più elevata
!Tuttavia, il prodotto scalare può essere effettuato interamente nello 
spazio originale a due dimensioni(,=-!""
2-!-""
-""""
(""*(&
(""*(&=$!""'!""+2$!$""'!'""+$""""'""""=""*&"""
data_test\rootfolder\università\MachineLearning\35-SVM(2)-sbloccato.pdf#9,9,"SVM Non Lineari: Kernel Function
12 prof. Davide Maltoni  – Università di Bologna  
ML 
Classificazione  SVM Non lineari: Kernel  functions  
Polinomio  di grado   𝑞 (iperparametro ): 
 Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le 
possibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  
componenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: 
Φ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  
 e quindi  𝑚=9.  
 Si dimostra  che: 
𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 
Radial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): 
 
𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2
2𝜎2 
2-layer  Neural  Network  (meno  utilizzato) : 
 
𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 
 
𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : 
una possibile  scelta  è: 𝜈=1,𝑎=1 
Il numero  di hidden  units  e i pesi sono  determinati  
automaticamente  da SVM  
 
 
 
 
 
 
 
 
 "
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#0,0,"MATLAB (MATrix LABoratory)
!Per installare il sofftware, accedere all’Area Sistemi Informativi di Roma Tre 
disponibile al seguente indirizzo: http://asi.uniroma3.it/ ---> cliccare su ‘servizi 
agli studenti’ ---> scorrere fino in fondo e cliccare su ‘MathWorks’
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#1,1,"MATLAB
Manualetto di Matlabr
L. Scuderi
1 Comandi d’avvio
Per avviare Matlab in ambiente Windows ` e su éciente selezionare con il mouse l’icona corrispon-
dente. In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il tasto di invio (o
enter, return, ...). Il simbolo >>che compare, ` e il prompt di Matlab . Per eseguire un comando
digitato occorre premere il tasto di invio. Per terminare la sessione di lavoro occorre digitare il
comando exit oppure quit .
Tabella 1. Alcuni comandi per gestire una sessione di lavoro.
Comando Signiﬁcato
help per visualizzare tutti gli argomenti presenti
help arg per visualizzare informazioni su arg
doc arg per visualizzare dettagliate informazioni su arg
clc per cancellare il contenuto della ﬁnestra di lavoro
; per non visualizzare il risultato di un’istruzione
... per continuare a scrivere un’istruzione nella riga successiva
who per visualizzare le variabili poste in memoria
whos per visualizzare informazioni sulle variabili poste in memoria
clear per cancellare tutte le variabili dalla memoria
clear var1 var2 per cancellare le variabili var1 evar2 dalla memoria
2 Le variabili in Matlab
I nomi delle variabili possono essere lunghi al massimo 32 caratteri. I caratteri utilizzabili sono
le lettere (maiuscole e minuscole), i numeri e il carattere “ _” (underscore). Un nome di variabile
deve cominciare con un carattere alfabetico (a-z, A-Z). Matlab distingue tra lettere maiuscole
e minuscole (ad esempio i nomi a1edA1rappresentano variabili diverse). La variabile si crea
automaticamente nel momento in cui si assegna ad essa un valore o il risultato di un’espressione.
L’assegnazione avviene mediante il simbolo =secondo la seguente sintassi
>> nome_variabile=espressione
Se la variabile che si vuole creare ` e di tipo stringa occorre racchiudere espressione tra una
coppia di apici. Nella tabella 2 abbiamo riportato alcune variabili scalari predeﬁnite.
Matlab lavora con sedici cifre signiﬁcative. Tuttavia, in output una variabile intera viene
visualizzata generalmente in un formato privo di punto decimale, mentre una variabile reale (non
intera) viene visualizzata solo con quattro cifre decimali. Se si vuole modiﬁcare il formato di output
si pu` o utilizzare uno dei comandi della tabella 3. Per visualizzare tutte le sedici cifre impiegate da
Matlab ` e necessario attivare il comando format long e .
Nella tabella 4 abbiamo riportato le principali operazioni eseguibili sulle variabili scalari. Oltre
alle operazioni di base, in Matlab sono presenti anche le funzioni predeﬁnite riportate nella tabella
5.
Gli elementi di un vettore vanno digitati tra parentesi quadre; gli elementi di un vettore riga
vanno separati con uno spazio oppure una virgola, quelli di un vettore colonna con un punto e virgola
1!Per avviare Matlab in ambiente Windows o Mac è sufficiente selezionare con 
il mouse l’icona corrispondente!In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il 
tasto Invio (o Enter, Return, ... )!Il simbolo >> che compare nella Command Window è il prompt di Matlab!Per eseguire un comando digitato occorre premere il tasto Invio!Per terminare la sessione di lavoro occorre digitare il comando exit o quit!Seguono alcuni comandi per gestire una sessione di lavoro"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#10,10,"Esempi in MATLAB
!Overfitting con SVM Non Lineare (Kernel Gaussiano)
σ=1/15, C=106Esempi in MATLAB –(7)
49
•Vediamo invece un esempio di overfitting utilizzando il kernel
gaussiano con 𝜎=1/15e 𝐶=106:
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#11,11,"Esempi in MATLAB
% … caricamento dei dati come nel caso precedente …%
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei petali
y = ~strcmp(species,'virginica'); % label 0 se Iris viginica, 1 se altre specie
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6,'KernelFunction' ,'gaussian' ,'KernelScale' ,
1/15);
% … disegno dello scatter plot come nel caso precedente …%
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2),'ko','MarkerSize',10) % cerchia i vettori di supporto
legend('Iris virginica','Altre specie','Support vectors','Location','southeast')
axis manual
% … disegno dello scatter plot come nel caso precedente …%
d=0.02; % intervallo utilizzato per generare la griglia di punti
[x1Grid,x2Grid]=meshgrid(min(X(:,1)):d:max(X(:,1)),min(X(:,2)):d:max(X(:,2))); % 
generazione della griglia
xGrid=[x1Grid(:),x2Grid(:)];
[~,scores1]=predict(SVMModel,xGrid); % valutiamo l’output del modello nei punti 
della griglia
contour(x1Grid,x2Grid,reshape(scores1(:,2),size(x1Grid)),[0 0],'k'); % plot del 
confine di decisione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#12,12,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#13,13,"Esempi in MATLAB
σ=1/15, C=106
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#14,14,"Esempi in MATLAB
σ=1/15, C=106Esempi in MATLAB –(8)
50
𝐶=106,𝜎=1/15
!Overfitting con SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#15,15,"Esempi in MATLAB
!Esempio di SVM Non Lineare (Kernel Gaussiano)
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#16,16,"Esempi in MATLAB
σ=5, C=100
% … caricamento dei dati come nel caso precedente …%
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);
% … disegno dello scatter plot come nel caso precedente …%
C σ!Esempio di SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#17,17,"Esempi in MATLAB
σ=5, C=100
Esempi in MATLAB –(8)
51
𝐶=100,𝜎=5!Esempio di SVM Non Lineare (Kernel Gaussiano)"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#18,18,"Classification Learner
The Classification Learner app lets you train models toclassify data using supervised
machine learning .
Using Classification Learner, you can perform common machine learning tasks such
asinteractively exploring your data, selecting features, specifying validation schemes,
training models, and assessing results .Choose from several classification types
including decision trees ,support vector machines (SVM) ,and k-nearest neighbors ,
and select from ensemble methods such asbagging, boosting, and random subspace .
Classification Learner helps you choose thebest model foryour data byletting you
perform model assessment and model comparisons using confusion matrices and
ROC curves .Export classification models tothe MATLAB workspace togenerate
predictions onnew data, orgenerate MATLAB code tointegrate models into
applications such ascomputer vision, signal processing, and data analytics ."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#19,19,"Classification Learner
Matrice diConfusione (oTabella diErrata Classificazione) :rappresentazione
dell'accuratezza diclassificazione statistica .
Ogni colonna della matrice rappresenta ivalori predetti, mentre ogni riga
rappresenta ivalori reali (i.e.,l'elemento sulla riga iesulla colonna jèilnumero di
casi incui ilclassificatore haclassificato laclasse ""vera"" icome classe j).
Attraverso questa matrice èosservabile seviè""confusione"" nella classificazione di
diverse classi .
Curve ROC (Receiver Operating Characteristic) :schemi grafici perunclassificatore
binario .
Lungo idue assi sipossono rappresentare lasensibilità e(1-specificità), come True
Positive Rate (vero positivo) eFalse Positive Rate (falso positivo) .Inaltri termini, si
studiano irapporti fraveri allarmi (hitrate) efalsi allarmi alvariare diuna soglia ."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#2,2,"Esempi in MATLAB
!Dataset multivariato Iris (Fisher's 1936 iris data)
!50 esemplari di Iris Setosa , 50 di Iris Versicolor , 50 di Iris Virginica
!4 feature: lunghezza e larghezza del sepalo, lunghezza e larghezza 
del petalo
!Sepalo: in botanica, ciascuno degli elementi, simili a foglioline verdi, 
che formano il calice del fiore
!Utilizzeremo solo lunghezza e larghezza del sepalo (per poter 
visualizzare i dati)
!Funzione fitcsvm di MATLAB (metodo di ottimizzazione adottato: 
Sequential Minimal Optimization (SMO))
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#20,20,"Classification Learner
-Avviare Matlab
-Scaricare il file ClassificationLearner_Example_Datasets.mat
-Doppio clic sul file ClassificationLearner_Example_Datasets.mat
-Selezionare i dati che si desidera importare 
[e.g., FisherIris (Numero di feature (predittori): 4, Numero di pattern (osservazioni): 150, Numero di 
classi: 3); tabella di 150 righe (osservazioni) e 5 colonne (4 valori delle feature + classe)]
-Digitare Finish per importarli nel Workspace di Matlab
-Avviare l’app Classification Learner (vedi scheda APPS o digitare al prompt il 
comando classificationLearner )"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#21,21,"Classification Learner
-New Session —> From Workspace
-Selezionare le feature e l’eventuale metodo di validazione
-Start Session
-Selezionare uno o più algoritmi di classificazione dalla barra superiore (per 
selezionare i parametri vedi Advanced)
-Train e buon divertimento!
-per ulteriori dettagli: https://it.mathworks.com/help/stats/classificationlearner -app.html"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#22,22,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#23,23,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#24,24,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#25,25,"CL Features
-Linear SVM
-Fine Gaussian SVM (Kernel Scale=0.35)
-Medium Gaussian SVM (Kernel Scale=1.4)
-Coarse Gaussian SVM (Kernel Scale=5.7)
-Quadratic SVM (Kernel Polinomiale con grado=2)
-Cubic SVM (Kernel Polinomiale con grado=3)
-Kernel scale parameter, specified as the comma -separated pair consisting of 'KernelScale' and 'auto' or a positive 
scalar. The software divides all elements of the predictor matrix X by the value of KernelScale. Then, the software 
applies the appropriate kernel norm to compute the Gram matrix.
-per ulteriori dettagli digitare al prompt il comando doc fitcsvm"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#26,26,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#27,27,"CL Features
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#28,28,"Altri Dataset
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#29,29,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#3,3,"Dataset Fisher Iris
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#30,30,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#31,31,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#32,32,Altri Dataset
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#33,33,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#34,34,"Classification Learner
“Plotting the fisheriris data, you can see that sepal length
and sepal width separate one ofthe classes well
(setosa) .You need toplot other predictors (features) to
see ifyou can separate theother two classes .”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#35,35,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#36,36,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#37,37,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#38,38,"Classification Learner
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#39,39,"Classification Learner
“Plotting thefisheriris data, you can seethat petal length and petal
width arethefeatures that separate theclasses best.”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#4,4,"Esempi in MATLAB
fitcsvm trains or cross -validates a support vector machine (SVM) model for 
two-class (binary) classification on a low -dimensional or moderate -
dimensional predictor data set. fitcsvm supports mapping the predictor data 
using kernel functions, and supports sequential minimal optimization (SMO), 
iterative single data algorithm (ISDA), or L1 soft -margin minimization via 
quadratic programming for objective -function minimization. Matlab Help
The support vectors are observations that occur on or beyond their estimated 
class boundaries. 
You can adjust the boundaries (and, therefore, the number of support 
vectors) by setting a box constraint during training using the 'BoxConstraint'
name -value ( C) pair argument."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#40,40,"L'errore di classificazione è uguale, ma i classificatori sono molto diversi fra loro!Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Classificatore 1  
(assegn aun 
oggetto sempre 
alla prima classe )
Errore: 3/10 = 0.3 
(30%)Classificatore 2Valutazione Prestazioni
Errore: 3/10 = 0.3
(30%)Il sempice errore di classificazione (i.e., numero di errori / numero totale di classificazioni) 
non sempre ci permette di capire o confrontare completamente due classificatori.
Esempio:"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#41,41,"Vera Assegna ta
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Elementi della classe 1 classificati  
come appartenenti alla classe 1
Elementi della classe 1classificati 
come appartenenti alla classe 2
Elementi della classe 2 classificati  
come appartenenti alla classe 2Matrice di Confusione
Elementi della classe 2classificati  
come appartenenti alla classe 15 2
1 2EsempioMatrice Mche ci dice come un classificatore opera rispetto alle diverse classi 
m(i,j) = numero di elementi della classe iclassificati come elementi della classe j
In altri termini, indice di riga i:valore reale , indice di colonna j:valore predetto"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#42,42,"Matrice di Confusione
L'errore di classificazione può essere calcolato facilmente dalla matrice di 
confusione
La somma di tutti gli elementi non appartenenti alla diagonale principale
O, meglio, può essere calcolato come “1 -Accuracy”
Accuracy: somma elementi diagonale principale / numero elementi totali"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#43,43,"Nel caso di problema a due classi la matrice di 
confusione  assume una forma particolare (2 classi, 
positivi vs negativi)
True  
Positive  
(TP)False  
Negative  
(FN)
False  
Positive  
(FP)True  
Negative  
(TN)ESEMPIO: classificazione tra malati (positivi) e sani(negativi)
CLASSIFICAZIONE CORRETTA:
Veri positivi: pazienti malati classificati come malati
Veri negativi: pazienti sani classificati come sani
CLASSIFICAZIONE ERRATA:
Falsi positivi: pazienti sani classificati come malati
Falsi negativi: pazienti malati classificati come saniMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#44,44,"Dalla matrice di confusione possono essere calcolati diversi indici
Indice Formula Intuizione
Accuracy Percentuale di classificazioni corrette
Precision Percentuale di classificazioni positive che  
sono corrette
Recall (Sensitivity) Percentuale di elementi positivi del tes tset 
che sono stati classificati come positivi
Specificity Percentuale di elementi negativi del test set 
che sono stati classificati come negativi
Precision: se dico “positivo”, è corretto ?
Recall: riesco a trovare tuttii positivi del testing set?Matrice di Confusione
TN
TN+FPTP
TP+FNTP+TN
TP+FP+TN+FN
TP
TP+FP"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#45,45,"Matrice di Confusione
Vera Assegnata
1 1
1 1
1 1
1 1
1 1
1 1
1 1
2 1
2 1
2 1Vera Assegnata
1 1
1 2
1 2
1 1
1 1
1 1
1 1
2 2
2 2
2 1Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 7/10 (0.7)
Recall: 7/7 (1)
Specificity: 0/3 (0)TP:7 FN:0
FP:3 TN:0Indice Formula
Accuracy
Precision
Recall (Sensitivity)
Specificity
Matrice diconfusione
Accuracy: 7/10 (0.7)
Precision: 5/6 (0.83)
Recall: 5/7 (0.71)
Specificity: 2/3 (0.66)TP:5 FN:2
FP:1 TN:2TP+TN
TP+FP+TN+FN
TP
TP+FP
TP
TP+FN
TN
TN+FP"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#46,46,"blu50 10
20 20Supponiamo diaver addestrato unmodello utilizzando 100
esempi ditraining .Diquesti 100,60sono diclasse “rosso” e
40sono diclasse “blu”.
Ilmodello haeffettuato leseguenti classificazioni :
Etichette predette
rosso blu
rosso
Etichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#47,47,"rosso
blu50 10
20 20Etichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#48,48,"rosso
bluTP FN
FP TNEtichette predette
rosso blu
NB: la somma è sempre  
100 (pari al numero di  
pattern ditraining)Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Matrice di confusioneEtichette
realiMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#49,49,"Precision: =50 / (50+20) =0.7142
TP +FPEtichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Precision: ""Quanti dei pattern che ho predetto di tipo rosso sono
davvero pattern di classe rosso ?""
TPMatrice di Confusione"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#5,5,"Esempi in MATLAB
load fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’
X=meas(:,3:4); % estrae lunghezza e larghezza dei sepali
y = ~strcmp(species, 'setosa' ); % label 0 se Iris setosa, 1 se altre specie
SVMModel=fitcsvm(X,y, 'BoxConstraint' ,+Inf); % C=+Inf —> hard-margin linear SVM
figure
gscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training
hold on
sv = SVMModel.SupportVectors;
plot(sv(:,1),sv(:,2), 'ko','MarkerSize' ,10) % cerchia i vettori di supporto
legend('Iris setosa' ,'Altre specie' ,'Support vectors' ,'Location' ,'southeast' )
axis manual
x1 = linspace( -5,5);
f=@(x)(-SVMModel.Bias -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % iperpiano di 
separazione
plot(x1,f(x1))
f1=@(x)( -SVMModel.Bias+1 -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
positivo
plot(x1,f1(x1))
f2=@(x)( -SVMModel.Bias -1-SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine 
negativo
plot(x1,f2(x1))"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#50,50,"Recall 
(Sensi tivity) :
TP
Sensitivity: =50 / (50+10) =0.8333Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
TP + FN
somma dei positivi nel training setMatrice di Confusione
“Dei pattern che dovrei predire come rosso (positivo) 
quanti ne ho predetti di classe rosso (positivo)?”"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#51,51,"Specificity: = 20 / (20+20) =0.5Etichetta reale Etichetta predetta Tipo predizione
rosso rosso True positive (TP) (50)
rosso blu False negative (FN) (10)
blu blu True negative (TN) (20)
blu rosso False positive (FP) (20)
Misure di performance :
Specifici ty:Matrice di Confusione
TN“Dei pattern che dovrei predire come blu(negativo) 
quanti ne ho predetti di classe blu(negativo)?”
TN+FP
somma dei negativi nel training set"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#52,52,"Lacurva ROC (Receiver Operating Characteristic) èuna
tecnica statistica attualmente utilizzata inuna grande varietà di
campi scientifici .
Questa tecnica trae origine nell'ambito della teoria della
rilevazione delsegnale .Sitratta diunametodologia cheèstata
adottata per laprima volta daalcuni ingegneri, durante la
seconda guerra mondiale, perl'analisi delle immagini radar elo
studio delrapporto segnale/disturbo .
E'possibile usare lacurva ROC anche pervalutare leprestazioni
diunmodello diclassificazione .Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#53,53,"Sistema molto utilizzato per valutare un classificatore binario
basato susoglia
Legenda: 
Positivo = Disease (Malati) 
Negativo = Normal (Sani)
Classificazione:
Negativo < !
Positivo > !
Variando il valore di soglia 
!(cut-off)si ottengono 
diversi valori di TP, TN, FP,
FN
Esempio: con ilvalore  di !
in figura i Falsi Positivi 
sono azeroCurva ROC
!"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#54,54,"La curva ROC mette in relazione la specificity (recall) 
conla sensitivity al variare della soglia
Fissata una soglia, quanti sono i veri positivi rispetto ai falsipositivi? 
Come si calcola:
Si fa variare la soglia calcolando i  
corrispondenti veri positivi e falsi  
positivi, che rappresentano un  
punto della curva
Il valore minimo/massimo della  
soglia è quello per cui sono tutti  
falsi positivi o tutti veri positiviCurva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#55,55,"Fissatauna sogliat,
peri tutti gliesempi  
quali il
(classificatore)modello
genera
unoscore >tvengono  
predetti positivi.
Questo cipermette di
quantificare, per ogni
scelta del valore di
soglia ,TP,TN, FPe
FN.
TP
FPCurva ROC
TN
FN"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#56,56,"Fissato unvalore dit
possiamo calcolare, ad
esempio :
TP=0.5  
FN=0.5  
FP=0.12  
FN=0.88
Possiamo  
identificare un  
punto sulla curva  
(associato al  
valore di tscelto)Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#57,57,"Possiamo calcolare TP  
e FP per una serie di  
valori  di t (es. 0.1,0.2,
0.3, 0.4, 0.5, 0.6, …,
1.0). In questo modo  
otteniamo diversi punti  
che compongono la  
curva ROC.
Curva ROC
Il valore degli score 
generati dal 
classificatore può 
variare tra 0 e 1."
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#58,58,"A seconda di come si vuole operare si sceglie lasoglia
Esempio 1 (curva) : Sensitivity al 95%, si 
ottiene un corrispondente valore di Specificity
(70%)
Esempio 2 (segmento tratteggiato) : 
Sensitivity = 100-Specificity, si chiama 
Equal Error Rate
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#59,59,"Ciò che èimportante
però non èlacurva di
persé,mal’area sotto
la curva . Questa
quantità èindicata con
iltermine Area Under
theROC Curve (AUC )
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#6,6,"Esempi in MATLAB Esempi in MATLAB –(3)
45
𝐶=+∞C=+∞
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#60,60,"AUC = 1:
Il classificatore è  
perfetto
AUC = 0.5 :
Il classificatore è
totalmente casuale
(lancio diunamoneta)
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#61,61,"Rispetto a TP e FP :
TP:0, FP:0
Predice sempre «negativo»
TP:1, FP:1
Predice sempre «positivo»
TP:1, FP:0
Classificatore ideale
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#62,62,"Si possono confrontare curve ROC calcolando l'area
sotto la curva (AUC –Area Under theCurve)
Un AUC più grande 
implica unclassificatore
migliore
Curva ROC"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#63,63,A B CA migliore di B migliore di C (C=lancio moneta)Curva ROC
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#64,64,"Join the protest!!!
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#7,7,"Esempi in MATLAB
C=+∞Esempi in MATLAB –(4)
46
𝐶=+∞
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#8,8,"Esempi in MATLAB
C=1Esempi in MATLAB –(5)
47
𝐶=1
"
data_test\rootfolder\università\MachineLearning\36-SVM(3)-sbloccato.pdf#9,9,"Esempi in MATLAB
C=10−6Esempi in MATLAB –(6)
48
𝐶=10−6
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: SVM (Ex 14)
1"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#1,1,"Sommario
Scikit-learn e SVM 
SVM e Iris dataset 
Use case: Stock forecasting 
Use case: Sentiment Analysis"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#10,10,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
... (completa)
11"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#11,11,"Esercitazione: stock forecasting
from
 sklearn.svm 
 import
 SVC
from
 sklearn.metrics 
 import
 accuracy_score
  
import
 pandas 
 as
 pd
import
 numpy 
as
 np
  
import
 matplotlib.pyplot 
 as
 plt
plt.style.use(
 'seaborn-darkgrid'
 )
  
import
 warnings
warnings.filterwarnings(
 ""ignore""
 )
df = pd.read_csv(
 'RELIANCE.csv'
 )
d
f.index = pd.to_datetime(df[
 'Date'
])
df = df.drop([
 'Date'
], axis=
 'columns'
 )
df[
'Open-Close'
 ] = df.Open - df.Close
df[
'High-Low'
 ] = df.High - df.Low
  
# per ora uso solo 2 valori
X = df[[
 'Open-Close'
 , 
'High-Low'
 ]]
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
>> [1 1 1 ... 1 0 0]
... (segue)
12"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#12,12,"Esercitazione: stock forecasting
split_percentage = 
 0.8
split = 
 int
(split_percentage*
 len
(df))
  
# Train data set
X_train = X[:split]
y_train = y[:split]
  
# Test data set
X_test = X[split:]
y_test = y[split:]
cls = SVC().fit(X_train, y_train)
df[
'Predicted_Signal'
 ] = cls.predict(X)
df[
'Return'
 ] = df.Close.pct_change()
df[
'Strategy_Return'
 ] = df.Return *df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
import
 matplotlib.pyplot 
 as
 plt
%matplotlib 
 inline
  
plt.plot(df[
 'Cum_Ret'
 ],color=
 'red'
)
plt.plot(df[
 'Cum_Strategy'
 ],color=
 'blue'
)
13"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#13,13,"Esercitazione: stock forecasting
14
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#14,14,"Esercitazione: stock forecasting
L'algoritmo genera un ritorno del 18.87% in un 1 anno, rispetto al 5.97% 
del titolo azionario. 
La funzione accuracy_score() restituisce una accuracy del 62.07% sul train 
set e 50.67 sul test set. 
Esercizi: (1) crea il target value a distanza di più giorni dall'istanza 
corrente; (2) usa gli ultimi 15 valori Close come istanza di input per predire 
il successivo; (3) impiega altri kernel (es. rbf).
15
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#15,15,"Esercitazione: Sentiment Analysis
Tecnica molto popolare per classiﬁcare brani di testo, micropost o frasi in 
linguaggio naturale in base al sentimento (es. positivo, negativo, neutro). 
Supponiamo di impiegare le review di ﬁlm, es: 
http://www.cs.cornell.edu/people/pabo/movie-review-data/  
Movie-review data for use in sentiment-analysis experiments. Available are collections of 
movie-review documents labeled with respect to their overall 
 sentiment polarity
  (positive 
or negative) or 
 subjective rating
  (e.g., ""two and a half stars"") and sentences labeled with 
respect to their 
 subjectivity status
  (subjective or objective) or 
 polarity 
import pandas as pd  
trainData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/train.csv
 "") 
testData = pd.read_csv(""
 https://raw.githubusercontent.com/Vasistareddy/
sentiment_analysis/master/data/test.csv
 "") 
trainData.sample(frac=1).head(5) # shuffle the df and pick first 5  
      
Content                                             
 Label 
56
    jarvis cocker of pulp once said that he wrote ...   pos  
1467
  david spade has a snide , sarcastic sense of h...   neg  
392
   upon arriving at the theater during the openin...   pos  
104
   every once in a while , a film sneaks up on me...   pos  
1035
  susan granger's review of "" american outlaws ""...   neg
16"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#16,16,"Esercitazione: Sentiment Analysis
Per impiegare il testo come input agli algoritmi di ML spesso si effettua una 
pipeline di processamento per trasformare parole o frasi in vettori numerici. 
Per dettagli: 
 https://medium.com/@vasista/preparing-the-text-data-with-
scikit-learn-b31a3df567e
   e  
https://scikit-learn.org/stable/modules/
generated/sklearn.feature_extraction.text.TﬁdfVectorizer.html   
from sklearn.feature_extraction.text import TfidfVectorizer  
# ignora i termini che compaiono in meno di 5 documenti 
# e i termini che compaiono in > 80% dei documenti; 
# abilita l'inverse document frequency per pesare i termini 
vectorizer = TfidfVectorizer(min_df = 5,  
                             max_df = 0.8,  
                             sublinear_tf = True,  
                             use_idf = True)  
train_vectors = vectorizer.fit_transform(trainData['Content'])  
test_vectors = vectorizer.transform(testData['Content']) 
Esercizio
 : completa il codice impiegando SVM lineare e valutane 
l'accuratezza. Testa la predizione su review di Amazon.
17"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#17,17,"Esercitazione: Sentiment Analysis
from sklearn import svm 
from sklearn.metrics import classification_report 
classifier_linear = svm.SVC(kernel='linear') 
classifier_linear.fit(train_vectors, trainData['Label']) 
prediction_linear = classifier_linear.predict(test_vectors) 
time_linear_train = t1-t0 
time_linear_predict = t2-t1 
report = classification_report(testData['Label'], prediction_linear, 
output_dict=True) 
print('positive: ', report['pos']) 
print('negative: ', report['neg']) 
positive:  {'precision': 0.9191919191919192, 'recall': 0.91, 'f1-score': 
0.9145728643216081, 'support': 100} 
negative:  {'precision': 0.9108910891089109, 'recall': 0.92, 'f1-score': 
0.9154228855721394, 'support': 100} 
review = """"""Very good picture and sound, very glad I chose this unit"""""" 
review_vector = vectorizer.transform([review]) # vectorizing 
print(classifier_linear.predict(review_vector))  
18"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#18,18,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and TensorFlow: 
Concepts, Tools, and Techniques to Build Intelligent Systems
 . O'Reilly Media 
2017 
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-
using-pandas/notebook   
https://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-
b31a3df567e    
https://scikit-learn.org/stable/modules/generated/
sklearn.feature_extraction.text.TﬁdfVectorizer.html  
Tutorial: 
 https://www.geeksforgeeks.org/predicting-stock-price-direction-using-
support-vector-machines/?ref=rp  
Tutorial: 
 https://medium.com/@vasista/sentiment-analysis-using-
svm-338d418e3ff1
Testi di Riferimento
19"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#2,2,"Support Vector Machines
L'algoritmo SVM è impiegato in ambito di classiﬁcazione e regressione. 
Ha molti vantaggi tra cui: 
Efﬁcace in spazi con molte dimensioni (cioè features) 
Può trattare casi in cui le dimensioni sono maggiori delle istanze 
È efﬁciente in termini di spazio di memoria richiesto 
Attenzione: 
Se le dimensioni sono molto maggiori delle istanze, la scelta della 
funzione kernel e la regolarizzazione sono fondamentali. 
SVM non restituisce direttamente probabilità.
3"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#3,3,"Scikit-learn: Support Vector Machines
I dati in input supportati in scikit-learn sono sia 
 dense
  (es. 
numpy.ndarray
 , 
numpy.asarray
 ) sia sparsi (qualsiasi 
 scipy.sparse
 ) 
>>> 
from 
sklearn 
import
 svm 
>>> 
X 
=
 [[
0
, 
0
], [
1
, 
1
]] 
>>> 
y 
=
 [
0
, 
1
] 
>>> 
clf 
=
 svm
.
SVC() 
>>> 
clf
.
fit(X, y) 
SVC() 
>>> 
clf
.
predict([[
 2.
, 
2.
]]) 
array([1]) 
>>> 
# support vectors  
>>> 
clf
.
support_vectors_ 
array([[0., 0.],  
       [1., 1.]])  
>>> 
# indici dei support vectors  
>>> 
clf
.
support_ 
array([0, 1]...)  
>>> 
# numero dei support vectors per ogni classe  
>>> 
clf
.
n_support_ 
array([1, 1]...)
4"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#4,4,"Scikit-learn: Support Vector Machines
Esempio IRIS dataset: 
# carico il dataset IRIS
iris 
=
 load_iris()
# uso solo le prime due features
X 
=
 iris.data[:, :
 2
]
Y 
=
 iris.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)
# equivale a SVC(kernel
 =
""linear""
 )
svm 
=
 LinearSVC()
svm.fit(X_train_std, Y_train)
 
print
(
""Accuracy Train Set:""
 , svm.score(X_train_std, Y_train))
print
(
""Accuracy Test Set:""
 , svm.score(X_test_std, Y_test))
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire?
5"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#5,5,"Scikit-learn: Support Vector Machines
>> Accuracy Train Set: 0.8285714285714286
>> 
Accuracy Test Set: 0.6888888888888889
Cosa possiamo dire? 
Il modello soffre di overﬁtting. 
Esercizio: prova ad impiegare tutte le features del dataset.
6
"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#6,6,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features.
7"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#7,7,"Scikit-learn: Support Vector Machines
Esercizio: prova ad impiegare tutte le features del dataset. 
>> Accuracy Train Set: 0.9428571428571428
>> 
Accuracy Test Set: 0.9555555555555556
Esercizio: cambia il parametro 
 kernel
  di SVC() e testa le altre funzioni oltre 
alla 
 linear
  cioè 
 rbf
, 
sigmoid
  e 
poly
 impiegando sempre 2 features. 
8
Accuracy Train Set: 0.81
Accuracy Test Set: 0.78Accuracy Train Set: 0.72
Accuracy Test Set: 0.8Accuracy Train Set: 0.76
Accuracy Test Set: 0.67"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#8,8,"Stock forecasting
Alcuni servizi web rendono disponibili gli andamenti di titoli azionari via 
APIs, es: 
Open: Starting price at which a stock is traded in a day. 
Close: Closing price. 
High: The highest price of equity symbol in a day. 
Low: The lowest price of the share in a day 
VWAP: Volume weighted average price 
Volume: Total volume of stocks traded on a particular day.  
I dati possono essere interpretati come 
 time series
 , cioè sequenze di valori 
ordinati temporalmente. 
Per approfondimenti:  
https://www.kaggle.com/code/parulpandey/getting-started-with-time-series-using-pandas/notebook  
Il task della stock price forecasting è predire il valore futuro (es. intraday, 
giornalieri, mensile, etc). di un titolo in base ai valori passati.
9"
data_test\rootfolder\università\MachineLearning\37-Ex_14 Esercitazione SVM-sbloccato.pdf#9,9,"Esercitazione: stock forecasting
Al seguente indirizzo trovi i dati storici del titolo RELIANCE: 
https://storage.googleapis.com/kaggle-forum-message-attachments/894813/16059/RELIANCE.csv 
Possiamo impiegare l'istanza attuale come input e tentare di fare predizione 
sul comprare (+1) oppure no (0). 
In ambito azionario è utile deﬁnire nuove features che combinano quelle 
attuali, es. Open-Close o High-Low: 
df[
'Open-Close'
 ] = df.Open - df.Close
La variabile target puoi essere approssimare nel seguente modo: 
y = np.where(df[
 'Close'
].shift(
 -1
) > df[
'Close'
], 
1
, 
0
)
Il ritorno cumulato può essere ottenuto nel seguente modo: 
df[
'Return'
 ] = df.Close.pct_change() 
 # variazione percentuale rispetto al prec
df[
'Strategy_Return'
 ] = df.Return * df.Predicted_Signal.shift(
 1
)
df[
'Cum_Ret'
 ] = df[
'Return'
 ].cumsum()
df[
'Cum_Strategy'
 ] = df[
'Strategy_Return'
 ].cumsum()
Esercizio
 : impiega l'algoritmo SVM per la predizione e valuta l'accuratezza.
10"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Riduzione di Dimensionalità"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#1,1,"Sommario
!Introduzione
!Definizioni
!Le Principali Tecniche
!PCA vs LDA
!Principal Component Analysis (PCA)
!Linear Discriminant Analysis (LDA)
!t-SNE"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#10,10,"PCA: Retro -Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#11,11,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#12,12,"PCA: Esempio Riduzione 2 --->1
7prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: esempio riduzione 2 o1
L’
ellisse rappresenta la distribuzione dei pattern nel training set .
𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.
Gli 
autovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo 
gli assi 𝝋1e 𝝋2.
𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.
Se 
𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′
(retroproiezione di 𝐲) senza perdite significative di informazione. 
Si 
può dimostrare che tra tutte le riduzioni di dimensionalità
lineari PCA è quella che preserva al massimo l’informazione dei 
vettori originali.0
Spazio iniziale
(𝑑=2)Spazio KL
(𝑘=1)
𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘
𝜆2
𝜆1𝑥2
𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1
𝐲=𝑦1,𝐲∈1
ത𝐱=𝑥1,𝑥2𝑡,𝐱∈2
𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#13,13,"PCA: Scelta di k
8prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: scelta di 𝑘
Talvolta
 lascelta di𝑘èobbligata :adesempio per la
visualizzazione 2Do3Ddeidati.
Quando
 invecel’obiettivo èquello discartare informazione
inutile edati correlati mantenendo gran parte delcontenuto
informativo sipuòscegliere 𝑘nelmodo seguente :
Fissata
 una percentuale 𝑡delcontenuto informativo chesi
vuole preservare (es.𝑡=95%)sisceglie ilminimo valore di
𝑘percuilasomma deipiùgrandi𝑘autovalori ,rispetto alla
somma dituttigliautovalori ,èmaggiore ouguale a𝑡.
Considerando
 gliautovalori ordinati inordine decrescente :
𝑘=𝑎𝑟𝑔𝑚𝑖𝑛
𝑧σ𝑖=1…𝑧𝜆𝑖
σ𝑖=1…𝑑𝜆𝑖≥𝑡
Infatti, ricordando che gliautovalori denotano lavarianza
lungo idiversi assi, ilrapporto nella formula indica lavarianza
«conservata» rispetto allavarianza totale ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#14,14,"PCA: Codifica di Immagini
9prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: codifica di un’immagine
𝐱∈16500
𝐲∈15
𝐱′∈16500Immagine
originaleRicostruzione
(retroproiezione)
proiezione retro-proiezioneiprimi 8 autovettori o componenti principali
(denominati eigenfaces nell’applicazione al riconoscimento volto )
𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ15𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ15
-2532 2193 -2179 2099 491
427 -324 961 35 -40
-149 -624 317 -158 -142"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#15,15,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#16,16,"Singular Value Decomposition (SVD)
!LaDecomposizione aiValori Singolari (Singular Value
Decomposition, SVD) èuna importante fattorizzazione per
matrici avalori reali ocomplessi chesiavvale diautovalori
eautovettori
!Ogni matrice M∈!m×npuò essere fattorizzata in 
M=U""V*
dove
!Uèuna matrice m×munitaria (cioè UUt=Im)
!#èuna matrice m×ndiagonale rettangolare con soli elementi
reali non negativi
!V*èlatrasposta coniugata diuna matrice n×nunitaria V"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#17,17,"Singular Value Decomposition (SVD)
!Glielementi della diagonale di""sono detti valori singolari diM
!Lemcolonne diUsono dette vettori singolari sinistri diM
!Lencolonne diVsono dette vettori singolari destri diM
!Vale quanto segue
!Ivettori singolari sinistri diMsono gliautovettori diM∙M*
!Ivettori singolari destri diMsono gliautovettori diM*∙M
!Ivalori singolari diMsono leradici quadrate degli autovalori non
nulli diM∙M* eM*∙M"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#18,18,"Calcolo PCA in Pratica
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
10prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo PCA in pratica
Per𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di
covarianza puòessere molto grande .
per
𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !
se
𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi
𝑘autovettori) attraverso decomposizione SVD della matrice
rettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare
perlamatrice dicovarianza (vedi [1]).
𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱
decomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛
ortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .
𝚺=1
𝑛𝐗𝐗𝑡=1
𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1
𝑛𝐔𝚪2𝐔𝑡
Autovettori eautovalori di𝚺possono dunque essere ottenuti
dalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti
elementi diagonali di𝚪alquadrato (valori singolari alquadrato
di𝐗).
[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component 
Analysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione
formato trasposto rispetto a 
𝐗usata in regressione.
Ogni pattern una colonna.
decomposizione 
spettrale della 
matrice quadrata 𝚺
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#19,19,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2Ricordiamo, infatti, che gliautovettori della matrice dicovarianza !
sono paralleli agli assi dell’ellisse che rappresenta ladistribuzione dei
pattern delTraning Set(TS)"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#2,2,"Definizioni
2prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàDefinizioni
Obiettivo dei metodi per lariduzione didimensionalità
(dimensionality reduction )èquello dieseguire unmapping dallo
spazio iniziale𝑑aunospazio didimensione inferiore 𝑘,𝑘<𝑑.
Può essere vista come unaforma dicompressione (con perdita di
informazione) .Obiettivo èscartare leinformazioni non rilevanti o
meno rilevanti perilproblema diinteresse :
allevia
 iproblemi collegati allacurse ofdimensionality :operare
inspazi adelevata dimensionalità ,acausa delfatto che i
pattern sono molto sparsi, richiede ingenti moli didati per
l’addestramento .
operare
 inspazi adimensionalità inferiore rende piùsemplice
addestrare algoritmi dimachine learning .Scartando dati
ridondanti (informazioni correlate) erumorosi talvolta si
migliorano anche leprestazioni .
Attenzione :riduzione didimensionalità non significa mantenere
alcune «dimensioni» ecancellarne altre, ma «combinare »le
dimensioni inmodo opportuno ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#20,20,"PCA Whitening
11prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA Whitening
Èunatecnica dipre-normalizzazione deidati, che:
Rimuove
 lecorrelazioni traledimensioni, ruotando lanuvola di
punti per allineare gliassi divariazione principale deidati
(autovettori )agliassicartesiani .
Sfericizza
 l’ellissoide, uniformando levarianze (denotate dagli
autovalori )a1lungo tuttigliassi
Dopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘
autovettori )èsufficiente dividere ogni dimensione perlaradice
quadrata dell’autovalore corrispondente (deviazione standard) .
Lamatrice dicovarianza deidati normalizzati èl’identità .𝝋1
𝝋2 𝝋1𝝋2
𝝋1𝝋2
𝝋1𝝋2"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#21,21,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#22,22,"Linear Discriminant Analysis (LDA)
12prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLinear Discriminant Analysis (LDA)
Riduzione didimensionalità lineare esupervisionata ilcui
obiettivo èmassimizzare laseparazione traleclassi (che nelTS
sono etichettate ).L’esempio seguente mostra chealfinedella
discriminazione lasoluzione ottimale può essere anche molto
diversa dalla soluzione PCA.
Per
 formulare ilcriterio diottimizzazione dimassima
separazione traleclassi sono definite leseguenti matrici di
scattering (initaliano“sparpagliamento” ):
within
 -class𝐒𝑤:indica come ivettori sono scattered rispetto
alcentro delle classi (ciascuno rispetto allapropria classe) .
between
 -class𝐒𝑏:indica come icentri delle classi sono
scattered rispetto alcentro generale della distribuzione
(ovvero quanto leclassi sono scattered ).
Una matrice discatter sicalcola come unamatrice dicovarianza
senza normalizzare perilnumero dipatternaltezzapesoPCA
LDAuomini
donne"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#23,23,"Calcolo LDA
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#24,24,"Richiami
!Latraccia diuna matrice èdefinita solo per lematrici
quadrate edèlasomma degli elementi presenti sulla
diagonale principale .
!Traccia eautovalori diuna matrice :latraccia diuna
matrice èuguale allasomma deisuoi autovalori moltiplicati
perlerispettive molteplicità algebriche ,cioè seλ1,λ2,...,λp
sono gliautovalori distinti diuna matrice Adiordine n,
dette m1,m2,...,mplerispettive molteplicità algebriche, se
m1+m2+...+mp=n,allora
tr(A) =m1λ1+m2λ2+...+mpλp"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#25,25,"Richiami
!SiaAuna matrice quadrata diordine nesiaλ0unsuo
autovalore .Sidice molteplicità algebrica dell’autovalore λ0,
esiindica conma(λ0),ilnumero cheesprime quante volte
l’autovalore λ0annulla ilpolinomio caratteristico .
!Ricordiamo che ilpolinomio caratteristico associato auna
matrice quadrata Aèildeterminante della matrice A-λIn,
dove Aèlamatrice inesame, λèun’incognita eInèla
matrice identità dello stesso ordine di A.
Informule :
pA(λ):=det(A-λIn)"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#26,26,"Calcolo LDA
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa 𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1
13prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàCalcolo LDA
Dato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,
dove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le
etichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore
medio della classe i-esima .Allora lematrici discattering sono
definite come :
within
 -class :
𝐒𝑤=෍
𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍
𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡
between
 -class :
𝐒𝑏=෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1
𝑛෍
𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖
Tra idiversi criteri diottimizzazione possibili quello più
frequentemente utilizzato èlamassimizzazione della quantità :
𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍
𝑖=1…𝑑𝜆𝑖
dove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il
criterio èintuitivo inquanto cerca dimassimizzare loscattering tra
leclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa𝐒𝑤−1)
quelloall’interno diogni classe .
Sidimostra che perlamassimizzazione di𝐽1lospazio LDA è
definito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<
𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎
𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒
valoremassimo di𝑘=𝑠−1"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#27,27,"t-distributed Stochastic Neighbor Embedding (t -SNE)
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten andG.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#28,28,"14prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-distributed Stochastic Neighbor 
Embedding (t-SNE)
Èunatecnica nonlineare (nonsupervisionata )perlariduzione
didimensionalità introdotta nel2008 daVan derMaaten e
Hinton [1].
Rappresenta
 lostatodell’arte perlavisualizzazione 2Do3Ddi
dati multidimensionali .Implementazione disponibile inmolti
linguaggi in[2].
Anche
 PCA (con𝑘=2o𝑘=3)può essere utilizzata atale
scopo, madaticondistribuzioni spiccatamente nonmultinormali
non possono essere efficacemente «ridotti» attraverso un
mapping lineare .
Esempio
 :visualizzazione 2DdiMNIST (digit scritti amano) .
[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-
SNE.Journal ofMachine Learning Research ,2008 .
[2]https ://lvdmaaten .github .io/tsne/
t-SNE: Esempio"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#29,29,"t-SNE in Scikit -Learn
Per maggiori dettagli vedi documentazione online della libreria
open source scikit -learn :sklearn .manifold .TSNE!Esempio :visualizzazione 2Ddiundataset contenente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients)
invece deipixel .
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#3,3,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#30,30,"15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.
15prof. Davide Maltoni –Università di Bologna
ML
Riduzione Dimensionalitàt-SNE in sklearn
Esempio
 :visualizzazione 2Ddiundataset contente immagini
(non controllate) di1000 Cani +1000 Gatti, utilizzando come
feature diinput leHOG (Histogram ofOriented Gradients )
invece deipixel.
Vedi
 https ://distill .pub/2016 /misread -tsne/perconsigli sucome
tarare iparametri (es.perplexity )ditsne.
I due cluster sono 
molto sovrapposti. I 
classificatori 
tradizionali (es. SVM) 
raggiungono il 70% 
circa, sfruttando la 
maggiore densità dei 
patter verdi (gatti) in 
una certa regione.I due cluster appaiono molto 
sovrapposti. 
I classificatori tradizionali 
(e.g., SVM) raggiungono una 
accuratezza di circa il 70%, 
sfruttando la maggiore 
densità dei pattern verdi 
(gatti) in una certa regione.t-SNE in Scikit -Learn"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#31,31,"!Matlab Toolbox for Dimensionality Reduction:
https://lvdmaaten.github.io/drtoolbox/
t-SNE in Matlab"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#32,32,"Riferimenti
!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern 
Approach (4 ed.) , Pearson, 2020.
!K. Fukunaga, Statistical Pattern Recognition , Academic Press, 
1990.
!D. Maltoni , Machine Learning , Università di Bologna, 2017.
!C.M. Bishop, Pattern Recognition and Machine Learning , 
Springer, 2006.
!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The 
MIT Press, 2012.
!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification 
(2nd Edition). Wiley -Interscience , New York, NY, USA. "
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#4,4,"Le Principali Tecniche
3prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàLe principali tecniche
Lepiùnote tecniche diriduzione didimensionalità (che vedremo)
sono :
Principal
 Component Analysis (PCA):trasformazione non-
supervisionata nota anche come Karhunen Loeve (KL)
transform .Esegue unmapping lineare conl’obiettivo di
preservare almassimo l’informazione deipattern .
Linear
 Discriminant Analysis (LDA):ilmapping èancora lineare ,
mainquesto caso èsupervisionato .Mentre PCA privilegia le
dimensioni cherappresentano almeglio ipattern, LDA privilegia
ledimensioni chediscriminano almeglio ipattern delTS.
t-distributed Stochastic Neighbor Embedding (t-SNE):
trasformazione non lineare e non supervisionata ,
specificatamente ideata per ridurre dimensionalità a2o3
dimensioni onde poter visualizzare datimultidimensionali .
Altre tecniche diinteresse :
Independent
 Component Analysis (ICA):trasformazione lineare
orientata aproiettare ipattern suuna base dicomponenti
(statisticamente indipendenti ).
Kernel
 PCA:simile aPCA mapiùpotente perché ilmapping è
non-lineare .Utilizza un«trucco» simile aquello chepermette di
passare daSVM lineare aSVM nonlineare .
Local
 Linear Embedding (LLE):trasformazione non-lineare che
invece dicalcolare unmapping «globale», considera relazioni
tragruppi dipattern vicini ."
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#5,5,"Esempio PCA vs LDA
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
4prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàEsempio PCA vs LDA
Infigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=
1dimensione :
Il
segmento nero cheidentifica lasoluzione PCA èl’iperpiano
sulquale proiettando ipattern (indipendentemente dalla loro
classe) conserviamo almassimo l’informazione .
Il
segmento verde cheidentifica lasoluzione LDA èl’iperpiano
sulquale proiettando ipattern siamo ingrado didistinguere al
meglio ledueclassi (pattern rossi contro blu).
Entrambi sono mapping lineari2→1malasoluzione (retta) è
profondamente diversa .
"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#6,6,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#7,7,"Principal Component Analysis (PCA)
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#8,8,"Principal Component Analysis (PCA)
!Riassumendo
!Dagli npattern delTraining Set (TS) sicalcolano vettore medio e
matrice dicovarianza !
!Dalla matrice dicovarianza sicalcolano idautovalori eautovettori
!Dei dautovalori siconsiderano solo ikautovalori con valore
maggiore (inordine decrescente)
!Lamatrice diproiezione ""ksarà unmatrice (d×k)lecuikcolonne
sono costituite dagli autovettori relativi aikautovalori calcolati
come sopra
!Gli autovettori !idella matrice di 
covarianza ""sono paralleli agli 
assi dell’ ellisse che rappresenta 
ladistribuzione dei pattern nel TS
!Gli autovalori #isono le varianze 
lungo gli assi !i
5prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPrincipal Component Analysis 
(PCA)
Dato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :
ത𝐱=1
𝑛෍
𝑖=1…𝑛𝐱𝑖
𝚺=1
𝑛−1෍
𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡
ilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑
(definizioni simili aquelle usate per ilclassificatore diBayes
parametrico con multinormali .Ladivisione per𝑛−1invece di
𝑛dovuta acorrezione diBessel percaso unbiased ).
allora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale
(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di
proiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli
autovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :
Φ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑
𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑
𝝋𝒊𝟏indica la direzione di 
maggior varianza nel 
training set TS𝝋𝒊𝟏
𝝋𝒊𝟐
I primi 𝑘autovettori sono 
detti componenti principali"
data_test\rootfolder\università\MachineLearning\38-RD-sbloccato.pdf#9,9,"PCA: Proiezione
6prof. Davide Maltoni –Università di Bologna
ML
Riduzione DimensionalitàPCA: proiezione e retroproiezione
Proiezione
 (o):una volta determinato lospazio PCA, la
proiezione diunpattern sutale spazio èsemplicemente la
proiezione geometrica diunvettoresull’iperpiano chedefinisce
lospazio .Inrealtà lavera proiezione geometrica èunvettore
chehalastessa dimensionalità delvettore originale mentre in
questo contesto indichiamo con proiezione ilvettore (ridotto)
nello spazio PCA.Matematicamente questa operazione è
eseguita come prodotto della matrice diproiezione trasposta
perilpattern alquale èpreventivamente sottratta lamedia .
𝑃𝐶𝐴:𝑑→𝑘
𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱
Retro
 -proiezione (m):Dato unvettore nello spazio PCA, lasua
retro-proiezione verso lospazio originale siottiene moltiplicando
ilvettore perlamatrice diproiezione esommando ilvettore
medio .Questa trasformazione non sposta spazialmente il
vettore, che giace ancora sullo spazio PCA,maopera un
cambiamento dicoordinate che nepermette lacodifica in
termini delle𝑑componenti dello spazio originale .
𝑃𝐶𝐴:𝑘→𝑑
𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱
𝑑=3,𝑘=2
𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Riduzione dimensionalità (Ex 15)
1"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#1,1,"Sommario
Richiami riduzione dimensionalità, projection, mainfold learning 
PCA in Python 
Scikit-learn e PCA 
PCA e compressione 
Randomized PCA 
Kernel PCA 
Locally Linear Embedding LLE 
Esercitazione"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#10,10,"PCA: Step by step in Python
Una volta ottenute le componenti, deﬁniamo il nuovo iperspazio con 
 d 
dimensioni. Prendiamo le prime d colonne di 
 V
 e proiettiamo le istanze nel 
nuovo spazio: 
X
d-proj
 = X W
 d 
In Python: 
W2 
= 
Vt
.
T
[:, :
2
]
X2D 
= 
X_centered
 .
dot
(
W2
)
11"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#11,11,"Scikit-learn e PCA
Scikit-learn implementa la PCA nel seguente modo: 
from 
sklearn.decomposition 
 import 
PCA
pca 
= 
PCA
(
n_components 
 = 
2
)
X2D 
= 
pca
.
fit_transform
 (
X
)
La variabile components_ contiene i vettori. Per accedere al primo vettore:  
pca.components_.T[:,0] 
Ogni componente è associata alla relativa varianza che si può analizzare 
con la variabile 
 explained_variance_ratio_
 . Considerando l'esempio 
precedente si ottiene: 
>>> 
pca
.
explained_variance_ratio_
array([0.84248607, 0.14631839])
12"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#12,12,"Scikit-learn e PCA
La scelta del numero di dimensioni dipende dalla varianza: si tende a 
scegliere il numero che garantisce sempre elevata varianza (es. 95%). 
Eccezione se vogliamo fare un diagramma dei campioni, in tal caso ci 
occorrono 2 o 3 dimensioni. 
Il seguente codice ricava il numero di dimensioni che preservano il 95% 
della varianza sul training set: 
pca 
= 
PCA
()
pca
.
fit
(
X_train
)
cumsum 
= 
np
.
cumsum
(
pca
.
explained_variance_ratio_
 )
d 
= 
np
.
argmax
(
cumsum 
>= 
0.95
) 
+ 
1
Un modo alternativo per speciﬁcare la varianza: 
pca 
= 
PCA
(
n_components
 =
0.95
)
X_reduced 
 = 
pca
.
fit_transform
 (
X_train
)
(continua)
13"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#13,13,"Scikit-learn e PCA
Ulteriore metodo per ﬁssare d è fare un graﬁco del cumsum della varianza. 
Il 
gomito
  della curva è dove la varianza interrompe la crescita veloce.  
Nell'esempio una dimensionalità inferiore a 100 è un valore ideale:
14
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#14,14,"PCA e compressione
Una volta ottenuto il dataset proiettato sulle componenti, la dimensione del 
dataset si riduce sensibilmente. 
La funzione 
 inverse_transform
 () di PCA permette di ricostruire una 
approsimazione del dataset con le dimensioni originali a partire dalle 
istanze nello spazio ridotto. 
X
recovered
  = X
 d-proj
 W
d
T 
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset. (2) visualizza le cifre ricostruite con 
 inverse_transform(). 
Suggerimento per visualizzare le cifre
 : 
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
15"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#15,15,"PCA e compressione
Esercizio
 : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la 
PCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo 
dataset 
from
 sklearn.decomposition 
 import
 PCA
from
 sklearn 
 import
 datasets
from
 sklearn.model_selection 
 import
 train_test_split
from
 sklearn.datasets 
 import
 fetch_openml
from
 sklearn.preprocessing 
 import
 StandardScaler
mnist = fetch_openml(
 'mnist_784'
 )
X_train, X_test, y_train, y_test  = train_test_split
        (mnist.data, mnist.target, test_size=
 1
/
7.0
, random_state=
 0
)
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
pca = PCA(n_components = 
 154
)
X_reduced = pca.fit_transform(X_train)
X_recovered = pca.inverse_transform(X_reduced)
(continua)
16"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#16,16,"PCA e compressione
original_len = X_train.flatten().size
print
(original_len)
red_len = X_reduced.flatten().size
print
(red_len)
rec_len = X_recovered.flatten().size
print
(rec_len)
pct = (red_len - original_len) * 
 100
 / original_len
print
 (pct)
47040000
9240000
47040000
-80.35714285714286 
Dataset ridotto al 20% della dimensione originale! 
17"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#17,17,"PCA e compressione
Esercizio
 : ... (2) visualizza le cifre ricostruite con 
 inverse_transform().  
import
 matplotlib.pyplot 
 as
 plt
plt.imshow(X_train[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
plt.imshow(X_recovered[
 0
].reshape((
 28
, 
28
)), cmap=
 'gray'
)
plt.show()
18
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#18,18,"Scikit-learn: Randomized PCA
Impiegando il parametro 
 svd_solver
 =
""randomized"", impieghiamo 
l'algoritmo Randomized PCA che riduce notevolmente il tempo di 
esecuzione essendo d << n: 
O(
m × n
2
) + O(
 n
3
)  --->   O(
 m × d
2
) + O(
 d
3
) 
Per default sciki-learn usa il solver 
 auto
, che impiega la versione 
randomized se 
 m
 o 
n
 sono maggiori di 500 e d è minore del 80% rispetto a 
m
 o 
n
.  
Per forzare l'impiego della versione esatta, impiegare l'opzione 
 full
. 
19"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#19,19,"Scikit-learn: Incremental PCA
L'algoritmo PCA richieda che l'intero dataset sia presente in memoria. 
L'algoritmo Incremental PCA accetta il dataset suddiviso in mini-batch, e 
può essere impiegato 
 online
 . 
from 
sklearn.decomposition 
 import 
IncrementalPCA
n_batches 
 = 
100
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
)
for 
X_batch 
 in 
np
.
array_split
 (
X_train
, 
n_batches
 ):
    
inc_pca
.
partial_fit
 (
X_batch
)
X_reduced 
 = 
inc_pca
.
transform
 (
X_train
)
Con la classe memmap di NumPy possiamo leggere gli array 
incrementalmente da ﬁle binary: 
X_mm 
= 
np
.
memmap
(
filename
 , 
dtype
=
""float32""
 , 
mode
=
""readonly""
 , 
shape
=
(
m
, 
n
))
batch_size 
 = 
m 
// 
n_batches
inc_pca 
 = 
IncrementalPCA
 (
n_components
 =
154
, 
batch_size
 =
batch_size
 )
inc_pca
.
fit
(
X_mm
)
20"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#2,2,"Richiami: riduzione di dimensionalità
In casi reali i dati da analizzare possono essere sempliﬁcati riducendo il 
numero di features. L'obiettivo è velocizzare il processo di training senza 
inﬂuire troppo sulle performance, e ridurre l'eventuale rumore, es: 
Nel MNIST dataset i pixel nei bordi sono sempre bianchi, possiamo 
pensare di rimuoverli 
Spesso i pixel neri sono correlati, cioè appaiono vicini. È possibile 
fonderli facendone una media.  
Se creassimo a caso immagini, in rarissimi casi potrebbero assomigliare 
alle cifre nel dataset. Perciò i gradi di libertà disponibili nella creazione 
di istanze sono notevolmente ridotti rispetto a quelli potenziali in uno 
spazio con le medesime dimensioni. 
Inoltre la riduzione di dimensionalità permette di creare graﬁci nel caso in 
cui le dimensioni siano 2 o 3.
3"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#20,20,"Scikit-learn: Kernel PCA (kPCA)
In modo simile ai kernel del SVM è possibile fare proiezioni non lineari 
complesse per la riduzione di dimensionalità. 
Similmente al SVM, ha il vantaggio di mantenere cluster di istanze dopo la 
proiezione, oppure operare 
 unrolling
  di forme complesse. 
In scikit-learn impiegando il kernel rbf si ha: 
from 
sklearn.decomposition 
 import 
KernelPCA
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.04
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
Di seguito alcuni esempi di proiezioni a 2 dimensioni con vari kernel:
21
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#21,21,"Scikit-learn: Kernel PCA (kPCA)
La scelta del kernel dipende dal task. Se il task è supervisionato, si può fare 
una semplice grid search sui kernel e i relativi iperparametri per ottenere 
performance migliori. 
Nel seguente codice si impiega una pipeline per il task di regressione: 
from 
sklearn.model_selection 
 import 
GridSearchCV
from 
sklearn.linear_model 
 import 
LogisticRegression
from 
sklearn.pipeline 
 import 
Pipeline
clf 
= 
Pipeline
 ([
(
""kpca""
, 
KernelPCA
 (
n_components
 =
2
)),
(
""log_reg""
 , 
LogisticRegression
 ())
])
param_grid 
 = 
[{
""kpca__gamma""
 : 
np
.
linspace
 (
0.03
, 
0.05
, 
10
),
""kpca__kernel""
 : [
""rbf""
, 
""sigmoid""
 ]
}]
grid_search 
 = 
GridSearchCV
 (
clf
, 
param_grid
 , 
cv
=
3
)
grid_search
 .
fit
(
X
, 
y
)
>>> 
print
(
grid_search
 .
best_params_
 )
{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}
22"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#22,22,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri?
23"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#23,23,"Scikit-learn: Kernel PCA (kPCA)
Se il task è unsupervised, è possibile comunque fare un tuning dei 
parametri? 
Se ricostruiamo i dati originali con le componenti PCA possiamo valutare 
le performance con una misura di discostamento (es. distanza quadratica). 
Attenzione
 : l'impiego dei kernel implica che la ricostruzione generi un 
feature space inﬁnito-dimensionale. Perciò non è possibile confrontare 
direttamente le istanze con lo spazio originale. Con la tecnica 
recontruction pre-image è possibile trovare il punto nello spazio originale 
che è vicino alla istanza 
 ricostruita
 .
24
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#24,24,"Scikit-learn: Kernel PCA (kPCA)
Il parametro ﬁt_inverse_transform=True adotta questa strategia: 
rbf_pca 
 = 
KernelPCA
 (
n_components 
 = 
2
, 
kernel
=
""rbf""
, 
gamma
=
0.0433
,
              
 fit_inverse_transform
 =
True
)
X_reduced 
 = 
rbf_pca
.
fit_transform
 (
X
)
X_preimage 
 = 
rbf_pca
.
inverse_transform
 (
X_reduced
 )
>>> 
from 
sklearn.metrics 
 import 
mean_squared_error
>>> 
mean_squared_error
 (
X
, 
X_preimage
 )
32.786308795766132
25"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#25,25,"Scikit-learn: Locally Linear Embedding (LLE)
È una ulteriore tecnica non lineare, ma non si basa sulle proiezioni. 
In sintesi, nella prima fase analizza le similarità tra una istanza e le istanze 
vicine (neighbors), e successivamente crea un iperspazio con meno 
dimensioni che mantiene queste tali relazioni.  
È un approccio ideale per fare unrolling e in presenza di poco rumore. 
from 
sklearn.manifold 
 import 
LocallyLinearEmbedding
lle 
= 
LocallyLinearEmbedding
 (
n_components
 =
2
, 
n_neighbors
 =
10
)
X_reduced 
 = 
lle
.
fit_transform
 (
X
)
Lo spazio risultate è correttamente dispiegato, anche se le distanze relative 
non sono mantenute coerenti.
26
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#26,26,"Esercitazione
Carica il dataset MNIST e suddividilo in 60K training e 10K test set. 
Addestra un classiﬁcatore Random Forest, calcola il tempo di training e le 
performance. 
Applica PCA con una 
 explained variance ratio
  del 95%. 
Addestra un nuovo classiﬁcatore Random Forest, calcola il tempo di 
training e le performance, e confronta i valori con i valori precedenti.
27"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#27,27,"Esercitazione
from
 sklearn.datasets 
 import
 fetch_openml
mnist = fetch_openml(
 'mnist_784'
 )
X_train = mnist[
 'data'
][:
60000
]
y_train = mnist[
 'target'
 ][:
60000
]
X_test = mnist[
 'data'
][
60000
:]
y_test = mnist[
 'target'
 ][
60000
:]
from
 sklearn.ensemble 
 import
 RandomForestClassifier
rnd_clf = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
import
 time
t0 = time.time()
rnd_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
28"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#28,28,"Esercitazione
from
 sklearn.metrics 
 import
 accuracy_score
y_pred = rnd_clf.predict(X_test)
accuracy_score(y_test, y_pred)
from
 sklearn.decomposition 
 import
 PCA
pca = PCA(n_components=
 0.95
)
X_train_reduced = pca.fit_transform(X_train)
rnd_clf2 = RandomForestClassifier(n_estimators=
 100
, random_state=
 42
)
t0 = time.time()
rnd_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
X_test_reduced = pca.transform(X_test)
y_pred = rnd_clf2.predict(X_test_reduced)
accuracy_score(y_test, y_pred)
29"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#29,29,"Esercitazione
from
 sklearn.linear_model 
 import
 LogisticRegression
log_clf = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf.fit(X_train, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf.predict(X_test)
print(
accuracy_score(y_test, y_pred))
log_clf2 = LogisticRegression(multi_class=
 ""multinomial""
 , solver=
 ""lbfgs""
, 
random_state=
 42
)
t0 = time.time()
log_clf2.fit(X_train_reduced, y_train)
t1 = time.time()
print
(
""Training took {:.2f}s""
 .
format
(t1 - t0))
y_pred = log_clf2.predict(X_test_reduced)
print(
accuracy_score(y_test, y_pred))
30"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#3,3,"Osservazione
Presi 2 punti a caso in un quadrato di dimensioni 1x1, la distanza media è 
0.52. In un cubo 3d è 0.66. In un ipercubo di 1M dimensioni è 408,25. 
In dataset con alta dimensionalità il rischio di data sparity è elevato. 
Una nuova istanza è molto probabile che sia lontana dalle altre già 
incontrate in precedenza; probabile overﬁtting durante il test. 
Se incrementiamo le istanze nel training set riduciamo il problema, ma il 
tempo di addestramento si allungano, e a volte non è possibile 
collezionare nuove istanze. 
Il numero di istanze da includere cresce esponenzialmente col numero 
di dimensioni del dataset.
4"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#30,30,"Esercitazione
>>>
Training took 57.60s
Training took 124.90s
0.9255
Training took 55.04s
Training took 15.68s
0.9201
31"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#31,31,"Andreas C. Müller, Sarah Guido. 
 Introduction to Machine Learning with 
Python: A Guide for Data Scientists
 . O'Reilly Media 2016  
Aurélien Géron. 
 Hands-On Machine Learning with Scikit-Learn and 
TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
 . 
O'Reilly Media 2017
Testi di Riferimento
32"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#4,4,"Projection
Spesso le features sono correlate tra loro, oppure assumono spesso valori in 
piccoli intervalli. 
Nell'esempio seguente si può notare come molti punti sono vicini ad un 
piano (2d). Se proiettiamo questi punti sul piano (sottospazio) otteniamo un 
dataset di dimensioni ridotte, con 2 nuove features, cioè le coordinate nel 
piano.
5
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#5,5,"Projection
In altri casi la proiezione è difﬁcile o impossibile. 
Nel dataset toy Swiss roll, semplici piani non permettono di mantenere la 
coerenza spaziale originale delle istanze. Solo ""dispiegando il rotolo"" di 
punti è possibile avere un piano coerente.
6
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#6,6,"Manifold learning
Nell'esempio precedente, il 
 roll
 è una struttura che assomiglia a un piano 
2d (d=2) che è disposta (rotolata) in uno spazio 3d (n=3 con n>d). 
Manifold assumption
 : l'ipotesi che molti dataset reali possono essere 
rappresentati in spazi con dimensioni ridotte. Inoltre suppone che nello 
spazio ridotto sia più facile risolvere problemi di classiﬁcazione, 
regressione, etc.  
Quest'ultima assunzione non è sempre vera, es:
7
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#7,7,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Quale piano sceglieresti?
8
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#8,8,"Richiami: PCA
Per proiettare i dati in uno iperspazio con meno dimensioni, occorre prima 
deﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza 
massima, mentre i 2 piani tratteggiati hanno varianze più basse. 
Il piano con massima varianza potenzialmente riduce la perdita di 
informazione durante la proiezione. 
PCA mira a identiﬁcare tali assi.
9
"
data_test\rootfolder\università\MachineLearning\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#9,9,"PCA: Step by step in Python
Attenzione
 : se perturbiamo leggermente il training set, i 
 principal 
component 
 (gli assi) possono cambiare, ad esempio invertendo la 
direzione, anche se il piano deﬁnito da essi rimane generalmente lo stesso. 
Per trovare le compomenti si impiega la Singular Value Decomposition 
(SVD) che permette di ottenere la seguente decomposizione: 
X = U 
 Σ
 V
T 
dove le colonne di V rappresentano le componenti che stiamo cercando. 
In Python possiamo ottenerle nel seguente modo: 
X_centered 
 = 
X 
- 
X
.
mean
(
axis
=
0
)
U
, 
s
, 
Vt 
= 
np
.
linalg
.
svd
(
X_centered
 )
c1 
= 
Vt
.
T
[:, 
0
]
c2 
= 
Vt
.
T
[:, 
1
]
Attenzione
 : è sempre consigliabile centrare i dati nell'origine impiegando 
lo 
StandardScaler
 ().
10"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Valutazione delle prestazioni
Machine Learning "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#1,1,"Sommario
Introduzione alla Valutazione delle Prestazioni nella 
Regression 
Loss Function e le tre misure di Loss: 
•
 Training Error, Generalization Error, Test Error 
Overﬁtting 
Le tre fonti di errore: Noise, Bias, Variance
 
2"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#10,10,"Training Error vs.  
Complessità del Modello
 
11E’ interessante vedere come può variare tale errore in base 
alla complessità del modello.  
caso di modello costante:  
y
Area xPrezzo
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#11,11,"Training Error vs.  
Complessità del Modello
 
12caso di modello lineare:  
y
Area xPrezzo
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#12,12,"Training Error vs.  
Complessità del Modello
 
13
caso di modello quadratico:  
Complessità del modelloErrore 
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#13,13,"Training Error vs.  
Complessità del Modello
 
14
caso di modello polinomiale:  
Complessità del modelloErrore 
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#14,14,"Training Error vs.  
Complessità del Modello
 
15L’andamento dell’errore ha dunque in genere la seguente 
forma: 
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#15,15,"Training Error vs.  
Complessità del Modello
 
16Il training error non è una buona misura della predictive 
performance: 
Esso è eccessivamente ottimistico, proprio perché il vettore 
ŵ è calcolato afﬁnché il modello si adatti ai dati di training. y
Area xPrezzo
xt
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#16,16,"Generalization Error
 
17Sarebbe interessante conoscere il “loss” prendendo in 
considerazione tutte le possibili coppie ( x, y), ossia, per il 
nostro esempio degli appartamenti, tutte le possibili case della 
zona presa in considerazione, calcolando la media della 
funzione loss su tali appartamenti. 
In genere però nel nostro data set abbiamo soltanto un 
numero limitato di osservazioni ( x, y). "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#17,17,"Generalization Error
 
18Per effettuare una stima di tale costo dovremmo cercare di 
pesare le varie coppie ( x, y) in base alla probabilità che hanno 
di essere presenti nella zona d’interesse.  
E’ dunque utile prendere in considerazione la distribuzione 
degli appartamenti in base al valore della loro area:
Area"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#18,18,"Generalization Error
 
19Potremmo inoltre considerare la distribuzione delle case in 
base al loro prezzo, a parità di area:
Prezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#19,19,"Generalization Error
 
20Formalmente, possiamo deﬁnire il Generalization (o True) 
Error come segue:
Generalization Error = Ex,y[L(y,f ˆw(x))]
ossia come l’average value della funzione Loss, calcolato su 
tutte le possibili coppie ( x, y) pesate in base alla loro 
probabilità di comparire nella zona."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#2,2,"La valutazione delle prestazioni è di importanza cruciale 
per poter apprezzare il metodo che stiamo utilizzando per 
le nostre previsioni. 
Essa ci aiuta nella scelta tra modelli di diversa complessità 
a nostra disposizione. 
A tal ﬁne occorre deﬁnire una metrica che ci consenta di 
valutare quanto perdiamo (loss) quando facciamo una 
certa previsione. 
 
3
Introduzione alla  
Valutazione delle Prestazioni"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#20,20,"Generalization Error
 
21Vediamo ora di intuire come tale errore possa variare in base 
alla complessità del modello. 
Per far questo ci avvarremo della rappresentazione che segue, 
dove la regione in blu rappresenta, con le diverse gradazioni 
nei vari punti, la distribuzione di probabilità di avere una casa 
nel nostro data set (la parte bianca rappresenta le più alte 
probabilità):
y
Area xPrezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#21,21,"Generalization Error
 
22Per valutare l’errore consideriamo come la “ﬁtted function” f 
(in verde nella ﬁgura precedente e in quelle successive), che 
si adatta alle osservazioni del training set, possa predire i 
valori delle case non presenti nel training set, pesate dalle 
loro probabilità. 
Ossia dobbiamo vedere quanto la f sia “vicina” all’area in 
bianco della distribuzione rappresentata in ﬁgura. 
Nei lucidi che seguono cercheremo di intuire l’andamento del 
Generalization Error a fronte di diverse complessità del 
modello (costante, lineare, quadratico, ecc.)."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#22,22,"Generalization Error vs.  
Complessità del Modello
 
23caso di modello costante: 
Prezzo
AreaErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#23,23,"Generalization Error vs.  
Complessità del Modello
 
24caso di modello lineare: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#24,24,"Generalization Error vs.  
Complessità del Modello
 
25caso di modello quadratico: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#25,25,"Generalization Error vs.  
Complessità del Modello
 
26caso di modello polinomiale: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#26,26,"Generalization Error vs.  
Complessità del Modello
 
27caso di modello “High level”: 
AreaPrezzoErrore 
Complessità del modello"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#27,27,"Generalization Error vs.  
Complessità del Modello
 
28L’andamento dell’errore è dunque in genere il seguente: 
Complessità del ModelloErrore"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#28,28,"Generalization Error
 
29Ricordiamoci però che, a differenza di ciò che accade per 
il training error, NON è possibile calcolare il 
Generalization Error. 
Per calcolarlo, dovremmo conoscere la “true distribution” 
delle probabilità vista prima, cosa che non sappiamo fare. "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#29,29,"Test Error
Deﬁnito come average loss sui punti dell’insieme di test:
 
30
Test Error =1
Ntest·X
i2testL[yi,fˆw(xi)]
AreaPrezzo"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#3,3,"Loss Function
 
4Possiamo indicare una funzione di Loss come segue:
dove y è l’actual value, mentre la funzione f ci fornisce il 
valore previsto ŷ.  
Tale funzione L rappresenta il costo che abbiamo se usiamo 
la f con il vettore dei pesi ŵ a fronte dell’input x.L[y, f ˆw(x)]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#30,30,"Andamento degli errori  vs.  
Complessità del Modello
 
31Training Error: 
Training Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#31,31,"Andamento degli errori vs.  
Complessità del Modello
 
32Generalization Error: 
Generalization Error
Training Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#32,32,"Andamento degli errori vs.  
Complessità del Modello
 
33Test Error: approssima il Generalization Error 
Generalization Error
Training ErrorTest Error
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#33,33,"Overﬁtting
 
34Dato un modello con parametri ŵ, si ha overﬁtting se esiste un 
modello con i parametri stimati w’ tale che: 
 1. training error( ŵ) < training error(w’) 
 2. true error( ŵ) > true error(w’) 
Generalization (true) Error
Training ErrorTest Error
ŵw’
Complessità del modelloErrore "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#34,34,"Training/Test Split
Un importante problema da considerare ai ﬁni 
dell’addestramento e della valutazione di un modello è la 
suddivisione delle osservazioni disponibili tra training set 
e test set:
 
35
Training Set Test Set"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#35,35,"Training/Test Split
Se per il training set abbiamo poche osservazioni 
rischiamo di non stimare in modo adeguato il modello, 
cosa che potrebbe comportare previsioni imprecise da 
parte dello stesso.
 
36
Training Set Test Set
Troppo pochi ➝ ŵ non stimato adeguatamente  "
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#36,36,"Training/Test Split
D’altro canto, se abbiamo poche osservazioni per il test 
set rischiamo di non avere una rappresentazione adeguata 
dei dati che stiamo analizzando (e.g., tutte le case in 
vendita) 
 
37
Training Set Test Set
Troppo pochi ➝ true error non stimato  
                       adeguatamente dal test error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#37,37,"Training/Test Split
Purtroppo non esiste una formula che ci dica come 
suddividere esattamente i dati in training set e test set. 
Una regola pratica da poter seguire consiste nell’usare un 
numero sufﬁciente di punti per il test set per consentire 
una ragionevole approssimazione del true error: 
 
38
Training Set Test Set
Se ciò lascia troppi pochi punti per il training set,  ci 
possiamo avvalere di altri metodi che vedremo 
successivamente (
 cross validation
 )."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#38,38,"Le tre sorgenti di errore
Noise 
Bias  
Variance
 
39Test SetE’ estremamente utile analizzare le diverse cause che possono 
portare ad un errore nelle previsioni. Esse sono le seguenti:
Cominciamo a vedere in modo intuitivo di cosa si tratta."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#39,39,"Noise
Come sappiamo, in genere i dati sono intrinsecamente 
“rumorosi”. 
Nel nostro caso, possiamo ipotizzare che esista una “true 
function” che lega 
 x
 a y. Essa però non è una descrizione 
perfetta di tale legame. Ci sono infatti altri fattori che 
magari non abbiamo tenuto in conto (altri attributi, ecc.)
 
40
Tutto ciò comporta un “rumore” intrinseco, che possiamo 
rappresentare con il termine 
 ε
, che ha media uguale a zero.y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#4,4,"Esempi di Loss Function
 
5La funzione di Loss può essere ad esempio deﬁnita come 
Errore Assoluto (Absolute Error):
oppure come Errore Quadratico (Squared Error):L[y, f ˆw(x)] = |y fˆw(x)|
L[y, f ˆw(x)] = [ y fˆw(x)]2
Tali esempi di funzione assumono che il “loss” per 
underpredicting sia uguale a quello di overpredicting."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#40,40,"Noise
Tale rumore comporta in genere uno scostamento (spread) 
rispetto alla funzione vera. 
Possiamo dunque prendere in considerazione la varianza 
di tale variabile:
 
41varianza di ε
Il rumore in questione è chiamato “
 irreducible error
 ”.y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#41,41,"Bias
Il rumore prima descritto non lo possiamo controllare. 
Possiamo però controllare il bias e la variance. 
Per deﬁnire il bias, consideriamo ad es. un modello 
costante addestrato con diversi training set:
 
42y
Area xPrezzo
y
Area xPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#42,42,"Bias
Consideriamo adesso la funzione media (quella tratteggiata) 
delle varie funzioni f stimate:
 
43y
Area xPrezzo
y
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#43,43,"Bias
Il bias è deﬁnito come la differenza tra la funzione media 
e la true function:
 
44
E’ in sostanza una valutazione di quanto il mio modello si 
adatti alla true function.
low complexity → high biasy
Area xPrezzo
bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#44,44,"Variance
Per introdurre il concetto di varianza nella regression, 
dobbiamo considerare quanto le varie funzioni f stimate 
differiscono dalla funzione media. Vediamo ad esempio il 
caso di modello costante: 
 
45Non abbiamo una variazione elevata  
per le diverse funzioni stimate.
low complexity → low variancey
Area xPrezzo
y
Area xPrezzo
y
Area xPrezzo
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#45,45,"Variance
Per un modello polinomiale di grado elevato le cose 
vanno in modo diverso:
 
46
Prezzo
Prezzo
Area Area"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#46,46,"Variance
Se consideriamo le funzioni f stimate per i possibili 
training set:
 
47
Questa volta la variazione è elevata.
high complexity → high varianceArea AreaPrezzo
Prezzo
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#47,47,"Bias per  
high-complexity models
Il bias per modelli “high order” è invece in genere basso:
 
48high complexity → low biasy
Area xPrezzo
f¯w(xt),Etrain [fˆw(xt)]
bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#48,48," 
49
Bias-Variance Tradeoff
bias variance
Complessità del Modello
sweet spotMSE = bias + variance2"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#49,49," 
50
Bias-Variance Tradeoff
goal in ML →  trovare il cosiddetto “sweet spot”
purtroppo non possiamo calcolare bias e variance!
Per calcolarle dovremmo avere a disposizione la true 
function e tutti i possibili training set. 
Vedremo in seguito come poter operare in pratica per 
ottimizzare il tradeoff."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#5,5,"Valutare la funzione Loss 
 
6Ai ﬁni della valutazione del “loss” occorre deﬁnire i 
seguenti tipi di errore: 
• Training Error 
• Generalization Error (True Error) 
• Test Error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#50,50," 
51
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)
bias + noise
#data points nel training settrue errorErrore
training error"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#51,51," 
52Andamento del True Error:
Se abbiamo pochi punti nel training set l’errore è alto, perché la 
funzione f (ﬁtted function) non stima bene la “true relationship” 
tra 
x
 e y. 
Aumentando i punti l’errore diminuisce. 
Al limite, esso tende ad un valore uguale a: bias + noise. Questo 
perché, anche se avessimo tutte le osservazioni possibili, il 
modello potrebbe non essere sufﬁcientemente ﬂessibile per 
catturare perfettamente la “true relationship” (questa è la nostra 
deﬁnizione di bias). 
A ciò si aggiunge il noise che, come sappiamo, non possiamo 
controllare. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#52,52," 
53Andamento del Training Error:
Se abbiamo pochi punti nel training set l’errore è basso, 
perché la funzione f (ﬁtted function) può approssimare più 
facilmente la “true relationship” tra 
 x
 e y. 
Aumentando i punti l’errore aumenta. 
Al limite, anch’esso tende ad un valore uguale a: bias + noise. 
Questo perché, se avessimo tutte le osservazioni possibili, 
l’errore calcolato sarebbe proprio il true error che, come 
abbiamo visto, tende al valore bias + noise. 
Errori vs. numerosità dei dati 
(con un modello di ﬁssata complessità)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#53,53,"Workﬂow per Regression  
(e per il ML in generale)
I due task importanti che dobbiamo attuare nella 
regression sono: 
1.
 Scelta del modello di regressione (
 model selection
 ) 
2.
 Valutazione del modello (
 model assessment
 )
 
54"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#54,54,"Workﬂow per Regression (e ML)
1.
 Model selection 
Spesso dobbiamo scegliere dei parametri di tuning 
 λ 
che controllano la complessità del modello (e.g., grado 
del polinomio) 
2.
 Model assessment 
Una volta scelto il modello, dobbiamo effettuare la 
valutazione del Generalization Error.
 
55"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#55,55,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
• 
stima dei parametri 
 ŵ
λ
 sui training data 
•
 valutazione delle prestazioni sui test data 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso test error  
2.
 Model assessment 
Considerare il test error calcolato su 
 ŵ
λ
*
 (ﬁtted model per la 
complessità scelta 
 λ
*) per approssimare il Generalization 
Error.
 
56Un approccio ingenuo  al problema potrebbe essere il seguente:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#56,56,"Workﬂow per Regression (e ML)
 
57Attenzione! 
Si è veriﬁcato un Peaking!!!
•E’ accaduto che l’ipotesi (i.e., la funzione stimata) è stata 
selezionata  in base alle sue prestazioni sull’insieme di test . 
•L’informazione che avrebbe dovuto rimanere conﬁnata in 
tale insieme si è, per così dire, “inﬁltrata” nell’algoritmo di 
apprendimento."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#57,57,"Una soluzione è quella di considerare non solo due data 
set, ossia il training set e il test set: 
 
58
Training 
SetTest 
Set
ma considerarne tre (a patto di avere dati sufﬁcienti): 
Training 
SetTest 
Set
Validation
 Set
Workﬂow per Regression (e ML)"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#58,58,"Workﬂow per Regression (e ML)
1.
 Model selection 
Per ogni modello di complessità 
 λ
: 
•
 stima dei parametri 
 ŵ
λ 
sul training set 
•
 valutazione delle prestazioni sul validation set 
•
scelta del parametro 
 λ
 (
λ
*) che comporta il più basso errore sul 
validation set 
2.
 Model assessment 
Calcolo del test error (usando dunque il test set) con 
 ŵ
λ
*
 per 
approssimare il Generalization Error.
 
59L’approccio in questo caso è il seguente:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#59,59,"Tipici split 
 
60Non c’è una regola generale per suddividere le 
osservazioni disponibili tra i tre data set. 
Tipici split sono i seguenti:
Training 
SetTest 
Set
Validation
 Set
80%      10 %   10%
50%      25%   25%"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#6,6,"Training Error
 
7Consideriamo ancora l’esempio relativo ai prezzi degli 
appartamenti. Supponiamo di avere a disposizione le 
osservazioni come rappresentate in ﬁgura:
y
AreaxPrezzo
"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#60,60,"Riferimenti
 
61
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2008. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#7,7,"Training Error
 
8y
AreaxPrezzo
Come sappiamo, dobbiamo decidere il modello da 
utilizzare (lineare, quadratico, ecc.) e scegliere un 
sottoinsieme delle osservazioni per effettuare la fase di 
training del modello:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#8,8,"Training Error
 
9y
AreaxPrezzo
Possiamo ad esempio scegliere un modello quadratico e 
calcolare i pesi w tali da minimizzare la funzione RSS:"
data_test\rootfolder\università\MachineLearning\4-Regression-Valutazione-sbloccato.pdf#9,9,"Calcolo del Training Error
 
10Una volta stimati i parametri del modello, possiamo 
valutare il training error di tale modello stimato come 
segue: 
1. Deﬁnizione di una Loss Function (absolute error, squared 
error, ecc.) 
2. Calcolo del Training Error come “average loss”, deﬁnito 
sugli N punti di training: 
Training Error =1
N·NX
i=1L[yi,fˆw(xi)]"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#0,0,"Machine Learning
Università Roma Tre  
Dipartimento di Ingegneria 
Anno Accademico 2021 -2022
Reinforcement Learning"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#1,1,"Acknowledgements, sources and links
Organization, content and images of the slides are extracted from  the 
following sources:
•Reinforcement Learning: An Introduction . Richard S. Sutton  
and Andrew G. Barto, second edition, 2018.
•Implementation of Reinforcement Learning algorithms, from 
Sutton -Barto’s book . Denny Britz, GitHub project, 2016.
•Tutorial: Introduction to Reinforcement Learning with 
Function Approximation . Richard S. Sutton, 2016.
•UCL Course, Reinforcement Learning, videos and slides .  
David Silver, 2015.
•UCL course, Advanced Deep Learning & Reinforcement 
Learning, videos and slides . DeepMind, 2018."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#10,10,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(Ot,Rt,At−1,Ot−1,Rt−1,...))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. .."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#11,11,"First actor: the agent
A never -ending loop
•...we(the agent) receive Rtand observe Ot...
•...wechoose the action At∼π(·,f(history ))...
•...and because ofour action At, the environment send usareward
•Rt+1 and a new state , that we observe as Ot+1. .."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#12,12,"Not alone! Second actor: the environment
Agent, step t
•Receives observation Ot
•Receives scalar reward Rt 
•Computes his own state !!""
•Executes action At.
Environment, step t
•Receives action At 
•Computes his own state !!#$%
•Emits observation Ot+1
•Emits scalar reward Rt+1"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#13,13,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#14,14,"History , agent state , environment state
Notation
•History : the sequence of observations, actions, rewards up 
to  time step t:
Ht:=O1,R1,A1,...,At−1,Ot,Rt
•The agent selects actions, and the environment answers with
observations andrewards
•State : the information used (by the agent and the  
environment) to determine what happens next
•State is naturally a sequence St
•Agent state is a function of history: St := f (Ht)
•Environment state ""!""is different from agent state ""!#"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#15,15,"Markov state
Uncertainty
Since we have no control of environment, everything is a random  
variable
Definition
A sequence of states (random variables) is Markov if and only if
Pr(St+1|St)=Pr(St+1|S1,...,St)
•The future is independent of the past given the present:
St  →Ht+1:+ ∞
•Once the state is known, the history may be thrown away: the  
state is a sufficient statistic of the future
Exercise
Is the environment state ""!""Markov? Is the history HtMarkov?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#16,16,"Fully observable environments
•Agent observes environment
state: Ot = !!""=!!%
•Agent state andenvironment  
state coincides!
Anever -ending loop
•...we(the agent) receive Rt
and observe St...
•...and thus wedecide todo  
action At∼π(·,St)...
•...andenvironment answers  
At with a new reward, state  
pair Rt+1,St+1..."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#17,17,"Example: themaze
Exercise
Discuss this example in terms of the language you have  
learned up tonow."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#18,18,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3 What do we know? State and observability
4 What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#19,19,"Strategy Policy
Arrows represent the policy π: which action to take from  
every state.Example: a policy for themaze
"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#2,2,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#20,20,"Example: values for the policy of the maze
•Let πbe the optimal policy
•Value vπ (s) for every state s
Exercise
Choose a state s and compute vπ (s) by yourself. If sj denote s
the successor state of s, can the value vπ (sj) help with this  
computation?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#21,21,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -and model?
5 The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#22,22,"Prediction , improvement and control
The prediction problem inRL
Forecast the future: can you say from each state how much will be  
your return? It depends on the policy!
The improvement problem inRL
Change the future: can you find a different policy that will give  
you a better return?
The control problem inRL
Change the future: can you find the best policy atall?
Exercise
State formally the prediction, the improvement and the control  
problem."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#23,23,"Gridworld example: prediction
Exercise
Compute the value function for the uniform random policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#24,24,"Gridworld example: improvement
Exercise
Find an improvement of the uniform policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#25,25,"Gridworld example: optimal control
Exercise
Compute the optimal value function over all possible policies.  
Given the optimal value v∗as above, find the optimal policy.  Is 
the optimal policy unique?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#26,26,"Wrapping up
Learning goals
•Understand the RL problem, and how RL differs from  
supervised learning
•Understand reward, return and how they are used to 
make  decisions
•Understand actions, states and rewards in term 
of  agent/environment interactions
•Understand the optimal control problem"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#27,27,"Wrapping up
What we (hopefully) have learnt
•Reinforcement Learning (RL) is concerned with goal -directed  
learning and decision -making. In RL an agent learns from  
experiences it gains by interacting with the environment. In  
supervised learning we cannot affect theenvironment
•In RL rewards are often delayed in time and the agent tries to  
maximize the cumulative sum of rewards, called return .Return 
is a long -term goal. For example, one may need to  make 
seemingly suboptimal moves to reach a winning position in a 
game
•An agent interacts with the environment via actions. The  
environment answers with states and rewards ... and so on in 
a  loop, that can finish after a certain number of steps or go 
on  forever
•Optimal control can be achieved by a prediction -improvement  
loop"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#28,28,"Exercises
•Can every decision task be represented as an optimization  
problem with respect to a suitable reward?
•Is the reward an intrinsic datum of the decision task?
•Make an example where the greedy policy isoptimal.
•Make an example of a decision task with non-Markov  
environment state.
•Make an example of a decision task with non-Markov agent  
state."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#29,29,"Exercises
The generic definition of policy is a time -dependant stochastic  
function of the history: πt (At|Ht ) = Pr(At |Ht ). Give a definition  of the 
policy in the following cases, and find a corresponding task.
•Fully observable environment, stochastic and non-stationary  
policy.
•Partially observable environment, stochastic and stationary  
policy.
•Fully observable environment, deterministic and stationary  
policy."
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#3,3,"1What is Reinforcement Learning?
The RL setup: problem and actors
 2
3What do we know? State and observability
4What can we do? Policy and value -andmodel?
5The never -ending control loop: prediction =improvement"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#4,4,"The RLproblem
Important points
•Trying to reach a goal
•Interactions: active decision -making agent vs environment
•Uncertainty about theenvironment
•Effects of actions cannot be fully predicted: 
adaptation required ( learning )
The RL reward hypothesis
All goals can be described by the maximization of some expected  
cumulative reward
•Is it true? Interesting analysis at  
http://incompleteideas.net/rlai.cs.ualberta.ca/ 
RLAI/rewardhypothesis.html
•Related with the expected utility hypothesis from von  
Neumann -Morgenstern utility theory"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#5,5,"The RLproblem
RL main task
Decision problem: we would like to choose actions that maximize  
the return , i.e. the total future reward
Sequential decision making
Actions may have long term consequences
Uncertainty
The best we can aim for is maximizing the value , i.e.the
expected total future reward
Exercise
Find an example of a deterministic task, that is, a task where  your 
actions gives a fixed outcome (that you may or may not know  in 
advance)"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#6,6,"The RLproblem
To be greedy can bewrong
•A financial investment (may take months to mature)
•Refuelling a helicopter (might prevent a crash in 
several  hours)
•Blocking opponent moves (might help winning chances 
many moves from now)
Exercise
Discuss the difference between return and value"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#7,7,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#8,8,"The RLproblem
Examples of reward
•Games: RT := −1, 0, +1 (win, draw, lose). More generally,
•RT can be the final score
•Games: RT := 0, +1 (win, lose). In this case, the value is the  
probability of winning. Why?
•Atari games: Rt is the immediate score increment at step t
•Walking robot: Rt := +1 for every step he doesn’t fall
https://www.youtube.com/watch?v=gn4nRCC9TwQ .
•Financial investment: Rt is the money increment in the last  
time step in portfolio
•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  
Wrong. Why?
•Maze and Gridworld: −1 for every move. Correct. Why?"
data_test\rootfolder\università\MachineLearning\40-RL(1)-sbloccato.pdf#9,9,"Examples
Games
TD-Gammon, 1995, ACM Communications .  
Atari’s family (video ).
•49 out of 57: DQN, 25 Feb 2015, Nature .
•52 out of 57: R2D2, Sep 2018, ICLR 2019 .
•51 out of 57: MuZero, Nov 2019, arXiv .
•57 out of 57: Agent57, Mar 2020, arXiv .
AlphaGo’s family (video ).
•AlphaGo, 27 Jan 2016, Nature .
•AlphaGo Zero, Oct 2017, Nature . 
•AlphaZero, Dec 2018, Science .
•MuZero, Nov 2019, arXiv .
StarCraft II (video ).AlphaStar, Nov 2019, Nature .
Protein folding
How a protein’s amino acid sequence dictates its three -dimensional  
structure? AlphaFold :Oct 2019, PROTEINS ;Jan 2020, Nature ."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#0,0,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equationsMDP: Markov Decision Processes
"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#1,1,"Basic block: state , action , model ,reward
uintermediate
or initial state
 vintermediate
or final state
w
r =+3
p(v,+3|u,a)=0.7
r =−1
p(w,−1|u,a)=0.3intermediate
or final stateaction a"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#10,10,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#11,11,"The D in MDP: decisions
Where are thedecisions?
•In any state s, the agent must choose between available  
actions a
•When choosing a from s, the environment answers s’ 
with probability #!!!"". Environment decision.
•The agent behaviour is given by probabilities π(a|s): ”how  
likely I’m going to choose a from s?”.  Agent decision.
Definition
A policy π is a probability distribution over actions given states:
π(a|s) := Pr(At = a|St =s)"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#12,12,"Example: uniform stochastic policy
A
1
B
1
0.5
0.5
0.8,+10
 0.2,+3
0.1,+2
 0.9,−30.5
0.5
0.1,+39
0.9,+42
0.1,−2
0.9,+3
2 2
What can wedo?
At every step, we choose the action according to the probability."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#13,13,"Example: deterministic policy
A
1
2B
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2
What can wedo?
At every step, we choose the given action."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#14,14,"Tabular representation
S and Aarefinite
A policy can be represented by a table: every line in the table  
corresponds to a state.
Stochastic policy
A[0.5,0.5]
B[0.5,0.5]
Deterministic policy
A2
B1"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#15,15,"The return : towards the goal
Definition
•Total return ofanepisode ending attime T:thevalue ofthe  
random variable Gt:=Rt+1+Rt+2+···+RTfortheepisode
•If the MDP is continuing, we need a discount factor :
Why?
•Transforming theterminal state inabsorbing with reward 0,we  
can use a unified notation for episodic and continuing MDP:
•In episodic tasks we can use γ = 1, in continuing tasks we  
must use γ <1!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#
!!≔#!""#+%#!""$+%$#!""%+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#16,16,"The return : towards the goal
Why the discount
•The discount factor measures how much do we care about 
rewards far in thefuture
•A reward r after k + 1 time -steps is worth “only” γkr : wesay
myopic evaluation if γ ∼0, far-sighted evaluation if γ ∼1
•Convenience: avoids infinite returns in cyclic MDP
•We shouldn’t trust our model too much: uncertainty about  
the future may not be fully represented
•If the reward is financial, immediate rewards may earn more  
interest than delayed rewards
•Animal and human behaviour shows preference for immediate  
reward"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#17,17,"1Distribution model
2Decisions andreturn
3Value functions
4 Bellman equations"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#18,18,"How much are states and actions worth?
Remark
The total return Gt at time t is a random variable:
Thus, it makes sense to compute its expected value.
Definition :state -value function
The state -value function vπ(s)foraMDP isthe return wecan
expect toaccumulate starting from state s,following thepolicy π:
vπ(s):=""π[Gt|St=s]
Exercise
Is the above definition/notation correct?!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#19,19,"How much are states and actions worth?
Total return
State -value function
vπ(s)=""π[Gt|St=s]
Definition: action -value function
The action -value function qπ (s,a) for a MDP is the return we can 
expect to accumulate starting from a state s, choosing action a, 
and then following the policy π:
qπ(s,a):=Eπ[Gt|St=s,At=a]!!≔#!""#+%#!""$+%$#!""%+%%#!""*+…=(
&'("")
%&#!""&""#"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#2,2,"Basic block: state , action , model ,reward
u
v
wa
r = +3, p =0.7
r=−1,p=0.3"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#20,20,"Example
Exercise
Compute qπ(A,1),qπ(A,2),qπ(B,1) and qπ(B,2) forthe uniform policy π."
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#3,3,"Markov Decision Process: MDP
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
Distribution model
The probability distribution p is called distribution model , or  
simply model, of the MDP
Focus on finite MDP
From now on, assume that S, Aand Rarefinite"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#4,4,"MDP: meaning of the model
Markov decision process data
•Asetofstates S,asetofactions Aandasetofrewards R
•For each state s ∈S and action a∈A, a probability  
distribution p(·,·|s,a)over S×R
•A discount factor γ ∈[0,1]
From distribution model to random variables St andRt
The probability distribution p of the MDP gives the next state and  
reward:
Pr(St=s',Rt=r|St−1=s,At−1=a):=p(s',r|s,a)"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#5,5,"MDP: meaning of the model
Exercises
•Explain what St,At and Rtare
•Given p, give a formula for Pr(St = s'|St−1 = s, At−1 = a)
•Given p, give a formula for ""[Rt|St−1 = s, At−1 =a]
•Given p, give a formula for ""[Rt|St−1 = s, At−1 = a,St = s']"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#6,6,"The M in MDP: Markov property
Tabular representation: transitions
An action a ∈Agives a transition probability from a state s toa
state s' :
Thus, we have a transition matrix Pa for each action a, and a  
corresponding underlying Markov stochastic process.
Tabular representation: rewards
An action a ∈A gives an average reward for any state s:
Thus, we have an average reward vector Ra for any action a.!!!!""≔#$#|$,'==!)*$=$#|*$%&=$,+$%&='
,!""=-,$|*$%&=$,+$%&='"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#7,7,"Example
u
1
2v
1
2
0.8,+10
 0.2,+3
0.1,+2
 0.9,−3
0.1,+39
0.9,+42
0.9,+3
0.1,−2"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#8,8,"Example
u1
2v1
0.8,+10 0.2,+3
0.1,+2 0.9,−30.1,+39
0.9,+42
0.9,+30.1,−2
2
= distribution model"
data_test\rootfolder\università\MachineLearning\41-RL(2)-sbloccato.pdf#9,9,"Episodic MDP
•If there is a special terminal  
state reachable from every  
state, the MDP is episodic
•Otherwise, the MDP is
continuing
•Episode : any sample
S0,A0,R1,S1,...terminating  
in the final state
Exercise
•Write an episode, and compute its probability 
of  happening. Hint: tricky question."
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 16)
1"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#1,1,"Sommario
Richiami RL e Q-learning 
Esempio taxi  
Ambiente OpenAI Gym 
Approccio non RL 
Approccio Q-Learning 
Approccio Epsilon-Greedy Q-Learning 
Valutazione e iperparametri"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#10,10,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
https://www.gymlibrary.ml  
La libreria include già l'ambiente Taxi già costruito. 
!
pip install cmake 
 'gym[atari]'
  scipy
import
 gym
# carichiamo l'environment taxi
env = gym.make(
 ""Taxi-v3""
 ).env
env.render()
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | 
: |
|
Y
| : |B: |
+---------+
11"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#11,11,"OpenAI Gym
...
env.reset() 
 # reset environment to a new, random state
env.render()
print
(
""Action Space {}""
 .
format
(env.action_space))
print
(
""State Space {}""
 .
format
(env.observation_space))
>>
+---------+
|R: | : :
 G
|
| : | : : |
| : : 
: : |
| | : | : |
|Y| : |
 B
: |
+---------+
>> Action Space Discrete(6)
>> State Space Discrete(500)
...
12"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#12,12,"OpenAI Gym
Le azioni sono codiﬁcate con interi:  
0 = south, 1 = north, 2 = east, 3 = west, 4 = pickup, 5 = dropoff 
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : 
| : |
|Y| : |
 B
: |
+---------+
state, reward, done, info 
 =
 env.step(
 0
) # azione: verso south
env.render()
+---------+
|R: | : :
 G
|
| : | : : |
| : : : : |
| | : | : |
|Y| : 
|
B
: |
+---------+
13"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#13,13,"OpenAI Gym
Sono delle API in Python che permettono di sperimentare approcci RL. 
# parametri (taxi row, taxi column, passenger index, destination index) 
state = env.encode(
 3
, 
1
, 
2
, 
0
)
print
(
""State:""
 , state)
env.s = state
env.render()
>> State: 328
+---------+
|
R
: | : :G|
| : | : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
14"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#14,14,"OpenAI Gym
Possiamo rappresentare un certo stato dell'environment esplicitamente. 
Allo stato sarà associato un id numerico (328). 
state 
=
 env.
encode
(
3
, 
1
, 
2
, 
0
)  
# (taxi row, taxi column, passenger index, destination index)
print
(
""State:""
 , state)
env.
s 
=
 state
env.
render
()
State: 328
+---------+
|
R
: | : :G|
| : : : : |
| : : : : |
| | 
: | : |
|
Y
| : |B: |
+---------+
15"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#15,15,"OpenAI Gym
La reward table rappresenta coppie stati x azioni. 
Ad esempio, per lo stato 328 otteniamo il seguente dizionario: 
env.P[
328
]
>>
{0: [(1.0, 428, -1, False)],
 1: [(1.0, 228, -1, False)],
 2: [(1.0, 348, -1, False)],
 3: [(1.0, 328, -1, False)],
 4: [(1.0, 328, -10, False)],
 5: [(1.0, 328, -10, False)]}
Dove il dizionario ha la struttura:  
{action: [(probability 
 sempre_1
 , next-state, reward, done)]}.
16"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#16,16,"Esercizio Taxi: senza RL
Supponi che l'agente abbia accesso unicamente la 
 reward table
  P per 
decidere quale azioni compiere. Perciò non apprende dall'esperienza 
acquista nel passato. 
Crea un loop che prosegua ﬁnché il cliente non sia arrivato a destinazione. 
Suggerimento: la funzione 
 env.action_space
 .
sample
 ()
 restituisce una 
azione in modo casuale.
17"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#17,17,"Esercizio Taxi: senza RL
env.
s 
= 
328  
# stato iniziale
epochs 
= 
0
penalties, reward 
 = 
0
, 
0
frames 
=
 [] 
# per animazione
done 
= 
False
while 
not
 done:
    action 
 =
 env.
action_space
 .
sample
()
    state, reward, done, info 
 =
 env.
step
(action)
    
if
 reward 
 == 
-
10
:
        penalties 
 += 
1
    
    frames.
 append
({
        
 'frame'
: env.
render
(mode
=
'ansi'
),
        
 'state'
: state,
        
 'action'
 : action,
        
 'reward'
 : reward
        }
    )
    epochs 
 += 
1
    
print
(
""Timesteps taken: {}""
 .
format
(epochs))
print
(
""Penalties incurred: {}""
 .
format
(penalties))
18"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#18,18,"Esercizio Taxi: senza RL
Per l'animazione: 
from
 IPython.
 display 
import
 clear_output
from
 time 
import
 sleep
def
 print_frames(frames):
    
for
 i, frame 
 in 
enumerate
 (frames):
        clear_output(wait
 =
True
)
        
 print
(frame[
'frame'
].
getvalue
 ())
        
 print
(
f""Timestep: 
 {i 
+ 
1
}
""
)
        
 print
(
f""State: 
 {frame[
'state'
]}
""
)
        
 print
(
f""Action: 
 {frame[
'action'
 ]}
""
)
        
 print
(
f""Reward: 
 {frame[
'reward'
 ]}
""
)
        sleep(
 .1
)
        
print_frames(frames)
L'algoritmo può impiegare molti step (oltre 1000) incorrendo in molte 
penalty (oltre 300).
19"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#19,19,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
20"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#2,2,"Richiami: Reinforcement Learning
Nell'ambito del Reinforcement Learning (RL), la 
 policy
  è la strategia per 
scegliere una azione nello stato corrente che determini la massima 
ricompensa (
 reward)
 . 
Il 
Q-learning
  è un algoritmo che mira a determinare col tempo la migliore 
azione (
 best action
 ), dato lo stato corrente (
 current state), 
 in base alla stima 
di 
reward
  attesa. 
Misura la bontà di una combinazione stato-azione in termini di 
 reward
 . 
Impiega una 
 Q-table
  aggiornata dopo ogni episodio, dove la riga 
corrisponde allo stato e la colonna all'azione. Il Q-value dentro la tabella 
indicano quanto una azione è stata buona (alto reward) in passato. 
È un algoritmo model-free, poiché l'agente non conosce il valore di una 
azione prima di effettuarla.  
Non segue un approccio greedy poiché scegliere sempre l'azione con 
reward immediato massimo potrebbe determinare sequenze di azioni non 
ottime.
3"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#20,20,"Esercizio: Q-learning in Python
Esercizio
 : modiﬁca il codice precedente implementando l'algoritmo  
Q-learning. 
%%time   # stampa il tempo trascorso al termine dell'esecuzione
import
 numpy 
as
 np
import
 random
from
 IPython.display 
 import
 clear_output
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
# per il report
all_epochs = []
all_penalties = []
q_table = np.zeros([env.observation_space.n, env.action_space.n])
...
21"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#21,21,"Esercizio: Q-learning in Python
...
for
 i 
in 
range
(
1
, 
100001
):
    state = env.reset()
    epochs, penalties, reward, = 
 0
, 
0
, 
0
    done = 
 False
    
    
while 
not
 done:
        action = np.argmax(q_table[state])
        next_state, reward, done, info = env.step(action) 
        
        old_value = q_table[state, action]
        next_max = np.
 max
(q_table[next_state])
        
 # eq Bellman 
        new_value = (
 1
 - alpha) * old_value + alpha * 
                    (reward + gamma * next_max)
        q_table[state, action] = new_value
...
22"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#22,22,"Esercizio: Q-learning in Python
...
        
 if
 reward == 
 -10
:
            penalties += 
 1
        state = next_state
        epochs += 
 1
        
    
if
 i % 
100
 == 
0
:
        clear_output(wait=
 True
)
        
 print
(
f
""Episode: 
 {i}
""
)
print
(
""Training finished.\n""
 )
>> Episode: 100000
>> Training finished.
>> CPU times: user 1min 25s, sys: 15 s, total: 1min 40s
>> Wall time: 1min 29s
q_table[
 328
] # l'azione migliore è north -2.27
>> array([-2.31436727, -2.27325184, -2.31164458, -2.3090025 , 
          -2.8816    , -2.8816    ])
23"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#23,23,"Esercizio: Q-learning in Python
Esercizio
 : valuta nuovamente l'algoritmo con le best action ricavate dalla 
Q-table. 
24"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#24,24,"Esercizio: Q-learning in Python
Valutazione dell'algoritmo con le best action ricavate dalla Q-table: 
total_epochs, total_penalties 
 = 
0
, 
0
episodes 
 = 
100
for
 _ 
in 
range
(episodes):
    state 
 =
 env.
reset
()
    epochs, penalties, reward 
 = 
0
, 
0
, 
0
    
    done 
 = 
False
    
while 
not
 done:
        
 action 
=
 np.
argmax
(q_table[state])
        state, reward, done, info 
 =
 env.
step
(action)
        
 if
 reward 
 == 
-
10
:
            penalties 
 += 
1
        epochs 
 += 
1
    total_penalties 
 +=
 penalties
    total_epochs 
 +=
 epochs
print
(
f""Results after 
 {episodes}
  episodes:""
 )
print
(
f""Average timesteps per episode: 
 {total_epochs  
/ 
episodes}
 ""
)
print
(
f""Average penalties per episode: 
 {total_penalties  
/ 
episodes}
 ""
)
>> Results after 100 episodes:
>> Average timesteps per episode: 13.01     
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
25"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#25,25,"Epsilon-Greedy Q-learning
Con l'approccio Epsilon-greedy Q-learning introduciamo il bilanciamento 
tra 
exploration
  e 
exploitation
 .  
Nei modelli model-free è fondamentale esplorare l'ambiente per ottenere 
informazioni su cui basare le successive decisioni informate. 
Nella versione Espilon-greedy, con probabilità epsilon l'agente sceglie una 
azione in modo casuale (esplorazione) e segue l'azioni valutata migliore 
nell'altro caso (1-epsilon).  
Esercizio
 : modiﬁca il codice introducendo questa versione.
26
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#26,26,"Epsilon-Greedy Q-learning
Esercizio
 : modiﬁca il codice introducendo questa versione. 
... 
# iperparametri
alpha = 
 0.1
gamma = 
 0.6
epsilon = 
 0.1
...
while 
not
 done:
        
 if
 random.uniform(
 0
, 
1
) < epsilon:
            action = env.action_space.sample() 
 # Explore action space
        
 else
:
            action = np.argmax(q_table[state]) 
 # Exploit learned values
...
>> Results after 100 episodes:
>> Average timesteps per episode: 12.81     <-- invece di 13.01 
>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti 
27"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#27,27,"Valutazione approccio RL
Alcune metriche da considerare nella valutazione sono: 
Numero medio di 
 penalità
  per episodio (ideale --> 0) 
Numero medio di 
 timesteps
  per percorso  
Valore medio di 
 reward
  per mossa
28
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#28,28,"Iperparametri
Alpha
 : da decrementare con l'incremento dell'esperienza acquisita 
Gamma
 : se ci avviciniamo all'obiettivo dobbiamo ridurre l'importanza 
della reward a lungo termine 
Epsilon
 : con l'accumularsi dei tentativi, epsilon deve ridursi. 
Esercizio: applica un approccio 
 grid search
  per ricavare una 
approssimazione degli iperparametri nello scenario del taxi che guida da 
solo.
29"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#29,29,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
30"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#3,3,"Richiami: Reinforcement Learning
Step #1: inizializzo la Q-table con valori pari a 0, ogni azioni e 
equiprobabile. 
Step #2: scegli l'azione in modo random, o sfrutta l'eventuale informazione 
che hai al principio 
Step #3: esegui l'azioni e colleziona il reward 
Step #4: aggiorna la Q-table di conseguenza 
4
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#4,4,"Richiami: Reinforcement Learning
L'equazione di 
 Bellman
  aggiorna i Q-values determinando il valore 
massimo di 
 reward
  atteso per ogni stato nella Q-table.  
Il primo termine 
 Q()
 indica il valore dell'azione corrente nello stato 
corrente. Il secondo combina il reward corrente e il valore discount dello 
stato futuro caratterizzato da reward massima.  
Il 
discount factor lambda
  [0,1] permette di ridurre il reward col tempo e 
indica quanta importanza assegnamo ai futuri reward: valori vicini allo 0 
indicano che l'agente si limita a valutare i reward immediati, vicini al 1 
permettono di valutare l'effetto a lungo termine dei reward. 
Il valore 
 alpha
  (learning rate (0,1]) determina l'importanza che assegniamo 
ai valori futuri rispetto a quelli attuali.
5
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#5,5,"Esempio: taxi che guida da solo
Deﬁniamo un ambiente (environment) sempliﬁcato dove un taxi deve 
prendere un cliente in una certa locazione e lasciarlo in un'altra. 
Vogliamo altresì: 
Lasciare il cliente nel luogo giusto 
Minimizzare il tempo per il trasporto 
Seguire le regole della strada 
Dobbiamo deﬁnire: rewards, states, actions. 
Quali puoi ipotizzare?
6"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#6,6,"Taxi che guida da solo: reward
Per i reward possiamo ipotizzare: 
Alto reward se il cliente viene lasciato correttamente. 
Penalizzazione se il cliente viene lasciato nella location sbagliata. 
Per ogni istante di tempo trascorso, una piccola penalità.
7"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#7,7,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Quanti sono il numero dei possibili stati?
8
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#8,8,"Taxi che guida da solo: state space
Lo state space corrisponde a tutte le possibili situazioni in cui un taxi si può 
trovare. Ogni stato deve contenere abbastanza informazioni per permettere 
all'agente di decidere una azione. 
Supponiamo il taxi sia l'unico veicolo. 
Suddividiamo l'ambiente in una griglia 5x5  
Posizione corrente (3,1) 
4 location per il pick up e drop off: R,G,Y,B;  
cioè [(0,0), (0,4), (4,0), (4,3)] 
Il cliente è in Y e vuole andare in R. 
Uno stato aggiuntivo che rappresenta  
il cliente all'interno del taxi. 
Possibili stati: 5 x 5 x 5 x 4 = 500
9
"
data_test\rootfolder\università\MachineLearning\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#9,9,"Taxi che guida da solo: action space
L'agente può in ogni stato fare una delle seguenti azioni: 
muoversi a nord 
muoversi a su 
muoversi a est 
muoversi a ovest 
prendere il cliente 
lasciare il cliente 
Se l'agente non può fare una certa azione in uno stato (es. presenza di un 
muro) possiamo assegnare una penalità di -1.
10"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Reinforcement Learning (Ex 17)
1"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#1,1,"Sommario
OpenAI GYM: Ambienti  
Deep Q-learning 
Libreria Baseline3"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#10,10,"OpenAI GYM: Environments
..
env = gym.make(
 ""Qbert-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
11
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#11,11,"OpenAI GYM: Environments
12
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#12,12,"Deep Q-learning
Per ambienti complessi (es. 10K stati e 1K azioni), la Q-table associata ad 
ogni observation può risultare complessa (10M di celle). La stima di un 
certo valore a partire da quelli esplorati in passato richiede: 
molta memoria per la Q-table 
tempo necessario per esplorare tutti gli stati e ricavare i valori 
Nel Deep Q-learning usiamo una rete neurale per stimare i Q-value, dove 
in output abbiamo il valore stimato per ogni azione.
13
Q learning Deep Q learning"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#13,13,"Deep Q-learning: Temporal Difference
La rete neurale ha bisogno di un valore di loss. 
Deﬁniamo la 
 Temporal Difference:   
Q(s,a)
  è il Q-value per una certa azione a. Dopo aver eseguito l'azione avremo 
un reward R(s,a). 
 Q
t-1
(s,a)
 è il Q-value precedente . 
Idealmente le due parti devono coincidere, essendo la prima impiegata per 
ricavare la seconda, ma la casualità dell'ambiente e il tempo di apprendimento 
creano discostamenti. 
Il valore del loss è determinato dal discostamento (
 Temporal Difference target)  
dal target: Q-value - Q* 
Impiegando il learning rate alpha, usiamo la TD per ricavare il nuovo Q-value.
14
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#14,14,"Deep Q-learning
Nel Deep Q-learning l'azione da eseguire è determinata dal valore 
massimo in output dalla rete (non esiste la Q-table tradizionale). Ogni 
nodo di output è una azione possibile. 
Otteniamo un problema di regressione, senza però conoscere il valore del 
target
  (nell'equazione in verde) non essendoci Q-table. 
La nuova eq per il Q-learning diverrà: 
il brackpropagation tenderà a convergere i Q-value e i reward. 
15
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#15,15,"Deep Q-learning: Neural Fitted Q Iteration 
La rete ci restituisce i Q-value target per ogni azione.  
La loss sarà così deﬁnita: 
Nota: nel Q-learning tradizionale, il Q-value viene aggiornato ad ogni 
transizione di stato. Nel Deep Q-learning il processo è più complesso...
16
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#16,16,"Deep Q-learning: Neural Fitted Q Iteration 
La rete deve valutare sia il valore 
 predetto
  sia il 
 target
 . Per tale motivo se ne 
usano 2 con stessa architettura ma pesi distinti. 
Una rete per i valori 
 target
  con i parametri ""ﬁssi"". Ad ogni C iterazioni (es. 
100) i parametri della 
 prediction
  network (aggiornata spesso, es. ogni 4 
steps) saranno copiati nella 
 target
  network. Questo rende il training più 
stabile poiché mantiene la funzione target stabile. Approccio ""
 Neural Fitted 
Q Iteration (NFQ)
 "" 
17
La target nework stima il Temporal difference target"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#17,17,"Experience replay
Data la numerosità degli stati possibili, conviene salvarli per poi ""rigiocarci"" 
in seguito. È una 
 off-line policy
 , cioè si sfrutta l'esperienza acquisita nelle 
azioni fatte nel passato per aggiornare i parametri attuali. 
Dare in input lunghe sequenze di stati correlati (es. foto di percorsi 
autostradali rettilinei) può creare bias nella rete e non permettere di 
adattarsi in altre situazione. 
A differenza del Q-learning, durante l'esecuzione i dati [state, action, 
reward, next_state] sono salvati in un buffer chiamato 
 experience replay
 . 
Supponendo che l'ambiente sia un gioco, durante il training possiamo 
campionare periodicamente (es. ogni 4 step) in modo casuale 64 frames 
(batch) dei 100K possibili in modo che abbiano scarsa correlazione tra 
loro. Questo permette di non introdurre bias dovuti alla particolare subset 
di istanze considerate.
18"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#18,18,"Deep Q-learning: step principali
Ricava i Q-values dalla rete per ogni azione dando in input lo stato 
corrente (es. screenshot). 
Seleziona una azione con 
 epsilon-greedy policy
 , cioè random con 
probabilità 
 epsilon
 , altrimenti l'azione con Q-value massimo. 
Valuta l'azione che genera il nuovo stato 
 s'
, e ricava il reward 
corrispondente. Lo stato 
 s'
 corrisponde allo screen successivo. La 
transizione 
 <s,a,r,s’>
  è salvata nel replay buffer. 
Campiona casualmente batch di transizioni dal replay buffer e ricava la loss 
corrispondente. 
Esegui il 
 gradient descent
  con la differenza tra 
 target Q
  e 
predicted Q 
impiegando la rete e i parametri attuali minimizzando la loss. 
Ogni C iterazioni trasferisci i parametri della rete alla rete target. 
Ripeti il procedimento M episodi.
19"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#19,19,"Deep Q-learning in Python: CartPole
# codice tratto da 
 https://github.com/mswang12/minDQN/blob/main/minDQN.py
import
 gym
import
 tensorflow 
 as
 tf
import
 numpy 
as
 np
from
 tensorflow 
 import
 keras
from
 collections 
 import
 deque
import
 time
import
 random
RANDOM_SEED = 
 5
tf.random.set_seed(RANDOM_SEED)
env = gym.make(
 'CartPole-v1'
 )
env.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
print
(
""Action Space: {}""
 .
format
(env.action_space))
print
(
""State space: {}""
 .
format
(env.observation_space))
# An episode a full game
train_episodes = 
 300
test_episodes = 
 100
...
20"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#2,2,"OpenAI GYM: Environments
La classe Env implementa il simulatore dell'ambiente in cui l'agente si 
muove.  
Alcuni esempi di environment disponibili in Gym: 
import
 gym
env = gym.make(
 'MountainCar-v0'
 )
Esempio
 : nel MointainCar, un carrello deve incrementare l'inerzia per 
riuscire a passare la collina.
3
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#20,20,"Deep Q-learning in Python: CartPole
...
def 
agent
(
state_shape
 , 
action_shape
 ):
    # l'output è il Q-value stimato per ogni azione
    learning_rate = 
 0.001
    init = tf.keras.initializers.HeUniform()
    model = keras.Sequential()
    model.add(keras.layers.Dense(
 24
, input_shape=state_shape, activation=
 'relu'
, 
kernel_initializer=init))
    model.add(keras.layers.Dense(
 12
, activation=
 'relu'
, kernel_initializer=init))
    model.add(keras.layers.Dense(action_shape, activation=
 'linear'
 , 
kernel_initializer=init))
    model.
 compile
(loss=tf.keras.losses.Huber(), 
optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=[
 'accuracy'
 ])
    
return
 model
def 
get_qs
(
model
, 
state
, 
step
):
    
return
 model.predict(state.reshape([
 1
, state.shape[
 0
]]))[
0
]
...
21"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#21,21,"Deep Q-learning in Python: CartPole
...
def 
train
(
env
, 
replay_memory
 , 
model
, 
target_model
 , 
done
):
    learning_rate = 
 0.7 
# Learning rate
    discount_factor = 
 0.618
    MIN_REPLAY_SIZE = 
 1000
    
if 
len
(replay_memory) < MIN_REPLAY_SIZE:
        
 return
    batch_size = 
 64
 * 
2
    mini_batch = random.sample(replay_memory, batch_size)
    current_states = np.array([transition[
 0
] 
for
 transition 
 in
 mini_batch])
    current_qs_list = model.predict(current_states)
    new_current_states = np.array([transition[
 3
] 
for
 transition 
 in
 mini_batch])
    future_qs_list = target_model.predict(new_current_states)
    X = []
    Y = []
...
22"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#22,22,"Deep Q-learning in Python: CartPole
...
    
for
 index, (observation, action, reward, new_observation, done) 
 in 
                                       
 enumerate
 (mini_batch):
        
 if 
not
 done:
            max_future_q = reward + discount_factor * 
        np.
 max
(future_qs_list[index])
        
 else
:
            max_future_q = reward
        current_qs = current_qs_list[index]
        current_qs[action] = (
 1
 - learning_rate) * current_qs[action] + 
                 learning_rate * max_future_q
        X.append(observation)
        Y.append(current_qs)
    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=
 0
, 
        shuffle=
 True
)
 ...
23"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#23,23,"Deep Q-learning in Python: CartPole
...
def 
main
():
    epsilon = 
 1 
# inizializzato ad 1, cioè ogni azione è random
    max_epsilon = 
 1
    min_epsilon = 
 0.01 
# al valore minimo, 1% sarà ancora esplorazione
    decay = 
 0.01
    
# 1. Initializzazione Target e Main models
    
# Main Model (updated every 4 steps)
    model = agent(env.observation_space.shape, env.action_space.n)
    
# Target Model (updated every 100 steps)
    target_model = agent(env.observation_space.shape, env.action_space.n)
    target_model.set_weights(model.get_weights())
    replay_memory = deque(maxlen=
 50
_
000
)
    target_update_counter = 
 0
    
# X = states, y = actions
    X = []
    y = []
...
24"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#24,24,"Deep Q-learning in Python: CartPole
...
    steps_to_update_target_model = 
 0
    
for
 episode 
 in 
range
(train_episodes):
        total_training_rewards = 
 0
        observation = env.reset()
        done = 
 False
        
 while 
not
 done:
            steps_to_update_target_model += 
 1
            
 if True:            # Su Colab può dare problemi
            
    env.render()
            random_number = np.random.rand()
            
 # 2. Esplora con Epsilon Greedy Exploration Strategy
            
 if
 random_number <= epsilon:
                
 # Explore
                action = env.action_space.sample()
            
 else
:
                
 # Exploit best known action
                
 # model dims are (batch, env.observation_space.n)
                encoded = observation
                encoded_reshaped = encoded.reshape([
 1
, encoded.shape[
 0
]])
                predicted = model.predict(encoded_reshaped).flatten()
                action = np.argmax(predicted)
            new_observation, reward, done, info = env.step(action)
            replay_memory.append([observation, action, reward, new_observation, done])
...
25"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#25,25,"Deep Q-learning in Python: CartPole
...
           
 # 3. Aggiorna la rete con la Bellman Equation
            
 if
 steps_to_update_target_model % 
 4
 == 
0 
or
 done:
                train(env, replay_memory, model, target_model, done)
            observation = new_observation
            total_training_rewards += reward
            
 if
 done:
                
 print
(
'Total training rewards: {} after n steps = {} with final 
                      reward = {}'
 .
format
(total_training_rewards, episode, reward))
                total_training_rewards += 
 1
                
 if
 steps_to_update_target_model >= 
 100
:
                    
 print
(
'Copying main network weights to the target network 
                           weights'
 )
                    target_model.set_weights(model.get_weights())
                    steps_to_update_target_model = 
 0
                
 break
        epsilon = min_epsilon+(max_epsilon - min_epsilon)*np.exp(-decay * episode)
    env.close()
if
 __name__ == 
 '__main__'
 :
    main()
26"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#26,26,"Action Space: Discrete(2)
State space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)
Total training rewards: 19.0 after n steps = 0 with final reward = 1.0
...
Copying main network weights to the target network weights
Total training rewards: 184.0 after n steps = 291 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 152.0 after n steps = 292 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 47.0 after n steps = 293 with final reward = 1.0
Total training rewards: 20.0 after n steps = 294 with final reward = 1.0
Total training rewards: 121.0 after n steps = 295 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 10.0 after n steps = 296 with final reward = 1.0
Total training rewards: 124.0 after n steps = 297 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 272.0 after n steps = 298 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 41.0 after n steps = 299 with final reward = 1.0
Deep Q-learning in Python: CartPole
27"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#27,27,"Deep Q-learning: Stable Baseline3
Stable Baselines3 (SB3) implementa algoritmi di RL in PyTorch.  
Possono essere impiegati in OpenAI GYM. 
Github repository: 
 https://github.com/DLR-RM/stable-baselines3  
La classe DQN implementa l'approccio descritto in precedenza 
https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html   
https://stable-baselines3.readthedocs.io/en/master/guide/examples.html  
28"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#28,28,"Deep Q-learning: Stable Baseline3
Algoritmi implementati:
29
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#29,29,"Deep Q-learning: CartPole in GYM
# Anaconda: conda install -c conda-forge stable-baselines3 
!
pip install stable-baselines3[extra]
import
 gym
from
 stable_baselines3 
 import
 DQN
env = gym.make(
 ""CartPole-v0""
 )
model = DQN(
 ""MlpPolicy""
 , env, verbose=
 1
)
model.learn(total_timesteps=
 10000
, log_interval=
 4
)
model.save(
 ""dqn_cartpole""
 )
del
 model 
# remove to demonstrate saving and loading
model = DQN.load(
 ""dqn_cartpole""
 )
obs = env.reset()
while 
True
:
    action, _states = model.predict(obs, deterministic=
 True
)
    obs, reward, done, info = env.step(action)
    env.render()                 
 # Su colab può dare problemi
    
if
 done:
      obs = env.reset()
30"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#3,3,"OpenAI GYM: Environments
La variabile 
 observation_space
  deﬁnisce la struttura e gli stati permessi 
dell'ambiente.  
Per esempio, posizione  rispetto all'orgine e velocità del carrello 
CartPole, rappresentati come vettore numerico. 
Ma in casi più complessi è possibile fare un rendering dello stato (es. 
uno screenshot di un arcade) è impiegare una matrice di pixel come 
stato. 
La variabile 
 action_space
  consiste nelle azioni permesse nell'ambiente. 
Gym fornisce diverse strutture per rappresentare osservazioni e stati (es. 
discrete action space, continuous action space, ecc). 
4"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#30,30,"Deep Q-learning: CartPole in GYM
L'output dipende dall'approccio RL scelto, es. per agenti PPO - Proximal 
Policy Optimization algorithm che combina il A2C multiple workers, e 
TRPO:
31
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#31,31,"Deep Q-learning: CartPole in GYM
32
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#32,32,"Deep Q-learning: CartPole in GYM
33
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#33,33,"Deep Q-learning: CartPole in GYM
34
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#34,34,"Esercitazione
Deﬁnisci una misura di prestazioni per confrontare diverse approcci RL 
Impiega la classe Deep Q Network (DQN) 
Sperimenta diversi iperparametri e valuta le differenze: 
learning_rate 
exploration_initial_eps  e  exploration_ﬁnal_eps 
buffer_size 
batch_size 
gamma 
train_freq 
Usa altri ambienti, es: Atlantis-v0, MountainCar-v0, o ambienti Atari.
35"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#35,35,"OpenAI Gym 
 https://www.gymlibrary.ml
Testi di Riferimento
36"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#4,4,"OpenAI GYM
Come ispezionare l'ambiente. 
import
 gym
def 
query_environment
 (
name
):
    env = gym.make(name)
    spec = gym.spec(name)
    
print
(
f
""Action Space: 
 {env.action_space}
 ""
)
    
print
(
f
""Observation Space: 
 {env.observation_space}
 ""
)
    
print
(
f
""Max Episode Steps: 
 {spec.max_episode_steps}
 ""
)
    
print
(
f
""Nondeterministic: 
 {spec.nondeterministic}
 ""
)
    
print
(
f
""Reward Range: 
 {env.reward_range}
 ""
)
    
print
(
f
""Reward Threshold: 
 {spec.reward_threshold}
 ""
)
query_environment(
 ""MountainCar-v0""
 )
3 azioni: Accelerate forward, decelerate, backward
>> Action Space: Discrete(3)
2 ﬂoat: velocità e posizione; (2,) indica la struttura del dato
>> Observation Space: 
                 Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)
200 step disponibili
>> Max Episode Steps: 200
>> Nondeterministic: False
Per il reward occorre ispezionare il codice (i.e., nessun reward tranne quando il carrello riesce ad uscire)
>> Reward Range: (-inf, inf)
>> Reward Threshold: -110.0
5"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#5,5,"OpenAI GYM
query_environment(
 ""CartPole-v1""
 )
2 valori: spingi a sinistra, spingi a destra
>> Action Space: Discrete(2)
4 valori: Cart Position, Cart Velocity, Pole Angle, Pole Velocity At Tip
>> Observation Space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), 
float32)
>> Max Episode Steps: 500
>> Nondeterministic: False
reward +1 per ogni step, e termino quando il palo cade, o se mi sposto di >2.4 unità dal centro
>> Reward Range: (-inf, inf)
>> Reward Threshold: 475.0
query_environment(
 ""MountainCarContinuous-v0""
 )
1 valore: quanta forza imprimere (a sinistra o destra)
>> Action Space: Box(-1.0, 1.0, (1,), float32)
>> Observation Space: Box(-1.2000000476837158, 0.6000000238418579, (2,), 
float32)
>> Max Episode Steps: 999
>> Nondeterministic: False
>> Reward Range: (-inf, inf)
>> Reward Threshold: 90.0
6"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#6,6,"OpenAI GYM
Nell'ambiente Atari breakout, l'observation space può corrispondere alle 
dimensioni dell screen (210x160) o alla RAM dell'elaboratore (128 bytes). 
query_environment(
 ""Breakout-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (210, 160, 3), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
query_environment(
 ""Breakout-ram-v0""
 )
Action Space: Discrete(4)
Observation Space: Box(0, 255, (128,), uint8)
Max Episode Steps: 10000
Nondeterministic: False
Reward Range: (-inf, inf)
Reward Threshold: None
7
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#7,7,"OpenAI GYM: Environments
Come applicare un'azione sull'ambiente. 
# reset 
obs = env.reset()
print
(
""The initial observation is {}""
 .
format
(obs))
random_action = env.action_space.sample()
# Applichiamo l'azione all'ambiente
new_obs, reward, done, info = env.step(random_action)
print
(
""The new observation is {}""
 .
format
(new_obs))
>> OUTPUT:
>> 
The initial observation 
 is
 [
-0.48235664   
0
.]
>> 
The new observation 
 is
 [
-0.48366517  
-0.00130853
 ]
8"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#8,8,"OpenAI GYM: Environments
Per visualizzare lo stato a video su Colab inserire il seguente codice: 
# vedi 
https://github.com/ryanrudes/colabgymrender  
!
pip install gym pyvirtualdisplay > /dev/null 
 2
>&
1
!
apt-get install -y xvfb python-opengl ffmpeg > /dev/null 
 2
>&
1
!
pip install colabgymrender==
 1.0.2
import
 gym
from
 colabgymrender.recorder 
 import
 Recorder
env = gym.make(
 ""MountainCar-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
observation = env.reset()
terminal = 
 False
while 
not
 terminal:
# Azione random
  action = env.action_space.sample()
  observation, reward, terminal, info = env.step(action)
env.play()
9
"
data_test\rootfolder\università\MachineLearning\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#9,9,"OpenAI GYM: Environments
...
env = gym.make(
 ""Atlantis-v0""
 )
directory = 
 './video'
env = Recorder(env, directory)
...
10
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#0,0,"Machine Learning 
Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Esercitazione: Introduzione al Deep Learning  
(Ex 18/19)
1"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#1,1,"Sommario
Introduzione 
Il concetto di Deep Learning 
Esempi di applicazioni 
Translational simmetry 
Convolutional Neural network 
•
Convolutional layer 
•
Local receptive ﬁeld 
•
Stride e Padding 
•
Filters e Feature Maps 
•
Pooling Layer 
Architettura LeNet-5 
Architettura AlexNet 
Architettura GoogleNet e Inception Module 
Architettura Residual Network (ResNet)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#10,10,"Esercizio
Realizzo un classiﬁcatore binario che mi identiﬁca se in una 
porzione di immagine c’è un pedone. 
Scorro l’immagine per trovare una porzione con un pedone  
 
        
11
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#11,11,"Object recognition
Yolo https://pjreddie.com/darknet/yolov2/ 
https://www.youtube.com/watch?v=VOC3huqHrss 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#12,12,"Pose estimation
Zhe Cao , Tomas Simon, Shih-En Wei, Yaser Sheikh   
https://www.youtube.com/watch?v=pW6nZXeWlGM 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#13,13,"Object Tracking
 Beijing DeepGlint  https://www.youtube.com/watch?v=xhp47v5OBXQ  
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#14,14,"Activity Recognition
 MIT CS & AI Lab http://relation.csail.mit.edu
https://www.youtube.com/watch?v=JBwSk6nJOyM 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#15,15,"Tesla Self Driving Demo 2016
Tesla   https://www.youtube.com/watch?v=VG68SKoG7vE 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#16,16,"Introduzione
Alcune soﬁsticate 
 architetture ML
  sono riuscite a ottenere 
 performance superiori a 
quelle umane
  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al 
2000
  si sono ottenute
  buone performance per  
task apparentemente più semplici
 , 
come: 
•
Riconoscere un giocattolo in una immagine 
•
Speech recognition - riconoscimento vocale  
Per noi sono task semplici perché l'evoluzione ha portato il cervello a costruire 
strutture con funzioni speciﬁche.  
Quando le informazioni arrivano alle parti deputate al ragionamento ad alto 
livello, sono già arricchite di features ad alto livello elaborate da queste strutture. 
•
Sebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale 
processo abbiamo seguito per identiﬁcarlo. 
•
Le architetture 
 Convolutional Neural Networks (CNN)
  sono state sviluppate negli 
anni '80 in base agli studi della zona della corteccia deputata al riconoscimento 
visivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di 
 GPU
 .
17"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#17,17,"L'architettura della Visual cortex
Negli anni '60 
 Hubel e Wiesel
  hanno dimostrato che  
•
molti neuroni nella parte di corteccia deputata al riconoscimento di 
immagini possiedono un piccolo 
 Local receptive ﬁeld (LRF)
 , cioè possono 
reagire agli stimoli situati in regioni limitate del campo visuale. 
•
sebbene condividano il LRF, 
 alcuni neuroni si attivano 
 solo
 in presenza di 
linee orizzontali
 , 
altri 
solo 
con quelle 
 verticali
 . 
•
alcuni neuroni hanno LRF più estesi
  e 
si attivano in presenza di certe 
conﬁgurazioni di più caratteristiche a basso livello
 .  
•
si può desumere che l'attivazione di neuroni ad alto livello é basata 
sull'output di neuroni a basso-livello che sono ritenuti ""vicini"". 
Aumentando la complessità, ripetendo più volte in cascata i passi riportati, 
possiamo riconoscere 
 patterns visuali 
 anche molto 
 complessi
 . 
Nota
 : il resto della lezione suppone di considerare 
 immagini
  come istanze di 
input, ma le tecnologie introdotte possono essere usate anche per altri input.
18"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#18,18,"L'architettura della Visual cortex
19
Secondo te è una MLP?Ad ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#19,19,"L'architettura della Visual cortex
20
È simile a una MLP , 
ma ogni nodo e connesso solo  
a un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione 
nei pattern individuati
Local receptive ﬁelds"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#2,2,"Deep Learning - Cos’è?
Invece di una singola rete con molti parametri da individuare 
tutti insieme, si suddividono le elaborazione in più moduli 
distinti a cascata. 
Sviluppato negli anni ’80 (Geoff Hinton, Yann Lecun, Yoshua 
Bengio, Jürgen Schmidhuber) ispirandosi ai risultati sulla 
cognizione umana. 
Ma al tempo non c’erano le infrastrutture hardware e software 
adatte (GPU-enabled). 
Utile in scenari con grosse moli di dati complessi. 
Uno degli obiettivi è ignorare la (noiosa) fase di deﬁnizione di 
feature ad-hoc per lo speciﬁco problema da esaminare e lasciare 
alle reti neurali identiﬁcare le features più adatte.
3"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#20,20,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti?
21"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#21,21,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra 
notevolmente le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri da stimare
 .
22"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#22,22,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
1.
A causa dell'
 elevato numero di parametri da stimare  
•
Supponiamo di avere in input una piccola immagine di 100x100 pixel 
•
Creiamo un primo layer di appena 1000 nodi, che perciò ﬁltra notevolmente 
le informazioni passata ai successivi layer. 
•
Per questo primo strato abbiamo già 
 10 milioni di parametri 
 da stimare. 
2.
Supponiamo che 
 certi nodi 
 del primo strato 
 si specializzino su un certo task
 , es. 
riconoscere linee orizzontali. 
•
I neuroni specializzati sono attivati se il pattern da identiﬁcare è localizzato in 
una certa zona.  
•
Ma vorremmo poter identiﬁcare lo stesso pattern indipendentemente da dove 
compare. 
Con 
translational symmetry
  intendiamo che lo stesso output deve essere 
prodotto anche a seguito di operazioni di traslazione sulla istanza in input. 
23"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#23,23,"MLP - fully connected
Perché non usiamo una NN MLP per riconoscere gli oggetti? 
3. Le reti 
 MLP 
non riescono a codiﬁcare esplicitamente l'organizzazione 
spaziale delle features
 . 
•
Nel Visual cortex i neuroni degli strati più vicini all'input identiﬁcano 
features analizzando piccole aree dell'immagine. 
•
I neuroni ""ad alto livello"" combinano tali features per identiﬁcare features 
spazialmente più estese.
24"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#24,24,"Esempi di 
 translational simmetry
25
Nel task a lato, per addestrare una MLP dovremmo avere 
un training set con: 
•stessa specie animale che compare in varie 
posizioni, angolazioni e dimensioni. 
•specie visualizzate parzialmente (es. sul bordo). 
•casi di overlap tra specie diverse di animali"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#25,25,"Ulteriore considerazione: 
 sparsity
26Per riconoscere certe caratteristiche speciﬁche analizziamo informazioni ""locali"" o ravvicinate, cioè con una 
distanza relativa limitata. Non c'è bisogno di considerare l'intera immagine iniziale. 
Un output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#26,26,"Convolutional NN
Le architetture 
 Convolutional NN (CNN)
  consistono in varie tecniche 
ispirate al funzionalmente del cervello.  
Il blocco più importante è il 
 convolutional layer
  così costituito: 
•
I nodi nel primo layer 
 non sono connessi con tutti i pixel
  dell'immagine in 
input, ma 
 solo in una regione
  (es. un rettangolo). Tale regione è chiamata 
Local receptive ﬁeld (LRF)
 . 
•
Questo permette alla rete di 
 specializzarsi
  su caratteristiche a basso 
livello che saranno poi elaborate in caratteristiche a più alto livello nei 
successivi hidden layer. 
•
Una rete CNN è 
 gerarchica
 , con più convolutional layer nascosti che 
individuano via via caratteristiche più astratte.
27"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#27,27,"CNN - Convolutional layer e LRF
28
nodo
input per il successivo hidden layer
25x2521x21
Esempio di input: 
immagine 25x25 pixel
in bianco e neroOutput dopo il primo  
layer convolutivo.local receptive ﬁeldOgni nodo è attivato in base 
all'input determinato 
da una certa posizione del 
LRF che scorre lungo l'input.input
Convolutional layer
notiamo la riduzione della  
dimensione rispetto all'inputmatrice delle attivazioni
elaborazione"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#28,28,"CNN - Struttura gerarchica
29Input layer: 
È un layer costituito da unità 
a cui viene associato il valore 
dei singoli pixel dell'immagine.  
Non c'è reale elaborazione.Primo convolutional layer
Secondo convolutional layerDato una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base 
alle features estratte da una certa zona dell'input. Astrazione delle features
Nota: Nelle tradizionali MLP, input bidimensionali [N, M] (es. immagini in bianco e nero) sono 
comunemente ridimensionati a vettori, ovvero matrici di dimensioni [NxM, 1].  
Nelle CNN tale ridimensionamento è controproducente poiché si perderebbe l'informazione relativa alla 
vicinanza delle features in input. Struttura gerarchica
 Nell'input layer le features 
corrispondono ai singoli pixel"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#29,29,"CNN - LRF
30Output layer precedente•In un certo layer convoluzionale, un nodo con indice (i, j) prende in input gli output dei nodi 
del layer precedente posizionati all'interno del LRF .
•la regione LRF va dalla riga i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1
•fh e f w corrispondono all'altezza e larghezza del LRF. 
•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1
Il convolutional layer è 
rappresentato da una 
griglia bidimensionale 
che contiene il risultato 
delle attivazioni.forward propagation
Esempio con LRF 3x3 
con stride pari a 1.<------ padding ------>
<------ padding ------><------ dim x ------>
<--- dimy -->
Padding 
(discusso più avanti)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#3,3,"Deep Learning - Cos’è? (2)
In estrema sintesi: 
Si compongono più strutture di reti neurali in cascata il cui 
scopo è analizzare l’input ed estrarre ad ogni passo un 
insieme di features (in automatico). 
L’output di una rete neurale è l’input della successiva. 
Tipicamente l’input iniziale è low-level (es. gruppi di pixel di 
una immagine) e ogni rete genera rappresentazioni più ad 
alto livello (es. contorno viso, bocca, bocca sorridente etc.). 
Le elaborazioni degli strati intermedi sono tipicamente 
unsupervised.
4"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#30,30,"CNN - Stride
31•La distanza s tra due LRF adiacenti è chiamata stride. 
•Finora abbiamo visto stride di 1 pixel, ma la LRF può scorrere di più pixel. 
Output layer precedenteLayer convoluzionale
<------ padding ------>
<------ padding ------>
LRF di 3x3 
Stride = 2"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#31,31,"CNN: Padding
32•Supponendo stride > 1, può accadere che il convolutional layer (comunque ridotto di fw-1 e 
fh-1 a causa del LRF) non abbia le stesse dimensioni del layer precedente poiché la LRF non 
può scorrere l'intera instanza in input. 
•Il padding aggiunge dimensioni ai dati in input. Normalmente i dati inseriti sono valori nulli 
(0-padding). Si hanno i seguenti vantaggi:
•Permettere alla LRF di scorrere per intero l'immagine in input senza ignorarne delle parti.
•Un LRF potrebbe ""imparare"" a riconosce una certa feature quando è centrata 
nell'immagine. Se la feature è posizionata molto vicino al bordo, senza padding potrebbe 
essere ignorata.
0-padding
✓LRF
Output layer precedente senza padding Output layer precedente con padding"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#32,32,"CNN - Esempio di attivazione di un nodo 
L'attivazione di un nodo in un layer convoluzionale si ottiene 
analizzando l’output dal layer precedente per mezzo del 
 LRF
. 
Esempio: la funzione d’attivazione (
 σ
) per il nodo <
 l
,
k
> si valuta 
considerando il bias 
 b
 e la matrice 
 W
 di dimensione 
 f
h  
f
w 
associati al 
LRF, in questo caso pari a 3
 3. 
 
W
 e 
b
 sono i parametri da determinare.  
i
 e 
j
 sono gli offset riferiti al 
 LRF
. 
Se la ﬁnestra scorre un passo alla volta allora 
 l
 e 
k
 fanno riferimento 
all’origine della ﬁnestra del 
 LRF
.
×
×
σ
(
b
+
2
∑
i
=
0
2
∑
j
=
0
w
i
,
j
⋅
x
i
+
l
,
j
+
k
)
ijlk
LRF"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#33,33,"CNN: Riduzione dimensionalità e Stride
34Output layer precedente•La presenza di stride > 1 altera gli indici iniziali e ﬁnali che identiﬁcato il LRF associato ad 
un certo nodo. 
•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei 
nodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  
j × s w  a  j × s w + f w - 1.
•Per s pari a 1, si torna alla formulazione già vista.
•Stride > 1 riducono la dimensione del layer convoluzionale a scapito della precisione.
Layer convoluzionale
<------ padding ------>
<------ padding ------>stride verticale
stride orizzontaleLRF di 3x3 
Stride = 2"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#34,34,"CNN: Filters
35Filters•Supponiamo di poter rappresentare graﬁcamente i pesi associati a un certo nodo, usati per 
il calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters o convolution kernels  
(o kernels )
•Ad esempio, una LRF 7 7 corrisponderà ad un ﬁltro con medesime dimensioni. ×
Nell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, 
tranne una colonna di 1 e una riga di 1, rispettivamente.
Input"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#35,35,"Esempi di ﬁltri e attivazioni (1)
36Esempio di input 
immagine 25x25 pixel
Output dopo il primo  
layer convolutivo.
Immagine in input
Immagine in inputOutput
OutputFiltro
FiltroAttivazioni
Attivazioni"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#36,36,"Esempi di ﬁltri e attivazioni (2)
http://brohrer.github.io/how_convolutional_neural_networks_work.html
1-1-1
-11-1
-1-11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33
-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11
0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55
0.33 0.33 -0.33 0.55 -0.33 0.33 0.33
0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11
-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11
0.33 -0.11 0.55 0.33 0.11 -0.11 0.77
-1-11
-11-1
1-1-11-11
-11-1
1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11
0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11
-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55
0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=
=-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1
-11-1-1-1-1-11-1
-1-11-1-1-11-1-1
-1-1-11-11-1-1-1
-1-1-1-11-1-1-1-1
-1-1-11-11-1-1-1
-1-11-1-1-11-1-1
-11-1-1-1-1-11-1
-1-1-1-1-1-1-1-1-1ﬁltroattivazioni
ﬁltro
ﬁltro"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#37,37,"CNN: Feature Maps
38Filters•Le LRF scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del 
ﬁltro usato per il calcolo dell'attivazione. Tale approccio prende il nome di shared weights. 
•L'insieme delle attivazioni ottenute con lo stesso ﬁltro viene chiamato feature map. Esse 
possono essere visualizzate come una immagine.
Nell'esempio si nota che il Vertical ﬁlter crea una feature map dove le zone dell'input simili a una 
linea verticale sono più evidenziate (cioè più attivazione), mentre le zone  meno simili saranno 
più scure e sfocate. Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps
Input"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#38,38,"CNN: Stacking feature maps
In 
ogni layer
  possiamo contemplare 
 più ﬁltri con le medesime dimensioni
 . 
Ogni ﬁltro produrrà una diversa feature map. Ogni layer sarà così costituito 
da una sequenza di matrici di attivazioni, perciò una 
 struttura 3d
 . 
Durante il 
 forward propagation
  è fondamentale che i ﬁltri, cioè i parametri 
pesi
 e 
bias
 che costituiscono il layer convoluzionale, rimangano costanti, 
sebbene il valore delle attivazioni, ovvero la 
 feature map
 , cambiano in base 
alla posizione del 
 LRF
. Questo permette di: 
•
Avere un numero molto minore di parametri da stimare rispetto a un layer 
MLP. 
•
Durante la backpropagation, adattare ogni ﬁltro ad una particolare 
caratteristica saliente.  
•
La possibilità di usare lo stesso ﬁltro in diverse zone dell'immagine garantisce la 
translational simmetry
 , cioè possiamo riconoscere la caratteristica in diverse 
posizioni. Una rete Fully connected (
 FC
) potrebbe riconoscere una caratteristica 
in una posizione stimando certi parametri, ma non sarebbe in grado di 
riutilizzarli in altre posizioni.
39"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#39,39,"CNN: Feature Maps
40...Input
Convolutional layer 2
Convolutional layer 1
Una immagine a colori con 3 matrici 
associate ai canali RGB.Possiamo deﬁnire un certo numero di ﬁltri (es. 12) per riconoscere diverse caratteristiche salienti dell'immagine iniziale. I ﬁltri analizzano contemporaneamente 3 canali RGB, perciò i ﬁltri saranno deﬁniti con matrici a 3 dimensioni. Un ﬁltro applicato all'immagine in input produce un singolo convolutional layer.I successivi layer convoluzionali analizzato le attivazioni di più ﬁltri contemporaneamente. I ﬁltri di questo layer riconosceranno caratteristiche più astratte.depth = 3 depth = 12 depth = 7"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#4,4,"Deep Learning - Principali vantaggi
Rispetto ad altri approcci: 
Si può sviluppare un unico framework computazionale che 
può essere implementato ed eseguito su varie piattaforme 
hardware e cloud. 
Il framework offre funzionalità valide per molte architetture di 
reti e tasks (es. natural language processing, computer vision, 
speech recognition, etc.) 
Si possono condividere e riutilizzare i parametri ottenuti 
durante l’apprendimento per uno speciﬁco task in altri 
contesti.
5"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#40,40,"TensorFlow: Padding
TensorFlow fornisce il parametro 
 padding
  che può assumere due valori: 
•
""
VALID
 "" nel caso in cui si voglia ignorare il padding  
•
""
SAME
 "" per aggiungere automaticamente righe e colonne composte da 
valori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice 
in input.
4101234567891011121300 12345678910111213
senza padding ('VALID') con padding ('SAME')ignorati
stride=5padding P=+3"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#41,41,"Tuning delle CNN
Rispetto a una MLP abbiamo 
 molti più iperparametri da stimare
 : 
Numero di ﬁltri per layer (o 
 depth
 ) 
Dimensione del LRF 
Stride e padding 
Invece di usare tecniche automatiche per il tuning,
  ci si ispira ad 
architetture già studiate 
 in letteratura per avere una conﬁgurazione 
verosimilmente già ottimizzata.
42"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#42,42,"Risorse di memoria: considerazioni
La backpropagation richiede di memorizzare tutti i valor intermedi calcolati 
durante la forward propagation
 . 
•
Ad esempio, 
 convolutional layer 
 con ﬁltri 5
 5 e con 200 feature maps di 
dimensione 150
 100 con stride 1 e padding SAME: se in input abbiamo 
immagini RGB 150
 100, il numero di 
 parametri
  è (5
 5
3+1)
 200 = 
 15.200 
•
Nella 
 MLP
, un layer 150
 100 completamente connesso col layer in input 
richiederebbe 150
 100
 150
 100
 3 = 
67.5M di parametri
 . 
•
Ognuna delle 200 mappe contiene 150
 100 nodi, ed ogni nodo ricava 
l'attivazione valutando 5
 5
3 input, che corrispondono a 
 225 milioni di 
moltiplicazioni
  in virgola mobile. 
•
Con ﬂoat di 
 32bit
  il layer di output impiega 200
 150
 100
 32 = 
 11.5Mb 
circa
  per ogni istanza. Per 100 istanze il layer occuperebbe più di un 
 1Gb
. 
In produzione, le attivazioni di un layer possono essere dimenticate appena i 
calcoli sul layer successivo sono terminati, richiedendo molta meno memoria 
(cioè al massimo quella di 2 layer contemporaneamente). 
×
×
×
 ×
×
 ×
×
×
 ×
 ×
 ×
×
×
×
×
 ×
 ×
43"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#43,43,"Pooling layer (1)
I 
layer di pooling 
 ha lo scopo di 
 ridurre il numero di parametri 
 operando un 
campionamento
  (o 
down-sampling
 ) dei dati. I vantaggi sono i seguenti: 
•
Meno complessità computazione 
•
Meno risorse di memoria 
•
Meno parametri (e ridurre l'overﬁtting come effetto collaterale) 
Come nel convolutional layer, 
 ogni nodo è connesso con un numero limitato di 
nodi del layer precedente 
 posizionati in un certo LRF. 
•
Occorre deﬁnire dimensione, stride e padding 
Il 
pooling layer non ha parametri.
  Opera semplicemente una ""
 aggregazione
 "" dei 
valori associati ai nodi, ad esempio calcolando 
 media
  o 
valore massimo
 . 
Spesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta 
rispetto all'intera profondità del layer precedente (es. sul canale R, G e B 
separatamente).  
•
La profondità (numero di layer) in uscita corrisponderà a quella che si ha in 
ingresso. 
44"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#44,44,"Pooling layer (2)
Non ha parametri da inferire
 , ma solo iperparametri, cioè dimensione del 
ﬁeld (
 pooling size
 ), il 
pooling stride
 , e tipo di aggregazione. 
•
Spesso pooling size e stride corrispondono. 
In molti scenari 
 non è fondamentale la posizione esatta di una certa 
caratteristica
 , ma il fatto che esista in una certa zona, o che sia identiﬁcata 
una certa sequenza (o pattern) di features senza considerare esattamente le 
rispettive distanze reciproche. 
•
Ad esempio, nella face detection ho interesse a riconoscere due occhi 
vicini, ma non mi interessa la distanza esatta. 
Esistono 
 due tipi principali di aggregazione
 : 
•
max-pooling:  
un nodo assume l’attivazione massima tra i valori presenti 
nel ﬁeld considerato. 
•
average pooling:
  considero il valor medio nel ﬁeld.
45"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#45,45,"Esempio: Pooling layer
Nell'esempio il pooling kernel è di 2
 2, lo stride pari a 2, padding VALID e 
aggregazione max. 
•
Il layer di output contiene il 75% in meno dei valori del layer precedente.
×
46
A causa del padding VALID 
il valore di alcuni nodi sarà ignorato.
Se in input abbiamo un canale con un layer NN,  f po è il pooling size, s po il pooling stride,  
 
una dimensione del layer di output è:  ×
N−fpo
spo+1"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#46,46,"CNN: Convolutional layer e dimensione output
La dimensione dell'output di un 
 convolutional layer
  si ricava a 
partire dalla dimensione dell'input e dal valore degli iperparametri. 
Se per semplicità assumiamo input 
 N
N
, e la dimensione del 
 LRF 
 
f
h
 = f
 w
 = 
f
, lo stride 
 s,
 e le righe (o colonne) 
 p
 aggiunte come 
padding, allora una delle due dimensione del layer di output è la 
seguente: 
 
La dimensione in output perciò corrisponde a 
 O
O.
×
O
=
N
−
f
+
p
s
+
1
×"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#47,47,"AlexNet
  (2012) è una delle prime architetture di reti neurali che combina CNN e 
GPU nell'ambito della classiﬁcazione degli oggetti.
Esempio: calcolo parametri AlexNetoutput depth = 96input depth = 3
Ricordiamoci  che il local receptive ﬁeld  
ha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer 
hidden: 
•Dim. immagine in Input = 227 227 3 
•Dim. LRF = 11 11 
•Stride = 4; padding VALID 
•Numero ﬁltri (o depth) = 96 
•L’output per ogni ﬁltro avrà dimensione di lato (227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. 
•Considerando la profondità si ha: 55x55x96 =290.400 nodi. 
•L'attivazione di un nodo si ricava considerando 11x11x3 nodi del layer precedente.  
•In una MLP si avrebbero 105.415.200 parametri. 
•Per la proprietà degli shared weights, nella CNN il numero di parametri sarà 11x11x3x96 + 96 = 34.944. × ×
×
×
feature mapscomputazione"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#48,48,"Architettura LeNet-5 per OCR
LeNet-5
  (1989) è una delle prime architetture CNN.  
•
E' stata ideata per fare OCR garantendo un errore <1% su MNIST. 
Combina layers 
 CNN
  con una rete tradizionale 
 MLP
 a valle.  
•
Lo scopo è di impiegare le caratteristiche salienti identiﬁcate dalle CNN 
per fare classiﬁcazione per mezzo della MLP. 
•
Una rete interamente 
 MLP fully connected avrebbe richiesto molti più 
parametri
  per ottenere le stesse prestazioni."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#49,49,"Demo LeNet-5
da http://yann.lecun.com/exdb/lenet/ "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#5,5,"DeepMind e Atari Breakout
Google Deepminds https://deepmind.com 
https://www.youtube.com/watch?v=eG1Ed8PTJ18 "
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#50,50,"Architettura LeNet-5
convolutional layer#1 conv. layer
feature maps:  
28x28, depth 6#3 conv. layer 
feature maps: 
10x10, depth 16
avg.  
poolingconv. layeravg.  
pooling#2 pooling layer
feature maps: 
14x14, depth 6#4 pooling layer
feature maps: 
5x5, depth 16
conv. layer#6 fully connected layer 
nodi 84#5 conv. layer 
feature maps:  
1x1, depth 120
Immagini  
32x32x1 (gray scale)LRF
L'output dell'ultimo 
convolution layer è 
convertito in un vettore 
120x1, adatto come input di 
un fully connected layer.
La ReLU non era ancora 
stata approfondita ai tempi di 
LeNet-5. Si è impiegata la 
più tradizionale tanh.#7 fully connected layer 
nodi 10
La conﬁgurazione degli 
iperparametri e la dimensione 
dell'input non necessita di 
impiegare il padding."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#51,51,"LeNet-5 in Keras
Con Keras l'implementazione di LeNet-5 per il dataset MNIST è rapida poiché i 
layer di pooling e di convoluzione sono già fatti:  
model = keras.Sequential()
model.add(layers.Conv2D(filters=
 6
, kernel_size=(
 3
, 
3
), activation=
 'relu'
, 
                     input_shape=(
 32
,
32
,
1
)))
model.add(layers.AveragePooling2D())
model.add(layers.Conv2D(filters=
 16
, kernel_size=(
 3
, 
3
), activation=
 'relu'
))
model.add(layers.AveragePooling2D())
# cambio il formato da matrice a vettore
model.add(layers.Flatten())
# layer fully connected o denso
model.add(layers.Dense(units=
 120
, activation=
 'relu'
))
model.add(layers.Dense(units=
 84
, activation=
 'relu'
))
model.add(layers.Dense(units=
 10
, activation = 
 'softmax'
 ))"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#52,52,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema?
53"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#53,53,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 .
54"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#54,54,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere.
55"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#55,55,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 .
56"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#56,56,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32.
57"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#57,57,"CNN - Esercizio
Se le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le 
5 cose che puoi fare per risolvere il problema? 
1.
Ridurre la 
 dimensione del mini-batch
 . 
2.
Ridurre la 
 dimensionalità nella rete
 , ad esempio con stride > 1 in uno o più 
layers, o con pooling layers. 
•
Anche un convolutional layer riduce la dimensione del layer precedente ma, a 
differena del pooling layer, introduce ulteriori parametri da apprendere. 
3.
Cambiare l'architettura 
 rimuovendo un layer
 . 
4.
Usare rappresentazioni
  ﬂoat a 16
  bit invece che 32. 
5.
Distribuire la computazione
  su più elaboratori.
58"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#58,58,"Architettura AlexNet
Architettura CNN vincitrice della challenge object detection ILSVRC 2012 con un 
top-5 error del 17% (il secondo ha ottenuto 26%).  
E' molto simile a 
 LeNet-5
  ma con più profondità, con stacking dei pooling layer 
uno dopo l'altro (senza strato di pooling). 
•
Primo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti 
complesse.
Dopo i 5 convolutional 
layers (11x11, 5x5 e 3x3) 
c'è il max pooling, e una 
rete FC da 3 layer. 
Impiega ReLI, SGD e 
momentum. 
 
La doppia pipeline è 
dovuta all’hardware 
impiegato per 
l’addestramento (2 gpu)"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#59,59,"Architettura AlexNet (2)
Impiega 
 dropout
  sugli strati FC, e 
 data augumentation
 . Nei layer C1 e C3 impiega 
la 
Local response normalization:
  se un nodo riceve una attivazione signiﬁcativa, 
si inibiscono i nodi nella stessa posizione ma in altre feature maps.  
•
L'ipotesi è quella di favorire la competitività, specializzando ogni feature map su 
caratteristiche distinte.
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#6,6,"Robot Learns to Flip Pancakes
Petar Kormushev (IIT): https://www.youtube.com/watch?v=W_gxLKSsSIE 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#60,60,"CNN: Alcune problematiche 
Nei seguenti esempi riconosciamo un cane, ma la posizione e 
dimensione dell’animale sono molto diverse tra loro.  
•
Non è facile determinare la giusta dimensione (e il numero) dei 
ﬁltri negli strati iniziali. 
E nonostante le tecnologie di apprendimento introdotte, in 
architetture molto deep (con molti strati) può sempre riproporsi il 
vanishing gradient problem
 . 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#61,61,"CNN: Inception module (GoogleNet)
L'
inception module
  si basa sulla ipotesi che 
 combinare
  le 
informazioni provenienti da diverse pipeline di processamento basate 
convolutional layer permetta di estendere le caratteristiche salienti 
identiﬁcate. 
•
Più convolution layer in parallelo
 , ognuno con una 
 diversa 
dimensione dei ﬁltri
 . Gli output dei convolution layers sono 
""combinati"" in una singola struttura che consisterà nell'input per il 
layer successivo. 
•
Si impiegano ﬁltri con dimensioni pari a 
 1x1
, 
3x3
 e 
5x5
, tutti con 
stride 1
 , 
SAME
  padding e 
 ReLU
  activation function. 
In pratica si processa lo stesso input contemporaneamente 
considerando più dimensioni di LRF.  
L'inception module è stato impiegato per la prima volta 
nell'architettura 
 GoogleLeNet
 ."
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#62,62,"Inception module
L'input è dato contemporaneamente a 
 3 convolution layers
  e un 
 3x3 
max pooling
 .  
•
Le 
1x1 convolution 
 ""
comprimono
 "" la profondità dell'input, utili 
soprattutto per 
 sempliﬁcare i dati in input 
 alle convoluzioni 3x3 e 
5x5 che richiedono risorse computazionali. 
•
La combinazione 
 1x1+3x3
  e 
1x1+5x5
  hanno più possibilità di 
rappresentare 
 feature più complesse 
 rispetto ai singoli 3x3 e 5x5. 
•
Sperimentalmente si nota come gli inception module sono più 
efﬁcienti se usati negli higher layers. 
Inception module
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#63,63,"Architettura GoogLeNet v1
L’architettura vincitrice della object detection challenge ILSRC 2014 
raggiungendo un top-5 error < 7%.  
La principale caratteristica è la profondità: 
 22 layer
  (27 considerando anche i 
pooling layers) con 9 
 inception module
  in cascata.  
•
Dopo ogni 
 inception module
  si opera una average pooling per ridurre il 
numero di parametri. 
•
Sebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni 
circa)
Altre tecniche impiegate: batch 
normalization, image distortions e RMSprop?? inception module"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#64,64,"Architettura GoogLeNet v1 (2)
L’
output di due inception module intermedi (3º e 6º inception module) è valutato 
preliminarmente nel task della classiﬁcazione 
 per mezzo di una softmax. 
Si affrontare il problema del 
 vanishing gradient problem
 , dato che si generano 
gradienti addizionali negli hidden layer lontani dall'ultimo layer. 
Il valore della loss intermedia è chiamato 
 auxiliary loss
 . Durante il training 
viene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  
In produzione e nel test set non vengono impiegati. 
Nota
 : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per 
rendere più efﬁciente il training e migliorare l’accuracy.
auxiliary classiﬁerauxiliary classiﬁer"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#65,65,"GoogLeNet: esempio di ﬁltri
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#66,66,"Architettura Residual Network (ResNet)
ResNet
  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers. 
Una rete con tale profondità non potrebbe essere addestrata a causa del 
vanishing gradient problem. 
Si introducono le 
 skip connections
 , che propagano l'output di un certo layer 
nell'input di un layer che è posizionato più a valle.   
•
L'ipotesi è di rendere 
 più semplice propagare segnali 
 su varie parti della rete. 
•
Nelle fasi iniziali (comportamento random) si obbliga parti della rete ad 
comportarsi in modo da riproporre i valori in input, rendendo 
 più veloce 
l'apprendimento
 .
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#67,67,"ResNet: Residual learning
Addestrare una rete neurale può essere interpretato come approssimare una 
funzione h(
 x
). Se aggiungi un valore x all'output della rete, allora la rete è 
obbligata a modellare la funzione f(
 x
) = h(
 x
) - 
x
. Tale approccio è chiamato 
residual learning
 . 
Dal punto di vista operativo, è sufﬁciente combinare l'output di un layer con 
l'output di un layer posizionato più a monte prima di valutare la funzione di 
attivazione (ReLU).
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#68,68,"Architetture CNN
Principali architetture CNN per le immagini, complessità, numero di operazioni 
richieste per l'addestramento e accuratezza. 
69
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#7,7,"Chess Game
Stati possibili: ~1047
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#8,8,"Driverless cars
Stati possibili: ?Microsoft AirSim simulator 
https://www.youtube.com/watch?v=fv-oFP AqSZ4 
"
data_test\rootfolder\università\MachineLearning\44-Ex18 Intro DL-sbloccato.pdf#9,9,"Esercizio
Voglio sapere se c’è un pedone di fronte a me analizzando 
l’immagine di una camera dalla mia auto, come procedo? 
10
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Ridge Regression 
Cross Validation
Machine Learning "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#1,1,"Sommario
Overﬁtting nella polynomial  regression 
Sintomi dell’Overﬁtting 
Funzione di Costo nella Ridge Regression 
Minimizzazione della Funzione di Costo 
Forma Chiusa 
Gradient Descent 
K-fold Cross Validation
 
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#10,10,"Overﬁtting e #input
 
11
Anche il numero di input inﬂuenza l’overﬁtting: 
1 input (e.g., sq.ft)  → per evitare l’overﬁtting servono 
osservazioni che sono molto “dense” sull’asse delle ascisse. 
Servono in sostanza osservazioni rappresentative di tutte le 
coppie (x, y), cosa  difﬁcile da ottenere.  
d input (e.g., sq.ft, #bagni, #camere-letto, anno di costruzione, 
ecc.) → è ancora  più difﬁcile avere molte osservazioni 
rappresentative delle coppie (x, y) .
AreaPrezzoy
x"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#11,11,"Funzione di Costo 
nella Ridge Regression
 
12
L’idea alla base della Ridge Regression è quella di limitare 
il valore assoluto dei coefﬁcienti wi deﬁnendo come 
segue la funzione di costo totale (da minimizzare nella 
fase di training): 
costo_ridge  = misura del “ﬁt” + misura della grandezza dei coefﬁcienti
Per misura del “ﬁt” intendiamo una funzione come la RSS. 
La misura dei coefﬁcienti possiamo deﬁnirla in vari modi. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#12,12,"Misura dei Coefﬁcienti  
di Regressione
 
13
Somma dei valori:                                                  
Somma dei valori assoluti ( L1 norm ): 
Somma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD
|w0|+|w1|+|w2|+···+|wD|=DX
j=0|wj|,kwk1
👍
👎
👍
w2
0+w2
1+w2
2+···+w2
D=DX
j=0w2
j,kwk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#13,13,"Funzione di Costo 
nella Ridge Regression
 
14
La Ridge Regression usa la somma dei quadrati ( L2 
Regularization ). 
La funzione che rappresenta il costo totale nella Ridge è 
dunque la seguente:    
dove il parametro λ (tuning parameter ) serve per 
bilanciare i due termini.                                              costo ridge(w)=R S S ( w)+ ·kwk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#14,14," 
15Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵ = 0 
Se 0 < λ < ∞: 
Funzione di Costo 
nella Ridge Regression
0kˆwk2
2kˆwLSk2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#15,15,"Bias-Variance tradeoff
 
16
Parametro λ elevato: 
high bias, low variance  (e.g., ŵ = 0 per λ = ∞) 
Parametro λ piccolo: 
low bias, high variance  (e.g., standard least squares ﬁt 
per polinomi di grado elevato) "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#16,16,"Esempio di polynomial ﬁt 
rivisitato
 
17
Rivediamo ora la demo relativa al polinomio di grado 16, 
applicando però l’approccio della Ridge Regression con 
diversi valori del parametro λ. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#17,17,"Polinomio di grado 16 
lambda = 1.00e-25
 
18
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#18,18,"Polinomio di grado 16 
lambda = 1.00e-10
 
19
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#19,19,"Polinomio di grado 16 
lambda = 1.00e-06
 
20
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#2,2,"Il problema dell’Overﬁtting 
nella polynomial regression
 
3
Ricordiamo il nostro modello nella polynomial  
regression:
A seconda del grado del polinomio possiamo avere 
diverse situazioni:
overﬁt
yi=w0+w1xi+w2x2
i+···+wpxp
i+✏i
y
Area xPrezzo
AreaPrezzoy
x"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#20,20,"Polinomio di grado 16 
lambda = 1.00e-03 
 
21
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#21,21,"Polinomio di grado 16 
lambda = 1.00e+02
 
22
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#22,22," 
23costo ridge(w)=R S S ( w)+ ·kwk2
2=(y  w)T(y  w)+ ·wTw
kwk2
2=w2
0+w2
1+w2
2+···+w2
D=wT·w
Gradiente della Funzione di Costo 
Per il calcolo del gradiente della funzione di costo, 
riscriviamo tale funzione in notazione matriciale:
poiché:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#23,23,"Gradiente della Funzione di Costo 
 
24rcosto ridge(w)= r[(y  w)T(y  w)+ ·wTw]=
=r[(y  w)T(y  w)] + ·r[wTw]=
= 2 T(y  w)+ ·2w
Il gradiente della funzione è il seguente:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#24,24,"Algoritmi per adattare il modello 
[caso della Ridge Regression]
Anche nel caso della Ridge Regression, una volta calcolato 
il gradiente della funzione 
 costo_ridge
  ci sono due possibili 
approcci per minimizzare la funzione di costo: 
“
Forma chiusa
 ”: Si uguaglia il gradiente a zero e si risolvono le equazioni 
(non sempre è possibile o conveniente dal punto di vista computazionale) 
Algoritmo di Discesa del Gradiente (
 Gradient Descent
 ) (richiede la 
deﬁnizione del criterio di convergenza e dello “step size”)
 
25"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#25,25,"Forma Chiusa 
[caso della Ridge Regression] 
 
26Poniamo il gradiente uguale a zero:
rcosto ridge( w)= 2 T(y  w)+2 · w=0
 2 Ty+2 T ˆw+2 · ˆw=0
  Ty+ T ˆw+ Iˆ w =0
 T ˆw+ Iˆ w = Ty
( T + I)ˆw= Ty
( T + I) 1( T + I)ˆw=( T + I) 1 Ty
Iˆ w =( T + I) 1 Ty
ˆwridge=( T + I) 1 Tyda cui si ha:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#26,26,"Gradient Descent (1/4) 
[caso della Ridge Regression] 
 
27w(t+1) w(t) ↵·rcosto ridge(w(t))
w(t+1)
0 w(t)
0 ↵·@costo ridge(w(t))
@w0
w(t+1)
1 w(t)
1 ↵·@costo ridge(w(t))
@w1
······ ·····················
w(t+1)
j w(t)
j ↵·@costo ridge(w(t))
@wj
······ ·····················
w(t+1)
D w(t)
D ↵·@costo ridge(w(t))
@wD
I singoli pesi devono pertanto essere aggiornati come segue:
Dobbiamo aggiornare il vettore dei pesi in modo tale da 
spostarci nel verso opposto al gradiente:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#27,27,"Gradient Descent (2/4) 
[caso della Ridge Regression] 
 
28@costo ridge(w(t))
@wj=@RSS(w(t))
@wj+ ·@(w(t)T·w(t))
@wjcosto ridge(w)=R S S ( w)+ ·kwk2
2=R S S ( w)+ ·wTw
Per il calcolo delle derivate parziali precedenti, consideriamo 
di nuovo l’espressione della funzione costo_ridge:
La derivata parziale della funzione di costo rispetto al 
generico peso w j è dunque:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#28,28,"Gradient Descent (3/4) 
[caso della Ridge Regression] 
 
29@RSS(w(t))
@wj= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
@(w(t)T·w(t))
@wj=2 ·w(t)
j
Poiché:
abbiamo:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#29,29,"Gradient Descent (4/4) 
[caso della Ridge Regression] 
 
30
L’aggiornamento del generico peso w j:
diventa:
ossia:"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#3,3,"Sintomi dell’Overﬁtting
 
4
Spesso, quando il fenomeno dell’overﬁtting si manifesta, 
accade che i valori assoluti dei parametri stimati ŵ 
assumono valori molto alti. 
Vediamo ora una semplice demo in cui si mostra questo 
fenomeno."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#30,30,"Algoritmo di Gradient Descent 
[caso della Ridge Regression] 
 
31w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
w(t+1)
j (1 2↵ )w(t)
j ↵⇤derivata parziale RSS[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#31,31,"Andamento Coefﬁcienti 
Ridge
 
32
λ "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#32,32," 
33
Selezione dei parametri  
via Cross Validation 
Un problema importante è quello relativo alla scelta del 
parametro λ. Lo affrontiamo per la Ridge, ma le 
considerazioni sono più generali. 
Come è stato detto in precedenza, per ogni valore di λ che 
vogliamo considerare possiamo addestrare il nostro modello 
sui dati di training, valutarlo sul validation set e scegliere il 
valore di λ che ottiene i migliori risultati (validation error più 
basso). 
Possiamo poi valutare le prestazioni del modello selezionato 
sul test set."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#33,33,"Tutto ciò è certamente possibile, a patto di avere un numero 
sufﬁciente di dati:
 
34
Training 
SetTest 
Set
Validation
 Set
ﬁt ŵλ 
test prestazioni di ŵλ  
per selezionare λ* 
valutare il  
true error di ŵλ*  
Selezione dei parametri  
via Cross Validation "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#34,34,"La domanda che dobbiamo porci è però la seguente: cosa 
accade se non abbiamo dati sufﬁcienti per dividerli nei tre 
sottoinsiemi necessari? 
 
35
Dati disponibili
Resto dei dati Test 
Set
Selezione dei parametri  
via Cross Validation 
Supponiamo dunque di trovarci in questa situazione, in cui i 
dati disponibili sono pochi:
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#35,35," 
36
Dopo aver scorporato il test set di dimensione adeguata, 
vediamo come poter gestire il resto dei dati da utilizzare  per 
il training e la validation.
Un uso ingenuo potrebbe essere il seguente:
Selezione dei parametri  
via Cross Validation 
Resto dei dati 
Training 
Set
Validation
 Set
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#36,36," 
37
Il metodo però non funzionerebbe perché, con pochi dati a 
disposizione, il validation set non sarebbe sufﬁcientemente 
ampio per consentire una valutazione adeguata.
Questo varrebbe per la suddivisione mostrata nella ﬁgura 
precedente, ma anche per altre suddivisioni, come ad es.:
Selezione dei parametri  
via Cross Validation 
Validation
 Set
Validation
 Set"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#37,37," 
38
Ossia vale per qualsiasi scelta di un sottoinsieme dei dati 
disponibili, da utilizzare come validation set.
Quale di tali sottoinsiemi possiamo utilizzare? Sappiamo che 
ciascuno di essi è troppo piccolo per le valutazioni di nostro 
interesse.
Selezione dei parametri  
via Cross Validation 
La risposta è la seguente: li utilizziamo tutti, effettuando una 
“averge performance” su tutte le scelte. 
In tal modo (cross validation) si evita la “sensitivity” dei 
risultati in base al particolare sottoinsieme scelto, causata 
delle poche osservazioni che contiene."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#38,38," 
39
k-fold Cross Validation 
Consideriamo dunque il resto dei dati (N dati), ottenuto 
scorporando un training set di dimensione adeguata dai dati 
disponibili.
Suddividiamo tali N dati in K blocchi, assegnando casualmente  
i dati a ciascuno dei blocchi:
Resto dei dati 
N/K N/K N/K ………….1 2 K ………."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#39,39," 
40
k-fold Cross Validation 
Per ciascuno dei K blocchi, operiamo considerandolo il 
Validation Set, utilizzando quindi i dati rimanenti come 
Training Set.
In sostanza, dopo aver ﬁssato un valore per λ, operiamo 
come segue per il primo blocco (ricordiamoci che in verde 
abbiamo il Training Set):
Validation
 Set
ˆw(1)
 error 1( )1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#4,4,"Esempio di funzione
 
5
Applichiamo rumore gaussiano, campioniamo 30 
osservazioni e addestriamo vari modelli:y=s i n ( 4 x)"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#40,40," 
41
k-fold Cross Validation 
Per il secondo blocco abbiamo:
Validation
 Set
ˆw(2)
  error 2( )2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#41,41," 
42
k-fold Cross Validation 
… e così via ﬁno al blocco K:
Validation
 Set
ˆw(K)
 errorK( )K"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#42,42," 
43
k-fold Cross Validation 
L’algoritmo è il seguente:
Per ogni scelta del valore di λ:
 for k = 1, 2, …., K 
   1. stima di ŵλ sui blocchi di training 
   2. calcolo dell’errore sul “validation block”:
Calcolo dell’Average Error: CV( )=1
K·KX
k=1error k( )
Scelta di λ* che minimizza l’errore CV( λ)error k( )"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#43,43," 
44
leave-one-out Cross Validation 
Formalmente, la migliore approssimazione si ha per validation 
set di dimensione 1 (K = N).
In tal caso si parla di leave-one-out cross validation :
123 n
1 2 3 N
2 3 N
1 2 3 N
1 2 3 N
……………1…
…
…
…
…1 2 3 N"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#44,44,"Scelta del valore K 
 
45
Il Leave-one-out è molto pesante dal punto di vista 
computazionale: 
richiede il calcolo di N “ﬁt” del modello per ogni λ. 
In genere, tipici valori utilizzati per K sono: 
K = 5 (5-fold CV) 
K = 10 (10-fold CV)"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#45,45," 
46
La gestione dell’intercetta 
Nella discussione su Ridge e Cross Validation non abbiamo 
considerato il come gestire l’intercetta, che compare in tanti  
modelli.
yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i=
=DX
j=0wj j(xi)+✏i
Ricordiamoci innanzi tutto il modello a “multiple regression”:
Sappiamo che spesso la feature ɸ0 è posta uguale a 1. In tal 
caso il coefﬁciente w 0 rappresenta per l’appunto l’intercetta 
del modello."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#46,46," 
47
La gestione dell’intercetta 
Conosciamo bene la funzione di costo per la Ridge:
Minimizzando tale funzione, anche l’intercetta w 0 (così 
come gli altri coefﬁcienti) tende ad assumere piccoli valori.RSS(w)+ ·kwk2
2
In realtà ciò non sarebbe necessario. L’intercetta non è 
indicativa dell’overﬁtting."
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#47,47," 
48
La gestione dell’intercetta 
Possiamo dunque considerare una versione modiﬁcata della 
funzione di costo per la Ridge:
In tal modo, la parte relativa alla L 2-norm (penalty) non 
considera w 0.
Vediamo come possiamo implementare ciò nel caso in cui si 
usi l’algoritmo di Gradient Descent.RSS(w0,wresto)+ ·kwrestok2
2"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#48,48," 
49
L’algoritmo viene modiﬁcato come segue:
Algoritmo di Gradient Descent 
[caso della Ridge Regression senza penalizzazione dell’intercetta] 
w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrcosto ridge( w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale RSS[ j]= 2NX
i=1 j(xi)[yi ˆyi(w(t))]
ifj=0
w(t+1)
j w(t)
j ↵⇤derivata parziale RSS[ j]
else
w(t+1)
j (1 2↵ )w(t)
j ↵⇤derivata parziale RSS[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#49,49,"Riferimenti
 
50
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#5,5,"Polinomio di grado 2
 
6
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#6,6,"Polinomio di grado 4
 
7
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#7,7,"Polinomio di grado 16
 
8
"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#8,8,"Overﬁtting con molte feature
 
9
Questo fenomeno accade non solo nella polynomial 
regression, ma anche: 
 quando è elevato il numero degli input d (e.g., per il 
caso degli appartamenti, oltre alla metratura abbiamo 
il #bagni, ecc.); 
e, più in generale, quando è elevato il numero delle 
feature ( D elevato):
yi=DX
j=0wj j(xi)+✏i"
data_test\rootfolder\università\MachineLearning\5-Ridge Regression - Cross Validation-sbloccato.pdf#9,9,"Overﬁtting e #osservazioni
 
10
Il problema dell’overﬁtting, che in genere aumenta 
all’aumentare della complessità del modello, dipende 
anche dal numero delle osservazioni di cui disponiamo: 
Poche osservazioni (N piccolo) → è facile avere overﬁt al crescere 
della complessità del modello. 
Tante osservazioni (N molto grande)  → è più  difﬁcile avere overﬁt.Prezzo
Prezzo
Area Area"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Feature Selection e LASSO
Machine Learning 
 
1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#1,1,"Sommario
La Selezione delle Feature nella Regression 
Algoritmo All Subsets 
Approccio Greedy per Feature Selection (Forward Stepsize 
Algorithm) 
Algoritmo Coordinate Descent 
LASSO 
Confronto tra Ridge e LASSO
 
2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#10,10," 
11
La scelta del Modello 
Ci sono varie possibilità: 
Valutazione delle prestazioni sul validation set (se abbiamo dati sufﬁcienti) 
Cross Validation 
Altre metriche proposte in letteratura che penalizzano la “model 
complexity”
La domanda ora è la seguente: quale conﬁgurazione di 
feature scegliamo? 
Come sappiamo, non conviene scegliere il modello con RSS 
più basso, che diminuisce all’aumentare della complessità del 
modello."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#11,11,"Complessità di “All Subsets”
 
12
La complessità computazionale dell’algoritmo è elevata: basti 
considerare il numero di modelli da valutare! E’ esponenziale 
rispetto al numero delle feature:
[000 ···0]
[100 ···0]
[010 ···0]
···
[110 ···0]
···
[111 ···1]yi= ✏i
yi=w0 0(xi)+✏i
yi=w1 1(xi)+✏i
··· ··· ···
yi=w0 0(xi)+w1 1(xi)+✏i
··· ··· ···
yi=w0 0(xi)+w1 1(xi)+ ···+wD D(xi)+✏i
2D+1feature vector"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#12,12,"Algoritmi Greedy
 
13
Un approccio alternativo è quello di utilizzare algoritmi 
greedy che ci consentono di ottenere soluzioni sub-ottime, 
ma con complessità computazionale molto più bassa.
L’algoritmo che ora vedremo si chiama Forward Stepsize 
Algorithm. Esso si distingue dal precedente perché, 
all’aumentare del numero di feature, sceglie solo una nuova 
feature conservando quelle scelte nei passi precedenti."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#13,13,"Forward Stepsize Algorithm
 
14
Partiamo dalla ﬁgura che rappresenta la fase ﬁnale di All Subsets:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#14,14," 
15
Vediamo come il Forward Stepsize si differenzia:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#15,15," 
16
Per #features = 1 sceglie la migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#16,16," 
17
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
deriva dal passo  
precedente
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#17,17," 
18
Per #features = 2 aggiunge alla 1
 a
 già scelta la 2
 a
 migliore:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
seconda feature 
selezionata"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#18,18," 
19
E’ evidente la differenza rispetto all’algoritmo All Subset:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm
feature selezionate da 
“all subset algorithm”"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#19,19," 
20
… e così via …
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#2,2,"Selezione delle Feature
 
3
La selezione delle feature nella regression è una fase molto 
importante per due motivi: 
1. Efﬁcienza di elaborazione : 
•Se la dimensione di w è elevata (e.g., 100B) la predizione è 
molto pesante computazionalmente. 
•Del resto, se ŵ è sparso, il calcolo dipende solo dai valori 
non nulli. 
2. Interpretabilità : 
• Quali feature sono rilevanti per la nostra  predizione? "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#20,20," 
21
… ﬁno al caso che considera tutte le feature:
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Forward Stepsize Algorithm"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#21,21," 
22
Consideriamo il dizionario delle feature {
 ɸ
0
, 
ɸ
1
, … , 
ɸ
D
} 
Impostiamo l’insieme delle feature F come segue: F
 0
 = 
∅
   (
o impostiamo 
 ɸ
0
 a 1
); 
addestriamo e calcoliamo l’errore. 
t = 0 
•
Per ogni j (≠ dalle feature correnti), addestriamo il modello usando le 
feature correnti F
 t
 + {
ɸ
j
(x)} per ottenere il vettore dei pesi 
 ŵ
 per j. 
•
Selezioniamo la best feature 
 ɸ
j*
(x) (e.g., quella che dà luogo al training 
error più basso quando addestriamo con F
 t
 + {
ɸ
j*
(x)}) 
•
Set  F
 t+1
 <— F
 t 
+ {
ɸ
j*
(x)};  
•
t = t + 1 
•
Ripetere il ciclo 
Forward Stepsize Algorithm
L’algoritmo in sintesi è il seguente:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#22,22," 
23
La complessità computazionale di questo algoritmo è 
sensibilmente minore di quella dell’All Stepsize Algorithm. 
Infatti, il numero di modelli valutati (con D feature) è il 
seguente: 
1° step: D modelli 
2° step: D-1 modelli (si aggiunge 1 feature tra le D-1 possibili) 
3° step: D-2 modelli (si aggiunge 1 feature tra le D-2 possibili) 
ecc.
Forward Stepsize Algorithm
Il numero massimo di step è uguale a D. Abbiamo dunque: 
O(D2)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#23,23," 
24
Questo metodo, proposto da Robert Tibshirani nel 1996, consente 
di effettuare una feature selection, oltre a limitare i valori assoluti 
dei coefﬁcienti w. 
Lasso Regression usa la somma dei valori assoluti dei pesi ( L1 
Regularization ). 
La funzione che rappresenta il costo totale nel Lasso è dunque la 
seguente:    
dove il parametro λ (tuning parameter ) serve per bilanciare i due 
termini.                                              costo lasso(w)=R S S ( w)+ ·kwk1
LASSO 
(
Least Absolute Shrinkage and Selection Operator
 )"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#24,24," 
25Vediamo cosa accade a fronte di diversi valori del parametro λ: 
Se λ = 0: 
ci riconduciamo alla vecchia soluzione, ossia minimizzazione 
dell’ RSS( w) → ŵLS 
Se λ → ∞: 
per soluzioni dove ŵ ≠ 0, il costo totale → ∞ 
l’unica soluzione per minimizzare il costo è: ŵlasso = 0 
Se 0 < λ < ∞: 
Soluzioni Lasso 
per diversi valori 
 λ
0kˆwlassok1kˆwLSk1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#25,25,"Andamento Coefﬁcienti 
Ridge e Lasso
 
26
Ridge Lasso
λ λ "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#26,26,"Visualizzazione costo Ridge
 
27
ellissicosto ridge(w)=R S S ( w)+ ·kwk2
2
RSS(w)=NX
i=1[yi w0 0(xi) w1 1(xi)]2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#27,27," 
28
circonferenzecosto ridge(w)=R S S ( w)+ ·kwk2
2
kwk2
2=w2
0+w2
1
Visualizzazione costo Ridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#28,28,"Simulazione Ridge
 
29
λ = 0
λ→∞ˆwridge
ˆwridgeˆwridge
ˆwridge ˆwridge ˆwridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#29,29," 
30
costo lasso(w)=R S S ( w)+ ·kwk1
RSS(w)=NX
i=1[yi w0 0(xi) w1 1(xi)]2ellissi
Visualizzazione costo Lasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#3,3,"Selezione delle Feature
 
4
Un approccio che possiamo adottare per selezionare le 
migliori feature consiste nel considerare ogni possibile 
combinazione delle feature che abbiamo disponibili, 
veriﬁcando le prestazioni di ciascuna scelta. 
Questo è esattamente ciò che fa l’ All Subset Algorithm  che 
ora vediamo. 
Esso comincia considerando 0 feature, poi tutte le 
possibilità per 1 feature, poi tutte le possibilità per 2 
feature, ecc., scegliendo ogni volta la migliore 
combinazione."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#30,30," 
31
kwk1= |w0|+|w1|costo lasso(w)=R S S ( w)+ ·kwk1
diamonds 
Visualizzazione costo Lasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#31,31,"Simulazione Lasso
 
32
λ→∞λ = 0
ˆwlasso
ˆwlassoˆwlasso
ˆwlasso ˆwlasso ˆwlasso"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#32,32,"Confronto tra Ridge e Lasso
 
33
Per ogni valore di 
 λ
, per la Ridge esiste un certo valore 
 s
 tale 
che le seguenti due equazioni forniscono le stesse stime dei 
coefﬁcienti w
 ridge
:
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
jsargmin
w[RSS(w)+ ·kwk2
2]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#33,33,"Confronto tra Ridge e Lasso
 
34w1
w0
w2
0+w2
1s
argmin
wRSS(w)
sotto la condizione:DX
j=0w2
js
Consideriamo per semplicità il caso a 2 dimensioni. L’equazione: 
indica che i coefﬁcienti ŵridge stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al cerchio deﬁnito da: w2
0+w2
1s"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#34,34,"Confronto tra Ridge e Lasso
 
35
Analogamente, per ogni valore di 
 λ
, per il Lasso esiste un 
certo valore 
 s
 tale che le seguenti due equazioni forniscono 
le stesse stime dei coefﬁcienti w
 lasso
:
argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|sargmin
w[RSS(w)+ ·kwk1]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#35,35,"Confronto tra Ridge e Lasso
 
36|w0|+|w1|sw0w1
|w0|+|w1|s
Analogamente, la seguente equazione:  
indica che i coefﬁcienti ŵlasso stimati sono quelli che hanno il più 
piccolo RSS tra i punti appartenenti al “diamante”: argmin
wRSS(w)
sotto la condizione:DX
j=0|wj|s"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#36,36,"Confronto tra Ridge e Lasso
 
37
La ﬁgura seguente ci mostra i punti di minimo per i due casi, e il 
perché Lasso spesso consente di eliminare alcune feature. In rosso 
sono indicate le curve di livello per RSS.
|w0|+|w1|s w2
0+w2
1s
w0w1
w0w1
ˆwLSˆwLS
ˆwlasso ˆwridge"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#37,37,"Confronto tra Ridge e Lasso
 
38
Se 
s
 è sufﬁcientemente grande, le regioni in verde conterranno la 
soluzione Least Squares. Pertanto le stime della Ridge regression e 
del Lasso saranno le stesse della Least Squares (tale grande valore per 
s
 corrisponde a 
 λ
 = 0) 
Se invece la soluzione Least Squares sta al di fuori delle regioni in 
verde, essa non può essere la soluzione perché non rispetta i vincoli 
citati in precedenza. 
I punti di minimo sono dunque quelli che corrispondono alla curva 
di livello più “stretta” che passa per l’area in verde (ricordiamoci che 
le curve di livello per RSS corrispondono a valori sempre più alti 
mano a mano che si “allargano” rispetto alla soluzione LS)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#38,38,"Confronto tra Ridge e Lasso
 
39
Nella ﬁgura abbiamo considerato il caso di 2 dimensioni per il 
vettore 
 w
. 
Nel caso di 3 dimensioni la “constraint region” in verde diventa una 
sfera per la Ridge e un poliedro per il Lasso. 
Nel caso di dimensione > 3, essa diventa una ipersfera per la Ridge e 
un politopo per il Lasso (politopo è un termine coniato da Alicia 
Boole, ﬁglia di George Boole)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#39,39,"Minimizzazione della  
funzione di costo Lasso
In precedenza abbiamo visto come poter minimizzare la 
funzione di costo (per LS e per Ridge) mediante: 
La forma chiusa (uguagliando a zero il gradiente della 
funzione) 
Gradient Descent 
Per il Lasso ci sono delle difﬁcoltà per il calcolo del gradiente.
 
40"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#4,4,"Ricerca delle migliori feature 
Size: 0
 
5# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#40,40,"Minimizzazione della  
funzione di costo Lasso
La funzione da minimizzare è la seguente: 
 
41
wj
|wj|
derivata = +1 derivata = -1
non derivabile
costo lasso(w)=R S S ( w)+ ·kwk1
come calcolare 
la derivata?"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#41,41,"Minimizzazione della  
funzione di costo
Non possiamo quindi calcolare il gradiente della funzione. 
Successivamente vedremo come utilizzare il concetto di 
subgradient
  per superare la difﬁcoltà appena vista. 
Ora cogliamo l’occasione per vedere un nuovo algoritmo per 
minimizzare una funzione di costo, chiamato 
 Coordinate 
Descent
 . 
Presenteremo l’algoritmo in generale, per poi vedere come esso 
possa essere usato convenientemente per minimizzare la 
funzione di costo per il Lasso.
 
42"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#42,42,"Il nostro scopo è quello di minimizzare una certa funzione:
Algoritmo Coordinate Descent
g(w)=g(w0,w1,···,wD)
La caratteristica distintiva del Coordinate Descent è che la 
minimizzazione avviene lungo una singola dimensione per 
volta, come illustrato qui di seguito nel semplice caso di 
funzione di due variabili w
 0
 e w
 1
. 
 
43"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#43,43,"Algoritmo Coordinate Descent
Curve di livello di una funzione g(
 w
) da minimizzare:
 
44
w0w1
scegliamo il 
punto inizialevalori di g( w) maggiori per  
curve di livello più esterne "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#44,44,"Facciamo variare una sola coordinata:
 
45
w0w1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#45,45,"Troviamo il minimo e spostiamoci su tale punto (axis-alined move):
 
46
w0w1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#46,46,"Facciamo variare una sola altra coordinata:
 
47
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#47,47,"Troviamo il minimo e passiamo su tale punto:
 
48
w0w1
w0
1
w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#48,48,"……. e così via …….
 
49
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#49,49,"………
 
50
w0w1
w0
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#5,5," 
6# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature 
Size: 1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#50,50,"………
 
51
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#51,51,"………
 
52
w0w1
w0
1w00
1
w00
0w0
0
Algoritmo Coordinate Descent"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#52,52,"…. ﬁno ad arrivare al minimo globale:
 
53
w0w1
w0
1w00
1
w00
0w0
0
……
Algoritmo Coordinate Descent
per problemi convessi, 
step sempre più piccoli 
man mano che ci  
avviciniamo alla soluzione"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#53,53,"Algoritmo Coordinate Descent
 
54
Inizializza ŵ = 0 (o in modo “smart”) 
while  not converged: 
   scegli una coordinata j
si minimizza solo sulla j-esima coordinataˆwj argmin
!g(ˆw0,ˆw1,···,ˆwj 1,!,ˆwj+1,···,ˆwD)"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#54,54,"Algoritmo Coordinate Descent
 
55
Come scegliere nell’algoritmo la coordinata successiva? 
In modo casuale (“random” o “stochastic"" coordinate descent) 
In modo “round robin” 
ecc. 
Si noti che in questo algoritmo non è necessario scegliere lo step size! 
Tale approccio è utilissimo per numerosi problemi 
Converge ad un ottimo in vari altri casi (e.g., funzione “strongly 
convex”) 
Converge per la funzione obiettivo Lasso "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#55,55,"Normalizzazione delle Feature
 
56
L’applicazione dell’algoritmo Coordinate Descent per il Lasso è 
sempliﬁcata se operiamo una normalizzazione delle feature. 
Per far questo dobbiamo prendere in considerazione la matrice 
delle feature   usata in precedenza, nella quale ogni colonna 
corrisponde ad una feature (0, 1, … D) applicata ai vari ingressi xi 
dei training data.  "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#56,56,"Normalizzazione Feature
 
57 =2
664 0(x1) 1(x1) ...  j(x1) ...  D(x1)
 0(x2) 1(x2) ...  j(x2) ...  D(x2)
... ... ... ... ... ...
 0(xN) 1(xN) ...  j(xN) ...  D(xN)3
775
 j(xk)= j(xk)qPN
i=1 2
j(xi)feature generica normalizzata:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#57,57,"Normalizzazione delle Feature
 
58Zj=vuutNX
i=1 2
j(xi)
Per normalizzare abbiamo usato a denominatore il seguente 
“normalizer”: 
Ricordiamoci che per i test data dovremo applicare lo stesso 
normalizer.  "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#58,58,"Coordinate Descent per 
Unregularized Regression
 
59
Vediamo ora come sia possibile applicare l’algoritmo Coordinate 
Descent nel caso di regressione senza regularization, ossia nel 
caso Least Squares. 
Il passo successivo sarà la sua applicazione al Lasso. 
Per l’applicazione al caso Least Squares (con feature 
normalizzate) dobbiamo calcolare le derivare parziali della 
funzione di costo RSS (necessarie per minimizzare sulla singola 
coordinata): 
RSS(w)=NX
i=1[yi DX
j=0wj j(xi)]2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#59,59,"Derivate di RSS 
con feature normalizzate
 
60@RSS(w)
@wj= 2NX
i=1 j(xi)[yi ˆyi(w)] = 2NX
i=1 j(xi)[yi DX
j=0wj j(xi)] =
= 2NX
i=1 j(xi)[yi X
k 6=jwk k(xi) wj j(xi)] =
= 2⇢jz }| {
NX
i=1 j(xi)[yi X
k 6=jwk k(xi)]
| {z }
prediz. senza  j+2wj,1z}|{
NX
i=1 2
j(xi)=
= 2⇢j+2wj"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#6,6," 
7# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliore feature
Ricerca delle migliori feature 
Size: 1"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#60,60,"Ricerca del minimo per una 
coordinata
 
61⇢j=NX
i=1 j(xi)[yi X
k6=jwk k(xi)] =NX
i=1 j(xi)[yi ˆyi(ˆw j)]@RSS(w)
@wj= 2⇢j+2wj=0
ˆwj=⇢j
dove:"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#61,61,"Algoritmo Coordinate Descent 
per Least Squares
 
62set:calcola:
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
⇢j=NX
i=1 j(xi)[z}| {
yi ˆyi(ˆw j)|{z}]residual senza la feature j
predizione senza 
la feature j
ˆwj=⇢j"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#62,62," 
63ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2
Algoritmo Coordinate Descent 
per Lasso
Vediamo ora la versione dell’algoritmo per il caso del Lasso. 
In questo caso l’impostazione per il peso 
 ŵ
j
 dipende dal valore 
assunto dal parametro 
 λ
: 
Una dimostrazione formale è mostrata nella prossima lezione. "
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#63,63,"Coefﬁcienti per LS, Ridge e Lasso
 
64ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2
soft thresholding
+ 
2  
2⇢i 0 0 ⇢i0 0ˆwj ˆwj"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#64,64,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature normalizzate]
 
65ˆwj=8
<
:⇢j+ 
2se⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2se⇢j> 
2set:calcola:
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#65,65,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
66
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2zj=NX
i=1 j(xi)2
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#66,66," 
67
Un aspetto importante è il criterio di convergenza. 
Per problemi convessi (in particolare strongly convex) gli step 
sono sempre più piccoli mano a mano che ci si avvicina al 
punto di ottimo:
Algoritmo Coordinate Descent 
per Lasso
Un criterio che possiamo utilizzare per la convergenza è quello 
di considerare una misura degli step fatti in un ciclo completo su 
tutte le feature e fermarsi quando: 
 max step < 
 ε"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#67,67,"Scelta del parametro 
 λ
per approfondimenti: 
Murphy, K. “
 Machine Learning: A Probabilistic Perspective
 ”. The MIT Press, 
2012.
 
68
Il parametro 
 λ
 può essere scelto avvalendosi dell’approccio che 
usa il validation set, a patto di avere un numero sufﬁciente di 
osservazioni. 
Altrimenti possiamo usare la k-fold cross validation. 
Quest’ultima tende a scegliere il parametro che ottiene la 
migliore “predictive accuracy”. Essa tende a favorire soluzioni 
meno “sparse”, ossia con piccoli valori di 
 λ
, anziché soluzioni 
con maggiore feature selection."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#68,68,"Riferimenti
 
69
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#7,7," 
8# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
migliori 2 feature
Ricerca delle migliori feature 
Size: 2"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#8,8," 
9
Ricerca delle migliori feature 
Size: 8
# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront"
data_test\rootfolder\università\MachineLearning\6-Regression - FS  Lasso-sbloccato.pdf#9,9," 
10# di featuresRSS(ŵ)
0 1 2 3 4 5 6 7 8 •# bedrooms 
•# bathrooms 
•sq.ft. living 
•sq.ft. lot 
•ﬂoors 
•year built 
•year renovated 
•waterfront
Ricerca delle migliori feature  
andamento in base al numero di feature"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Dimostrazioni Formali Lasso
Machine Learning "
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#1,1,"Sommario
 
2Dimostrazione della formula di aggiornamento dei 
coefﬁcienti nell’algoritmo coordinate descent per 
LASSO
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#10,10,"Differential set della  
funzione di costo Lasso
 
11
Il differential set rispetto al generico peso w
 j
 è pertanto il seguente:
@wj[costo lasso] = 2 zjwj 2⇢j+ ·@wj|wj|da RSS da L 1 penalty
@wj[costo lasso] = 2 zjwj 2⇢j+8
<
:   sewj<0
[  , ]s e wj=0
  sewj>0
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#11,11,"Differential Set della  
funzione di costo Lasso  
 
12
Abbiamo pertanto la seguente espressione ﬁnale:
@wj[costo lasso] =8
<
:2zjwj 2⇢j   sewj<0
[ 2⇢j  , 2⇢j+ ]s e wj=0
2zjwj 2⇢j+  sewj>0"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#12,12,"Soluzione ottima 
 
13
Se uguagliamo a zero la precedente espressione, abbiamo tre casi:
caso 1 (
 w
j  
< 0
):2zjˆwj 2⇢j  =0
ˆwj=2⇢j+ 
2zj=⇢j+ 
2
zj
ˆwj=⇢j+ 
2
zj<0 ⇢j+ 
2<0 ⇢j<  
2
da cui otteniamo:
Poiché 
 ŵ
j  
< 0, abbiamo:"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#13,13,"Soluzione ottima 
 
14
Abbiamo dunque:
In deﬁnitiva:
caso 2 ( wj  = 0): l’intervallo                                            deve contenere 0 [ 2⇢j  , 2⇢j+ ]
  
2⇢j 
2 2⇢j+  0 2⇢j  0
⇢j 
2⇢j   
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#14,14,"Soluzione ottima 
 
15
caso 3 (
 w
j  
> 0
):
da cui otteniamo:
Poiché 
 ŵ
j  
> 0, abbiamo:2zjˆwj 2⇢j+ =0
ˆwj=2⇢j  
2zj=⇢j  
2
zj
ˆwj=⇢j  
2
zj>0 ⇢j  
2>0 ⇢j> 
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#15,15," 
16
In conclusione:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2@wj[costo lasso] =8
<
:2zjwj 2⇢j   sewj<0
[ 2⇢j  , 2⇢j+ ]s e wj=0
2zjwj 2⇢j+  sewj>0
Soluzione ottima "
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#16,16,"Algoritmo Coordinate Descent 
per Lasso  
[versione con feature non normalizzate]
 
17
calcola:  
Inizializza ŵ = 0 (o in altro modo) 
while  not converged: 
   for j = 0, 1, …, D:
set:calcola:
ˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2zj=NX
i=1 j(xi)2
⇢j=NX
i=1 j(xi)[yi ˆyi(ˆw j)]"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#17,17,"Coefﬁcienti per LS, Ridge e Lasso
 
18
soft thresholding
+ 
2  
2⇢i 0 0 ⇢i0 0ˆwj ˆwjˆwj=8
><
>:⇢j+ 
2
zjse⇢j<  
2
0 se ⇢j2[  
2, 
2]
⇢j  
2
zjse⇢j> 
2"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#18,18,"Riferimenti
 
19
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. 
Murphy, K.P. 
 Machine Learning - A Probabilistic Approach
 , The MIT Press, 2012."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#2,2,"Ottimizzazione Lasso
 
3
Come sappiamo, la Funzione Obiettivo per il Lasso da ottimizzare 
mediante Coordinate Descent è la seguente:
RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
Vediamo come calcolare le derivate parziali dei due termini 
presenti nell’espressione rispetto ai pesi w j."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#3,3,"Derivazione del termine RSS
 
4RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
@RSS(w)
@wj= 2NX
i=1 j(xi)[yi ˆyi(w)] = 2NX
i=1 j(xi)[yi DX
j=0wj j(xi)] =
= 2NX
i=1 j(xi)[yi X
k 6=jwk k(xi) wj j(xi)] =
= 2⇢jz }| {
NX
i=1 j(xi)[yi X
k 6=jwk k(xi)]
| {z }
prediz. senza  j+2wj,zjz}|{
NX
i=1 2
j(xi)=
= 2⇢j+2wjzj"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#4,4," 
5
In questo caso c’è il problema del calcolo della derivata parziale:
RSS(w)+ ·kwk1=NX
i=1[yi DX
j=0wj j(xi)]2+ DX
j=0|wj|
 ·@|wj|
@wj=?
Derivazione del termine L
 1
 penalty
derivata = +1 derivata = -1
non derivabilewj|wj|
"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#5,5,"Subgradiente di Funzioni Convesse 
 6
I metodi che conosciamo (e.g., Gradient Descent, Coordinate 
Descent) richiedono che la funzione da ottimizzare sia 
differenziabile. 
E’ possibile però generalizzare la discussione andando al di là 
delle funzioni differenziabili. 
E’ possibile ad esempio mostrare come i precedenti algoritmi 
possano essere applicati anche per funzioni non differenziabili, 
utilizzando il subgradiente anziché il gradiente."
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#6,6,"Subgradiente di Funzioni Convesse
 
7Un vettore S che soddisfa la: 
è detto subgradiente di g in v.g(w) g(v)+ST(w v)
.wg(w)
vS1pendenza 
S2 pendenza 
. 
. 
.g:R!R
L’insieme dei subgradienti di g in v è chiamato “differential set” e 
indicato: @g(v)"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#7,7,"Subgradiente della funzione  
Valore Assoluto
 
8
Nel punto non derivabile della funzione “valore assoluto” i 
subgradienti variano da -1 a +1:
derivata = +1 derivata = -1
wj|wj|"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#8,8,"Subgradiente della funzione  
Valore Assoluto
 
9
Il “differential set” è dunque il seguente per i vari punti:
@wj|wj|=8
<
:{ 1} sewj<0
[ 1,1] se wj=0
{1} sewj>0"
data_test\rootfolder\università\MachineLearning\7-Dimostrazioni-Lasso-sbloccato.pdf#9,9,"Subgradiente di L
 1
 term
 
10
Nel caso del Lasso abbiamo:
 ·@wj|wj|=8
<
:   sewj<0
[  , ]s e wj=0
  sewj>0"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Regressione:  
Fonti di Errore 
Expected Prediction Error
Machine Learning "
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#1,1,"Sommario
Le tre fonti di errore: Noise, Bias, Variance 
Deﬁnizione e derivazione formale delle tre fonti di 
errore 
Expected Prediction Error 
 
2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#10,10,"Noise: 
Varianza dell’Errore del modello
 
11
EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
y=fw(true)(x)+ ✏
 2= varianza di ✏"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#11,11,"Bias della funzione stimata 
 
12bias( fˆw(xt)) = fw(true) (xt) f¯w(xt)EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
x
t(true) (true)
(true)average 
estimated 
function:
f¯w(xt),Etrain [fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#12,12,"Varianza della funzione stimata 
 
13EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
var(fˆw(xt)) =Etrain [(fˆw(xt) f¯w(xt))2]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#13,13,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Vediamo ora come dimostrare la formula dell’EPE, in cui 
entrano in gioco i tre termini che abbiamo deﬁniti 
formalmente in precedenza:
 
14EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#14,14,"Dimostrazione per  
l’Expected Prediction Error (EPE)
A tal ﬁne, ricordiamo innanzi tutto la deﬁnizione di tale 
errore:
 
15EPE = Etrain[Generalization Error per ˆw(train)] =
=Etrain[Ex,y[L(y,f ˆw(train) (x))]]
1.
 Consideriamo: 
2.
 Riferiamoci ad uno speciﬁco 
 x
tL[y, f ˆw(x)] = ( y ˆy)2=[y fˆw(x)]2
Facciamo poi le seguenti due assunzioni (già citate prima):"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#15,15,"Dimostrazione per  
l’Expected Prediction Error (EPE)
Con le due assunzioni precedenti l’espressione per l’EPE 
si sempliﬁca come segue:
 
16EPE( xt)=Etrain ,yt[(yt ˆyt)2]=Etrain ,yt[(yt fˆw(train) (xt))2]
dove non abbiamo più l’Expectation su 
 x
, avendo ﬁssato 
uno speciﬁco 
 x
t
, e dove l’Expectation su y è diventata 
l’Expectation su y
 t
 perché dobbiamo considerare solo le 
osservazioni che abbiamo a fronte dell’input 
 x
t
."
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#16,16,"Expected Prediction Error
Partendo da tale espressione, vediamo come dimostrare la 
formula dell’EPE:
 
17EPE( xt)= Etrain ,yt[(yt ˆyt)2]=Etrain ,yt[(yt fˆw(train) (xt))2]=
=Etrain ,yt[(yt fz }| {
fw(true) (xt)+fz }| {
fw(true) (xt) ˆfz }| {
fˆw(train) (xt))2]=
=Etrain ,yt[((yt f)+(f ˆf))2]=
=Etrain ,yt[(yt f)2+ 2(yt f)·(f ˆf)+(f ˆf)2]=
=Etrain ,yt[(yt f)2]+2 ·Etrain ,yt[(yt f)·(f ˆf)] +Etrain ,yt[(f ˆf)2]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#17,17,"Expected Prediction Error
1° termine: Si sempliﬁca come segue, poiché  y
 t
 e f non 
dipendono dal training set:
 
18
Si noti che l’Expectation del quadrato dell’errore 
 ε
 è la 
varianza di 
 ε
, avendo esso media nulla.Etrain ,yt[(yt f)2]=Eyt[(yt f)2]=Eyt[✏2], 2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#18,18,"Expected Prediction Error
2° termine:
 
192·Etrain ,yt[(yt f)·(f ˆf)] = 2 ·Etrain ,yt[(✏)·(f ˆf)] =
=2 ·Etrain ,yt[✏]·Etrain ,yt[(f ˆf)] =
=2 ·0·Etrain ,yt[(f ˆf)] = 0
Si noti che ε è indipendente da  e da , e quindi è 
indipendente da           .  
Si ricordi, inoltre, che l’Expectation dell’errore ε è uguale 
a zero.ˆf f
(f ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#19,19,"Expected Prediction Error
3° termine:
 
20
L’espressione per l’errore EPE può essere dunque scritta 
così:
Abbiamo: Etrain ,yt[(f ˆf)2]=Etrain [(f ˆf)2]
EPE( xt)= 2+M S E ( ˆf)MSE( ˆf),Etrain[(f ˆf)2]
Consideriamo ora il Means Squared Error (MSE), deﬁnito 
come segue:"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#2,2,"Deﬁnizione e derivazione 
formale
Occupiamoci della deﬁnizione e derivazione formale delle 
tre sorgenti di errore: 
noise 
bias 
variance 
A tal ﬁne introduciamo innanzi tutto l’Expected Prediction 
Error, le cui componenti sono le suddette sorgenti di errore.
 
3"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#20,20,"Means Squared Error
Dobbiamo ora dimostrare che:
 
21MSE[ fˆw(train) (xt)] = Etrain[(fw(true) (xt) fˆw(train) (xt))2]=
=Etrain[(fz }| {
fw(true) (xt) ¯fz}|{
f¯w(xt)+¯fz}|{
f¯w(xt) ˆfz }| {
fˆw(train) (xt))2]=
=Etrain[((f ¯f)+( ¯f ˆf))2]=
=Etrain[(f ¯f)2+ 2(f ¯f)·(¯f ˆf)+( ¯f ˆf)2]=
=Etrain[(f ¯f)2]+2 ·Etrain[(f ¯f)·(¯f ˆf)] +Etrain[(¯f ˆf)2]MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#21,21,"1° termine: ricordiamo che
 
22
Ne consegue che:
poiché   e    non dipendono dal training set. f¯f
Means Squared Error
¯f,Etrain [ˆf]
Etrain [(f ¯f)2]=(f ¯f)2,[bias( ˆf)]2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#22,22,"2° termine:
 
232·Etrain [(f ¯f)·(¯f ˆf)] = 2 ·(f ¯f)·Etrain [(¯f ˆf)] =
=2 ·(f ¯f)·(¯f Etrain [ˆf]) =
=2 ·(f ¯f)·(¯f ¯f)=
=2 ·(f ¯f)·0=0
Means Squared Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#23,23,"Means Squared Error
3° termine:
 
24Etrain [(¯f ˆf)2]=Etrain [(ˆf ¯f)2],var( ˆf)"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#24,24,"E’ in tal modo dimostrato che:
 
25MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)
Means Squared Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#25,25,"In conclusione:
 
26EPE( xt)= 2+M S E [ fˆw(xt)] = 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
le 3 sorgenti di errore
Espressione per 
Expected Prediction Error"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#26,26,"Riferimenti
 
27
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Regression
 , University of Washington - Coursera, 2015. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#3,3,"Training Set Randomness
Un Training Set è un campione di N osservazioni (e.g., N 
appartamenti venduti di cui conosciamo le features e il 
prezzo).  
Cosa accade se il Training Set è costituito da altre N 
osservazioni diverse dalle precedenti?  
Come cambiano le prestazioni del sistema?
 
4"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#4,4,"Training Set Randomness
Ad esempio, nella ﬁgura sono mostrate due situazioni 
relative a due diverse scelte del training set:
 
5Test Set
Per valutare la prestazione dei due “ﬁt” dobbiamo 
prendere in considerazione il Generalization Error."
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#5,5,"Training Set Randomness
Nei due casi otterremo due diversi valori del 
Generalization Error:
 
6Test Set
"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#6,6,"Expected Prediction Error
Idealmente, vorremmo poter ottenere una misura delle 
prestazioni del sistema, mediata su tutti i possibili training 
set. 
Possiamo deﬁnire formalmente tale quantità, che 
chiamiamo Expected Prediction Error (EPE), come segue: 
 
7EPE = Etrain[Generalization Error per ˆw(train)]
“averaging” su tutti i possibili Training Set 
(pesati in base alle loro probabilità)parametri calcolati su 
uno speciﬁco Training Set"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#7,7,"Expected Prediction Error 
su un target input
Per analizzare questo tipo di errore, cominciamo a 
prendere in considerazione uno speciﬁco punto 
 x
t
: 
 
8Test 
x
t
Supponiamo  inoltre che la Loss function sia la seguente: 
L[y, f ˆw(x)] = ( y ˆy)2=[y fˆw(x)]2"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#8,8,"Expected Prediction Error 
su un target input
E’ possibile dimostrare che l’errore EPE in 
 x
t
 è uguale alla 
somma di tre termini:
 
9
Vediamo ora di illustrare adeguatamente tali tre termini.EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]"
data_test\rootfolder\università\MachineLearning\8-Expected Prediction Error-sbloccato.pdf#9,9,"Noise: 
Varianza dell’Errore del modello
 
10EPE( xt)= 2+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]
fw(true) (x)
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#0,0,"Università Roma Tre 
Dipartimento di Ingegneria 
Anno Accademico 2021 - 2022 
Introduzione  
alla  
Classiﬁcazione
Machine Learning "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#1,1,"Sommario
Introduzione alla Classiﬁcazione 
Esempi di applicazione della Classiﬁcazione 
Decision Boundary 
Logistic Regression 
Maximum Likelihood Estimation 
Training mediante Gradient Ascent
 
2"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#10,10,"Introduzione alla Classiﬁcazione
 
11
•Come si vede in ﬁgura, tutte le immagini del test set, tranne una, 
sono classiﬁcate correttamente. 
•L’errore per il Boston terrier  è dovuto completamente alla nostra 
scelta delle features, scelta fatta basandoci sul training set 
disponibile (un po’ troppo piccolo). 
•Per migliorare dobbiamo perciò ricominciare, collezionando più 
dati e individuare più features."
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#11,11,"Learning Pipeline
 
12
•In ﬁgura è rappresentata la learning pipeline del problema di 
classiﬁcazione che stiamo considerando. 
•Lo stesso processo è usato essenzialmente per tutti i task di 
Machine Learning, non solo per la classiﬁcazione. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#12,12,"Learning Pipeline
 
13•Deﬁnire il problema . Qual è il task che vogliamo sia appreso dal 
computer? 
•Collezionare i dati . Raccogliere i dati per il training set e il test set. Più 
i dati sono numerosi e diversiﬁcati, meglio è per il successo del 
sistema da realizzare. 
•Individuare le features . Quali sono le features migliori per descrivere i 
dati? 
•Addestrare il modello . Scegliere il modello e calibrare i suoi parametri 
sul training set mediante metodi di ottimizzazione. 
•Testare il modello . Valutare sul test set le prestazioni del modello 
addestrato. Se i risultati non sono soddisfacenti, ripensare la scelta 
delle features utilizzate e collezionare, se possibile, più dati. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#13,13,"Minimizzazione di una funzione di costo
 
14
Caso della regressione:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#14,14,"Minimizzazione di una funzione di costo
 
15
Caso della classiﬁcazione:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#15,15,"Esempi di applicazione 
Object Detection
 
16
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#16,16,"Esempi di applicazione 
Spam Filtering
 
17(Testo della email, 
mittente, IP, ecc.)
Input: x Output: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#17,17,"Esempi di applicazione 
Image Classiﬁcation
 
18
Input: x Output: ŷ
(pixel dell’immagine) (categoria predetta)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#18,18,"Esempi di applicazione 
Diagnosi Mediche Personalizzate 
 
19Input: x Output: ŷ
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#19,19,"Esempi di applicazione 
Reading Your Mind
 
20
Output: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#2,2,"Introduzione alla Classiﬁcazione
Il task della 
 Classiﬁcazione
  è simile in linea di principio a 
quello della 
 Regressione  
La vera differenza tra i due è che, anziché predire un valore di 
output continuo, nella classiﬁcazione cerchiamo di prevedere 
valori discreti o 
 classi 
 
3"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#20,20,"Esempi di applicazione 
 
21Sentiment Analysis
Esempio: classiﬁcatore di reviews di ristorantiInput: xOutput: ŷ"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#21,21,"Esempi di applicazione 
Sentiment Analysis
 
22
Input x:  In questo ristorante preparano i migliori  
“spaghetti alla carbonara” di Roma
ŷ = +1"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#22,22,"Punteggio di una frase 
(
Score
 ) 
 
23Termine Peso w
migliore 1.5
buono 1.0
cattivo -1.0
magniﬁco 2.0
terribile -2.1
eccezionale 2.7
il, noi, dove, ecc. 0.0Un modo che possiamo adottare per classiﬁcare una review come 
positiva o negativa consiste nel considerare alcuni “termini” che 
riteniamo rilevanti ai ﬁni della classiﬁcazione, calcolando per ciascuno 
di essi il numero di occorrenze con cui compare nella review e un 
“valore di rilevanza” (peso) da utilizzare per calcolare un “punteggio”. 
Ad esempio:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#23,23," 
24x1 = #eccezionalex2 = #terribile
+
++ ++-
--
-
+Score( x) = 2.7 x1 - 2.1 x2Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
-Score( x) < 0
Score( x) > 0r:  2.7 x1 - 2.1 x2 = 0  
      (decision boundary)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#24,24," 
25+
++ ++-
--
-
+Termine Peso w
eccezionale 2.7
terribile -2.1
Punteggio di una frase 
(
Score
 ) 
+Score( x) < 0
Score( x) > 0
x1 = #eccezionalex2 = #terribiler:  1.0 + 2.7 x1 - 2.1 x2 = 0 
    (decision boundary)Score( x) = 1.0 + 2.7 x1 - 2.1 x2"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#25,25," 26
ˆyi= sign[Score( xi)]Nel caso in cui i termini siano d possiamo calcolare il punteggio 
come segue:
e classiﬁcare la review in questo modo:
Punteggio di una frase 
(
Score
 ) 
dove:
sign(Score) =⇢+1 se Score >0
 1 se Score <0"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#26,26," 27ˆyi= sign[Score( xi)]Score( xi)= w0 0(xi)+w1 1(xi)+ ···+wD D(xi)=
=DX
j=0wj j(xi)=wT· (xi)Nel caso generale di classiﬁcazione binaria abbiamo:
Punteggio di una frase 
(
Score
 ) "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#27,27,"Afﬁdabilità della Previsione 
 28•La funzione sign vista in precedenza ci fornisce una 
classiﬁcazione binaria del sentiment della revisione. 
•Potremmo però essere interessati anche ad avere un grado di 
conﬁdenza della previsione. 
•Ad esempio, potremmo voler distinguere il caso di uno 
Score di poco superiore allo zero (e.g., 0.1) dal caso di uno 
Score ben più elevato (e.g., 4.0), punteggi che in entrambi i 
casi danno luogo a review positive. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#28,28,"Probabilità come “degree of belief” 
 290 1P(yi = +1)
Assolutamente certo 
review negative0.5
Assolutamente certo 
review positive
Non so se le review  
sono positive o negative•A tale scopo possiamo avvalerci del calcolo delle probabilità. 
•Se diciamo che la probabilità di avere y i = +1 è di 0.7, vogliamo 
dire che ci aspettiamo di avere nell’insieme delle review 
disponibili il 70% di review positive. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#29,29,"Probabilità come “degree of belief” 
Probabilità Condizionate 
 30•E’ molto utile in tale contesto considerare le probabilità 
condizionate. 
•Se diciamo ad esempio che la probabilità di avere una review 
positiva, condizionata al fatto di avere nella review 3 occorrenze 
di “eccezionale” ed 1 di “terribile”, è di 0.9, vogliamo dire che ci 
aspettiamo il 90% delle review positive nella lista delle review 
disponibili, considerando però solo quelle che hanno 3 
“eccezionale” e 1 “terribile” (in verde nella ﬁgura che segue). "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#3,3,"Introduzione alla Classiﬁcazione
In buona sostanza, un classiﬁcatore realizza un mapping: 
dove  
    è l’
 instance space
 , ossia l’insieme di tutte le possibili 
istanze del problema. Se esse sono descritte da un numero 
precisato di features, abbiamo: 
 
    è un ﬁnito e in genere piccolo insieme di 
 class labels
 : 
 
4C
C=[C1,C2,...,C k]X!C
X=[F1⇥F2⇥···⇥FD]X"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#30,30," 
31 xi : testo della review yi: sentiment
Il cacio e pepe era delizioso. +1
La carbonara era eccezionale. L’ambiente terribile. Il servizio eccezionale. 
Complessivamente un ristorante eccezionale.+1
Mia moglie ha preso i carcioﬁ alla romana, che erano pessimi. -1
………… -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale -1
………… +1
……. eccezionale ……… terribile …… eccezionale …… eccezionale +1P(y i = +1| 3 eccezionale & 1 terribile) = 0.9Probabilità come “degree of belief” 
Probabilità Condizionate "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#31,31," 320 1P(yi = +1| xi)
Assolutamente certo 
che xi è negativa0.5
Assolutamente certo 
che xi è positiva
Non sono sicuro se la xi  
è positiva o negativaIn generale, dato un input xi, (e.g., una review) abbiamo la 
seguente situazione: Probabilità come “degree of belief” 
Probabilità Condizionate "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#32,32,"Link Function 
 33Score( xi, w)- ∞ + ∞ •Il problema che dobbiamo risolvere, se vogliamo avvalerci delle 
probabilità condizionate, è capire come passare dai valori dello 
Score a quelli delle probabilità. 
•La funzione Score ha un range che va da -∞ a +∞: 
•La probabilità, come sappiamo, può variare da 0 a 1:  
0 1P(yi = +1| xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#33,33," 34Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = g[Score( xi, w)]Link Function 
•Dobbiamo pertanto deﬁnire una “link function” g (generalized 
linear model ) che realizzi un mapping tra i due intervalli: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#34,34," 
35
•Una funzione tipicamente usata in questi casi è la funzione 
logistica , o sigmoide , così deﬁnita:Link Function 
•Essa, come si vede, ha l’insieme di deﬁnizione costituito 
dall’intervallo (-∞, +∞) e come codominio l’intervallo [0, 1].  "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#35,35," 36Score( xi, w)
- ∞ + ∞ 
0 10
0.5
P(yi = +1| xi, w) = sigmoid [Score( xi, w)]Logistic Regression Model 
•Il nostro modello diventa dunque il seguente: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#36,36," 37Logistic Regression Model 
•L’espressione per la probabilità, dato un ingresso xi ed un vettore 
dei pesi calcolato ŵ, è dunque la seguente: 
ˆP(yi=+ 1 |xi,ˆw)=1
1+e ˆwT· (xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#37,37," 38Il Processo di Training 
•Il processo di training consiste nel deﬁnire una funzione di costo, 
o una funzione che misura la “qualità” della previsione, e nel 
determinare la conﬁgurazione dei pesi (vettore w) che ottimizza 
la funzione per gli esempi di training. 
•Nella ﬁgura che segue sono mostrati i passi relativi a tale 
processo. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#38,38,"Il Processo di Training 
[caso della Classiﬁcazione]
Dati di 
Training
Estrazione 
delle 
Features  
Modello 
di ML
metrica 
valutazione 
qualità
Calcolo vettore 
dei pesi ŵyi osservato(xi)
 39xi
Funzione  
valutazione 
qualitàŵɸ
(N esempi)
Algoritmo di 
ApprendimentoˆP(yi=+ 1 |xi,ˆw)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#39,39,"Funzione per Valutazione Qualità 
 
40•Dobbiamo ora deﬁnire una funzione che possiamo usare per la 
valutazione della qualità delle prestazioni del sistema. 
•A tal ﬁne possiamo prendere in considerazione le probabilità 
condizionate deﬁnite in precedenza. 
•in particolare, per ciascuno degli esempi di training ( xi, yi) che 
abbiamo disponibili, possiamo calcolare la probabilità di avere in 
uscita un valore y i dato un vettore di pesi w (vedi ﬁgura seguente). "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#4,4,"Introduzione alla Classiﬁcazione
 
5
Vediamo un semplice esempio di classiﬁcazione: 
Supponiamo di voler addestrare un computer a distinguere 
immagini di gatti da immagini di cani (
 task
). 
•
Dobbiamo innanzi tutto procurarci un certo numero di 
immagini (
 training set
 ) in modo da poter addestrare il 
computer: 
"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#40,40,"Maximum Likelihood Estimation 
(
MLE
)
 
41Data Point xi,1 xi,2 yi Scegliere w che massimizza:
x1, y1 2 1 +1 P(y 1=+1| x1, w)
x2, y2 0 2 -1 P(y 2=-1| x2, w)
x3, y3 3 3 -1 P(y 3=-1| x3, w)
x4, y4 4 1 +1 P(y 4=+1| x4, w)
L(w)=P(y1|x1,w)·P(y2|x2,w)·P(y3|x3,w)·P(y4|x4,w)La funzione che possiamo usare per la valutazione della qualità è: "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#41,41," 
42L(w)=NY
i=1P(yi|xi,w)La forma generale della funzione Likelihood  è:
L’obiettivo è dunque quello di massimizzare tale funzione, ad 
esempio mediante Hill Climbing (o Gradient Ascent ), visto che 
non si ha una forma chiusa:
max
wL(w) = max
wNY
i=1P(yi|xi,w)
Maximum Likelihood Estimation 
(
MLE
)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#42,42," 
43•Per il calcolo del gradiente dobbiamo calcolare le varie derivate parziali 
della funzione. 
•Possiamo sempliﬁcare tale calcolo trasformando la funzione,  
considerando il logaritmo naturale del Likelihood: 
•In tal modo trasformiamo i prodotti in somme, pur non cambiando il 
punto di massimo assoluto. Infatti si ha:lnL(w)=l nNY
i=1P(yi|xi,w)=NX
i=1lnP(yi|xi,w)
ˆw= argmax
wL(w) ˆwln= argmax
wlnL(w) ˆw=ˆwln
Log-Likelihood 
[facilita l'operazione di derivazione]"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#43,43,"Log-Likelihood 
[facilita l'operazione di derivazione]
 
44
dove è stata utilizzata la Indicator Function :Per facilitare i calcoli possiamo riscrivere la funzione come segue:
lnL(w)=NX
i=1lnP(yi|xi,w)=
=NX
i=1{I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi= 1]·lnP(yi= 1|xi,w)}"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#44,44," 
45
Log-Likelihood 
[facilita l'operazione di derivazione]
Sostituendo alle probabilità P le seguenti espressioni:
otteniamo, per un solo punto  i, la forma che segue:P(yi=+ 1 |xi,w)=1
1+e wT· (xi)
P(yi= 1|xi,w)=1  P(yi=+ 1 |xi,w)=1 1
1+e wT· (xi)=
=1+e wT· (xi) 1
1+e wT· (xi)=e wT· (xi)
1+e wT· (xi)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#45,45,"Forma della Funzione da Derivare 
[per un punto 
 i
] 
 
46lnL(w)= I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi= 1]·lnP(yi= 1|xi,w)=
= I[yi= +1] ·ln1
1+e wT· (xi)+( 1 I[yi= +1]) ·lne wT· (xi)
1+e wT· (xi)=
= I[yi= +1] ·ln(1 + e wT· (xi))+
+(1 I[yi= +1]) ·[ wT· (xi) ln(1 + e wT· (xi))] =
= (1 I[yi= +1]) wT· (xi) ln(1 + e wT· (xi))"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#46,46," 
47
Regole applicate:
lne wT· (xi)
1+e wT· (xi)=l n ( e wT· (xi)) ln(1 + e wT· (xi))=
= wT· (xi) ln(1 + e wT· (xi))ln1
1+e wT· (xi)= ln(1 + e wT· (xi))
Forma della Funzione da Derivare 
[per un punto 
 i
] "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#47,47," 
48lnL(w)= (1 I[yi= +1]) wT· (xi) ln(1 + e wT· (xi))
Forma della Funzione da Derivare 
[per un punto 
 i
] "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#48,48,"Derivata Parziale per un punto
 
49dove:
e:Per uno solo punto i abbiamo:
@(wT· (xi))
@wj= j(xi)@lnL(w)
@wj= (1 I[yi= +1]) ·@(wT· (xi))
@wj @
@wjln(1 + e wT· (xi))=
= (1 I[yi= +1]) · j(xi)+ j(xi)·P(yi= 1|xi,w)=
= j(xi){I[yi= +1] P(yi=+ 1 |xi,w)}
@
@wjln(1 + e wT· (xi))=  j(xi)·e wT· (xi)
1+e wT· (xi)=  j(xi)·P(yi= 1|xi,w)"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#49,49,"Derivata parziale su tutti i punti
 
50Sommando su tutti i punti i otteniamo:
Questa è la forma della derivata parziale che possiamo usare 
nell’algoritmo di Gradient Ascent  per trovare il vettore ŵ che 
ottimizza la funzione:@lnL(w)
@wj=NX
i=1 j(xi){ tra valore vero e predettoz }| {
I[yi= +1] P(yi=+ 1 |xi,w)}"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#5,5,"Introduzione alla Classiﬁcazione
 
6
•
Dobbiamo poi identiﬁcare le caratteristiche distintive 
(
features
 ) che ci possano consentire di distinguere le due 
tipologie di immagini. Nel nostro caso potremmo ad esempio 
scegliere le due seguenti: 
•
Dimensione del naso (da piccolo a grande) 
•
Forma delle orecchie (da arrotondate ad appuntite) 
supponendo di essere in grado di estrarle dalle immagini. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#50,50,"Algoritmo di Gradient Ascent
 
51w(1)= 0 (oppure lo inizializziamo in modo casuale)
t=1
whilekrlnL(w(t))k2>✏
for j=0,1,. . . ,D
derivata parziale[ j]=NX
i=1 j(xi){I[yi= +1] P(yi=+ 1 |xi,w(t))}
w(t+1)
j w(t)
j+↵⇤derivata parziale[ j]
t t+1"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#51,51,"Riferimenti
 
52
Watt, J., Borhani, R., Katsaggelos, A.K. 
 Machine Learning Reﬁned
 , 2nd edition, 
Cambridge University Press, 2020. 
James, G., Witten, D., Hastie, T., Tibishirani, R. 
 An Introduction to Statistical 
Learning
 , Springer, 2013. 
Ross, S.M. 
 Probabilità e Statistica per l’Ingegneria e le Scienze
 , 3a edizione, 
Apogeo, 2015. 
Machine Learning: Classiﬁcation
 , University of Washington - Coursera, 2017. 
Flach, P. 
 Machine Learning - The Art and Science of Algorithms that Make Sense of 
Data
, Cambridge University Press, 2012. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#6,6,"Introduzione alla Classiﬁcazione
 
7
•Se rappresentiamo le immagini del training set nello spazio 
delle features , abbiamo le seguente situazione, in cui le varie 
immagini appaiono ben aggregate:"
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#7,7,"Introduzione alla Classiﬁcazione
 
8•Ora che abbiamo una buona rappresentazione dei dati di 
training nello spazio delle features, l’ultimo passo per 
addestrare il computer a distinguere le immagini dei gatti da 
quelle dei cani è un problema geometrico: 
•identiﬁcare un modello (ad esempio un linear model ) che 
separi chiaramente i gatti dai cani nello spazio delle 
features."
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#8,8,"Introduzione alla Classiﬁcazione
 
9
•La ﬁgura che segue mostra un modello lineare (la retta in nero) 
“addestrato” ( trained linear model ), che divide lo spazio delle 
features in due regioni. 
•Una volta determinata questa linea, una nuova immagine la cui 
rappresentazione sta al di sopra della linea (regione blu) sarà 
considerata dal computer relativa ad un gatto. Se invece sta 
sotto la linea sarà considerata relativa ad un cane. "
data_test\rootfolder\università\MachineLearning\9-Classification - IntroduzioneLR-sbloccato.pdf#9,9,"Introduzione alla Classiﬁcazione
 
10
•Per veriﬁcare l’efﬁcacia del sistema dobbiamo valutare le sue 
prestazioni su un insieme di immagini ( test set ) distinte da 
quelle usate per l’addestramento: "
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#0,0,Diagrammi a Blocchi
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#1,1,"Cos’è un diagramma a blocchi?Il diagramma a blocchi (diagramma di flusso o flow chart) è uno schema a blocchi utilizzato per rappresentare gli algoritmi.
Si tratta di una rappresentazione grafica che utilizza delle forme geometriche per descrivere gli algoritmi."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#10,10,"Cos’è una variabile?Le variabili sono aree di memoria RAM dove vengono memorizzati i dati e che possono essere cambiati durante l’esecuzione di un’applicazione.
Le costanti invece contengono un valore non modificabile.
Per entrambe è opportuno dare dei nomi sensati, non troppo lunghi e non separati da spazi."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#11,11,"Esercizi struttura sequenziale (1)Eseguire il prodotto tra due numeri;
Calcolare l'ipotenusa date le misure dei cateti di un triangolo rettangolo
Date 2 variabili, scambiarne il contenuto;
Calcolare il numero minimo di banconote per un importo in euro, tenendo conto dei diversi tagli da 500, 200, 100, 50, 20, 10, 5 euro.

"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#12,12,Esercizi struttura condizionale (1)
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#13,13,Esercizi struttura iterativa (1)
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#14,14,"Esercizi vettori (1)Caricamento di 10 numeri in un vettore;
Somma degli elementi di un vettore;
Ricerca di un valore all’interno di un vettore."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#2,2,"Cos’è un algoritmo? A cosa serve?Per algoritmo si intende una successione di passi (o istruzioni) che definiscono le operazioni da eseguire sui dati per ottenere i risultati.
Esempi di algoritmi ne troviamo tantissimi, anche nella vita di tutti i giorni. Tipicamente è necessario un algoritmo a fronte di un problema, come ad esempio: andare a scuola; per risolvere questo problema dobbiamo seguire una sequenza ordinata e finita di passi (algoritmo), come ad esempio:
Svegliarsi  Fare colazione  Vestirsi  Uscire di casa  Prendere l’autobus  Entrare in classe
Quindi, l’insieme dei passi che consentono di risolvere un problema prende nome di algoritmo."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#3,3,"Come si descrive un algoritmo?Ci sono tanti modi per rappresentare un algoritmo, un metodo molto utilizzato è quello basato sui diagrammi a blocchi, conosciuti anche con il nome di flow chart (letteralmente diagrammi di flusso).
Sono dunque utilizzati dei blocchi, cioè delle forme geometriche e ciascuna di essa ha un significato ben preciso."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#4,4,"Quanti e quali blocchi abbiamo in un diagramma?I blocchi convenzionalmente utilizzati in un flow chart sono:
Ellisse
Parallelogramma
Rettangolo
Rombo"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#5,5,"EllisseL’ellisse è utilizzata semplicemente solo per indicare l’inizio e la fine di un diagramma a blocchi.
Quindi ciascun diagramma inizierà con il blocco inizio e terminerà, dopo aver risolto il compito assegnato, con il blocco fine."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#6,6,"ParallelogrammaIl parallelogramma è utilizzato per prendere dei dati in INPUT o per visualizzare dei dati in OUTPUT. 
Nel caso in cui deve prendere dei dati in input è consigliabile inserire una I in alto a sinistra, seguita dai due punti. Similmente per l’output, che si è soliti indicare con una O in alto a sinistra, sempre seguita dai due punti (ma va bene una qualunque altra convenzione)."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#7,7,"RettangoloIl rettangolo è utilizzato per eseguire dei calcoli, ovvero per elaborare dei dati. 
Ad esempio: per calcolare la somma tra due numeri, l’area di un rettangolo, la media fra tre numeri, …"
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#8,8,"RomboIl rombo è utilizzato per le istruzioni condizionali, ovvero per porre una domanda. All’interno dunque viene fatto un test, per cui si valuta una condizione che può essere o vera o falsa, quindi si sceglie tra due strade diverse. 
Un esempio di semplice test potrebbe essere quello di vedere se un numero è positivo o negativo."
data_test\rootfolder\varie\DiagrammiABlocchi.pptx#9,9,RomboIl rombo viene spesso utilizzato anche per i cicli while e do-while.
data_test\rootfolder\varie\HTML&CSS.pptx#0,0,HTML e CSS
data_test\rootfolder\varie\HTML&CSS.pptx#1,1,"Tag base dell’HTML: <p>, <div> e <span><p>, <div> e <span> sono tre diversi tipi di contenitori (di testo o altro), e si comportano in modo diverso:
<p> è un elemento di blocco e lascia spazio prima e dopo la propria chiusura;
<div> è un elemento di blocco, non lascia spazio prima e dopo la propria chiusura, ma va a capo;
<span> è un elemento inline e quindi non va a capo."
data_test\rootfolder\varie\HTML&CSS.pptx#2,2,"Tag base dell’HTML: <ul>, <ol> e <li><ul> e <ol> sono tag che descrivono l’inizio di una lista, in particolare:
<ul> per le liste non ordinate;
<ol> per le liste ordinate.
<li> serve a descrivere l’inizio di un elemento della lista.
Esempio di utilizzo:
"
data_test\rootfolder\varie\HTML&CSS.pptx#3,3,"Tag base dell’HTML: <table>, <tr>, <th> e <td><table> descrive l’inizio di una tabella, e contiene al suo interno i tag <tr>, che descrivono l’inizio di una riga; i tag <tr> a loro volta possono contenere due tag:
<th> per descrivere una cella di «testata»;
<td> per descrivere una generica cella di contenuto."
data_test\rootfolder\varie\HTML&CSS.pptx#4,4,"Tag base dell’HTML: <img><img> serve per inserire un’immagine all’interno della pagina, l’attributo «src» dei questo tag serve a specificare quale immagine caricare."
data_test\rootfolder\varie\HTML&CSS.pptx#5,5,"Tag base dell’HTML: <form>Un form (modulo) è una sezione di documento HTML che contiene elementi di controllo che l’utente può utilizzare per inserire dati o in generale per interagire. I dati inseriti possono essere poi inoltrati al server dove un agente può processarli. Gli elementi di controllo sono caratterizzati da un valore iniziale e da un valore corrente. Gli elementi di controllo possono essere: 
Bottoni di azione
Checkbox (caselle di spunta)
Radio Button (bottoni mutuamente esclusivi)
Liste di selezione (lista di opzioni)
Caselle di inserimento di testo"
data_test\rootfolder\varie\HTML&CSS.pptx#6,6,Esercizi
data_test\rootfolder\varie\homework\id-homework-1.pptx#0,0,Ingegneria dei dati 2022/2023Homework 1Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-1.pptx#1,1,"Homework 1Leggere l'articolo (divulgativo) di Andrew Ng ""Data-centric AI"" (https://spectrum.ieee.org/andrew-ng-data-centric-ai)
In una relazione di circa 300 parole: 1) descrivi quella consideri la tesi più importante dell'autore e 2) esprimi la tua posizione rispetto ad essa. 

Termini di consegna: inviare la relazione entro le ore 12:00 del14 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-2.pptx#0,0,Ingegneria dei dati 2022/2023Homework 2(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-2.pptx#1,1,"Homework 2A partire dal codice github dell'ing. Tommaso Teofili (https://github.com/tteofili/lucenex):
scrivere un programma Java che indicizza i file .txt contenuti in una directory del proprio laptop. In particolare, si devono considerare due campi (e quindi creare due indici): il nome del file, il contenuto del file. Per ciascun campo utilizzare un analyzer appropriato
scrivere un programma Java che legge una query da console, interroga l'indice e stampa il risultato. Usare una semplice sintassi per la query (ad esempio, una query inizia con la parola chiave nome o contentuto seguita da una sequenza di termini (eventualmente racchiusi tra virgolette per esprimere una phrase query)
testare il sistema con una decina di query diverse

Scrivere una relazione che, oltre a riportare l'url del proprio progetto su Github (o analogo) descriva:
gli analyzer che si è scelto di utilizzare (motivando le scelte)
il numero di file indicizzati e i tempi di indicizzazione
le query usate per testare il sistema"
data_test\rootfolder\varie\homework\id-homework-2.pptx#2,2,"Homework 2
Termini di consegna: inviare la relazione entro le ore 21:00 del 22 ottobre 2022 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-3.pptx#0,0,Ingegneria dei datiHomework 3(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-3.pptx#1,1,"Homework 3Implementare l'algoritmo ""MergeList"" per la soluzione al problema ""Joinable Table Search""
Utilizzare la libreria Apache Lucene
Testare la correttezza dell'algoritmo su un piccolo insieme di tabelle, appositamente costruito
Testare l'efficacia e l'efficienza dell'algoritmo sulle tabelle contenute nel dataset ""tables"" del progetto Mentor: https://gitlab.com/Rm3UofA/Mentor/Datasets"
data_test\rootfolder\varie\homework\id-homework-3.pptx#2,2,"Homework 3Ogni team deve preparare 
una presentazione di 5' per illustrare le caratteristiche del dataset 
una presentazione di 10' minuti per illustrare la valutazione sperimentale della propria implementazione dell'algoritmo ""MergeList""
Termini di consegna: entro le ore 19:00 del 2 novembre 2022 ogni membro del team deve inviare le due presentazioni al docente compilando il seguente modulo (compilare il modulo due volte, una per ciascuna presentazione):
             https://forms.office.com/r/PYP0ncXYqc 

Quattro team (scelti dal docente) presenteranno il proprio lavoro nella lezione del 3 novembre 2022


"
data_test\rootfolder\varie\homework\id-homework-3.pptx#3,3,"Presentazione Caratteristiche del DatasetDurata 5'
Deve riportare statistiche sul dataset ""tables"" che possano essere utili all'analisi del problema, all'implementazione dell'algoritmo di soluzione e alla sua valutazione. 
Ad esempio:
Numero di tabelle
Numero medio di righe
Numero medio di colonne
Numero medio di valori nulli per tabella
Distribuzione numero di righe (quante tabelle hanno 1, 2, 3, 4, etc. righe)
Distribuzione numero di colonne (quante tabelle hanno 1, 2, 3, 4, etc. colonne)
Distribuzione valori distinti (quante colonne hanno 1, 2, 3, 4, etc valori distinti)
Altro a vostra scelta
Presentare le statiche in maniera opportuna, anche attraverso l'uso di rappresentazioni grafiche
"
data_test\rootfolder\varie\homework\id-homework-3.pptx#4,4,"Presentazione Valutazione SperimentaleDurata 10'
Deve includere
Descrizione ad alto livello dell'implementazione (classi e metodi principali)
Principali problemi riscontrati nell'implementazione
Valutazione sperimentale:
Con una descrizione chiara e precisa di obiettivi e metriche di ciascun esperimento"
data_test\rootfolder\varie\homework\id-homework-4.pptx#0,0,Ingegneria dei datiHomework 4(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-4.pptx#1,1,"Homework 4 - Esercizio 1Scegliere una tipologia di prodotti su amazon.it (ad esempio fotocamere, oppure prodotti senza glutine)
Scegliere un pagina con un prodotto della tipologia scelta
Individuare nella pagina almeno 5 caratteristiche del prodotto
Scrivere un'espressione XPath per estrarre il nome, il prezzo e il valore di ciascuna delle caratteristiche individuate al punto precedente
Verificare che le espressioni XPath funzionino correttamente su almeno altre 10 pagine di prodotti della stessa categoria
Se una regola XPath non funziona, correggerla affinchè funzioni correttamente su tutte e 10 le pagine

"
data_test\rootfolder\varie\homework\id-homework-4.pptx#2,2,"Homework 4 - Esercizio 2Scegliere un tipo di entità di interesse (ad esempio, giocatori di basketball, aziende, università, etc.)
Cercare 5 sorgenti Web che pubblicano pagine di dettaglio di istanze dell'entità scelta (ad esempio siti web che pubblicano pagine di giocatori di basketball)
Su ogni sorgente scegliere 5 pagine di dettaglio
Scrivere espressioni XPath per estrarre I valori di (almeno) 5 attributi rilevanti su tutte le pagine scelte
"
data_test\rootfolder\varie\homework\id-homework-4.pptx#3,3,"Termini di consegnaOgni studente deve preparare individualmente una relazione in cui descrive l'attività svolta per portare a termine l'homework
Termini di consegna: entro le ore 19:00 del 19 novembre 2022 inviare la relazione al docente compilando il seguente modulo:
             https://forms.office.com/r/PYP0ncXYqc 


"
data_test\rootfolder\varie\homework\id-homework-5.pptx#0,0,Ingegneria dei datiHomework 5(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-5.pptx#1,1,"Homework 5Obiettivo: creare un dataset strutturato con dati estratti da sorgenti Web
Ci interessano dati su una tipologia di entità: aziende
Per semplicità, ci concentriamo su sorgenti in lingua inglese
Scrivere un programma di estrazione dati per almeno 1000 istanze da almeno 4 sorgenti web"
data_test\rootfolder\varie\homework\id-homework-5.pptx#2,2,"TecnologieE' possibile usare una delle seguenti tecnologie (ma è possibile usarne altre)

In Python: 
https://scrapy.org/ 
https://www.crummy.com/software/BeautifulSoup/
In Java: 
https://www.selenium.dev/ 
https://jsoup.org/ 

"
data_test\rootfolder\varie\homework\id-homework-5.pptx#3,3,"Termini di consegnaOgni team deve preparare una presentazione così strutturata
1 minuto per illustrare come è stata scelta la tecnologia per implementare il sistema di estrazione
2 minuti per illustrare l'architettura del sistema di estrazione dati realizzato
3 minuti per illustrare le prestazioni del sistema di estrazione
4 minuti per illustrare le caratteristiche delle sorgenti e le caratteristiche del dataset ottenuto
Termini di consegna: 
entro le ore 19:00 del 9 dicembre 2022 inviare la presentazione al docente compilando il seguente modulo: https://forms.office.com/r/PYP0ncXYqc 
Il 13 dicembre, ogni team dovrà consegnare il dataset con i dati estratti al docente (in un file compresso). Ogni team può liberamente scegliere in che modo strutturare il dataset
Quattro team (scelti dal docente) presenteranno il proprio lavoro nelle lezioni del 13 e del 15 dicembre 2022
"
data_test\rootfolder\varie\homework\id-homework-6.pptx#0,0,Ingegneria dei datiHomework 6(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-6.pptx#1,1,"Homework 6Leggere uno tra questi due articoli: 
Y. Suhara et at ""Annotating Columns with Pre-trained Language Models"" (https://arxiv.org/pdf/2104.01785.pdf) 
K. Koutras et at ""Valentine: Evaluating Matching Techniques for Dataset Discovery""(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458921) 
In una relazione di circa 900 parole, descrivere: 1) descrivere  il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 
Leggere l'articolo (scientifico):
P. Konda et al. ""Magellan: Toward Building Entity Matching Management Systems"" (http://www.vldb.org/pvldb/vol9/p1197-pkonda.pdf)
In una relazione di circa 900 parole, descrivere: 1) il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. 

Termini di consegna: inviare le due relazioni entro le ore 18:00 del 5 gennaio 2023 attraverso il seguente modulo online:https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-7.pptx#0,0,Ingegneria dei datiHomework 7(da svolgere individualmente)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-7.pptx#1,1,"Homework 7L'obiettivo dell'homework è quello di valutare il sistema CERTA per la generazione di spiegazioni di diversi sistemi di Record Linkage basati su tecniche di deep learning

Seguire le istruzioni riportate a questo indirizzo:
	 https://gist.github.com/tteofili/eaaeaaa8af2d22005fe199f1dc8874ad 

Termini di consegna: entro le ore 18.00 del 21 gennaio 2023 caricare il file cvv nel seguente modulo:
	https://forms.office.com/r/PYP0ncXYqc "
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#0,0,Ingegneria dei datiHomework 8(da svolgere in gruppo)Paolo Merialdo
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#1,1,"Homework 8L'obiettivo dell'homework è quello di integrare le sorgenti dati collezionate da tutti i team nell'homework 5 e di arricchirle con le tecniche sviluppate nell'homework 3 
Analizzare le sorgenti dati e individuare le principali eterogeneità
Definire uno schema mediato opportuno ed allineare gli schemi delle sorgenti allo schema mediato. È possibile usare:
Una soluzione custom (anche manuale)
FlexMatcher https://flexmatcher.readthedocs.io/en/latest/ 
Coma https://sourceforge.net/projects/coma-ce/  
Uno dei tool del progetto Valentine https://github.com/delftdata/valentine
Calcolare il Record linkage. E' possibile usare:
Una soluzione custom
Python Record Linkage Toolkit https://recordlinkage.readthedocs.io/en/latest/ 
Magellan https://github.com/anhaidgroup/deepmatcher
DeepMatcher (soluzione neural network) https://github.com/anhaidgroup/deepmatcher 
Ditto (soluzione neural network) https://github.com/megagonlabs/ditto 
EMT (soluzione neural network molto simile a Ditto) https://github.com/brunnurs/entity-matching-transformer 
Un sistema non supervisionato  https://github.com/uestc-db/Unsupervised-Entity-Resolution oppure https://github.com/chu-data-lab/zeroer
Arricchire i dati integrati usando le tecniche (e il dataset di tabelle) sviluppate nell'homework 3
"
data_test\rootfolder\varie\homework\id-homework-8-progetto-finale.pptx#2,2,"Termini di consegnaPreparare un documento scritto di 4 pagine e una presentazione di 15' che descrivano:
Le caratteristiche salienti delle sorgenti
I benefici potenziali di integrare i loro dati
Lo schema mediato
Le soluzioni che avete scelto per integrare i dati
Le prestazioni (in termini id precision, recall, F-measure, tempi di calcolo, sforzo umano)
I dati tabulari che avete trovato per arricchire le informazioni integrate dalle sorgenti
Il documento e la presentazione vanno consegnati caricandoli attraverso il modulo all'indirizzo:
	https://forms.office.com/r/PYP0ncXYqc
"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#0,0,"Caratteristiche del dataset tables - Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#1,1,Formato del dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#10,10,Distribuzione numero di colonne
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#11,11,Distribuzione numero di valori distinti per colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#12,12,Distribuzione percentuale di valori distinti per colonna
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#2,2,Formato del dataset
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#3,3,"Formato delle celle
	- Celle vuote e «None»
	- Classificazione tipi di cella"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#4,4,"Formato delle celle
	- Frequenza di termini all’interno del dataset"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#5,5,"Formato delle celle
	- Frequenza di termini all’interno del dataset"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#6,6,"Formato delle righe
	- Righe con celle vuote e con celle «None»"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#7,7,"Formato delle colonne
	- Colonne con celle vuote e con celle «None»
	- Classificazione tipi di colonna"
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#8,8,Distribuzione numero di righe
data_test\rootfolder\varie\relazioni\HW3-AnalisiDelDataset.pptx#9,9,"Fun Fact
	- Tabelle con 100 righe: 5 076"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#0,0,"Ingegneria Dei Dati:Valutazione Sperimentale Homework 3 Federico Bianchi	--  Matr. 534835
Andrea de Donato  -- Matr. 536795
Paolo Di Simone  -- Matr. 584638dedo99/Homework3 (github.com)Link Repository Progetto:"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#1,1,"Organizzazione del progetto: packageIndex
indicizzazione di tutto il file in inputModel
modello utilizzato per estrarre i dati dal datasetQuery
esecuzione delle query ed estrazione dei documenti ritenuti compatibili"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#10,10,"Valutazione sperimentale del progetto (2)Tempo necessario per l’indicizzazione dell’intero file JSON contenente 550.271 tabelle (14,2 Gb): 297.882 s (c.a. 5 minuti)

Query d’esempio [«singlular», «plural», «fmou», «dual»], tempo di esecuzione:
Con SimpleTextCodec: 18 minuti
Senza SimpleTextCodec: 6 secondi"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#11,11,"Valutazione sperimentale del progetto (3)Per testare l’efficacia e l’efficienza del sistema sono state effettuate tre tipologie di test:

Test al variare di k

Test al variare della lunghezza della query

Precision, Recall, F1 e Accuracy su dataset di test"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#12,12,Test al variare di k
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#13,13,Test al variare della lunghezza della query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#14,14,"Dataset di testÈ stato costruito un dataset per testare l’efficacia del sistema, con le seguenti caratteristiche:

30 tabelle

Ogni tabella riporta informazioni su film, libri, autori, attori, …"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#15,15,Dataset di test
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#16,16,Dataset di test: distribuzione righe
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#17,17,Dataset di test: distribuzione colonne
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#18,18,Dataset di test: distribuzione valori distinti
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#19,19,"QuerySono state costruite 23 query di test, ottenute calcolando lo score Jaccard fra tutte le possibili coppie di colonne all’interno del dataset. Ogni query di test contiene:

Colonna di valori che rappresenta la query

Top 3 colonne con score Jaccard più alto"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#2,2,Le classiIndexCellModelCoordinatesQueryJSONObjectJSONIndexerQueryManager
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#20,20,Query
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#21,21,"Precision, Recall, F1 e Accuracy"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#22,22,"QuerySolo per una query il sistema non restituisce alcun risultato corretto:
[«USA», «USA», «USA», «USA», «USA», «USA», «USA»]

Le altre query su cui il sistema fatica a restituire il risultato corretto sono molto simili:
[«USA», «Italia», «Italia», «Francia», «Inghilterra», …]"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#3,3,"Classe JSONIndexer (1)La classe JSONIndexer è composta da due metodi:


readJsonStream(InputStream in, Codec codec): lettura dell’input dal file JSON


indexJSONStream(JsonReader reader, Codec codec): estrazioni degli oggetti JSON (tabelle) dal reader, parsing in un oggetto Java e successiva indicizzazione. I documenti inseriti nell’indice corrispondono ciascuno ad una colonna di una tabella.


Uso della libreria Gson per convertire rappresentazioni JSON in oggetti Java e viceversa."
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#4,4,"Classe JSONIndexer (2)Definizione di un Tokenizer CustomCreazione dei documentiAnalyzer analyzer = CustomAnalyzer.builder()        .withTokenizer(PatternTokenizerFactory.NAME, ""pattern"", ""~"", ""group"", ""-1"")        .build();for(Cell c : obj.getCells())    if (!c.getHeader()) {        if(colonnaXvalori.containsKey(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString())) {            String value = colonnaXvalori.get(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString());            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), value + ""~"" + c.getCleanedText());        } else            colonnaXvalori.put(obj.getId() + ""_"" + c.getCoordinates().getColumn().toString(), c.getCleanedText());    }"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#5,5,"Classi JsonObject, Cell e CoordinatesLe classi JsonObject, Cell e Coordinates sono stati realizzate per rendere agevole la trasformazione da un oggetto Json ad un oggetto Java.

Le seguenti classi sono dotate di variabili di istanza, relative alle sole informazioni necessarie rispetto al completo contenuto dell’oggetto Json, e i corrispondenti metodi setter e getter.public class JSONObject {
 String id;
 Cell[] cells;
}public class Cell {
 Boolean isHeader;
 String cleanedText;
 Coordinates Coordinates;
}public class Coordinates {
 Double row;
 Double column;
}"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#6,6,"Classe QueryManager
mergeList(int n, String[] queryString) restituisce le prime n colonne tra tutte le tabelle che hanno corrispondenze con il maggior numero di termini nella query

executeQuery(String field, String[] queryString) genera una mappa (idTabella_idcolonna -> numero corrispondenze) scansionando tutti gli elementi presenti nella query

sortMapByValues(Map<String, Integer> columnsXcount) effettua l’ordinamento della mappa sull’intero contenuto nel campo valore

runQuery(IndexSearcher searcher, Query query,  Map<String, Integer> columnsXcount) restituisce per ciascun elemento della query una mappa con le colonne delle tabelle in cui è presente

"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#7,7,"Problemi riscontratiIndividuare la corretta rappresentazione dei documenti nell’indice

Individuare un modo corretto di tokenizzare i documenti (nello specifico il campo ‘value’)

Tempi di indicizzazione"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#8,8,"ObiettiviImplementare nel modo più efficiente l’indicizzazione di una grande quantità di dati

Restituire, a seguito di una query, le tabelle con la relativa colonna in cui sono state incontrate delle corrispondenze senza includere nel conteggio eventuali ripetizioni dello stesso termine nella colonna 

Restituire in ordine decrescente i risultati sulla base del numero di corrispondenze ottenute"
data_test\rootfolder\varie\relazioni\HW3-ValutazioneSperimentale.pptx#9,9,"Valutazione sperimentale del progetto (1)Tutti i risultati sono stati ottenuti utilizzando un calcolatore con le seguenti specifiche:

Processore Intel core i7 di 8° gen

RAM 8Gb

SSD 512Gb"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#0,0,"Web Scraping:Scraping business informationDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
13 Dicembre 2022Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselGitHub: Web Scraping- Homework5"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#1,1,"Purpose del progettoIntroduzioneAutomatizzazione della ricerca ed estrazione di informazioni relative ad aziende


Utilità

Creazione di un dataset relativo ad aziende per diversi task:
Addestramento modello AI
Analytics

Data IntegrationScopo"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#10,10,Sorgente: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#11,11,Sorgente: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#12,12,"Efficacia X-Paths: Data ConsistencyAnalisi pattern

Address, Business code, Business name (E-business), Date, ecc…

Analisi frequenza valori celle 
Legal form, Status, ecc…



Analisi frequenza token 
Business name, ecc…Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#13,13,"Efficacia X-Paths: Analisi PatternTable: GOV.UK

Field: Address

Example values: '38SpringfieldRoad Gillingham Kent England ME71YJ’



    
Regex: 
	([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|
	(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|
	([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\s?[0-9][A-Za-z]{2})
UK Postal codeLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#14,14,"Efficacia X-Paths: Analisi PatternIndirizzi non conformi

Austrasse429490 Vaduz Liechtenstein

Pasiadou5KatoLakatamia 2332Nicosia Nicosia Cyprus

LaChausseeStreet PortLouis MauritiusLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#15,15,"Efficacia X-Paths: Frequenza ValoriTable: E-Business

Field: Legal form

Example values:
Private limited company, Public limited company, Non-profit association, ecc…


    
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#16,16,Efficacia X-Paths: Frequenza ValoriLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#17,17,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Example values: P & A PROPERTY (WESTON) LIMITED, P A JONES LIMITED, P A H 		       CARPENTRY & JOINERY LTD  

	
    
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#18,18,"Efficacia X-Paths: Frequenza TokenTable: GOV.UK

Field: Name

Most frequent tokens:
Limited, LTD,LTD., Services, …


    
Analisi

1466 su 1469 hanno nel loro nome 
      i 10 token più frequenti
1 ) LIMITED -> 728
2 ) LTD -> 533
3 ) SERVICES -> 94
4 ) ELECTRICAL -> 38
5 ) CONSTRUCTION -> 37
6 ) BUSINESS -> 36
7 ) CORP. -> 35
8 ) PROPERTIES -> 34
9 ) HOMES -> 27
10 ) LTD. -> 26
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#19,19,"Test sistema: WorkflowIl sistema è stato testato nel seguente modo:
Campionamento casuale del dataset estratto:
Companiesmarketcap  30 URL
Infoclipper  50 URL
GovUK  29 URL
Ebusiness  30 URL
Estrazione manuale dei dati contenuti nel campione selezionato
Confronto dati estratti dal sistema e dati ottenuti manualmente
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#2,2,"Ricerca sitiFiltraggio sitiSchema datiParsing dati &
Data ConsistencyAcquisizione datiAnalisi datiRoad mapIntroduzione"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#20,20,"Test sistema: companiesmarketcap.comLilla SystemErrori dovuti esclusivamente alla variabilità giornaliera dei campi
"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#21,21,Test sistema: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#22,22,Test sistema: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#23,23,"Test sistema: info-clipper.comLilla SystemPostalcode
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {187’, 00187’} 
State
Nel nostro sistema nel campo state inseriamo anche la sigla dello stato, nei test l’utente non inserisce nel campo State la sigla  {'California(CA)', 'California'} "
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#24,24,Test sistema: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#25,25,"Test sistema: gov.ukLilla SystemCompany ID
Le differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {'6174105', '06174105’} 
Company Status
Gli errori sono dovuti al cambiamento di status dell’azienda  {'Active', 'Dissolved'}
Dissolution Date
L’azienda nel frattempo è stata dissolta  {'nan', 14 February 2023 '} 
"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#26,26,"Efficienza temporale: Estrazione datiTempo complessivo

Tempo di request 

Tempo di estrazione del dato (navigazione del dom via X-Path)
Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#27,27,Efficienza temporale: RequestLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#28,28,"Efficienza temporale: Estrazione datiLilla System//div[@class = ""company-code""]//*[@id=""cmkt""]/div[3]/div[1]/div[2]/div[3]/div[1]/a/text()"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#29,29,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#3,3,"
Beautiful soup

Request

LXML & Etree
Web ScrapingPandas & numpy                    	
Matplotlib

Geopandas
Data ProfilingTecnologieLilla SystemPython"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#30,30,"Dataset: companiesmarketcap.com   Analisi campi

Name: Nome dell’azienda
Company Code: Codice identificativo delle società quotate in borsa (WMT, AMZN, UPS, KR, …)
Marketcap: Somma del valore totale delle azioni in circolo
Share Price: Costo singola azione
Earnings: Profitto annuo
Revenue: Ricavi annui
Shares: Numero totale di azioni in circolo
Employees: Numero totale di dipendenti


  Numeriche generali

Totale istanze: 1400
Totale colonne: 10


Celle totali: 14000
Valori nulli: 21Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#31,31,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#32,32,Dataset: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#33,33,Dataset: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#34,34,"Dataset: e-BusinessAnalisi campi

Name: Nome dell’azienda
Company code: Codice identificativo dell’azienda
Legal Form: Forma giuridica dell’azienda
Status: Status dell’azienda (Deleted, Entered into the register, ecc…)
Registration Date: Data di inserimento dell’azienda nel registro
Capital: Capitale dell’azienda
Address: Indirizzo sede dell’azienda
Deletion Time: Data di eliminazione dell’azienda dal registro

  Numeriche generali

Totale istanze: 1469
Totale colonne: 10



Celle totali: 14690
Valori nulli: 2120 Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#35,35,Dataset: e-BusinessLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#36,36,Dataset: e-BusinessESTONIALilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#37,37,"Dataset: info-clipper.comAnalisi campi

Name: Nome dell’azienda
Trade Name: Nome commerciale dell’azienda
Address: Indirizzo sede dell’azienda
City: Città 
Postalcode: Codice postale nei formati UK, USA, Italia, Estonia
State: Stato Americano di residenza o Nazione di residenza
Country: Nazione di residenza
Location type: Tipo di sede (es. Headquarter, Secondary Office, ecc…)



  Numeriche generali

Totale istanze: 1504
Totale colonne: 10



Celle totali: 15040
Valori nulli: 1289Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#38,38,"Dataset: info-clipper.com


Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#39,39,"Dataset: info-clipper.com


STATI UNITILilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#4,4,"Lilla
SystemGeneral web pageRequest: get informationResponse: list of linksRequest: get all linksResponse:  informationCreate datasetSpecific web pageDatasetData Parsing and
Data ConsistencyArchitetturaLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#40,40,"Dataset: info-clipper.com


ESTONIALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#41,41,"Dataset: info-clipper.com


ITALIALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#42,42,"Dataset: info-clipper.com


INGHILTERRALilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#43,43,"Analisi campi

Name: Nome dell’azienda
Company ID: Codice identificativo dell’azienda
Company Status: Status dell’azienda (Active, Dissolved, Registered, Liquidated)
Company Type: Tipo dell’azienda (Overseas Entity, Private Limited Company, ecc…)
Registration Date: Data di registrazione di aziende estere
Incorporation Date: Data di inserimento delle aziende inglesi nel registro
Dissolution Date: Data di dissoluzione dell’azienda
Office Address: Indirizzo dell’azienda


Dataset: gov.uk  Numeriche generali

Totale istanze: 1331
Totale colonne: 10



Celle totali: 13310
Valori nulli: 2555Lilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#44,44,Dataset: gov.ukLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#45,45,Dataset: gov.ukREGNO UNITOLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#46,46,Dataset: gov.ukINGHILTERRALilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#47,47,"Member: Pietro Baroni
Matricola: 536373
Task: Algoritmi
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Task: Analytics
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693 
Task: AlgoritmiLinkedin: Matteo WisselTeamLilla System"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#48,48,"GRAZIE PER L’ATTENZIONERoma, 13  Dicembre 2022GitHub: Web Scraping- Homework5"
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#5,5,Sorgente: companiesmarketcap.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#6,6,Sorgente: ariregister.rik.ee (e-Business)Lilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#7,7,Sorgente: ariregister.rik.ee (e-Business)Lilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#8,8,Sorgente: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW5-WebScarping.pptx#9,9,Sorgente: info-clipper.comLilla System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#0,0,"Data integration:Arlecchino systemDipartimento di Ingegneria
Corso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico 
2022-2023
22 Febbraio 2023Corso Ingegneria dei datiProfessore
Paolo MerialdoStudenti
Paolo Di Simone
Pietro Baroni
Matteo WisselArlecchino System
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#1,1,"Purpose del progettoIntroduzioneUse Case

Integrazione di dataset aziendaliScopo

Implementazione di un sistema di Data IntegrationDataset

Dataset_Corso_Ingegneria_dei_Dati_2022/23
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#10,10,"ParsingArlecchino SystemParsing nomi colonne
Trasformazione in lower case  
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)  Parsing valori celle 

Parsing di stringhe: 
Trasformazione in lower case
Eliminazione caratteri speciali (-, /, …)
Eliminazione di skip words (of, the, del, di, …)
Esempio: Amazon -> amazon
  
Parsing di valori monetari:
Normalizzazione valori 
Inserimento unità di misura
Esempio: $102 million -> doll_ 0.102 b 

Parsing valori percentuali
Parsing valori rank
Parsing valori date
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#11,11,Schema matching: Formulazione problemaArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#12,12,"Schema Matching: Matching Module (SMM)Arlecchino SystemPre-processing module

Input: colonne e samples di valori 
Output: un dizionario parziale di sinonimi
Utilità: 1. riduzione del search space del JaccardModule
    2. inferisce informazioni al JaccardModule  
JaccardModule

Input: dizionario sinonimi_preprocessing
Output: dizionario sinonimi_finale
Utilità: trova le reali correlazioni semantiche tra le colonneUser"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#13,13,"SMM: MotivazioniArlecchino SystemAnalisi senza pre-processingAnalisi con pre-processingSample data: 1000 per colonna
Colonne totali: 18
Numero medio di sinonimi reali: 1.6 

Stima confronti totali: ≈ 153
Numero medio confronti per colonna: ≈ 18
Numero medio di confronti inutili: ≈ 17
Esempio 
cluster cbinsightsSample data: 1000 per colonna

Colonne totali: 18

Numero medio di sinonimi reali: 1.6

Stima confronti totali: 14
Numero medio confronti per colonna:  2.5
Numero medio di confronti inutili: 0.84

Fattore di riduzione: ≈ 12"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#14,14,"Pre-processing: Name SimilarityArlecchino SystemName similarity di colonne

Input: (column_names, dizionario_sinonimi_pregressi)
Output: un dizionario parziale di sinonimi
Utilità: individua i sinonimi schema-wise 
	(dettati da similarità di nome)Logica:	
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#15,15,"Pre-processing: Data CorrelationArlecchino System

Data similarity di colonne [1]

Input: (sample_dati_colonne)
Output: un dizionario sinonimi4cluster
Utilità: individua i sinonimi data-wise
	(dettati da similarità di dati) [1] Schema Matching using Machine LearningTanvi Sahay, Ankita Mehta, Shruti Jadon"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#16,16,"SMM: Features EngineeringArlecchino SystemFeatures selezionate
Min_val
Max_val
Avg
Variance
Standard_Dev
Is_incremental
Is_year Type_of_string (1 perc_, 2 rank_, 3 link, 4-5 monetari, 6 resto)
AVG_monetary_value
AVG_len_of_field
VAR_len_of_field
SDEV_len_of_field
Ratio_white_space
Ratio_numeric_values
Is_country (1 se country, 0 altrimenti)
Is_sector (1 se sector, 0 altrimenti)1. Type_of_data (0 string, 1 integer, 2 date)for Integerfor stringsfor date"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#17,17,"Pre-processing: Analisi OutputArlecchino SystemDizionario sinonimi_preprocessing (largo)

Unione dei dizionari di sinonimi prodotti dai due step di pre-processing
Scopo: limitare eventuali errori (high recall)
Esempio (companiesmarketcap):
Token: market_cap

True_sinonimi
	market_cap->{marketcap, market_capitalization, pricecap, …}
sinonimi4NameCorr
	market_cap->{marketcap, market_capitalization,…}

sinonimi4Clusters
	market_cap->{marketcap, pricecap, …}

sinonimi_preprocessing
	market_cap->{marketcap, market_capitalization, pricecap, …}
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#18,18,"SMM: JaccardModuleArlecchino SystemJaccardModule

Input: sinonimi_preprocessing

Logica: per ogni colonna c presente nel dizionario dei sinonimi_preprocessing, il sistema genera un file .csv contenente tutte le colonne giudicate sinonimi"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#19,19,"SMM: OutputArlecchino SystemDizionario sinonimi finali

Risultato finale del Matching module
Per ogni colonna dello schema mediato è definita  una lista di  possibili sinonimi (colonne semanticamente simili)

L’utente seleziona i match opportuni eliminando eventuali errori del sistema

Al netto della validazione dell’utente, il sistema aggiorna il dizionario dei sinonimi pregressi


User"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#2,2,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#20,20,Schema MediatoArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#21,21,"Record LinkageArlecchino SystemInput: schema mediato (184.587 record)

Output: dataset finale

Scopo: Trovare nella tabella in input i record relativi alla stessa entità ed unirli in un unico record

 Record Linkage
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#22,22,"Record Linkage: BlockingArlecchino SystemNumero di confronti iniziali: 34.072.360.569 Numero di confronti post-blocking: 2.177.713Tempi: 76 min 36 secBlocking step1. overlap di una parola nel nome delle aziende

2. overlap di una parola nel paese delle aziende (se presente)

3. Indice di Levenshtein < 0.7 tra i nomi
 delle aziende

"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#23,23,"Record Linkage: Training SetArlecchino SystemTotale record: 1300

Divisi in training set, test set e validation set (ratio 3:1:1)

Label Match: 695

Label No-Match: 605

Training set"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#24,24,"Record Linkage: Model TrainingArlecchino SystemIperparametri:
Epoche = 10
Dimensione batch = 16 
Statistiche:
Tempo impiegato: 10 min 29 secModello utilizzato: Matching Model di Deep MatcherModel Training"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#25,25,"Record Linkage: PredictionArlecchino SystemStatistiche:
Predizioni effettuate: 2.177.713
Predizioni Match: 1.480.727
Tempo impiegato: 14 ore e 45 minuti
Utilizzo del modello addestrato per eseguire le predizioni sulle coppie non bloccatePrediction"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#26,26,Record Linkage: JoinArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#27,27,Schema IntegratoArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#28,28,"ArricchimentoColonna usate come input:
Nome dell’azienda
CEO dell’aziendaTabelle con più occorrenze in output:
List of S&P 500 companies
List of largest companies by revenue
List of largest European manufacturing companies by revenue
List of multinationals with research and development centres in Israel
List of largest Nordic companies
Automotive industryPMF system(HW3)Top table ids Dataset utenteinput (Schema mediato, 
[name, ceo] )Indice HW3Arlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#29,29,Schema ArricchitoArlecchino System142 celle riempite
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#3,3,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#30,30,"Testing SMM: MetricheArlecchino SystemLogica

 Confronto tra i sinonimi computati per una colonna dello schema mediato S e i sinonimi veri S’

Metriche

Numero di confronti inutili effettuato per sorgente

Similarità tra sinonimi computati:
Precision
Recall
F1"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#31,31,Testing: Pre-Processing per clustering (Conf.)Arlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#32,32,Testing: performance SMM clusterArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#33,33,"Testing: Pre-Processing per clusteringArlecchino SystemRisultati
"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#34,34,"Testing: JaccardModule for cluster Arlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0.5 "
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#35,35,Testing: Pre-processing for schema mediatoArlecchino SystemRisultati
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#36,36,Testing: performance SMM schema finaleArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#37,37,"Testing: Schema MediatoArlecchino SystemConfigurazione

Threshold Jaccard*: 0.1

Threshold edit: 0..5Pre-processingJaccardModule"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#38,38,Testing: Record LinkageArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#39,39,MiglioramentiArlecchino System
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#4,4,Caratteristiche dei sorgenti: ClusterSorgenti	
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#40,40,"Member: Pietro Baroni
Matricola: 536373
Linkedin: Pietro BaroniMember: Paolo Di Simone
Matricola: 584638
Linkedin: Paolo Di SimoneMember: Matteo Wissel
Matricola: 534693Linkedin: Matteo WisselTeamArlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#41,41,"GRAZIE PER L’ATTENZIONERoma, 22 Febbraio 2023GitHub: Arlecchino System"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#5,5,"Analisi dei sorgentiDati finanziari
Dati giuridici
Dati geografici
Dati di personale
Etichette tipologie datiSorgenti	"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#6,6,"Struttura dello schema mediato Schema mediatoVisione unificata delle informazioni


Schema mediato
Benefici"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#7,7,Arlecchino SystemArlecchino System…
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#8,8,"TecnologieArlecchino SystemSchema Matching

Preprocessing Module - custom
JaccardModule - customRecord Linkage

Magellan (py_entitymatching)
DeepMatcherData Enrichment

 Sistema HW3"
data_test\rootfolder\varie\relazioni\HW8-DataIntegration.pptx#9,9,ArchitetturaArlecchino SystemParsing&CleaningSchema MatchingRecord Linkage
